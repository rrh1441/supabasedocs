This file is a merged representation of the entire codebase, combined into a single document by Repomix. The content has been processed where security check has been disabled.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Security check has been disabled - content may contain sensitive information
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
supabase_com_docs_guides_ai_automatic_embeddings.md
supabase_com_docs_guides_ai_choosing_compute_addon.md
supabase_com_docs_guides_ai_concepts.md
supabase_com_docs_guides_ai_engineering_for_scale.md
supabase_com_docs_guides_ai_examples_building_chatgpt_plugins.md
supabase_com_docs_guides_ai_examples_headless_vector_search.md
supabase_com_docs_guides_ai_examples_huggingface_image_captioning.md
supabase_com_docs_guides_ai_examples_image_search_openai_clip.md
supabase_com_docs_guides_ai_examples_mixpeek_video_search.md
supabase_com_docs_guides_ai_examples_nextjs_vector_search.md
supabase_com_docs_guides_ai_examples_openai.md
supabase_com_docs_guides_ai_examples_semantic_image_search_amazon_titan.md
supabase_com_docs_guides_ai_going_to_prod.md
supabase_com_docs_guides_ai_google_colab.md
supabase_com_docs_guides_ai_hugging_face.md
supabase_com_docs_guides_ai_hybrid_search.md
supabase_com_docs_guides_ai_integrations_amazon_bedrock.md
supabase_com_docs_guides_ai_integrations_llamaindex.md
supabase_com_docs_guides_ai_integrations_roboflow.md
supabase_com_docs_guides_ai_keyword_search.md
supabase_com_docs_guides_ai_langchain.md
supabase_com_docs_guides_ai_python_api.md
supabase_com_docs_guides_ai_python_clients.md
supabase_com_docs_guides_ai_quickstarts_face_similarity.md
supabase_com_docs_guides_ai_quickstarts_generate_text_embeddings.md
supabase_com_docs_guides_ai_quickstarts_hello_world.md
supabase_com_docs_guides_ai_quickstarts_text_deduplication.md
supabase_com_docs_guides_ai_rag_with_permissions.md
supabase_com_docs_guides_ai_semantic_search.md
supabase_com_docs_guides_ai_structured_unstructured.md
supabase_com_docs_guides_ai_vecs_python_client.md
supabase_com_docs_guides_ai_vector_columns.md
supabase_com_docs_guides_ai_vector_indexes_hnsw_indexes.md
supabase_com_docs_guides_ai_vector_indexes_ivf_indexes.md
supabase_com_docs_guides_ai_vector_indexes.md
supabase_com_docs_guides_ai.md
supabase_com_docs_guides_api_api_keys.md
supabase_com_docs_guides_api_automatic_retries_in_supabase_js.md
supabase_com_docs_guides_api_creating_routes.md
supabase_com_docs_guides_api_quickstart.md
supabase_com_docs_guides_api_rest_auto_generated_docs.md
supabase_com_docs_guides_api_rest_client_libs.md
supabase_com_docs_guides_api_rest_generating_types.md
supabase_com_docs_guides_api_securing_your_api.md
supabase_com_docs_guides_api_sql_to_api.md
supabase_com_docs_guides_api_sql_to_rest.md
supabase_com_docs_guides_api_using_custom_schemas.md
supabase_com_docs_guides_api.md
supabase_com_docs_guides_auth_architecture.md
supabase_com_docs_guides_auth_auth_anonymous.md
supabase_com_docs_guides_auth_auth_captcha.md
supabase_com_docs_guides_auth_auth_email_passwordless.md
supabase_com_docs_guides_auth_auth_email_templates.md
supabase_com_docs_guides_auth_auth_helpers_auth_ui.md
supabase_com_docs_guides_auth_auth_helpers_flutter_auth_ui.md
supabase_com_docs_guides_auth_auth_helpers_nextjs_pages.md
supabase_com_docs_guides_auth_auth_helpers_nextjs.md
supabase_com_docs_guides_auth_auth_helpers_remix.md
supabase_com_docs_guides_auth_auth_helpers_sveltekit.md
supabase_com_docs_guides_auth_auth_helpers.md
supabase_com_docs_guides_auth_auth_hooks_custom_access_token_hook.md
supabase_com_docs_guides_auth_auth_hooks_mfa_verification_hook.md
supabase_com_docs_guides_auth_auth_hooks_password_verification_hook.md
supabase_com_docs_guides_auth_auth_hooks_send_email_hook_490.md
supabase_com_docs_guides_auth_auth_hooks_send_email_hook.md
supabase_com_docs_guides_auth_auth_hooks_send_sms_hook.md
supabase_com_docs_guides_auth_auth_hooks.md
supabase_com_docs_guides_auth_auth_identity_linking.md
supabase_com_docs_guides_auth_auth_mfa_phone.md
supabase_com_docs_guides_auth_auth_mfa_totp.md
supabase_com_docs_guides_auth_auth_mfa.md
supabase_com_docs_guides_auth_auth_smtp.md
supabase_com_docs_guides_auth_debugging_error_codes.md
supabase_com_docs_guides_auth_enterprise_sso_auth_sso_saml.md
supabase_com_docs_guides_auth_enterprise_sso.md
supabase_com_docs_guides_auth_general_configuration.md
supabase_com_docs_guides_auth_identities.md
supabase_com_docs_guides_auth_jwts.md
supabase_com_docs_guides_auth_managing_user_data.md
supabase_com_docs_guides_auth_native_mobile_deep_linking.md
supabase_com_docs_guides_auth_password_security.md
supabase_com_docs_guides_auth_passwords.md
supabase_com_docs_guides_auth_phone_login.md
supabase_com_docs_guides_auth_quickstarts_nextjs.md
supabase_com_docs_guides_auth_quickstarts_react_native.md
supabase_com_docs_guides_auth_quickstarts_react.md
supabase_com_docs_guides_auth_rate_limits.md
supabase_com_docs_guides_auth_redirect_urls.md
supabase_com_docs_guides_auth_server_side_advanced_guide.md
supabase_com_docs_guides_auth_server_side_creating_a_client.md
supabase_com_docs_guides_auth_server_side_migrating_to_ssr_from_auth_helpers.md
supabase_com_docs_guides_auth_server_side_nextjs.md
supabase_com_docs_guides_auth_server_side_sveltekit.md
supabase_com_docs_guides_auth_server_side.md
supabase_com_docs_guides_auth_sessions_implicit_flow.md
supabase_com_docs_guides_auth_sessions_pkce_flow.md
supabase_com_docs_guides_auth_sessions.md
supabase_com_docs_guides_auth_signout.md
supabase_com_docs_guides_auth_social_login_auth_apple.md
supabase_com_docs_guides_auth_social_login_auth_azure.md
supabase_com_docs_guides_auth_social_login_auth_bitbucket.md
supabase_com_docs_guides_auth_social_login_auth_discord.md
supabase_com_docs_guides_auth_social_login_auth_facebook.md
supabase_com_docs_guides_auth_social_login_auth_figma.md
supabase_com_docs_guides_auth_social_login_auth_github.md
supabase_com_docs_guides_auth_social_login_auth_gitlab.md
supabase_com_docs_guides_auth_social_login_auth_google.md
supabase_com_docs_guides_auth_social_login_auth_kakao.md
supabase_com_docs_guides_auth_social_login_auth_keycloak.md
supabase_com_docs_guides_auth_social_login_auth_linkedin.md
supabase_com_docs_guides_auth_social_login_auth_notion.md
supabase_com_docs_guides_auth_social_login_auth_slack.md
supabase_com_docs_guides_auth_social_login_auth_spotify.md
supabase_com_docs_guides_auth_social_login_auth_twitch.md
supabase_com_docs_guides_auth_social_login_auth_twitter.md
supabase_com_docs_guides_auth_social_login_auth_workos.md
supabase_com_docs_guides_auth_social_login_auth_zoom.md
supabase_com_docs_guides_auth_social_login.md
supabase_com_docs_guides_auth_third_party_auth0.md
supabase_com_docs_guides_auth_third_party_aws_cognito.md
supabase_com_docs_guides_auth_third_party_firebase_auth.md
supabase_com_docs_guides_auth_third_party_overview.md
supabase_com_docs_guides_auth_users.md
supabase_com_docs_guides_auth.md
supabase_com_docs_guides_cron_install.md
supabase_com_docs_guides_cron_quickstart.md
supabase_com_docs_guides_cron.md
supabase_com_docs_guides_database_arrays.md
supabase_com_docs_guides_database_beekeeper_studio.md
supabase_com_docs_guides_database_connecting_to_postgres.md
supabase_com_docs_guides_database_connection_management.md
supabase_com_docs_guides_database_custom_postgres_config.md
supabase_com_docs_guides_database_dbeaver.md
supabase_com_docs_guides_database_debugging_performance.md
supabase_com_docs_guides_database_drizzle.md
supabase_com_docs_guides_database_extensions_http.md
supabase_com_docs_guides_database_extensions_hypopg.md
supabase_com_docs_guides_database_extensions_index_advisor.md
supabase_com_docs_guides_database_extensions_pg_cron.md
supabase_com_docs_guides_database_extensions_pg_graphql.md
supabase_com_docs_guides_database_extensions_pg_hashids.md
supabase_com_docs_guides_database_extensions_pg_jsonschema.md
supabase_com_docs_guides_database_extensions_pg_net.md
supabase_com_docs_guides_database_extensions_pg_plan_filter.md
supabase_com_docs_guides_database_extensions_pg_repack.md
supabase_com_docs_guides_database_extensions_pg_stat_statements.md
supabase_com_docs_guides_database_extensions_pgaudit.md
supabase_com_docs_guides_database_extensions_pgjwt.md
supabase_com_docs_guides_database_extensions_pgmq.md
supabase_com_docs_guides_database_extensions_pgroonga.md
supabase_com_docs_guides_database_extensions_pgrouting.md
supabase_com_docs_guides_database_extensions_pgsodium.md
supabase_com_docs_guides_database_extensions_pgtap.md
supabase_com_docs_guides_database_extensions_pgvector.md
supabase_com_docs_guides_database_extensions_plpgsql_check.md
supabase_com_docs_guides_database_extensions_plv8.md
supabase_com_docs_guides_database_extensions_postgis.md
supabase_com_docs_guides_database_extensions_postgres_fdw.md
supabase_com_docs_guides_database_extensions_rum.md
supabase_com_docs_guides_database_extensions_timescaledb.md
supabase_com_docs_guides_database_extensions_uuid_ossp.md
supabase_com_docs_guides_database_extensions_wrappers_overview.md
supabase_com_docs_guides_database_extensions.md
supabase_com_docs_guides_database_full_text_search.md
supabase_com_docs_guides_database_functions.md
supabase_com_docs_guides_database_hardening_data_api.md
supabase_com_docs_guides_database_import_data.md
supabase_com_docs_guides_database_inspect.md
supabase_com_docs_guides_database_joins_and_nesting.md
supabase_com_docs_guides_database_json.md
supabase_com_docs_guides_database_metabase.md
supabase_com_docs_guides_database_orioledb.md
supabase_com_docs_guides_database_overview.md
supabase_com_docs_guides_database_partitions.md
supabase_com_docs_guides_database_pgadmin.md
supabase_com_docs_guides_database_postgres_cascade_deletes.md
supabase_com_docs_guides_database_postgres_column_level_security.md
supabase_com_docs_guides_database_postgres_configuration.md
supabase_com_docs_guides_database_postgres_custom_claims_and_role_based_access_control_rbac.md
supabase_com_docs_guides_database_postgres_dropping_all_tables_in_schema.md
supabase_com_docs_guides_database_postgres_enums.md
supabase_com_docs_guides_database_postgres_first_row_in_group.md
supabase_com_docs_guides_database_postgres_indexes.md
supabase_com_docs_guides_database_postgres_js.md
supabase_com_docs_guides_database_postgres_roles_superuser.md
supabase_com_docs_guides_database_postgres_roles.md
supabase_com_docs_guides_database_postgres_row_level_security.md
supabase_com_docs_guides_database_postgres_setup_replication_external.md
supabase_com_docs_guides_database_postgres_timeouts.md
supabase_com_docs_guides_database_postgres_triggers.md
supabase_com_docs_guides_database_postgres_which_version_of_postgres.md
supabase_com_docs_guides_database_prisma_prisma_troubleshooting.md
supabase_com_docs_guides_database_prisma.md
supabase_com_docs_guides_database_psql.md
supabase_com_docs_guides_database_query_optimization.md
supabase_com_docs_guides_database_replication.md
supabase_com_docs_guides_database_secure_data.md
supabase_com_docs_guides_database_supavisor.md
supabase_com_docs_guides_database_tables.md
supabase_com_docs_guides_database_testing.md
supabase_com_docs_guides_database_vault.md
supabase_com_docs_guides_database_webhooks.md
supabase_com_docs_guides_deployment_branching.md
supabase_com_docs_guides_deployment_database_migrations.md
supabase_com_docs_guides_deployment_going_into_prod.md
supabase_com_docs_guides_deployment_managing_environments.md
supabase_com_docs_guides_deployment_maturity_model.md
supabase_com_docs_guides_deployment_shared_responsibility_model.md
supabase_com_docs_guides_deployment.md
supabase_com_docs_guides_functions_ai_models.md
supabase_com_docs_guides_functions_auth.md
supabase_com_docs_guides_functions_background_tasks.md
supabase_com_docs_guides_functions_cicd_workflow.md
supabase_com_docs_guides_functions_compression.md
supabase_com_docs_guides_functions_connect_to_postgres.md
supabase_com_docs_guides_functions_cors.md
supabase_com_docs_guides_functions_dart_edge.md
supabase_com_docs_guides_functions_debugging_tools.md
supabase_com_docs_guides_functions_dependencies.md
supabase_com_docs_guides_functions_deploy.md
supabase_com_docs_guides_functions_ephemeral_storage.md
supabase_com_docs_guides_functions_examples_amazon_bedrock_image_generator.md
supabase_com_docs_guides_functions_examples_auth_send_email_hook_react_email_resend.md
supabase_com_docs_guides_functions_examples_cloudflare_turnstile.md
supabase_com_docs_guides_functions_examples_discord_bot.md
supabase_com_docs_guides_functions_examples_elevenlabs_generate_speech_stream.md
supabase_com_docs_guides_functions_examples_elevenlabs_transcribe_speech.md
supabase_com_docs_guides_functions_examples_github_actions.md
supabase_com_docs_guides_functions_examples_image_manipulation.md
supabase_com_docs_guides_functions_examples_og_image.md
supabase_com_docs_guides_functions_examples_push_notifications.md
supabase_com_docs_guides_functions_examples_rate_limiting.md
supabase_com_docs_guides_functions_examples_screenshots.md
supabase_com_docs_guides_functions_examples_semantic_search.md
supabase_com_docs_guides_functions_examples_send_emails.md
supabase_com_docs_guides_functions_examples_sentry_monitoring.md
supabase_com_docs_guides_functions_examples_slack_bot_mention.md
supabase_com_docs_guides_functions_examples_stripe_webhooks.md
supabase_com_docs_guides_functions_examples_telegram_bot.md
supabase_com_docs_guides_functions_examples_upstash_redis.md
supabase_com_docs_guides_functions_kysely_postgres.md
supabase_com_docs_guides_functions_limits.md
supabase_com_docs_guides_functions_local_development.md
supabase_com_docs_guides_functions_logging.md
supabase_com_docs_guides_functions_pricing.md
supabase_com_docs_guides_functions_quickstart.md
supabase_com_docs_guides_functions_regional_invocation.md
supabase_com_docs_guides_functions_routing.md
supabase_com_docs_guides_functions_schedule_functions.md
supabase_com_docs_guides_functions_secrets.md
supabase_com_docs_guides_functions_status_codes.md
supabase_com_docs_guides_functions_storage_caching.md
supabase_com_docs_guides_functions_troubleshooting.md
supabase_com_docs_guides_functions_unit_test.md
supabase_com_docs_guides_functions_wasm.md
supabase_com_docs_guides_functions_websockets.md
supabase_com_docs_guides_functions.md
supabase_com_docs_guides_getting_started_ai_prompts.md
supabase_com_docs_guides_getting_started_architecture.md
supabase_com_docs_guides_getting_started_features.md
supabase_com_docs_guides_getting_started_mcp.md
supabase_com_docs_guides_getting_started_quickstarts_flutter.md
supabase_com_docs_guides_getting_started_quickstarts_hono.md
supabase_com_docs_guides_getting_started_quickstarts_ios_swiftui.md
supabase_com_docs_guides_getting_started_quickstarts_kotlin.md
supabase_com_docs_guides_getting_started_quickstarts_laravel.md
supabase_com_docs_guides_getting_started_quickstarts_nextjs.md
supabase_com_docs_guides_getting_started_quickstarts_nuxtjs.md
supabase_com_docs_guides_getting_started_quickstarts_reactjs.md
supabase_com_docs_guides_getting_started_quickstarts_redwoodjs.md
supabase_com_docs_guides_getting_started_quickstarts_refine.md
supabase_com_docs_guides_getting_started_quickstarts_ruby_on_rails.md
supabase_com_docs_guides_getting_started_quickstarts_solidjs.md
supabase_com_docs_guides_getting_started_quickstarts_sveltekit.md
supabase_com_docs_guides_getting_started_quickstarts_vue.md
supabase_com_docs_guides_getting_started_tutorials_with_angular.md
supabase_com_docs_guides_getting_started_tutorials_with_expo_react_native.md
supabase_com_docs_guides_getting_started_tutorials_with_flutter.md
supabase_com_docs_guides_getting_started_tutorials_with_ionic_angular.md
supabase_com_docs_guides_getting_started_tutorials_with_ionic_react.md
supabase_com_docs_guides_getting_started_tutorials_with_ionic_vue.md
supabase_com_docs_guides_getting_started_tutorials_with_kotlin.md
supabase_com_docs_guides_getting_started_tutorials_with_nextjs.md
supabase_com_docs_guides_getting_started_tutorials_with_nuxt_3.md
supabase_com_docs_guides_getting_started_tutorials_with_react.md
supabase_com_docs_guides_getting_started_tutorials_with_redwoodjs.md
supabase_com_docs_guides_getting_started_tutorials_with_refine.md
supabase_com_docs_guides_getting_started_tutorials_with_solidjs.md
supabase_com_docs_guides_getting_started_tutorials_with_svelte.md
supabase_com_docs_guides_getting_started_tutorials_with_sveltekit.md
supabase_com_docs_guides_getting_started_tutorials_with_swift.md
supabase_com_docs_guides_getting_started_tutorials_with_vue_3.md
supabase_com_docs_guides_getting_started.md
supabase_com_docs_guides_integrations_build_a_supabase_integration_oauth_scopes.md
supabase_com_docs_guides_integrations_build_a_supabase_integration.md
supabase_com_docs_guides_integrations_supabase_marketplace.md
supabase_com_docs_guides_integrations_vercel_marketplace.md
supabase_com_docs_guides_integrations.md
supabase_com_docs_guides_local_development_cli_getting_started.md
supabase_com_docs_guides_local_development_cli_testing_and_linting.md
supabase_com_docs_guides_local_development_customizing_email_templates.md
supabase_com_docs_guides_local_development_declarative_database_schemas.md
supabase_com_docs_guides_local_development_managing_config.md
supabase_com_docs_guides_local_development_overview.md
supabase_com_docs_guides_local_development_seeding_your_database.md
supabase_com_docs_guides_local_development_testing_overview.md
supabase_com_docs_guides_local_development_testing_pgtap_extended.md
supabase_com_docs_guides_local_development.md
supabase_com_docs_guides_platform_access_control.md
supabase_com_docs_guides_platform_backups.md
supabase_com_docs_guides_platform_billing_faq.md
supabase_com_docs_guides_platform_billing_on_supabase.md
supabase_com_docs_guides_platform_compute_and_disk.md
supabase_com_docs_guides_platform_cost_control.md
supabase_com_docs_guides_platform_credits.md
supabase_com_docs_guides_platform_custom_domains.md
supabase_com_docs_guides_platform_database_size.md
supabase_com_docs_guides_platform_fly_postgres.md
supabase_com_docs_guides_platform_get_set_up_for_billing.md
supabase_com_docs_guides_platform_hipaa_projects.md
supabase_com_docs_guides_platform_manage_your_subscription.md
supabase_com_docs_guides_platform_manage_your_usage_advanced_mfa_phone.md
supabase_com_docs_guides_platform_manage_your_usage_branching.md
supabase_com_docs_guides_platform_manage_your_usage_compute.md
supabase_com_docs_guides_platform_manage_your_usage_custom_domains.md
supabase_com_docs_guides_platform_manage_your_usage_disk_iops.md
supabase_com_docs_guides_platform_manage_your_usage_disk_size.md
supabase_com_docs_guides_platform_manage_your_usage_disk_throughput.md
supabase_com_docs_guides_platform_manage_your_usage_edge_function_invocations.md
supabase_com_docs_guides_platform_manage_your_usage_egress.md
supabase_com_docs_guides_platform_manage_your_usage_ipv4.md
supabase_com_docs_guides_platform_manage_your_usage_log_drains.md
supabase_com_docs_guides_platform_manage_your_usage_monthly_active_users_sso.md
supabase_com_docs_guides_platform_manage_your_usage_monthly_active_users_third_party.md
supabase_com_docs_guides_platform_manage_your_usage_monthly_active_users.md
supabase_com_docs_guides_platform_manage_your_usage_point_in_time_recovery.md
supabase_com_docs_guides_platform_manage_your_usage_read_replicas.md
supabase_com_docs_guides_platform_manage_your_usage_realtime_messages.md
supabase_com_docs_guides_platform_manage_your_usage_realtime_peak_connections.md
supabase_com_docs_guides_platform_manage_your_usage_storage_image_transformations.md
supabase_com_docs_guides_platform_manage_your_usage_storage_size.md
supabase_com_docs_guides_platform_manage_your_usage.md
supabase_com_docs_guides_platform_migrating_to_supabase_amazon_rds.md
supabase_com_docs_guides_platform_migrating_to_supabase_auth0.md
supabase_com_docs_guides_platform_migrating_to_supabase_firebase_auth.md
supabase_com_docs_guides_platform_migrating_to_supabase_firebase_storage.md
supabase_com_docs_guides_platform_migrating_to_supabase_firestore_data.md
supabase_com_docs_guides_platform_migrating_to_supabase_heroku.md
supabase_com_docs_guides_platform_migrating_to_supabase_mssql.md
supabase_com_docs_guides_platform_migrating_to_supabase_mysql.md
supabase_com_docs_guides_platform_migrating_to_supabase_neon.md
supabase_com_docs_guides_platform_migrating_to_supabase_postgres.md
supabase_com_docs_guides_platform_migrating_to_supabase_render.md
supabase_com_docs_guides_platform_migrating_to_supabase_vercel_postgres.md
supabase_com_docs_guides_platform_migrating_to_supabase.md
supabase_com_docs_guides_platform_migrating_within_supabase_backup_restore.md
supabase_com_docs_guides_platform_migrating_within_supabase_dashboard_restore.md
supabase_com_docs_guides_platform_migrating_within_supabase.md
supabase_com_docs_guides_platform_multi_factor_authentication.md
supabase_com_docs_guides_platform_network_restrictions.md
supabase_com_docs_guides_platform_performance.md
supabase_com_docs_guides_platform_permissions.md
supabase_com_docs_guides_platform_project_transfer.md
supabase_com_docs_guides_platform_read_replicas.md
supabase_com_docs_guides_platform_regions.md
supabase_com_docs_guides_platform_ssl_enforcement.md
supabase_com_docs_guides_platform_sso_azure.md
supabase_com_docs_guides_platform_sso_gsuite.md
supabase_com_docs_guides_platform_sso_okta.md
supabase_com_docs_guides_platform_sso.md
supabase_com_docs_guides_platform_upgrading.md
supabase_com_docs_guides_platform_your_monthly_invoice.md
supabase_com_docs_guides_platform.md
supabase_com_docs_guides_queues_api.md
supabase_com_docs_guides_queues_pgmq.md
supabase_com_docs_guides_queues_quickstart.md
supabase_com_docs_guides_queues.md
supabase_com_docs_guides_realtime_architecture.md
supabase_com_docs_guides_realtime_authorization.md
supabase_com_docs_guides_realtime_benchmarks.md
supabase_com_docs_guides_realtime_broadcast.md
supabase_com_docs_guides_realtime_concepts.md
supabase_com_docs_guides_realtime_error_codes.md
supabase_com_docs_guides_realtime_migrate_from_postgres_changes.md
supabase_com_docs_guides_realtime_postgres_changes.md
supabase_com_docs_guides_realtime_presence.md
supabase_com_docs_guides_realtime_pricing.md
supabase_com_docs_guides_realtime_protocol.md
supabase_com_docs_guides_realtime_quotas.md
supabase_com_docs_guides_realtime_realtime_listening_flutter.md
supabase_com_docs_guides_realtime_realtime_user_presence.md
supabase_com_docs_guides_realtime_realtime_with_nextjs.md
supabase_com_docs_guides_realtime_subscribing_to_database_changes.md
supabase_com_docs_guides_realtime.md
supabase_com_docs_guides_resources_glossary.md
supabase_com_docs_guides_resources.md
supabase_com_docs_guides_security_hipaa_compliance.md
supabase_com_docs_guides_security_product_security.md
supabase_com_docs_guides_security_soc_2_compliance.md
supabase_com_docs_guides_security.md
supabase_com_docs_guides_self_hosting_docker.md
supabase_com_docs_guides_self_hosting.md
supabase_com_docs_guides_storage_buckets_creating_buckets.md
supabase_com_docs_guides_storage_buckets_fundamentals.md
supabase_com_docs_guides_storage_cdn_fundamentals.md
supabase_com_docs_guides_storage_cdn_metrics.md
supabase_com_docs_guides_storage_cdn_smart_cdn.md
supabase_com_docs_guides_storage_debugging_error_codes.md
supabase_com_docs_guides_storage_debugging_logs.md
supabase_com_docs_guides_storage_management_copy_move_objects.md
supabase_com_docs_guides_storage_management_delete_objects.md
supabase_com_docs_guides_storage_management_pricing.md
supabase_com_docs_guides_storage_production_scaling.md
supabase_com_docs_guides_storage_quickstart.md
supabase_com_docs_guides_storage_s3_authentication.md
supabase_com_docs_guides_storage_s3_compatibility.md
supabase_com_docs_guides_storage_schema_custom_roles.md
supabase_com_docs_guides_storage_schema_design.md
supabase_com_docs_guides_storage_schema_helper_functions.md
supabase_com_docs_guides_storage_security_access_control.md
supabase_com_docs_guides_storage_security_ownership.md
supabase_com_docs_guides_storage_serving_bandwidth.md
supabase_com_docs_guides_storage_serving_downloads.md
supabase_com_docs_guides_storage_serving_image_transformations.md
supabase_com_docs_guides_storage_uploads_file_limits.md
supabase_com_docs_guides_storage_uploads_resumable_uploads.md
supabase_com_docs_guides_storage_uploads_s3_uploads.md
supabase_com_docs_guides_storage_uploads_standard_uploads.md
supabase_com_docs_guides_storage.md
supabase_com_docs_guides_telemetry_advanced_log_filtering.md
supabase_com_docs_guides_telemetry_log_drains.md
supabase_com_docs_guides_telemetry_logs.md
supabase_com_docs_guides_telemetry_metrics.md
supabase_com_docs_guides_telemetry_sentry_monitoring.md
supabase_com_docs_guides_telemetry.md
supabase_com_docs_guides_troubleshooting_42501__permission_denied_for_table_httprequestqueue_KnozmQ.md
supabase_com_docs_guides_troubleshooting_all_about_supabase_egress_a_Sg_e.md
supabase_com_docs_guides_troubleshooting_an_invalid_response_was_received_from_the_upstream_server_error_when_querying_auth_RI4Vl_.md
supabase_com_docs_guides_troubleshooting_are_all_features_available_in_self_hosted_supabase_THPcqw.md
supabase_com_docs_guides_troubleshooting_auth_error_401_invalid_claim_missing_sub__AFwMR.md
supabase_com_docs_guides_troubleshooting_avoiding_timeouts_in_long_running_queries_6nmbdN.md
supabase_com_docs_guides_troubleshooting_canceling_statement_due_to_statement_timeout_581wFv.md
supabase_com_docs_guides_troubleshooting_certain_operations_are_too_complex_to_perform_directly_using_the_client_libraries_8JaphH.md
supabase_com_docs_guides_troubleshooting_change_email_associated_with_supabase_account_T5eHNT.md
supabase_com_docs_guides_troubleshooting_change_project_region_eWJo5Z.md
supabase_com_docs_guides_troubleshooting_check_usage_for_monthly_active_users_mau_MwZaBs.md
supabase_com_docs_guides_troubleshooting_converted_github_account_to_organisation___lost_supabase_account_access_5wsE_1.md
supabase_com_docs_guides_troubleshooting_customizing_emails_by_language_KZ_38Q.md
supabase_com_docs_guides_troubleshooting_dashboard_errors_when_managing_users_N1ls4A.md
supabase_com_docs_guides_troubleshooting_database_error_remaining_connection_slots_are_reserved_for_non_replication_superuser_connections_3V3nIb.md
supabase_com_docs_guides_troubleshooting_database_error_saving_new_user_RU_EwB.md
supabase_com_docs_guides_troubleshooting_deprecated_rls_features_Pm77Zs.md
supabase_com_docs_guides_troubleshooting_disabling_prepared_statements_qL8lEL.md
supabase_com_docs_guides_troubleshooting_discovering_and_interpreting_api_errors_in_the_logs_7xREI9.md
supabase_com_docs_guides_troubleshooting_do_i_need_to_expose_security_definer_functions_in_row_level_security_policies_iI0uOw.md
supabase_com_docs_guides_troubleshooting_download_logical_backups.md
supabase_com_docs_guides_troubleshooting_edge_function_wall_clock_time_limit_reached_Nk38bW.md
supabase_com_docs_guides_troubleshooting_error_connection_refused_when_trying_to_connect_to_supabase_database_hwG0Dr.md
supabase_com_docs_guides_troubleshooting_error_index_row_size_exceeds_btree_version_4_maximum_for_index_LMmoeU.md
supabase_com_docs_guides_troubleshooting_error_invalid_totp_code_entered_CukLCj.md
supabase_com_docs_guides_troubleshooting_error_no_pghbaconf_entry_for_host_xxxxxxxxxxx_user_postgres_database_postgres_ssl_off_GOt5Ja.md
supabase_com_docs_guides_troubleshooting_error_prepared_statement_xxx_already_exists_3laqeM.md
supabase_com_docs_guides_troubleshooting_exhaust_disk_io.md
supabase_com_docs_guides_troubleshooting_exhaust_ram.md
supabase_com_docs_guides_troubleshooting_exhaust_swap.md
supabase_com_docs_guides_troubleshooting_failed_to_fetch_in_dashboard_and_other_areas____browser_extension_dyDTRU.md
supabase_com_docs_guides_troubleshooting_failed_to_restore_from_backup_all_subscriptions_and_replication_slots_must_be_dropped_before_a_backup_can_be_restored_L_rCvt.md
supabase_com_docs_guides_troubleshooting_fetch_requests_to_api_endpoints_arent_showing_the_session_UbUwRs.md
supabase_com_docs_guides_troubleshooting_fixing_520_errors_in_the_database_rest_api_Ur5_B2.md
supabase_com_docs_guides_troubleshooting_forbidden_resource_error_from_the_cli_L6rm6l.md
supabase_com_docs_guides_troubleshooting_google_auth_fails_for_some_users_XcFXEu.md
supabase_com_docs_guides_troubleshooting_grafana_not_displaying_data_sXJrMj.md
supabase_com_docs_guides_troubleshooting_high_cpu_usage.md
supabase_com_docs_guides_troubleshooting_high_latency_with_supabase_client_z0pZzR.md
supabase_com_docs_guides_troubleshooting_how_can_i_revoke_execution_of_a_postgresql_function_2GYb0A.md
supabase_com_docs_guides_troubleshooting_how_do_i_check_gotrueapi_version_of_a_supabase_project_lQAnOR.md
supabase_com_docs_guides_troubleshooting_how_do_i_make_the_cookies_httponly_vwweFx.md
supabase_com_docs_guides_troubleshooting_how_do_i_reset_my_supabase_database_password_oTs5sB.md
supabase_com_docs_guides_troubleshooting_how_do_i_update_connection_pool_settings_in_my_dashboard_wAxTJ_.md
supabase_com_docs_guides_troubleshooting_how_do_you_troubleshoot_nextjs___supabase_auth_issues_riMCZV.md
supabase_com_docs_guides_troubleshooting_how_long_does_it_take_to_restore_a_database_from_a_point_in_time_backup_pitr_qO8gOG.md
supabase_com_docs_guides_troubleshooting_how_postgres_chooses_which_index_to_use__JHrf4.md
supabase_com_docs_guides_troubleshooting_how_to_change_max_database_connections__BQ8P5.md
supabase_com_docs_guides_troubleshooting_how_to_check_if_my_queries_are_being_blocked_by_other_queries_NSKtR1.md
supabase_com_docs_guides_troubleshooting_how_to_delete_a_role_in_postgres_8_AvxY.md
supabase_com_docs_guides_troubleshooting_how_to_interpret_and_explore_the_postgres_logs_OuCIOj.md
supabase_com_docs_guides_troubleshooting_how_to_migrate_from_supabase_auth_helpers_to_ssr_package_5NRunM.md
supabase_com_docs_guides_troubleshooting_how_to_view_database_metrics_uqf2z_.md
supabase_com_docs_guides_troubleshooting.md
supabase_com_docs.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="supabase_com_docs_guides_ai_automatic_embeddings.md">
AI & Vectors

# Automatic embeddings

* * *

Vector embeddings enable powerful [semantic search](https://supabase.com/docs/guides/ai/semantic-search) capabilities in Postgres, but managing them alongside your content has traditionally been complex. This guide demonstrates how to automate embedding generation and updates using Supabase [Edge Functions](https://supabase.com/docs/guides/functions), [pgmq](https://supabase.com/docs/guides/database/extensions/pgmq), [pg\_net](https://supabase.com/docs/guides/database/extensions/pg_net), and [pg\_cron](https://supabase.com/docs/guides/cron).

## Understanding the challenge [\#](https://supabase.com/docs/guides/ai/automatic-embeddings\#understanding-the-challenge)

When implementing semantic search with pgvector, developers typically need to:

1. Generate embeddings via an external API (like OpenAI)
2. Store these embeddings alongside the content
3. Keep embeddings in sync when content changes
4. Handle failures and retries in the embedding generation process

While Postgres [full-text search](https://supabase.com/docs/guides/database/full-text-search) can handle this internally through synchronous calls to `to_tsvector` and [triggers](https://www.postgresql.org/docs/current/textsearch-features.html#TEXTSEARCH-UPDATE-TRIGGERS), semantic search requires asynchronous API calls to a provider like OpenAI to generate vector embeddings. This guide demonstrates how to use triggers, queues, and Supabase Edge Functions to bridge this gap.

## Understanding the architecture [\#](https://supabase.com/docs/guides/ai/automatic-embeddings\#understanding-the-architecture)

We'll leverage the following Postgres and Supabase features to create the automated embedding system:

1. [pgvector](https://supabase.com/docs/guides/database/extensions/pgvector): Stores and queries vector embeddings
2. [pgmq](https://supabase.com/docs/guides/queues): Queues embedding generation requests for processing and retries
3. [pg\_net](https://supabase.com/docs/guides/database/extensions/pg_net): Handles asynchronous HTTP requests to Edge Functions directly from Postgres
4. [pg\_cron](https://supabase.com/docs/guides/cron): Automatically processes and retries embedding generations
5. [Triggers](https://supabase.com/docs/guides/database/postgres/triggers): Detects content changes and enqueues embedding generation requests
6. [Edge Functions](https://supabase.com/docs/guides/functions): Generates embeddings via an API like OpenAI (customizable)

We'll design the system to:

1. Be generic, so that it can be used with any table and content. This allows you to configure embeddings in multiple places, each with the ability to customize the input used for embedding generation. These will all use the same queue infrastructure and Edge Function to generate the embeddings.

2. Handle failures gracefully, by retrying failed jobs and providing detailed information about the status of each job.


## Implementation [\#](https://supabase.com/docs/guides/ai/automatic-embeddings\#implementation)

We'll start by setting up the infrastructure needed to queue and process embedding generation requests. Then we'll create an example table with triggers to enqueue these embedding requests whenever content is inserted or updated.

### Step 1: Enable extensions [\#](https://supabase.com/docs/guides/ai/automatic-embeddings\#step-1-enable-extensions)

First, let's enable the required extensions:

SQLDashboard

`
-- For vector operations
create extension if not exists vector
with
schema extensions;
-- For queueing and processing jobs
-- (pgmq will create its own schema)
create extension if not exists pgmq;
-- For async HTTP requests
create extension if not exists pg_net
with
schema extensions;
-- For scheduled processing and retries
-- (pg_cron will create its own schema)
create extension if not exists pg_cron;
-- For clearing embeddings during updates
create extension if not exists hstore
with
schema extensions;
`

Even though the SQL code is `create extension`, this is the equivalent of "enabling the extension".
To disable an extension, call `drop extension`.

### Step 2: Create utility functions [\#](https://supabase.com/docs/guides/ai/automatic-embeddings\#step-2-create-utility-functions)

Before we set up our embedding logic, we need to create some utility functions:

`
-- Schema for utility functions
create schema util;
-- Utility function to get the Supabase project URL (required for Edge Functions)
create function util.project_url()
returns text
language plpgsql
security definer
as $$
declare
secret_value text;
begin
  -- Retrieve the project URL from Vault
select decrypted_secret into secret_value from vault.decrypted_secrets where name = 'project_url';
return secret_value;
end;
$$;
-- Generic function to invoke any Edge Function
create or replace function util.invoke_edge_function(
name text,
body jsonb,
timeout_milliseconds int = 5 * 60 * 1000  -- default 5 minute timeout
)
returns void
language plpgsql
as $$
declare
headers_raw text;
auth_header text;
begin
  -- If we're in a PostgREST session, reuse the request headers for authorization
headers_raw := current_setting('request.headers', true);
  -- Only try to parse if headers are present
auth_header := case
    when headers_raw is not null then
      (headers_raw::json->>'authorization')
    else
      null
end;
  -- Perform async HTTP request to the edge function
perform net.http_post(
    url => util.project_url() || '/functions/v1/' || name,
    headers => jsonb_build_object(
      'Content-Type', 'application/json',
      'Authorization', auth_header
    ),
    body => body,
    timeout_milliseconds => timeout_milliseconds
);
end;
$$;
-- Generic trigger function to clear a column on update
create or replace function util.clear_column()
returns trigger
language plpgsql as $$
declare
    clear_column text := TG_ARGV[0];
begin
    NEW := NEW #= hstore(clear_column, NULL);
    return NEW;
end;
$$;
`

Here we create:

- A schema `util` to store utility functions.
- A function to retrieve the Supabase project URL from [Vault](https://supabase.com/docs/guides/database/vault). We'll add this secret next.
- A generic function to invoke any Edge Function with a given name and request body.
- A generic trigger function to clear a column on update. This function accepts the column name as an argument and sets it to `NULL` in the `NEW` record. We'll explain how to use this function later.

Every project has a unique API URL that is required to invoke Edge Functions. Let's go ahead and add the project URL secret to Vault depending on your environment.

When working with a local Supabase stack, add the following to your `supabase/seed.sql` file:

`
select
vault.create_secret('http://api.supabase.internal:8000', 'project_url');
`

When deploying to the cloud platform, open the [SQL editor](https://supabase.com/dashboard/project/_/sql/new) and run the following, replacing `<project-url>` with your [project's API URL](https://supabase.com/dashboard/project/_/settings/api):

`
select
vault.create_secret('<project-url>', 'project_url');
`

### Step 3: Create queue and triggers [\#](https://supabase.com/docs/guides/ai/automatic-embeddings\#step-3-create-queue-and-triggers)

Our goal is to automatically generate embeddings whenever content is inserted or updated within a table. We can use triggers and queues to achieve this. Our approach is to automatically queue embedding jobs whenever records are inserted or updated in a table, then process them asynchronously using a cron job. If a job fails, it will remain in the queue and be retried in the next scheduled task.

First we create a `pgmq` queue for processing embedding requests:

`
-- Queue for processing embedding jobs
select pgmq.create('embedding_jobs');
`

Next we create a trigger function to queue embedding jobs. We'll use this function to handle both insert and update events:

`
-- Generic trigger function to queue embedding jobs
create or replace function util.queue_embeddings()
returns trigger
language plpgsql
as $$
declare
content_function text = TG_ARGV[0];
embedding_column text = TG_ARGV[1];
begin
perform pgmq.send(
    queue_name => 'embedding_jobs',
    msg => jsonb_build_object(
      'id', NEW.id,
      'schema', TG_TABLE_SCHEMA,
      'table', TG_TABLE_NAME,
      'contentFunction', content_function,
      'embeddingColumn', embedding_column
    )
);
return NEW;
end;
$$;
`

Our `util.queue_embeddings` trigger function is generic and can be used with any table and content function. It accepts two arguments:

1. `content_function`: The name of a function that returns the text content to be embedded. The function should accept a single row as input and return text (see the `embedding_input` example).

This allows you to customize the text input passed to the embedding model - for example, you could concatenate multiple columns together like `title` and `content` and use the result as input.

2. `embedding_column`: The name of the destination column where the embedding will be stored.


Note that the `util.queue_embeddings` trigger function requires a `for each row` clause to work correctly. See [Usage](https://supabase.com/docs/guides/ai/automatic-embeddings#usage) for an example of how to use this trigger function with your table.

Next we'll create a function to process the embedding jobs. This function will read jobs from the queue, group them into batches, and invoke the Edge Function to generate embeddings. We'll use `pg_cron` to schedule this function to run every 10 seconds.

`
-- Function to process embedding jobs from the queue
create or replace function util.process_embeddings(
batch_size int = 10,
max_requests int = 10,
timeout_milliseconds int = 5 * 60 * 1000 -- default 5 minute timeout
)
returns void
language plpgsql
as $$
declare
job_batches jsonb[];
batch jsonb;
begin
with
    -- First get jobs and assign batch numbers
    numbered_jobs as (
      select
        message || jsonb_build_object('jobId', msg_id) as job_info,
        (row_number() over (order by 1) - 1) / batch_size as batch_num
      from pgmq.read(
        queue_name => 'embedding_jobs',
        vt => timeout_milliseconds / 1000,
        qty => max_requests * batch_size
      )
    ),
    -- Then group jobs into batches
    batched_jobs as (
      select
        jsonb_agg(job_info) as batch_array,
        batch_num
      from numbered_jobs
      group by batch_num
    )
  -- Finally aggregate all batches into array
select array_agg(batch_array)
from batched_jobs
into job_batches;
  -- Invoke the embed edge function for each batch
foreach batch in array job_batches loop
    perform util.invoke_edge_function(
      name => 'embed',
      body => batch,
      timeout_milliseconds => timeout_milliseconds
    );
end loop;
end;
$$;
-- Schedule the embedding processing
select
cron.schedule(
    'process-embeddings',
    '10 seconds',
    $$
    select util.process_embeddings();
    $$
);
`

Let's discuss some common questions about this approach:

#### Why not generate all embeddings in a single Edge Function request? [\#](https://supabase.com/docs/guides/ai/automatic-embeddings\#why-not-generate-all-embeddings-in-a-single-edge-function-request)

While this is possible, it can lead to long processing times and potential timeouts. Batching allows us to process multiple embeddings concurrently and handle failures more effectively.

#### Why not one request per row? [\#](https://supabase.com/docs/guides/ai/automatic-embeddings\#why-not-one-request-per-row)

This approach can lead to API rate limiting and performance issues. Batching provides a balance between efficiency and reliability.

#### Why queue requests instead of processing them immediately? [\#](https://supabase.com/docs/guides/ai/automatic-embeddings\#why-queue-requests-instead-of-processing-them-immediately)

Queuing allows us to handle failures gracefully, retry requests, and manage concurrency more effectively. Specifically we are using `pgmq`'s visibility timeouts to ensure that failed requests are retried.

#### How do visibility timeouts work? [\#](https://supabase.com/docs/guides/ai/automatic-embeddings\#how-do-visibility-timeouts-work)

Every time we read a message from the queue, we set a visibility timeout which tells `pgmq` to hide the message from other readers for a certain period. If the Edge Function fails to process the message within this period, the message becomes visible again and will be retried by the next scheduled task.

#### How do we handle retries? [\#](https://supabase.com/docs/guides/ai/automatic-embeddings\#how-do-we-handle-retries)

We use `pg_cron` to schedule a task that reads messages from the queue and processes them. If the Edge Function fails to process a message, it becomes visible again after a timeout and can be retried by the next scheduled task.

#### Is 10 seconds a good interval for processing? [\#](https://supabase.com/docs/guides/ai/automatic-embeddings\#is-10-seconds-a-good-interval-for-processing)

This interval is a good starting point, but you may need to adjust it based on your workload and the time it takes to generate embeddings. You can adjust the `batch_size`, `max_requests`, and `timeout_milliseconds` parameters to optimize performance.

### Step 4: Create the Edge Function [\#](https://supabase.com/docs/guides/ai/automatic-embeddings\#step-4-create-the-edge-function)

Finally we'll create the Edge Function to generate embeddings. We'll use OpenAI's API in this example, but you can replace it with any other embedding generation service.

Use the Supabase CLI to create a new Edge Function:

`
supabase functions new embed
`

This will create a new directory `supabase/functions/embed` with an `index.ts` file. Replace the contents of this file with the following:

_supabase/functions/embed/index.ts_:

``
// Setup type definitions for built-in Supabase Runtime APIs
import 'jsr:@supabase/functions-js/edge-runtime.d.ts'
// We'll use the OpenAI API to generate embeddings
import OpenAI from 'jsr:@openai/openai'
import { z } from 'npm:zod'
// We'll make a direct Postgres connection to update the document
import postgres from 'https://deno.land/x/postgresjs@v3.4.5/mod.js'
// Initialize OpenAI client
const openai = new OpenAI({
// We'll need to manually set the `OPENAI_API_KEY` environment variable
apiKey: Deno.env.get('OPENAI_API_KEY'),
})
// Initialize Postgres client
const sql = postgres(
// `SUPABASE_DB_URL` is a built-in environment variable
Deno.env.get('SUPABASE_DB_URL')!
)
const jobSchema = z.object({
jobId: z.number(),
id: z.number(),
schema: z.string(),
table: z.string(),
contentFunction: z.string(),
embeddingColumn: z.string(),
})
const failedJobSchema = jobSchema.extend({
error: z.string(),
})
type Job = z.infer<typeof jobSchema>
type FailedJob = z.infer<typeof failedJobSchema>
type Row = {
id: string
content: unknown
}
const QUEUE_NAME = 'embedding_jobs'
// Listen for HTTP requests
Deno.serve(async (req) => {
if (req.method !== 'POST') {
    return new Response('expected POST request', { status: 405 })
}
if (req.headers.get('content-type') !== 'application/json') {
    return new Response('expected json body', { status: 400 })
}
// Use Zod to parse and validate the request body
const parseResult = z.array(jobSchema).safeParse(await req.json())
if (parseResult.error) {
    return new Response(`invalid request body: ${parseResult.error.message}`, {
      status: 400,
    })
}
const pendingJobs = parseResult.data
// Track jobs that completed successfully
const completedJobs: Job[] = []
// Track jobs that failed due to an error
const failedJobs: FailedJob[] = []
async function processJobs() {
    let currentJob: Job | undefined
    while ((currentJob = pendingJobs.shift()) !== undefined) {
      try {
        await processJob(currentJob)
        completedJobs.push(currentJob)
      } catch (error) {
        failedJobs.push({
          ...currentJob,
          error: error instanceof Error ? error.message : JSON.stringify(error),
        })
      }
    }
}
try {
    // Process jobs while listening for worker termination
    await Promise.race([processJobs(), catchUnload()])
} catch (error) {
    // If the worker is terminating (e.g. wall clock limit reached),
    // add pending jobs to fail list with termination reason
    failedJobs.push(
      ...pendingJobs.map((job) => ({
        ...job,
        error: error instanceof Error ? error.message : JSON.stringify(error),
      }))
    )
}
// Log completed and failed jobs for traceability
console.log('finished processing jobs:', {
    completedJobs: completedJobs.length,
    failedJobs: failedJobs.length,
})
return new Response(
    JSON.stringify({
      completedJobs,
      failedJobs,
    }),
    {
      // 200 OK response
      status: 200,
      // Custom headers to report job status
      headers: {
        'content-type': 'application/json',
        'x-completed-jobs': completedJobs.length.toString(),
        'x-failed-jobs': failedJobs.length.toString(),
      },
    }
)
})
/**
* Generates an embedding for the given text.
*/
async function generateEmbedding(text: string) {
const response = await openai.embeddings.create({
    model: 'text-embedding-3-small',
    input: text,
})
const [data] = response.data
if (!data) {
    throw new Error('failed to generate embedding')
}
return data.embedding
}
/**
* Processes an embedding job.
*/
async function processJob(job: Job) {
const { jobId, id, schema, table, contentFunction, embeddingColumn } = job
// Fetch content for the schema/table/row combination
const [row]: [Row] = await sql`
    select
      id,
      ${sql(contentFunction)}(t) as content
    from
      ${sql(schema)}.${sql(table)} t
    where
      id = ${id}
`
if (!row) {
    throw new Error(`row not found: ${schema}.${table}/${id}`)
}
if (typeof row.content !== 'string') {
    throw new Error(`invalid content - expected string: ${schema}.${table}/${id}`)
}
const embedding = await generateEmbedding(row.content)
await sql`
    update
      ${sql(schema)}.${sql(table)}
    set
      ${sql(embeddingColumn)} = ${JSON.stringify(embedding)}
    where
      id = ${id}
`
await sql`
    select pgmq.delete(${QUEUE_NAME}, ${jobId}::bigint)
`
}
/**
* Returns a promise that rejects if the worker is terminating.
*/
function catchUnload() {
return new Promise((reject) => {
    addEventListener('beforeunload', (ev: any) => {
      reject(new Error(ev.detail?.reason))
    })
})
}
``

The Edge Function listens for incoming HTTP requests from `pg_net` and processes each embedding job. It is a generic worker that can handle embedding jobs for any table and column. It uses OpenAI's API to generate embeddings and updates the corresponding row in the database. It also deletes the job from the queue once it has been processed.

The function is designed to process multiple jobs independently. If one job fails, it will not affect the processing of other jobs. The function returns a `200 OK` response with a list of completed and failed jobs. We can use this information to diagnose failed jobs. See [Troubleshooting](https://supabase.com/docs/guides/ai/automatic-embeddings#troubleshooting) for more details.

You will need to set the `OPENAI_API_KEY` environment variable to authenticate with OpenAI. When running the Edge Function locally, you can add it to a `.env` file:

_.env_:

`
OPENAI_API_KEY=your-api-key
`

When you're ready to deploy the Edge Function, set can set the environment variable using the Supabase CLI:

`
supabase secrets set --env-file .env
`

or

`
supabase secrets set OPENAI_API_KEY=<your-api-key>
`

Alternatively, you can replace the `generateEmbedding` function with your own embedding generation logic.

See [Deploy to Production](https://supabase.com/docs/guides/functions/deploy) for more information on how to deploy the Edge Function.

## Usage [\#](https://supabase.com/docs/guides/ai/automatic-embeddings\#usage)

Now that the infrastructure is in place, let's go through an example of how to use this system to automatically generate embeddings for a table of documents. You can use this approach with multiple tables and customize the input for each embedding generation as needed.

### 1\. Create table to store documents with embeddings [\#](https://supabase.com/docs/guides/ai/automatic-embeddings\#1-create-table-to-store-documents-with-embeddings)

We'll set up a new `documents` table that will store our content and embeddings:

`
-- Table to store documents with embeddings
create table documents (
id integer primary key generated always as identity,
title text not null,
content text not null,
embedding halfvec(1536),
created_at timestamp with time zone default now()
);
-- Index for vector search over document embeddings
create index on documents using hnsw (embedding halfvec_cosine_ops);
`

Our `documents` table stores the title and content of each document along with its vector embedding. We use a `halfvec(1536)` column to store the embeddings.

`halfvec` is a `pgvector` data type that stores float values in half precision (16 bits) to save space. Our Edge Function used OpenAI's `text-embedding-3-small` model which generates 1536-dimensional embeddings, so we use the same dimensionality here. Adjust this based on the number of dimensions your embedding model generates.

We use an [HNSW index](https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes) on the vector column. Note that we are choosing `halfvec_cosine_ops` as the index method, which means our future queries will need to use cosine distance ( `<=>`) to find similar embeddings. Also note that HNSW indexes support a maximum of 4000 dimensions for `halfvec` vectors, so keep this in mind when choosing an embedding model. If your model generates embeddings with more than 4000 dimensions, you will need to reduce the dimensionality before indexing them. See [Matryoshka embeddings](https://supabase.com/blog/matryoshka-embeddings) for a potential solution to shortening dimensions.

Also note that the table must have a primary key column named `id` for our triggers to work correctly with the `util.queue_embeddings` function and for our Edge Function to update the correct row.

### 2\. Create triggers to enqueue embedding jobs [\#](https://supabase.com/docs/guides/ai/automatic-embeddings\#2-create-triggers-to-enqueue-embedding-jobs)

Now we'll set up the triggers to enqueue embedding jobs whenever content is inserted or updated:

`
-- Customize the input for embedding generation
-- e.g. Concatenate title and content with a markdown header
create or replace function embedding_input(doc documents)
returns text
language plpgsql
immutable
as $$
begin
return '# ' || doc.title || E'\n\n' || doc.content;
end;
$$;
-- Trigger for insert events
create trigger embed_documents_on_insert
after insert
on documents
for each row
execute function util.queue_embeddings('embedding_input', 'embedding');
-- Trigger for update events
create trigger embed_documents_on_update
after update of title, content -- must match the columns in embedding_input()
on documents
for each row
execute function util.queue_embeddings('embedding_input', 'embedding');
`

We create 2 triggers:

1. `embed_documents_on_insert`: Enqueues embedding jobs whenever new rows are inserted into the `documents` table.

2. `embed_documents_on_update`: Enqueues embedding jobs whenever the `title` or `content` columns are updated in the `documents` table.


Both of these triggers use the same `util.queue_embeddings` function that will queue the embedding jobs for processing. They accept 2 arguments:

1. `embedding_input`: The name of the function that generates the input for embedding generation. This function allows you to customize the text input passed to the embedding model (e.g. concatenating the title and content). The function should accept a single row as input and return text.

2. `embedding`: The name of the destination column where the embedding will be stored.


Note that the update trigger only fires when the `title` or `content` columns are updated. This is to avoid unnecessary updates to the embedding column when other columns are updated. Make sure that these columns match the columns used in the `embedding_input` function.

#### (Optional) Clearing embeddings on update [\#](https://supabase.com/docs/guides/ai/automatic-embeddings\#optional-clearing-embeddings-on-update)

Note that our trigger will enqueue new embedding jobs when content is updated, but it will not clear any existing embeddings. This means that an embedding can be temporarily out of sync with the content until the new embedding is generated and updated.

If it is more important to have _accurate_ embeddings than _any_ embedding, you can add another trigger to clear the existing embedding until the new one is generated:

`
-- Trigger to clear the embedding column on update
create trigger clear_document_embedding_on_update
before update of title, content -- must match the columns in embedding_input()
on documents
for each row
execute function util.clear_column('embedding');
`

`util.clear_column` is a generic trigger function we created earlier that can be used to clear any column in a table.

- It accepts the column name as an argument. This column must be nullable.
- It requires a `before` trigger with a `for each row` clause.
- It requires the `hstore` extension we created earlier.

This example will clear the `embedding` column whenever the `title` or `content` columns are updated (note the `of title, content` clause). This ensures that the embedding is always in sync with the title and content, but it will result in temporary gaps in search results until the new embedding is generated.

We intentionally use a `before` trigger because it allows us to modify the record before it's written to disk, avoiding an extra `update` statement that would be needed with an `after` trigger.

### 3\. Insert and update documents [\#](https://supabase.com/docs/guides/ai/automatic-embeddings\#3-insert-and-update-documents)

Let's insert a new document and update its content to see the embedding generation in action:

`
-- Insert a new document
insert into documents (title, content)
values
('Understanding Vector Databases', 'Vector databases are specialized...');
-- Immediately check the embedding column
select id, embedding
from documents
where title = 'Understanding Vector Databases';
`

You should observe that the `embedding` column is initially `null` after inserting the document. This is because the embedding generation is asynchronous and will be processed by the Edge Function in the next scheduled task.

Wait up to 10 seconds for the next task to run, then check the `embedding` column again:

`
select id, embedding
from documents
where title = 'Understanding Vector Databases';
`

You should see the generated embedding for the document.

Next let's update the content of the document:

`
-- Update the content of the document
update documents
set content = 'Vector databases allow you to query...'
where title = 'Understanding Vector Databases';
-- Immediately check the embedding column
select id, embedding
from documents
where title = 'Understanding Vector Databases';
`

You should observe that the `embedding` column is reset to `null` after updating the content. This is because of the trigger we added to clear existing embeddings whenever the content is updated. The embedding will be regenerated by the Edge Function in the next scheduled task.

Wait up to 10 seconds for the next task to run, then check the `embedding` column again:

`
select id, embedding
from documents
where title = 'Understanding Vector Databases';
`

You should see the updated embedding for the document.

Finally we'll update the title of the document:

`
-- Update the title of the document
update documents
set title = 'Understanding Vector Databases with Supabase'
where title = 'Understanding Vector Databases';
`

You should observe that the `embedding` column is once again reset to `null` after updating the title. This is because the trigger we added to clear existing embeddings fires when either the `content` or `title` columns are updated. The embedding will be regenerated by the Edge Function in the next scheduled task.

Wait up to 10 seconds for the next task to run, then check the `embedding` column again:

`
select id, embedding
from documents
where title = 'Understanding Vector Databases with Supabase';
`

You should see the updated embedding for the document.

## Troubleshooting [\#](https://supabase.com/docs/guides/ai/automatic-embeddings\#troubleshooting)

The `embed` Edge Function processes a batch of embedding jobs and returns a `200 OK` response with a list of completed and failed jobs in the body. For example:

`
{
"completedJobs": [\
    {\
      "jobId": "1",\
      "id": "1",\
      "schema": "public",\
      "table": "documents",\
      "contentFunction": "embedding_input",\
      "embeddingColumn": "embedding"\
    }\
],
"failedJobs": [\
    {\
      "jobId": "2",\
      "id": "2",\
      "schema": "public",\
      "table": "documents",\
      "contentFunction": "embedding_input",\
      "embeddingColumn": "embedding",\
      "error": "error connecting to openai api"\
    }\
]
}
`

It also returns the number of completed and failed jobs in the response headers. For example:

`
x-completed-jobs: 1
x-failed-jobs: 1
`

You can also use the `x-deno-execution-id` header to trace the execution of the Edge Function within the [dashboard](https://supabase.com/dashboard/project/_/functions) logs.

Each failed job includes an `error` field with a description of the failure. Reasons for a job failing could include:

- An error generating the embedding via external API
- An error connecting to the database
- The edge function being terminated (e.g. due to a wall clock limit)
- Any other error thrown during processing

`pg_net` stores HTTP responses in the `net._http_response` table, which can be queried to diagnose issues with the embedding generation process.

`
select
*
from
net._http_response
where
(headers->>'x-failed-jobs')::int > 0;
`

## Conclusion [\#](https://supabase.com/docs/guides/ai/automatic-embeddings\#conclusion)

Automating embedding generation and updates in Postgres allow you to build powerful semantic search capabilities without the complexity of managing embeddings manually.

By combining Postgres features like triggers, queues, and other extensions with Supabase Edge Functions, we can create a robust system that handles embedding generation asynchronously and retries failed jobs automatically.

This system can be customized to work with any content and embedding generation service, providing a flexible and scalable solution for semantic search in Postgres.

## See also [\#](https://supabase.com/docs/guides/ai/automatic-embeddings\#see-also)

- [What are embeddings?](https://supabase.com/docs/guides/ai/concepts)
- [Semantic search](https://supabase.com/docs/guides/ai/semantic-search)
- [Vector indexes](https://supabase.com/docs/guides/ai/vector-indexes)
- [Supabase Edge Functions](https://supabase.com/docs/guides/functions)

### Is this helpful?

NoYes

### On this page

[Understanding the challenge](https://supabase.com/docs/guides/ai/automatic-embeddings#understanding-the-challenge) [Understanding the architecture](https://supabase.com/docs/guides/ai/automatic-embeddings#understanding-the-architecture) [Implementation](https://supabase.com/docs/guides/ai/automatic-embeddings#implementation) [Step 1: Enable extensions](https://supabase.com/docs/guides/ai/automatic-embeddings#step-1-enable-extensions) [Step 2: Create utility functions](https://supabase.com/docs/guides/ai/automatic-embeddings#step-2-create-utility-functions) [Step 3: Create queue and triggers](https://supabase.com/docs/guides/ai/automatic-embeddings#step-3-create-queue-and-triggers) [Step 4: Create the Edge Function](https://supabase.com/docs/guides/ai/automatic-embeddings#step-4-create-the-edge-function) [Usage](https://supabase.com/docs/guides/ai/automatic-embeddings#usage) [1\. Create table to store documents with embeddings](https://supabase.com/docs/guides/ai/automatic-embeddings#1-create-table-to-store-documents-with-embeddings) [2\. Create triggers to enqueue embedding jobs](https://supabase.com/docs/guides/ai/automatic-embeddings#2-create-triggers-to-enqueue-embedding-jobs) [3\. Insert and update documents](https://supabase.com/docs/guides/ai/automatic-embeddings#3-insert-and-update-documents) [Troubleshooting](https://supabase.com/docs/guides/ai/automatic-embeddings#troubleshooting) [Conclusion](https://supabase.com/docs/guides/ai/automatic-embeddings#conclusion) [See also](https://supabase.com/docs/guides/ai/automatic-embeddings#see-also)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_choosing_compute_addon.md">
AI & Vectors

# Choosing your Compute Add-on

## Choosing the right Compute Add-on for your vector workload.

* * *

You have two options for scaling your vector workload:

1. Increase the size of your database. This guide will help you choose the right size for your workload.
2. Spread your workload across multiple databases. You can find more details about this approach in [Engineering for Scale](https://supabase.com/docs/guides/ai/engineering-for-scale).

## Dimensionality [\#](https://supabase.com/docs/guides/ai/choosing-compute-addon\#dimensionality)

The number of dimensions in your embeddings is the most important factor in choosing the right Compute Add-on. In general, the lower the dimensionality the better the performance. We've provided guidance for some of the more common embedding dimensions below. For each benchmark, we used [Vecs](https://github.com/supabase/vecs) to create a collection, upload the embeddings to a single table, and create both the `IVFFlat` and `HNSW` indexes for `inner-product` distance measure for the embedding column. We then ran a series of queries to measure the performance of different compute add-ons:

## HNSW [\#](https://supabase.com/docs/guides/ai/choosing-compute-addon\#hnsw)

### 384 dimensions [\#](https://supabase.com/docs/guides/ai/choosing-compute-addon\#hnsw-384-dimensions)

This benchmark uses the dbpedia-entities-openai-1M dataset containing 1,000,000 embeddings of text, regenerated for 384 dimension embeddings. Each embedding is generated using [gte-small](https://huggingface.co/Supabase/gte-small).

gte-small-384

| Compute Size | Vectors | m | ef\_construction | ef\_search | QPS | Latency Mean | Latency p95 | RAM Usage | RAM |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Micro | 100,000 | 16 | 64 | 60 | 580 | 0.017 sec | 0.024 sec | 1.2 (Swap) | 1 GB |
| Small | 250,000 | 24 | 64 | 60 | 440 | 0.022 sec | 0.033 sec | 2 GB | 2 GB |
| Medium | 500,000 | 24 | 64 | 80 | 350 | 0.028 sec | 0.045 sec | 4 GB | 4 GB |
| Large | 1,000,000 | 32 | 80 | 100 | 270 | 0.073 sec | 0.108 sec | 7 GB | 8 GB |
| XL | 1,000,000 | 32 | 80 | 100 | 525 | 0.038 sec | 0.059 sec | 9 GB | 16 GB |
| 2XL | 1,000,000 | 32 | 80 | 100 | 790 | 0.025 sec | 0.037 sec | 9 GB | 32 GB |
| 4XL | 1,000,000 | 32 | 80 | 100 | 1650 | 0.015 sec | 0.018 sec | 11 GB | 64 GB |
| 8XL | 1,000,000 | 32 | 80 | 100 | 2690 | 0.015 sec | 0.016 sec | 13 GB | 128 GB |
| 12XL | 1,000,000 | 32 | 80 | 100 | 3900 | 0.014 sec | 0.016 sec | 13 GB | 192 GB |
| 16XL | 1,000,000 | 32 | 80 | 100 | 4200 | 0.014 sec | 0.016 sec | 20 GB | 256 GB |

Accuracy was 0.99 for benchmarks.

### 960 dimensions [\#](https://supabase.com/docs/guides/ai/choosing-compute-addon\#hnsw-960-dimensions)

This benchmark uses the [gist-960](http://corpus-texmex.irisa.fr/) dataset, which contains 1,000,000 embeddings of images. Each embedding is 960 dimensions.

gist-960

| Compute Size | Vectors | m | ef\_construction | ef\_search | QPS | Latency Mean | Latency p95 | RAM Usage | RAM |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Micro | 30,000 | 16 | 64 | 65 | 430 | 0.024 sec | 0.034 sec | 1.2 GB (Swap) | 1 GB |
| Small | 100,000 | 32 | 80 | 60 | 260 | 0.040 sec | 0.054 sec | 2.2 GB (Swap) | 2 GB |
| Medium | 250,000 | 32 | 80 | 90 | 120 | 0.083 sec | 0.106 sec | 4 GB | 4 GB |
| Large | 500,000 | 32 | 80 | 120 | 160 | 0.063 sec | 0.087 sec | 7 GB | 8 GB |
| XL | 1,000,000 | 32 | 80 | 200 | 200 | 0.049 sec | 0.072 sec | 13 GB | 16 GB |
| 2XL | 1,000,000 | 32 | 80 | 200 | 340 | 0.025 sec | 0.029 sec | 17 GB | 32 GB |
| 4XL | 1,000,000 | 32 | 80 | 200 | 630 | 0.031 sec | 0.050 sec | 18 GB | 64 GB |
| 8XL | 1,000,000 | 32 | 80 | 200 | 1100 | 0.034 sec | 0.048 sec | 19 GB | 128 GB |
| 12XL | 1,000,000 | 32 | 80 | 200 | 1420 | 0.041 sec | 0.095 sec | 21 GB | 192 GB |
| 16XL | 1,000,000 | 32 | 80 | 200 | 1650 | 0.037 sec | 0.081 sec | 23 GB | 256 GB |

Accuracy was 0.99 for benchmarks.

QPS can also be improved by increasing [`m` and `ef_construction`](https://supabase.com/docs/guides/ai/going-to-prod#hnsw-understanding-efconstruction--efsearch--and-m). This will allow you to use a smaller value for `ef_search` and increase QPS.

### 1536 dimensions [\#](https://supabase.com/docs/guides/ai/choosing-compute-addon\#hnsw-1536-dimensions)

This benchmark uses the [dbpedia-entities-openai-1M](https://huggingface.co/datasets/KShivendu/dbpedia-entities-openai-1M) dataset, which contains 1,000,000 embeddings of text. And 224,482 embeddings from [Wikipedia articles](https://huggingface.co/datasets/Supabase/wikipedia-en-embeddings) for compute add-ons `large` and below. Each embedding is 1536 dimensions created with the [OpenAI Embeddings API](https://platform.openai.com/docs/guides/embeddings).

OpenAI-1536

| Compute Size | Vectors | m | ef\_construction | ef\_search | QPS | Latency Mean | Latency p95 | RAM Usage | RAM |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Micro | 15,000 | 16 | 40 | 40 | 480 | 0.011 sec | 0.016 sec | 1.2 GB (Swap) | 1 GB |
| Small | 50,000 | 32 | 64 | 100 | 175 | 0.031 sec | 0.051 sec | 2.2 GB (Swap) | 2 GB |
| Medium | 100,000 | 32 | 64 | 100 | 240 | 0.083 sec | 0.126 sec | 4 GB | 4 GB |
| Large | 224,482 | 32 | 64 | 100 | 280 | 0.017 sec | 0.028 sec | 8 GB | 8 GB |
| XL | 500,000 | 24 | 56 | 100 | 360 | 0.055 sec | 0.135 sec | 13 GB | 16 GB |
| 2XL | 1,000,000 | 24 | 56 | 250 | 560 | 0.036 sec | 0.058 sec | 32 GB | 32 GB |
| 4XL | 1,000,000 | 24 | 56 | 250 | 950 | 0.021 sec | 0.033 sec | 39 GB | 64 GB |
| 8XL | 1,000,000 | 24 | 56 | 250 | 1650 | 0.016 sec | 0.023 sec | 40 GB | 128 GB |
| 12XL | 1,000,000 | 24 | 56 | 250 | 1900 | 0.015 sec | 0.021 sec | 38 GB | 192 GB |
| 16XL | 1,000,000 | 24 | 56 | 250 | 2200 | 0.015 sec | 0.020 sec | 40 GB | 256 GB |

Accuracy was 0.99 for benchmarks.

QPS can also be improved by increasing [`m` and `ef_construction`](https://supabase.com/docs/guides/ai/going-to-prod#hnsw-understanding-efconstruction--efsearch--and-m). This will allow you to use a smaller value for `ef_search` and increase QPS. For example, increasing `m` to 32 and `ef_construction` to 80 for 4XL will increase QPS to 1280.

It is possible to upload more vectors to a single table if Memory allows it (for example, 4XL plan and higher for OpenAI embeddings). But it will affect the performance of the queries: QPS will be lower, and latency will be higher. Scaling should be almost linear, but it is recommended to benchmark your workload to find the optimal number of vectors per table and per database instance.

![multi database](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fai%2Finstance-type%2Fhnsw-dims--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

## IVFFlat [\#](https://supabase.com/docs/guides/ai/choosing-compute-addon\#ivfflat)

### 384 dimensions [\#](https://supabase.com/docs/guides/ai/choosing-compute-addon\#ivfflat-384-dimensions)

This benchmark uses the dbpedia-entities-openai-1M dataset containing 1,000,000 embeddings of text, regenerated for 384 dimension embeddings. Each embedding is generated using [gte-small](https://huggingface.co/Supabase/gte-small).

gte-small-384, accuracy=.98gte-small-384, accuracy=.99

| Compute Size | Vectors | Lists | Probes | QPS | Latency Mean | Latency p95 | RAM Usage | RAM |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Micro | 100,000 | 500 | 50 | 205 | 0.048 sec | 0.066 sec | 1.2 GB (Swap) | 1 GB |
| Small | 250,000 | 1000 | 60 | 160 | 0.062 sec | 0.079 sec | 2 GB | 2 GB |
| Medium | 500,000 | 2000 | 80 | 120 | 0.082 sec | 0.104 sec | 3.2 GB | 4 GB |
| Large | 1,000,000 | 5000 | 150 | 75 | 0.269 sec | 0.375 sec | 6.5 GB | 8 GB |
| XL | 1,000,000 | 5000 | 150 | 150 | 0.131 sec | 0.178 sec | 9 GB | 16 GB |
| 2XL | 1,000,000 | 5000 | 150 | 300 | 0.066 sec | 0.099 sec | 10 GB | 32 GB |
| 4XL | 1,000,000 | 5000 | 150 | 570 | 0.035 sec | 0.046 sec | 10 GB | 64 GB |
| 8XL | 1,000,000 | 5000 | 150 | 1400 | 0.023 sec | 0.028 sec | 12 GB | 128 GB |
| 12XL | 1,000,000 | 5000 | 150 | 1550 | 0.030 sec | 0.039 sec | 12 GB | 192 GB |
| 16XL | 1,000,000 | 5000 | 150 | 1800 | 0.030 sec | 0.039 sec | 16 GB | 256 GB |

### 960 dimensions [\#](https://supabase.com/docs/guides/ai/choosing-compute-addon\#ivfflat-960-dimensions)

This benchmark uses the [gist-960](http://corpus-texmex.irisa.fr/) dataset, which contains 1,000,000 embeddings of images. Each embedding is 960 dimensions.

gist-960, probes = 10

| Compute Size | Vectors | Lists | QPS | Latency Mean | Latency p95 | RAM Usage | RAM |
| --- | --- | --- | --- | --- | --- | --- | --- |
| Micro | 30,000 | 30 | 75 | 0.065 sec | 0.088 sec | 1.1 GB (Swap) | 1 GB |
| Small | 100,000 | 100 | 78 | 0.064 sec | 0.092 sec | 1.8 GB | 2 GB |
| Medium | 250,000 | 250 | 58 | 0.085 sec | 0.129 sec | 3.2 GB | 4 GB |
| Large | 500,000 | 500 | 55 | 0.088 sec | 0.140 sec | 5 GB | 8 GB |
| XL | 1,000,000 | 1000 | 110 | 0.046 sec | 0.070 sec | 14 GB | 16 GB |
| 2XL | 1,000,000 | 1000 | 235 | 0.083 sec | 0.136 sec | 10 GB | 32 GB |
| 4XL | 1,000,000 | 1000 | 420 | 0.071 sec | 0.106 sec | 11 GB | 64 GB |
| 8XL | 1,000,000 | 1000 | 815 | 0.072 sec | 0.106 sec | 13 GB | 128 GB |
| 12XL | 1,000,000 | 1000 | 1150 | 0.052 sec | 0.078 sec | 15.5 GB | 192 GB |
| 16XL | 1,000,000 | 1000 | 1345 | 0.072 sec | 0.106 sec | 17.5 GB | 256 GB |

### 1536 dimensions [\#](https://supabase.com/docs/guides/ai/choosing-compute-addon\#ivfflat-1536-dimensions)

This benchmark uses the [dbpedia-entities-openai-1M](https://huggingface.co/datasets/KShivendu/dbpedia-entities-openai-1M) dataset, which contains 1,000,000 embeddings of text. Each embedding is 1536 dimensions created with the [OpenAI Embeddings API](https://platform.openai.com/docs/guides/embeddings).

OpenAI-1536, probes = 10OpenAI-1536, probes = 40

| Compute Size | Vectors | Lists | QPS | Latency Mean | Latency p95 | RAM Usage | RAM |
| --- | --- | --- | --- | --- | --- | --- | --- |
| Micro | 20,000 | 40 | 135 | 0.372 sec | 0.412 sec | 1.2 GB (Swap) | 1 GB |
| Small | 50,000 | 100 | 140 | 0.357 sec | 0.398 sec | 1.8 GB | 2 GB |
| Medium | 100,000 | 200 | 130 | 0.383 sec | 0.446 sec | 3.7 GB | 4 GB |
| Large | 250,000 | 500 | 130 | 0.378 sec | 0.434 sec | 7 GB | 8 GB |
| XL | 500,000 | 1000 | 235 | 0.213 sec | 0.271 sec | 13.5 GB | 16 GB |
| 2XL | 1,000,000 | 2000 | 380 | 0.133 sec | 0.236 sec | 30 GB | 32 GB |
| 4XL | 1,000,000 | 2000 | 720 | 0.068 sec | 0.120 sec | 35 GB | 64 GB |
| 8XL | 1,000,000 | 2000 | 1250 | 0.039 sec | 0.066 sec | 38 GB | 128 GB |
| 12XL | 1,000,000 | 2000 | 1600 | 0.030 sec | 0.052 sec | 41 GB | 192 GB |
| 16XL | 1,000,000 | 2000 | 1790 | 0.029 sec | 0.051 sec | 45 GB | 256 GB |

For 1,000,000 vectors 10 probes results to accuracy of 0.91. And for 500,000 vectors and below 10 probes results to accuracy in the range of 0.95 - 0.99. To increase accuracy, you need to increase the number of probes.

![multi database](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fai%2Fgoing-prod%2Fsize-to-rps--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

It is possible to upload more vectors to a single table if Memory allows it (for example, 4XL plan and higher for OpenAI embeddings). But it will affect the performance of the queries: QPS will be lower, and latency will be higher. Scaling should be almost linear, but it is recommended to benchmark your workload to find the optimal number of vectors per table and per database instance.

## Performance tips [\#](https://supabase.com/docs/guides/ai/choosing-compute-addon\#performance-tips)

There are various ways to improve your pgvector performance. Here are some tips:

### Pre-warming your database [\#](https://supabase.com/docs/guides/ai/choosing-compute-addon\#pre-warming-your-database)

It's useful to execute a few thousand warm-up queries before going into production. This helps help with RAM utilization. This can also help to determine that you've selected the right compute size for your workload.

### Fine-tune index parameters [\#](https://supabase.com/docs/guides/ai/choosing-compute-addon\#fine-tune-index-parameters)

You can increase the Requests per Second by increasing `m` and `ef_construction` or `lists`. This also has an important caveat: building the index takes longer with higher values for these parameters.

HNSWIVFFlat

![multi database](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fai%2Fgoing-prod%2Fdbpedia-hnsw-build-parameters--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

Check out more tips and the complete step-by-step guide in [Going to Production for AI applications](https://supabase.com/docs/guides/ai/going-to-prod).

## Benchmark methodology [\#](https://supabase.com/docs/guides/ai/choosing-compute-addon\#benchmark-methodology)

We follow techniques outlined in the [ANN Benchmarks](https://github.com/erikbern/ann-benchmarks) methodology. A Python test runner is responsible for uploading the data, creating the index, and running the queries. The pgvector engine is implemented using [vecs](https://github.com/supabase/vecs), a Python client for pgvector.

![multi database](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fai%2Finstance-type%2Fvecs-benchmark--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

Each test is run for a minimum of 30-40 minutes. They include a series of experiments executed at different concurrency levels to measure the engine's performance under different load types. The results are then averaged.

As a general recommendation, we suggest using a concurrency level of 5 or more for most workloads and 30 or more for high-load workloads.

### Is this helpful?

NoYes

### On this page

[Dimensionality](https://supabase.com/docs/guides/ai/choosing-compute-addon#dimensionality) [HNSW](https://supabase.com/docs/guides/ai/choosing-compute-addon#hnsw) [384 dimensions](https://supabase.com/docs/guides/ai/choosing-compute-addon#hnsw-384-dimensions) [960 dimensions](https://supabase.com/docs/guides/ai/choosing-compute-addon#hnsw-960-dimensions) [1536 dimensions](https://supabase.com/docs/guides/ai/choosing-compute-addon#hnsw-1536-dimensions) [IVFFlat](https://supabase.com/docs/guides/ai/choosing-compute-addon#ivfflat) [384 dimensions](https://supabase.com/docs/guides/ai/choosing-compute-addon#ivfflat-384-dimensions) [960 dimensions](https://supabase.com/docs/guides/ai/choosing-compute-addon#ivfflat-960-dimensions) [1536 dimensions](https://supabase.com/docs/guides/ai/choosing-compute-addon#ivfflat-1536-dimensions) [Performance tips](https://supabase.com/docs/guides/ai/choosing-compute-addon#performance-tips) [Pre-warming your database](https://supabase.com/docs/guides/ai/choosing-compute-addon#pre-warming-your-database) [Fine-tune index parameters](https://supabase.com/docs/guides/ai/choosing-compute-addon#fine-tune-index-parameters) [Benchmark methodology](https://supabase.com/docs/guides/ai/choosing-compute-addon#benchmark-methodology)

![multi database](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fai%2Finstance-type%2Fhnsw-dims--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![multi database](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fai%2Fgoing-prod%2Fdbpedia-hnsw-build-parameters--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![multi database](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fai%2Finstance-type%2Fvecs-benchmark--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![multi database](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fai%2Fgoing-prod%2Fsize-to-rps--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_concepts.md">
AI & Vectors

# Concepts

* * *

Embeddings are core to many AI and vector applications. This guide covers these concepts. If you prefer to get started right away, see our guide on [Generating Embeddings](https://supabase.com/docs/guides/ai/quickstarts/generate-text-embeddings).

## What are embeddings? [\#](https://supabase.com/docs/guides/ai/concepts\#what-are-embeddings)

Embeddings capture the "relatedness" of text, images, video, or other types of information. This relatedness is most commonly used for:

- **Search:** how similar is a search term to a body of text?
- **Recommendations:** how similar are two products?
- **Classifications:** how do we categorize a body of text?
- **Clustering:** how do we identify trends?

Let's explore an example of text embeddings. Say we have three phrases:

1. "The cat chases the mouse"
2. "The kitten hunts rodents"
3. "I like ham sandwiches"

Your job is to group phrases with similar meaning. If you are a human, this should be obvious. Phrases 1 and 2 are almost identical, while phrase 3 has a completely different meaning.

Although phrases 1 and 2 are similar, they share no common vocabulary (besides "the"). Yet their meanings are nearly identical. How can we teach a computer that these are the same?

## Human language [\#](https://supabase.com/docs/guides/ai/concepts\#human-language)

Humans use words and symbols to communicate language. But words in isolation are mostly meaningless - we need to draw from shared knowledge & experience in order to make sense of them. The phrase You should Google it only makes sense if you know that Google is a search engine and that people have been using it as a verb.

In the same way, we need to train a neural network model to understand human language. An effective model should be trained on millions of different examples to understand what each word, phrase, sentence, or paragraph could mean in different contexts.

So how does this relate to embeddings?

## How do embeddings work? [\#](https://supabase.com/docs/guides/ai/concepts\#how-do-embeddings-work)

Embeddings compress discrete information (words & symbols) into distributed continuous-valued data (vectors). If we took our phrases from before and plot them on a chart, it might look something like this:

![Vector similarity](https://supabase.com/docs/img/ai/vector-similarity.png)

Phrases 1 and 2 would be plotted close to each other, since their meanings are similar. We would expect phrase 3 to live somewhere far away since it isn't related. If we had a fourth phrase, Sally ate Swiss cheese, this might exist somewhere between phrase 3 (cheese can go on sandwiches) and phrase 1 (mice like Swiss cheese).

In this example we only have 2 dimensions: the X and Y axis. In reality, we would need many more dimensions to effectively capture the complexities of human language.

## Using embeddings [\#](https://supabase.com/docs/guides/ai/concepts\#using-embeddings)

Compared to our 2-dimensional example above, most embedding models will output many more dimensions. For example the open source [`gte-small`](https://huggingface.co/Supabase/gte-small) model outputs 384 dimensions.

Why is this useful? Once we have generated embeddings on multiple texts, it is trivial to calculate how similar they are using vector math operations like cosine distance. A common use case for this is search. Your process might look something like this:

1. Pre-process your knowledge base and generate embeddings for each page
2. Store your embeddings to be referenced later
3. Build a search page that prompts your user for input
4. Take user's input, generate a one-time embedding, then perform a similarity search against your pre-processed embeddings.
5. Return the most similar pages to the user

## See also [\#](https://supabase.com/docs/guides/ai/concepts\#see-also)

- [Structured and Unstructured embeddings](https://supabase.com/docs/guides/ai/structured-unstructured)

### Is this helpful?

NoYes

### On this page

[What are embeddings?](https://supabase.com/docs/guides/ai/concepts#what-are-embeddings) [Human language](https://supabase.com/docs/guides/ai/concepts#human-language) [How do embeddings work?](https://supabase.com/docs/guides/ai/concepts#how-do-embeddings-work) [Using embeddings](https://supabase.com/docs/guides/ai/concepts#using-embeddings) [See also](https://supabase.com/docs/guides/ai/concepts#see-also)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_engineering_for_scale.md">
AI & Vectors

# Engineering for Scale

## Building an enterprise-grade vector architecture.

* * *

Content sources for vectors can be extremely large. As you grow you should run your Vector workloads across several secondary databases (sometimes called "pods"), which allows each collection to scale independently.

## Simple workloads [\#](https://supabase.com/docs/guides/ai/engineering-for-scale\#simple-workloads)

For small workloads, it's typical to store your data in a single database.

If you've used [Vecs](https://supabase.com/docs/guides/ai/vecs-python-client) to create 3 different collections, you can expose collections to your web or mobile application using [views](https://supabase.com/docs/guides/database/tables#views):

![single database](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fai%2Fscaling%2Fengineering-for-scale--single-database--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

For example, with 3 collections, called `docs`, `posts`, and `images`, we could expose the "docs" inside the public schema like this:

`
create view public.docs as
select
id,
embedding,
metadata, # Expose the metadata as JSON
(metadata->>'url')::text as url # Extract the URL as a string
from vector
`

You can then use any of the client libraries to access your collections within your applications:

`
const { data, error } = await supabase
.from('docs')
.select('id, embedding, metadata')
.eq('url', '/hello-world')
`

## Enterprise workloads [\#](https://supabase.com/docs/guides/ai/engineering-for-scale\#enterprise-workloads)

As you move into production, we recommend splitting your collections into separate projects. This is because it allows your vector stores to scale independently of your production data. Vectors typically grow faster than operational data, and they have different resource requirements. Running them on separate databases removes the single-point-of-failure.

![With secondaries](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fai%2Fscaling%2Fengineering-for-scale--with-secondaries--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

You can use as many secondary databases as you need to manage your collections. With this architecture, you have 2 options for accessing collections within your application:

1. Query the collections directly using Vecs.
2. Access the collections from your Primary database through a Wrapper.

You can use both of these in tandem to suit your use-case. We recommend option `1` wherever possible, as it offers the most scalability.

### Query collections using Vecs [\#](https://supabase.com/docs/guides/ai/engineering-for-scale\#query-collections-using-vecs)

Vecs provides methods for querying collections, either using a [cosine similarity function](https://supabase.github.io/vecs/api/#basic) or with [metadata filtering](https://supabase.github.io/vecs/api/#metadata-filtering).

`
# cosine similarity
docs.query(query_vector=[0.4,0.5,0.6], limit=5)
# metadata filtering
docs.query(
    query_vector=[0.4,0.5,0.6],
    limit=5,
    filters={"year": {"$eq": 2012}}, # metadata filters
)
`

### Accessing external collections using Wrappers [\#](https://supabase.com/docs/guides/ai/engineering-for-scale\#accessing-external-collections-using-wrappers)

Supabase supports [Foreign Data Wrappers](https://supabase.com/blog/postgres-foreign-data-wrappers-rust). Wrappers allow you to connect two databases together so that you can query them over the network.

This involves 2 steps: connecting to your remote database from the primary and creating a Foreign Table.

#### Connecting your remote database [\#](https://supabase.com/docs/guides/ai/engineering-for-scale\#connecting-your-remote-database)

Inside your Primary database we need to provide the credentials to access the secondary database:

`
create extension postgres_fdw;
create server docs_server
foreign data wrapper postgres_fdw
options (host 'db.xxx.supabase.co', port '5432', dbname 'postgres');
create user mapping for docs_user
server docs_server
options (user 'postgres', password 'password');
`

#### Create a foreign table [\#](https://supabase.com/docs/guides/ai/engineering-for-scale\#create-a-foreign-table)

We can now create a foreign table to access the data in our secondary project.

`
create foreign table docs (
id text not null,
embedding vector(384),
metadata jsonb,
url text
)
server docs_server
options (schema_name 'public', table_name 'docs');
`

This looks very similar to our View example above, and you can continue to use the client libraries to access your collections through the foreign table:

`
const { data, error } = await supabase
.from('docs')
.select('id, embedding, metadata')
.eq('url', '/hello-world')
`

### Enterprise architecture [\#](https://supabase.com/docs/guides/ai/engineering-for-scale\#enterprise-architecture)

This diagram provides an example architecture that allows you to access the collections either with our client libraries or using Vecs. You can add as many secondary databases as you need (in this example we only show one):

![multi database](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fai%2Fscaling%2Fengineering-for-scale--multi-database--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Simple workloads](https://supabase.com/docs/guides/ai/engineering-for-scale#simple-workloads) [Enterprise workloads](https://supabase.com/docs/guides/ai/engineering-for-scale#enterprise-workloads) [Query collections using Vecs](https://supabase.com/docs/guides/ai/engineering-for-scale#query-collections-using-vecs) [Accessing external collections using Wrappers](https://supabase.com/docs/guides/ai/engineering-for-scale#accessing-external-collections-using-wrappers) [Enterprise architecture](https://supabase.com/docs/guides/ai/engineering-for-scale#enterprise-architecture)

![single database](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fai%2Fscaling%2Fengineering-for-scale--single-database--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![With secondaries](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fai%2Fscaling%2Fengineering-for-scale--with-secondaries--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![multi database](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fai%2Fscaling%2Fengineering-for-scale--multi-database--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_examples_building_chatgpt_plugins.md">
AI & Vectors

# Building ChatGPT plugins

## Use Supabase as a Retrieval Store for your ChatGPT plugin.

* * *

ChatGPT recently released [Plugins](https://openai.com/blog/chatgpt-plugins) which help ChatGPT access up-to-date information, run computations, or use third-party services.
If you're building a plugin for ChatGPT, you'll probably want to answer questions from a specific source. We can solve this with retrieval plugins, which allow ChatGPT to access information from a database.

## What is ChatGPT Retrieval Plugin? [\#](https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins\#what-is-chatgpt-retrieval-plugin)

A [Retrieval Plugin](https://github.com/openai/chatgpt-retrieval-plugin) is a Python project designed to inject external data into a ChatGPT conversation. It does a few things:

1. Turn documents into smaller chunks.
2. Converts chunks into embeddings using OpenAI's `text-embedding-ada-002` model.
3. Stores the embeddings into a vector database.
4. Queries the vector database for relevant documents when a question is asked.

It allows ChatGPT to dynamically pull relevant information into conversations from your data sources. This could be PDF documents, Confluence, or Notion knowledge bases.

## Example: Chat with Postgres docs [\#](https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins\#example-chat-with-postgres-docs)

Lets build an example where we can ask ChatGPT questions about the Postgres documentation. Although ChatGPT already knows about the Postgres documentation because it is publicly available, this is a simple example which demonstrates how to work with PDF files.

This plugin requires several steps:

1. Download all the [Postgres docs as a PDF](https://www.postgresql.org/files/documentation/pdf/15/postgresql-15-US.pdf)
2. Convert the docs into chunks of embedded text and store them in Supabase
3. Run our plugin locally so that we can ask questions about the Postgres docs.

We'll be saving the Postgres documentation in Postgres, and ChatGPT will be retrieving the documentation whenever a user asks a question:

![diagram reference](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fai%2Fchatgpt-plugins%2Fchatgpt-plugin-scheme--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Step 1: Fork the ChatGPT Retrieval Plugin repository [\#](https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins\#step-1-fork-the-chatgpt-retrieval-plugin-repository)

Fork the ChatGPT Retrieval Plugin repository to your GitHub account and clone it to your local machine. Read through the `README.md` file to understand the project structure.

### Step 2: Install dependencies [\#](https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins\#step-2-install-dependencies)

Choose your desired datastore provider and remove unused dependencies from `pyproject.toml`. For this example, we'll use Supabase. And install dependencies with Poetry:

`
poetry install
`

### Step 3: Create a Supabase project [\#](https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins\#step-3-create-a-supabase-project)

Create a [Supabase project](https://supabase.com/dashboard) and database by following the instructions [here](https://supabase.com/docs/guides/platform). Export the environment variables required for the retrieval plugin to work:

`
export OPENAI_API_KEY=<open_ai_api_key>
export DATASTORE=supabase
export SUPABASE_URL=<supabase_url>
export SUPABASE_SERVICE_ROLE_KEY=<supabase_key>
`

For Postgres datastore, you'll need to export these environment variables instead:

`
export OPENAI_API_KEY=<open_ai_api_key>
export DATASTORE=postgres
export PG_HOST=<postgres_host_url>
export PG_PASSWORD=<postgres_password>
`

### Step 4: Run Postgres locally [\#](https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins\#step-4-run-postgres-locally)

To start quicker you may use Supabase CLI to spin everything up locally as it already includes pgvector from the start. Install `supabase-cli`, go to the `examples/providers` folder in the repo and run:

`
supabase start
`

This will pull all docker images and run Supabase stack in docker on your local machine. It will also apply all the necessary migrations to set the whole thing up. You can then use your local setup the same way, just export the environment variables and follow to the next steps.

Using `supabase-cli` is not required and you can use any other docker image or hosted version of Postgres that includes `pgvector`. Just make sure you run migrations from `examples/providers/supabase/migrations/20230414142107_init_pg_vector.sql`.

### Step 5: Obtain OpenAI API key [\#](https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins\#step-5-obtain-openai-api-key)

To create embeddings Plugin uses OpenAI API and `text-embedding-ada-002` model. Each time we add some data to our datastore, or try to query relevant information from it, embedding will be created either for inserted data chunk, or for the query itself. To make it work we need to export `OPENAI_API_KEY`. If you already have an account in OpenAI, you just need to go to [User Settings - API keys](https://platform.openai.com/account/api-keys) and Create new secret key.

![OpenAI Secret Keys](https://supabase.com/docs/img/ai/chatgpt-plugins/openai-secret-keys.png)

### Step 6: Run the plugin [\#](https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins\#step-6-run-the-plugin)

Execute the following command to run the plugin:

`
poetry run dev
# output
INFO:     Will watch for changes in these directories: ['./chatgpt-retrieval-plugin']
INFO:     Uvicorn running on http://localhost:3333 (Press CTRL+C to quit)
INFO:     Started reloader process [87843] using WatchFiles
INFO:     Started server process [87849]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
`

The plugin will start on your localhost - port `:3333` by default.

### Step 6: Populating data in the datastore [\#](https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins\#step-6-populating-data-in-the-datastore)

For this example, we'll upload Postgres documentation to the datastore. Download the [Postgres documentation](https://www.postgresql.org/files/documentation/pdf/15/postgresql-15-US.pdf) and use the `/upsert-file` endpoint to upload it:

`
curl -X POST -F \\"file=@./postgresql-15-US.pdf\\" <http://localhost:3333/upsert-file>
`

The plugin will split your data and documents into smaller chunks automatically. You can view the chunks using the Supabase dashboard or any other SQL client you prefer. The entire Postgres Documentation yielded 7,904 records, which is not a lot, but we can try to add index for `embedding` column to speed things up by a little. To do so, you should run the following SQL command:

`
create index on documents
using hnsw (embedding vector_ip_ops)
with (lists = 10);
`

This will create an index for the inner product distance function. Important to note that it is an approximate index. It will change the logic from performing the exact nearest neighbor search to the approximate nearest neighbor search.

We are using `lists = 10`, because as a general guideline, you should start looking for optimal lists constant value with the formula: `rows / 1000` when you have less than 1 million records in your table.

### Step 7: Using our plugin within ChatGPT [\#](https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins\#step-7-using-our-plugin-within-chatgpt)

To integrate our plugin with ChatGPT, register it in the ChatGPT dashboard. Assuming you have access to ChatGPT Plugins and plugin development, select the Plugins model in a new chat, then choose "Plugin store" and "Develop your own plugin." Enter `localhost:3333` into the domain input, and your plugin is now part of ChatGPT.

![ChatGPT Plugin Store](https://supabase.com/docs/img/ai/chatgpt-plugins/chatgpt-plugin-store.png)

![ChatGPT Local Plugin](https://supabase.com/docs/img/ai/chatgpt-plugins/chatgpt-local-plugin.png)

You can now ask questions about Postgres and receive answers derived from the documentation.

Let's try it out: ask ChatGPT to find out when to use `check` and when to use `using`. You will be able to see what queries were sent to our plugin and what it responded to.

![Ask ChatGPT](https://supabase.com/docs/img/ai/chatgpt-plugins/ask-chatgpt.png)

And after ChatGPT receives a response from the plugin it will answer your question with the data from the documentation.

![ChatGPT Reply](https://supabase.com/docs/img/ai/chatgpt-plugins/chatgpt-reply.png)

## Resources [\#](https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins\#resources)

- ChatGPT Retrieval Plugin: [github.com/openai/chatgpt-retrieval-plugin](https://github.com/openai/chatgpt-retrieval-plugin)
- ChatGPT Plugins: [official documentation](https://platform.openai.com/docs/plugins/introduction)

### Is this helpful?

NoYes

### On this page

[What is ChatGPT Retrieval Plugin?](https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins#what-is-chatgpt-retrieval-plugin) [Example: Chat with Postgres docs](https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins#example-chat-with-postgres-docs) [Step 1: Fork the ChatGPT Retrieval Plugin repository](https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins#step-1-fork-the-chatgpt-retrieval-plugin-repository) [Step 2: Install dependencies](https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins#step-2-install-dependencies) [Step 3: Create a Supabase project](https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins#step-3-create-a-supabase-project) [Step 4: Run Postgres locally](https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins#step-4-run-postgres-locally) [Step 5: Obtain OpenAI API key](https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins#step-5-obtain-openai-api-key) [Step 6: Run the plugin](https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins#step-6-run-the-plugin) [Step 6: Populating data in the datastore](https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins#step-6-populating-data-in-the-datastore) [Step 7: Using our plugin within ChatGPT](https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins#step-7-using-our-plugin-within-chatgpt) [Resources](https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins#resources)

![diagram reference](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fai%2Fchatgpt-plugins%2Fchatgpt-plugin-scheme--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_examples_headless_vector_search.md">
AI & Vectors

# Adding generative Q&A for your documentation

## Learn how to build a ChatGPT-style doc search powered using our headless search toolkit.

* * *

Supabase provides a [Headless Search Toolkit](https://github.com/supabase/headless-vector-search) for adding "Generative Q&A" to your documentation. The toolkit is "headless", so that you can integrate it into your existing website and style it to match your website theme.

You can see how this works with the Supabase docs. Just hit `cmd+k` and "ask" for something like "what are the features of Supabase?". You will see that the response is streamed back, using the information provided in the docs:

![headless search](https://supabase.com/docs/img/ai/headless-search/headless.png)

## Tech stack [\#](https://supabase.com/docs/guides/ai/examples/headless-vector-search\#tech-stack)

- Supabase: Database & Edge Functions.
- OpenAI: Embeddings and completions.
- GitHub Actions: for ingesting your markdown docs.

## Toolkit [\#](https://supabase.com/docs/guides/ai/examples/headless-vector-search\#toolkit)

This toolkit consists of 2 parts:

- The [Headless Vector Search](https://github.com/supabase/headless-vector-search) template which you can deploy in your own organization.
- A [GitHub Action](https://github.com/supabase/embeddings-generator) which will ingest your markdown files, convert them to embeddings, and store them in your database.

## Usage [\#](https://supabase.com/docs/guides/ai/examples/headless-vector-search\#usage)

There are 3 steps to build similarity search inside your documentation:

1. Prepare your database.
2. Ingest your documentation.
3. Add a search interface.

### Prepare your database [\#](https://supabase.com/docs/guides/ai/examples/headless-vector-search\#prepare-your-database)

To prepare, create a [new Supabase project](https://database.new/) and store the database and API credentials, which you can find in the project [settings](https://supabase.com/dashboard/project/_/settings).

Now we can use the [Headless Vector Search](https://github.com/supabase/headless-vector-search#set-up) instructions to set up the database:

1. Clone the repo to your local machine: `git clone git@github.com:supabase/headless-vector-search.git`
2. Link the repo to your remote project: `supabase link --project-ref XXX`
3. Apply the database migrations: `supabase db push`
4. Set your OpenAI key as a secret: `supabase secrets set OPENAI_API_KEY=sk-xxx`
5. Deploy the Edge Functions: `supabase functions deploy --no-verify-jwt`
6. Expose `docs` schema via API in Supabase Dashboard [settings](https://supabase.com/dashboard/project/_/settings/api) \> `API Settings` \> `Exposed schemas`

### Ingest your documentation [\#](https://supabase.com/docs/guides/ai/examples/headless-vector-search\#ingest-your-documentation)

Now we need to push your documentation into the database as embeddings. You can do this manually, but to make it easier we've created a [GitHub Action](https://github.com/marketplace/actions/supabase-embeddings-generator) which can update your database every time there is a Pull Request.

In your knowledge base repository, create a new action called `.github/workflows/generate_embeddings.yml` with the following content:

`
name: 'generate_embeddings'
on: # run on main branch changes
push:
    branches:
      - main
jobs:
generate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: supabase/embeddings-generator@v0.0.x # Update this to the latest version.
        with:
          supabase-url: 'https://your-project-ref.supabase.co' # Update this to your project URL.
          supabase-service-role-key: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          openai-key: ${{ secrets.OPENAI_API_KEY }}
          docs-root-path: 'docs' # the path to the root of your md(x) files
`

Make sure to choose the latest version, and set your `SUPABASE_SERVICE_ROLE_KEY` and `OPENAI_API_KEY` as repository secrets in your repo settings (settings > secrets > actions).

### Add a search interface [\#](https://supabase.com/docs/guides/ai/examples/headless-vector-search\#add-a-search-interface)

Now inside your docs, you need to create a search interface. Because this is a headless interface, you can use it with any language. The only requirement is that you send the user query to the `query` Edge Function, which will stream an answer back from OpenAI. It might look something like this:

``
const onSubmit = (e: Event) => {
e.preventDefault()
answer.value = ""
isLoading.value = true
const query = new URLSearchParams({ query: inputRef.current!.value })
const projectUrl = `https://your-project-ref.supabase.co/functions/v1`
const queryURL = `${projectURL}/${query}`
const eventSource = new EventSource(queryURL)
eventSource.addEventListener("error", (err) => {
    isLoading.value = false
    console.error(err)
})
eventSource.addEventListener("message", (e: MessageEvent) => {
    isLoading.value = false
    if (e.data === "[DONE]") {
      eventSource.close()
      return
    }
    const completionResponse: CreateCompletionResponse = JSON.parse(e.data)
    const text = completionResponse.choices[0].text
    answer.value += text
});
isLoading.value = true
}
``

## Resources [\#](https://supabase.com/docs/guides/ai/examples/headless-vector-search\#resources)

- Read about how we built [ChatGPT for the Supabase Docs](https://supabase.com/blog/chatgpt-supabase-docs).
- Read the pgvector Docs for [Embeddings and vector similarity](https://supabase.com/docs/guides/database/extensions/pgvector)
- See how to build something like this from scratch [using Next.js](https://supabase.com/docs/guides/ai/examples/nextjs-vector-search).

### Is this helpful?

NoYes

### On this page

[Tech stack](https://supabase.com/docs/guides/ai/examples/headless-vector-search#tech-stack) [Toolkit](https://supabase.com/docs/guides/ai/examples/headless-vector-search#toolkit) [Usage](https://supabase.com/docs/guides/ai/examples/headless-vector-search#usage) [Prepare your database](https://supabase.com/docs/guides/ai/examples/headless-vector-search#prepare-your-database) [Ingest your documentation](https://supabase.com/docs/guides/ai/examples/headless-vector-search#ingest-your-documentation) [Add a search interface](https://supabase.com/docs/guides/ai/examples/headless-vector-search#add-a-search-interface) [Resources](https://supabase.com/docs/guides/ai/examples/headless-vector-search#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_examples_huggingface_image_captioning.md">
AI & Vectors

# Generate image captions using Hugging Face

## Use the Hugging Face Inference API to make calls to 100,000+ Machine Learning models from Supabase Edge Functions.

* * *

We can combine Hugging Face with [Supabase Storage](https://supabase.com/storage) and [Database Webhooks](https://supabase.com/docs/guides/database/webhooks) to automatically caption for any image we upload to a storage bucket.

## About Hugging Face [\#](https://supabase.com/docs/guides/ai/examples/huggingface-image-captioning\#about-hugging-face)

[Hugging Face](https://huggingface.co/) is the collaboration platform for the machine learning community.

[Huggingface.js](https://huggingface.co/docs/huggingface.js/index) provides a convenient way to make calls to 100,000+ Machine Learning models, making it easy to incorporate AI functionality into your [Supabase Edge Functions](https://supabase.com/edge-functions).

## Setup [\#](https://supabase.com/docs/guides/ai/examples/huggingface-image-captioning\#setup)

- Open your Supabase project dashboard or [create a new project](https://supabase.com/dashboard/projects).
- [Create a new bucket](https://supabase.com/dashboard/project/_/storage/buckets) called `images`.
- Generate TypeScript types from remote Database.
- Create a new Database table called `image_caption`.
  - Create `id` column of type `uuid` which references `storage.objects.id`.
  - Create a `caption` column of type `text`.
- Regenerate TypeScript types to include new `image_caption` table.
- Deploy the function to Supabase: `supabase functions deploy huggingface-image-captioning`.
- Create the Database Webhook in the [Supabase Dashboard](https://supabase.com/dashboard/project/_/database/hooks) to trigger the `huggingface-image-captioning` function anytime a record is added to the `storage.objects` table.

## Generate TypeScript types [\#](https://supabase.com/docs/guides/ai/examples/huggingface-image-captioning\#generate-typescript-types)

To generate the types.ts file for the storage and public schemas, run the following command in the terminal:

`
supabase gen types typescript --project-id=your-project-ref --schema=storage,public > supabase/functions/huggingface-image-captioning/types.ts
`

## Code [\#](https://supabase.com/docs/guides/ai/examples/huggingface-image-captioning\#code)

Find the complete code on [GitHub](https://github.com/supabase/supabase/tree/master/examples/edge-functions/supabase/functions/huggingface-image-captioning).

``
import { serve } from 'https://deno.land/std@0.168.0/http/server.ts'
import { HfInference } from 'https://esm.sh/@huggingface/inference@2.3.2'
import { createClient } from 'jsr:@supabase/supabase-js@2'
import { Database } from './types.ts'
console.log('Hello from `huggingface-image-captioning` function!')
const hf = new HfInference(Deno.env.get('HUGGINGFACE_ACCESS_TOKEN'))
type SoRecord = Database['storage']['Tables']['objects']['Row']
interface WebhookPayload {
type: 'INSERT' | 'UPDATE' | 'DELETE'
table: string
record: SoRecord
schema: 'public'
old_record: null | SoRecord
}
serve(async (req) => {
const payload: WebhookPayload = await req.json()
const soRecord = payload.record
const supabaseAdminClient = createClient<Database>(
    // Supabase API URL - env var exported by default when deployed.
    Deno.env.get('SUPABASE_URL') ?? '',
    // Supabase API SERVICE ROLE KEY - env var exported by default when deployed.
    Deno.env.get('SUPABASE_SERVICE_ROLE_KEY') ?? ''
)
// Construct image url from storage
const { data, error } = await supabaseAdminClient.storage
    .from(soRecord.bucket_id!)
    .createSignedUrl(soRecord.path_tokens!.join('/'), 60)
if (error) throw error
const { signedUrl } = data
// Run image captioning with Huggingface
const imgDesc = await hf.imageToText({
    data: await (await fetch(signedUrl)).blob(),
    model: 'nlpconnect/vit-gpt2-image-captioning',
})
// Store image caption in Database table
await supabaseAdminClient
    .from('image_caption')
    .insert({ id: soRecord.id!, caption: imgDesc.generated_text })
    .throwOnError()
return new Response('ok')
})
``

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2FOgnYxRkxEUw%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[About Hugging Face](https://supabase.com/docs/guides/ai/examples/huggingface-image-captioning#about-hugging-face) [Setup](https://supabase.com/docs/guides/ai/examples/huggingface-image-captioning#setup) [Generate TypeScript types](https://supabase.com/docs/guides/ai/examples/huggingface-image-captioning#generate-typescript-types) [Code](https://supabase.com/docs/guides/ai/examples/huggingface-image-captioning#code)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_examples_image_search_openai_clip.md">
AI & Vectors

# Image Search with OpenAI CLIP

## Implement image search with the OpenAI CLIP Model and Supabase Vector.

* * *

The [OpenAI CLIP Model](https://github.com/openai/CLIP) was trained on a variety of (image, text)-pairs. You can use the CLIP model for:

- Text-to-Image / Image-To-Text / Image-to-Image / Text-to-Text Search
- You can fine-tune it on your own image and text data with the regular `SentenceTransformers` training code.

[`SentenceTransformers`](https://www.sbert.net/examples/applications/image-search/README.html) provides models that allow you to embed images and text into the same vector space. You can use this to find similar images as well as to implement image search.

You can find the full application code as a Python Poetry project on [GitHub](https://github.com/supabase/supabase/tree/master/examples/ai/image_search#image-search-with-supabase-vector).

## Create a new Python project with Poetry [\#](https://supabase.com/docs/guides/ai/examples/image-search-openai-clip\#create-a-new-python-project-with-poetry)

[Poetry](https://python-poetry.org/) provides packaging and dependency management for Python. If you haven't already, install poetry via pip:

`
pip install poetry
`

Then initialize a new project:

`
poetry new image-search
`

## Setup Supabase project [\#](https://supabase.com/docs/guides/ai/examples/image-search-openai-clip\#setup-supabase-project)

If you haven't already, [install the Supabase CLI](https://supabase.com/docs/guides/cli), then initialize Supabase in the root of your newly created poetry project:

`
supabase init
`

Next, start your local Supabase stack:

`
supabase start
`

This will start up the Supabase stack locally and print out a bunch of environment details, including your local `DB URL`. Make a note of that for later user.

## Install the dependencies [\#](https://supabase.com/docs/guides/ai/examples/image-search-openai-clip\#install-the-dependencies)

We will need to add the following dependencies to our project:

- [`vecs`](https://github.com/supabase/vecs#vecs): Supabase Vector Python Client.
- [`sentence-transformers`](https://huggingface.co/sentence-transformers/clip-ViT-B-32): a framework for sentence, text and image embeddings (used with OpenAI CLIP model)
- [`matplotlib`](https://matplotlib.org/): for displaying our image result

`
poetry add vecs sentence-transformers matplotlib
`

## Import the necessary dependencies [\#](https://supabase.com/docs/guides/ai/examples/image-search-openai-clip\#import-the-necessary-dependencies)

At the top of your main python script, import the dependencies and store your `DB URL` from above in a variable:

`
from PIL import Image
from sentence_transformers import SentenceTransformer
import vecs
from matplotlib import pyplot as plt
from matplotlib import image as mpimg
DB_CONNECTION = "postgresql://postgres:postgres@localhost:54322/postgres"
`

## Create embeddings for your images [\#](https://supabase.com/docs/guides/ai/examples/image-search-openai-clip\#create-embeddings-for-your-images)

In the root of your project, create a new folder called `images` and add some images. You can use the images from the example project on [GitHub](https://github.com/supabase/supabase/tree/master/examples/ai/image_search/images) or you can find license free images on [Unsplash](https://unsplash.com/).

Next, create a `seed` method, which will create a new Supabase Vector Collection, generate embeddings for your images, and upsert the embeddings into your database:

`
def seed():
    # create vector store client
    vx = vecs.create_client(DB_CONNECTION)
    # create a collection of vectors with 3 dimensions
    images = vx.get_or_create_collection(name="image_vectors", dimension=512)
    # Load CLIP model
    model = SentenceTransformer('clip-ViT-B-32')
    # Encode an image:
    img_emb1 = model.encode(Image.open('./images/one.jpg'))
    img_emb2 = model.encode(Image.open('./images/two.jpg'))
    img_emb3 = model.encode(Image.open('./images/three.jpg'))
    img_emb4 = model.encode(Image.open('./images/four.jpg'))
    # add records to the *images* collection
    images.upsert(
        records=[\
            (\
                "one.jpg",        # the vector's identifier\
                img_emb1,          # the vector. list or np.array\
                {"type": "jpg"}   # associated  metadata\
            ), (\
                "two.jpg",\
                img_emb2,\
                {"type": "jpg"}\
            ), (\
                "three.jpg",\
                img_emb3,\
                {"type": "jpg"}\
            ), (\
                "four.jpg",\
                img_emb4,\
                {"type": "jpg"}\
            )\
        ]
    )
    print("Inserted images")
    # index the collection for fast search performance
    images.create_index()
    print("Created index")
`

Add this method as a script in your `pyproject.toml` file:

`
[tool.poetry.scripts]
seed = "image_search.main:seed"
search = "image_search.main:search"
`

After activating the virtual environment with `poetry shell` you can now run your seed script via `poetry run seed`. You can inspect the generated embeddings in your local database by visiting the local Supabase dashboard at [localhost:54323](http://localhost:54323/project/default/editor), selecting the `vecs` schema, and the `image_vectors` database.

## Perform an image search from a text query [\#](https://supabase.com/docs/guides/ai/examples/image-search-openai-clip\#perform-an-image-search-from-a-text-query)

With Supabase Vector we can query our embeddings. We can use either an image as search input or alternative we can generate an embedding from a string input and use that as the query input:

`
def search():
    # create vector store client
    vx = vecs.create_client(DB_CONNECTION)
    images = vx.get_or_create_collection(name="image_vectors", dimension=512)
    # Load CLIP model
    model = SentenceTransformer('clip-ViT-B-32')
    # Encode text query
    query_string = "a bike in front of a red brick wall"
    text_emb = model.encode(query_string)
    # query the collection filtering metadata for "type" = "jpg"
    results = images.query(
        data=text_emb,                      # required
        limit=1,                            # number of records to return
        filters={"type": {"$eq": "jpg"}},   # metadata filters
    )
    result = results[0]
    print(result)
    plt.title(result)
    image = mpimg.imread('./images/' + result)
    plt.imshow(image)
    plt.show()
`

By limiting the query to one result, we can show the most relevant image to the user. Finally we use `matplotlib` to show the image result to the user.

Go ahead and test it out by running `poetry run search` and you will be presented with an image of a "bike in front of a red brick wall".

## Conclusion [\#](https://supabase.com/docs/guides/ai/examples/image-search-openai-clip\#conclusion)

With just a couple of lines of Python you are able to implement image search as well as reverse image search using OpenAI's CLIP model and Supabase Vector.

### Is this helpful?

NoYes

### On this page

[Create a new Python project with Poetry](https://supabase.com/docs/guides/ai/examples/image-search-openai-clip#create-a-new-python-project-with-poetry) [Setup Supabase project](https://supabase.com/docs/guides/ai/examples/image-search-openai-clip#setup-supabase-project) [Install the dependencies](https://supabase.com/docs/guides/ai/examples/image-search-openai-clip#install-the-dependencies) [Import the necessary dependencies](https://supabase.com/docs/guides/ai/examples/image-search-openai-clip#import-the-necessary-dependencies) [Create embeddings for your images](https://supabase.com/docs/guides/ai/examples/image-search-openai-clip#create-embeddings-for-your-images) [Perform an image search from a text query](https://supabase.com/docs/guides/ai/examples/image-search-openai-clip#perform-an-image-search-from-a-text-query) [Conclusion](https://supabase.com/docs/guides/ai/examples/image-search-openai-clip#conclusion)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_examples_mixpeek_video_search.md">
AI & Vectors

# Video Search with Mixpeek Multimodal Embeddings

## Implement video search with the Mixpeek Multimodal Embed API and Supabase Vector.

* * *

The [Mixpeek Embed API](https://docs.mixpeek.com/api-documentation/inference/embed) allows you to generate embeddings for various types of content, including videos and text. You can use these embeddings for:

- Text-to-Video / Video-To-Text / Video-to-Video / Text-to-Text Search
- Fine-tuning on your own video and text data

This guide demonstrates how to implement video search using Mixpeek Embed for video processing and embedding, and Supabase Vector for storing and querying embeddings.

You can find the full application code as a Python Poetry project on [GitHub](https://github.com/yourusername/your-repo-name).

## Create a new Python project with Poetry [\#](https://supabase.com/docs/guides/ai/examples/mixpeek-video-search\#create-a-new-python-project-with-poetry)

[Poetry](https://python-poetry.org/) provides packaging and dependency management for Python. If you haven't already, install poetry via pip:

`
pip install poetry
`

Then initialize a new project:

`
poetry new video-search
`

## Setup Supabase project [\#](https://supabase.com/docs/guides/ai/examples/mixpeek-video-search\#setup-supabase-project)

If you haven't already, [install the Supabase CLI](https://supabase.com/docs/guides/cli), then initialize Supabase in the root of your newly created poetry project:

`
supabase init
`

Next, start your local Supabase stack:

`
supabase start
`

This will start up the Supabase stack locally and print out a bunch of environment details, including your local `DB URL`. Make a note of that for later use.

## Install the dependencies [\#](https://supabase.com/docs/guides/ai/examples/mixpeek-video-search\#install-the-dependencies)

Add the following dependencies to your project:

- [`supabase`](https://github.com/supabase-community/supabase-py): Supabase Python Client
- [`mixpeek`](https://github.com/mixpeek/python-client): Mixpeek Python Client for embedding generation

`
poetry add supabase mixpeek
`

## Import the necessary dependencies [\#](https://supabase.com/docs/guides/ai/examples/mixpeek-video-search\#import-the-necessary-dependencies)

At the top of your main Python script, import the dependencies and store your environment variables:

`
from supabase import create_client, Client
from mixpeek import Mixpeek
import os
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_API_KEY")
MIXPEEK_API_KEY = os.getenv("MIXPEEK_API_KEY")
`

## Create embeddings for your videos [\#](https://supabase.com/docs/guides/ai/examples/mixpeek-video-search\#create-embeddings-for-your-videos)

Next, create a `seed` method, which will create a new Supabase table, generate embeddings for your video chunks, and insert the embeddings into your database:

`
def seed():
    # Initialize Supabase and Mixpeek clients
    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
    mixpeek = Mixpeek(MIXPEEK_API_KEY)
    # Create a table for storing video chunk embeddings
    supabase.table("video_chunks").create({
        "id": "text",
        "start_time": "float8",
        "end_time": "float8",
        "embedding": "vector(768)",
        "metadata": "jsonb"
    })
    # Process and embed video
    video_url = "https://example.com/your_video.mp4"
    processed_chunks = mixpeek.tools.video.process(
        video_source=video_url,
        chunk_interval=1,  # 1 second intervals
        resolution=[720, 1280]
    )
    for chunk in processed_chunks:
        print(f"Processing video chunk: {chunk['start_time']}")
        # Generate embedding using Mixpeek
        embed_response = mixpeek.embed.video(
            model_id="vuse-generic-v1",
            input=chunk['base64_chunk'],
            input_type="base64"
        )
        # Insert into Supabase
        supabase.table("video_chunks").insert({
            "id": f"chunk_{chunk['start_time']}",
            "start_time": chunk["start_time"],
            "end_time": chunk["end_time"],
            "embedding": embed_response['embedding'],
            "metadata": {"video_url": video_url}
        }).execute()
    print("Video processed and embeddings inserted")
    # Create index for fast search performance
    supabase.query("CREATE INDEX ON video_chunks USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100)").execute()
    print("Created index")
`

Add this method as a script in your `pyproject.toml` file:

`
[tool.poetry.scripts]
seed = "video_search.main:seed"
search = "video_search.main:search"
`

After activating the virtual environment with `poetry shell`, you can now run your seed script via `poetry run seed`. You can inspect the generated embeddings in your local database by visiting the local Supabase dashboard at [localhost:54323](http://localhost:54323/project/default/editor).

## Perform a video search from a text query [\#](https://supabase.com/docs/guides/ai/examples/mixpeek-video-search\#perform-a-video-search-from-a-text-query)

With Supabase Vector, you can query your embeddings. You can use either a video clip as search input or alternatively, you can generate an embedding from a string input and use that as the query input:

`
def search():
    # Initialize Supabase and Mixpeek clients
    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
    mixpeek = Mixpeek(MIXPEEK_API_KEY)
    # Generate embedding for text query
    query_string = "a car chase scene"
    text_emb = mixpeek.embed.video(
        model_id="vuse-generic-v1",
        input=query_string,
        input_type="text"
    )
    # Query the collection
    results = supabase.rpc(
        'match_video_chunks',
        {
            'query_embedding': text_emb['embedding'],
            'match_threshold': 0.8,
            'match_count': 5
        }
    ).execute()
    # Display the results
    if results.data:
        for result in results.data:
            print(f"Matched chunk from {result['start_time']} to {result['end_time']} seconds")
            print(f"Video URL: {result['metadata']['video_url']}")
            print(f"Similarity: {result['similarity']}")
            print("---")
    else:
        print("No matching video chunks found")
`

This query will return the top 5 most similar video chunks from your database.

You can now test it out by running `poetry run search`, and you will be presented with the most relevant video chunks to the query "a car chase scene".

## Conclusion [\#](https://supabase.com/docs/guides/ai/examples/mixpeek-video-search\#conclusion)

With just a couple of Python scripts, you are able to implement video search as well as reverse video search using Mixpeek Embed and Supabase Vector. This approach allows for powerful semantic search capabilities that can be integrated into various applications, enabling you to search through video content using both text and video queries.

### Is this helpful?

NoYes

### On this page

[Create a new Python project with Poetry](https://supabase.com/docs/guides/ai/examples/mixpeek-video-search#create-a-new-python-project-with-poetry) [Setup Supabase project](https://supabase.com/docs/guides/ai/examples/mixpeek-video-search#setup-supabase-project) [Install the dependencies](https://supabase.com/docs/guides/ai/examples/mixpeek-video-search#install-the-dependencies) [Import the necessary dependencies](https://supabase.com/docs/guides/ai/examples/mixpeek-video-search#import-the-necessary-dependencies) [Create embeddings for your videos](https://supabase.com/docs/guides/ai/examples/mixpeek-video-search#create-embeddings-for-your-videos) [Perform a video search from a text query](https://supabase.com/docs/guides/ai/examples/mixpeek-video-search#perform-a-video-search-from-a-text-query) [Conclusion](https://supabase.com/docs/guides/ai/examples/mixpeek-video-search#conclusion)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_examples_nextjs_vector_search.md">
AI & Vectors

# Vector search with Next.js and OpenAI

## Learn how to build a ChatGPT-style doc search powered by Next.js, OpenAI, and Supabase.

* * *

While our [Headless Vector search](https://supabase.com/docs/guides/ai/examples/headless-vector-search) provides a toolkit for generative Q&A, in this tutorial we'll go more in-depth, build a custom ChatGPT-like search experience from the ground-up using Next.js. You will:

1. Convert your markdown into embeddings using OpenAI.
2. Store you embeddings in Postgres using pgvector.
3. Deploy a function for answering your users' questions.

You can read our [Supabase Clippy](https://supabase.com/blog/chatgpt-supabase-docs) blog post for a full example.

We assume that you have a Next.js project with a collection of `.mdx` files nested inside your `pages` directory. We will start developing locally with the Supabase CLI and then push our local database changes to our hosted Supabase project. You can find the [full Next.js example on GitHub](https://github.com/supabase-community/nextjs-openai-doc-search).

## Create a project [\#](https://supabase.com/docs/guides/ai/examples/nextjs-vector-search\#create-a-project)

1. [Create a new project](https://supabase.com/dashboard) in the Supabase Dashboard.
2. Enter your project details.
3. Wait for the new database to launch.

## Prepare the database [\#](https://supabase.com/docs/guides/ai/examples/nextjs-vector-search\#prepare-the-database)

Let's prepare the database schema. We can use the "OpenAI Vector Search" quickstart in the [SQL Editor](https://supabase.com/dashboard/project/_/sql), or you can copy/paste the SQL below and run it yourself.

DashboardSQL

1. Go to the [SQL Editor](https://supabase.com/dashboard/project/_/sql) page in the Dashboard.
2. Click **OpenAI Vector Search**.
3. Click **Run**.

## Pre-process the knowledge base at build time [\#](https://supabase.com/docs/guides/ai/examples/nextjs-vector-search\#pre-process-the-knowledge-base-at-build-time)

With our database set up, we need to process and store all `.mdx` files in the `pages` directory. You can find the full script [here](https://github.com/supabase-community/nextjs-openai-doc-search/blob/main/lib/generate-embeddings.ts), or follow the steps below:

1

### Generate Embeddings

Create a new file `lib/generate-embeddings.ts` and copy the code over from [GitHub](https://github.com/supabase-community/nextjs-openai-doc-search/blob/main/lib/generate-embeddings.ts).

`
curl \
https://raw.githubusercontent.com/supabase-community/nextjs-openai-doc-search/main/lib/generate-embeddings.ts \
-o "lib/generate-embeddings.ts"
`

2

### Set up environment variables

We need some environment variables to run the script. Add them to your `.env` file and make sure your `.env` file is not committed to source control!
You can get your local Supabase credentials by running `supabase status`.

`
NEXT_PUBLIC_SUPABASE_URL=
NEXT_PUBLIC_SUPABASE_ANON_KEY=
SUPABASE_SERVICE_ROLE_KEY=
# Get your key at https://platform.openai.com/account/api-keys
OPENAI_API_KEY=
`

3

### Run script at build time

Include the script in your `package.json` script commands to enable Vercel to automatically run it at build time.

`
"scripts": {
"dev": "next dev",
"build": "pnpm run embeddings && next build",
"start": "next start",
"embeddings": "tsx lib/generate-embeddings.ts"
},
`

## Create text completion with OpenAI API [\#](https://supabase.com/docs/guides/ai/examples/nextjs-vector-search\#create-text-completion-with-openai-api)

Anytime a user asks a question, we need to create an embedding for their question, perform a similarity search, and then send a text completion request to the OpenAI API with the query and then context content merged together into a prompt.

All of this is glued together in a [Vercel Edge Function](https://vercel.com/docs/concepts/functions/edge-functions), the code for which can be found on [GitHub](https://github.com/supabase-community/nextjs-openai-doc-search/blob/main/pages/api/vector-search.ts).

1

### Create Embedding for Question

In order to perform similarity search we need to turn the question into an embedding.

``
const embeddingResponse = await fetch('https://api.openai.com/v1/embeddings', {
method: 'POST',
headers: {
    Authorization: `Bearer ${openAiKey}`,
    'Content-Type': 'application/json',
},
body: JSON.stringify({
    model: 'text-embedding-ada-002',
    input: sanitizedQuery.replaceAll('\n', ' '),
}),
})
if (embeddingResponse.status !== 200) {
throw new ApplicationError('Failed to create embedding for question', embeddingResponse)
}
const {
data: [{ embedding }],
} = await embeddingResponse.json()
``

2

### Perform similarity search

Using the `embeddingResponse` we can now perform similarity search by performing an remote procedure call (RPC) to the database function we created earlier.

`
const { error: matchError, data: pageSections } = await supabaseClient.rpc(
'match_page_sections',
{
    embedding,
    match_threshold: 0.78,
    match_count: 10,
    min_content_length: 50,
}
)
`

3

### Perform text completion request

With the relevant content for the user's question identified, we can now build the prompt and make a text completion request via the OpenAI API.

If successful, the OpenAI API will respond with a `text/event-stream` response that we can forward to the client where we'll process the event stream to smoothly print the answer to the user.

``
const prompt = codeBlock`
${oneLine`
    You are a very enthusiastic Supabase representative who loves
    to help people! Given the following sections from the Supabase
    documentation, answer the question using only that information,
    outputted in markdown format. If you are unsure and the answer
    is not explicitly written in the documentation, say
    "Sorry, I don't know how to help with that."
`}
Context sections:
${contextText}
Question: """
${sanitizedQuery}
"""
Answer as markdown (including related code snippets if available):
`
const completionOptions: CreateCompletionRequest = {
model: 'gpt-3.5-turbo-instruct',
prompt,
max_tokens: 512,
temperature: 0,
stream: true,
}
const response = await fetch('https://api.openai.com/v1/completions', {
method: 'POST',
headers: {
    Authorization: `Bearer ${openAiKey}`,
    'Content-Type': 'application/json',
},
body: JSON.stringify(completionOptions),
})
if (!response.ok) {
const error = await response.json()
throw new ApplicationError('Failed to generate completion', error)
}
// Proxy the streamed SSE response from OpenAI
return new Response(response.body, {
headers: {
    'Content-Type': 'text/event-stream',
},
})
``

## Display the answer on the frontend [\#](https://supabase.com/docs/guides/ai/examples/nextjs-vector-search\#display-the-answer-on-the-frontend)

In a last step, we need to process the event stream from the OpenAI API and print the answer to the user. The full code for this can be found on [GitHub](https://github.com/supabase-community/nextjs-openai-doc-search/blob/main/components/SearchDialog.tsx).

``
const handleConfirm = React.useCallback(
async (query: string) => {
    setAnswer(undefined)
    setQuestion(query)
    setSearch('')
    dispatchPromptData({ index: promptIndex, answer: undefined, query })
    setHasError(false)
    setIsLoading(true)
    const eventSource = new SSE(`api/vector-search`, {
      headers: {
        apikey: process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY ?? '',
        Authorization: `Bearer ${process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY}`,
        'Content-Type': 'application/json',
      },
      payload: JSON.stringify({ query }),
    })
    function handleError<T>(err: T) {
      setIsLoading(false)
      setHasError(true)
      console.error(err)
    }
    eventSource.addEventListener('error', handleError)
    eventSource.addEventListener('message', (e: any) => {
      try {
        setIsLoading(false)
        if (e.data === '[DONE]') {
          setPromptIndex((x) => {
            return x + 1
          })
          return
        }
        const completionResponse: CreateCompletionResponse = JSON.parse(e.data)
        const text = completionResponse.choices[0].text
        setAnswer((answer) => {
          const currentAnswer = answer ?? ''
          dispatchPromptData({
            index: promptIndex,
            answer: currentAnswer + text,
          })
          return (answer ?? '') + text
        })
      } catch (err) {
        handleError(err)
      }
    })
    eventSource.stream()
    eventSourceRef.current = eventSource
    setIsLoading(true)
},
[promptIndex, promptData]
)
``

## Learn more [\#](https://supabase.com/docs/guides/ai/examples/nextjs-vector-search\#learn-more)

Want to learn more about the awesome tech that is powering this?

- Read about how we built [ChatGPT for the Supabase Docs](https://supabase.com/blog/chatgpt-supabase-docs).
- Read the pgvector Docs for [Embeddings and vector similarity](https://supabase.com/docs/guides/database/extensions/pgvector)
- Watch Greg's video for a full breakdown:

ClippyGPT - How I Built Supabases OpenAI Doc Search (Embeddings) - YouTube

Rabbit Hole Syndrome

25.7K subscribers

[ClippyGPT - How I Built Supabases OpenAI Doc Search (Embeddings)](https://www.youtube.com/watch?v=Yhtjd7yGGGA)

Rabbit Hole Syndrome

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=Yhtjd7yGGGA "Watch on YouTube")

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2FxmfNUCjszh4%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Create a project](https://supabase.com/docs/guides/ai/examples/nextjs-vector-search#create-a-project) [Prepare the database](https://supabase.com/docs/guides/ai/examples/nextjs-vector-search#prepare-the-database) [Pre-process the knowledge base at build time](https://supabase.com/docs/guides/ai/examples/nextjs-vector-search#pre-process-the-knowledge-base-at-build-time) [Create text completion with OpenAI API](https://supabase.com/docs/guides/ai/examples/nextjs-vector-search#create-text-completion-with-openai-api) [Display the answer on the frontend](https://supabase.com/docs/guides/ai/examples/nextjs-vector-search#display-the-answer-on-the-frontend) [Learn more](https://supabase.com/docs/guides/ai/examples/nextjs-vector-search#learn-more)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_examples_openai.md">
AI & Vectors

# Generating OpenAI GPT3 completions

## Generate GPT text completions using OpenAI and Supabase Edge Functions.

* * *

OpenAI provides a [completions API](https://platform.openai.com/docs/api-reference/completions) that allows you to use their generative GPT models in your own applications.

OpenAI's API is intended to be used from the server-side. Supabase offers Edge Functions to make it easy to interact with third party APIs like OpenAI.

## Setup Supabase project [\#](https://supabase.com/docs/guides/ai/examples/openai\#setup-supabase-project)

If you haven't already, [install the Supabase CLI](https://supabase.com/docs/guides/cli) and initialize your project:

`
supabase init
`

## Create edge function [\#](https://supabase.com/docs/guides/ai/examples/openai\#create-edge-function)

Scaffold a new edge function called `openai` by running:

`
supabase functions new openai
`

A new edge function will now exist under `./supabase/functions/openai/index.ts`.

We'll design the function to take your user's query (via POST request) and forward it to OpenAI's API.

index.ts

`
import OpenAI from 'https://deno.land/x/openai@v4.24.0/mod.ts'
Deno.serve(async (req) => {
const { query } = await req.json()
const apiKey = Deno.env.get('OPENAI_API_KEY')
const openai = new OpenAI({
    apiKey: apiKey,
})
// Documentation here: https://github.com/openai/openai-node
const chatCompletion = await openai.chat.completions.create({
    messages: [{ role: 'user', content: query }],
    // Choose model from here: https://platform.openai.com/docs/models
    model: 'gpt-3.5-turbo',
    stream: false,
})
const reply = chatCompletion.choices[0].message.content
return new Response(reply, {
    headers: { 'Content-Type': 'text/plain' },
})
})
`

Note that we are setting `stream` to `false` which will wait until the entire response is complete before returning. If you wish to stream GPT's response word-by-word back to your client, set `stream` to `true`.

## Create OpenAI key [\#](https://supabase.com/docs/guides/ai/examples/openai\#create-openai-key)

You may have noticed we were passing `OPENAI_API_KEY` in the Authorization header to OpenAI. To generate this key, go to [https://platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys) and create a new secret key.

After getting the key, copy it into a new file called `.env.local` in your `./supabase` folder:

`
OPENAI_API_KEY=your-key-here
`

## Run locally [\#](https://supabase.com/docs/guides/ai/examples/openai\#run-locally)

Serve the edge function locally by running:

`
supabase functions serve --env-file ./supabase/.env.local --no-verify-jwt
`

Notice how we are passing in the `.env.local` file.

Use cURL or Postman to make a POST request to [http://localhost:54321/functions/v1/openai](http://localhost:54321/functions/v1/openai).

`
curl -i --location --request POST http://localhost:54321/functions/v1/openai \
  --header 'Content-Type: application/json' \
  --data '{"query":"What is Supabase?"}'
`

You should see a GPT response come back from OpenAI!

## Deploy [\#](https://supabase.com/docs/guides/ai/examples/openai\#deploy)

Deploy your function to the cloud by running:

`
supabase functions deploy --no-verify-jwt openai
supabase secrets set --env-file ./supabase/.env.local
`

## Go deeper [\#](https://supabase.com/docs/guides/ai/examples/openai\#go-deeper)

If you're interesting in learning how to use this to build your own ChatGPT, read [the blog post](https://supabase.com/blog/chatgpt-supabase-docs) and check out the video:

ClippyGPT - How I Built Supabases OpenAI Doc Search (Embeddings) - YouTube

Rabbit Hole Syndrome

25.7K subscribers

[ClippyGPT - How I Built Supabases OpenAI Doc Search (Embeddings)](https://www.youtube.com/watch?v=Yhtjd7yGGGA)

Rabbit Hole Syndrome

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=Yhtjd7yGGGA "Watch on YouTube")

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2F29p8kIqyU_Y%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Setup Supabase project](https://supabase.com/docs/guides/ai/examples/openai#setup-supabase-project) [Create edge function](https://supabase.com/docs/guides/ai/examples/openai#create-edge-function) [Create OpenAI key](https://supabase.com/docs/guides/ai/examples/openai#create-openai-key) [Run locally](https://supabase.com/docs/guides/ai/examples/openai#run-locally) [Deploy](https://supabase.com/docs/guides/ai/examples/openai#deploy) [Go deeper](https://supabase.com/docs/guides/ai/examples/openai#go-deeper)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_examples_semantic_image_search_amazon_titan.md">
AI & Vectors

# Semantic Image Search with Amazon Titan

## Implement semantic image search with Amazon Titan and Supabase Vector in Python.

* * *

[Amazon Bedrock](https://aws.amazon.com/bedrock) is a fully managed service that offers a choice of high-performing foundation models (FMs) from leading AI companies like AI21 Labs, Anthropic, Cohere, Meta, Mistral AI, Stability AI, and Amazon. Each model is accessible through a common API which implements a broad set of features to help build generative AI applications with security, privacy, and responsible AI in mind.

[Amazon Titan](https://aws.amazon.com/bedrock/titan/) is a family of foundation models (FMs) for text and image generation, summarization, classification, open-ended Q&A, information extraction, and text or image search.

In this guide we'll look at how we can get started with Amazon Bedrock and Supabase Vector in Python using the Amazon Titan multimodal model and the [vecs client](https://supabase.com/docs/guides/ai/vecs-python-client).

You can find the full application code as a Python Poetry project on [GitHub](https://github.com/supabase/supabase/tree/master/examples/ai/aws_bedrock_image_search).

## Create a new Python project with Poetry [\#](https://supabase.com/docs/guides/ai/examples/semantic-image-search-amazon-titan\#create-a-new-python-project-with-poetry)

[Poetry](https://python-poetry.org/) provides packaging and dependency management for Python. If you haven't already, install poetry via pip:

`
pip install poetry
`

Then initialize a new project:

`
poetry new aws_bedrock_image_search
`

## Spin up a Postgres database with pgvector [\#](https://supabase.com/docs/guides/ai/examples/semantic-image-search-amazon-titan\#spin-up-a-postgres-database-with-pgvector)

If you haven't already, head over to [database.new](https://database.new/) and create a new project. Every Supabase project comes with a full Postgres database and the [pgvector extension](https://supabase.com/docs/guides/database/extensions/pgvector) preconfigured.

When creating your project, make sure to note down your database password as you will need it to construct the `DB_URL` in the next step.

You can find the database connection string in your Supabase Dashboard [database settings](https://supabase.com/dashboard/project/_/settings/database). Select "Use connection pooling" with `Mode: Session` for a direct connection to your Postgres database. It will look something like this:

`
postgresql://postgres.[PROJECT-REF]:[YOUR-PASSWORD]@aws-0-[REGION].pooler.supabase.com:5432/postgres
`

## Install the dependencies [\#](https://supabase.com/docs/guides/ai/examples/semantic-image-search-amazon-titan\#install-the-dependencies)

We will need to add the following dependencies to our project:

- [`vecs`](https://github.com/supabase/vecs#vecs): Supabase Vector Python Client.
- [`boto3`](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html): AWS SDK for Python.
- [`matplotlib`](https://matplotlib.org/): for displaying our image result.

`
poetry add vecs boto3 matplotlib
`

## Import the necessary dependencies [\#](https://supabase.com/docs/guides/ai/examples/semantic-image-search-amazon-titan\#import-the-necessary-dependencies)

At the top of your main python script, import the dependencies and store your `DB URL` from above in a variable:

`
import sys
import boto3
import vecs
import json
import base64
from matplotlib import pyplot as plt
from matplotlib import image as mpimg
from typing import Optional
DB_CONNECTION = "postgresql://postgres.[PROJECT-REF]:[YOUR-PASSWORD]@aws-0-[REGION].pooler.supabase.com:5432/postgres"
`

Next, get the [credentials to your AWS account](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html) and instantiate the `boto3` client:

`
bedrock_client = boto3.client(
    'bedrock-runtime',
    region_name='us-west-2',
    # Credentials from your AWS account
    aws_access_key_id='<replace_your_own_credentials>',
    aws_secret_access_key='<replace_your_own_credentials>',
    aws_session_token='<replace_your_own_credentials>',
)
`

## Create embeddings for your images [\#](https://supabase.com/docs/guides/ai/examples/semantic-image-search-amazon-titan\#create-embeddings-for-your-images)

In the root of your project, create a new folder called `images` and add some images. You can use the images from the example project on [GitHub](https://github.com/supabase/supabase/tree/master/examples/ai/aws_bedrock_image_search/images) or you can find license free images on [Unsplash](https://unsplash.com/).

To send images to the Amazon Bedrock API we need to need to encode them as `base64` strings. Create the following helper methods:

`
def readFileAsBase64(file_path):
    """Encode image as base64 string."""
    try:
        with open(file_path, "rb") as image_file:
            input_image = base64.b64encode(image_file.read()).decode("utf8")
        return input_image
    except:
        print("bad file name")
        sys.exit(0)
def construct_bedrock_image_body(base64_string):
    """Construct the request body.
    https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-titan-embed-mm.html
    """
    return json.dumps(
        {
            "inputImage": base64_string,
            "embeddingConfig": {"outputEmbeddingLength": 1024},
        }
    )
def get_embedding_from_titan_multimodal(body):
    """Invoke the Amazon Titan Model via API request."""
    response = bedrock_client.invoke_model(
        body=body,
        modelId="amazon.titan-embed-image-v1",
        accept="application/json",
        contentType="application/json",
    )
    response_body = json.loads(response.get("body").read())
    print(response_body)
    return response_body["embedding"]
def encode_image(file_path):
    """Generate embedding for the image at file_path."""
    base64_string = readFileAsBase64(file_path)
    body = construct_bedrock_image_body(base64_string)
    emb = get_embedding_from_titan_multimodal(body)
    return emb
`

Next, create a `seed` method, which will create a new Supabase Vector Collection, generate embeddings for your images, and upsert the embeddings into your database:

`
def seed():
    # create vector store client
    vx = vecs.create_client(DB_CONNECTION)
    # get or create a collection of vectors with 1024 dimensions
    images = vx.get_or_create_collection(name="image_vectors", dimension=1024)
    # Generate image embeddings with Amazon Titan Model
    img_emb1 = encode_image('./images/one.jpg')
    img_emb2 = encode_image('./images/two.jpg')
    img_emb3 = encode_image('./images/three.jpg')
    img_emb4 = encode_image('./images/four.jpg')
    # add records to the *images* collection
    images.upsert(
        records=[\
            (\
                "one.jpg",       # the vector's identifier\
                img_emb1,        # the vector. list or np.array\
                {"type": "jpg"}  # associated  metadata\
            ), (\
                "two.jpg",\
                img_emb2,\
                {"type": "jpg"}\
            ), (\
                "three.jpg",\
                img_emb3,\
                {"type": "jpg"}\
            ), (\
                "four.jpg",\
                img_emb4,\
                {"type": "jpg"}\
            )\
        ]
    )
    print("Inserted images")
    # index the collection for fast search performance
    images.create_index()
    print("Created index")
`

Add this method as a script in your `pyproject.toml` file:

`
[tool.poetry.scripts]
seed = "image_search.main:seed"
search = "image_search.main:search"
`

After activating the virtual environment with `poetry shell` you can now run your seed script via `poetry run seed`. You can inspect the generated embeddings in your Supabase Dashboard by visiting the [Table Editor](https://supabase.com/dashboard/project/_/editor), selecting the `vecs` schema, and the `image_vectors` table.

## Perform an image search from a text query [\#](https://supabase.com/docs/guides/ai/examples/semantic-image-search-amazon-titan\#perform-an-image-search-from-a-text-query)

We can use Supabase Vector to query our embeddings. We can either use an image as the search input or generate an embedding from a string input:

`
def search(query_term: Optional[str] = None):
    if query_term is None:
        query_term = sys.argv[1]
    # create vector store client
    vx = vecs.create_client(DB_CONNECTION)
    images = vx.get_or_create_collection(name="image_vectors", dimension=1024)
    # Encode text query
    text_emb = get_embedding_from_titan_multimodal(json.dumps(
        {
            "inputText": query_term,
            "embeddingConfig": {"outputEmbeddingLength": 1024},
        }
    ))
    # query the collection filtering metadata for "type" = "jpg"
    results = images.query(
        data=text_emb,                      # required
        limit=1,                            # number of records to return
        filters={"type": {"$eq": "jpg"}},   # metadata filters
    )
    result = results[0]
    print(result)
    plt.title(result)
    image = mpimg.imread('./images/' + result)
    plt.imshow(image)
    plt.show()
`

By limiting the query to one result, we can show the most relevant image to the user. Finally we use `matplotlib` to show the image result to the user.

Go ahead and test it out by running `poetry run search` and you will be presented with an image of a "bike in front of a red brick wall".

## Conclusion [\#](https://supabase.com/docs/guides/ai/examples/semantic-image-search-amazon-titan\#conclusion)

With just a couple of lines of Python you are able to implement image search as well as reverse image search using the Amazon Titan multimodal model and Supabase Vector.

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2FA3uND5sgiO0%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Create a new Python project with Poetry](https://supabase.com/docs/guides/ai/examples/semantic-image-search-amazon-titan#create-a-new-python-project-with-poetry) [Spin up a Postgres database with pgvector](https://supabase.com/docs/guides/ai/examples/semantic-image-search-amazon-titan#spin-up-a-postgres-database-with-pgvector) [Install the dependencies](https://supabase.com/docs/guides/ai/examples/semantic-image-search-amazon-titan#install-the-dependencies) [Import the necessary dependencies](https://supabase.com/docs/guides/ai/examples/semantic-image-search-amazon-titan#import-the-necessary-dependencies) [Create embeddings for your images](https://supabase.com/docs/guides/ai/examples/semantic-image-search-amazon-titan#create-embeddings-for-your-images) [Perform an image search from a text query](https://supabase.com/docs/guides/ai/examples/semantic-image-search-amazon-titan#perform-an-image-search-from-a-text-query) [Conclusion](https://supabase.com/docs/guides/ai/examples/semantic-image-search-amazon-titan#conclusion)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_going_to_prod.md">
AI & Vectors

# Going to Production

## Going to production checklist for AI applications.

* * *

This guide will help you to prepare your application for production. We'll provide actionable steps to help you scale your application, ensure that it is reliable, can handle the load, and provide optimal accuracy for your use case.

See our [Engineering for Scale](https://supabase.com/docs/guides/ai/engineering-for-scale) guide for more information about engineering at scale.

## Do you need indexes? [\#](https://supabase.com/docs/guides/ai/going-to-prod\#do-you-need-indexes)

Sequential scans will result in significantly higher latencies and lower throughput, guaranteeing 100% accuracy and not being RAM bound.

There are a couple of cases where you might not need indexes:

- You have a small dataset and don't need to scale it.
- You are not expecting high amounts of vector search queries per second.
- You need to guarantee 100% accuracy.

You don't have to create indexes in these cases and can use sequential scans instead. This type of workload will not be RAM bound and will not require any additional resources but will result in higher latencies and lower throughput. Extra CPU cores may help to improve queries per second, but it will not help to improve latency.

On the other hand, if you need to scale your application, you will need to [create indexes](https://supabase.com/docs/guides/ai/vector-indexes). This will result in lower latencies and higher throughput, but will require additional RAM to make use of Postgres Caching. Also, using indexes will result in lower accuracy, since you are replacing exact (KNN) search with approximate (ANN) search.

## HNSW vs IVFFlat indexes [\#](https://supabase.com/docs/guides/ai/going-to-prod\#hnsw-vs-ivfflat-indexes)

`pgvector` supports two types of indexes: HNSW and IVFFlat. We recommend using [HNSW](https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes) because of its [performance](https://supabase.com/blog/increase-performance-pgvector-hnsw#hnsw-performance-1536-dimensions) and [robustness against changing data](https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes#when-should-you-create-hnsw-indexes).

![dbpedia embeddings comparing ivfflat and hnsw queries-per-second using the 4XL compute add-on](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fai%2Fgoing-prod%2Fdbpedia-ivfflat-vs-hnsw-4xl--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

## HNSW, understanding `ef_construction`, `ef_search`, and `m` [\#](https://supabase.com/docs/guides/ai/going-to-prod\#hnsw-understanding-efconstruction--efsearch--and-m)

Index build parameters:

- `m` is the number of bi-directional links created for every new element during construction. Higher `m` is suitable for datasets with high dimensionality and/or high accuracy requirements. Reasonable values for `m` are between 2 and 100. Range 12-48 is a good starting point for most use cases (16 is the default value).

- `ef_construction` is the size of the dynamic list for the nearest neighbors (used during the construction algorithm). Higher `ef_construction` will result in better index quality and higher accuracy, but it will also increase the time required to build the index. `ef_construction` has to be at least 2 \* `m` (64 is the default value). At some point, increasing `ef_construction` does not improve the quality of the index. You can measure accuracy when `ef_search` = `ef_construction`: if accuracy is lower than 0.9, then there is room for improvement.


Search parameters:

- `ef_search` is the size of the dynamic list for the nearest neighbors (used during the search). Increasing `ef_search` will result in better accuracy, but it will also increase the time required to execute a query (40 is the default value).

![dbpedia embeddings comparing hnsw queries-per-second using different build parameters](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fai%2Fgoing-prod%2Fdbpedia-hnsw-build-parameters--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

## IVFFlat, understanding `probes` and `lists` [\#](https://supabase.com/docs/guides/ai/going-to-prod\#ivfflat-understanding-probes-and-lists)

Indexes used for approximate vector similarity search in pgvector divides a dataset into partitions. The number of these partitions is defined by the `lists` constant. The `probes` controls how many lists are going to be searched during a query.

The values of lists and probes directly affect accuracy and queries per second (QPS).

- Higher `lists` means an index will be built slower, but you can achieve better QPS and accuracy.
- Higher `probes` means that select queries will be slower, but you can achieve better accuracy.
- `lists` and `probes` are not independent. Higher `lists` means that you will have to use higher `probes` to achieve the same accuracy.

You can find more examples of how `lists` and `probes` constants affect accuracy and QPS in [pgvector 0.4.0 performance](https://supabase.com/blog/pgvector-performance) blogpost.

![multi database](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fai%2Fgoing-prod%2Flists-count--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

## Performance tips when using indexes [\#](https://supabase.com/docs/guides/ai/going-to-prod\#performance-tips-when-using-indexes)

First, a few generic tips which you can pick and choose from:

1. The Supabase managed platform will automatically optimize Postgres configs for you based on your compute add-on. But if you self-host, consider **adjusting your Postgres config** based on RAM & CPU cores. See [example optimizations](https://gist.github.com/egor-romanov/323e2847851bbd758081511785573c08) for more details.
2. Prefer `inner-product` to `L2` or `Cosine` distances if your vectors are normalized (like `text-embedding-ada-002`). If embeddings are not normalized, `Cosine` distance should give the best results with an index.
3. **Pre-warm your database.** Implement the warm-up technique before transitioning to production or running benchmarks.
   - Use [pg\_prewarm](https://www.postgresql.org/docs/current/pgprewarm.html) to load the index into RAM `select pg_prewarm('vecs.docs_vec_idx');`. This will help to avoid cold cache issues.
   - Execute 10,000 to 50,000 "warm-up" queries before each benchmark/prod. This will help to utilize cache and buffers more efficiently.
4. **Establish your workload.** Fine-tune `m` and `ef_construction` or `lists` constants for the pgvector index to accelerate your queries (at the expense of a slower build times). For instance, for benchmarks with 1,000,000 OpenAI embeddings, we set `m` and `ef_construction` to 32 and 80, and it resulted in 35% higher QPS than 24 and 56 values respectively.
5. **Benchmark your own specific workloads.** Doing this during cache warm-up helps gauge the best value for the index build parameters, balancing accuracy with queries per second (QPS).

## Going into production [\#](https://supabase.com/docs/guides/ai/going-to-prod\#going-into-production)

1. Decide if you are going to use indexes or not. You can skip the rest of this guide if you do not use indexes.
2. Over-provision RAM during preparation. You can scale down in step `5`, but it's better to start with a larger size to get the best results for RAM requirements. (We'd recommend at least 8XL if you're using Supabase.)
3. Upload your data to the database. If you use the [`vecs`](https://supabase.com/docs/guides/ai/python/api) library, it will automatically generate an index with default parameters.
4. Run a benchmark using randomly generated queries and observe the results. Again, you can use the `vecs` library with the `ann-benchmarks` tool. Do it with default values for index build parameters, you can later adjust them to get the best results.
5. Monitor the RAM usage, and save it as a note for yourself. You would likely want to use a compute add-on in the future that has the same amount of RAM that was used at the moment (both actual RAM usage and RAM used for cache and buffers).
6. Scale down your compute add-on to the one that would have the same amount of RAM used at the moment.
7. Repeat step 3 to load the data into RAM. You should see QPS increase on subsequent runs, and stop when it no longer increases.
8. Run a benchmark using real queries and observe the results. You can use the `vecs` library for that as well with `ann-benchmarks` tool. Tweak `ef_search` for HNSW or `probes` for IVFFlat until you see that both accuracy and QPS match your requirements.
9. If you want higher QPS you can increase `m` and `ef_construction` for HNSW or `lists` for IVFFlat parameters (consider switching from IVF to HNSW). You have to rebuild the index with a higher `m` and `ef_construction` values and repeat steps 6-7 to find the best combination of `m`, `ef_construction` and `ef_search` constants to achieve the best QPS and accuracy values. Higher `m`, `ef_construction` mean that index will build slower, but you can achieve better QPS and accuracy. Higher `ef_search` mean that select queries will be slower, but you can achieve better accuracy.

## Useful links [\#](https://supabase.com/docs/guides/ai/going-to-prod\#useful-links)

Don't forget to check out the general [Production Checklist](https://supabase.com/docs/guides/platform/going-into-prod) to ensure your project is secure, performant, and will remain available for your users.

You can look at our [Choosing Compute Add-on](https://supabase.com/docs/guides/ai/choosing-compute-addon) guide to get a basic understanding of how much compute you might need for your workload.

Or take a look at our [pgvector 0.5.0 performance](https://supabase.com/blog/increase-performance-pgvector-hnsw) and [pgvector 0.4.0 performance](https://supabase.com/blog/pgvector-performance) blog posts to see what pgvector is capable of and how the above technique can be used to achieve the best results.

![multi database](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fai%2Fgoing-prod%2Fsize-to-rps--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Do you need indexes?](https://supabase.com/docs/guides/ai/going-to-prod#do-you-need-indexes) [HNSW vs IVFFlat indexes](https://supabase.com/docs/guides/ai/going-to-prod#hnsw-vs-ivfflat-indexes) [HNSW, understanding ef\_construction, ef\_search, and m](https://supabase.com/docs/guides/ai/going-to-prod#hnsw-understanding-efconstruction--efsearch--and-m) [IVFFlat, understanding probes and lists](https://supabase.com/docs/guides/ai/going-to-prod#ivfflat-understanding-probes-and-lists) [Performance tips when using indexes](https://supabase.com/docs/guides/ai/going-to-prod#performance-tips-when-using-indexes) [Going into production](https://supabase.com/docs/guides/ai/going-to-prod#going-into-production) [Useful links](https://supabase.com/docs/guides/ai/going-to-prod#useful-links)

![dbpedia embeddings comparing ivfflat and hnsw queries-per-second using the 4XL compute add-on](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fai%2Fgoing-prod%2Fdbpedia-ivfflat-vs-hnsw-4xl--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![multi database](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fai%2Fgoing-prod%2Flists-count--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![multi database](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fai%2Fgoing-prod%2Fsize-to-rps--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![dbpedia embeddings comparing hnsw queries-per-second using different build parameters](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fai%2Fgoing-prod%2Fdbpedia-hnsw-build-parameters--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_google_colab.md">
AI & Vectors

# Google Colab

## Use Google Colab to manage your Supabase Vector store.

* * *

[![](https://supabase.com/docs/img/ai/colab-badge.svg)](https://colab.research.google.com/github/supabase/supabase/blob/master/examples/ai/vector_hello_world.ipynb)

Google Colab is a hosted Jupyter Notebook service. It provides free access to computing resources, including GPUs and TPUs, and is well-suited to machine learning, data science, and education. We can use Colab to manage collections using [Supabase Vecs](https://supabase.com/docs/guides/ai/vecs-python-client).

In this tutorial we'll connect to a database running on the Supabase [platform](https://supabase.com/dashboard/). If you don't already have a database, you can create one here: [database.new](https://database.new/).

## Create a new notebook [\#](https://supabase.com/docs/guides/ai/google-colab\#create-a-new-notebook)

Start by visiting [colab.research.google.com](https://colab.research.google.com/). There you can create a new notebook.

![Google Colab new notebook](https://supabase.com/docs/img/ai/google-colab/colab-new.png)

## Install Vecs [\#](https://supabase.com/docs/guides/ai/google-colab\#install-vecs)

We'll use the Supabase Vector client, [Vecs](https://supabase.com/docs/guides/ai/vecs-python-client), to manage our collections.

At the top of the notebook add the notebook paste the following code and hit the "execute" button ( `ctrl+enter`):

`
pip install vecs
`

![Install vecs](https://supabase.com/docs/img/ai/google-colab/install-vecs.png)

## Connect to your database [\#](https://supabase.com/docs/guides/ai/google-colab\#connect-to-your-database)

Find the Postgres pooler connection string for your Supabase project in the [database settings](https://supabase.com/dashboard/project/_/settings/database) of the dashboard. Copy the "URI" format, which should look something like `postgres://postgres.xxxx:password@xxxx.pooler.supabase.com:6543/postgres`

Create a new code block below the install block ( `ctrl+m b`) and add the following code using the Postgres URI you copied above:

`
import vecs
DB_CONNECTION = "postgres://postgres.xxxx:password@xxxx.pooler.supabase.com:6543/postgres"
# create vector store client
vx = vecs.create_client(DB_CONNECTION)
`

Execute the code block ( `ctrl+enter`). If no errors were returned then your connection was successful.

## Create a collection [\#](https://supabase.com/docs/guides/ai/google-colab\#create-a-collection)

Now we're going to create a new collection and insert some documents.

Create a new code block below the install block ( `ctrl+m b`). Add the following code to the code block and execute it ( `ctrl+enter`):

`
collection = vx.get_or_create_collection(name="colab_collection", dimension=3)
collection.upsert(
    vectors=[\
        (\
         "vec0",           # the vector's identifier\
         [0.1, 0.2, 0.3],  # the vector. list or np.array\
         {"year": 1973}    # associated  metadata\
        ),\
        (\
         "vec1",\
         [0.7, 0.8, 0.9],\
         {"year": 2012}\
        )\
    ]
)
`

This will create a table inside your database within the `vecs` schema, called `colab_collection`. You can view the inserted items in the [Table Editor](https://supabase.com/dashboard/project/_/editor/), by selecting the `vecs` schema from the schema dropdown.

![Colab documents](https://supabase.com/docs/img/ai/google-colab/colab-documents.png)

## Query your documents [\#](https://supabase.com/docs/guides/ai/google-colab\#query-your-documents)

Now we can search for documents based on their similarity. Create a new code block and execute the following code:

`
collection.query(
    query_vector=[0.4,0.5,0.6],  # required
    limit=5,                     # number of records to return
    filters={},                  # metadata filters
    measure="cosine_distance",   # distance measure to use
    include_value=False,         # should distance measure values be returned?
    include_metadata=False,      # should record metadata be returned?
)
`

You will see that this returns two documents in an array `['vec1', 'vec0']`:

![Colab results](https://supabase.com/docs/img/ai/google-colab/colab-results.png)

It also returns a warning:

`
Query does not have a covering index for cosine_distance.
`

You can lean more about creating indexes in the [Vecs documentation](https://supabase.github.io/vecs/api/#create-an-index).

## Resources [\#](https://supabase.com/docs/guides/ai/google-colab\#resources)

- Vecs API: [supabase.github.io/vecs/api](https://supabase.github.io/vecs/api)

### Is this helpful?

NoYes

### On this page

[Create a new notebook](https://supabase.com/docs/guides/ai/google-colab#create-a-new-notebook) [Install Vecs](https://supabase.com/docs/guides/ai/google-colab#install-vecs) [Connect to your database](https://supabase.com/docs/guides/ai/google-colab#connect-to-your-database) [Create a collection](https://supabase.com/docs/guides/ai/google-colab#create-a-collection) [Query your documents](https://supabase.com/docs/guides/ai/google-colab#query-your-documents) [Resources](https://supabase.com/docs/guides/ai/google-colab#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_hugging_face.md">
AI & Vectors

# Hugging Face Inference API

* * *

[Hugging Face](https://huggingface.co/) is an open source hub for AI/ML models and tools. With over 100,000 machine learning models available, Hugging Face provides a great way to integrate specialized AI & ML tasks into your application.

There are 3 ways to use Hugging Face models in your application:

1. Use the [Transformers](https://huggingface.co/docs/transformers/index) Python library to perform inference in a Python backend.
2. [Generate embeddings](https://supabase.com/docs/guides/ai/quickstarts/generate-text-embeddings) directly in Edge Functions using Transformers.js.
3. Use Hugging Face's hosted [Inference API](https://huggingface.co/inference-api) to execute AI tasks remotely on Hugging Face servers. This guide will walk you through this approach.

## AI tasks [\#](https://supabase.com/docs/guides/ai/hugging-face\#ai-tasks)

Below are some of the types of tasks you can perform with Hugging Face:

### Natural language [\#](https://supabase.com/docs/guides/ai/hugging-face\#natural-language)

- [Summarization](https://huggingface.co/tasks/summarization)
- [Text classification](https://huggingface.co/tasks/text-classification)
- [Text generation](https://huggingface.co/tasks/text-generation)
- [Translation](https://huggingface.co/tasks/translation)
- [Fill in the blank](https://huggingface.co/tasks/fill-mask)

### Computer vision [\#](https://supabase.com/docs/guides/ai/hugging-face\#computer-vision)

- [Image to text](https://huggingface.co/tasks/image-to-text)
- [Text to image](https://huggingface.co/tasks/text-to-image)
- [Image classification](https://huggingface.co/tasks/image-classification)
- [Video classification](https://huggingface.co/tasks/video-classification)
- [Object detection](https://huggingface.co/tasks/object-detection)
- [Image segmentation](https://huggingface.co/tasks/image-segmentation)

### Audio [\#](https://supabase.com/docs/guides/ai/hugging-face\#audio)

- [Text to speech](https://huggingface.co/tasks/text-to-speech)
- [Speech to text](https://huggingface.co/tasks/automatic-speech-recognition)
- [Audio classification](https://huggingface.co/tasks/audio-classification)

See a [full list of tasks](https://huggingface.co/tasks).

## Access token [\#](https://supabase.com/docs/guides/ai/hugging-face\#access-token)

First generate a Hugging Face access token for your app:

[https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)

Name your token based on the app its being used for and the environment. For example, if you are building an image generation app you might create 2 tokens:

- "Image Generator (Dev)"
- "Image Generator (Prod)"

Since we will be using this token for the inference API, choose the `read` role.

Though it is possible to use the Hugging Face inference API today without an access token, [you may be rate limited](https://huggingface.co/docs/huggingface.js/inference/README#usage).

To ensure you don't experience any unexpected downtime or errors, we recommend creating an access token.

## Edge Functions [\#](https://supabase.com/docs/guides/ai/hugging-face\#edge-functions)

Edge Functions are server-side TypeScript functions that run on-demand. Since Edge Functions run on a server, you can safely give them access to your Hugging Face access token.

You will need the `supabase` CLI [installed](https://supabase.com/docs/guides/cli) for the following commands to work.

To create a new Edge Function, navigate to your local project and initialize Supabase if you haven't already:

`
supabase init
`

Then create an Edge Function:

`
supabase functions new text-to-image
`

Create a file called `.env.local` to store your Hugging Face access token:

`
HUGGING_FACE_ACCESS_TOKEN=<your-token-here>
`

Let's modify the Edge Function to import Hugging Face's inference client and perform a `text-to-image` request:

`
import { serve } from 'https://deno.land/std@0.168.0/http/server.ts'
import { HfInference } from 'https://esm.sh/@huggingface/inference@2.3.2'
const hf = new HfInference(Deno.env.get('HUGGING_FACE_ACCESS_TOKEN'))
serve(async (req) => {
const { prompt } = await req.json()
const image = await hf.textToImage(
    {
      inputs: prompt,
      model: 'stabilityai/stable-diffusion-2',
    },
    {
      use_cache: false,
    }
)
return new Response(image)
})
`

1. This function creates a new instance of `HfInference` using the `HUGGING_FACE_ACCESS_TOKEN` environment variable.

2. It expects a POST request that includes a JSON request body. The JSON body should include a parameter called `prompt` that represents the text-to-image prompt that we will pass to Hugging Face's inference API.

3. Next we call `textToImage()`, passing in the user's prompt along with the model that we would like to use for the image generation. Today Hugging Face recommends `stabilityai/stable-diffusion-2`, but you can change this to any other text-to-image model. You can see a list of which models are supported for each task by navigating to their [models page](https://huggingface.co/models?pipeline_tag=text-to-image) and filtering by task.

4. We set `use_cache` to `false` so that repeat queries with the same prompt will produce new images. If the task and model you are using is deterministic (will always produce the same result based on the same input), consider setting `use_cache` to `true` for faster responses.

5. The `image` result returned from the API will be a `Blob`. We can pass the `Blob` directly into a `new Response()` which will automatically set the content type and body of the response from the `image`.


Finally let's serve the Edge Function locally to test it:

`
supabase functions serve --env-file .env.local --no-verify-jwt
`

Remember to pass in the `.env.local` file using the `--env-file` parameter so that the Edge Function can access the `HUGGING_FACE_ACCESS_TOKEN`.

For demo purposes we set `--no-verify-jwt` to make it easy to test the Edge Function without passing in a JWT token. In a real application you will need to pass the JWT as a `Bearer` token in the `Authorization` header.

At this point, you can make an API request to your Edge Function using your preferred frontend framework (Next.js, React, Expo, etc). We can also test from the terminal using `curl`:

`
curl --output result.jpg --location --request POST 'http://localhost:54321/functions/v1/text-to-image' \
  --header 'Content-Type: application/json' \
  --data '{"prompt":"Llama wearing sunglasses"}'
`

In this example, your generated image will save to `result.jpg`:

![Llama wearing sunglasses example](https://supabase.com/docs/img/ai/hugging-face/llama-sunglasses-example.png)

## Next steps [\#](https://supabase.com/docs/guides/ai/hugging-face\#next-steps)

You can now create an Edge Function that invokes a Hugging Face task using your model of choice.

Try running some other [AI tasks](https://supabase.com/docs/guides/ai/hugging-face#ai-tasks).

## Resources [\#](https://supabase.com/docs/guides/ai/hugging-face\#resources)

- Official [Hugging Face site](https://huggingface.co/).
- Official [Hugging Face JS docs](https://huggingface.co/docs/huggingface.js).
- [Generate image captions](https://supabase.com/docs/guides/ai/examples/huggingface-image-captioning) using Hugging Face.

### Is this helpful?

NoYes

### On this page

[AI tasks](https://supabase.com/docs/guides/ai/hugging-face#ai-tasks) [Natural language](https://supabase.com/docs/guides/ai/hugging-face#natural-language) [Computer vision](https://supabase.com/docs/guides/ai/hugging-face#computer-vision) [Audio](https://supabase.com/docs/guides/ai/hugging-face#audio) [Access token](https://supabase.com/docs/guides/ai/hugging-face#access-token) [Edge Functions](https://supabase.com/docs/guides/ai/hugging-face#edge-functions) [Next steps](https://supabase.com/docs/guides/ai/hugging-face#next-steps) [Resources](https://supabase.com/docs/guides/ai/hugging-face#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_hybrid_search.md">
AI & Vectors

# Hybrid search

## Combine keyword search with semantic search.

* * *

Hybrid search combines [full text search](https://supabase.com/docs/guides/ai/keyword-search) (searching by keyword) with [semantic search](https://supabase.com/docs/guides/ai/semantic-search) (searching by meaning) to identify results that are both directly and contextually relevant to the user's query.

## Use cases for hybrid search [\#](https://supabase.com/docs/guides/ai/hybrid-search\#use-cases-for-hybrid-search)

Sometimes a single search method doesn't quite capture what a user is really looking for. For example, if a user searches for "Italian recipes with tomato sauce" on a cooking app, a keyword search would pull up recipes that specifically mention "Italian," "recipes," and "tomato sauce" in the text. However, it might miss out on dishes that are quintessentially Italian and use tomato sauce but don't explicitly label themselves with these words, or use variations like "pasta sauce" or "marinara." On the other hand, a semantic search might understand the culinary context and find recipes that match the intent, such as a traditional "Spaghetti Marinara," even if they don't match the exact keyword phrase. However, it could also suggest recipes that are contextually related but not what the user is looking for, like a "Mexican salsa" recipe, because it understands the context to be broadly about tomato-based sauces.

Hybrid search combines the strengths of both these methods. It would ensure that recipes explicitly mentioning the keywords are prioritized, thus capturing direct hits that satisfy the keyword criteria. At the same time, it would include recipes identified through semantic understanding as being related in meaning or context, like different Italian dishes that traditionally use tomato sauce but might not have been tagged explicitly with the user's search terms. It identifies results that are both directly and contextually relevant to the user's query while ideally minimizing misses and irrelevant suggestions.

## When to consider hybrid search [\#](https://supabase.com/docs/guides/ai/hybrid-search\#when-to-consider-hybrid-search)

The decision to use hybrid search depends on what your users are looking for in your app. For a code repository where developers need to find exact lines of code or error messages, keyword search is likely ideal because it matches specific terms. In a mental health forum where users search for advice or experiences related to their feelings, semantic search may be better because it finds results based on the meaning of a query, not just specific words. For a shopping app where customers might search for specific product names yet also be open to related suggestions, hybrid search combines the best of both worlds - finding exact matches while also uncovering similar products based on the shopping context.

## How to combine search methods [\#](https://supabase.com/docs/guides/ai/hybrid-search\#how-to-combine-search-methods)

Hybrid search merges keyword search and semantic search, but how does this process work?

First, each search method is executed separately. Keyword search, which involves searching by specific words or phrases present in the content, will yield its own set of results. Similarly, semantic search, which involves understanding the context or meaning behind the search query rather than the specific words used, will generate its own unique results.

Now with these separate result lists available, the next step is to combine them into a single, unified list. This is achieved through a process known as fusion. Fusion takes the results from both search methods and merges them together based on a certain ranking or scoring system. This system may prioritize certain results based on factors like their relevance to the search query, their ranking in the individual lists, or other criteria. The result is a final list that integrates the strengths of both keyword and semantic search methods.

## Reciprocal Ranked Fusion (RRF) [\#](https://supabase.com/docs/guides/ai/hybrid-search\#reciprocal-ranked-fusion-rrf)

One of the most common fusion methods is Reciprocal Ranked Fusion (RRF). The key idea behind RRF is to give more weight to the top-ranked items in each individual result list when building the final combined list.

In RRF, we iterate over each record and assign a score (noting that each record could exist in one or both lists). The score is calculated as 1 divided by that record's rank in each list, summed together between both lists. For example, if a record with an ID of `123` was ranked third in the keyword search and ninth in semantic search, it would receive a score of 13+19=0.444\\dfrac{1}{3} + \\dfrac{1}{9} = 0.44431+91=0.444. If the record was found in only one list and not the other, it would receive a score of 0 for the other list. The records are then sorted by this score to create the final list. The items with the highest scores are ranked first, and lowest scores ranked last.

This method ensures that items that are ranked high in multiple lists are given a high rank in the final list. It also ensures that items that are ranked high in only a few lists but low in others are not given a high rank in the final list. Placing the rank in the denominator when calculating score helps penalize the low ranking records.

### Smoothing constant `k` [\#](https://supabase.com/docs/guides/ai/hybrid-search\#smoothing-constant-k)

To prevent extremely high scores for items that are ranked first (since we're dividing by the rank), a `k` constant is often added to the denominator to smooth the score:

1k+rank\\dfrac{1}{k+rank}k+rank1

This constant can be any positive number, but is typically small. A constant of 1 would mean that a record ranked first would have a score of 11+1=0.5\\dfrac{1}{1+1} = 0.51+11=0.5 instead of 111. This adjustment can help balance the influence of items that are ranked very high in individual lists when creating the final combined list.

## Hybrid search in Postgres [\#](https://supabase.com/docs/guides/ai/hybrid-search\#hybrid-search-in-postgres)

Let's implement hybrid search in Postgres using `tsvector` (keyword search) and `pgvector` (semantic search).

First we'll create a `documents` table to store the documents that we will search over. This is just an example - adjust this to match the structure of your application.

`
create table documents (
id bigint primary key generated always as identity,
content text,
fts tsvector generated always as (to_tsvector('english', content)) stored,
embedding vector(512)
);
`

The table contains 4 columns:

- `id` is an auto-generated unique ID for the record. We'll use this later to match records when performing RRF.
- `content` contains the actual text we will be searching over.
- `fts` is an auto-generated `tsvector` column that is generated using the text in `content`. We will use this for [full text search](https://supabase.com/docs/guides/database/full-text-search) (search by keyword).
- `embedding` is a [vector column](https://supabase.com/docs/guides/ai/vector-columns) that stores the vector generated from our embedding model. We will use this for [semantic search](https://supabase.com/docs/guides/ai/semantic-search) (search by meaning). We chose 512 dimensions for this example, but adjust this to match the size of the embedding vectors generated from your preferred model.

Next we'll create indexes on the `fts` and `embedding` columns so that their individual queries will remain fast at scale:

`
-- Create an index for the full-text search
create index on documents using gin(fts);
-- Create an index for the semantic vector search
create index on documents using hnsw (embedding vector_ip_ops);
`

For full text search we use a [generalized inverted (GIN) index](https://www.postgresql.org/docs/current/gin-intro.html) which is designed for handling composite values like those stored in a `tsvector`.

For semantic vector search we use an [HNSW index](https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes), which is a high performing approximate nearest neighbor (ANN) search algorithm. Note that we are using the `vector_ip_ops` (inner product) operator with this index because we plan on using the inner product ( `<#>`) operator later in our query. If you plan to use a different operator like cosine distance ( `<=>`), be sure to update the index accordingly. For more information, see [distance operators](https://supabase.com/docs/guides/ai/vector-indexes#distance-operators).

Finally we'll create our `hybrid_search` function:

`
create or replace function hybrid_search(
query_text text,
query_embedding vector(512),
match_count int,
full_text_weight float = 1,
semantic_weight float = 1,
rrf_k int = 50
)
returns setof documents
language sql
as $$
with full_text as (
select
    id,
    -- Note: ts_rank_cd is not indexable but will only rank matches of the where clause
    -- which shouldn't be too big
    row_number() over(order by ts_rank_cd(fts, websearch_to_tsquery(query_text)) desc) as rank_ix
from
    documents
where
    fts @@ websearch_to_tsquery(query_text)
order by rank_ix
limit least(match_count, 30) * 2
),
semantic as (
select
    id,
    row_number() over (order by embedding <#> query_embedding) as rank_ix
from
    documents
order by rank_ix
limit least(match_count, 30) * 2
)
select
documents.*
from
full_text
full outer join semantic
    on full_text.id = semantic.id
join documents
    on coalesce(full_text.id, semantic.id) = documents.id
order by
coalesce(1.0 / (rrf_k + full_text.rank_ix), 0.0) * full_text_weight +
coalesce(1.0 / (rrf_k + semantic.rank_ix), 0.0) * semantic_weight
desc
limit
least(match_count, 30)
$$;
`

Let's break this down:

- **Parameters:** The function accepts quite a few parameters, but the main (required) ones are `query_text`, `query_embedding`, and `match_count`.


  - `query_text` is the user's query text (more on this shortly)
  - `query_embedding` is the vector representation of the user's query produced by the embedding model. We chose 512 dimensions for this example, but adjust this to match the size of the embedding vectors generated from your preferred model. This must match the size of the `embedding` vector on the `documents` table (and use the same model).
  - `match_count` is the number of records returned in the `limit` clause.

The other parameters are optional, but give more control over the fusion process.
  - `full_text_weight` and `semantic_weight` decide how much weight each search method gets in the final score. These are both 1 by default which means they both equally contribute towards the final rank. A `full_text_weight` of 2 and `semantic_weight` of 1 would give full-text search twice as much weight as semantic search.
  - `rrf_k` is the `k` [smoothing constant](https://supabase.com/docs/guides/ai/hybrid-search#smoothing-constant-k) added to the reciprocal rank. The default is 50.
- **Return type:** The function returns a set of records from our `documents` table.

- **CTE:** We create two [common table expressions (CTE)](https://www.postgresql.org/docs/current/queries-with.html), one for full-text search and one for semantic search. These perform each query individually prior to joining them.

- **RRF:** The final query combines the results from the two CTEs using [reciprocal rank fusion (RRF)](https://supabase.com/docs/guides/ai/hybrid-search#reciprocal-ranked-fusion-rrf).


## Running hybrid search [\#](https://supabase.com/docs/guides/ai/hybrid-search\#running-hybrid-search)

To use this function in SQL, we can run:

`
select
*
from
hybrid_search(
    'Italian recipes with tomato sauce', -- user query
    '[...]'::vector(512), -- embedding generated from user query
    10
);
`

In practice, you will likely be calling this from the [Supabase client](https://supabase.com/docs/reference/javascript/introduction) or through a custom backend layer. Here is a quick example of how you might call this from an [Edge Function](https://supabase.com/docs/guides/functions) using JavaScript:

`
import { createClient } from 'jsr:@supabase/supabase-js@2'
import OpenAI from 'npm:openai'
const supabaseUrl = Deno.env.get('SUPABASE_URL')!
const supabaseServiceRoleKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!
const openaiApiKey = Deno.env.get('OPENAI_API_KEY')!
Deno.serve(async (req) => {
// Grab the user's query from the JSON payload
const { query } = await req.json()
// Instantiate OpenAI client
const openai = new OpenAI({ apiKey: openaiApiKey })
// Generate a one-time embedding for the user's query
const embeddingResponse = await openai.embeddings.create({
    model: 'text-embedding-3-large',
    input: query,
    dimensions: 512,
})
const [{ embedding }] = embeddingResponse.data
// Instantiate the Supabase client
// (replace service role key with user's JWT if using Supabase auth and RLS)
const supabase = createClient(supabaseUrl, supabaseServiceRoleKey)
// Call hybrid_search Postgres function via RPC
const { data: documents } = await supabase.rpc('hybrid_search', {
    query_text: query,
    query_embedding: embedding,
    match_count: 10,
})
return new Response(JSON.stringify(documents), {
    headers: { 'Content-Type': 'application/json' },
})
})
`

This uses OpenAI's `text-embedding-3-large` model to generate embeddings (shortened to 512 dimensions for faster retrieval). Swap in your preferred embedding model (and dimension size) accordingly.

To test this, make a `POST` request to the function's endpoint while passing in a JSON payload containing the user's query. Here is an example `POST` request using cURL:

`
curl -i --location --request POST \
'http://127.0.0.1:54321/functions/v1/hybrid-search' \
  --header 'Authorization: Bearer <anonymous key>' \
  --header 'Content-Type: application/json' \
  --data '{"query":"Italian recipes with tomato sauce"}'
`

For more information on how to create, test, and deploy edge functions, see [Getting started](https://supabase.com/docs/guides/functions/quickstart).

## See also [\#](https://supabase.com/docs/guides/ai/hybrid-search\#see-also)

- [Embedding concepts](https://supabase.com/docs/guides/ai/concepts)
- [Vector columns](https://supabase.com/docs/guides/ai/vector-columns)
- [Vector indexes](https://supabase.com/docs/guides/ai/vector-indexes)
- [Semantic search](https://supabase.com/docs/guides/ai/semantic-search)
- [Full text (keyword) search](https://supabase.com/docs/guides/database/full-text-search)

### Is this helpful?

NoYes

### On this page

[Use cases for hybrid search](https://supabase.com/docs/guides/ai/hybrid-search#use-cases-for-hybrid-search) [When to consider hybrid search](https://supabase.com/docs/guides/ai/hybrid-search#when-to-consider-hybrid-search) [How to combine search methods](https://supabase.com/docs/guides/ai/hybrid-search#how-to-combine-search-methods) [Reciprocal Ranked Fusion (RRF)](https://supabase.com/docs/guides/ai/hybrid-search#reciprocal-ranked-fusion-rrf) [Smoothing constant k](https://supabase.com/docs/guides/ai/hybrid-search#smoothing-constant-k) [Hybrid search in Postgres](https://supabase.com/docs/guides/ai/hybrid-search#hybrid-search-in-postgres) [Running hybrid search](https://supabase.com/docs/guides/ai/hybrid-search#running-hybrid-search) [See also](https://supabase.com/docs/guides/ai/hybrid-search#see-also)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_integrations_amazon_bedrock.md">
AI & Vectors

# Amazon Bedrock

* * *

[Amazon Bedrock](https://aws.amazon.com/bedrock) is a fully managed service that offers a choice of high-performing foundation models (FMs) from leading AI companies like AI21 Labs, Anthropic, Cohere, Meta, Mistral AI, Stability AI, and Amazon. Each model is accessible through a common API which implements a broad set of features to help build generative AI applications with security, privacy, and responsible AI in mind.

This guide will walk you through an example using Amazon Bedrock SDK with `vecs`. We will create embeddings using the Amazon Titan Embeddings G1  Text v1.2 (amazon.titan-embed-text-v1) model, insert these embeddings into a Postgres database using vecs, and then query the collection to find the most similar sentences to a given query sentence.

## Create an environment [\#](https://supabase.com/docs/guides/ai/integrations/amazon-bedrock\#create-an-environment)

First, you need to set up your environment. You will need Python 3.7+ with the `vecs` and `boto3` libraries installed.

You can install the necessary Python libraries using pip:

`
pip install vecs boto3
`

You'll also need:

- [Credentials to your AWS account](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html)
- [A Postgres Database with the pgvector extension](https://supabase.com/docs/guides/ai/integrations/hosting.md)

## Create embeddings [\#](https://supabase.com/docs/guides/ai/integrations/amazon-bedrock\#create-embeddings)

Next, we will use Amazons Titan Embedding G1 - Text v1.2 model to create embeddings for a set of sentences.

`
import boto3
import vecs
import json
client = boto3.client(
    'bedrock-runtime',
    region_name='us-east-1',
	# Credentials from your AWS account
    aws_access_key_id='<replace_your_own_credentials>',
    aws_secret_access_key='<replace_your_own_credentials>',
    aws_session_token='<replace_your_own_credentials>',
)
dataset = [\
    "The cat sat on the mat.",\
    "The quick brown fox jumps over the lazy dog.",\
    "Friends, Romans, countrymen, lend me your ears",\
    "To be or not to be, that is the question.",\
]
embeddings = []
for sentence in dataset:
    # invoke the embeddings model for each sentence
    response = client.invoke_model(
        body= json.dumps({"inputText": sentence}),
        modelId= "amazon.titan-embed-text-v1",
        accept = "application/json",
        contentType = "application/json"
    )
    # collect the embedding from the response
    response_body = json.loads(response["body"].read())
    # add the embedding to the embedding list
    embeddings.append((sentence, response_body.get("embedding"), {}))
`

### Store the embeddings with vecs [\#](https://supabase.com/docs/guides/ai/integrations/amazon-bedrock\#store-the-embeddings-with-vecs)

Now that we have our embeddings, we can insert them into a Postgres database using vecs.

`
import vecs
DB_CONNECTION = "postgresql://<user>:<password>@<host>:<port>/<db_name>"
# create vector store client
vx = vecs.Client(DB_CONNECTION)
# create a collection named 'sentences' with 1536 dimensional vectors
# to match the default dimension of the Titan Embeddings G1 - Text model
sentences = vx.get_or_create_collection(name="sentences", dimension=1536)
# upsert the embeddings into the 'sentences' collection
sentences.upsert(records=embeddings)
# create an index for the 'sentences' collection
sentences.create_index()
`

### Querying for most similar sentences [\#](https://supabase.com/docs/guides/ai/integrations/amazon-bedrock\#querying-for-most-similar-sentences)

Now, we query the `sentences` collection to find the most similar sentences to a sample query sentence. First need to create an embedding for the query sentence. Next, we query the collection we created earlier to find the most similar sentences.

`
query_sentence = "A quick animal jumps over a lazy one."
# create vector store client
vx = vecs.Client(DB_CONNECTION)
# create an embedding for the query sentence
response = client.invoke_model(
        body= json.dumps({"inputText": query_sentence}),
        modelId= "amazon.titan-embed-text-v1",
        accept = "application/json",
        contentType = "application/json"
    )
response_body = json.loads(response["body"].read())
query_embedding = response_body.get("embedding")
# query the 'sentences' collection for the most similar sentences
results = sentences.query(
    data=query_embedding,
    limit=3,
    include_value = True
)
# print the results
for result in results:
    print(result)
`

This returns the most similar 3 records and their distance to the query vector.

`
('The quick brown fox jumps over the lazy dog.', 0.27600620558852)
('The cat sat on the mat.', 0.609986272479202)
('To be or not to be, that is the question.', 0.744849503688346)
`

## Resources [\#](https://supabase.com/docs/guides/ai/integrations/amazon-bedrock\#resources)

- [Amazon Bedrock](https://aws.amazon.com/bedrock)
- [Amazon Titan](https://aws.amazon.com/bedrock/titan)
- [Semantic Image Search with Amazon Titan](https://supabase.com/docs/guides/ai/examples/semantic-image-search-amazon-titan)

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2FA3uND5sgiO0%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Create an environment](https://supabase.com/docs/guides/ai/integrations/amazon-bedrock#create-an-environment) [Create embeddings](https://supabase.com/docs/guides/ai/integrations/amazon-bedrock#create-embeddings) [Store the embeddings with vecs](https://supabase.com/docs/guides/ai/integrations/amazon-bedrock#store-the-embeddings-with-vecs) [Querying for most similar sentences](https://supabase.com/docs/guides/ai/integrations/amazon-bedrock#querying-for-most-similar-sentences) [Resources](https://supabase.com/docs/guides/ai/integrations/amazon-bedrock#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_integrations_llamaindex.md">
AI & Vectors

# Learn how to integrate Supabase with LlamaIndex, a data framework for your LLM applications.

## Learn how to integrate Supabase with LlamaIndex, a data framework for your LLM applications.

* * *

This guide will walk you through a basic example using the LlamaIndex [`SupabaseVectorStore`](https://github.com/supabase/supabase/blob/master/examples/ai/llamaindex/llamaindex.ipynb).

## Project setup [\#](https://supabase.com/docs/guides/ai/integrations/llamaindex\#project-setup)

Let's create a new Postgres database. This is as simple as starting a new Project in Supabase:

1. [Create a new project](https://database.new/) in the Supabase dashboard.
2. Enter your project details. Remember to store your password somewhere safe.

Your database will be available in less than a minute.

**Finding your credentials:**

You can find your project credentials inside the project [settings](https://supabase.com/dashboard/project/_/settings/), including:

- [Database credentials](https://supabase.com/dashboard/project/_/settings/database): connection strings and connection pooler details.
- [API credentials](https://supabase.com/dashboard/project/_/settings/database): your serverless API URL and `anon` / `service_role` keys.

## Launching a notebook [\#](https://supabase.com/docs/guides/ai/integrations/llamaindex\#launching-a-notebook)

Launch our [LlamaIndex](https://github.com/supabase/supabase/blob/master/examples/ai/llamaindex/llamaindex.ipynb) notebook in Colab:

[![](https://supabase.com/docs/img/ai/colab-badge.svg)](https://colab.research.google.com/github/supabase/supabase/blob/master/examples/ai/llamaindex/llamaindex.ipynb)

At the top of the notebook, you'll see a button `Copy to Drive`. Click this button to copy the notebook to your Google Drive.

## Fill in your OpenAI credentials [\#](https://supabase.com/docs/guides/ai/integrations/llamaindex\#fill-in-your-openai-credentials)

Inside the Notebook, add your `OPENAI_API_KEY` key. Find the cell which contains this code:

`
import os
os.environ['OPENAI_API_KEY'] = "[your_openai_api_key]"
`

## Connecting to your database [\#](https://supabase.com/docs/guides/ai/integrations/llamaindex\#connecting-to-your-database)

Inside the Notebook, find the cell which specifies the `DB_CONNECTION`. It will contain some code like this:

`
DB_CONNECTION = "postgresql://<user>:<password>@<host>:<port>/<db_name>"
# create vector store client
vx = vecs.create_client(DB_CONNECTION)
`

Replace the `DB_CONNECTION` with your own connection string for your database. You can find the Postgres connection string in the [Database Settings](https://supabase.com/dashboard/project/_/settings/database) of your Supabase project.

SQLAlchemy requires the connection string to start with `postgresql://` (instead of `postgres://`). Don't forget to rename this after copying the string from the dashboard.

You must use the "connection pooling" string (domain ending in `*.pooler.supabase.com`) with Google Colab since Colab does not support IPv6.

## Stepping through the notebook [\#](https://supabase.com/docs/guides/ai/integrations/llamaindex\#stepping-through-the-notebook)

Now all that's left is to step through the notebook. You can do this by clicking the "execute" button ( `ctrl+enter`) at the top left of each code cell. The notebook guides you through the process of creating a collection, adding data to it, and querying it.

You can view the inserted items in the [Table Editor](https://supabase.com/dashboard/project/_/editor/), by selecting the `vecs` schema from the schema dropdown.

![Colab documents](https://supabase.com/docs/img/ai/google-colab/colab-documents.png)

## Resources [\#](https://supabase.com/docs/guides/ai/integrations/llamaindex\#resources)

- Visit the LlamaIndex + `SupabaseVectorStore` [docs](https://gpt-index.readthedocs.io/en/latest/examples/vector_stores/SupabaseVectorIndexDemo.html)
- Visit the official LlamaIndex [repo](https://github.com/jerryjliu/llama_index/)

### Is this helpful?

NoYes

### On this page

[Project setup](https://supabase.com/docs/guides/ai/integrations/llamaindex#project-setup) [Launching a notebook](https://supabase.com/docs/guides/ai/integrations/llamaindex#launching-a-notebook) [Fill in your OpenAI credentials](https://supabase.com/docs/guides/ai/integrations/llamaindex#fill-in-your-openai-credentials) [Connecting to your database](https://supabase.com/docs/guides/ai/integrations/llamaindex#connecting-to-your-database) [Stepping through the notebook](https://supabase.com/docs/guides/ai/integrations/llamaindex#stepping-through-the-notebook) [Resources](https://supabase.com/docs/guides/ai/integrations/llamaindex#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_integrations_roboflow.md">
AI & Vectors

# Roboflow

## Learn how to integrate Supabase with Roboflow, a tool for running fine-tuned and foundation vision models.

* * *

In this guide, we will walk through two examples of using [Roboflow Inference](https://inference.roboflow.com/) to run fine-tuned and foundation models. We will run inference and save predictions using an object detection model and [CLIP](https://github.com/openai/CLIP).

## Project setup [\#](https://supabase.com/docs/guides/ai/integrations/roboflow\#project-setup)

Let's create a new Postgres database. This is as simple as starting a new Project in Supabase:

1. [Create a new project](https://database.new/) in the Supabase dashboard.
2. Enter your project details. Remember to store your password somewhere safe.

Your database will be available in less than a minute.

**Finding your credentials:**

You can find your project credentials inside the project [settings](https://supabase.com/dashboard/project/_/settings/), including:

- [Database credentials](https://supabase.com/dashboard/project/_/settings/database): connection strings and connection pooler details.
- [API credentials](https://supabase.com/dashboard/project/_/settings/database): your serverless API URL and `anon` / `service_role` keys.

## Save computer vision predictions [\#](https://supabase.com/docs/guides/ai/integrations/roboflow\#save-computer-vision-predictions)

Once you have a trained vision model, you need to create business logic for your application. In many cases, you want to save inference results to a file.

The steps below show you how to run a vision model locally and save predictions to Supabase.

### Preparation: Set up a model [\#](https://supabase.com/docs/guides/ai/integrations/roboflow\#preparation-set-up-a-model)

Before you begin, you will need an object detection model trained on your data.

You can [train a model on Roboflow](https://blog.roboflow.com/getting-started-with-roboflow/), leveraging end-to-end tools from data management and annotation to deployment, or [upload custom model weights](https://docs.roboflow.com/deploy/upload-custom-weights) for deployment.

All models have an infinitely scalable API through which you can query your model, and can be run locally.

For this guide, we will use a demo [rock, paper, scissors](https://universe.roboflow.com/roboflow-58fyf/rock-paper-scissors-sxsw) model.

### Step 1: Install and start Roboflow Inference [\#](https://supabase.com/docs/guides/ai/integrations/roboflow\#step-1-install-and-start-roboflow-inference)

You will deploy our model locally using Roboflow Inference, a computer vision inference server.

To install and start Roboflow Inference, first install Docker on your machine.

Then, run:

`
pip install inference inference-cli inference-sdk && inference server start
`

An inference server will be available at `http://localhost:9001`.

### Step 2: Run inference on an image [\#](https://supabase.com/docs/guides/ai/integrations/roboflow\#step-2-run-inference-on-an-image)

You can run inference on images and videos. Let's run inference on an image.

Create a new Python file and add the following code:

`
from inference_sdk import InferenceHTTPClient
image = "example.jpg"
MODEL_ID = "rock-paper-scissors-sxsw/11"
client = InferenceHTTPClient(
    api_url="http://localhost:9001",
    api_key="ROBOFLOW_API_KEY"
)
with client.use_model(MODEL_ID):
    predictions = client.infer(image)
print(predictions)
`

Above, replace:

1. The image URL with the name of the image on which you want to run inference.
2. `ROBOFLOW_API_KEY` with your Roboflow API key. [Learn how to retrieve your Roboflow API key](https://docs.roboflow.com/api-reference/authentication#retrieve-an-api-key).
3. `MODEL_ID` with your Roboflow model ID. [Learn how to retrieve your model ID](https://docs.roboflow.com/api-reference/workspace-and-project-ids).

When you run the code above, a list of predictions will be printed to the console:

`
{'time': 0.05402109300121083, 'image': {'width': 640, 'height': 480}, 'predictions': [{'x': 312.5, 'y': 392.0, 'width': 255.0, 'height': 110.0, 'confidence': 0.8620790839195251, 'class': 'Paper', 'class_id': 0}]}
`

### Step 3: Save results in Supabase [\#](https://supabase.com/docs/guides/ai/integrations/roboflow\#step-3-save-results-in-supabase)

To save results in Supabase, add the following code to your script:

`
import os
from supabase import create_client, Client
url: str = os.environ.get("SUPABASE_URL")
key: str = os.environ.get("SUPABASE_KEY")
supabase: Client = create_client(url, key)
result = supabase.table('predictions') \
    .insert({"filename": image, "predictions": predictions}) \
    .execute()
`

You can then query your predictions using the following code:

`
result = supabase.table('predictions') \
    .select("predictions") \
    .filter("filename", "eq", image) \
    .execute()
print(result)
`

Here is an example result:

`
data=[{'predictions': {'time': 0.08492901099998562, 'image': {'width': 640, 'height': 480}, 'predictions': [{'x': 312.5, 'y': 392.0, 'width': 255.0, 'height': 110.0, 'confidence': 0.8620790839195251, 'class': 'Paper', 'class_id': 0}]}}, {'predictions': {'time': 0.08818970100037404, 'image': {'width': 640, 'height': 480}, 'predictions': [{'x': 312.5, 'y': 392.0, 'width': 255.0, 'height': 110.0, 'confidence': 0.8620790839195251, 'class': 'Paper', 'class_id': 0}]}}] count=None
`

## Calculate and save CLIP embeddings [\#](https://supabase.com/docs/guides/ai/integrations/roboflow\#calculate-and-save-clip-embeddings)

You can use the Supabase vector database functionality to store and query CLIP embeddings.

Roboflow Inference provides a HTTP interface through which you can calculate image and text embeddings using CLIP.

### Step 1: Install and start Roboflow Inference [\#](https://supabase.com/docs/guides/ai/integrations/roboflow\#step-1-install-and-start-roboflow-inference)

See [Step #1: Install and Start Roboflow Inference](https://supabase.com/docs/guides/ai/integrations/roboflow#step-1-install-and-start-roboflow-inference) above to install and start Roboflow Inference.

### Step 2: Run CLIP on an image [\#](https://supabase.com/docs/guides/ai/integrations/roboflow\#step-2-run-clip-on-an-image)

Create a new Python file and add the following code:

`
import cv2
import supervision as sv
import requests
import base64
import os
IMAGE_DIR = "images/train/images/"
API_KEY = ""
SERVER_URL = "http://localhost:9001"
results = []
for i, image in enumerate(os.listdir(IMAGE_DIR)):
    print(f"Processing image {image}")
    infer_clip_payload = {
        "image": {
            "type": "base64",
            "value": base64.b64encode(open(IMAGE_DIR + image, "rb").read()).decode("utf-8"),
        },
    }
    res = requests.post(
        f"{SERVER_URL}/clip/embed_image?api_key={API_KEY}",
        json=infer_clip_payload,
    )
    embeddings = res.json()['embeddings']
    results.append({
        "filename": image,
        "embeddings": embeddings
    })
`

This code will calculate CLIP embeddings for each image in the directory and print the results to the console.

Above, replace:

1. `IMAGE_DIR` with the directory containing the images on which you want to run inference.
2. `ROBOFLOW_API_KEY` with your Roboflow API key. [Learn how to retrieve your Roboflow API key](https://docs.roboflow.com/api-reference/authentication#retrieve-an-api-key).

You can also calculate CLIP embeddings in the cloud by setting `SERVER_URL` to `https://infer.roboflow.com`.

### Step 3: Save embeddings in Supabase [\#](https://supabase.com/docs/guides/ai/integrations/roboflow\#step-3-save-embeddings-in-supabase)

You can store your image embeddings in Supabase using the Supabase `vecs` Python package:

First, install `vecs`:

`
pip install vecs
`

Next, add the following code to your script to create an index:

`
import vecs
DB_CONNECTION = "postgresql://postgres:[password]@[host]:[port]/[database]"
vx = vecs.create_client(DB_CONNECTION)
# create a collection of vectors with 3 dimensions
images = vx.get_or_create_collection(name="image_vectors", dimension=512)
for result in results:
    image = result["filename"]
    embeddings = result["embeddings"][0]
    # insert a vector into the collection
    images.upsert(
        records=[\
            (\
                image,\
                embeddings,\
                {} # metadata\
            )\
        ]
    )
images.create_index()
`

Replace `DB_CONNECTION` with the authentication information for your database. You can retrieve this from the Supabase dashboard in `Project Settings > Database Settings`.

You can then query your embeddings using the following code:

`
infer_clip_payload = {
    "text": "cat",
}
res = requests.post(
    f"{SERVER_URL}/clip/embed_text?api_key={API_KEY}",
    json=infer_clip_payload,
)
embeddings = res.json()['embeddings']
result = images.query(
    data=embeddings[0],
    limit=1
)
print(result[0])
`

## Resources [\#](https://supabase.com/docs/guides/ai/integrations/roboflow\#resources)

- [Roboflow Inference documentation](https://inference.roboflow.com/)
- [Roboflow Getting Started guide](https://blog.roboflow.com/getting-started-with-roboflow/)
- [How to Build a Semantic Image Search Engine with Supabase and OpenAI CLIP](https://blog.roboflow.com/how-to-use-semantic-search-supabase-openai-clip/)

### Is this helpful?

NoYes

### On this page

[Project setup](https://supabase.com/docs/guides/ai/integrations/roboflow#project-setup) [Save computer vision predictions](https://supabase.com/docs/guides/ai/integrations/roboflow#save-computer-vision-predictions) [Preparation: Set up a model](https://supabase.com/docs/guides/ai/integrations/roboflow#preparation-set-up-a-model) [Step 1: Install and start Roboflow Inference](https://supabase.com/docs/guides/ai/integrations/roboflow#step-1-install-and-start-roboflow-inference) [Step 2: Run inference on an image](https://supabase.com/docs/guides/ai/integrations/roboflow#step-2-run-inference-on-an-image) [Step 3: Save results in Supabase](https://supabase.com/docs/guides/ai/integrations/roboflow#step-3-save-results-in-supabase) [Calculate and save CLIP embeddings](https://supabase.com/docs/guides/ai/integrations/roboflow#calculate-and-save-clip-embeddings) [Step 1: Install and start Roboflow Inference](https://supabase.com/docs/guides/ai/integrations/roboflow#step-1-install-and-start-roboflow-inference) [Step 2: Run CLIP on an image](https://supabase.com/docs/guides/ai/integrations/roboflow#step-2-run-clip-on-an-image) [Step 3: Save embeddings in Supabase](https://supabase.com/docs/guides/ai/integrations/roboflow#step-3-save-embeddings-in-supabase) [Resources](https://supabase.com/docs/guides/ai/integrations/roboflow#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_keyword_search.md">
AI & Vectors

# Keyword search

## Learn how to search by words or phrases.

* * *

Keyword search involves locating documents or records that contain specific words or phrases, primarily based on the exact match between the search terms and the text within the data. It differs from [semantic search](https://supabase.com/docs/guides/ai/semantic-search), which interprets the meaning behind the query to provide results that are contextually related, even if the exact words aren't present in the text. Semantic search considers synonyms, intent, and natural language nuances to provide a more nuanced approach to information retrieval.

In Postgres, keyword search is implemented using [full-text search](https://supabase.com/docs/guides/database/full-text-search). It supports indexing and text analysis for data retrieval, focusing on records that match the search criteria. Postgres' full-text search extends beyond simple keyword matching to address linguistic nuances, making it effective for applications that require precise text queries.

## When and why to use keyword search [\#](https://supabase.com/docs/guides/ai/keyword-search\#when-and-why-to-use-keyword-search)

Keyword search is particularly useful in scenarios where precision and specificity matter. It's more effective than semantic search when users are looking for information using exact terminology or specific identifiers. It ensures that results directly contain those terms, reducing the chance of retrieving irrelevant information that might be semantically related but not what the user seeks.

For example in technical or academic research databases, researchers often search for specific studies, compounds, or concepts identified by certain terms or codes. Searching for a specific chemical compound using its exact molecular formula or a unique identifier will yield more focused and relevant results compared to a semantic search, which could return a wide range of documents discussing the compound in different contexts. Keyword search ensures documents that explicitly mention the exact term are found, allowing users to access the precise data they need efficiently.

It's also possible to combine keyword search with semantic search to get the best of both worlds. See [Hybrid search](https://supabase.com/docs/guides/ai/hybrid-search) for more details.

## Using full-text search [\#](https://supabase.com/docs/guides/ai/keyword-search\#using-full-text-search)

For an in-depth guide to Postgres' full-text search, including how to store, index, and query records, see [Full text search](https://supabase.com/docs/guides/database/full-text-search).

## See also [\#](https://supabase.com/docs/guides/ai/keyword-search\#see-also)

- [Semantic search](https://supabase.com/docs/guides/ai/semantic-search)
- [Hybrid search](https://supabase.com/docs/guides/ai/hybrid-search)

### Is this helpful?

NoYes

### On this page

[When and why to use keyword search](https://supabase.com/docs/guides/ai/keyword-search#when-and-why-to-use-keyword-search) [Using full-text search](https://supabase.com/docs/guides/ai/keyword-search#using-full-text-search) [See also](https://supabase.com/docs/guides/ai/keyword-search#see-also)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_langchain.md">
AI & Vectors

# LangChain

* * *

[LangChain](https://langchain.com/) is a popular framework for working with AI, Vectors, and embeddings. LangChain supports using Supabase as a [vector store](https://js.langchain.com/docs/modules/indexes/vector_stores/integrations/supabase), using the `pgvector` extension.

## Initializing your database [\#](https://supabase.com/docs/guides/ai/langchain\#initializing-your-database)

Prepare you database with the relevant tables:

DashboardSQL

1. Go to the [SQL Editor](https://supabase.com/dashboard/project/_/sql) page in the Dashboard.
2. Click **LangChain** in the Quick start section.
3. Click **Run**.

## Usage [\#](https://supabase.com/docs/guides/ai/langchain\#usage)

You can now search your documents using any Node.js application. This is intended to be run on a secure server route.

``
import { SupabaseVectorStore } from 'langchain/vectorstores/supabase'
import { OpenAIEmbeddings } from 'langchain/embeddings/openai'
import { createClient } from '@supabase/supabase-js'
const supabaseKey = process.env.SUPABASE_SERVICE_ROLE_KEY
if (!supabaseKey) throw new Error(`Expected SUPABASE_SERVICE_ROLE_KEY`)
const url = process.env.SUPABASE_URL
if (!url) throw new Error(`Expected env var SUPABASE_URL`)
export const run = async () => {
const client = createClient(url, supabaseKey)
const vectorStore = await SupabaseVectorStore.fromTexts(
    ['Hello world', 'Bye bye', "What's this?"],
    [{ id: 2 }, { id: 1 }, { id: 3 }],
    new OpenAIEmbeddings(),
    {
      client,
      tableName: 'documents',
      queryName: 'match_documents',
    }
)
const resultOne = await vectorStore.similaritySearch('Hello world', 1)
console.log(resultOne)
}
``

### Simple metadata filtering [\#](https://supabase.com/docs/guides/ai/langchain\#simple-metadata-filtering)

Given the above `match_documents` Postgres function, you can also pass a filter parameter to only return documents with a specific metadata field value. This filter parameter is a JSON object, and the `match_documents` function will use the Postgres JSONB Containment operator `@>` to filter documents by the metadata field values you specify. See details on the [Postgres JSONB Containment operator](https://www.postgresql.org/docs/current/datatype-json.html#JSON-CONTAINMENT) for more information.

``
import { SupabaseVectorStore } from 'langchain/vectorstores/supabase'
import { OpenAIEmbeddings } from 'langchain/embeddings/openai'
import { createClient } from '@supabase/supabase-js'
// First, follow set-up instructions above
const privateKey = process.env.SUPABASE_SERVICE_ROLE_KEY
if (!privateKey) throw new Error(`Expected env var SUPABASE_SERVICE_ROLE_KEY`)
const url = process.env.SUPABASE_URL
if (!url) throw new Error(`Expected env var SUPABASE_URL`)
export const run = async () => {
const client = createClient(url, privateKey)
const vectorStore = await SupabaseVectorStore.fromTexts(
    ['Hello world', 'Hello world', 'Hello world'],
    [{ user_id: 2 }, { user_id: 1 }, { user_id: 3 }],
    new OpenAIEmbeddings(),
    {
      client,
      tableName: 'documents',
      queryName: 'match_documents',
    }
)
const result = await vectorStore.similaritySearch('Hello world', 1, {
    user_id: 3,
})
console.log(result)
}
``

### Advanced metadata filtering [\#](https://supabase.com/docs/guides/ai/langchain\#advanced-metadata-filtering)

You can also use query builder-style filtering ( [similar to how the Supabase JavaScript library works](https://supabase.com/docs/reference/javascript/using-filters)) instead of passing an object. Note that since the filter properties will be in the metadata column, you need to use arrow operators ( `->` for integer or `->>` for text) as defined in [PostgREST API documentation](https://postgrest.org/en/stable/references/api/tables_views.html?highlight=operators#json-columns) and specify the data type of the property (e.g. the column should look something like `metadata->some_int_value::int`).

``
import { SupabaseFilterRPCCall, SupabaseVectorStore } from 'langchain/vectorstores/supabase'
import { OpenAIEmbeddings } from 'langchain/embeddings/openai'
import { createClient } from '@supabase/supabase-js'
// First, follow set-up instructions above
const privateKey = process.env.SUPABASE_SERVICE_ROLE_KEY
if (!privateKey) throw new Error(`Expected env var SUPABASE_SERVICE_ROLE_KEY`)
const url = process.env.SUPABASE_URL
if (!url) throw new Error(`Expected env var SUPABASE_URL`)
export const run = async () => {
const client = createClient(url, privateKey)
const embeddings = new OpenAIEmbeddings()
const store = new SupabaseVectorStore(embeddings, {
    client,
    tableName: 'documents',
})
const docs = [\
    {\
      pageContent:\
        'This is a long text, but it actually means something because vector database does not understand Lorem Ipsum. So I would need to expand upon the notion of quantum fluff, a theoretical concept where subatomic particles coalesce to form transient multidimensional spaces. Yet, this abstraction holds no real-world application or comprehensible meaning, reflecting a cosmic puzzle.',\
      metadata: { b: 1, c: 10, stuff: 'right' },\
    },\
    {\
      pageContent:\
        'This is a long text, but it actually means something because vector database does not understand Lorem Ipsum. So I would need to proceed by discussing the echo of virtual tweets in the binary corridors of the digital universe. Each tweet, like a pixelated canary, hums in an unseen frequency, a fascinatingly perplexing phenomenon that, while conjuring vivid imagery, lacks any concrete implication or real-world relevance, portraying a paradox of multidimensional spaces in the age of cyber folklore.',\
      metadata: { b: 2, c: 9, stuff: 'right' },\
    },\
    { pageContent: 'hello', metadata: { b: 1, c: 9, stuff: 'right' } },\
    { pageContent: 'hello', metadata: { b: 1, c: 9, stuff: 'wrong' } },\
    { pageContent: 'hi', metadata: { b: 2, c: 8, stuff: 'right' } },\
    { pageContent: 'bye', metadata: { b: 3, c: 7, stuff: 'right' } },\
    { pageContent: "what's this", metadata: { b: 4, c: 6, stuff: 'right' } },\
]
await store.addDocuments(docs)
const funcFilterA: SupabaseFilterRPCCall = (rpc) =>
    rpc
      .filter('metadata->b::int', 'lt', 3)
      .filter('metadata->c::int', 'gt', 7)
      .textSearch('content', `'multidimensional' & 'spaces'`, {
        config: 'english',
      })
const resultA = await store.similaritySearch('quantum', 4, funcFilterA)
const funcFilterB: SupabaseFilterRPCCall = (rpc) =>
    rpc
      .filter('metadata->b::int', 'lt', 3)
      .filter('metadata->c::int', 'gt', 7)
      .filter('metadata->>stuff', 'eq', 'right')
const resultB = await store.similaritySearch('hello', 2, funcFilterB)
console.log(resultA, resultB)
}
``

## Hybrid search [\#](https://supabase.com/docs/guides/ai/langchain\#hybrid-search)

LangChain supports the concept of a hybrid search, which combines Similarity Search with Full Text Search. Read the official docs to get started: [Supabase Hybrid Search](https://js.langchain.com/docs/modules/indexes/retrievers/supabase-hybrid).

You can install the LangChain Hybrid Search function though our [database.dev package manager](https://database.dev/langchain/hybrid_search).

## Resources [\#](https://supabase.com/docs/guides/ai/langchain\#resources)

- Official [LangChain site](https://langchain.com/).
- Official [LangChain docs](https://js.langchain.com/docs/modules/indexes/vector_stores/integrations/supabase).
- Supabase [Hybrid Search](https://js.langchain.com/docs/modules/indexes/retrievers/supabase-hybrid).

### Is this helpful?

NoYes

### On this page

[Initializing your database](https://supabase.com/docs/guides/ai/langchain#initializing-your-database) [Usage](https://supabase.com/docs/guides/ai/langchain#usage) [Simple metadata filtering](https://supabase.com/docs/guides/ai/langchain#simple-metadata-filtering) [Advanced metadata filtering](https://supabase.com/docs/guides/ai/langchain#advanced-metadata-filtering) [Hybrid search](https://supabase.com/docs/guides/ai/langchain#hybrid-search) [Resources](https://supabase.com/docs/guides/ai/langchain#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_python_api.md">
AI & Vectors

# API

* * *

`vecs` is a python client for managing and querying vector stores in PostgreSQL with the [pgvector extension](https://github.com/pgvector/pgvector). This guide will help you get started with using vecs.

If you don't have a Postgres database with the pgvector ready, see [hosting](https://supabase.github.io/vecs/hosting) for easy options.

## Installation [\#](https://supabase.com/docs/guides/ai/python/api\#installation)

Requires:

- Python 3.7+

You can install vecs using pip:

`
pip install vecs
`

## Usage [\#](https://supabase.com/docs/guides/ai/python/api\#usage)

## Connecting [\#](https://supabase.com/docs/guides/ai/python/api\#connecting)

Before you can interact with vecs, create the client to communicate with Postgres. If you haven't started a Postgres instance yet, see [hosting](https://supabase.github.io/vecs/hosting).

`
import vecs
DB_CONNECTION = "postgresql://<user>:<password>@<host>:<port>/<db_name>"
# create vector store client
vx = vecs.create_client(DB_CONNECTION)
`

## Get or Create a Collection [\#](https://supabase.com/docs/guides/ai/python/api\#get-or-create-a-collection)

You can get a collection (or create if it doesn't exist), specifying the collection's name and the number of dimensions for the vectors you intend to store.

`
docs = vx.get_or_create_collection(name="docs", dimension=3)
`

## Upserting vectors [\#](https://supabase.com/docs/guides/ai/python/api\#upserting-vectors)

`vecs` combines the concepts of "insert" and "update" into "upsert". Upserting records adds them to the collection if the `id` is not present, or updates the existing record if the `id` does exist.

`
# add records to the collection
docs.upsert(
    records=[\
        (\
         "vec0",           # the vector's identifier\
         [0.1, 0.2, 0.3],  # the vector. list or np.array\
         {"year": 1973}    # associated  metadata\
        ),\
        (\
         "vec1",\
         [0.7, 0.8, 0.9],\
         {"year": 2012}\
        )\
    ]
)
`

## Deleting vectors [\#](https://supabase.com/docs/guides/ai/python/api\#deleting-vectors)

Deleting records removes them from the collection. To delete records, specify a list of `ids` or metadata filters to the `delete` method. The ids of the sucessfully deleted records are returned from the method. Note that attempting to delete non-existent records does not raise an error.

`
docs.delete(ids=["vec0", "vec1"])
# or delete by a metadata filter
docs.delete(filters={"year": {"$eq": 2012}})
`

## Create an index [\#](https://supabase.com/docs/guides/ai/python/api\#create-an-index)

Collections can be queried immediately after being created.
However, for good throughput, the collection should be indexed after records have been upserted.

Only one index may exist per-collection. By default, creating an index will replace any existing index.

To create an index:

`
docs.create_index()
`

You may optionally provide a distance measure and index method.

Available options for distance `measure` are:

- `vecs.IndexMeasure.cosine_distance`
- `vecs.IndexMeasure.l2_distance`
- `vecs.IndexMeasure.l1_distance`
- `vecs.IndexMeasure.max_inner_product`

which correspond to different methods for comparing query vectors to the vectors in the database.

If you aren't sure which to use, the default of cosine\_distance is the most widely compatible with off-the-shelf embedding methods.

Available options for index `method` are:

- `vecs.IndexMethod.auto`
- `vecs.IndexMethod.hnsw`
- `vecs.IndexMethod.ivfflat`

Where `auto` selects the best available index method, `hnsw` uses the [HNSW](https://github.com/pgvector/pgvector#hnsw) method and `ivfflat` uses [IVFFlat](https://github.com/pgvector/pgvector#ivfflat).

HNSW and IVFFlat indexes both allow for parameterization to control the speed/accuracy tradeoff. vecs provides sane defaults for these parameters. For a greater level of control you can optionally pass an instance of `vecs.IndexArgsIVFFlat` or `vecs.IndexArgsHNSW` to `create_index`'s `index_arguments` argument. Descriptions of the impact for each parameter are available in the [pgvector docs](https://github.com/pgvector/pgvector).

When using IVFFlat indexes, the index must be created **after** the collection has been populated with records. Building an IVFFlat index on an empty collection will result in significantly reduced recall. You can continue upserting new documents after the index has been created, but should rebuild the index if the size of the collection more than doubles since the last index operation.

HNSW indexes can be created immediately after the collection without populating records.

To manually specify `method`, `measure`, and `index_arguments` add them as arguments to `create_index` for example:

`
docs.create_index(
    method=IndexMethod.hnsw,
    measure=IndexMeasure.cosine_distance,
    index_arguments=IndexArgsHNSW(m=8),
)
`

The time required to create an index grows with the number of records and size of vectors.
For a few thousand records expect sub-minute a response in under a minute. It may take a few
minutes for larger collections.

## Query [\#](https://supabase.com/docs/guides/ai/python/api\#query)

Given a collection `docs` with several records:

### Basic [\#](https://supabase.com/docs/guides/ai/python/api\#basic)

The simplest form of search is to provide a query vector.

Indexes are essential for good performance. See

[creating an index](https://supabase.com/docs/guides/ai/python/api#create-an-index)

for more info.

If you do not create an index, every query will return a warning

`
query does not have a covering index for cosine_similarity. See Collection.create_index
`

that incldues the `IndexMeasure` you should index.

`
docs.query(
    data=[0.4,0.5,0.6],          # required
    limit=5,                     # number of records to return
    filters={},                  # metadata filters
    measure="cosine_distance",   # distance measure to use
    include_value=False,         # should distance measure values be returned?
    include_metadata=False,      # should record metadata be returned?
)
`

Which returns a list of vector record `ids`.

### Metadata Filtering [\#](https://supabase.com/docs/guides/ai/python/api\#metadata-filtering)

The metadata that is associated with each record can also be filtered during a query.

As an example, `{"year": {"$eq": 2005}}` filters a `year` metadata key to be equal to 2005

In context:

`
docs.query(
    data=[0.4,0.5,0.6],
    filters={"year": {"$eq": 2012}}, # metadata filters
)
`

For a complete reference, see the [metadata guide](https://supabase.com/docs/guides/ai/python/metadata).

### Disconnect [\#](https://supabase.com/docs/guides/ai/python/api\#disconnect)

When you're done with a collection, be sure to disconnect the client from the database.

`
vx.disconnect()
`

alternatively, use the client as a context manager and it will automatically close the connection on exit.

`
import vecs
DB_CONNECTION = "postgresql://<user>:<password>@<host>:<port>/<db_name>"
# create vector store client
with vecs.create_client(DB_CONNECTION) as vx:
    # do some work here
    pass
# connections are now closed
`

## Adapters [\#](https://supabase.com/docs/guides/ai/python/api\#adapters)

Adapters are an optional feature to transform data before adding to or querying from a collection. Adapters make it possible to interact with a collection using only your project's native data type (eg. just raw text), rather than manually handling vectors.

For a complete list of available adapters, see [built-in adapters](https://supabase.github.io/vecs/concepts_adapters#built-in-adapters).

As an example, we'll create a collection with an adapter that chunks text into paragraphs and converts each chunk into an embedding vector using the `all-MiniLM-L6-v2` model.

First, install `vecs` with optional dependencies for text embeddings:

`
pip install "vecs[text_embedding]"
`

Then create a collection with an adapter to chunk text into paragraphs and embed each paragraph using the `all-MiniLM-L6-v2` 384 dimensional text embedding model.

`
import vecs
from vecs.adapter import Adapter, ParagraphChunker, TextEmbedding
# create vector store client
vx = vecs.Client("postgresql://<user>:<password>@<host>:<port>/<db_name>")
# create a collection with an adapter
docs = vx.get_or_create_collection(
    name="docs",
    adapter=Adapter(
        [\
            ParagraphChunker(skip_during_query=True),\
            TextEmbedding(model='all-MiniLM-L6-v2'),\
        ]
    )
)
`

With the adapter registered against the collection, we can upsert records into the collection passing in text rather than vectors.

`
# add records to the collection using text as the media type
docs.upsert(
    records=[\
        (\
         "vec0",\
         "four score and ....", # <- note that we can now pass text here\
         {"year": 1973}\
        ),\
        (\
         "vec1",\
         "hello, world!",\
         {"year": "2012"}\
        )\
    ]
)
`

Similarly, we can query the collection using text.

`
# search by text
docs.query(data="foo bar")
`

* * *

## Deprecated [\#](https://supabase.com/docs/guides/ai/python/api\#deprecated)

### Create collection [\#](https://supabase.com/docs/guides/ai/python/api\#create-collection)

Deprecated: use

[get\_or\_create\_collection](https://supabase.com/docs/guides/ai/python/api#get-or-create-a-collection)

You can create a collection to store vectors specifying the collections name and the number of dimensions in the vectors you intend to store.

`
docs = vx.create_collection(name="docs", dimension=3)
`

### Get an existing collection [\#](https://supabase.com/docs/guides/ai/python/api\#get-an-existing-collection)

Deprecated: use

[get\_or\_create\_collection](https://supabase.com/docs/guides/ai/python/api#get-or-create-a-collection)

To access a previously created collection, use `get_collection` to retrieve it by name

`
docs = vx.get_collection(name="docs")
`

### Is this helpful?

NoYes

### On this page

[Installation](https://supabase.com/docs/guides/ai/python/api#installation) [Usage](https://supabase.com/docs/guides/ai/python/api#usage) [Connecting](https://supabase.com/docs/guides/ai/python/api#connecting) [Get or Create a Collection](https://supabase.com/docs/guides/ai/python/api#get-or-create-a-collection) [Upserting vectors](https://supabase.com/docs/guides/ai/python/api#upserting-vectors) [Deleting vectors](https://supabase.com/docs/guides/ai/python/api#deleting-vectors) [Create an index](https://supabase.com/docs/guides/ai/python/api#create-an-index) [Query](https://supabase.com/docs/guides/ai/python/api#query) [Basic](https://supabase.com/docs/guides/ai/python/api#basic) [Metadata Filtering](https://supabase.com/docs/guides/ai/python/api#metadata-filtering) [Disconnect](https://supabase.com/docs/guides/ai/python/api#disconnect) [Adapters](https://supabase.com/docs/guides/ai/python/api#adapters) [Deprecated](https://supabase.com/docs/guides/ai/python/api#deprecated) [Create collection](https://supabase.com/docs/guides/ai/python/api#create-collection) [Get an existing collection](https://supabase.com/docs/guides/ai/python/api#get-an-existing-collection)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_python_clients.md">
AI & Vectors

# Choosing a Client

* * *

As described in [Structured & Unstructured Embeddings](https://supabase.com/docs/guides/ai/structured-unstructured), AI workloads come in many forms.

For data science or ephemeral workloads, the [Supabase Vecs](https://supabase.github.io/vecs/) client gets you started quickly. All you need is a connection string and vecs handles setting up your database to store and query vectors with associated metadata.

You can get your connection string from the [**Database Settings**](https://supabase.com/dashboard/project/_/settings/database) page in your dashboard. Make sure to check **Use connection pooling**, then copy the URI. Also, change the URI scheme from `postgres` to `postgresql`. `vecs` uses SQLAlchemy under the hood, which only supports `postgresql` as a dialect.

For production python applications with version controlled migrations, we recommend adding first class vector support to your toolchain by [registering the vector type with your ORM](https://github.com/pgvector/pgvector-python). pgvector provides bindings for the most commonly used SQL drivers/libraries including Django, SQLAlchemy, SQLModel, psycopg, asyncpg and Peewee.

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_quickstarts_face_similarity.md">
AI & Vectors

# Face similarity search

## Identify the celebrities who look most similar to you using Supabase Vecs.

* * *

This guide will walk you through a ["Face Similarity Search"](https://github.com/supabase/supabase/blob/master/examples/ai/face_similarity.ipynb) example using Colab and Supabase Vecs. You will be able to identify the celebrities who look most similar to you (or any other person). You will:

1. Launch a Postgres database that uses pgvector to store embeddings
2. Launch a notebook that connects to your database
3. Load the " `ashraq/tmdb-people-image`" celebrity dataset
4. Use the `face_recognition` model to create an embedding for every celebrity photo.
5. Search for similar faces inside the dataset.

## Project setup [\#](https://supabase.com/docs/guides/ai/quickstarts/face-similarity\#project-setup)

Let's create a new Postgres database. This is as simple as starting a new Project in Supabase:

1. [Create a new project](https://database.new/) in the Supabase dashboard.
2. Enter your project details. Remember to store your password somewhere safe.

Your database will be available in less than a minute.

**Finding your credentials:**

You can find your project credentials inside the project [settings](https://supabase.com/dashboard/project/_/settings/), including:

- [Database credentials](https://supabase.com/dashboard/project/_/settings/database): connection strings and connection pooler details.
- [API credentials](https://supabase.com/dashboard/project/_/settings/database): your serverless API URL and `anon` / `service_role` keys.

## Launching a notebook [\#](https://supabase.com/docs/guides/ai/quickstarts/face-similarity\#launching-a-notebook)

Launch our [`semantic_text_deduplication`](https://github.com/supabase/supabase/blob/master/examples/ai/face_similarity.ipynb) notebook in Colab:

[![](https://supabase.com/docs/img/ai/colab-badge.svg)](https://colab.research.google.com/github/supabase/supabase/blob/master/examples/ai/face_similarity.ipynb)

At the top of the notebook, you'll see a button `Copy to Drive`. Click this button to copy the notebook to your Google Drive.

## Connecting to your database [\#](https://supabase.com/docs/guides/ai/quickstarts/face-similarity\#connecting-to-your-database)

Inside the Notebook, find the cell which specifies the `DB_CONNECTION`. It will contain some code like this:

`
import vecs
DB_CONNECTION = "postgresql://<user>:<password>@<host>:<port>/<db_name>"
# create vector store client
vx = vecs.create_client(DB_CONNECTION)
`

Replace the `DB_CONNECTION` with your own connection string for your database. You can find the Postgres connection string in the [Database Settings](https://supabase.com/dashboard/project/_/settings/database) of your Supabase project.

SQLAlchemy requires the connection string to start with `postgresql://` (instead of `postgres://`). Don't forget to rename this after copying the string from the dashboard.

You must use the "connection pooling" string (domain ending in `*.pooler.supabase.com`) with Google Colab since Colab does not support IPv6.

## Stepping through the notebook [\#](https://supabase.com/docs/guides/ai/quickstarts/face-similarity\#stepping-through-the-notebook)

Now all that's left is to step through the notebook. You can do this by clicking the "execute" button ( `ctrl+enter`) at the top left of each code cell. The notebook guides you through the process of creating a collection, adding data to it, and querying it.

You can view the inserted items in the [Table Editor](https://supabase.com/dashboard/project/_/editor/), by selecting the `vecs` schema from the schema dropdown.

![Colab documents](https://supabase.com/docs/img/ai/google-colab/colab-documents.png)

## Next steps [\#](https://supabase.com/docs/guides/ai/quickstarts/face-similarity\#next-steps)

You can now start building your own applications with Vecs. Check our [examples](https://supabase.com/docs/guides/ai#examples) for ideas.

### Is this helpful?

NoYes

### On this page

[Project setup](https://supabase.com/docs/guides/ai/quickstarts/face-similarity#project-setup) [Launching a notebook](https://supabase.com/docs/guides/ai/quickstarts/face-similarity#launching-a-notebook) [Connecting to your database](https://supabase.com/docs/guides/ai/quickstarts/face-similarity#connecting-to-your-database) [Stepping through the notebook](https://supabase.com/docs/guides/ai/quickstarts/face-similarity#stepping-through-the-notebook) [Next steps](https://supabase.com/docs/guides/ai/quickstarts/face-similarity#next-steps)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_quickstarts_generate_text_embeddings.md">
AI & Vectors

# Generate Embeddings

## Generate text embeddings using Edge Functions.

* * *

This guide will walk you through how to generate high quality text embeddings in [Edge Functions](https://supabase.com/docs/guides/functions) using its built-in AI inference API, so no external API is required.

## Build the Edge Function [\#](https://supabase.com/docs/guides/ai/quickstarts/generate-text-embeddings\#build-the-edge-function)

Let's build an Edge Function that will accept an input string and generate an embedding for it. Edge Functions are server-side TypeScript HTTP endpoints that run on-demand closest to your users.

1

### Set up Supabase locally

Make sure you have the latest version of the [Supabase CLI installed](https://supabase.com/docs/guides/cli/getting-started).

Initialize Supabase in the root directory of your app and start your local stack.

`
supabase init
supabase start
`

2

### Create Edge Function

Create an Edge Function that we will use to generate embeddings. We'll call this `embed` (you can name this anything you like).

This will create a new TypeScript file called `index.ts` under `./supabase/functions/embed`.

`
supabase functions new embed
`

3

### Setup Inference Session

Let's create a new inference session to be used in the lifetime of this function. Multiple requests can use the same inference session.

Currently, only the `gte-small` ( [https://huggingface.co/Supabase/gte-small](https://huggingface.co/Supabase/gte-small)) text embedding model is supported in Supabase's Edge Runtime.

./supabase/functions/embed/index.ts

`
const session = new Supabase.ai.Session('gte-small');
`

4

### Implement request handler

Modify our request handler to accept an `input` string from the POST request JSON body.

Then generate the embedding by calling `session.run(input)`.

./supabase/functions/embed/index.ts

`
Deno.serve(async (req) => {
// Extract input string from JSON body
const { input } = await req.json();
// Generate the embedding from the user input
const embedding = await session.run(input, {
    mean_pool: true,
    normalize: true,
});
// Return the embedding
return new Response(
    JSON.stringify({ embedding }),
    { headers: { 'Content-Type': 'application/json' } }
);
});
`

Note the two options we pass to `session.run()`:

- `mean_pool`: The first option sets `pooling` to `mean`. Pooling refers to how token-level embedding representations are compressed into a single sentence embedding that reflects the meaning of the entire sentence. Average pooling is the most common type of pooling for sentence embeddings.
- `normalize`: The second option tells to normalize the embedding vector so that it can be used with distance measures like dot product. A normalized vector means its length (magnitude) is 1 - also referred to as a unit vector. A vector is normalized by dividing each element by the vector's length (magnitude), which maintains its direction but changes its length to 1.

5

### Test it!

To test the Edge Function, first start a local functions server.

`
supabase functions serve
`

Then in a new shell, create an HTTP request using cURL and pass in your input in the JSON body.

`
curl --request POST 'http://localhost:54321/functions/v1/embed' \
  --header 'Authorization: Bearer ANON_KEY' \
  --header 'Content-Type: application/json' \
  --data '{ "input": "hello world" }'
`

Be sure to replace `ANON_KEY` with your project's anonymous key. You can get this key by running `supabase status`.

## Next steps [\#](https://supabase.com/docs/guides/ai/quickstarts/generate-text-embeddings\#next-steps)

- Learn more about [embedding concepts](https://supabase.com/docs/guides/ai/concepts)
- [Store your embeddings](https://supabase.com/docs/guides/ai/vector-columns) in a database

### Is this helpful?

NoYes

### On this page

[Build the Edge Function](https://supabase.com/docs/guides/ai/quickstarts/generate-text-embeddings#build-the-edge-function) [Next steps](https://supabase.com/docs/guides/ai/quickstarts/generate-text-embeddings#next-steps)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_quickstarts_hello_world.md">
AI & Vectors

# Creating and managing collections

## Connecting to your database with Colab.

* * *

This guide will walk you through a basic ["Hello World"](https://github.com/supabase/supabase/blob/master/examples/ai/vector_hello_world.ipynb) example using Colab and Supabase Vecs. You'll learn how to:

1. Launch a Postgres database that uses pgvector to store embeddings
2. Launch a notebook that connects to your database
3. Create a vector collection
4. Add data to the collection
5. Query the collection

## Project setup [\#](https://supabase.com/docs/guides/ai/quickstarts/hello-world\#project-setup)

Let's create a new Postgres database. This is as simple as starting a new Project in Supabase:

1. [Create a new project](https://database.new/) in the Supabase dashboard.
2. Enter your project details. Remember to store your password somewhere safe.

Your database will be available in less than a minute.

**Finding your credentials:**

You can find your project credentials inside the project [settings](https://supabase.com/dashboard/project/_/settings/), including:

- [Database credentials](https://supabase.com/dashboard/project/_/settings/database): connection strings and connection pooler details.
- [API credentials](https://supabase.com/dashboard/project/_/settings/database): your serverless API URL and `anon` / `service_role` keys.

## Launching a notebook [\#](https://supabase.com/docs/guides/ai/quickstarts/hello-world\#launching-a-notebook)

Launch our [`vector_hello_world`](https://github.com/supabase/supabase/blob/master/examples/ai/vector_hello_world.ipynb) notebook in Colab:

[![](https://supabase.com/docs/img/ai/colab-badge.svg)](https://colab.research.google.com/github/supabase/supabase/blob/master/examples/ai/vector_hello_world.ipynb)

At the top of the notebook, you'll see a button `Copy to Drive`. Click this button to copy the notebook to your Google Drive.

## Connecting to your database [\#](https://supabase.com/docs/guides/ai/quickstarts/hello-world\#connecting-to-your-database)

Inside the Notebook, find the cell which specifies the `DB_CONNECTION`. It will contain some code like this:

`
import vecs
DB_CONNECTION = "postgresql://<user>:<password>@<host>:<port>/<db_name>"
# create vector store client
vx = vecs.create_client(DB_CONNECTION)
`

Replace the `DB_CONNECTION` with your own connection string for your database. You can find the Postgres connection string in the [Database Settings](https://supabase.com/dashboard/project/_/settings/database) of your Supabase project.

SQLAlchemy requires the connection string to start with `postgresql://` (instead of `postgres://`). Don't forget to rename this after copying the string from the dashboard.

You must use the "connection pooling" string (domain ending in `*.pooler.supabase.com`) with Google Colab since Colab does not support IPv6.

## Stepping through the notebook [\#](https://supabase.com/docs/guides/ai/quickstarts/hello-world\#stepping-through-the-notebook)

Now all that's left is to step through the notebook. You can do this by clicking the "execute" button ( `ctrl+enter`) at the top left of each code cell. The notebook guides you through the process of creating a collection, adding data to it, and querying it.

You can view the inserted items in the [Table Editor](https://supabase.com/dashboard/project/_/editor/), by selecting the `vecs` schema from the schema dropdown.

![Colab documents](https://supabase.com/docs/img/ai/google-colab/colab-documents.png)

## Next steps [\#](https://supabase.com/docs/guides/ai/quickstarts/hello-world\#next-steps)

You can now start building your own applications with Vecs. Check our [examples](https://supabase.com/docs/guides/ai#examples) for ideas.

### Is this helpful?

NoYes

### On this page

[Project setup](https://supabase.com/docs/guides/ai/quickstarts/hello-world#project-setup) [Launching a notebook](https://supabase.com/docs/guides/ai/quickstarts/hello-world#launching-a-notebook) [Connecting to your database](https://supabase.com/docs/guides/ai/quickstarts/hello-world#connecting-to-your-database) [Stepping through the notebook](https://supabase.com/docs/guides/ai/quickstarts/hello-world#stepping-through-the-notebook) [Next steps](https://supabase.com/docs/guides/ai/quickstarts/hello-world#next-steps)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_quickstarts_text_deduplication.md">
AI & Vectors

# Semantic Text Deduplication

## Finding duplicate movie reviews with Supabase Vecs.

* * *

This guide will walk you through a ["Semantic Text Deduplication"](https://github.com/supabase/supabase/blob/master/examples/ai/semantic_text_deduplication.ipynb) example using Colab and Supabase Vecs. You'll learn how to find similar movie reviews using embeddings, and remove any that seem like duplicates. You will:

1. Launch a Postgres database that uses pgvector to store embeddings
2. Launch a notebook that connects to your database
3. Load the IMDB dataset
4. Use the `sentence-transformers/all-MiniLM-L6-v2` model to create an embedding representing the semantic meaning of each review.
5. Search for all duplicates.

## Project setup [\#](https://supabase.com/docs/guides/ai/quickstarts/text-deduplication\#project-setup)

Let's create a new Postgres database. This is as simple as starting a new Project in Supabase:

1. [Create a new project](https://database.new/) in the Supabase dashboard.
2. Enter your project details. Remember to store your password somewhere safe.

Your database will be available in less than a minute.

**Finding your credentials:**

You can find your project credentials inside the project [settings](https://supabase.com/dashboard/project/_/settings/), including:

- [Database credentials](https://supabase.com/dashboard/project/_/settings/database): connection strings and connection pooler details.
- [API credentials](https://supabase.com/dashboard/project/_/settings/database): your serverless API URL and `anon` / `service_role` keys.

## Launching a notebook [\#](https://supabase.com/docs/guides/ai/quickstarts/text-deduplication\#launching-a-notebook)

Launch our [`semantic_text_deduplication`](https://github.com/supabase/supabase/blob/master/examples/ai/semantic_text_deduplication.ipynb) notebook in Colab:

[![](https://supabase.com/docs/img/ai/colab-badge.svg)](https://colab.research.google.com/github/supabase/supabase/blob/master/examples/ai/semantic_text_deduplication.ipynb)

At the top of the notebook, you'll see a button `Copy to Drive`. Click this button to copy the notebook to your Google Drive.

## Connecting to your database [\#](https://supabase.com/docs/guides/ai/quickstarts/text-deduplication\#connecting-to-your-database)

Inside the Notebook, find the cell which specifies the `DB_CONNECTION`. It will contain some code like this:

`
import vecs
DB_CONNECTION = "postgresql://<user>:<password>@<host>:<port>/<db_name>"
# create vector store client
vx = vecs.create_client(DB_CONNECTION)
`

Replace the `DB_CONNECTION` with your own connection string for your database. You can find the Postgres connection string in the [Database Settings](https://supabase.com/dashboard/project/_/settings/database) of your Supabase project.

SQLAlchemy requires the connection string to start with `postgresql://` (instead of `postgres://`). Don't forget to rename this after copying the string from the dashboard.

You must use the "connection pooling" string (domain ending in `*.pooler.supabase.com`) with Google Colab since Colab does not support IPv6.

## Stepping through the notebook [\#](https://supabase.com/docs/guides/ai/quickstarts/text-deduplication\#stepping-through-the-notebook)

Now all that's left is to step through the notebook. You can do this by clicking the "execute" button ( `ctrl+enter`) at the top left of each code cell. The notebook guides you through the process of creating a collection, adding data to it, and querying it.

You can view the inserted items in the [Table Editor](https://supabase.com/dashboard/project/_/editor/), by selecting the `vecs` schema from the schema dropdown.

![Colab documents](https://supabase.com/docs/img/ai/google-colab/colab-documents.png)

## Deployment [\#](https://supabase.com/docs/guides/ai/quickstarts/text-deduplication\#deployment)

If you have your own infrastructure for deploying Python apps, you can continue to use `vecs` as described in this guide.

Alternatively if you would like to quickly deploy using Supabase, check out our guide on using the [Hugging Face Inference API](https://supabase.com/docs/guides/ai/hugging-face) in Edge Functions using TypeScript.

## Next steps [\#](https://supabase.com/docs/guides/ai/quickstarts/text-deduplication\#next-steps)

You can now start building your own applications with Vecs. Check our [examples](https://supabase.com/docs/guides/ai#examples) for ideas.

### Is this helpful?

NoYes

### On this page

[Project setup](https://supabase.com/docs/guides/ai/quickstarts/text-deduplication#project-setup) [Launching a notebook](https://supabase.com/docs/guides/ai/quickstarts/text-deduplication#launching-a-notebook) [Connecting to your database](https://supabase.com/docs/guides/ai/quickstarts/text-deduplication#connecting-to-your-database) [Stepping through the notebook](https://supabase.com/docs/guides/ai/quickstarts/text-deduplication#stepping-through-the-notebook) [Deployment](https://supabase.com/docs/guides/ai/quickstarts/text-deduplication#deployment) [Next steps](https://supabase.com/docs/guides/ai/quickstarts/text-deduplication#next-steps)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_rag_with_permissions.md">
AI & Vectors

# RAG with Permissions

## Fine-grain access control with Retrieval Augmented Generation.

* * *

Since pgvector is built on top of Postgres, you can implement fine-grain access control on your vector database using [Row Level Security (RLS)](https://supabase.com/docs/guides/database/postgres/row-level-security). This means you can restrict which documents are returned during a vector similarity search to users that have access to them. Supabase also supports [Foreign Data Wrappers (FDW)](https://supabase.com/docs/guides/database/extensions/wrappers/overview) which means you can use an external database or data source to determine these permissions if your user data doesn't exist in Supabase.

Use this guide to learn how to restrict access to documents when performing retrieval augmented generation (RAG).

## Example [\#](https://supabase.com/docs/guides/ai/rag-with-permissions\#example)

In a typical RAG setup, your documents are chunked into small subsections and similarity is performed over those sections:

`
-- Track documents/pages/files/etc
create table documents (
id bigint primary key generated always as identity,
name text not null,
owner_id uuid not null references auth.users (id) default auth.uid(),
created_at timestamp with time zone not null default now()
);
-- Store the content and embedding vector for each section in the document
-- with a reference to original document (one-to-many)
create table document_sections (
id bigint primary key generated always as identity,
document_id bigint not null references documents (id),
content text not null,
embedding vector (384)
);
`

Notice how we record the `owner_id` on each document. Let's create an RLS policy that restricts access to `document_sections` based on whether or not they own the linked document:

`
-- enable row level security
alter table document_sections enable row level security;
-- setup RLS for select operations
create policy "Users can query their own document sections"
on document_sections for select to authenticated using (
document_id in (
    select id
    from documents
    where (owner_id = (select auth.uid()))
)
);
`

In this example, the current user is determined using the built-in `auth.uid()` function when the query is executed through your project's auto-generated [REST API](https://supabase.com/docs/guides/api). If you are connecting to your Supabase database through a direct Postgres connection, see [Direct Postgres Connection](https://supabase.com/docs/guides/ai/rag-with-permissions#direct-postgres-connection) below for directions on how to achieve the same access control.

Now every `select` query executed on `document_sections` will implicitly filter the returned sections based on whether or not the current user has access to them.

For example, executing:

`
select * from document_sections;
`

as an authenticated user will only return rows that they are the owner of (as determined by the linked document). More importantly, semantic search over these sections (or any additional filtering for that matter) will continue to respect these RLS policies:

`
-- Perform inner product similarity based on a match_threshold
select *
from document_sections
where document_sections.embedding <#> embedding < -match_threshold
order by document_sections.embedding <#> embedding;
`

The above example only configures `select` access to users. If you wanted, you could create more RLS policies for inserts, updates, and deletes in order to apply the same permission logic for those other operations. See [Row Level Security](https://supabase.com/docs/guides/database/postgres/row-level-security) for a more in-depth guide on RLS policies.

## Alternative scenarios [\#](https://supabase.com/docs/guides/ai/rag-with-permissions\#alternative-scenarios)

Every app has its own unique requirements and may differ from the above example. Here are some alternative scenarios we often see and how they are implemented in Supabase.

### Documents owned by multiple people [\#](https://supabase.com/docs/guides/ai/rag-with-permissions\#documents-owned-by-multiple-people)

Instead of a one-to-many relationship between `users` and `documents`, you may require a many-to-many relationship so that multiple people can access the same document. Let's reimplement this using a join table:

`
create table document_owners (
id bigint primary key generated always as identity,
owner_id uuid not null references auth.users (id) default auth.uid(),
document_id bigint not null references documents (id)
);
`

Then your RLS policy would change to:

`
create policy "Users can query their own document sections"
on document_sections for select to authenticated using (
document_id in (
    select document_id
    from document_owners
    where (owner_id = (select auth.uid()))
)
);
`

Instead of directly querying the `documents` table, we query the join table.

### User and document data live outside of Supabase [\#](https://supabase.com/docs/guides/ai/rag-with-permissions\#user-and-document-data-live-outside-of-supabase)

You may have an existing system that stores users, documents, and their permissions in a separate database. Let's explore the scenario where this data exists in another Postgres database. We'll use a foreign data wrapper (FDW) to connect to the external DB from within your Supabase DB:

RLS is latency-sensitive, so extra caution should be taken before implementing this method. Use the [query plan analyzer](https://supabase.com/docs/guides/platform/performance#optimizing-poor-performing-queries) to measure execution times for your queries to ensure they are within expected ranges. For enterprise applications, contact [enterprise@supabase.io](mailto:enterprise@supabase.io).

For data sources other than Postgres, see [Foreign Data Wrappers](https://supabase.com/docs/guides/database/extensions/wrappers/overview) for a list of external sources supported today. If your data lives in a source not provided in the list, contact [support](https://supabase.com/dashboard/support/new) and we'll be happy to discuss your use case.

Let's assume your external DB contains a `users` and `documents` table like this:

`
create table public.users (
id bigint primary key generated always as identity,
email text not null,
created_at timestamp with time zone not null default now()
);
create table public.documents (
id bigint primary key generated always as identity,
name text not null,
owner_id bigint not null references public.users (id),
created_at timestamp with time zone not null default now()
);
`

In your Supabase DB, let's create foreign tables that link to the above tables:

`
create schema external;
create extension postgres_fdw with schema extensions;
-- Setup the foreign server
create server foreign_server
foreign data wrapper postgres_fdw
options (host '<db-host>', port '<db-port>', dbname '<db-name>');
-- Map local 'authenticated' role to external 'postgres' user
create user mapping for authenticated
server foreign_server
options (user 'postgres', password '<user-password>');
-- Import foreign 'users' and 'documents' tables into 'external' schema
import foreign schema public limit to (users, documents)
from server foreign_server into external;
`

This example maps the `authenticated` role in Supabase to the `postgres` user in the external DB. In production, it's best to create a custom user on the external DB that has the minimum permissions necessary to access the information you need.

On the Supabase DB, we use the built-in `authenticated` role which is automatically used when end users make authenticated requests over your auto-generated REST API. If you plan to connect to your Supabase DB over a direct Postgres connection instead of the REST API, you can change this to any user you like. See [Direct Postgres Connection](https://supabase.com/docs/guides/ai/rag-with-permissions#direct-postgres-connection) for more info.

We'll store `document_sections` and their embeddings in Supabase so that we can perform similarity search over them via pgvector.

`
create table document_sections (
id bigint primary key generated always as identity,
document_id bigint not null,
content text not null,
embedding vector (384)
);
`

We maintain a reference to the foreign document via `document_id`, but without a foreign key reference since foreign keys can only be added to local tables. Be sure to use the same ID data type that you use on your external documents table.

Since we're managing users and authentication outside of Supabase, we have two options:

1. Make a direct Postgres connection to the Supabase DB and set the current user every request
2. Issue a custom JWT from your system and use it to authenticate with the REST API

#### Direct Postgres connection [\#](https://supabase.com/docs/guides/ai/rag-with-permissions\#direct-postgres-connection)

You can directly connect to your Supabase Postgres DB using the [connection info](https://supabase.com/dashboard/project/_/settings/database) on your project's database settings page. To use RLS with this method, we use a custom session variable that contains the current user's ID:

`
-- enable row level security
alter table document_sections enable row level security;
-- setup RLS for select operations
create policy "Users can query their own document sections"
on document_sections for select to authenticated using (
document_id in (
    select id
    from external.documents
    where owner_id = current_setting('app.current_user_id')::bigint
)
);
`

The session variable is accessed through the `current_setting()` function. We name the variable `app.current_user_id` here, but you can modify this to any name you like. We also cast it to a `bigint` since that was the data type of the `user.id` column. Change this to whatever data type you use for your ID.

Now for every request, we set the user's ID at the beginning of the session:

`
set app.current_user_id = '<current-user-id>';
`

Then all subsequent queries will inherit the permission of that user:

`
-- Only document sections owned by the user are returned
select *
from document_sections
where document_sections.embedding <#> embedding < -match_threshold
order by document_sections.embedding <#> embedding;
`

You might be tempted to discard RLS completely and simply filter by user within the `where` clause. Though this will work, we recommend RLS as a general best practice since RLS is always applied even as new queries and application logic is introduced in the future.

#### Custom JWT with REST API [\#](https://supabase.com/docs/guides/ai/rag-with-permissions\#custom-jwt-with-rest-api)

If you would like to use the auto-generated REST API to query your Supabase database using JWTs from an external auth provider, you can get your auth provider to issue a custom JWT for Supabase.

See the [Clerk Supabase docs](https://clerk.com/docs/integrations/databases/supabase) for an example of how this can be done. Modify the instructions to work with your own auth provider as needed.

Now we can use the same RLS policy from our first example:

`
-- enable row level security
alter table document_sections enable row level security;
-- setup RLS for select operations
create policy "Users can query their own document sections"
on document_sections for select to authenticated using (
document_id in (
    select id
    from documents
    where (owner_id = (select auth.uid()))
)
);
`

Under the hood, `auth.uid()` references `current_setting('request.jwt.claim.sub')` which corresponds to the JWT's `sub` (subject) claim. This setting is automatically set at the beginning of each request to the REST API.

All subsequent queries will inherit the permission of that user:

`
-- Only document sections owned by the user are returned
select *
from document_sections
where document_sections.embedding <#> embedding < -match_threshold
order by document_sections.embedding <#> embedding;
`

### Other scenarios [\#](https://supabase.com/docs/guides/ai/rag-with-permissions\#other-scenarios)

There are endless approaches to this problem based on the complexities of each system. Luckily Postgres comes with all the primitives needed to provide access control in the way that works best for your project.

If the examples above didn't fit your use case or you need to adjust them slightly to better fit your existing system, feel free to reach out to [support](https://supabase.com/dashboard/support/new) and we'll be happy to assist you.

### Is this helpful?

NoYes

### On this page

[Example](https://supabase.com/docs/guides/ai/rag-with-permissions#example) [Alternative scenarios](https://supabase.com/docs/guides/ai/rag-with-permissions#alternative-scenarios) [Documents owned by multiple people](https://supabase.com/docs/guides/ai/rag-with-permissions#documents-owned-by-multiple-people) [User and document data live outside of Supabase](https://supabase.com/docs/guides/ai/rag-with-permissions#user-and-document-data-live-outside-of-supabase) [Other scenarios](https://supabase.com/docs/guides/ai/rag-with-permissions#other-scenarios)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_semantic_search.md">
AI & Vectors

# Semantic search

## Learn how to search by meaning rather than exact keywords.

* * *

Semantic search interprets the meaning behind user queries rather than exact [keywords](https://supabase.com/docs/guides/ai/keyword-search). It uses machine learning to capture the intent and context behind the query, handling language nuances like synonyms, phrasing variations, and word relationships.

## When to use semantic search [\#](https://supabase.com/docs/guides/ai/semantic-search\#when-to-use-semantic-search)

Semantic search is useful in applications where the depth of understanding and context is important for delivering relevant results. A good example is in customer support or knowledge base search engines. Users often phrase their problems or questions in various ways, and a traditional keyword-based search might not always retrieve the most helpful documents. With semantic search, the system can understand the meaning behind the queries and match them with relevant solutions or articles, even if the exact wording differs.

For instance, a user searching for "increase text size on display" might miss articles titled "How to adjust font size in settings" in a keyword-based search system. However, a semantic search engine would understand the intent behind the query and correctly match it to relevant articles, regardless of the specific terminology used.

It's also possible to combine semantic search with keyword search to get the best of both worlds. See [Hybrid search](https://supabase.com/docs/guides/ai/hybrid-search) for more details.

## How semantic search works [\#](https://supabase.com/docs/guides/ai/semantic-search\#how-semantic-search-works)

Semantic search uses an intermediate representation called an embedding vector to link database records with search queries. A vector, in the context of semantic search, is a list of numerical values. They represent various features of the text and allow for the semantic comparison between different pieces of text.

The best way to think of embeddings is by plotting them on a graph, where each embedding is a single point whose coordinates are the numerical values within its vector. Importantly, embeddings are plotted such that similar concepts are positioned close together while dissimilar concepts are far apart. For more details, see [What are embeddings?](https://supabase.com/docs/guides/ai/concepts#what-are-embeddings)

Embeddings are generated using a language model, and embeddings are compared to each other using a similarity metric. The language model is trained to understand the semantics of language, including syntax, context, and the relationships between words. It generates embeddings for both the content in the database and the search queries. Then the similarity metric, often a function like cosine similarity or dot product, is used to compare the query embeddings with the document embeddings (in other words, to measure how close they are to each other on the graph). The documents with embeddings most similar to the query's are deemed the most relevant and are returned as search results.

## Embedding models [\#](https://supabase.com/docs/guides/ai/semantic-search\#embedding-models)

There are many embedding models available today. Supabase Edge Functions has [built in support](https://supabase.com/docs/guides/functions/examples/semantic-search) for the `gte-small` model. Others can be accessed through third-party APIs like [OpenAI](https://platform.openai.com/docs/guides/embeddings), where you send your text in the request and receive an embedding vector in the response. Others can run locally on your own compute, such as through Transformers.js for JavaScript implementations. For more information on local implementation, see [Generate embeddings](https://supabase.com/docs/guides/ai/quickstarts/generate-text-embeddings).

It's crucial to remember that when using embedding models with semantic search, you must use the same model for all embedding comparisons. Comparing embeddings created by different models will yield meaningless results.

## Semantic search in Postgres [\#](https://supabase.com/docs/guides/ai/semantic-search\#semantic-search-in-postgres)

To implement semantic search in Postgres we use `pgvector` \- an extension that allows for efficient storage and retrieval of high-dimensional vectors. These vectors are numerical representations of text (or other types of data) generated by embedding models.

1. Enable the `pgvector` extension by running:



`
create extension vector
with
schema extensions;
`

2. Create a table to store the embeddings:



`
create table documents (
id bigint primary key generated always as identity,
content text,
embedding vector(512)
);
`



Or if you have an existing table, you can add a vector column like so:



`
alter table documents
add column embedding vector(512);
`



In this example, we create a column named `embedding` which uses the newly enabled `vector` data type. The size of the vector (as indicated in parentheses) represents the number of dimensions in the embedding. Here we use 512, but adjust this to match the number of dimensions produced by your embedding model.


For more details on vector columns, including how to generate embeddings and store them, see [Vector columns](https://supabase.com/docs/guides/ai/vector-columns).

### Similarity metric [\#](https://supabase.com/docs/guides/ai/semantic-search\#similarity-metric)

`pgvector` support 3 operators for computing distance between embeddings:

| **Operator** | **Description** |
| --- | --- |
| `<->` | Euclidean distance |
| `<#>` | negative inner product |
| `<=>` | cosine distance |

These operators are used directly in your SQL query to retrieve records that are most similar to the user's search query. Choosing the right operator depends on your needs. Inner product (also known as dot product) tends to be the fastest if your vectors are normalized.

The easiest way to perform semantic search in Postgres is by creating a function:

`
-- Match documents using cosine distance (<=>)
create or replace function match_documents (
query_embedding vector(512),
match_threshold float,
match_count int
)
returns setof documents
language sql
as $$
select *
from documents
where documents.embedding <=> query_embedding < 1 - match_threshold
order by documents.embedding <=> query_embedding asc
limit least(match_count, 200);
$$;
`

Here we create a function `match_documents` that accepts three parameters:

1. `query_embedding`: a one-time embedding generated for the user's search query. Here we set the size to 512, but adjust this to match the number of dimensions produced by your embedding model.
2. `match_threshold`: the minimum similarity between embeddings. This is a value between 1 and -1, where 1 is most similar and -1 is most dissimilar.
3. `match_count`: the maximum number of results to return. Note the query may return less than this number if `match_threshold` resulted in a small shortlist. Limited to 200 records to avoid unintentionally overloading your database.

In this example, we return a `setof documents` and refer to `documents` throughout the query. Adjust this to use the relevant tables in your application.

You'll notice we are using the cosine distance ( `<=>`) operator in our query. Cosine distance is a safe default when you don't know whether or not your embeddings are normalized. If you know for a fact that they are normalized (for example, your embedding is returned from OpenAI), you can use negative inner product ( `<#>`) for better performance:

`
-- Match documents using negative inner product (<#>)
create or replace function match_documents (
query_embedding vector(512),
match_threshold float,
match_count int
)
returns setof documents
language sql
as $$
select *
from documents
where documents.embedding <#> query_embedding < -match_threshold
order by documents.embedding <#> query_embedding asc
limit least(match_count, 200);
$$;
`

Note that since `<#>` is negative, we negate `match_threshold` accordingly in the `where` clause. For more information on the different operators, see the [pgvector docs](https://github.com/pgvector/pgvector?tab=readme-ov-file#vector-operators).

### Calling from your application [\#](https://supabase.com/docs/guides/ai/semantic-search\#calling-from-your-application)

Finally you can execute this function from your application. If you are using a Supabase client library such as [`supabase-js`](https://github.com/supabase/supabase-js), you can invoke it using the `rpc()` method:

`
const { data: documents } = await supabase.rpc('match_documents', {
query_embedding: embedding, // pass the query embedding
match_threshold: 0.78, // choose an appropriate threshold for your data
match_count: 10, // choose the number of matches
})
`

You can also call this method directly from SQL:

`
select *
from match_documents(
'[...]'::vector(512), -- pass the query embedding
0.78, -- chose an appropriate threshold for your data
10 -- choose the number of matches
);
`

In this scenario, you'll likely use a Postgres client library to establish a direct connection from your application to the database. It's best practice to parameterize your arguments before executing the query.

## Next steps [\#](https://supabase.com/docs/guides/ai/semantic-search\#next-steps)

As your database scales, you will need an index on your vector columns to maintain fast query speeds. See [Vector indexes](https://supabase.com/docs/guides/ai/vector-indexes) for an in-depth guide on the different types of indexes and how they work.

## See also [\#](https://supabase.com/docs/guides/ai/semantic-search\#see-also)

- [Embedding concepts](https://supabase.com/docs/guides/ai/concepts)
- [Vector columns](https://supabase.com/docs/guides/ai/vector-columns)
- [Vector indexes](https://supabase.com/docs/guides/ai/vector-indexes)
- [Hybrid search](https://supabase.com/docs/guides/ai/hybrid-search)
- [Keyword search](https://supabase.com/docs/guides/ai/keyword-search)

### Is this helpful?

NoYes

### On this page

[When to use semantic search](https://supabase.com/docs/guides/ai/semantic-search#when-to-use-semantic-search) [How semantic search works](https://supabase.com/docs/guides/ai/semantic-search#how-semantic-search-works) [Embedding models](https://supabase.com/docs/guides/ai/semantic-search#embedding-models) [Semantic search in Postgres](https://supabase.com/docs/guides/ai/semantic-search#semantic-search-in-postgres) [Similarity metric](https://supabase.com/docs/guides/ai/semantic-search#similarity-metric) [Calling from your application](https://supabase.com/docs/guides/ai/semantic-search#calling-from-your-application) [Next steps](https://supabase.com/docs/guides/ai/semantic-search#next-steps) [See also](https://supabase.com/docs/guides/ai/semantic-search#see-also)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_structured_unstructured.md">
AI & Vectors

# Structured and Unstructured

## Supabase is flexible enough to associate structured and unstructured metadata with embeddings.

* * *

Most vector stores treat metadata associated with embeddings like NoSQL, unstructured data. Supabase is flexible enough to store unstructured and structured metadata.

## Structured [\#](https://supabase.com/docs/guides/ai/structured-unstructured\#structured)

`
create table docs (
id uuid primary key,
embedding vector(3),
content text,
url text
);
insert into docs
(id, embedding, content, url)
values
('79409372-7556-4ccc-ab8f-5786a6cfa4f7', array[0.1, 0.2, 0.3], 'Hello world', '/hello-world');
`

Notice that we've associated two pieces of metadata, `content` and `url`, with the embedding. Those fields can be filtered, constrained, indexed, and generally operated on using the full power of SQL. Structured metadata fits naturally with a traditional Supabase application, and can be managed via database [migrations](https://supabase.com/docs/guides/deployment/database-migrations).

## Unstructured [\#](https://supabase.com/docs/guides/ai/structured-unstructured\#unstructured)

`
create table docs (
id uuid primary key,
embedding vector(3),
meta jsonb
);
insert into docs
(id, embedding, meta)
values
(
    '79409372-7556-4ccc-ab8f-5786a6cfa4f7',
    array[0.1, 0.2, 0.3],
    '{"content": "Hello world", "url": "/hello-world"}'
);
`

An unstructured approach does not specify the metadata fields that are expected. It stores all metadata in a flexible `json`/ `jsonb` column. The tradeoff is that the querying/filtering capabilities of a schemaless data type are less flexible than when each field has a dedicated column. It also pushes the burden of metadata data integrity onto application code, which is more error prone than enforcing constraints in the database.

The unstructured approach is recommended:

- for ephemeral/interactive workloads e.g. data science or scientific research
- when metadata fields are user-defined or unknown
- during rapid prototyping

Client libraries like python's [vecs](https://github.com/supabase/vecs) use this structure. For example, running:

`
#!/usr/bin/env python3
import vecs
# In practice, do not hard-code your password. Use environment variables.
DB_CONNECTION = "postgresql://<user>:<password>@<host>:<port>/<db_name>"
# create vector store client
vx = vecs.create_client(DB_CONNECTION)
docs = vx.get_or_create_collection(name="docs", dimension=1536)
docs.upsert(vectors=[\
('79409372-7556-4ccc-ab8f-5786a6cfa4f7', [100, 200, 300], { url: '/hello-world' })\
])
`

automatically creates the unstructured SQL table during the call to `get_or_create_collection`.

Note that when working with client libraries that emit SQL DDL, like `create table ...`, you should add that SQL to your migrations when moving to production to maintain a single source of truth for your database's schema.

## Hybrid [\#](https://supabase.com/docs/guides/ai/structured-unstructured\#hybrid)

The structured metadata style is recommended when the fields being tracked are known in advance. If you have a combination of known and unknown metadata fields, you can accommodate the unknown fields by adding a `json`/ `jsonb` column to the table. In that situation, known fields should continue to use dedicated columns for best query performance and throughput.

`
create table docs (
id uuid primary key,
embedding vector(3),
content text,
url string,
meta jsonb
);
insert into docs
(id, embedding, content, url, meta)
values
(
    '79409372-7556-4ccc-ab8f-5786a6cfa4f7',
    array[0.1, 0.2, 0.3],
    'Hello world',
    '/hello-world',
    '{"key": "value"}'
);
`

## Choosing the right model [\#](https://supabase.com/docs/guides/ai/structured-unstructured\#choosing-the-right-model)

Both approaches create a table where you can store your embeddings and some metadata. You should choose the best approach for your use-case. In summary:

- Structured metadata is best when fields are known in advance or query patterns are predictable e.g. a production Supabase application
- Unstructured metadata is best when fields are unknown/user-defined or when working with data interactively e.g. exploratory research

Both approaches are valid, and the one you should choose depends on your use-case.

### Is this helpful?

NoYes

### On this page

[Structured](https://supabase.com/docs/guides/ai/structured-unstructured#structured) [Unstructured](https://supabase.com/docs/guides/ai/structured-unstructured#unstructured) [Hybrid](https://supabase.com/docs/guides/ai/structured-unstructured#hybrid) [Choosing the right model](https://supabase.com/docs/guides/ai/structured-unstructured#choosing-the-right-model)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_vecs_python_client.md">
AI & Vectors

# Python client

## Manage unstructured vector stores in PostgreSQL.

* * *

Supabase provides a Python client called [`vecs`](https://github.com/supabase/vecs) for managing unstructured vector stores. This client provides a set of useful tools for creating and querying collections in Postgres using the [pgvector](https://supabase.com/docs/guides/database/extensions/pgvector) extension.

## Quick start [\#](https://supabase.com/docs/guides/ai/vecs-python-client\#quick-start)

Let's see how Vecs works using a local database. Make sure you have the Supabase CLI [installed](https://supabase.com/docs/guides/cli#installation) on your machine.

### Initialize your project [\#](https://supabase.com/docs/guides/ai/vecs-python-client\#initialize-your-project)

Start a local Postgres instance in any folder using the `init` and `start` commands. Make sure you have Docker running!

`
# Initialize your project
supabase init
# Start Postgres
supabase start
`

### Create a collection [\#](https://supabase.com/docs/guides/ai/vecs-python-client\#create-a-collection)

Inside a Python shell, run the following commands to create a new collection called "docs", with 3 dimensions.

`
import vecs
# create vector store client
vx = vecs.create_client("postgresql://postgres:postgres@localhost:54322/postgres")
# create a collection of vectors with 3 dimensions
docs = vx.get_or_create_collection(name="docs", dimension=3)
`

### Add embeddings [\#](https://supabase.com/docs/guides/ai/vecs-python-client\#add-embeddings)

Now we can insert some embeddings into our "docs" collection using the `upsert()` command:

`
import vecs
# create vector store client
docs = vecs.get_or_create_collection(name="docs", dimension=3)
# a collection of vectors with 3 dimensions
vectors=[\
("vec0", [0.1, 0.2, 0.3], {"year": 1973}),\
("vec1", [0.7, 0.8, 0.9], {"year": 2012})\
]
# insert our vectors
docs.upsert(vectors=vectors)
`

### Query the collection [\#](https://supabase.com/docs/guides/ai/vecs-python-client\#query-the-collection)

You can now query the collection to retrieve a relevant match:

`
import vecs
docs = vecs.get_or_create_collection(name="docs", dimension=3)
# query the collection filtering metadata for "year" = 2012
docs.query(
    data=[0.4,0.5,0.6],      # required
    limit=1,                         # number of records to return
    filters={"year": {"$eq": 2012}}, # metadata filters
)
`

## Deep dive [\#](https://supabase.com/docs/guides/ai/vecs-python-client\#deep-dive)

For a more in-depth guide on `vecs` collections, see [API](https://supabase.com/docs/guides/ai/python/api).

## Resources [\#](https://supabase.com/docs/guides/ai/vecs-python-client\#resources)

- Official Vecs Documentation: [https://supabase.github.io/vecs/api](https://supabase.github.io/vecs/api)
- Source Code: [https://github.com/supabase/vecs](https://github.com/supabase/vecs)

### Is this helpful?

NoYes

### On this page

[Quick start](https://supabase.com/docs/guides/ai/vecs-python-client#quick-start) [Initialize your project](https://supabase.com/docs/guides/ai/vecs-python-client#initialize-your-project) [Create a collection](https://supabase.com/docs/guides/ai/vecs-python-client#create-a-collection) [Add embeddings](https://supabase.com/docs/guides/ai/vecs-python-client#add-embeddings) [Query the collection](https://supabase.com/docs/guides/ai/vecs-python-client#query-the-collection) [Deep dive](https://supabase.com/docs/guides/ai/vecs-python-client#deep-dive) [Resources](https://supabase.com/docs/guides/ai/vecs-python-client#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_vector_columns.md">
AI & Vectors

# Vector columns

* * *

Supabase offers a number of different ways to store and query vectors within Postgres. The SQL included in this guide is applicable for clients in all programming languages. If you are a Python user see your [Python client options](https://supabase.com/docs/guides/ai/python-clients) after reading the `Learn` section.

Vectors in Supabase are enabled via [pgvector](https://github.com/pgvector/pgvector/), a Postgres extension for storing and querying vectors in Postgres. It can be used to store [embeddings](https://supabase.com/docs/guides/ai/concepts#what-are-embeddings).

## Usage [\#](https://supabase.com/docs/guides/ai/vector-columns\#usage)

### Enable the extension [\#](https://supabase.com/docs/guides/ai/vector-columns\#enable-the-extension)

DashboardSQL

1. Go to the [Database](https://supabase.com/dashboard/project/_/database/tables) page in the Dashboard.
2. Click on **Extensions** in the sidebar.
3. Search for "vector" and enable the extension.

### Create a table to store vectors [\#](https://supabase.com/docs/guides/ai/vector-columns\#create-a-table-to-store-vectors)

After enabling the `vector` extension, you will get access to a new data type called `vector`. The size of the vector (indicated in parenthesis) represents the number of dimensions stored in that vector.

`
create table documents (
id serial primary key,
title text not null,
body text not null,
embedding vector(384)
);
`

In the above SQL snippet, we create a `documents` table with a column called `embedding` (note this is just a regular Postgres column - you can name it whatever you like). We give the `embedding` column a `vector` data type with 384 dimensions. Change this to the number of dimensions produced by your embedding model. For example, if you are [generating embeddings](https://supabase.com/docs/guides/ai/quickstarts/generate-text-embeddings) using the open source [`gte-small`](https://huggingface.co/Supabase/gte-small) model, you would set this number to 384 since that model produces 384 dimensions.

In general, embeddings with fewer dimensions perform best. See our [analysis on fewer dimensions in pgvector](https://supabase.com/blog/fewer-dimensions-are-better-pgvector).

### Storing a vector / embedding [\#](https://supabase.com/docs/guides/ai/vector-columns\#storing-a-vector--embedding)

In this example we'll generate a vector using Transformers.js, then store it in the database using the Supabase JavaScript client.

`
import { pipeline } from '@xenova/transformers'
const generateEmbedding = await pipeline('feature-extraction', 'Supabase/gte-small')
const title = 'First post!'
const body = 'Hello world!'
// Generate a vector using Transformers.js
const output = await generateEmbedding(body, {
pooling: 'mean',
normalize: true,
})
// Extract the embedding output
const embedding = Array.from(output.data)
// Store the vector in Postgres
const { data, error } = await supabase.from('documents').insert({
title,
body,
embedding,
})
`

This example uses the JavaScript Supabase client, but you can modify it to work with any [supported language library](https://supabase.com/docs#client-libraries).

### Querying a vector / embedding [\#](https://supabase.com/docs/guides/ai/vector-columns\#querying-a-vector--embedding)

Similarity search is the most common use case for vectors. `pgvector` support 3 new operators for computing distance:

| Operator | Description |
| --- | --- |
| `<->` | Euclidean distance |
| `<#>` | negative inner product |
| `<=>` | cosine distance |

Choosing the right operator depends on your needs. Dot product tends to be the fastest if your vectors are normalized. For more information on how embeddings work and how they relate to each other, see [What are Embeddings?](https://supabase.com/docs/guides/ai/concepts#what-are-embeddings).

Supabase client libraries like `supabase-js` connect to your Postgres instance via [PostgREST](https://supabase.com/docs/guides/getting-started/architecture#postgrest-api). PostgREST does not currently support `pgvector` similarity operators, so we'll need to wrap our query in a Postgres function and call it via the `rpc()` method:

`
create or replace function match_documents (
query_embedding vector(384),
match_threshold float,
match_count int
)
returns table (
id bigint,
title text,
body text,
similarity float
)
language sql stable
as $$
select
    documents.id,
    documents.title,
    documents.body,
    1 - (documents.embedding <=> query_embedding) as similarity
from documents
where 1 - (documents.embedding <=> query_embedding) > match_threshold
order by (documents.embedding <=> query_embedding) asc
limit match_count;
$$;
`

This function takes a `query_embedding` argument and compares it to all other embeddings in the `documents` table. Each comparison returns a similarity score. If the similarity is greater than the `match_threshold` argument, it is returned. The number of rows returned is limited by the `match_count` argument.

Feel free to modify this method to fit the needs of your application. The `match_threshold` ensures that only documents that have a minimum similarity to the `query_embedding` are returned. Without this, you may end up returning documents that subjectively don't match. This value will vary for each application - you will need to perform your own testing to determine the threshold that makes sense for your app.

If you index your vector column, ensure that the `order by` sorts by the distance function directly (rather than sorting by the calculated `similarity` column, which may lead to the index being ignored and poor performance).

To execute the function from your client library, call `rpc()` with the name of your Postgres function:

`
const { data: documents } = await supabaseClient.rpc('match_documents', {
query_embedding: embedding, // Pass the embedding you want to compare
match_threshold: 0.78, // Choose an appropriate threshold for your data
match_count: 10, // Choose the number of matches
})
`

In this example `embedding` would be another embedding you wish to compare against your table of pre-generated embedding documents. For example if you were building a search engine, every time the user submits their query you would first generate an embedding on the search query itself, then pass it into the above `rpc()` function to match.

Be sure to use embeddings produced from the same embedding model when calculating distance. Comparing embeddings from two different models will produce no meaningful result.

Vectors and embeddings can be used for much more than search. Learn more about embeddings at [What are Embeddings?](https://supabase.com/docs/guides/ai/concepts#what-are-embeddings).

### Indexes [\#](https://supabase.com/docs/guides/ai/vector-columns\#indexes)

Once your vector table starts to grow, you will likely want to add an index to speed up queries. See [Vector indexes](https://supabase.com/docs/guides/ai/vector-indexes) to learn how vector indexes work and how to create them.

### Is this helpful?

NoYes

### On this page

[Usage](https://supabase.com/docs/guides/ai/vector-columns#usage) [Enable the extension](https://supabase.com/docs/guides/ai/vector-columns#enable-the-extension) [Create a table to store vectors](https://supabase.com/docs/guides/ai/vector-columns#create-a-table-to-store-vectors) [Storing a vector / embedding](https://supabase.com/docs/guides/ai/vector-columns#storing-a-vector--embedding) [Querying a vector / embedding](https://supabase.com/docs/guides/ai/vector-columns#querying-a-vector--embedding) [Indexes](https://supabase.com/docs/guides/ai/vector-columns#indexes)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_vector_indexes_hnsw_indexes.md">
AI & Vectors

# HNSW indexes

* * *

HNSW is an algorithm for approximate nearest neighbor search. It is a frequently used index type that can improve performance when querying highly-dimensional vectors, like those representing embeddings.

## Usage [\#](https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes\#usage)

The way you create an HNSW index depends on the distance operator you are using. `pgvector` includes 3 distance operators:

| Operator | Description | [**Operator class**](https://www.postgresql.org/docs/current/sql-createopclass.html) |
| --- | --- | --- |
| `<->` | Euclidean distance | `vector_l2_ops` |
| `<#>` | negative inner product | `vector_ip_ops` |
| `<=>` | cosine distance | `vector_cosine_ops` |

Use the following SQL commands to create an HNSW index for the operator(s) used in your queries.

### Euclidean L2 distance ( `vector_l2_ops`) [\#](https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes\#euclidean-l2-distance--vectorl2ops-)

`
create index on items using hnsw (column_name vector_l2_ops);
`

### Inner product ( `vector_ip_ops`) [\#](https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes\#inner-product--vectoripops-)

`
create index on items using hnsw (column_name vector_ip_ops);
`

### Cosine distance ( `vector_cosine_ops`) [\#](https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes\#cosine-distance--vectorcosineops-)

`
create index on items using hnsw (column_name vector_cosine_ops);
`

Currently vectors with up to 2,000 dimensions can be indexed.

## How does HNSW work? [\#](https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes\#how-does-hnsw-work)

HNSW uses proximity graphs (graphs connecting nodes based on distance between them) to approximate nearest-neighbor search. To understand HNSW, we can break it down into 2 parts:

- **Hierarchical (H):** The algorithm operates over multiple layers
- **Navigable Small World (NSW):** Each vector is a node within a graph and is connected to several other nodes

### Hierarchical [\#](https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes\#hierarchical)

The hierarchical aspect of HNSW builds off of the idea of skip lists.

Skip lists are multi-layer linked lists. The bottom layer is a regular linked list connecting an ordered sequence of elements. Each new layer above removes some elements from the underlying layer (based on a fixed probability), producing a sparser subsequence that skips over elements.

![visual of an example skip list](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fai%2Fvector-indexes%2Fhnsw-indexes%2Fskip-list--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

When searching for an element, the algorithm begins at the top layer and traverses its linked list horizontally. If the target element is found, the algorithm stops and returns it. Otherwise if the next element in the list is greater than the target (or `NULL`), the algorithm drops down to the next layer below. Since each layer below is less sparse than the layer above (with the bottom layer connecting all elements), the target will eventually be found. Skip lists offer O(log n) average complexity for both search and insertion/deletion.

### Navigable Small World [\#](https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes\#navigable-small-world)

A navigable small world (NSW) is a special type of proximity graph that also includes long-range connections between nodes. These long-range connections support the small world property of the graph, meaning almost every node can be reached from any other node within a few hops. Without these additional long-range connections, many hops would be required to reach a far-away node.

![visual of an example navigable small world graph](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fai%2Fvector-indexes%2Fhnsw-indexes%2Fnsw.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

The navigable part of NSW specifically refers to the ability to logarithmically scale the greedy search algorithm on the graph, an algorithm that attempts to make only the locally optimal choice at each hop. Without this property, the graph may still be considered a small world with short paths between far-away nodes, but the greedy algorithm tends to miss them. Greedy search is ideal for NSW because it is quick to navigate and has low computational costs.

### **Hierarchical +** Navigable Small World [\#](https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes\#hierarchical--navigable-small-world)

HNSW combines these two concepts. From the hierarchical perspective, the bottom layer consists of a NSW made up of short links between nodes. Each layer above skips elements and creates longer links between nodes further away from each other.

Just like skip lists, search starts at the top layer and works its way down until it finds the target element. However, instead of comparing a scalar value at each layer to determine whether or not to descend to the layer below, a multi-dimensional distance measure (such as Euclidean distance) is used.

## When should you create HNSW indexes? [\#](https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes\#when-should-you-create-hnsw-indexes)

HNSW should be your default choice when creating a vector index. Add the index when you don't need 100% accuracy and are willing to trade a small amount of accuracy for a lot of throughput.

Unlike IVFFlat indexes, you are safe to build an HNSW index immediately after the table is created. HNSW indexes are based on graphs which inherently are not affected by the same limitations as IVFFlat. As new data is added to the table, the index will be filled automatically and the index structure will remain optimal.

## Resources [\#](https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes\#resources)

Read more about indexing on `pgvector`'s [GitHub page](https://github.com/pgvector/pgvector#indexing).

### Is this helpful?

NoYes

### On this page

[Usage](https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes#usage) [Euclidean L2 distance (vector\_l2\_ops)](https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes#euclidean-l2-distance--vectorl2ops-) [Inner product (vector\_ip\_ops)](https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes#inner-product--vectoripops-) [Cosine distance (vector\_cosine\_ops)](https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes#cosine-distance--vectorcosineops-) [How does HNSW work?](https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes#how-does-hnsw-work) [Hierarchical](https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes#hierarchical) [Navigable Small World](https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes#navigable-small-world) [Hierarchical + Navigable Small World](https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes#hierarchical--navigable-small-world) [When should you create HNSW indexes?](https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes#when-should-you-create-hnsw-indexes) [Resources](https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes#resources)

![visual of an example navigable small world graph](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fai%2Fvector-indexes%2Fhnsw-indexes%2Fnsw.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_vector_indexes_ivf_indexes.md">
AI & Vectors

# IVFFlat indexes

* * *

IVFFlat is a type of vector index for approximate nearest neighbor search. It is a frequently used index type that can improve performance when querying highly-dimensional vectors, like those representing embeddings.

## Choosing an index [\#](https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes\#choosing-an-index)

Today `pgvector` supports two types of indexes:

- [HNSW](https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes)
- [IVFFlat](https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes)

In general we recommend using [HNSW](https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes) because of its [performance](https://supabase.com/blog/increase-performance-pgvector-hnsw#hnsw-performance-1536-dimensions) and [robustness against changing data](https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes#when-should-you-create-hnsw-indexes). If you have a special use case that requires IVFFlat instead, keep reading.

## Usage [\#](https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes\#usage)

The way you create an IVFFlat index depends on the distance operator you are using. `pgvector` includes 3 distance operators:

| Operator | Description | [**Operator class**](https://www.postgresql.org/docs/current/sql-createopclass.html) |
| --- | --- | --- |
| `<->` | Euclidean distance | `vector_l2_ops` |
| `<#>` | negative inner product | `vector_ip_ops` |
| `<=>` | cosine distance | `vector_cosine_ops` |

Use the following SQL commands to create an IVFFlat index for the operator(s) used in your queries.

### Euclidean L2 distance ( `vector_l2_ops`) [\#](https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes\#euclidean-l2-distance--vectorl2ops-)

`
create index on items using ivfflat (column_name vector_l2_ops) with (lists = 100);
`

### Inner product ( `vector_ip_ops`) [\#](https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes\#inner-product--vectoripops-)

`
create index on items using ivfflat (column_name vector_ip_ops) with (lists = 100);
`

### Cosine distance ( `vector_cosine_ops`) [\#](https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes\#cosine-distance--vectorcosineops-)

`
create index on items using ivfflat (column_name vector_cosine_ops) with (lists = 100);
`

Currently vectors with up to 2,000 dimensions can be indexed.

## How does IVFFlat work? [\#](https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes\#how-does-ivfflat-work)

IVF stands for 'inverted file indexes'. It works by clustering your vectors in order to reduce the similarity search scope. Rather than comparing a vector to every other vector, the vector is only compared against vectors within the same cell cluster (or nearby clusters, depending on your configuration).

### Inverted lists (cell clusters) [\#](https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes\#inverted-lists-cell-clusters)

When you create the index, you choose the number of inverted lists (cell clusters). Increase this number to speed up queries, but at the expense of recall.

For example, to create an index with 100 lists on a column that uses the cosine operator:

`
create index on items using ivfflat (column_name vector_cosine_ops) with (lists = 100);
`

For more info on the different operators, see [Distance operations](https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes#distance-operators).

For every query, you can set the number of probes (1 by default). The number of probes corresponds to the number of nearby cells to probe for a match. Increase this for better recall at the expense of speed.

To set the number of probes for the duration of the session run:

`
set ivfflat.probes = 10;
`

To set the number of probes only for the current transaction run:

`
begin;
set local ivfflat.probes = 10;
select ...
commit;
`

If the number of probes is the same as the number of lists, exact nearest neighbor search will be performed and the planner won't use the index.

### Approximate nearest neighbor [\#](https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes\#approximate-nearest-neighbor)

One important note with IVF indexes is that nearest neighbor search is approximate, since exact search on high dimensional data can't be indexed efficiently. This means that similarity results will change (slightly) after you add an index (trading recall for speed).

## When should you create IVFFlat indexes? [\#](https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes\#when-should-you-create-ivfflat-indexes)

`pgvector` recommends building IVFFlat indexes only after the table has sufficient data, so that the internal IVFFlat cell clusters are based on your data's distribution. Anytime the distribution changes significantly, consider rebuilding indexes.

## Resources [\#](https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes\#resources)

Read more about indexing on `pgvector`'s [GitHub page](https://github.com/pgvector/pgvector#indexing).

### Is this helpful?

NoYes

### On this page

[Choosing an index](https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes#choosing-an-index) [Usage](https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes#usage) [Euclidean L2 distance (vector\_l2\_ops)](https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes#euclidean-l2-distance--vectorl2ops-) [Inner product (vector\_ip\_ops)](https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes#inner-product--vectoripops-) [Cosine distance (vector\_cosine\_ops)](https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes#cosine-distance--vectorcosineops-) [How does IVFFlat work?](https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes#how-does-ivfflat-work) [Inverted lists (cell clusters)](https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes#inverted-lists-cell-clusters) [Approximate nearest neighbor](https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes#approximate-nearest-neighbor) [When should you create IVFFlat indexes?](https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes#when-should-you-create-ivfflat-indexes) [Resources](https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai_vector_indexes.md">
AI & Vectors

# Vector indexes

* * *

Once your vector table starts to grow, you will likely want to add an index to speed up queries. Without indexes, you'll be performing a sequential scan which can be a resource-intensive operation when you have many records.

## Choosing an index [\#](https://supabase.com/docs/guides/ai/vector-indexes\#choosing-an-index)

Today `pgvector` supports two types of indexes:

- [HNSW](https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes)
- [IVFFlat](https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes)

In general we recommend using [HNSW](https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes) because of its [performance](https://supabase.com/blog/increase-performance-pgvector-hnsw#hnsw-performance-1536-dimensions) and [robustness against changing data](https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes#when-should-you-create-hnsw-indexes).

## Distance operators [\#](https://supabase.com/docs/guides/ai/vector-indexes\#distance-operators)

Indexes can be used to improve performance of nearest neighbor search using various distance measures. `pgvector` includes 3 distance operators:

| Operator | Description | [**Operator class**](https://www.postgresql.org/docs/current/sql-createopclass.html) |
| --- | --- | --- |
| `<->` | Euclidean distance | `vector_l2_ops` |
| `<#>` | negative inner product | `vector_ip_ops` |
| `<=>` | cosine distance | `vector_cosine_ops` |

Currently vectors with up to 2,000 dimensions can be indexed.

## Resources [\#](https://supabase.com/docs/guides/ai/vector-indexes\#resources)

Read more about indexing on `pgvector`'s [GitHub page](https://github.com/pgvector/pgvector#indexing).

### Is this helpful?

NoYes

### On this page

[Choosing an index](https://supabase.com/docs/guides/ai/vector-indexes#choosing-an-index) [Distance operators](https://supabase.com/docs/guides/ai/vector-indexes#distance-operators) [Resources](https://supabase.com/docs/guides/ai/vector-indexes#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_ai.md">
AI & Vectors

# AI & Vectors

## The best vector database is the database you already have.

* * *

Supabase provides an open source toolkit for developing AI applications using Postgres and pgvector. Use the Supabase client libraries to store, index, and query your vector embeddings at scale.

The toolkit includes:

- A [vector store](https://supabase.com/docs/guides/ai/vector-columns) and embeddings support using Postgres and pgvector.
- A [Python client](https://supabase.com/docs/guides/ai/vecs-python-client) for managing unstructured embeddings.
- An [embedding generation](https://supabase.com/docs/guides/ai/quickstarts/generate-text-embeddings) process using open source models directly in Edge Functions.
- [Database migrations](https://supabase.com/docs/guides/ai/examples/headless-vector-search#prepare-your-database) for managing structured embeddings.
- Integrations with all popular AI providers, such as [OpenAI](https://supabase.com/docs/guides/ai/examples/openai), [Hugging Face](https://supabase.com/docs/guides/ai/hugging-face), [LangChain](https://supabase.com/docs/guides/ai/langchain), and more.

## Search [\#](https://supabase.com/docs/guides/ai\#search)

You can use Supabase to build different types of search features for your app, including:

- [Semantic search](https://supabase.com/docs/guides/ai/semantic-search): search by meaning rather than exact keywords
- [Keyword search](https://supabase.com/docs/guides/ai/keyword-search): search by words or phrases
- [Hybrid search](https://supabase.com/docs/guides/ai/hybrid-search): combine semantic search with keyword search

## Examples [\#](https://supabase.com/docs/guides/ai\#examples)

Check out all of the AI [templates and examples](https://github.com/supabase/supabase/tree/master/examples/ai) in our GitHub repository.

[![Headless Vector Search](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
Headless Vector Search\\
\\
A toolkit to perform vector similarity search on your knowledge base embeddings.](https://supabase.com/docs/guides/ai/examples/headless-vector-search)

[![Image Search with OpenAI CLIP](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
Image Search with OpenAI CLIP\\
\\
Implement image search with the OpenAI CLIP Model and Supabase Vector.](https://supabase.com/docs/guides/ai/examples/image-search-openai-clip)

[![Hugging Face inference](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
Hugging Face inference\\
\\
Generate image captions using Hugging Face.](https://supabase.com/docs/guides/ai/examples/huggingface-image-captioning)

[![OpenAI completions](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
OpenAI completions\\
\\
Generate GPT text completions using OpenAI in Edge Functions.](https://supabase.com/docs/guides/ai/examples/openai)

[![Building ChatGPT Plugins](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
Building ChatGPT Plugins\\
\\
Use Supabase as a Retrieval Store for your ChatGPT plugin.](https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins)

[![Vector search with Next.js and OpenAI](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
Vector search with Next.js and OpenAI\\
\\
Learn how to build a ChatGPT-style doc search powered by Next.js, OpenAI, and Supabase.](https://supabase.com/docs/guides/ai/examples/nextjs-vector-search)

## Integrations [\#](https://supabase.com/docs/guides/ai\#integrations)

[OpenAI\\
\\
OpenAI is an AI research and deployment company. Supabase provides a simple way to use OpenAI in your applications.](https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins)

[Amazon Bedrock\\
\\
A fully managed service that offers a choice of high-performing foundation models from leading AI companies.](https://supabase.com/docs/guides/ai/integrations/amazon-bedrock)

[Hugging Face\\
\\
Hugging Face is an open-source provider of NLP technologies. Supabase provides a simple way to use Hugging Face's models in your applications.](https://supabase.com/docs/guides/ai/hugging-face)

[LangChain\\
\\
LangChain is a language-agnostic, open-source, and self-hosted API for text translation, summarization, and sentiment analysis.](https://supabase.com/docs/guides/ai/langchain)

[LlamaIndex\\
\\
LlamaIndex is a data framework for your LLM applications.](https://supabase.com/docs/guides/ai/integrations/llamaindex)

## Case studies [\#](https://supabase.com/docs/guides/ai\#case-studies)

[Berri AI Boosts Productivity by Migrating from AWS RDS to Supabase with pgvector\\
\\
Learn how Berri AI overcame challenges with self-hosting their vector database on AWS RDS and successfully migrated to Supabase.](https://supabase.com/customers/berriai)

[Mendable switches from Pinecone to Supabase for PostgreSQL vector embeddings\\
\\
How Mendable boosts efficiency and accuracy of chat powered search for documentation using Supabase with pgvector](https://supabase.com/customers/mendableai)

[Markprompt: GDPR-Compliant AI Chatbots for Docs and Websites\\
\\
AI-powered chatbot platform, Markprompt, empowers developers to deliver efficient and GDPR-compliant prompt experiences on top of their content, by leveraging Supabase's secure and privacy-focused database and authentication solutions](https://supabase.com/customers/markprompt)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_api_api_keys.md">
REST API

# Understanding API Keys

* * *

Supabase provides two default keys when you create a project: an `anon` key, and a `service_role` key. You can find both keys in the [API Settings](https://supabase.com/dashboard/project/_/settings/api).

The data APIs are designed to work with Postgres Row Level Security (RLS). These keys both map to Postgres roles. You can find an `anon` user and a `service_role` user in the [Roles](http://supabase.com/dashboard/project/_/database/roles) section of the dashboard.

The keys are both long-lived JWTs. If you decode these keys, you will see that they contain the "role", an "issued date", and an "expiry date" ~10 years in the future.

`
{
"role": "anon",
"iat": 1625137684,
"exp": 1940713684
}
`

## The `anon` key [\#](https://supabase.com/docs/guides/api/api-keys\#the-anon-key)

The `anon` key has very few privileges. You can use it in your [RLS policies](https://supabase.com/docs/guides/database/postgres/row-level-security) to allow unauthenticated access. For example, this policy will allow unauthenticated access to the `profiles` table:

`
create policy "Allow public access" on profiles to anon for
select
using (true);
`

And similarly for disallowing access:

`
create policy "Disallow public access" on profiles to anon for
select
using (false);
`

If you are using [Supabase Auth](https://supabase.com/docs/guides/auth/overview), then the `anon` role will automatically update to `authenticated` once a user is logged in:

`
create policy "Allow access to authenticated users" on profiles to authenticated for
select
using (true);
`

## The `service_role` key [\#](https://supabase.com/docs/guides/api/api-keys\#the-servicerole-key)

The "service\_role" is a predefined Postgres role with elevated privileges, designed to perform various administrative and service-related tasks. It can bypass Row Level Security, so it should only be used on a private server.

Never expose the `service_role` key in a browser or anywhere where a user can see it.

A common use case for the `service_role` key is running data analytics jobs on the backend. To support joins on user id, it is often useful to grant the service role read access to `auth.users` table.

`
grant
select
on table auth.users to service_role;
`

We have [partnered with GitHub](https://github.blog/changelog/2022-03-28-supabase-is-now-a-github-secret-scanning-partner/) to scan for Supabase `service_role` keys pushed to public repositories.
If they detect any keys with service\_role privileges being pushed to GitHub, they will forward the API key to us, so that we can automatically revoke the detected secrets and notify you, protecting your data against malicious actors.

### Is this helpful?

NoYes

### On this page

[The anon key](https://supabase.com/docs/guides/api/api-keys#the-anon-key) [The service\_role key](https://supabase.com/docs/guides/api/api-keys#the-servicerole-key)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_api_automatic_retries_in_supabase_js.md">
REST API

# How to do automatic retries with `supabase-js`

## Learn how to add automatic retries to your Supabase API requests using `fetch-retry`.

* * *

##### Important

You should only enable retries if your requests fail with network errors (e.g. 520 status from Cloudflare). A high number of retries have the potential to exhaust the Data API connection pool, which could result in lower throughput and failed requests.

The `fetch-retry` package allows you to add retry logic to `fetch` requests, making it a useful tool for enhancing the resilience of API calls in your Supabase applications. Here's a step-by-step guide on how to integrate `fetch-retry` with the `supabase-js` library.

## 1\. Install dependencies [\#](https://supabase.com/docs/guides/api/automatic-retries-in-supabase-js\#1-install-dependencies)

To get started, ensure you have both `supabase-js` and `fetch-retry` installed in your project:

`
npm install @supabase/supabase-js fetch-retry
`

## 2\. Wrap the fetch function [\#](https://supabase.com/docs/guides/api/automatic-retries-in-supabase-js\#2-wrap-the-fetch-function)

The `fetch-retry` package works by wrapping the native `fetch` function. You can create a custom fetch instance with retry logic and pass it to the `supabase-js` client.

`
import { createClient } from '@supabase/supabase-js'
import fetchRetry from 'fetch-retry'
// Wrap the global fetch with fetch-retry
const fetchWithRetry = fetchRetry(fetch)
// Create a Supabase client instance with the custom fetch
const supabase = createClient('https://your-supabase-url.supabase.co', 'your-anon-key', {
global: {
    fetch: fetchWithRetry,
},
})
`

## 3\. Configure retry options [\#](https://supabase.com/docs/guides/api/automatic-retries-in-supabase-js\#3-configure-retry-options)

You can configure `fetch-retry` options to control retry behavior, such as the number of retries, retry delay, and which errors should trigger a retry.

Here is an example with custom retry options:

`
const fetchWithRetry = fetchRetry(fetch, {
retries: 3, // Number of retry attempts
retryDelay: (attempt) => Math.min(1000 * 2 ** attempt, 30000), // Exponential backoff
retryOn: [520], // Retry only on Cloudflare errors
})
`

In this example, the `retryDelay` function implements an exponential backoff strategy, and retries are triggered only for specific HTTP status codes.

## 4\. Using the Supabase client [\#](https://supabase.com/docs/guides/api/automatic-retries-in-supabase-js\#4-using-the-supabase-client)

With `fetch-retry` integrated, you can use the Supabase client as usual. The retry logic will automatically apply to all network requests made by `supabase-js`.

`
async function fetchData() {
const { data, error } = await supabase.from('your_table').select('*')
if (error) {
    console.error('Error fetching data:', error)
} else {
    console.log('Fetched data:', data)
}
}
fetchData()
`

## 5\. Fine-Tuning retries for specific requests [\#](https://supabase.com/docs/guides/api/automatic-retries-in-supabase-js\#5-fine-tuning-retries-for-specific-requests)

If you need different retry logic for certain requests, you can use the `retryOn` with a custom function to inspect the URL or response and decide whether to retry the request.

``
const fetchWithRetry = fetchRetry(fetch, {
retryDelay: (attempt) => Math.min(1000 * 2 ** attempt, 30000),
retryOn: (attempt, error, response) => {
    const shouldRetry
      = (attempt: number, error: Error | null, response: Response | null) =>
        attempt < 3
          && response
          && response.status == 520 // Cloudflare errors
          && response.url.includes('rpc/your_stored_procedure')
    if (shouldRetry(attempt, error, response)) {
      console.log(`Retrying request... Attempt #${attempt}`, response)
      return true
    }
    return false
}
})
async function yourStoredProcedure() {
const { data, error } = await supabase
    .rpc('your_stored_procedure', { param1: 'value1' });
if (error) {
    console.log('Error executing RPC:', error);
} else {
    console.log('Response:', data);
}
}
yourStoredProcedure();
``

By using `retryOn` with a custom function, you can define specific conditions for retrying requests. In this example, the retry logic is applied only to requests targeting a specific stored procedure.

## Conclusion [\#](https://supabase.com/docs/guides/api/automatic-retries-in-supabase-js\#conclusion)

Integrating `fetch-retry` with `supabase-js` is a straightforward way to add robustness to your Supabase API requests. By handling transient errors and implementing retry strategies, you can improve the reliability of your application while maintaining a seamless user experience.

### Is this helpful?

NoYes

### On this page

[1\. Install dependencies](https://supabase.com/docs/guides/api/automatic-retries-in-supabase-js#1-install-dependencies) [2\. Wrap the fetch function](https://supabase.com/docs/guides/api/automatic-retries-in-supabase-js#2-wrap-the-fetch-function) [3\. Configure retry options](https://supabase.com/docs/guides/api/automatic-retries-in-supabase-js#3-configure-retry-options) [4\. Using the Supabase client](https://supabase.com/docs/guides/api/automatic-retries-in-supabase-js#4-using-the-supabase-client) [5\. Fine-Tuning retries for specific requests](https://supabase.com/docs/guides/api/automatic-retries-in-supabase-js#5-fine-tuning-retries-for-specific-requests) [Conclusion](https://supabase.com/docs/guides/api/automatic-retries-in-supabase-js#conclusion)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_api_creating_routes.md">
REST API

# Creating API Routes

* * *

API routes are automatically created when you create Postgres Tables, Views, or Functions.

## Create a table [\#](https://supabase.com/docs/guides/api/creating-routes\#create-a-table)

Let's create our first API route by creating a table called `todos` to store tasks.
This creates a corresponding route `todos` which can accept `GET`, `POST`, `PATCH`, & `DELETE` requests.

DashboardSQL

1. Go to the [Table editor](https://supabase.com/dashboard/project/_/editor) page in the Dashboard.
2. Click **New Table** and create a table with the name `todos`.
3. Click **Save**.
4. Click **New Column** and create a column with the name `task` and type `text`.
5. Click **Save**.

## API URL and keys [\#](https://supabase.com/docs/guides/api/creating-routes\#api-url-and-keys)

Every Supabase project has a unique API URL. Your API is secured behind an API gateway which requires an API Key for every request.

1. Go to the [Settings](https://supabase.com/dashboard/project/_/settings/general) page in the Dashboard.
2. Click **API** in the sidebar.
3. Find your API `URL`, `anon`, and `service_role` keys on this page.

The REST API is accessible through the URL `https://<project_ref>.supabase.co/rest/v1`

Both of these routes require the `anon` key to be passed through an `apikey` header.

## Using the API [\#](https://supabase.com/docs/guides/api/creating-routes\#using-the-api)

You can interact with your API directly via HTTP requests, or you can use the client libraries which we provide.

Let's see how to make a request to the `todos` table which we created in the first step,
using the API URL ( `SUPABASE_URL`) and Key ( `SUPABASE_ANON_KEY`) we provided:

JavascriptcURL

`
// Initialize the JS client
import { createClient } from '@supabase/supabase-js'
const supabase = createClient(SUPABASE_URL, SUPABASE_ANON_KEY)
// Make a request
const { data: todos, error } = await supabase.from('todos').select('*')
`

JS Reference: [`select()`](https://supabase.com/docs/reference/javascript/select),
[`insert()`](https://supabase.com/docs/reference/javascript/insert),
[`update()`](https://supabase.com/docs/reference/javascript/update),
[`upsert()`](https://supabase.com/docs/reference/javascript/upsert),
[`delete()`](https://supabase.com/docs/reference/javascript/delete),
[`rpc()`](https://supabase.com/docs/reference/javascript/rpc) (call Postgres functions).

### Is this helpful?

NoYes

### On this page

[Create a table](https://supabase.com/docs/guides/api/creating-routes#create-a-table) [API URL and keys](https://supabase.com/docs/guides/api/creating-routes#api-url-and-keys) [Using the API](https://supabase.com/docs/guides/api/creating-routes#using-the-api)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_api_quickstart.md">
REST API

# Build an API route in less than 2 minutes.

## Create your first API route by creating a table called `todos` to store tasks.

* * *

Let's create our first REST route which we can query using `cURL` or the browser.

We'll create a database table called `todos` for storing tasks. This creates a corresponding API route `/rest/v1/todos` which can accept `GET`, `POST`, `PATCH`, & `DELETE` requests.

1

### Set up a Supabase project with a 'todos' table

[Create a new project](https://supabase.com/dashboard) in the Supabase Dashboard.

After your project is ready, create a table in your Supabase database. You can do this with either the Table interface or the [SQL Editor](https://supabase.com/dashboard/project/_/sql).

SQLDashboard

`
-- Create a table called "todos"
-- with a column to store tasks.
create table todos (
id serial primary key,
task text
);
`

2

### Allow public access

Let's turn on Row Level Security for this table and allow public access.

`
-- Turn on security
alter table "todos"
enable row level security;
-- Allow anonymous access
create policy "Allow public access"
on todos
for select
to anon
using (true);
`

3

### Insert some dummy data

Now we can add some data to our table which we can access through our API.

`
insert into todos (task)
values
('Create tables'),
('Enable security'),
('Add data'),
('Fetch data from the API');
`

4

### Fetch the data

Find your API URL and Keys in your Dashboard [API Settings](https://supabase.com/dashboard/project/_/settings/api). You can now query your "todos" table by appending `/rest/v1/todos` to the API URL.

Copy this block of code, substitute `<PROJECT_REF>` and `<ANON_KEY>`, then run it from a terminal.

Terminal

`
curl 'https://<PROJECT_REF>.supabase.co/rest/v1/todos' \
-H "apikey: <ANON_KEY>" \
-H "Authorization: Bearer <ANON_KEY>"
`

## Bonus [\#](https://supabase.com/docs/guides/api/quickstart\#bonus)

There are several options for accessing your data:

### Browser [\#](https://supabase.com/docs/guides/api/quickstart\#browser)

You can query the route in your browser, by appending the `anon` key as a query parameter:

`https://<PROJECT_REF>.supabase.co/rest/v1/todos?apikey=<ANON_KEY>`

### Client libraries [\#](https://supabase.com/docs/guides/api/quickstart\#client-libraries)

We provide a number of [Client Libraries](https://github.com/supabase/supabase#client-libraries).

JavaScriptDartPythonSwift

`
const { data, error } = await supabase.from('todos').select()
`

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_api_rest_auto_generated_docs.md">
REST API

# Auto-generated documentation

* * *

Supabase generates documentation in the [Dashboard](https://supabase.com/dashboard) which updates as you make database changes.

1. Go to the [API](https://supabase.com/dashboard/project/_/api) page in the Dashboard.
2. Select any table under **Tables and Views** in the sidebar.
3. Switch between the JavaScript and the cURL docs using the tabs.

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_api_rest_client_libs.md">
REST API

# Client Libraries

* * *

Supabase provides client libraries for the REST and Realtime APIs. Some libraries are officially supported, and some are contributed by the community.

## Official libraries [\#](https://supabase.com/docs/guides/api/rest/client-libs\#official-libraries)

| `Language` | `Source Code` | `Documentation` |
| --- | --- | --- |
| Javascript/Typescript | [supabase-js](https://github.com/supabase/supabase-js) | [Docs](https://supabase.com/docs/reference/javascript/introduction) |
| Dart/Flutter | [supabase-flutter](https://github.com/supabase/supabase-flutter/tree/main/packages/supabase_flutter) | [Docs](https://supabase.com/docs/reference/dart/introduction) |
| Swift | [supabase-swift](https://github.com/supabase/supabase-swift) | [Docs](https://supabase.com/docs/reference/swift/introduction) |
| Python | [supabase-py](https://github.com/supabase/supabase-py) | [Docs](https://supabase.com/docs/reference/python/initializing) |

## Community libraries [\#](https://supabase.com/docs/guides/api/rest/client-libs\#community-libraries)

| `Language` | `Source Code` | `Documentation` |
| --- | --- | --- |
| C# | [supabase-csharp](https://github.com/supabase-community/supabase-csharp) | [Docs](https://supabase.com/docs/reference/csharp/introduction) |
| Go | [supabase-go](https://github.com/supabase-community/supabase-go) |  |
| Kotlin | [supabase-kt](https://github.com/supabase-community/supabase-kt) | [Docs](https://supabase.com/docs/reference/kotlin/introduction) |
| Ruby | [supabase-rb](https://github.com/supabase-community/supabase-rb) |  |
| Godot Engine (GDScript) | [supabase-gdscript](https://github.com/supabase-community/godot-engine.supabase) |  |

### Is this helpful?

NoYes

### On this page

[Official libraries](https://supabase.com/docs/guides/api/rest/client-libs#official-libraries) [Community libraries](https://supabase.com/docs/guides/api/rest/client-libs#community-libraries)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_api_rest_generating_types.md">
REST API

# Generating TypeScript Types

## How to generate types for your API and Supabase libraries.

* * *

Supabase APIs are generated from your database, which means that we can use database introspection to generate type-safe API definitions.

## Generating types from project dashboard [\#](https://supabase.com/docs/guides/api/rest/generating-types\#generating-types-from-project-dashboard)

Supabase allows you to generate and download TypeScript types directly from the [project dashboard](https://supabase.com/dashboard/project/_/api?page=tables-intro).

## Generating types using Supabase CLI [\#](https://supabase.com/docs/guides/api/rest/generating-types\#generating-types-using-supabase-cli)

The Supabase CLI is a single binary Go application that provides everything you need to setup a local development environment.

You can [install the CLI](https://www.npmjs.com/package/supabase) via npm or other supported package managers. The minimum required version of the CLI is [v1.8.1](https://github.com/supabase/cli/releases).

`
npm i supabase@">=1.8.1" --save-dev
`

Login with your Personal Access Token:

`
npx supabase login
`

Before generating types, ensure you initialize your Supabase project:

`
npx supabase init
`

Generate types for your project to produce the `database.types.ts` file:

`
npx supabase gen types typescript --project-id "$PROJECT_REF" --schema public > database.types.ts
`

or in case of local development:

`
npx supabase gen types typescript --local > database.types.ts
`

These types are generated from your database schema. Given a table `public.movies`, the generated types will look like:

`
create table public.movies (
id bigint generated always as identity primary key,
name text not null,
data jsonb null
);
`

./database.types.ts

``
export type Json = string | number | boolean | null | { [key: string]: Json | undefined } | Json[]
export interface Database {
public: {
    Tables: {
      movies: {
        Row: {
          // the data expected from .select()
          id: number
          name: string
          data: Json | null
        }
        Insert: {
          // the data to be passed to .insert()
          id?: never // generated columns must not be supplied
          name: string // `not null` columns with no default must be supplied
          data?: Json | null // nullable columns can be omitted
        }
        Update: {
          // the data to be passed to .update()
          id?: never
          name?: string // `not null` columns are optional on .update()
          data?: Json | null
        }
      }
    }
}
}
``

## Using TypeScript type definitions [\#](https://supabase.com/docs/guides/api/rest/generating-types\#using-typescript-type-definitions)

You can supply the type definitions to `supabase-js` like so:

./index.tsx

`
import { createClient } from '@supabase/supabase-js'
import { Database } from './database.types'
const supabase = createClient<Database>(process.env.SUPABASE_URL, process.env.SUPABASE_ANON_KEY)
`

## Helper types for tables and joins [\#](https://supabase.com/docs/guides/api/rest/generating-types\#helper-types-for-tables-and-joins)

You can use the following helper types to make the generated TypeScript types easier to use.

Sometimes the generated types are not what you expect. For example, a view's column may show up as nullable when you expect it to be `not null`. Using [type-fest](https://github.com/sindresorhus/type-fest), you can override the types like so:

./database-generated.types.ts

`
export type Json = // ...
export interface Database {
// ...
}
`

./database.types.ts

``
import { MergeDeep } from 'type-fest'
import { Database as DatabaseGenerated } from './database-generated.types'
export { Json } from './database-generated.types'
// Override the type for a specific column in a view:
export type Database = MergeDeep<
DatabaseGenerated,
{
    public: {
      Views: {
        movies_view: {
          Row: {
            // id is a primary key in public.movies, so it must be `not null`
            id: number
          }
        }
      }
    }
}
>
``

To use `MergeDeep`, set `compilerOptions.strictNullChecks` to `true` in your `tsconfig.json`.

You can also override the type of an individual successful response if needed:

``
// Partial type override allows you to only override some of the properties in your results
const { data } = await supabase.from('countries').select().overrideTypes<Array<{ id: string }>>()
// For a full replacement of the original return type use the `{ merge: false }` property as second argument
const { data } = await supabase
.from('countries')
.select()
.overrideTypes<Array<{ id: string }>, { merge: false }>()
// Use it with `maybeSingle` or `single`
const { data } = await supabase.from('countries').select().single().overrideTypes<{ id: string }>()
``

### Type shorthands [\#](https://supabase.com/docs/guides/api/rest/generating-types\#type-shorthands)

The generated types provide shorthands for accessing tables and enums.

./index.ts

`
import { Database, Tables, Enums } from "./database.types.ts";
// Before 
let movie: Database['public']['Tables']['movies']['Row'] = // ...
// After 
let movie: Tables<'movies'>
`

### Response types for complex queries [\#](https://supabase.com/docs/guides/api/rest/generating-types\#response-types-for-complex-queries)

`supabase-js` always returns a `data` object (for success), and an `error` object (for unsuccessful requests).

These helper types provide the result types from any query, including nested types for database joins.

Given the following schema with a relation between cities and countries:

`
create table countries (
"id" serial primary key,
"name" text
);
create table cities (
"id" serial primary key,
"name" text,
"country_id" int references "countries"
);
`

We can get the nested `CountriesWithCities` type like this:

``
import { QueryResult, QueryData, QueryError } from '@supabase/supabase-js'
const countriesWithCitiesQuery = supabase.from('countries').select(`
id,
name,
cities (
    id,
    name
)
`)
type CountriesWithCities = QueryData<typeof countriesWithCitiesQuery>
const { data, error } = await countriesWithCitiesQuery
if (error) throw error
const countriesWithCities: CountriesWithCities = data
``

## Update types automatically with GitHub Actions [\#](https://supabase.com/docs/guides/api/rest/generating-types\#update-types-automatically-with-github-actions)

One way to keep your type definitions in sync with your database is to set up a GitHub action that runs on a schedule.

Add the following script to your `package.json` to run it using `npm run update-types`

`
"update-types": "npx supabase gen types --lang=typescript --project-id \"$PROJECT_REF\" > database.types.ts"
`

Create a file `.github/workflows/update-types.yml` with the following snippet to define the action along with the environment variables. This script will commit new type changes to your repo every night.

`
name: Update database types
on:
schedule:
    # sets the action to run daily. You can modify this to run the action more or less frequently
    - cron: '0 0 * * *'
jobs:
update:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    env:
      SUPABASE_ACCESS_TOKEN: ${{ secrets.ACCESS_TOKEN }}
      PROJECT_REF: <your-project-id>
    steps:
      - uses: actions/checkout@v2
        with:
          persist-credentials: false
          fetch-depth: 0
      - uses: actions/setup-node@v2.1.5
        with:
          node-version: 16
      - run: npm run update-types
      - name: check for file changes
        id: git_status
        run: |
          echo "status=$(git status -s)" >> $GITHUB_OUTPUT
      - name: Commit files
        if: ${{contains(steps.git_status.outputs.status, ' ')}}
        run: |
          git add database.types.ts
          git config --local user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git commit -m "Update database types" -a
      - name: Push changes
        if: ${{contains(steps.git_status.outputs.status, ' ')}}
        uses: ad-m/github-push-action@master
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          branch: ${{ github.ref }}
`

Alternatively, you can use a community-supported GitHub action: [`generate-supabase-db-types-github-action`](https://github.com/lyqht/generate-supabase-db-types-github-action).

## Resources [\#](https://supabase.com/docs/guides/api/rest/generating-types\#resources)

- [Generating Supabase types with GitHub Actions](https://blog.esteetey.dev/how-to-create-and-test-a-github-action-that-generates-types-from-supabase-database)

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2F%2F7CqlTU9aOR4%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Generating types from project dashboard](https://supabase.com/docs/guides/api/rest/generating-types#generating-types-from-project-dashboard) [Generating types using Supabase CLI](https://supabase.com/docs/guides/api/rest/generating-types#generating-types-using-supabase-cli) [Using TypeScript type definitions](https://supabase.com/docs/guides/api/rest/generating-types#using-typescript-type-definitions) [Helper types for tables and joins](https://supabase.com/docs/guides/api/rest/generating-types#helper-types-for-tables-and-joins) [Type shorthands](https://supabase.com/docs/guides/api/rest/generating-types#type-shorthands) [Response types for complex queries](https://supabase.com/docs/guides/api/rest/generating-types#response-types-for-complex-queries) [Update types automatically with GitHub Actions](https://supabase.com/docs/guides/api/rest/generating-types#update-types-automatically-with-github-actions) [Resources](https://supabase.com/docs/guides/api/rest/generating-types#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_api_securing_your_api.md">
REST API

# Securing your API

* * *

The data APIs are designed to work with Postgres Row Level Security (RLS). If you use [Supabase Auth](https://supabase.com/docs/guides/auth), you can restrict data based on the logged-in user.

To control access to your data, you can use [Policies](https://supabase.com/docs/guides/auth#policies).

## Enabling row level security [\#](https://supabase.com/docs/guides/api/securing-your-api\#enabling-row-level-security)

Any table you create in the `public` schema will be accessible via the Supabase Data API.

To restrict access, enable Row Level Security (RLS) on all tables, views, and functions in the `public` schema. You can then write RLS policies to grant users access to specific database rows or functions based on their authentication token.

Always enable Row Level Security on tables, views, and functions in the `public` schema to protect your data.

Any table created through the Supabase Dashboard will have RLS enabled by default. If you created the tables via the SQL editor or via another way, enable RLS like so:

DashboardSQL

1. Go to the [Authentication > Policies](https://supabase.com/dashboard/project/_/auth/policies) page in the Dashboard.
2. Select **Enable RLS** to enable Row Level Security.

With RLS enabled, you can create Policies that allow or disallow users to access and update data. We provide a detailed guide for creating Row Level Security Policies in our [Authorization documentation](https://supabase.com/docs/guides/database/postgres/row-level-security).

Any table **without RLS enabled** in the `public` schema will be accessible to the public, using the `anon` role. Always make sure that RLS is enabled or that you've got other security measures in place to avoid unauthorized access to your project's data!

## Disable the API or restrict to custom schema [\#](https://supabase.com/docs/guides/api/securing-your-api\#disable-the-api-or-restrict-to-custom-schema)

If you don't use the Data API, or if you don't want to expose the `public` schema, you can either disable it entirely or change the automatically exposed schema to one of your choice. See **[Hardening the Data API](https://supabase.com/docs/guides/database/hardening-data-api)** for instructions.

## Enforce additional rules on each request [\#](https://supabase.com/docs/guides/api/securing-your-api\#enforce-additional-rules-on-each-request)

Using Row Level Security policies may not always be adequate or sufficient to protect APIs.

Here are some common situations where additional protections are necessary:

- Enforcing per-IP or per-user rate limits.
- Checking custom or additional API keys before allowing further access.
- Rejecting requests after exceeding a quota or requiring payment.
- Disallowing direct access to certain tables, views or functions in the `public` schema.

You can build these cases in your application by creating a Postgres function that will read information from the request and perform additional checks, such as counting the number of requests received or checking that an API key is already registered in your database before serving the response.

Define a function like so:

`
create function public.check_request()
returns void
language plpgsql
security definer
as $$
begin
  -- your logic here
end;
$$;
`

And register it to run on every Data API request using:

`
alter role authenticator
set pgrst.db_pre_request = 'public.check_request';
`

This configures the `public.check_request` function to run on every Data API request. To have the changes take effect, you should run:

`
notify pgrst, 'reload config';
`

Inside the function you can perform any additional checks on the request headers or JWT and raise an exception to prevent the request from completing. For example, this exception raises a HTTP 402 Payment Required response with a `hint` and additional `X-Powered-By` header:

`
raise sqlstate 'PGRST' using
message = json_build_object(
    'code',    '123',
    'message', 'Payment Required',
    'details', 'Quota exceeded',
    'hint',    'Upgrade your plan')::text,
detail = json_build_object(
    'status',  402,
    'headers', json_build_object(
      'X-Powered-By', 'Nerd Rage'))::text;
`

When raised within the `public.check_request` function, the resulting HTTP response will look like:

`
HTTP/1.1 402 Payment Required
Content-Type: application/json; charset=utf-8
X-Powered-By: Nerd Rage
{
"message": "Payment Required",
"details": "Quota exceeded",
"hint": "Upgrade your plan",
"code": "123"
}
`

Use the [JSON operator functions](https://www.postgresql.org/docs/current/functions-json.html) to build rich and dynamic responses from exceptions.

If you use a custom HTTP status code like 419, you can supply the `status_text` key in the `detail` clause of the exception to describe the HTTP status.

If you're using PostgREST version 11 or lower ( [find out your PostgREST version](https://supabase.com/dashboard/project/_/settings/infrastructure)) a different and less powerful [syntax](https://postgrest.org/en/stable/references/errors.html#raise-errors-with-http-status-codes) needs to be used.

### Accessing request information [\#](https://supabase.com/docs/guides/api/securing-your-api\#accessing-request-information)

Like with RLS policies, you can access information about the request by using the `current_setting()` Postgres function. Here are some examples on how this works:

`
-- To get all the headers sent in the request
SELECT current_setting('request.headers', true)::json;
-- To get a single header, you can use JSON arrow operators
SELECT current_setting('request.headers', true)::json->>'user-agent';
-- Access Cookies
SELECT current_setting('request.cookies', true)::json;
`

| `current_setting()` | Example | Description |
| --- | --- | --- |
| `request.method` | `GET`, `HEAD`, `POST`, `PUT`, `PATCH`, `DELETE` | Request's method |
| `request.path` | `table` | Table's path |
| `request.path` | `view` | View's path |
| `request.path` | `rpc/function` | Functions's path |
| `request.headers` | `{ "User-Agent": "...", ... }` | JSON object of the request's headers |
| `request.cookies` | `{ "cookieA": "...", "cookieB": "..." }` | JSON object of the request's cookies |
| `request.jwt` | `{ "sub": "a7194ea3-...", ... }` | JSON object of the JWT payload |

To access the IP address of the client look up the [X-Forwarded-For header](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Forwarded-For) in the `request.headers` setting. For example:

`
SELECT split_part(
current_setting('request.headers', true)::json->>'x-forwarded-for',
',', 1); -- takes the client IP before the first comma (,)
`

Read more about [PostgREST's pre-request function](https://postgrest.org/en/stable/references/transactions.html#pre-request).

### Examples [\#](https://supabase.com/docs/guides/api/securing-your-api\#examples)

Rate limit per IPUse additional API keys

You can only rate-limit `POST`, `PUT`, `PATCH` and `DELETE` requests. This is because `GET` and `HEAD` requests run in read-only mode, and will be served by [Read Replicas](https://supabase.com/docs/guides/platform/read-replicas) which do not support writing to the database.

Outline:

- A new row is added to a `private.rate_limits` table each time a modifying action is done to the database containing the IP address and the timestamp of the action.
- If there are over 100 requests from the same IP address in the last 5 minutes, the request is rejected with a HTTP 420 code.

Create the table:

`
create table private.rate_limits (
ip inet,
request_at timestamp
);
-- add an index so that lookups are fast
create index rate_limits_ip_request_at_idx on private.rate_limits (ip, request_at desc);
`

The `private` schema is used as it cannot be accessed over the API!

Create the `public.check_request` function:

`
create function public.check_request()
returns void
language plpgsql
security definer
as $$
declare
req_method text := current_setting('request.method', true);
req_ip inet := split_part(
    current_setting('request.headers', true)::json->>'x-forwarded-for',
    ',', 1)::inet;
count_in_five_mins integer;
begin
if req_method = 'GET' or req_method = 'HEAD' or req_method is null then
    -- rate limiting can't be done on GET and HEAD requests
    return;
end if;
select
    count(*) into count_in_five_mins
from private.rate_limits
where
    ip = req_ip and request_at between now() - interval '5 minutes' and now();
if count_in_five_mins > 100 then
    raise sqlstate 'PGRST' using
      message = json_build_object(
        'message', 'Rate limit exceeded, try again after a while')::text,
      detail = json_build_object(
        'status',  420,
        'status_text', 'Enhance Your Calm')::text;
end if;
insert into private.rate_limits (ip, request_at) values (req_ip, now());
end;
$$;
`

Finally, configure the `public.check_request()` function to run on every Data API request:

`
alter role authenticator
set pgrst.db_pre_request = 'public.check_request';
notify pgrst, 'reload config';
`

To clear old entries in the `private.rate_limits` table, set up a [pg\_cron](https://supabase.com/docs/guides/database/extensions/pg_cron) job to clean them up.

### Is this helpful?

NoYes

### On this page

[Enabling row level security](https://supabase.com/docs/guides/api/securing-your-api#enabling-row-level-security) [Disable the API or restrict to custom schema](https://supabase.com/docs/guides/api/securing-your-api#disable-the-api-or-restrict-to-custom-schema) [Enforce additional rules on each request](https://supabase.com/docs/guides/api/securing-your-api#enforce-additional-rules-on-each-request) [Accessing request information](https://supabase.com/docs/guides/api/securing-your-api#accessing-request-information) [Examples](https://supabase.com/docs/guides/api/securing-your-api#examples)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_api_sql_to_api.md">
REST API

# Converting SQL to JavaScript API

* * *

Many common SQL queries can be written using the JavaScript API, provided by the SDK to wrap Data API calls. Below are a few examples of conversions between SQL and JavaScript patterns.

## Select statement with basic clauses [\#](https://supabase.com/docs/guides/api/sql-to-api\#select-statement-with-basic-clauses)

Select a set of columns from a single table with where, order by, and limit clauses.

`
select first_name, last_name, team_id, age
from players
where age between 20 and 24 and team_id != 'STL'
order by last_name, first_name desc
limit 20;
`

`
const { data, error } = await supabase
.from('players')
.select('first_name,last_name,team_id,age')
.gte('age', 20)
.lte('age', 24)
.not('team_id', 'eq', 'STL')
.order('last_name', { ascending: true }) // or just .order('last_name')
.order('first_name', { ascending: false })
.limit(20)
`

## Select statement with complex Boolean logic clause [\#](https://supabase.com/docs/guides/api/sql-to-api\#select-statement-with-complex-boolean-logic-clause)

Select all columns from a single table with a complex where clause: OR AND OR

`
select *
from players
where ((team_id = 'CHN' or team_id is null) and (age > 35 or age is null));
`

`
const { data, error } = await supabase
.from('players')
.select() // or .select('*')
.or('team_id.eq.CHN,team_id.is.null')
.or('age.gt.35,age.is.null') // additional filters imply "AND"
`

Select all columns from a single table with a complex where clause: AND OR AND

`
select *
from players
where ((team_id = 'CHN' and age > 35) or (team_id != 'CHN' and age is not null));
`

`
const { data, error } = await supabase
.from('players')
.select() // or .select('*')
.or('and(team_id.eq.CHN,age.gt.35),and(team_id.neq.CHN,.not.age.is.null)')
`

## Resources [\#](https://supabase.com/docs/guides/api/sql-to-api\#resources)

- [Supabase - Get started for free](https://supabase.com/)
- [PostgREST Operators](https://postgrest.org/en/stable/api.html#operators)
- [Supabase API: JavaScript select](https://supabase.com/docs/reference/javascript/select)
- [Supabase API: JavaScript modifiers](https://supabase.com/docs/reference/javascript/using-modifiers)
- [Supabase API: JavaScript filters](https://supabase.com/docs/reference/javascript/using-filters)

### Is this helpful?

NoYes

### On this page

[Select statement with basic clauses](https://supabase.com/docs/guides/api/sql-to-api#select-statement-with-basic-clauses) [Select statement with complex Boolean logic clause](https://supabase.com/docs/guides/api/sql-to-api#select-statement-with-complex-boolean-logic-clause) [Resources](https://supabase.com/docs/guides/api/sql-to-api#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_api_sql_to_rest.md">
REST API

# SQL to REST API Translator

## Translate SQL queries to HTTP requests and Supabase client code

* * *

Sometimes it's challenging to translate SQL queries to the equivalent [PostgREST](https://postgrest.org/) request or Supabase client code. Use this tool to help with this translation.

PostgREST supports a subset of SQL, so not all SQL queries will translate.

Enter SQL to translate

1

select

Choose language to translate to

cURLHTTPJavaScript

```curl

curl -G http://localhost:54321/rest/v1/books \

  -d "select=title,description" \

  -d "description=ilike.*cheese*" \

  -d "order=title.desc" \

  -d "limit=5" \

  -d "offset=10"
```

### FAQs

What is `curl`?

What do `-G` and `-d` do?

Why is `%` getting converted to `*`?

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_api_using_custom_schemas.md">
REST API

# Using Custom Schemas

* * *

By default, your database has a `public` schema which is automatically exposed on data APIs.

## Creating custom schemas [\#](https://supabase.com/docs/guides/api/using-custom-schemas\#creating-custom-schemas)

You can create your own custom schema/s by running the following SQL, substituting `myschema` with the name you want to use for your schema:

`
CREATE SCHEMA myschema;
`

## Exposing custom schemas [\#](https://supabase.com/docs/guides/api/using-custom-schemas\#exposing-custom-schemas)

You can expose custom database schemas - to do so you need to follow these steps:

1. Go to [API settings](https://supabase.com/dashboard/project/_/settings/api) and add your custom schema to "Exposed schemas".
2. Run the following SQL, substituting `myschema` with your schema name:

`
GRANT USAGE ON SCHEMA myschema TO anon, authenticated, service_role;
GRANT ALL ON ALL TABLES IN SCHEMA myschema TO anon, authenticated, service_role;
GRANT ALL ON ALL ROUTINES IN SCHEMA myschema TO anon, authenticated, service_role;
GRANT ALL ON ALL SEQUENCES IN SCHEMA myschema TO anon, authenticated, service_role;
ALTER DEFAULT PRIVILEGES FOR ROLE postgres IN SCHEMA myschema GRANT ALL ON TABLES TO anon, authenticated, service_role;
ALTER DEFAULT PRIVILEGES FOR ROLE postgres IN SCHEMA myschema GRANT ALL ON ROUTINES TO anon, authenticated, service_role;
ALTER DEFAULT PRIVILEGES FOR ROLE postgres IN SCHEMA myschema GRANT ALL ON SEQUENCES TO anon, authenticated, service_role;
`

Now you can access these schemas from data APIs:

JavaScriptDartcURL

`
// Initialize the JS client
import { createClient } from '@supabase/supabase-js'
const supabase = createClient(SUPABASE_URL, SUPABASE_ANON_KEY, { db: { schema: 'myschema' } })
// Make a request
const { data: todos, error } = await supabase.from('todos').select('*')
// You can also change the target schema on a per-query basis
const { data: todos, error } = await supabase.schema('myschema').from('todos').select('*')
`

### Is this helpful?

NoYes

### On this page

[Creating custom schemas](https://supabase.com/docs/guides/api/using-custom-schemas#creating-custom-schemas) [Exposing custom schemas](https://supabase.com/docs/guides/api/using-custom-schemas#exposing-custom-schemas)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_api.md">
REST API

# REST API

* * *

Supabase auto-generates an API directly from your database schema allowing you to connect to your database through a restful interface, directly from the browser.

The API is auto-generated from your database and is designed to get you building as fast as possible, without writing a single line of code.

You can use them directly from the browser (two-tier architecture), or as a complement to your own API server (three-tier architecture).

## Features [\#](https://supabase.com/docs/guides/api\#rest-api-overview)

Supabase provides a RESTful API using [PostgREST](https://postgrest.org/). This is a very thin API layer on top of Postgres.
It exposes everything you need from a CRUD API at the URL `https://<project_ref>.supabase.co/rest/v1/`.

The REST interface is automatically reflected from your database's schema and is:

- **Instant and auto-generated.**

As you update your database the changes are immediately accessible through your API.
- **Self documenting.**

Supabase generates documentation in the Dashboard which updates as you make database changes.
- **Secure.**

The API is configured to work with PostgreSQL's Row Level Security, provisioned behind an API gateway with key-auth enabled.
- **Fast.**

Our benchmarks for basic reads are more than 300% faster than Firebase. The API is a very thin layer on top of Postgres, which does most of the heavy lifting.
- **Scalable.**

The API can serve thousands of simultaneous requests, and works well for Serverless workloads.

The reflected API is designed to retain as much of Postgres' capability as possible including:

- Basic CRUD operations (Create/Read/Update/Delete)
- Arbitrarily deep relationships among tables/views, functions that return table types can also nest related tables/views.
- Works with Postgres Views, Materialized Views and Foreign Tables
- Works with Postgres Functions
- User defined computed columns and computed relationships
- The Postgres security model - including Row Level Security, Roles, and Grants.

The REST API resolves all requests to a single SQL statement leading to fast response times and high throughput.

Reference:

- [Docs](https://postgrest.org/)
- [Source Code](https://github.com/PostgREST/postgrest)

## API URL and keys [\#](https://supabase.com/docs/guides/api\#api-url-and-keys)

You can find the API URL and Keys in the [Dashboard](https://supabase.com/dashboard/project/_/settings/api).

### Is this helpful?

NoYes

### On this page

[Features](https://supabase.com/docs/guides/api#rest-api-overview) [API URL and keys](https://supabase.com/docs/guides/api#api-url-and-keys)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_architecture.md">
Auth

# Auth architecture

## The architecture behind Supabase Auth.

* * *

There are four major layers to Supabase Auth:

1. [Client layer.](https://supabase.com/docs/guides/auth/architecture#client-layer) This can be one of the Supabase client SDKs, or manually made HTTP requests using the HTTP client of your choice.
2. Kong API gateway. This is shared between all Supabase products.
3. [Auth service](https://supabase.com/docs/guides/auth/architecture#auth-service) (formerly known as GoTrue).
4. [Postgres database.](https://supabase.com/docs/guides/auth/architecture#postgres) This is shared between all Supabase products.

![Diagram showing the architecture of Supabase. The Kong API gateway sits in front of 7 services: GoTrue, PostgREST, Realtime, Storage, pg_meta, Functions, and pg_graphql. All the services talk to a single Postgres instance.](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fsupabase-architecture--light.svg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

## Client layer [\#](https://supabase.com/docs/guides/auth/architecture\#client-layer)

The client layer runs in your app. This could be running in many places, including:

- Your frontend browser code
- Your backend server code
- Your native application

The client layer provides the functions that you use to sign in and manage users. We recommend using the Supabase client SDKs, which handle:

- Configuration and authentication of HTTP calls to the Supabase Auth backend
- Persistence, refresh, and removal of Auth Tokens in your app's storage medium
- Integration with other Supabase products

But at its core, this layer manages the making of HTTP calls, so you could write your own client layer if you wanted to.

See the Client SDKs for more information:

- [JavaScript](https://supabase.com/docs/reference/javascript/introduction)
- [Flutter](https://supabase.com/docs/reference/dart/introduction)
- [Swift](https://supabase.com/docs/reference/swift/introduction)
- [Python](https://supabase.com/docs/reference/python/introduction)
- [C#](https://supabase.com/docs/reference/csharp/introduction)
- [Kotlin](https://supabase.com/docs/reference/kotlin/introduction)

## Auth service [\#](https://supabase.com/docs/guides/auth/architecture\#auth-service)

The [Auth service](https://github.com/supabase/auth) is an Auth API server written and maintained by Supabase. It is a fork of the GoTrue project, originally created by Netlify.

When you deploy a new Supabase project, we deploy an instance of this server alongside your database, and inject your database with the required Auth schema.

The Auth service is responsible for:

- Validating, issuing, and refreshing JWTs
- Serving as the intermediary between your app and Auth information in the database
- Communicating with external providers for Social Login and SSO

## Postgres [\#](https://supabase.com/docs/guides/auth/architecture\#postgres)

Supabase Auth uses the `auth` schema in your Postgres database to store user tables and other information. For security, this schema is not exposed on the auto-generated API.

You can connect Auth information to your own objects using [database triggers](https://supabase.com/docs/guides/database/postgres/triggers) and [foreign keys](https://www.postgresql.org/docs/current/tutorial-fk.html). Make sure that any views you create for Auth data are adequately protected by [enabling RLS](https://supabase.com/docs/guides/database/postgres/row-level-security) or [revoking grants](https://www.postgresql.org/docs/current/sql-revoke.html).

Make sure any views you create for Auth data are protected.

Starting in Postgres version 15, views inherit the RLS policies of the underlying tables if created with `security_invoker`. Views in earlier versions, or those created without `security_invoker`, inherit the permissions of the owner, who can bypass RLS policies.

### Is this helpful?

NoYes

### On this page

[Client layer](https://supabase.com/docs/guides/auth/architecture#client-layer) [Auth service](https://supabase.com/docs/guides/auth/architecture#auth-service) [Postgres](https://supabase.com/docs/guides/auth/architecture#postgres)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_auth_anonymous.md">
Auth

# Anonymous Sign-Ins

## Create and use anonymous users to authenticate with Supabase

* * *

[Enable Anonymous Sign-Ins](https://supabase.com/dashboard/project/_/settings/auth) to build apps which provide users an authenticated experience without requiring users to enter an email address, password, use an OAuth provider or provide any other PII (Personally Identifiable Information). Later, when ready, the user can link an authentication method to their account.

##### Anonymous user vs the anon key

Calling `signInAnonymously()` creates an anonymous user. It's just like a permanent user, except the user can't access their account if they sign out, clear browsing data, or use another device.

Like permanent users, the `authenticated` Postgres role will be used when using the Data APIs to access your project. JWTs for these users will have an `is_anonymous` claim which you can use to distinguish in RLS policies.

This is different from the `anon` API key which does not create a user and can be used to implement public access to your database as it uses the `anonymous` Postgres role.

Anonymous sign-ins can be used to build:

- E-commerce applications, such as shopping carts before check-out
- Full-feature demos without collecting personal information
- Temporary or throw-away accounts

Review your existing RLS policies before enabling anonymous sign-ins. Anonymous users use the `authenticated` role. To distinguish between anonymous users and permanent users, your policies need to check the `is_anonymous` field of the user's JWT.

See the [Access control section](https://supabase.com/docs/guides/auth/auth-anonymous#access-control) for more details.

##### Use Dynamic Rendering with Next.js

The Supabase team has received reports of user metadata being cached across unique anonymous users as a result of Next.js static page rendering. For the best user experience, utilize dynamic page rendering.

##### Self hosting and local development

For self-hosting, you can update your project configuration using the files and environment variables provided. See the [local development docs](https://supabase.com/docs/guides/cli/config) for more details.

## Sign in anonymously [\#](https://supabase.com/docs/guides/auth/auth-anonymous\#sign-in-anonymously)

JavaScriptFlutterSwiftKotlinPython

Call the [`signInAnonymously()`](https://supabase.com/docs/reference/javascript/auth-signinanonymously) method:

`
const { data, error } = await supabase.auth.signInAnonymously()
`

## Convert an anonymous user to a permanent user [\#](https://supabase.com/docs/guides/auth/auth-anonymous\#convert-an-anonymous-user-to-a-permanent-user)

Converting an anonymous user to a permanent user requires [linking an identity](https://supabase.com/docs/guides/auth/auth-identity-linking#manual-linking-beta) to the user. This requires you to [enable manual linking](https://supabase.com/dashboard/project/_/settings/auth) in your Supabase project.

### Link an email / phone identity [\#](https://supabase.com/docs/guides/auth/auth-anonymous\#link-an-email--phone-identity)

JavaScriptFlutterSwiftKotlinPython

You can use the [`updateUser()`](https://supabase.com/docs/reference/javascript/auth-updateuser) method to link an email or phone identity to the anonymous user. To add a password for the anonymous user, the user's email or phone number needs to be verified first.

`
const { data, error } = await supabase.auth.updateUser({ email: 'valid.email@supabase.io' })
// verify the user's email by clicking on the email change link
// or entering the 6-digit OTP sent to the email address
// once the user has been verified, update the password
const { data, error } = await supabase.auth.updateUser({ password: 'password' })
`

### Link an OAuth identity [\#](https://supabase.com/docs/guides/auth/auth-anonymous\#link-an-oauth-identity)

JavaScriptFlutterSwiftKotlinPython

You can use the [`linkIdentity()`](https://supabase.com/docs/reference/javascript/auth-linkidentity) method to link an OAuth identity to the anonymous user.

`
const { data, error } = await supabase.auth.linkIdentity({ provider: 'google' })
`

## Access control [\#](https://supabase.com/docs/guides/auth/auth-anonymous\#access-control)

An anonymous user assumes the `authenticated` role just like a permanent user. You can use row-level security (RLS) policies to differentiate between an anonymous user and a permanent user by checking for the `is_anonymous` claim in the JWT returned by `auth.jwt()`:

`
create policy "Only permanent users can post to the news feed"
on news_feed as restrictive for insert
to authenticated
with check ((select (auth.jwt()->>'is_anonymous')::boolean) is false );
create policy "Anonymous and permanent users can view the news feed"
on news_feed for select
to authenticated
using ( true );
`

##### Use restrictive policies

RLS policies are permissive by default, which means that they are combined using an "OR" operator when multiple policies are applied. It is important to construct restrictive policies to ensure that the checks for an anonymous user are always enforced when combined with other policies.

## Resolving identity conflicts [\#](https://supabase.com/docs/guides/auth/auth-anonymous\#resolving-identity-conflicts)

Depending on your application requirements, data conflicts can arise when an anonymous user is converted to a permanent user. For example, in the context of an e-commerce application, an anonymous user would be allowed to add items to the shopping cart without signing up / signing in. When they decide to sign-in to an existing account, you will need to decide how you want to resolve data conflicts in the shopping cart:

1. Overwrite the items in the cart with those in the existing account
2. Overwrite the items in the cart with those from the anonymous user
3. Merge the items in the cart together

### Linking an anonymous user to an existing account [\#](https://supabase.com/docs/guides/auth/auth-anonymous\#linking-an-anonymous-user-to-an-existing-account)

In some cases, you may need to link an anonymous user to an existing account rather than creating a new permanent account. This process requires manual handling of potential conflicts. Here's a general approach:

`
// 1. Sign in anonymously (assuming the user is already signed in anonymously)
const { data: anonData, error: anonError } = await supabase.auth.getSession()
// 2. Attempt to update the user with the existing email
const { data: updateData, error: updateError } = await supabase.auth.updateUser({
email: 'valid.email@supabase.io',
})
// 3. Handle the error (since the email belongs to an existing user)
if (updateError) {
console.log('This email belongs to an existing user. Please sign in to that account.')
// 4. Sign in to the existing account
const {
    data: { user: existingUser },
    error: signInError,
} = await supabase.auth.signInWithPassword({
    email: 'valid.email@supabase.io',
    password: 'user_password',
})
if (existingUser) {
    // 5. Reassign entities tied to the anonymous user
    // This step will vary based on your specific use case and data model
    const { data: reassignData, error: reassignError } = await supabase
      .from('your_table')
      .update({ user_id: existingUser.id })
      .eq('user_id', anonData.session.user.id)
    // 6. Implement your chosen conflict resolution strategy
    // This could involve merging data, overwriting, or other custom logic
    await resolveDataConflicts(anonData.session.user.id, existingUser.id)
}
}
// Helper function to resolve data conflicts (implement based on your strategy)
async function resolveDataConflicts(anonymousUserId, existingUserId) {
// Implement your conflict resolution logic here
// This could involve ignoring the anonymous user's metadata, overwriting the existing user's metadata, or merging the data of both the anonymous and existing user.
}
`

## Abuse prevention and rate limits [\#](https://supabase.com/docs/guides/auth/auth-anonymous\#abuse-prevention-and-rate-limits)

Since anonymous users are stored in your database, bad actors can abuse the endpoint to increase your database size drastically. It is strongly recommended to [enable invisible CAPTCHA or Cloudflare Turnstile](https://supabase.com/docs/guides/auth/auth-captcha) to prevent abuse for anonymous sign-ins. An IP-based rate limit is enforced at 30 requests per hour which can be modified in your [dashboard](https://supabase.com/dashboard/project/_/auth/rate-limits). You can refer to the full list of rate limits [here](https://supabase.com/docs/guides/platform/going-into-prod#rate-limiting-resource-allocation--abuse-prevention).

## Automatic cleanup [\#](https://supabase.com/docs/guides/auth/auth-anonymous\#automatic-cleanup)

Automatic cleanup of anonymous users is currently not available. Instead, you can delete anonymous users from your project by running the following SQL:

`
-- deletes anonymous users created more than 30 days ago
delete from auth.users
where is_anonymous is true and created_at < now() - interval '30 days';
`

## Resources [\#](https://supabase.com/docs/guides/auth/auth-anonymous\#resources)

- [Supabase - Get started for free](https://supabase.com/)
- [Supabase JS Client](https://github.com/supabase/supabase-js)
- [Supabase Flutter Client](https://github.com/supabase/supabase-flutter)
- [Supabase Kotlin Client](https://github.com/supabase-community/supabase-kt)

### Is this helpful?

NoYes

### On this page

[Sign in anonymously](https://supabase.com/docs/guides/auth/auth-anonymous#sign-in-anonymously) [Convert an anonymous user to a permanent user](https://supabase.com/docs/guides/auth/auth-anonymous#convert-an-anonymous-user-to-a-permanent-user) [Link an email / phone identity](https://supabase.com/docs/guides/auth/auth-anonymous#link-an-email--phone-identity) [Link an OAuth identity](https://supabase.com/docs/guides/auth/auth-anonymous#link-an-oauth-identity) [Access control](https://supabase.com/docs/guides/auth/auth-anonymous#access-control) [Resolving identity conflicts](https://supabase.com/docs/guides/auth/auth-anonymous#resolving-identity-conflicts) [Linking an anonymous user to an existing account](https://supabase.com/docs/guides/auth/auth-anonymous#linking-an-anonymous-user-to-an-existing-account) [Abuse prevention and rate limits](https://supabase.com/docs/guides/auth/auth-anonymous#abuse-prevention-and-rate-limits) [Automatic cleanup](https://supabase.com/docs/guides/auth/auth-anonymous#automatic-cleanup) [Resources](https://supabase.com/docs/guides/auth/auth-anonymous#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_auth_captcha.md">
Auth

# Enable CAPTCHA Protection

* * *

Supabase provides you with the option of adding CAPTCHA to your sign-in, sign-up, and password reset forms. This keeps your website safe from bots and malicious scripts. Supabase authentication has support for [hCaptcha](https://www.hcaptcha.com/) and [Cloudflare Turnstile](https://www.cloudflare.com/products/turnstile/).

## Sign up for CAPTCHA [\#](https://supabase.com/docs/guides/auth/auth-captcha\#sign-up-for-captcha)

HCaptchaTurnstile

Go to the [hCaptcha](https://www.hcaptcha.com/) website and sign up for an account. On the Welcome page, copy the **Sitekey** and **Secret key**.

If you have already signed up and didn't copy this information from the Welcome page, you can get the **Secret key** from the Settings page.

![site_secret_settings.png](https://supabase.com/docs/img/guides/auth-captcha/site_secret_settings.png)

The **Sitekey** can be found in the **Settings** of the active site you created.

![sites_dashboard.png](https://supabase.com/docs/img/guides/auth-captcha/sites_dashboard.png)

In the Settings page, look for the **Sitekey** section and copy the key.

![sitekey_settings.png](https://supabase.com/docs/img/guides/auth-captcha/sitekey_settings.png)

## Enable CAPTCHA protection for your Supabase project [\#](https://supabase.com/docs/guides/auth/auth-captcha\#enable-captcha-protection-for-your-supabase-project)

Navigate to the **[Auth](https://supabase.com/dashboard/project/_/settings/auth)** section of your Project Settings in the Supabase Dashboard and find the **Enable CAPTCHA protection** toggle under Settings > Authentication > Bot and Abuse Protection > Enable CAPTCHA protection.

Select your CAPTCHA provider from the dropdown, enter your CAPTCHA **Secret key**, and click **Save**.

## Add the CAPTCHA frontend component [\#](https://supabase.com/docs/guides/auth/auth-captcha\#add-the-captcha-frontend-component)

The frontend requires some changes to provide the CAPTCHA on-screen for the user. This example uses React and the corresponding CAPTCHA React component, but both CAPTCHA providers can be used with any JavaScript framework.

HCaptchaTurnstile

Install `@hcaptcha/react-hcaptcha` in your project as a dependency.

`
npm install @hcaptcha/react-hcaptcha
`

Now import the `HCaptcha` component from the `@hcaptcha/react-hcaptcha` library.

`
import HCaptcha from '@hcaptcha/react-hcaptcha'
`

Let's create a empty state to store our `captchaToken`

`
const [captchaToken, setCaptchaToken] = useState()
`

Now lets add the `HCaptcha` component to the JSX section of our code

`
<HCaptcha />
`

We will pass it the sitekey we copied from the hCaptcha website as a property along with a `onVerify` property which takes a callback function. This callback function will have a token as one of its properties. Let's set the token in the state using `setCaptchaToken`

`
<HCaptcha
sitekey="your-sitekey"
onVerify={(token) => {
    setCaptchaToken(token)
}}
/>
`

Now lets use the CAPTCHA token we receive in our Supabase signUp function.

`
await supabase.auth.signUp({
email,
password,
options: { captchaToken },
})
`

We will also need to reset the CAPTCHA challenge after we have made a call to the function above.

Create a ref to use on our `HCaptcha` component.

`
const captcha = useRef()
`

Let's add a ref attribute on the `HCaptcha` component and assign the `captcha` constant to it.

`
<HCaptcha
ref={captcha}
sitekey="your-sitekey"
onVerify={(token) => {
    setCaptchaToken(token)
}}
/>
`

Reset the `captcha` after the signUp function is called using the following code:

`
captcha.current.resetCaptcha()
`

In order to test that this works locally we will need to use something like [ngrok](https://ngrok.com/) or add an entry to your hosts file. You can read more about this in the [hCaptcha docs](https://docs.hcaptcha.com/#local-development).

Run the application and you should now be provided with a CAPTCHA challenge.

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2Fem1cpOAXknM%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Sign up for CAPTCHA](https://supabase.com/docs/guides/auth/auth-captcha#sign-up-for-captcha) [Enable CAPTCHA protection for your Supabase project](https://supabase.com/docs/guides/auth/auth-captcha#enable-captcha-protection-for-your-supabase-project) [Add the CAPTCHA frontend component](https://supabase.com/docs/guides/auth/auth-captcha#add-the-captcha-frontend-component)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_auth_email_passwordless.md">
Auth

# Passwordless email logins

## Email logins using Magic Links or One-Time Passwords (OTPs)

* * *

Supabase Auth provides several passwordless login methods. Passwordless logins allow users to sign in without a password, by clicking a confirmation link or entering a verification code.

Passwordless login can:

- Improve the user experience by not requiring users to create and remember a password
- Increase security by reducing the risk of password-related security breaches
- Reduce support burden of dealing with password resets and other password-related flows

Supabase Auth offers two passwordless login methods that use the user's email address:

- [Magic Link](https://supabase.com/docs/guides/auth/auth-email-passwordless#with-magic-link)
- [OTP](https://supabase.com/docs/guides/auth/auth-email-passwordless#with-otp)

## With Magic Link [\#](https://supabase.com/docs/guides/auth/auth-email-passwordless\#with-magic-link)

Magic Links are a form of passwordless login where users click on a link sent to their email address to log in to their accounts. Magic Links only work with email addresses and are one-time use only.

### Enabling Magic Link [\#](https://supabase.com/docs/guides/auth/auth-email-passwordless\#enabling-magic-link)

Email authentication methods, including Magic Links, are enabled by default.

Configure the Site URL and any additional redirect URLs. These are the only URLs that are allowed as redirect destinations after the user clicks a Magic Link. You can change the URLs on the [Auth Providers page](https://supabase.com/dashboard/project/_/auth/providers) for hosted projects, or in the [configuration file](https://supabase.com/docs/guides/cli/config#auth.additional_redirect_urls) for self-hosted projects.

By default, a user can only request a magic link once every 60 seconds and they expire after 1 hour.

### Signing in with Magic Link [\#](https://supabase.com/docs/guides/auth/auth-email-passwordless\#signing-in-with-magic-link)

Call the "sign in with OTP" method from the client library.

Though the method is labelled "OTP", it sends a Magic Link by default. The two methods differ only in the content of the confirmation email sent to the user.

If the user hasn't signed up yet, they are automatically signed up by default. To prevent this, set the `shouldCreateUser` option to `false`.

JavaScriptExpo React NativeDartSwiftKotlinPython

`
async function signInWithEmail() {
const { data, error } = await supabase.auth.signInWithOtp({
    email: 'valid.email@supabase.io',
    options: {
      // set this to false if you do not want the user to be automatically signed up
      shouldCreateUser: false,
      emailRedirectTo: 'https://example.com/welcome',
    },
})
}
`

That's it for the implicit flow.

If you're using PKCE flow, edit the Magic Link [email template](https://supabase.com/docs/guides/auth/auth-email-templates) to send a token hash:

`
<h2>Magic Link</h2>
<p>Follow this link to login:</p>
<p><a href="{{ .SiteURL }}/auth/confirm?token_hash={{ .TokenHash }}&type=email">Log In</a></p>
`

At the `/auth/confirm` endpoint, exchange the hash for the session:

`
const { error } = await supabase.auth.verifyOtp({ token_hash, type })
`

## With OTP [\#](https://supabase.com/docs/guides/auth/auth-email-passwordless\#with-otp)

Email one-time passwords (OTP) are a form of passwordless login where users key in a six digit code sent to their email address to log in to their accounts.

### Enabling email OTP [\#](https://supabase.com/docs/guides/auth/auth-email-passwordless\#enabling-email-otp)

Email authentication methods, including Email OTPs, are enabled by default.

Email OTPs share an implementation with Magic Links. To send an OTP instead of a Magic Link, alter the **Magic Link** email template. For a hosted Supabase project, go to [Email Templates](https://supabase.com/dashboard/project/_/auth/templates) in the Dashboard. For a self-hosted project or local development, see the [Email Templates guide](https://supabase.com/docs/guides/auth/auth-email-templates).

Modify the template to include the `{{ .Token }}` variable, for example:

`
<h2>One time login code</h2>
<p>Please enter this code: {{ .Token }}</p>
`

By default, a user can only request an OTP once every 60 seconds and they expire after 1 hour. This is configurable via `Auth > Providers > Email > Email OTP Expiration`. An expiry duration of more than 86400 seconds (one day) is disallowed to guard against brute force attacks. The longer an OTP remains valid, the more time an attacker has to attempt brute force attacks. If the OTP is valid for several days, an attacker might have more opportunities to guess the correct OTP through repeated attempts.

### Signing in with email OTP [\#](https://supabase.com/docs/guides/auth/auth-email-passwordless\#signing-in-with-email-otp)

#### Step 1: Send the user an OTP code [\#](https://supabase.com/docs/guides/auth/auth-email-passwordless\#step-1-send-the-user-an-otp-code)

Get the user's email and call the "sign in with OTP" method from your client library.

If the user hasn't signed up yet, they are automatically signed up by default. To prevent this, set the `shouldCreateUser` option to `false`.

JavaScriptDartSwiftKotlinPython

`
const { data, error } = await supabase.auth.signInWithOtp({
email: 'valid.email@supabase.io',
options: {
    // set this to false if you do not want the user to be automatically signed up
    shouldCreateUser: false,
},
})
`

If the request is successful, you receive a response with `error: null` and a `data` object where both `user` and `session` are null. Let the user know to check their email inbox.

`
{
"data": {
    "user": null,
    "session": null
},
"error": null
}
`

#### Step 2: Verify the OTP to create a session [\#](https://supabase.com/docs/guides/auth/auth-email-passwordless\#step-2-verify-the-otp-to-create-a-session)

Provide an input field for the user to enter their one-time code.

Call the "verify OTP" method from your client library with the user's email address, the code, and a type of `email`:

JavaScriptSwiftKotlinPython

`
const {
data: { session },
error,
} = await supabase.auth.verifyOtp({
email,
token: '123456',
type: 'email',
})
`

If successful, the user is now logged in, and you receive a valid session that looks like:

`
{
"access_token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJhdXRoZW50aWNhdGVkIiwiZXhwIjoxNjI3MjkxNTc3LCJzdWIiOiJmYTA2NTQ1Zi1kYmI1LTQxY2EtYjk1NC1kOGUyOTg4YzcxOTEiLCJlbWFpbCI6IiIsInBob25lIjoiNjU4NzUyMjAyOSIsImFwcF9tZXRhZGF0YSI6eyJwcm92aWRlciI6InBob25lIn0sInVzZXJfbWV0YWRhdGEiOnt9LCJyb2xlIjoiYXV0aGVudGljYXRlZCJ9.1BqRi0NbS_yr1f6hnr4q3s1ylMR3c1vkiJ4e_N55dhM",
"token_type": "bearer",
"expires_in": 3600,
"refresh_token": "LSp8LglPPvf0DxGMSj-vaQ",
"user": {...}
}
`

### Is this helpful?

NoYes

### On this page

[With Magic Link](https://supabase.com/docs/guides/auth/auth-email-passwordless#with-magic-link) [Enabling Magic Link](https://supabase.com/docs/guides/auth/auth-email-passwordless#enabling-magic-link) [Signing in with Magic Link](https://supabase.com/docs/guides/auth/auth-email-passwordless#signing-in-with-magic-link) [With OTP](https://supabase.com/docs/guides/auth/auth-email-passwordless#with-otp) [Enabling email OTP](https://supabase.com/docs/guides/auth/auth-email-passwordless#enabling-email-otp) [Signing in with email OTP](https://supabase.com/docs/guides/auth/auth-email-passwordless#signing-in-with-email-otp)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_auth_email_templates.md">
Auth

# Email Templates

## Learn how to manage the email templates in Supabase.

* * *

You can customize the email messages used for the authentication flows. You can edit the following email templates:

- Confirm signup
- Invite user
- Magic Link
- Change Email Address
- Reset Password

## Terminology [\#](https://supabase.com/docs/guides/auth/auth-email-templates\#terminology)

The templating system provides the following variables for use:

| Name | Description |
| --- | --- |
| `{{ .ConfirmationURL }}` | Contains the confirmation URL. For example, a signup confirmation URL would look like: `https://project-ref.supabase.co/auth/v1/verify?token={{ .TokenHash }}&type=email&redirect_to=https://example.com/path` . |
| `{{ .Token }}` | Contains a 6-digit One-Time-Password (OTP) that can be used instead of the `{{. ConfirmationURL }}` . |
| `{{ .TokenHash }}` | Contains a hashed version of the `{{ .Token }}`. This is useful for constructing your own email link in the email template. |
| `{{ .SiteURL }}` | Contains your application's Site URL. This can be configured in your project's [authentication settings](https://supabase.com/dashboard/project/_/auth/url-configuration). |
| `{{ .RedirectTo }}` | Contains the redirect URL passed when `signUp`, `signInWithOtp`, `signInWithOAuth`, `resetPasswordForEmail` or `inviteUserByEmail` is called. The redirect URL allow list can be configured in your project's [authentication settings](https://supabase.com/dashboard/project/_/auth/url-configuration). |
| `{{ .Data }}` | Contains metadata from `auth.users.user_metadata`. Use this to personalize the email message. |

## Editing email templates [\#](https://supabase.com/docs/guides/auth/auth-email-templates\#editing-email-templates)

On hosted Supabase projects, edit your email templates on the [Email Templates](https://supabase.com/dashboard/project/_/auth/templates) page. On self-hosted projects or in local development, edit your [configuration files](https://supabase.com/docs/guides/local-development/customizing-email-templates).

## Mobile deep linking [\#](https://supabase.com/docs/guides/auth/auth-email-templates\#mobile-deep-linking)

For mobile applications, you might need to link or redirect to a specific page within your app. See the [Mobile Deep Linking guide](https://supabase.com/docs/guides/auth/native-mobile-deep-linking) to set this up.

## Limitations [\#](https://supabase.com/docs/guides/auth/auth-email-templates\#limitations)

### Email prefetching [\#](https://supabase.com/docs/guides/auth/auth-email-templates\#email-prefetching)

Certain email providers may have spam detection or other security features that prefetch URL links from incoming emails (e.g. [Safe Links in Microsoft Defender for Office 365](https://learn.microsoft.com/en-us/microsoft-365/security/office-365-security/safe-links-about?view=o365-worldwide)).
In this scenario, the `{{ .ConfirmationURL }}` sent will be consumed instantly which leads to a "Token has expired or is invalid" error.
To guard against this:

- Use an email OTP instead by including `{{ .Token }}` in the email template.

- Create your own custom email link to redirect the user to a page where they can click on a button to confirm the action.
For example, you can include the following in your email template:



`
<a href="{{ .SiteURL }}/confirm-signup?confirmation_url={{ .ConfirmationURL }}"
>Confirm your signup
</a>
`



The user should be brought to a page on your site where they can confirm the action by clicking a button.
The button should contain the actual confirmation link which can be obtained from parsing the `confirmation_url={{ .ConfirmationURL }}` query parameter in the URL.


### Email tracking [\#](https://supabase.com/docs/guides/auth/auth-email-templates\#email-tracking)

If you are using an external email provider that enables "email tracking", the links inside the Supabase email templates will be overwritten and won't perform as expected. We recommend disabling email tracking to ensure email links are not overwritten.

### Redirecting the user to a server-side endpoint [\#](https://supabase.com/docs/guides/auth/auth-email-templates\#redirecting-the-user-to-a-server-side-endpoint)

If you intend to use [Server-side rendering](https://supabase.com/docs/guides/auth/server-side-rendering), you might want the email link to redirect the user to a server-side endpoint to check if they are authenticated before returning the page. However, the default email link will redirect the user after verification to the redirect URL with the session in the query fragments. Since the session is returned in the query fragments by default, you won't be able to access it on the server-side.

You can customize the email link in the email template to redirect the user to a server-side endpoint successfully. For example:

`
<a
href="https://api.example.com/v1/authenticate?token_hash={{ .TokenHash }}&type=invite&redirect_to={{ .RedirectTo }}"
>Accept the invite
</a>
`

When the user clicks on the link, the request will hit `https://api.example.com/v1/authenticate` and you can grab the `token_hash`, `type` and `redirect_to` query parameters from the URL. Then, you can call the [`verifyOtp`](https://supabase.com/docs/reference/javascript/auth-verifyotp) method to get back an authenticated session before redirecting the user back to the client. Since the `verifyOtp` method makes a `POST` request to Supabase Auth to verify the user, the session will be returned in the response body, which can be read by the server. For example:

`
const { token_hash, type } = Object.fromEntries(new URLSearchParams(window.location.search))
const {
data: { session },
error,
} = await supabase.auth.verifyOtp({ token_hash, type })
// subsequently redirect the user back to the client using the redirect_to param
// ...
`

## Customization [\#](https://supabase.com/docs/guides/auth/auth-email-templates\#customization)

Supabase Auth makes use of [Go Templates](https://pkg.go.dev/text/template). This means it is possible to conditionally render information based on template properties.

### Send different email to early access users [\#](https://supabase.com/docs/guides/auth/auth-email-templates\#send-different-email-to-early-access-users)

Send a different email to users who signed up via an early access domain ( `https://www.earlyaccess.trial.com`).

`
{{ if eq .Data.Domain "https://www.example.com" }}
<h1>Welcome to Our Database Service!</h1>
<p>Dear Developer,</p>
<p>Welcome to Billy, the scalable developer platform!</p>
<p>Best Regards,<br>
Billy Team</p>
{{ else if eq .Data.Domain "https://www.earlyaccess.trial.com" }}
<h1>Welcome to Our Database Service!</h1>
<p>Dear Developer,</p>
<p>Welcome Billy, the scalable developer platform!</p>
<p> As an early access member, you have access to select features like Point To Space Restoration.</p>
<p>Best Regards,<br>
Billy Team</p>
{{ end }}
`

### Is this helpful?

NoYes

### On this page

[Terminology](https://supabase.com/docs/guides/auth/auth-email-templates#terminology) [Editing email templates](https://supabase.com/docs/guides/auth/auth-email-templates#editing-email-templates) [Mobile deep linking](https://supabase.com/docs/guides/auth/auth-email-templates#mobile-deep-linking) [Limitations](https://supabase.com/docs/guides/auth/auth-email-templates#limitations) [Email prefetching](https://supabase.com/docs/guides/auth/auth-email-templates#email-prefetching) [Email tracking](https://supabase.com/docs/guides/auth/auth-email-templates#email-tracking) [Redirecting the user to a server-side endpoint](https://supabase.com/docs/guides/auth/auth-email-templates#redirecting-the-user-to-a-server-side-endpoint) [Customization](https://supabase.com/docs/guides/auth/auth-email-templates#customization) [Send different email to early access users](https://supabase.com/docs/guides/auth/auth-email-templates#send-different-email-to-early-access-users)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_auth_helpers_auth_ui.md">
Auth

# Auth UI

* * *

As of 7th Feb 2024, [this repository](https://github.com/supabase-community/auth-ui) is no longer maintained by the Supabase Team. At the moment, the team does not have capacity to give the expected level of care to this repository. We may revisit Auth UI in the future but regrettably have to leave it on hold for now as we focus on other priorities such as improving the Server-Side Rendering (SSR) package and advanced Auth primitives.

Auth UI is a pre-built React component for authenticating users.
It supports custom themes and extensible styles to match your brand and aesthetic.

## Set up Auth UI [\#](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui\#set-up-auth-ui)

Install the latest version of [supabase-js](https://supabase.com/docs/reference/javascript) and the Auth UI package:

`
npm install @supabase/supabase-js @supabase/auth-ui-react @supabase/auth-ui-shared
`

### Import the Auth component [\#](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui\#import-the-auth-component)

Pass `supabaseClient` from `@supabase/supabase-js` as a prop to the component.

/src/index.js

`
import { createClient } from '@supabase/supabase-js'
import { Auth } from '@supabase/auth-ui-react'
const supabase = createClient('<INSERT PROJECT URL>', '<INSERT PROJECT ANON API KEY>')
const App = () => <Auth supabaseClient={supabase} />
`

This renders the Auth component without any styling.
We recommend using one of the predefined themes to style the UI.
Import the theme you want to use and pass it to the `appearance.theme` prop.

`
import { Auth } from '@supabase/auth-ui-react'
import {
// Import predefined theme
ThemeSupa,
} from '@supabase/auth-ui-shared'
const supabase = createClient(
'<INSERT PROJECT URL>',
'<INSERT PROJECT ANON API KEY>'
)
const App = () => (
<Auth
    supabaseClient={supabase}
    {/* Apply predefined theme */}
    appearance={{ theme: ThemeSupa }}
/>
)
`

### Social providers [\#](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui\#social-providers)

The Auth component also supports login with [official social providers](https://supabase.com/docs/guides/auth#providers).

`
import { createClient } from '@supabase/supabase-js'
import { Auth } from '@supabase/auth-ui-react'
import { ThemeSupa } from '@supabase/auth-ui-shared'
const supabase = createClient('<INSERT PROJECT URL>', '<INSERT PROJECT ANON API KEY>')
const App = () => (
<Auth
    supabaseClient={supabase}
    appearance={{ theme: ThemeSupa }}
    providers={['google', 'facebook', 'twitter']}
/>
)
`

### Options [\#](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui\#options)

Options are available via `queryParams`:

`
<Auth
supabaseClient={supabase}
providers={['google']}
queryParams={{
    access_type: 'offline',
    prompt: 'consent',
    hd: 'domain.com',
}}
onlyThirdPartyProviders
/>
`

### Provider scopes [\#](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui\#provider-scopes)

Provider Scopes can be requested through `providerScope`;

`
<Auth
supabaseClient={supabase}
providers={['google']}
queryParams={{
    access_type: 'offline',
    prompt: 'consent',
    hd: 'domain.com',
}}
providerScopes={{
    google: 'https://www.googleapis.com/auth/calendar.readonly',
}}
/>
`

### Supported views [\#](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui\#supported-views)

The Auth component is currently shipped with the following views:

- [Email Login](https://supabase.com/docs/guides/auth/auth-email)
- [Magic Link login](https://supabase.com/docs/guides/auth/auth-magic-link)
- [Social Login](https://supabase.com/docs/guides/auth/social-login)
- Update password
- Forgotten password

We are planning on adding more views in the future. Follow along on that [repo](https://github.com/supabase/auth-ui).

## Customization [\#](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui\#customization)

There are several ways to customize Auth UI:

- Use one of the [predefined themes](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui#predefined-themes) that comes with Auth UI
- Extend a theme by [overriding the variable tokens](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui#override-themes) in a theme
- [Create your own theme](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui#create-theme)
- [Use your own CSS classes](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui#custom-css-classes)
- [Use inline styles](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui#custom-inline-styles)
- [Use your own labels](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui#custom-labels)

### Predefined themes [\#](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui\#predefined-themes)

Auth UI comes with several themes to customize the appearance. Each predefined theme comes with at least two variations, a `default` variation, and a `dark` variation. You can switch between these themes using the `theme` prop. Import the theme you want to use and pass it to the `appearance.theme` prop.

`
import { createClient } from '@supabase/supabase-js'
import { Auth } from '@supabase/auth-ui-react'
import { ThemeSupa } from '@supabase/auth-ui-shared'
const supabase = createClient(
'<INSERT PROJECT URL>',
'<INSERT PROJECT ANON API KEY>'
)
const App = () => (
<Auth
    supabaseClient={supabase}
    {/* Apply predefined theme */}
    appearance={{ theme: ThemeSupa }}
/>
)
`

Currently there is only one predefined theme available, but we plan to add more.

### Switch theme variations [\#](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui\#switch-theme-variations)

Auth UI comes with two theme variations: `default` and `dark`. You can switch between these themes with the `theme` prop.

`
import { createClient } from '@supabase/supabase-js'
import { Auth } from '@supabase/auth-ui-react'
import { ThemeSupa } from '@supabase/auth-ui-shared'
const supabase = createClient(
'<INSERT PROJECT URL>',
'<INSERT PROJECT ANON API KEY>'
)
const App = () => (
<Auth
    supabaseClient={supabase}
    appearance={{ theme: ThemeSupa }}
    {/* Set theme to dark */}
    theme="dark"
/>
)
`

If you don't pass a value to `theme` it uses the `"default"` theme. You can pass `"dark"` to the theme prop to switch to the `dark` theme. If your theme has other variations, use the name of the variation in this prop.

### Override themes [\#](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui\#override-themes)

Auth UI themes can be overridden using variable tokens. See the [list of variable tokens](https://github.com/supabase/auth-ui/blob/main/packages/shared/src/theming/Themes.ts).

`
import { createClient } from '@supabase/supabase-js'
import { Auth } from '@supabase/auth-ui-react'
import { ThemeSupa } from '@supabase/auth-ui-shared'
const supabase = createClient('<INSERT PROJECT URL>', '<INSERT PROJECT ANON API KEY>')
const App = () => (
<Auth
    supabaseClient={supabase}
    appearance={{
      theme: ThemeSupa,
      variables: {
        default: {
          colors: {
            brand: 'red',
            brandAccent: 'darkred',
          },
        },
      },
    }}
/>
)
`

If you created your own theme, you may not need to override any of them.

### Create your own theme [\#](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui\#create-theme)

You can create your own theme by following the same structure within a `appearance.theme` property.
See the list of [tokens within a theme](https://github.com/supabase/auth-ui/blob/main/packages/shared/src/theming/Themes.ts).

/src/index.js

`
import { createClient } from '@supabase/supabase-js'
import { Auth } from '@supabase/auth-ui-react'
const supabase = createClient('<INSERT PROJECT URL>', '<INSERT PROJECT ANON API KEY>')
const customTheme = {
default: {
    colors: {
      brand: 'hsl(153 60.0% 53.0%)',
      brandAccent: 'hsl(154 54.8% 45.1%)',
      brandButtonText: 'white',
      // ..
    },
},
dark: {
    colors: {
      brandButtonText: 'white',
      defaultButtonBackground: '#2e2e2e',
      defaultButtonBackgroundHover: '#3e3e3e',
      //..
    },
},
// You can also add more theme variations with different names.
evenDarker: {
    colors: {
      brandButtonText: 'white',
      defaultButtonBackground: '#1e1e1e',
      defaultButtonBackgroundHover: '#2e2e2e',
      //..
    },
},
}
const App = () => (
<Auth
    supabaseClient={supabase}
    theme="default" // can also be "dark" or "evenDarker"
    appearance={{ theme: customTheme }}
/>
)
`

You can switch between different variations of your theme with the ["theme" prop](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui#switch-theme-variations).

### Custom CSS classes [\#](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui\#custom-css-classes)

You can use custom CSS classes for the following elements:
`"button"`, `"container"`, `"anchor"`, `"divider"`, `"label"`, `"input"`, `"loader"`, `"message"`.

/src/index.js

`
import { createClient } from '@supabase/supabase-js'
import { Auth } from '@supabase/auth-ui-react'
const supabase = createClient('<INSERT PROJECT URL>', '<INSERT PROJECT ANON API KEY>')
const App = () => (
<Auth
    supabaseClient={supabase}
    appearance={{
      // If you want to extend the default styles instead of overriding it, set this to true
      extend: false,
      // Your custom classes
      className: {
        anchor: 'my-awesome-anchor',
        button: 'my-awesome-button',
        //..
      },
    }}
/>
)
`

### Custom inline CSS [\#](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui\#custom-inline-styles)

You can use custom CSS inline styles for the following elements:
`"button"`, `"container"`, `"anchor"`, `"divider"`, `"label"`, `"input"`, `"loader"`, `"message"`.

/src/index.js

`
import { createClient } from '@supabase/supabase-js'
import { Auth } from '@supabase/auth-ui-react'
const supabase = createClient('<INSERT PROJECT URL>', '<INSERT PROJECT ANON API KEY>')
const App = () => (
<Auth
    supabaseClient={supabase}
    appearance={{
      style: {
        button: { background: 'red', color: 'white' },
        anchor: { color: 'blue' },
        //..
      },
    }}
/>
)
`

### Custom labels [\#](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui\#custom-labels)

You can use custom labels with `localization.variables` like so:

`
import { createClient } from '@supabase/supabase-js'
import { Auth } from '@supabase/auth-ui-react'
const supabase = createClient('<INSERT PROJECT URL>', '<INSERT PROJECT ANON API KEY>')
const App = () => (
<Auth
    supabaseClient={supabase}
    localization={{
      variables: {
        sign_in: {
          email_label: 'Your email address',
          password_label: 'Your strong password',
        },
      },
    }}
/>
)
`

A full list of the available variables is below:

Sign UpSign InMagic LinkForgotten PasswordUpdate PasswordVerify OTP

| Label Tag | Default Label |
| --- | --- |
| `email_label` | Email address |
| `password_label` | Create a Password |
| `email_input_placeholder` | Your email address |
| `password_input_placeholder` | Your password |
| `button_label` | Sign up |
| `loading_button_label` | Signing up ... |
| `social_provider_text` | Sign in with `{{provider}}` |
| `link_text` | Don't have an account? Sign up |
| `confirmation_text` | Check your email for the confirmation link |

Currently, translating error messages (e.g. "Invalid credentials") is not supported. Check [related issue.](https://github.com/supabase/auth-ui/issues/86)

### Hiding links [\#](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui\#hiding-links)

You can hide links by setting the `showLinks` prop to `false`

`
import { createClient } from '@supabase/supabase-js'
import { Auth } from '@supabase/auth-ui-react'
const supabase = createClient('<INSERT PROJECT URL>', '<INSERT PROJECT ANON API KEY>')
const App = () => <Auth supabaseClient={supabase} showLinks={false} />
`

Setting `showLinks` to `false` will hide the following links:

- Don't have an account? Sign up
- Already have an account? Sign in
- Send a magic link email
- Forgot your password?

### Sign in and sign up views [\#](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui\#sign-in-and-sign-up-views)

Add `sign_in` or `sign_up` views with the `view` prop:

`
<Auth
supabaseClient={supabase}
view="sign_up"
/>
`

### Is this helpful?

NoYes

### On this page

[Set up Auth UI](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui#set-up-auth-ui) [Import the Auth component](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui#import-the-auth-component) [Social providers](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui#social-providers) [Options](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui#options) [Provider scopes](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui#provider-scopes) [Supported views](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui#supported-views) [Customization](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui#customization) [Predefined themes](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui#predefined-themes) [Switch theme variations](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui#switch-theme-variations) [Override themes](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui#override-themes) [Create your own theme](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui#create-theme) [Custom CSS classes](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui#custom-css-classes) [Custom inline CSS](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui#custom-inline-styles) [Custom labels](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui#custom-labels) [Hiding links](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui#hiding-links) [Sign in and sign up views](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui#sign-in-and-sign-up-views)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_auth_helpers_flutter_auth_ui.md">
Auth

# Flutter Auth UI

* * *

Flutter Auth UI is a Flutter package containing pre-built widgets for authenticating users.
It is unstyled and can match your brand and aesthetic.

![Flutter Auth UI](https://raw.githubusercontent.com/supabase-community/flutter-auth-ui/main/screenshots/supabase_auth_ui.png)

## Add Flutter Auth UI [\#](https://supabase.com/docs/guides/auth/auth-helpers/flutter-auth-ui\#add-flutter-auth-ui)

Add the latest version of the package [supabase-auth-ui](https://pub.dev/packages/supabase_auth_ui) to pubspec.yaml:

`
flutter pub add supabase_auth_ui
`

### Initialize the Flutter Auth package [\#](https://supabase.com/docs/guides/auth/auth-helpers/flutter-auth-ui\#initialize-the-flutter-auth-package)

`
import 'package:flutter/material.dart';
import 'package:supabase_auth_ui/supabase_auth_ui.dart';
void main() async {
await Supabase.initialize(
    url: dotenv.get('SUPABASE_URL'),
    anonKey: dotenv.get('SUPABASE_ANON_KEY'),
);
runApp(const MyApp());
}
`

### Email Auth [\#](https://supabase.com/docs/guides/auth/auth-helpers/flutter-auth-ui\#email-auth)

Use a `SupaEmailAuth` widget to create an email and password signin and signup form. It also contains a button to toggle to display a forgot password form.

You can pass `metadataFields` to add additional fields to the form to pass as metadata to Supabase.

`
SupaEmailAuth(
redirectTo: kIsWeb ? null : 'io.mydomain.myapp://callback',
onSignInComplete: (response) {},
onSignUpComplete: (response) {},
metadataFields: [\
    MetaDataField(\
    prefixIcon: const Icon(Icons.person),\
    label: 'Username',\
    key: 'username',\
    validator: (val) {\
            if (val == null || val.isEmpty) {\
            return 'Please enter something';\
            }\
            return null;\
          },\
        ),\
    ],
)
`

### Magic link Auth [\#](https://supabase.com/docs/guides/auth/auth-helpers/flutter-auth-ui\#magic-link-auth)

Use `SupaMagicAuth` widget to create a magic link signIn form.

`
SupaMagicAuth(
redirectUrl: kIsWeb ? null : 'io.mydomain.myapp://callback',
onSuccess: (Session response) {},
onError: (error) {},
)
`

### Reset password [\#](https://supabase.com/docs/guides/auth/auth-helpers/flutter-auth-ui\#reset-password)

Use `SupaResetPassword` to create a password reset form.

`
SupaResetPassword(
accessToken: supabase.auth.currentSession?.accessToken,
onSuccess: (UserResponse response) {},
onError: (error) {},
)
`

### Phone Auth [\#](https://supabase.com/docs/guides/auth/auth-helpers/flutter-auth-ui\#phone-auth)

Use `SupaPhoneAuth` to create a phone authentication form.

`
SupaPhoneAuth(
authAction: SupaAuthAction.signUp,
onSuccess: (AuthResponse response) {},
),
`

### Social Auth [\#](https://supabase.com/docs/guides/auth/auth-helpers/flutter-auth-ui\#social-auth)

The package supports login with [official social providers](https://supabase.com/docs/guides/auth#providers).

Use `SupaSocialsAuth` to create list of social login buttons.

`
SupaSocialsAuth(
socialProviders: [\
    OAuthProvider.apple,\
    OAuthProvider.google,\
],
colored: true,
redirectUrl: kIsWeb
    ? null
    : 'io.mydomain.myapp://callback',
onSuccess: (Session response) {},
onError: (error) {},
)
`

### Theming [\#](https://supabase.com/docs/guides/auth/auth-helpers/flutter-auth-ui\#theming)

This package uses plain Flutter components allowing you to control the appearance of the components using your own theme.

### Is this helpful?

NoYes

### On this page

[Add Flutter Auth UI](https://supabase.com/docs/guides/auth/auth-helpers/flutter-auth-ui#add-flutter-auth-ui) [Initialize the Flutter Auth package](https://supabase.com/docs/guides/auth/auth-helpers/flutter-auth-ui#initialize-the-flutter-auth-package) [Email Auth](https://supabase.com/docs/guides/auth/auth-helpers/flutter-auth-ui#email-auth) [Magic link Auth](https://supabase.com/docs/guides/auth/auth-helpers/flutter-auth-ui#magic-link-auth) [Reset password](https://supabase.com/docs/guides/auth/auth-helpers/flutter-auth-ui#reset-password) [Phone Auth](https://supabase.com/docs/guides/auth/auth-helpers/flutter-auth-ui#phone-auth) [Social Auth](https://supabase.com/docs/guides/auth/auth-helpers/flutter-auth-ui#social-auth) [Theming](https://supabase.com/docs/guides/auth/auth-helpers/flutter-auth-ui#theming)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_auth_helpers_nextjs_pages.md">
Auth

# Supabase Auth with Next.js Pages Directory

* * *

The `auth-helpers` package has been replaced with the `@supabase/ssr` package. We recommend setting up Auth for your Next.js app with `@supabase/ssr` instead. See the [Next.js Server-Side Auth guide](https://supabase.com/docs/guides/auth/server-side/nextjs?router=pages) to learn how.

See legacy docs

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_auth_helpers_nextjs.md">
Auth

# Supabase Auth with the Next.js App Router

* * *

The `auth-helpers` are now deprecated. Use `@supabase/ssr` to set up Auth for your Next.js app. See the [Next.js Server-Side Auth guide](https://supabase.com/docs/guides/auth/server-side/nextjs) to learn how.

See legacy docs

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_auth_helpers_remix.md">
Auth

# Supabase Auth with Remix

* * *

We generally recommend using the new `@supabase/ssr` package instead of `auth-helpers`. `@supabase/ssr` takes the core concepts of the Auth Helpers package and makes them available to any server framework. Check out the [migration doc](https://supabase.com/docs/guides/auth/server-side/migrating-to-ssr-from-auth-helpers) to learn more.

See legacy docs

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_auth_helpers_sveltekit.md">
Auth

# Supabase Auth with SvelteKit

* * *

We generally recommend using the new `@supabase/ssr` package instead of `auth-helpers`. `@supabase/ssr` takes the core concepts of the Auth Helpers package and makes them available to any server framework. Check out the [migration doc](https://supabase.com/docs/guides/auth/server-side/migrating-to-ssr-from-auth-helpers) to learn more.

See legacy docs

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_auth_helpers.md">
Auth

# Auth Helpers

* * *

The Auth helpers package is deprecated. Use the new `@supabase/ssr` package for Server Side Authentication. `@supabase/ssr` takes the core concepts of the Auth Helpers package and makes them available to any server framework. Check out the [migration doc](https://supabase.com/docs/guides/auth/server-side/migrating-to-ssr-from-auth-helpers) to learn more.

Working with server-side frameworks is slightly different to client-side frameworks. In this section we cover the various ways of handling server-side authentication and demonstrate how to use the Supabase helper-libraries to make the process more seamless.

[**Next.js** \\
\\
Helpers for authenticating users in Next.js applications.](https://supabase.com/docs/guides/auth/auth-helpers/nextjs)

[**SvelteKit** \\
\\
Helpers for authenticating users in SvelteKit applications.](https://supabase.com/docs/guides/auth/auth-helpers/sveltekit)

[**Remix** \\
\\
Helpers for authenticating users in Remix applications.](https://supabase.com/docs/guides/auth/auth-helpers/remix)

## Status [\#](https://supabase.com/docs/guides/auth/auth-helpers\#status)

The Auth Helpers are `deprecated`. Use the new `@supabase/ssr` package for Server Side Authentication. Use the [migration doc](https://supabase.com/docs/guides/auth/server-side/migrating-to-ssr-from-auth-helpers) to learn more.

## Additional links [\#](https://supabase.com/docs/guides/auth/auth-helpers\#additional-links)

- [Source code](https://github.com/supabase/auth-helpers)
- [Known bugs and issues](https://github.com/supabase/auth-helpers/issues)

### Is this helpful?

NoYes

### On this page

[Status](https://supabase.com/docs/guides/auth/auth-helpers#status) [Additional links](https://supabase.com/docs/guides/auth/auth-helpers#additional-links)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_auth_hooks_custom_access_token_hook.md">
Auth

# Custom Access Token Hook

## Customize the access token issued by Supabase Auth

* * *

The custom access token hook runs before a token is issued and allows you to add additional claims based on the authentication method used.

Claims returned must conform to our specification. Supabase Auth will check for these claims after the hook is run and return an error if they are not present.

These are the fields currently available on an access token:

Required Claims: `iss`, `aud`, `exp`, `iat`, `sub`, `role`, `aal`, `session_id`
Optional Claims: `jti`, `nbf`, `app_metadata`, `user_metadata`, `amr`, `email`, `phone`

**Inputs**

| Field | Type | Description |
| --- | --- | --- |
| `user_id` | `string` | Unique identifier for the user attempting to sign in. |
| `claims` | `object` | Claims which are included in the access token. |
| `authentication_method` | `string` | The authentication method used to request the access token. Possible values include: `oauth`, `password`, `otp`, `totp`, `recovery`, `invite`, `sso/saml`, `magiclink`, `email/signup`, `email_change`, `token_refresh`, `anonymous`. |

JSONJSON Schema

`
{
"user_id": "8ccaa7af-909f-44e7-84cb-67cdccb56be6",
"claims": {
    "aud": "authenticated",
    "exp": 1715690221,
    "iat": 1715686621,
    "sub": "8ccaa7af-909f-44e7-84cb-67cdccb56be6",
    "email": "",
    "phone": "",
    "app_metadata": {},
    "user_metadata": {},
    "role": "authenticated",
    "aal": "aal1",
    "amr": [ { "method": "anonymous", "timestamp": 1715686621 } ],
    "session_id": "4b938a09-5372-4177-a314-cfa292099ea2",
    "is_anonymous": true
},
"authentication_method": "anonymous"
}
`

**Outputs**

Return these only if your hook processed the input without errors.

| Field | Type | Description |
| --- | --- | --- |
| `claims` | `object` | The updated claims after the hook has been run. |

SQLHTTP

Minimal JWTAdd admin roleAdd claim via plv8Restrict access to SSO users

Sometimes the size of the JWT can be a problem especially if you're using a [Server-Side Rendering framework](https://supabase.com/docs/guides/auth/server-side). Common situations where the JWT can get too large include:

- The user has a particularly large name, email address or phone number
- The default JWT has too many claims coming from OAuth providers
- A large avatar URL is included

To lower the size of the JWT you can define a Custom Access Token hook like the one below which will instruct the Auth server to issue a JWT with only the listed claims. Check the documentation above on what JWT claims must be present and cannot be removed.

Refer to the [Postgres JSON functions](https://www.postgresql.org/docs/current/functions-json.html) on how to manipulate `jsonb` objects.

`
create or replace function public.custom_access_token_hook(event jsonb)
returns jsonb
language plpgsql
as $$
declare
    original_claims jsonb;
    new_claims jsonb;
    claim text;
begin
    original_claims = event->'claims';
    new_claims = '{}'::jsonb;
    foreach claim in array array[\
      -- add claims you want to keep here\
      'iss',\
      'aud',\
      'exp',\
      'iat',\
      'sub',\
      'role',\
      'aal',\
      'session_id'\
] loop
      if original_claims ? claim then
        -- original_claims contains one of the listed claims, set it on new_claims
        new_claims = jsonb_set(new_claims, array[claim], original_claims->claim);
      end if;
    end loop;
    return jsonb_build_object('claims', new_claims);
end
$$;
`

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_auth_hooks_mfa_verification_hook.md">
Auth

# MFA Verification Hook

* * *

You can add additional checks to the [Supabase MFA implementation](https://supabase.com/docs/guides/auth/auth-mfa) with hooks. For example, you can:

- Limit the number of verification attempts performed over a period of time.
- Sign out users who have too many invalid verification attempts.
- Count, rate limit, or ban sign-ins.

**Inputs**

Supabase Auth will send a payload containing these fields to your hook:

| Field | Type | Description |
| --- | --- | --- |
| `factor_id` | `string` | Unique identifier for the MFA factor being verified |
| `factor_type` | `string` | `totp` or `phone` |
| `user_id` | `string` | Unique identifier for the user |
| `valid` | `boolean` | Whether the verification attempt was valid. For TOTP, this means that the six digit code was correct (true) or incorrect (false). |

JSONJSON Schema

`
{
"factor_id": "6eab6a69-7766-48bf-95d8-bd8f606894db",
"user_id": "3919cb6e-4215-4478-a960-6d3454326cec",
"valid": true
}
`

**Outputs**

Return this if your hook processed the input without errors.

| Field | Type | Description |
| --- | --- | --- |
| `decision` | `string` | The decision on whether to allow authentication to move forward. Use `reject` to deny the verification attempt and log the user out of all active sessions. Use `continue` to use the default Supabase Auth behavior. |
| `message` | `string` | The message to show the user if the decision was `reject`. |

`
{
"decision": "reject",
"message": "You have exceeded maximum number of MFA attempts."
}
`

SQL

Limit failed MFA verification attempts

Your company requires that a user can input an incorrect MFA Verification code no more than once every 2 seconds.

Create a table to record the last time a user had an incorrect MFA verification attempt for a factor.

`
create table public.mfa_failed_verification_attempts (
user_id uuid not null,
factor_id uuid not null,
last_failed_at timestamp not null default now(),
primary key (user_id, factor_id)
);
`

Create a hook to read and write information to this table. For example:

`
create function public.hook_mfa_verification_attempt(event jsonb)
returns jsonb
language plpgsql
as $$
declare
    last_failed_at timestamp;
begin
    if event->'valid' is true then
      -- code is valid, accept it
      return jsonb_build_object('decision', 'continue');
    end if;
    select last_failed_at into last_failed_at
      from public.mfa_failed_verification_attempts
      where
        user_id = event->'user_id'
          and
        factor_id = event->'factor_id';
    if last_failed_at is not null and now() - last_failed_at < interval '2 seconds' then
      -- last attempt was done too quickly
      return jsonb_build_object(
        'error', jsonb_build_object(
          'http_code', 429,
          'message',   'Please wait a moment before trying again.'
        )
      );
    end if;
    -- record this failed attempt
    insert into public.mfa_failed_verification_attempts
      (
        user_id,
        factor_id,
        last_refreshed_at
      )
      values
      (
        event->'user_id',
        event->'factor_id',
        now()
      )
      on conflict do update
        set last_refreshed_at = now();
    -- finally let Supabase Auth do the default behavior for a failed attempt
    return jsonb_build_object('decision', 'continue');
end;
$$;
-- Assign appropriate permissions and revoke access
grant all
on table public.mfa_failed_verification_attempts
to supabase_auth_admin;
revoke all
on table public.mfa_failed_verification_attempts
from authenticated, anon, public;
`

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_auth_hooks_password_verification_hook.md">
Auth

# Password Verification Hook

* * *

Your company wishes to increase security beyond the requirements of the default password implementation in order to fulfill security or compliance requirements. You plan to track the status of a password sign-in attempt and take action via an email or a restriction on logins where necessary.

As this hook runs on unauthenticated requests, malicious users can abuse the hook by calling it multiple times. Pay extra care when using the hook as you can unintentionally block legitimate users from accessing your application.

Check if a password is valid prior to taking any additional action to ensure the user is legitimate. Where possible, send an email or notification instead of blocking the user.

**Inputs**

| Field | Type | Description |
| --- | --- | --- |
| `user_id` | `string` | Unique identifier for the user attempting to sign in. Correlate this to the `auth.users` table. |
| `valid` | `boolean` | Whether the password verification attempt was valid. |

JSONJSON Schema

`
{
"user_id": "3919cb6e-4215-4478-a960-6d3454326cec",
"valid": true
}
`

**Outputs**

Return these only if your hook processed the input without errors.

| Field | Type | Description |
| --- | --- | --- |
| `decision` | `string` | The decision on whether to allow authentication to move forward. Use `reject` to deny the verification attempt and log the user out of all active sessions. Use `continue` to use the default Supabase Auth behavior. |
| `message` | `string` | The message to show the user if the decision was `reject`. |
| `should_logout_user` | `boolean` | Whether to log out the user if a `reject` decision is issued. Has no effect when a `continue` decision is issued. |

`
{
"decision": "reject",
"message": "You have exceeded maximum number of password sign-in attempts.",
"should_logout_user": "false"
}
`

SQL

Limit failed password verification attemptsSend email notification on failed password attempts

As part of new security measures within the company, users can only input an incorrect password every 10 seconds and not more than that. You want to write a hook to enforce this.

Create a table to record each user's last incorrect password verification attempt.

`
create table public.password_failed_verification_attempts (
user_id uuid not null,
last_failed_at timestamp not null default now(),
primary key (user_id)
);
`

Create a hook to read and write information to this table. For example:

`
create function public.hook_password_verification_attempt(event jsonb)
returns jsonb
language plpgsql
as $$
declare
    last_failed_at timestamp;
begin
    if event->'valid' is true then
      -- password is valid, accept it
      return jsonb_build_object('decision', 'continue');
    end if;
    select last_failed_at into last_failed_at
      from public.password_failed_verification_attempts
      where
        user_id = event->'user_id';
    if last_failed_at is not null and now() - last_failed_at < interval '10 seconds' then
      -- last attempt was done too quickly
      return jsonb_build_object(
        'error', jsonb_build_object(
          'http_code', 429,
          'message',   'Please wait a moment before trying again.'
        )
      );
    end if;
    -- record this failed attempt
    insert into public.password_failed_verification_attempts
      (
        user_id,
        last_failed_at
      )
      values
      (
        event->'user_id',
        now()
      )
      on conflict do update
        set last_failed_at = now();
    -- finally let Supabase Auth do the default behavior for a failed attempt
    return jsonb_build_object('decision', 'continue');
end;
$$;
-- Assign appropriate permissions
grant all
on table public.password_failed_verification_attempts
to supabase_auth_admin;
revoke all
on table public.password_failed_verification_attempts
from authenticated, anon, public;
`

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_auth_hooks_send_email_hook_490.md">
Auth

# Send Email Hook

## Use a custom email provider to send authentication messages

* * *

The Send Email Hook runs before an email is sent and allows for flexibility around email sending. You can use this hook to configure a back-up email provider or add internationalization to your emails.

## Email sending behavior [\#](https://supabase.com/docs/guides/auth/auth-hooks/send-email-hook\#email-sending-behavior)

Email sending depends on two settings: Email Provider and Auth Hook status.

| Email Provider | Auth Hook | Result |
| --- | --- | --- |
| Enabled | Enabled | Auth Hook handles email sending (SMTP not used) |
| Enabled | Disabled | SMTP handles email sending (custom if configured, default otherwise) |
| Disabled | Enabled | Email Signups Disabled |
| Disabled | Disabled | Email Signups Disabled |

**Inputs**

| Field | Type | Description |
| --- | --- | --- |
| `user` | [`User`](https://supabase.com/docs/guides/auth/users#the-user-object) | The user attempting to sign in. |
| `email` | `object` | Metadata specific to the email sending process. Includes the OTP and `token_hash`. |

JSONJSON Schema

`
{
"user": {
    "id": "8484b834-f29e-4af2-bf42-80644d154f76",
    "aud": "authenticated",
    "role": "authenticated",
    "email": "valid.email@supabase.io",
    "phone": "",
    "app_metadata": {
      "provider": "email",
      "providers": ["email"]
    },
    "user_metadata": {
      "email": "valid.email@supabase.io",
      "email_verified": false,
      "phone_verified": false,
      "sub": "8484b834-f29e-4af2-bf42-80644d154f76"
    },
    "identities": [\
      {\
        "identity_id": "bc26d70b-517d-4826-bce4-413a5ff257e7",\
        "id": "8484b834-f29e-4af2-bf42-80644d154f76",\
        "user_id": "8484b834-f29e-4af2-bf42-80644d154f76",\
        "identity_data": {\
          "email": "valid.email@supabase.io",\
          "email_verified": false,\
          "phone_verified": false,\
          "sub": "8484b834-f29e-4af2-bf42-80644d154f76"\
        },\
        "provider": "email",\
        "last_sign_in_at": "2024-05-14T12:56:33.824231484Z",\
        "created_at": "2024-05-14T12:56:33.824261Z",\
        "updated_at": "2024-05-14T12:56:33.824261Z",\
        "email": "valid.email@supabase.io"\
      }\
    ],
    "created_at": "2024-05-14T12:56:33.821567Z",
    "updated_at": "2024-05-14T12:56:33.825595Z",
    "is_anonymous": false
},
"email_data": {
    "token": "305805",
    "token_hash": "7d5b7b1964cf5d388340a7f04f1dbb5eeb6c7b52ef8270e1737a58d0",
    "redirect_to": "http://localhost:3000/",
    "email_action_type": "signup",
    "site_url": "http://localhost:9999",
    "token_new": "",
    "token_hash_new": ""
}
}
`

**Outputs**

- No outputs are required. An empty response with a status code of 200 is taken as a successful response.

SQLHTTP

Use Resend as an email providerAdd Internationalization for Email Templates

You can configure [Resend](https://resend.com/) as the custom email provider through the "Send Email" hook. This allows you to take advantage of Resend's developer-friendly APIs to send emails and leverage [React Email](https://react.email/) for managing your email templates. For a more advanced React Email tutorial, refer to [this guide](https://supabase.com/docs/guides/functions/examples/auth-send-email-hook-react-email-resend).

If you want to send emails through the Supabase Resend integration, which uses Resend's SMTP server, check out [this integration](https://supabase.com/partners/integrations/resend) instead.

Create a `.env` file with the following environment variables:

`
RESEND_API_KEY="your_resend_api_key"
SEND_EMAIL_HOOK_SECRET="v1,whsec_<base64_secret>"
`

You can generate the secret in the [Auth Hooks](https://supabase.com/dashboard/project/_/auth/hooks) section of the Supabase dashboard.

Set the secrets in your Supabase project:

`
supabase secrets set --env-file .env
`

Create a new edge function:

`
supabase functions new send-email
`

Add the following code to your edge function:

``
import { Webhook } from "https://esm.sh/standardwebhooks@1.0.0";
import { Resend } from "npm:resend";
const resend = new Resend(Deno.env.get("RESEND_API_KEY") as string);
const hookSecret = (Deno.env.get("SEND_EMAIL_HOOK_SECRET") as string).replace("v1,whsec_", "");
Deno.serve(async (req) => {
if (req.method !== "POST") {
    return new Response("not allowed", { status: 400 });
}
const payload = await req.text();
const headers = Object.fromEntries(req.headers);
const wh = new Webhook(hookSecret);
try {
    const { user, email_data } = wh.verify(payload, headers) as {
      user: {
        email: string;
      };
      email_data: {
        token: string;
        token_hash: string;
        redirect_to: string;
        email_action_type: string;
        site_url: string;
        token_new: string;
        token_hash_new: string;
      };
    };
    const { error } = await resend.emails.send({
      from: "welcome <onboarding@example.com>",
      to: [user.email],
      subject: "Welcome to my site!",
      text: `Confirm you signup with this code: ${email_data.token}`,
    });
    if (error) {
      throw error;
    }
} catch (error) {
    return new Response(
      JSON.stringify({
        error: {
          http_code: error.code,
          message: error.message,
        },
      }),
      {
        status: 401,
        headers: { "Content-Type": "application/json" },
      },
    );
}
const responseHeaders = new Headers();
responseHeaders.set("Content-Type", "application/json");
return new Response(JSON.stringify({}), {
    status: 200,
    headers: responseHeaders,
});
});
``

Deploy your edge function and [configure it as a hook](https://supabase.com/dashboard/project/_/auth/hooks):

`
supabase functions deploy send-email --no-verify-jwt
`

### Is this helpful?

NoYes

### On this page

[Email sending behavior](https://supabase.com/docs/guides/auth/auth-hooks/send-email-hook#email-sending-behavior)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_auth_hooks_send_email_hook.md">
Auth

# Send Email Hook

## Use a custom email provider to send authentication messages

* * *

The Send Email Hook runs before an email is sent and allows for flexibility around email sending. You can use this hook to configure a back-up email provider or add internationalization to your emails.

## Email sending behavior [\#](https://supabase.com/docs/guides/auth/auth-hooks/send-email-hook\#email-sending-behavior)

Email sending depends on two settings: Email Provider and Auth Hook status.

| Email Provider | Auth Hook | Result |
| --- | --- | --- |
| Enabled | Enabled | Auth Hook handles email sending (SMTP not used) |
| Enabled | Disabled | SMTP handles email sending (custom if configured, default otherwise) |
| Disabled | Enabled | Email Signups Disabled |
| Disabled | Disabled | Email Signups Disabled |

**Inputs**

| Field | Type | Description |
| --- | --- | --- |
| `user` | [`User`](https://supabase.com/docs/guides/auth/users#the-user-object) | The user attempting to sign in. |
| `email` | `object` | Metadata specific to the email sending process. Includes the OTP and `token_hash`. |

JSONJSON Schema

`
{
"user": {
    "id": "8484b834-f29e-4af2-bf42-80644d154f76",
    "aud": "authenticated",
    "role": "authenticated",
    "email": "valid.email@supabase.io",
    "phone": "",
    "app_metadata": {
      "provider": "email",
      "providers": ["email"]
    },
    "user_metadata": {
      "email": "valid.email@supabase.io",
      "email_verified": false,
      "phone_verified": false,
      "sub": "8484b834-f29e-4af2-bf42-80644d154f76"
    },
    "identities": [\
      {\
        "identity_id": "bc26d70b-517d-4826-bce4-413a5ff257e7",\
        "id": "8484b834-f29e-4af2-bf42-80644d154f76",\
        "user_id": "8484b834-f29e-4af2-bf42-80644d154f76",\
        "identity_data": {\
          "email": "valid.email@supabase.io",\
          "email_verified": false,\
          "phone_verified": false,\
          "sub": "8484b834-f29e-4af2-bf42-80644d154f76"\
        },\
        "provider": "email",\
        "last_sign_in_at": "2024-05-14T12:56:33.824231484Z",\
        "created_at": "2024-05-14T12:56:33.824261Z",\
        "updated_at": "2024-05-14T12:56:33.824261Z",\
        "email": "valid.email@supabase.io"\
      }\
    ],
    "created_at": "2024-05-14T12:56:33.821567Z",
    "updated_at": "2024-05-14T12:56:33.825595Z",
    "is_anonymous": false
},
"email_data": {
    "token": "305805",
    "token_hash": "7d5b7b1964cf5d388340a7f04f1dbb5eeb6c7b52ef8270e1737a58d0",
    "redirect_to": "http://localhost:3000/",
    "email_action_type": "signup",
    "site_url": "http://localhost:9999",
    "token_new": "",
    "token_hash_new": ""
}
}
`

**Outputs**

- No outputs are required. An empty response with a status code of 200 is taken as a successful response.

SQLHTTP

Use Resend as an email providerAdd Internationalization for Email Templates

You can configure [Resend](https://resend.com/) as the custom email provider through the "Send Email" hook. This allows you to take advantage of Resend's developer-friendly APIs to send emails and leverage [React Email](https://react.email/) for managing your email templates. For a more advanced React Email tutorial, refer to [this guide](https://supabase.com/docs/guides/functions/examples/auth-send-email-hook-react-email-resend).

If you want to send emails through the Supabase Resend integration, which uses Resend's SMTP server, check out [this integration](https://supabase.com/partners/integrations/resend) instead.

Create a `.env` file with the following environment variables:

`
RESEND_API_KEY="your_resend_api_key"
SEND_EMAIL_HOOK_SECRET="v1,whsec_<base64_secret>"
`

You can generate the secret in the [Auth Hooks](https://supabase.com/dashboard/project/_/auth/hooks) section of the Supabase dashboard.

Set the secrets in your Supabase project:

`
supabase secrets set --env-file .env
`

Create a new edge function:

`
supabase functions new send-email
`

Add the following code to your edge function:

``
import { Webhook } from "https://esm.sh/standardwebhooks@1.0.0";
import { Resend } from "npm:resend";
const resend = new Resend(Deno.env.get("RESEND_API_KEY") as string);
const hookSecret = (Deno.env.get("SEND_EMAIL_HOOK_SECRET") as string).replace("v1,whsec_", "");
Deno.serve(async (req) => {
if (req.method !== "POST") {
    return new Response("not allowed", { status: 400 });
}
const payload = await req.text();
const headers = Object.fromEntries(req.headers);
const wh = new Webhook(hookSecret);
try {
    const { user, email_data } = wh.verify(payload, headers) as {
      user: {
        email: string;
      };
      email_data: {
        token: string;
        token_hash: string;
        redirect_to: string;
        email_action_type: string;
        site_url: string;
        token_new: string;
        token_hash_new: string;
      };
    };
    const { error } = await resend.emails.send({
      from: "welcome <onboarding@example.com>",
      to: [user.email],
      subject: "Welcome to my site!",
      text: `Confirm you signup with this code: ${email_data.token}`,
    });
    if (error) {
      throw error;
    }
} catch (error) {
    return new Response(
      JSON.stringify({
        error: {
          http_code: error.code,
          message: error.message,
        },
      }),
      {
        status: 401,
        headers: { "Content-Type": "application/json" },
      },
    );
}
const responseHeaders = new Headers();
responseHeaders.set("Content-Type", "application/json");
return new Response(JSON.stringify({}), {
    status: 200,
    headers: responseHeaders,
});
});
``

Deploy your edge function and [configure it as a hook](https://supabase.com/dashboard/project/_/auth/hooks):

`
supabase functions deploy send-email --no-verify-jwt
`

### Is this helpful?

NoYes

### On this page

[Email sending behavior](https://supabase.com/docs/guides/auth/auth-hooks/send-email-hook#email-sending-behavior)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_auth_hooks_send_sms_hook.md">
Auth

# Send SMS Hook

## Use a custom SMS provider to send authentication messages

* * *

Runs before a message is sent. Use the hook to:

- Use a regional SMS Provider
- Use alternate messaging channels such as WhatsApp
- Adjust the message body to include platform specific fields such as the [`AppHash`](https://developers.google.com/identity/sms-retriever/overview)

**Inputs**

| Field | Type | Description |
| --- | --- | --- |
| `user` | [`User`](https://supabase.com/docs/guides/auth/users#the-user-object) | The user attempting to sign in. |
| `sms` | `object` | Metadata specific to the SMS sending process. Includes the OTP. |

JSONJSON Schema

`
{
"user": {
    "id": "6481a5c1-3d37-4a56-9f6a-bee08c554965",
    "aud": "authenticated",
    "role": "authenticated",
    "email": "",
    "phone": "+1333363128",
    "phone_confirmed_at": "2024-05-13T11:52:48.157306Z",
    "confirmation_sent_at": "2024-05-14T12:31:52.824573Z",
    "confirmed_at": "2024-05-13T11:52:48.157306Z",
    "phone_change_sent_at": "2024-05-13T11:47:02.183064Z",
    "last_sign_in_at": "2024-05-13T11:52:48.162518Z",
    "app_metadata": {
      "provider": "phone",
      "providers": ["phone"]
    },
    "user_metadata": {},
    "identities": [\
      {\
        "identity_id": "3be5e552-65aa-41d9-9db9-2a502f845459",\
        "id": "6481a5c1-3d37-4a56-9f6a-bee08c554965",\
        "user_id": "6481a5c1-3d37-4a56-9f6a-bee08c554965",\
        "identity_data": {\
          "email_verified": false,\
          "phone": "+1612341244428",\
          "phone_verified": true,\
          "sub": "6481a5c1-3d37-4a56-9f6a-bee08c554965"\
        },\
        "provider": "phone",\
        "last_sign_in_at": "2024-05-13T11:52:48.155562Z",\
        "created_at": "2024-05-13T11:52:48.155599Z",\
        "updated_at": "2024-05-13T11:52:48.159391Z"\
      }\
    ],
    "created_at": "2024-05-13T11:45:33.7738Z",
    "updated_at": "2024-05-14T12:31:52.82475Z",
    "is_anonymous": false
},
"sms": {
    "otp": "561166"
}
}
`

**Outputs**

- No outputs are required. An empty response with a status code of 200 is taken as a successful response.

SQLHTTP

Queue SMS Messages

Your company uses a worker to manage all messaging related jobs. For performance reasons, the messaging system sends messages in intervals via a job queue. Instead of sending a message immediately, messages are queued and sent in periodic intervals via `pg_cron`.

Create a table to store jobs

`
create table job_queue (
job_id uuid primary key default gen_random_uuid(),
job_data jsonb not null,
created_at timestamp default now(),
status text default 'pending',
priority int default 0,
retry_count int default 0,
max_retries int default 2,
scheduled_at timestamp default now()
);
`

Create the hook:

`
create or replace function send_sms(event jsonb) returns void as $$
declare
    job_data jsonb;
    scheduled_time timestamp;
    priority int;
begin
    -- extract phone and otp from the event json
    job_data := jsonb_build_object(
        'phone', event->'user'->>'phone',
        'otp', event->'sms'->>'otp'
    );
    -- calculate the nearest 5-minute window for scheduled_time
    scheduled_time := date_trunc('minute', now()) + interval '5 minute' * floor(extract('epoch' from (now() - date_trunc('minute', now())) / 60) / 5);
    -- assign priority dynamically (example logic: higher priority for earlier scheduled time)
    priority := extract('epoch' from (scheduled_time - now()))::int;
    -- insert the job into the job_queue table
    insert into job_queue (job_data, priority, scheduled_at, max_retries)
    values (job_data, priority, scheduled_time, 2);
end;
$$ language plpgsql;
grant all
on table public.job_queue
to supabase_auth_admin;
revoke all
on table public.job_queue
from authenticated, anon;
`

Create a function to periodically run and dequeue all jobs

`
create or replace function dequeue_and_run_jobs() returns void as $$
declare
    job record;
begin
    for job in
        select * from job_queue
        where status = 'pending'
          and scheduled_at <= now()
        order by priority desc, created_at
        for update skip locked
    loop
        begin
            -- add job processing logic here.
            -- for demonstration, we'll just update the job status to 'completed'.
            update job_queue
            set status = 'completed'
            where job_id = job.job_id;
        exception when others then
            -- handle job failure and retry logic
            if job.retry_count < job.max_retries then
                update job_queue
                set retry_count = retry_count + 1,
                    scheduled_at = now() + interval '1 minute'  -- delay retry by 1 minute
                where job_id = job.job_id;
            else
                update job_queue
                set status = 'failed'
                where job_id = job.job_id;
            end if;
        end;
    end loop;
end;
$$ language plpgsql;
grant execute
on function public.dequeue_and_run_jobs
to supabase_auth_admin;
revoke execute
on function public.dequeue_and_run_jobs
from authenticated, anon;
`

Configure `pg_cron` to run the job on an interval. You can use a tool like [crontab.guru](https://crontab.guru/) to check that your job is running on an appropriate schedule. Ensure that `pg_cron` is enabled under `Database > Extensions`

`
select
cron.schedule(
    '* * * * *', -- this cron expression means every minute.
    'select dequeue_and_run_jobs();'
);
`

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_auth_hooks.md">
Auth

# Auth Hooks

## Use HTTP or Postgres Functions to customize your authentication flow

* * *

## What is a hook [\#](https://supabase.com/docs/guides/auth/auth-hooks\#what-is-a-hook)

A hook is an endpoint that allows you to alter the default Supabase Auth flow at specific execution points. Developers can use hooks to add custom behavior that's not supported natively.

Hooks help you:

- Track the origin of user signups by adding metadata
- Improve security by adding additional checks to password and multi-factor authentication
- Support legacy systems by integrating with identity credentials from external authentication systems
- Add additional custom claims to your JWT
- Send authentication emails or SMS messages through a custom provider

The following hooks are available:

| Hook | Available on Plan |
| --- | --- |
| [Custom Access Token](https://supabase.com/docs/guides/auth/auth-hooks/custom-access-token-hook) | Free, Pro |
| [Send SMS](https://supabase.com/docs/guides/auth/auth-hooks/send-sms-hook) | Free, Pro |
| [Send Email](https://supabase.com/docs/guides/auth/auth-hooks/send-email-hook) | Free, Pro |
| [MFA Verification Attempt](https://supabase.com/docs/guides/auth/auth-hooks/mfa-verification-hook) | Teams and Enterprise |
| [Password Verification Attempt](https://supabase.com/docs/guides/auth/auth-hooks/password-verification-hook) | Teams and Enterprise |

Supabase supports 2 ways to [configure a hook](https://supabase.com/dashboard/project/_/auth/hooks) in your project:

Postgres FunctionHTTP Endpoint

A [Postgres function](https://supabase.com/docs/guides/database/functions) can be configured as a hook. The function should take in a single argument -- the event of type JSONB -- and return a JSONB object. Since the Postgres function runs on your database, the request does not leave your project's instance.

## Security model [\#](https://supabase.com/docs/guides/auth/auth-hooks\#security-model)

Sign the payload and grant permissions selectively in order to guard the integrity of the payload.

SQLHTTP

When you configure a Postgres function as a hook, Supabase will automatically apply the following grants to the function for these reasons:

- Allow the `supabase_auth_admin` role to execute the function. The `supabase_auth_admin` role is the Postgres role that is used by Supabase Auth to make requests to your database.
- Revoke permissions from other roles (e.g. `anon`, `authenticated`, `public`) to ensure the function is not accessible by Supabase Data APIs.

`
-- Grant access to function to supabase_auth_admin
grant execute
on function public.custom_access_token_hook
to supabase_auth_admin;
-- Grant access to schema to supabase_auth_admin
grant usage on schema public to supabase_auth_admin;
-- Revoke function permissions from authenticated, anon and public
revoke execute
on function public.custom_access_token_hook
from authenticated, anon, public;
`

You will need to alter your row-level security (RLS) policies to allow the `supabase_auth_admin` role to access tables that you have RLS policies on. You can read more about RLS policies [here](https://supabase.com/docs/guides/database/postgres/row-level-security).

Alternatively, you can create your Postgres function via the dashboard with the `security definer` tag. The `security definer` tag specifies that the function is to be executed with the privileges of the user that owns it.

Currently, functions created via the dashboard take on the `postgres` role. Read more about the `security definer` tag [in our database guide](https://supabase.com/docs/guides/database/functions#security-definer-vs-invoker)

## Using Hooks [\#](https://supabase.com/docs/guides/auth/auth-hooks\#using-hooks)

### Developing [\#](https://supabase.com/docs/guides/auth/auth-hooks\#developing)

Let us develop a Hook locally and then deploy it to the cloud. As a recap, heres a list of available Hooks

| Hook | Suggested Function Name | When it is called | What it Does |
| --- | --- | --- | --- |
| Send SMS | `send_sms` | Each time an SMS is sent | Allows you to customize message content and SMS Provider |
| Send Email | `send_email` | Each time an Email is sent | Allows you to customize message content and Email Provider |
| Custom Access Token | `custom_access_token` | Each time a new JWT is created | Returns the claims you wish to be present in the JWT. |
| MFA Verification Attempt | `mfa_verification_attempt` | Each time a user tries to verify an MFA factor. | Returns a decision on whether to reject the attempt and future ones, or to allow the user to keep trying. |
| Password Verification Attempt | `password_verification_attempt` | Each time a user tries to sign in with a password. | Return a decision whether to allow the user to reject the attempt, or to allow the user to keep trying. |

Edit `config.toml` to set up the Auth Hook locally.

SQLHTTP

Modify the `auth.hook.<hook_name>` field and set `uri` to a value of `pg-functions://postgres/<schema>/<function_name>`

`
[auth.hook.<hook_name>]
enabled = true
uri = "pg-functions://...."
`

You need to assign additional permissions so that Supabase Auth can access the hook as well as the tables it interacts with.

The `supabase_auth_admin` role does not have permissions to the `public` schema. You need to grant the role permission to execute your hook:

`
grant execute
on function public.custom_access_token_hook
to supabase_auth_admin;
`

You also need to grant usage to `supabase_auth_admin`:

`
grant usage on schema public to supabase_auth_admin;
`

Also revoke permissions from the `authenticated` and `anon` roles to ensure the function is not accessible by Supabase Serverless APIs.

`
revoke execute
on function public.custom_access_token_hook
from authenticated, anon;
`

For security, we recommend against the use the `security definer` tag. The `security definer` tag specifies that the function is to be executed with the privileges of the user that owns it. When a function is created via the Supabase dashboard with the tag, it will have the extensive permissions of the `postgres` role which make it easier for undesirable actions to occur.

We recommend that you do not use any tag and explicitly grant permissions to `supabase_auth_admin` as described above.

Read more about `security definer` tag [in our database guide](https://supabase.com/docs/guides/database/functions#security-definer-vs-invoker).

There are no restrictions as to what language can be used to write a Postgres Hook. If [PL/pgSQL](https://www.postgresql.org/docs/current/plpgsql.html) is too difficult consider using the [plv8](https://supabase.com/docs/guides/database/extensions/plv8) extension which lets you use JavaScript to define functions.

Once done, save your Auth Hook as a migration in order to version the Auth Hook and share it with other team members. Run [`supabase migration new`](https://supabase.com/docs/reference/cli/supabase-migration-new) to create a migration.

If you're using the Supabase SQL Editor, there's an issue when using the `?` ( _Does the string exist as a top-level key within the JSON value?_) operator. Use a direct connection to the database if you need to use it when defining a function.

Here is an example hook signature:

`
create or replace function public.custom_access_token_hook(event jsonb)
returns jsonb
language plpgsql
as $$
declare
  -- Insert variables here
begin
  -- Insert logic here
return event;
end;
$$;
`

You can visit `SQL Editor > Templates` for hook templates.

### Deploying [\#](https://supabase.com/docs/guides/auth/auth-hooks\#deploying)

In the dashboard, navigate to [`Authentication > Hooks`](https://supabase.com/dashboard/project/_/auth/hooks) and select the appropriate function type (SQL or HTTP) from the dropdown menu.

### Error handling [\#](https://supabase.com/docs/guides/auth/auth-hooks\#error-handling)

You should return an error when facing a runtime error. Runtime errors are specific to your application and arise from specific business rules rather than programmer errors.

Runtime errors could happen when:

- The user does not have appropriate permissions
- The event payload received does not have required claims.
- The user has performed an action which violates a business rule.
- The email or phone provider used in the webhook returned an error.

SQLHTTP

The error is a JSON object and has the following properties:

- `error` An object that contains information about the error.
  - `http_code` A number indicating the HTTP code to be returned. If not set, the code is HTTP 500 Internal Server Error.
  - `message` A message to be returned in the HTTP response. Required.

Here's an example:

`
{
"error": {
    "http_code": 429,
    "message": "You can only verify a factor once every 10 seconds."
}
}
`

Errors returned from a Postgres Hook are not retry-able. When an error is returned, the error is propagated from the hook to Supabase Auth and translated into a HTTP error which is returned to your application. Supabase Auth will only take into account the error and disregard the rest of the payload.

Outside of runtime errors, both HTTP Hooks and Postgres Hooks return timeout errors. Postgres Hooks have 2 seconds to complete processing while HTTP Hooks should complete in 5 seconds. Both HTTP Hooks and Postgres Hooks are run in a transaction do limit the duration of execution to avoid delays in authentication process.

## Available Hooks [\#](https://supabase.com/docs/guides/auth/auth-hooks\#available-hooks)

Each Hook description contains an example JSON Schema which you can use in conjunction with [JSON Schema Faker](https://json-schema-faker.js.org/) in order to generate a mock payload. For HTTP Hooks, you can also use [the Standard Webhooks Testing Tool](https://www.standardwebhooks.com/simulate) to simulate a request.

[Custom Access Token\\
\\
Customize the access token issued by Supabase Auth](https://supabase.com/docs/guides/auth/auth-hooks/custom-access-token-hook)

[Send SMS\\
\\
Use a custom SMS provider to send authentication messages](https://supabase.com/docs/guides/auth/auth-hooks/send-sms-hook)

[Send Email\\
\\
Use a custom email provider to send authentication messages](https://supabase.com/docs/guides/auth/auth-hooks/send-email-hook)

[MFA Verification\\
\\
Add additional checks to the MFA verification flow](https://supabase.com/docs/guides/auth/auth-hooks/mfa-verification-hook)

[Password verification\\
\\
Add additional checks to the password verification flow](https://supabase.com/docs/guides/auth/auth-hooks/password-verification-hook)

### Is this helpful?

NoYes

### On this page

[What is a hook](https://supabase.com/docs/guides/auth/auth-hooks#what-is-a-hook) [Security model](https://supabase.com/docs/guides/auth/auth-hooks#security-model) [Using Hooks](https://supabase.com/docs/guides/auth/auth-hooks#using-hooks) [Developing](https://supabase.com/docs/guides/auth/auth-hooks#developing) [Deploying](https://supabase.com/docs/guides/auth/auth-hooks#deploying) [Error handling](https://supabase.com/docs/guides/auth/auth-hooks#error-handling) [Available Hooks](https://supabase.com/docs/guides/auth/auth-hooks#available-hooks)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_auth_identity_linking.md">
Auth

# Identity Linking

## Manage the identities associated with your user

* * *

## Identity linking strategies [\#](https://supabase.com/docs/guides/auth/auth-identity-linking\#identity-linking-strategies)

Currently, Supabase Auth supports 2 strategies to link an identity to a user:

1. [Automatic Linking](https://supabase.com/docs/guides/auth/auth-identity-linking#automatic-linking)
2. [Manual Linking](https://supabase.com/docs/guides/auth/auth-identity-linking#manual-linking-beta)

### Automatic linking [\#](https://supabase.com/docs/guides/auth/auth-identity-linking\#automatic-linking)

Supabase Auth automatically links identities with the same email address to a single user. This helps to improve the user experience when multiple OAuth login options are presented since the user does not need to remember which OAuth account they used to sign up with. When a new user signs in with OAuth, Supabase Auth will attempt to look for an existing user that uses the same email address. If a match is found, the new identity is linked to the user.

In order for automatic linking to correctly identify the user for linking, Supabase Auth needs to ensure that all user emails are unique. It would also be an insecure practice to automatically link an identity to a user with an unverified email address since that could lead to pre-account takeover attacks. To prevent this from happening, when a new identity can be linked to an existing user, Supabase Auth will remove any other unconfirmed identities linked to an existing user.

Users that signed up with [SAML SSO](https://supabase.com/docs/guides/auth/sso/auth-sso-saml) will not be considered as targets for automatic linking.

### Manual linking (beta) [\#](https://supabase.com/docs/guides/auth/auth-identity-linking\#manual-linking-beta)

JavaScriptDartSwiftKotlinPython

Supabase Auth allows a user to initiate identity linking with a different email address when they are logged in. To link an OAuth identity to the user, call [`linkIdentity()`](https://supabase.com/docs/reference/javascript/auth-linkidentity):

`
const { data, error } = await supabase.auth.linkIdentity({ provider: 'google' })
`

In the example above, the user will be redirected to Google to complete the OAuth2.0 flow. Once the OAuth2.0 flow has completed successfully, the user will be redirected back to the application and the Google identity will be linked to the user. You can enable manual linking from your project's authentication [configuration options](https://supabase.com/dashboard/project/_/settings/auth) or by setting the environment variable `GOTRUE_SECURITY_MANUAL_LINKING_ENABLED: true` when self-hosting.

## Unlink an identity [\#](https://supabase.com/docs/guides/auth/auth-identity-linking\#unlink-an-identity)

JavaScriptDartSwiftKotlinPython

You can use [`getUserIdentities()`](https://supabase.com/docs/reference/javascript/auth-getuseridentities) to fetch all the identities linked to a user. Then, call [`unlinkIdentity()`](https://supabase.com/docs/reference/javascript/auth-unlinkidentity) to unlink the identity. The user needs to be logged in and have at least 2 linked identities in order to unlink an existing identity.

`
// retrieve all identities linked to a user
const {
data: { identities },
} = await supabase.auth.getUserIdentities()
// find the google identity linked to the user
const googleIdentity = identities.find((identity) => identity.provider === 'google')
// unlink the google identity from the user
const { data, error } = await supabase.auth.unlinkIdentity(googleIdentity)
`

## Frequently asked questions [\#](https://supabase.com/docs/guides/auth/auth-identity-linking\#frequently-asked-questions)

### How to add email/password login to an OAuth account? [\#](https://supabase.com/docs/guides/auth/auth-identity-linking\#how-to-add-emailpassword-login-to-an-oauth-account)

Call the `updateUser({ password: 'validpassword'})` to add email with password authentication to an account created with an OAuth provider (Google, GitHub, etc.).

### Can you sign up with email if already using OAuth? [\#](https://supabase.com/docs/guides/auth/auth-identity-linking\#can-you-sign-up-with-email-if-already-using-oauth)

If you try to create an email account after previously signing up with OAuth using the same email, you'll receive an obfuscated user response with no verification email sent. This prevents user enumeration attacks.

### Is this helpful?

NoYes

### On this page

[Identity linking strategies](https://supabase.com/docs/guides/auth/auth-identity-linking#identity-linking-strategies) [Automatic linking](https://supabase.com/docs/guides/auth/auth-identity-linking#automatic-linking) [Manual linking (beta)](https://supabase.com/docs/guides/auth/auth-identity-linking#manual-linking-beta) [Unlink an identity](https://supabase.com/docs/guides/auth/auth-identity-linking#unlink-an-identity) [Frequently asked questions](https://supabase.com/docs/guides/auth/auth-identity-linking#frequently-asked-questions) [How to add email/password login to an OAuth account?](https://supabase.com/docs/guides/auth/auth-identity-linking#how-to-add-emailpassword-login-to-an-oauth-account) [Can you sign up with email if already using OAuth?](https://supabase.com/docs/guides/auth/auth-identity-linking#can-you-sign-up-with-email-if-already-using-oauth)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_auth_mfa_phone.md">
Auth

# Multi-Factor Authentication (Phone)

* * *

## How does phone multi-factor-authentication work? [\#](https://supabase.com/docs/guides/auth/auth-mfa/phone\#how-does-phone-multi-factor-authentication-work)

Phone multi-factor authentication involves a shared code generated by Supabase Auth and the end user. The code is delivered via a messaging channel, such as SMS or WhatsApp, and the user uses the code to authenticate to Supabase Auth.

The phone messaging configuration for MFA is shared with [phone auth login](https://supabase.com/docs/guides/auth/phone-login). The same provider configuration that is used for phone login is used for MFA. You can also use the [Send SMS Hook](https://supabase.com/docs/guides/auth/auth-hooks/send-sms-hook) if you need to use an MFA (Phone) messaging provider different from what is supported natively.

Below is a flow chart illustrating how the Enrollment and Verify APIs work in the context of MFA (Phone).

![Diagram showing the flow of Multi-Factor authentication](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fauth-mfa%2Fauth-mfa-phone-flow.svg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Add enrollment flow [\#](https://supabase.com/docs/guides/auth/auth-mfa/phone\#add-enrollment-flow)

An enrollment flow provides a UI for users to set up additional authentication factors. Most applications add the enrollment flow in two places within their app:

1. Right after login or sign up.
This allows users quickly set up Multi Factor Authentication (MFA) post login or account creation. Where possible, encourage all users to set up MFA. Many applications offer this as an opt-in step in an
effort to reduce onboarding friction.
2. From within a settings page.
Allows users to set up, disable or modify their MFA settings.

As far as possible, maintain a generic flow that you can reuse in both cases with minor modifications.

Enrolling a factor for use with MFA takes three steps for phone MFA:

1. Call `supabase.auth.mfa.enroll()`.
2. Calling the `supabase.auth.mfa.challenge()` API. This sends a code via SMS or WhatsApp and prepares Supabase Auth to accept a verification code from the user.
3. Calling the `supabase.auth.mfa.verify()` API. `supabase.auth.mfa.challenge()` returns a challenge ID.
This verifies that the code issued by Supabase Auth matches the code input by the user. If the verification succeeds, the factor
immediately becomes active for the user account. If not, you should repeat
steps 2 and 3.

#### Example: React [\#](https://supabase.com/docs/guides/auth/auth-mfa/phone\#example-react)

Below is an example that creates a new `EnrollMFA` component that illustrates the important pieces of the MFA enrollment flow.

- When the component appears on screen, the `supabase.auth.mfa.enroll()` API is
called once to start the process of enrolling a new factor for the current
user.
- A challenge is created using the `supabase.auth.mfa.challenge()` API and the
code from the user is submitted for verification using the
`supabase.auth.mfa.verify()` challenge.
- `onEnabled` is a callback that notifies the other components that enrollment
has completed.
- `onCancelled` is a callback that notifies the other components that the user
has clicked the `Cancel` button.

`
export function EnrollMFA({
onEnrolled,
onCancelled,
}: {
onEnrolled: () => void
onCancelled: () => void
}) {
const [phoneNumber, setPhoneNumber] = useState('')
const [factorId, setFactorId] = useState('')
const [verifyCode, setVerifyCode] = useState('')
const [error, setError] = useState('')
const [challengeId, setChallengeId] = useState('')
const onEnableClicked = () => {
    setError('')
    ;(async () => {
      const verify = await auth.mfa.verify({
        factorId,
        challengeId,
        code: verifyCode,
      })
      if (verify.error) {
        setError(verify.error.message)
        throw verify.error
      }
      onEnrolled()
    })()
}
const onEnrollClicked = async () => {
    setError('')
    try {
      const factor = await auth.mfa.enroll({
        phone: phoneNumber,
        factorType: 'phone',
      })
      if (factor.error) {
        setError(factor.error.message)
        throw factor.error
      }
      setFactorId(factor.data.id)
    } catch (error) {
      setError('Failed to Enroll the Factor.')
    }
}
const onSendOTPClicked = async () => {
    setError('')
    try {
      const challenge = await auth.mfa.challenge({ factorId })
      if (challenge.error) {
        setError(challenge.error.message)
        throw challenge.error
      }
      setChallengeId(challenge.data.id)
    } catch (error) {
      setError('Failed to resend the code.')
    }
}
return (
    <>
      {error && <div className="error">{error}</div>}
      <input
        type="text"
        placeholder="Phone Number"
        value={phoneNumber}
        onChange={(e) => setPhoneNumber(e.target.value.trim())}
      />
      <input
        type="text"
        placeholder="Verification Code"
        value={verifyCode}
        onChange={(e) => setVerifyCode(e.target.value.trim())}
      />
      <input type="button" value="Enroll" onClick={onEnrollClicked} />
      <input type="button" value="Submit Code" onClick={onEnableClicked} />
      <input type="button" value="Send OTP Code" onClick={onSendOTPClicked} />
      <input type="button" value="Cancel" onClick={onCancelled} />
    </>
)
}
`

### Add a challenge step to login [\#](https://supabase.com/docs/guides/auth/auth-mfa/phone\#add-a-challenge-step-to-login)

Once a user has logged in via their first factor (email+password, magic link, one time password, social login etc.) you need to perform a check if any additional factors need to be verified.

This can be done by using the `supabase.auth.mfa.getAuthenticatorAssuranceLevel()` API. When the user signs in and is redirected back to your app, you should call this method to extract the user's current and next authenticator assurance level (AAL).

Therefore if you receive a `currentLevel` which is `aal1` but a `nextLevel` of `aal2`, the user should be given the option to go through MFA.

Below is a table that explains the combined meaning.

| Current Level | Next Level | Meaning |
| --: | :-- | :-- |
| `aal1` | `aal1` | User does not have MFA enrolled. |
| `aal1` | `aal2` | User has an MFA factor enrolled but has not verified it. |
| `aal2` | `aal2` | User has verified their MFA factor. |
| `aal2` | `aal1` | User has disabled their MFA factor. (Stale JWT.) |

#### Example: React [\#](https://supabase.com/docs/guides/auth/auth-mfa/phone\#example-react)

Adding the challenge step to login depends heavily on the architecture of your app. However, a fairly common way to structure React apps is to have a large component (often named `App`) which contains most of the authenticated application logic.

This example will wrap this component with logic that will show an MFA challenge screen if necessary, before showing the full application. This is illustrated in the `AppWithMFA` example below.

`
function AppWithMFA() {
const [readyToShow, setReadyToShow] = useState(false)
const [showMFAScreen, setShowMFAScreen] = useState(false)
useEffect(() => {
    ;(async () => {
      try {
        const { data, error } = await supabase.auth.mfa.getAuthenticatorAssuranceLevel()
        if (error) {
          throw error
        }
        console.log(data)
        if (data.nextLevel === 'aal2' && data.nextLevel !== data.currentLevel) {
          setShowMFAScreen(true)
        }
      } finally {
        setReadyToShow(true)
      }
    })()
}, [])
if (readyToShow) {
    if (showMFAScreen) {
      return <AuthMFA />
    }
    return <App />
}
return <></>
}
`

- `supabase.auth.mfa.getAuthenticatorAssuranceLevel()` does return a promise.
Don't worry, this is a very fast method (microseconds) as it rarely uses the
network.
- `readyToShow` only makes sure the AAL check completes before showing any
application UI to the user.
- If the current level can be upgraded to the next one, the MFA screen is
shown.
- Once the challenge is successful, the `App` component is finally rendered on
screen.

Below is the component that implements the challenge and verify logic.

`
function AuthMFA() {
const [verifyCode, setVerifyCode] = useState('')
const [error, setError] = useState('')
const [factorId, setFactorId] = useState('')
const [challengeId, setChallengeId] = useState('')
const [phoneNumber, setPhoneNumber] = useState('')
const startChallenge = async () => {
    setError('')
    try {
      const factors = await supabase.auth.mfa.listFactors()
      if (factors.error) {
        throw factors.error
      }
      const phoneFactor = factors.data.phone[0]
      if (!phoneFactor) {
        throw new Error('No phone factors found!')
      }
      const factorId = phoneFactor.id
      setFactorId(factorId)
      setPhoneNumber(phoneFactor.phone)
      const challenge = await supabase.auth.mfa.challenge({ factorId })
      if (challenge.error) {
        setError(challenge.error.message)
        throw challenge.error
      }
      setChallengeId(challenge.data.id)
    } catch (error) {
      setError(error.message)
    }
}
const verifyCode = async () => {
    setError('')
    try {
      const verify = await supabase.auth.mfa.verify({
        factorId,
        challengeId,
        code: verifyCode,
      })
      if (verify.error) {
        setError(verify.error.message)
        throw verify.error
      }
    } catch (error) {
      setError(error.message)
    }
}
return (
    <>
      <div>Please enter the code sent to your phone.</div>
      {phoneNumber && <div>Phone number: {phoneNumber}</div>}
      {error && <div className="error">{error}</div>}
      <input
        type="text"
        value={verifyCode}
        onChange={(e) => setVerifyCode(e.target.value.trim())}
      />
      {!challengeId ? (
        <input type="button" value="Start Challenge" onClick={startChallenge} />
      ) : (
        <input type="button" value="Verify Code" onClick={verifyCode} />
      )}
    </>
)
}
`

- You can extract the available MFA factors for the user by calling
`supabase.auth.mfa.listFactors()`. Don't worry this method is also very quick
and rarely uses the network.
- If `listFactors()` returns more than one factor (or of a different type) you
should present the user with a choice. For simplicity this is not shown in
the example.
- Phone numbers are unique per user. Users can only have one verified phone factor with a given phone number.
Attempting to enroll a new phone factor alongside an existing verified factor with the same number will result in an error.
- Each time the user presses the "Submit" button a new challenge is created for
the chosen factor (in this case the first one)
- On successful verification, the client library will refresh the session in
the background automatically and finally call the `onSuccess` callback, which
will show the authenticated `App` component on screen.

### Security configuration [\#](https://supabase.com/docs/guides/auth/auth-mfa/phone\#security-configuration)

Each code is valid for up to 5 minutes, after which a new one can be sent. Successive codes remain valid until expiry. When possible choose the longest code length acceptable to your use case, at a minimum of 6. This can be configured in the [Authentication Settings](https://supabase.com/dashboard/project/_/settings/auth).

Be aware that Phone MFA is vulnerable to SIM swap attacks where an attacker will call a mobile provider and ask to port the target's phone number to a new SIM card and then use the said SIM card to intercept an MFA code. Evaluate the your application's tolerance for such an attack. You can read more about SIM swapping attacks [here](https://en.wikipedia.org/wiki/SIM_swap_scam)

## Pricing [\#](https://supabase.com/docs/guides/auth/auth-mfa/phone\#pricing)

$0.1027 per hour ($75 per month) for the first project. $0.0137 per hour ($10 per month) for every additional project.

| Plan | Project 1 per month | Project 2 per month | Project 3 per month |
| --- | --- | --- | --- |
| Pro | $75 | $10 | $10 |
| Team | $75 | $10 | $10 |
| Enterprise | Custom | Custom | Custom |

For a detailed breakdown of how charges are calculated, refer to [Manage Advanced MFA Phone usage](https://supabase.com/docs/guides/platform/manage-your-usage/advanced-mfa-phone).

### Is this helpful?

NoYes

### On this page

[How does phone multi-factor-authentication work?](https://supabase.com/docs/guides/auth/auth-mfa/phone#how-does-phone-multi-factor-authentication-work) [Add enrollment flow](https://supabase.com/docs/guides/auth/auth-mfa/phone#add-enrollment-flow) [Add a challenge step to login](https://supabase.com/docs/guides/auth/auth-mfa/phone#add-a-challenge-step-to-login) [Security configuration](https://supabase.com/docs/guides/auth/auth-mfa/phone#security-configuration) [Pricing](https://supabase.com/docs/guides/auth/auth-mfa/phone#pricing)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_auth_mfa_totp.md">
Auth

# Multi-Factor Authentication (TOTP)

* * *

## How does app authenticator multi-factor authentication work? [\#](https://supabase.com/docs/guides/auth/auth-mfa/totp\#how-does-app-authenticator-multi-factor-authentication-work)

App Authenticator (TOTP) multi-factor authentication involves a timed one-time password generated from an authenticator app in the control of users. It uses a QR Code which to transmit a shared secret used to generate a One Time Password. A user can scan a QR code with their phone to capture a shared secret required for subsequent authentication.

The use of a QR code was [initially introduced by Google Authenticator](https://github.com/google/google-authenticator/wiki/Key-Uri-Format) but is now universally accepted by all authenticator apps. The QR code has an alternate representation in URI form following the `otpauth` scheme such as: `otpauth://totp/supabase:alice@supabase.com?secret=<secret>&issuer=supabase` which a user can manually input in cases where there is difficulty rendering a QR Code.

Below is a flow chart illustrating how the Enrollment, Challenge, and Verify APIs work in the context of MFA (TOTP).

![Diagram showing the flow of Multi-Factor authentication](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fauth-mfa%2Fauth-mfa-flow.svg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

[TOTP MFA API](https://supabase.com/docs/reference/javascript/auth-mfa-api) is free to use and is enabled on all Supabase projects by default.

### Add enrollment flow [\#](https://supabase.com/docs/guides/auth/auth-mfa/totp\#add-enrollment-flow)

An enrollment flow provides a UI for users to set up additional authentication factors. Most applications add the enrollment flow in two places within their app:

1. Right after login or sign up.
This lets users quickly set up MFA immediately after they log in or create an
account. We recommend encouraging all users to set up MFA if that makes sense
for your application. Many applications offer this as an opt-in step in an
effort to reduce onboarding friction.
2. From within a settings page.
Allows users to set up, disable or modify their MFA settings.

Enrolling a factor for use with MFA takes three steps:

1. Call `supabase.auth.mfa.enroll()`.
This method returns a QR code and a secret. Display the QR
code to the user and ask them to scan it with their authenticator application.
If they are unable to scan the QR code, show the secret in plain text which
they can type or paste into their authenticator app.
2. Calling the `supabase.auth.mfa.challenge()` API.
This prepares Supabase Auth to accept a verification code from the user
and returns a challenge ID. In the case of Phone MFA this step also sends the verification code to the user.
3. Calling the `supabase.auth.mfa.verify()` API.
This verifies that the user has indeed added the secret from step (1) into
their app and is working correctly. If the verification succeeds, the factor
immediately becomes active for the user account. If not, you should repeat
steps 2 and 3.

#### Example: React [\#](https://supabase.com/docs/guides/auth/auth-mfa/totp\#example-react)

Below is an example that creates a new `EnrollMFA` component that illustrates the important pieces of the MFA enrollment flow.

- When the component appears on screen, the `supabase.auth.mfa.enroll()` API is
called once to start the process of enrolling a new factor for the current
user.
- This API returns a QR code in the SVG format, which is shown on screen using
a normal `<img>` tag by encoding the SVG as a data URL.
- Once the user has scanned the QR code with their authenticator app, they
should enter the verification code within the `verifyCode` input field and
click on `Enable`.
- A challenge is created using the `supabase.auth.mfa.challenge()` API and the
code from the user is submitted for verification using the
`supabase.auth.mfa.verify()` challenge.
- `onEnabled` is a callback that notifies the other components that enrollment
has completed.
- `onCancelled` is a callback that notifies the other components that the user
has clicked the `Cancel` button.

``
/**
* EnrollMFA shows a simple enrollment dialog. When shown on screen it calls
* the `enroll` API. Each time a user clicks the Enable button it calls the
* `challenge` and `verify` APIs to check if the code provided by the user is
* valid.
* When enrollment is successful, it calls `onEnrolled`. When the user clicks
* Cancel the `onCancelled` callback is called.
*/
export function EnrollMFA({
onEnrolled,
onCancelled,
}: {
onEnrolled: () => void
onCancelled: () => void
}) {
const [factorId, setFactorId] = useState('')
const [qr, setQR] = useState('') // holds the QR code image SVG
const [verifyCode, setVerifyCode] = useState('') // contains the code entered by the user
const [error, setError] = useState('') // holds an error message
const onEnableClicked = () => {
    setError('')
    ;(async () => {
      const challenge = await supabase.auth.mfa.challenge({ factorId })
      if (challenge.error) {
        setError(challenge.error.message)
        throw challenge.error
      }
      const challengeId = challenge.data.id
      const verify = await supabase.auth.mfa.verify({
        factorId,
        challengeId,
        code: verifyCode,
      })
      if (verify.error) {
        setError(verify.error.message)
        throw verify.error
      }
      onEnrolled()
    })()
}
useEffect(() => {
    ;(async () => {
      const { data, error } = await supabase.auth.mfa.enroll({
        factorType: 'totp',
      })
      if (error) {
        throw error
      }
      setFactorId(data.id)
      // Supabase Auth returns an SVG QR code which you can convert into a data
      // URL that you can place in an <img> tag.
      setQR(data.totp.qr_code)
    })()
}, [])
return (
    <>
      {error && <div className="error">{error}</div>}
      <img src={qr} />
      <input
        type="text"
        value={verifyCode}
        onChange={(e) => setVerifyCode(e.target.value.trim())}
      />
      <input type="button" value="Enable" onClick={onEnableClicked} />
      <input type="button" value="Cancel" onClick={onCancelled} />
    </>
)
}
``

### Add a challenge step to login [\#](https://supabase.com/docs/guides/auth/auth-mfa/totp\#add-a-challenge-step-to-login)

Once a user has logged in via their first factor (email+password, magic link, one time password, social login etc.) you need to perform a check if any additional factors need to be verified.

This can be done by using the `supabase.auth.mfa.getAuthenticatorAssuranceLevel()` API. When the user signs in and is redirected back to your app, you should call this method to extract the user's current and next authenticator assurance level (AAL).

Therefore if you receive a `currentLevel` which is `aal1` but a `nextLevel` of `aal2`, the user should be given the option to go through MFA.

Below is a table that explains the combined meaning.

| Current Level | Next Level | Meaning |
| --: | :-- | :-- |
| `aal1` | `aal1` | User does not have MFA enrolled. |
| `aal1` | `aal2` | User has an MFA factor enrolled but has not verified it. |
| `aal2` | `aal2` | User has verified their MFA factor. |
| `aal2` | `aal1` | User has disabled their MFA factor. (Stale JWT.) |

#### Example: React [\#](https://supabase.com/docs/guides/auth/auth-mfa/totp\#example-react)

Adding the challenge step to login depends heavily on the architecture of your app. However, a fairly common way to structure React apps is to have a large component (often named `App`) which contains most of the authenticated application logic.

This example will wrap this component with logic that will show an MFA challenge screen if necessary, before showing the full application. This is illustrated in the `AppWithMFA` example below.

`
function AppWithMFA() {
const [readyToShow, setReadyToShow] = useState(false)
const [showMFAScreen, setShowMFAScreen] = useState(false)
useEffect(() => {
    ;(async () => {
      try {
        const { data, error } = await supabase.auth.mfa.getAuthenticatorAssuranceLevel()
        if (error) {
          throw error
        }
        console.log(data)
        if (data.nextLevel === 'aal2' && data.nextLevel !== data.currentLevel) {
          setShowMFAScreen(true)
        }
      } finally {
        setReadyToShow(true)
      }
    })()
}, [])
if (readyToShow) {
    if (showMFAScreen) {
      return <AuthMFA />
    }
    return <App />
}
return <></>
}
`

- `supabase.auth.mfa.getAuthenticatorAssuranceLevel()` does return a promise.
Don't worry, this is a very fast method (microseconds) as it rarely uses the
network.
- `readyToShow` only makes sure the AAL check completes before showing any
application UI to the user.
- If the current level can be upgraded to the next one, the MFA screen is
shown.
- Once the challenge is successful, the `App` component is finally rendered on
screen.

Below is the component that implements the challenge and verify logic.

`
function AuthMFA() {
const [verifyCode, setVerifyCode] = useState('')
const [error, setError] = useState('')
const onSubmitClicked = () => {
    setError('')
    ;(async () => {
      const factors = await supabase.auth.mfa.listFactors()
      if (factors.error) {
        throw factors.error
      }
      const totpFactor = factors.data.totp[0]
      if (!totpFactor) {
        throw new Error('No TOTP factors found!')
      }
      const factorId = totpFactor.id
      const challenge = await supabase.auth.mfa.challenge({ factorId })
      if (challenge.error) {
        setError(challenge.error.message)
        throw challenge.error
      }
      const challengeId = challenge.data.id
      const verify = await supabase.auth.mfa.verify({
        factorId,
        challengeId,
        code: verifyCode,
      })
      if (verify.error) {
        setError(verify.error.message)
        throw verify.error
      }
    })()
}
return (
    <>
      <div>Please enter the code from your authenticator app.</div>
      {error && <div className="error">{error}</div>}
      <input
        type="text"
        value={verifyCode}
        onChange={(e) => setVerifyCode(e.target.value.trim())}
      />
      <input type="button" value="Submit" onClick={onSubmitClicked} />
    </>
)
}
`

- You can extract the available MFA factors for the user by calling
`supabase.auth.mfa.listFactors()`. Don't worry this method is also very quick
and rarely uses the network.
- If `listFactors()` returns more than one factor (or of a different type) you
should present the user with a choice. For simplicity this is not shown in
the example.
- Each time the user presses the "Submit" button a new challenge is created for
the chosen factor (in this case the first one) and it is immediately
verified. Any errors are displayed to the user.
- On successful verification, the client library will refresh the session in
the background automatically and finally call the `onSuccess` callback, which
will show the authenticated `App` component on screen.

## Frequently asked questions [\#](https://supabase.com/docs/guides/auth/auth-mfa/totp\#frequently-asked-questions)

What's inside the QR code?

How long is the TOTP code valid for?

### Is this helpful?

NoYes

### On this page

[How does app authenticator multi-factor authentication work?](https://supabase.com/docs/guides/auth/auth-mfa/totp#how-does-app-authenticator-multi-factor-authentication-work) [Add enrollment flow](https://supabase.com/docs/guides/auth/auth-mfa/totp#add-enrollment-flow) [Add a challenge step to login](https://supabase.com/docs/guides/auth/auth-mfa/totp#add-a-challenge-step-to-login) [Frequently asked questions](https://supabase.com/docs/guides/auth/auth-mfa/totp#frequently-asked-questions)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_auth_mfa.md">
Auth

# Multi-Factor Authentication

* * *

Multi-factor authentication (MFA), sometimes called two-factor authentication (2FA), adds an additional layer of security to your application by verifying their identity through additional verification steps.

It is considered a best practice to use MFA for your applications.

Users with weak passwords or compromised social login accounts are prone to malicious account takeovers. These can be prevented with MFA because they require the user to provide proof of both of these:

- Something they know.
Password, or access to a social-login account.
- Something they have.
Access to an authenticator app (a.k.a. TOTP) or a mobile phone.

## Overview [\#](https://supabase.com/docs/guides/auth/auth-mfa\#overview)

Supabase Auth implements MFA via two methods: App Authenticator, which makes use of a Time based-one Time Password, and phone messaging, which makes use of a code generated by Supabase Auth.

Applications using MFA require two important flows:

1. **Enrollment flow.**
This lets users set up and control MFA in your app.
2. **Authentication flow.**
This lets users sign in using any factors after the conventional login step.

Supabase Auth provides:

- **Enrollment API** \- build rich user interfaces for adding and removing factors.
- **Challenge and Verify APIs** \- securely verify that the user has access to a factor.
- **List Factors API** \- build rich user interfaces for signing in with additional factors.

You can control access to the Enrollment API as well as the Challenge and Verify APIs via the Supabase Dashboard. A setting of `Verification Disabled` will disable both the challenge API and the verification API.

These sets of APIs let you control the MFA experience that works for you. You can create flows where MFA is optional, mandatory for all, or only specific groups of users.

Once users have enrolled or signed-in with a factor, Supabase Auth adds additional metadata to the user's access token (JWT) that your application can use to allow or deny access.

This information is represented by an [Authenticator Assurance Level](https://pages.nist.gov/800-63-3-Implementation-Resources/63B/AAL/), a standard measure about the assurance of the user's identity Supabase Auth has for that particular session. There are two levels recognized today:

1. **Assurance Level 1: `aal1`**
Means that the user's identity was verified using a conventional login method
such as email+password, magic link, one-time password, phone auth or social
login.
2. **Assurance Level 2: `aal2`**
Means that the user's identity was additionally verified using at least one
second factor, such as a TOTP code or One-Time Password code.

This assurance level is encoded in the `aal` claim in the JWT associated with the user. By decoding this value you can create custom authorization rules in your frontend, backend, and database that will enforce the MFA policy that works for your application. JWTs without an `aal` claim are at the `aal1` level.

## Adding to your app [\#](https://supabase.com/docs/guides/auth/auth-mfa\#adding-to-your-app)

Adding MFA to your app involves these four steps:

1. **Add enrollment flow.**
You need to provide a UI within your app that your users will be able to set-up
MFA in. You can add this right after sign-up, or as part of a separate flow in
the settings portion of your app.
2. **Add unenroll flow.**
You need to support a UI through which users can see existing devices and unenroll
devices which are no longer relevant.
3. **Add challenge step to login.**
If a user has set-up MFA, your app's login flow needs to present a challenge
screen to the user asking them to prove they have access to the additional
factor.
4. **Enforce rules for MFA logins.**
Once your users have a way to enroll and log in with MFA, you need to enforce
authorization rules across your app: on the frontend, backend, API servers or
Row-Level Security policies.

The enrollment flow and the challenge steps differ by factor and are covered on a separate page. Visit the [Phone](https://supabase.com/docs/guides/auth/auth-mfa/phone) or [App Authenticator](https://supabase.com/docs/guides/auth/auth-mfa/totp) pages to see how to add the flows for the respective factors. You can combine both flows and allow for use of both Phone and App Authenticator Factors.

### Add unenroll flow [\#](https://supabase.com/docs/guides/auth/auth-mfa\#add-unenroll-flow)

The unenroll process is the same for both Phone and TOTP factors.

An unenroll flow provides a UI for users to manage and unenroll factors linked to their accounts. Most applications do so via a factor management page where users can view and unlink selected factors.

When a user unenrolls a factor, call `supabase.auth.mfa.unenroll()` with the ID of the factor. For example, call:

`
supabase.auth.mfa.unenroll({factorId: "d30fd651-184e-4748-a928-0a4b9be1d429"})
`

to unenroll a factor with ID `d30fd651-184e-4748-a928-0a4b9be1d429`.

### Enforce rules for MFA logins [\#](https://supabase.com/docs/guides/auth/auth-mfa\#enforce-rules-for-mfa-logins)

Adding MFA to your app's UI does not in-and-of-itself offer a higher level of security to your users. You also need to enforce the MFA rules in your application's database, APIs, and server-side rendering.

Depending on your application's needs, there are three ways you can choose to enforce MFA.

1. **Enforce for all users (new and existing).**
Any user account will have to enroll MFA to continue using your app.
The application will not allow access without going through MFA first.
2. **Enforce for new users only.**
Only new users will be forced to enroll MFA, while old users will be encouraged
to do so.
The application will not allow access for new users without going through MFA
first.
3. **Enforce only for users that have opted-in.**
Users that want MFA can enroll in it and the application will not allow access
without going through MFA first.

#### Example: React [\#](https://supabase.com/docs/guides/auth/auth-mfa\#example-react)

Below is an example that creates a new `UnenrollMFA` component that illustrates the important pieces of the MFA enrollment flow. Note that users can only unenroll a factor after completing the enrollment flow and obtaining an `aal2` JWT claim. Here are some points of note:

- When the component appears on screen, the `supabase.auth.mfa.listFactors()` endpoint
fetches all existing factors together with their details.
- The existing factors for a user are displayed in a table.
- Once the user has selected a factor to unenroll, they can type in the `factorId` and click **Unenroll**
which creates a confirmation modal.

Unenrolling a factor will downgrade the assurance level from `aal2` to `aal1` only after the refresh interval has lapsed. For an immediate downgrade from `aal2` to `aal1` after enrolling one will need to manually call `refreshSession()`

`
/**
* UnenrollMFA shows a simple table with the list of factors together with a button to unenroll.
* When a user types in the factorId of the factor that they wish to unenroll and clicks unenroll
* the corresponding factor will be unenrolled.
*/
export function UnenrollMFA() {
const [factorId, setFactorId] = useState('')
const [factors, setFactors] = useState([])
const [error, setError] = useState('') // holds an error message
useEffect(() => {
    ;(async () => {
      const { data, error } = await supabase.auth.mfa.listFactors()
      if (error) {
        throw error
      }
      setFactors([...data.totp, ...data.phone])
    })()
}, [])
return (
    <>
      {error && <div className="error">{error}</div>}
      <tbody>
        <tr>
          <td>Factor ID</td>
          <td>Friendly Name</td>
          <td>Factor Status</td>
          <td>Phone Number</td>
        </tr>
        {factors.map((factor) => (
          <tr>
            <td>{factor.id}</td>
            <td>{factor.friendly_name}</td>
            <td>{factor.factor_type}</td>
            <td>{factor.status}</td>
            <td>{factor.phone}</td>
          </tr>
        ))}
      </tbody>
      <input type="text" value={verifyCode} onChange={(e) => setFactorId(e.target.value.trim())} />
      <button onClick={() => supabase.auth.mfa.unenroll({ factorId })}>Unenroll</button>
    </>
)
}
`

#### Database [\#](https://supabase.com/docs/guides/auth/auth-mfa\#database)

Your app should sufficiently deny or allow access to tables or rows based on the user's current and possible authenticator levels.

Postgres has two types of policies: permissive and restrictive. This guide uses restrictive policies. Make sure you don't omit the `as restrictive` clause.

##### Enforce for all users (new and existing)

If your app falls under this case, this is a template Row Level Security policy you can apply to all your tables:

`
create policy "Policy name."
on table_name
as restrictive
to authenticated
using ((select auth.jwt()->>'aal') = 'aal2');
`

- Here the policy will not accept any JWTs with an `aal` claim other than
`aal2`, which is the highest authenticator assurance level.
- **Using `as restrictive` ensures this policy will restrict all commands on the**
**table regardless of other policies!**

##### Enforce for new users only

If your app falls under this case, the rules get more complex. User accounts created past a certain timestamp must have a `aal2` level to access the database.

`
create policy "Policy name."
on table_name
as restrictive -- very important!
to authenticated
using
    (array[(select auth.jwt()->>'aal')] <@ (
       select
         case
           when created_at >= '2022-12-12T00:00:00Z' then array['aal2']
           else array['aal1', 'aal2']
         end as aal
       from auth.users
       where (select auth.uid()) = id));
`

- The policy will accept both `aal1` and `aal2` for users with a `created_at`
timestamp prior to 12th December 2022 at 00:00 UTC, but will only accept
`aal2` for all other timestamps.
- The `<@` operator is PostgreSQL's ["contained in"\\
operator.](https://www.postgresql.org/docs/current/functions-array.html)
- **Using `as restrictive` ensures this policy will restrict all commands on the**
**table regardless of other policies!**

##### Enforce only for users that have opted-in

Users that have enrolled MFA on their account are expecting that your
application only works for them if they've gone through MFA.

`
create policy "Policy name."
on table_name
as restrictive -- very important!
to authenticated
using (
    array[(select auth.jwt()->>'aal')] <@ (
      select
          case
            when count(id) > 0 then array['aal2']
            else array['aal1', 'aal2']
          end as aal
        from auth.mfa_factors
        where ((select auth.uid()) = user_id) and status = 'verified'
    ));
`

- The policy will only accept only `aal2` when the user has at least one MFA
factor verified.
- Otherwise, it will accept both `aal1` and `aal2`.
- The `<@` operator is PostgreSQL's ["contained in"\\
operator.](https://www.postgresql.org/docs/current/functions-array.html)
- **Using `as restrictive` ensures this policy will restrict all commands on the**
**table regardless of other policies!**

### Server-Side Rendering [\#](https://supabase.com/docs/guides/auth/auth-mfa\#server-side-rendering)

When using the Supabase JavaScript library in a server-side rendering context, make sure you always create a new object for each request! This will prevent you from accidentally rendering and serving content belonging to different users.

It is possible to enforce MFA on the Server-Side Rendering level. However, this can be tricky do to well.

You can use the `supabase.auth.mfa.getAuthenticatorAssuranceLevel()` and `supabase.auth.mfa.listFactors()` APIs to identify the AAL level of the session and any factors that are enabled for a user, similar to how you would use these on the browser.

However, encountering a different AAL level on the server may not actually be a security problem. Consider these likely scenarios:

1. User signed-in with a conventional method but closed their tab on the MFA
flow.
2. User forgot a tab open for a very long time. (This happens more often than
you might imagine.)
3. User has lost their authenticator device and is confused about the next
steps.

We thus recommend you redirect users to a page where they can authenticate using their additional factor, instead of rendering a HTTP 401 Unauthorized or HTTP 403 Forbidden content.

### APIs [\#](https://supabase.com/docs/guides/auth/auth-mfa\#apis)

If your application uses the Supabase Database, Storage or Edge Functions, just using Row Level Security policies will give you sufficient protection. In the event that you have other APIs that you wish to protect, follow these general guidelines:

1. **Use a good JWT verification and parsing library for your language.**
This will let you securely parse JWTs and extract their claims.
2. **Retrieve the `aal` claim from the JWT and compare its value according to**
**your needs.**
If you've encountered an AAL level that can be increased, ask the user to
continue the login process instead of logging them out.
3. **Use the `https://<project-ref>.supabase.co/rest/v1/auth/factors` REST**
**endpoint to identify if the user has enrolled any MFA factors.**
Only `verified` factors should be acted upon.

## Frequently asked questions [\#](https://supabase.com/docs/guides/auth/auth-mfa\#frequently-asked-questions)

How do I check when a user went through MFA?

### Is this helpful?

NoYes

### On this page

[Overview](https://supabase.com/docs/guides/auth/auth-mfa#overview) [Adding to your app](https://supabase.com/docs/guides/auth/auth-mfa#adding-to-your-app) [Add unenroll flow](https://supabase.com/docs/guides/auth/auth-mfa#add-unenroll-flow) [Enforce rules for MFA logins](https://supabase.com/docs/guides/auth/auth-mfa#enforce-rules-for-mfa-logins) [Server-Side Rendering](https://supabase.com/docs/guides/auth/auth-mfa#server-side-rendering) [APIs](https://supabase.com/docs/guides/auth/auth-mfa#apis) [Frequently asked questions](https://supabase.com/docs/guides/auth/auth-mfa#frequently-asked-questions)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_auth_smtp.md">
Auth

# Send emails with custom SMTP

* * *

If you're using Supabase Auth with the following configuration:

- Email and password accounts
- Passwordless accounts using one-time passwords or links sent over email (OTP, magic link, invites)
- Email-based user invitations from the [Users page](https://supabase.com/dashboard/project/_/auth/users) or from the Auth admin APIs
- Social login with email confirmation

You will need to set up a custom SMTP server to handle the delivery of messages to your users.

To get you started and let you explore and set up email message templates for your application, Supabase provides a simple SMTP server for all projects. This server imposes a few important restrictions and is not meant for production use.

**Send messages only to pre-authorized addresses.**

Unless you configure a custom SMTP server for your project, Supabase Auth will refuse to deliver messages to addresses that are not part of the project's team. You can manage this in the [Team tab](https://supabase.com/dashboard/org/_/team) of the organization's settings.

For example, if your project's organization has these member accounts `person-a@example.com`, `person-b@example.com` and `person-c@example.com` then Supabase Auth will only send messages to these addresses. All other addresses will fail with the error message _Email address not authorized._

**Significant rate-limits that can change over time.**

To maintain the health and reputation of the default SMTP sending service, the number of messages your project can send is limited and can change without notice. Currently this value is set to 2 messages per hour.

**No SLA guarantee on message delivery or uptime for the default SMTP service.**

The default SMTP service is provided as best-effort only and intended for the following non-production use cases:

- Exploring and getting started with Supabase Auth
- Setting up and testing email templates with the members of the project's team
- Building toy projects, demos or any non-mission-critical application

We urge all customers to set up custom SMTP server for all other use cases.

## How to set up a custom SMTP server? [\#](https://supabase.com/docs/guides/auth/auth-smtp\#how-to-set-up-a-custom-smtp-server)

Supabase Auth works with any email sending service that supports the SMTP protocol. First you will need to choose a service, create an account (if you already do not have one) and obtain the SMTP server settings and credentials for your account. These include: the SMTP server host, port, user and password. You will also need to choose a default From address, usually something like `no-reply@example.com`.

A non-exhaustive list of services that work with Supabase Auth is:

- [Resend](https://resend.com/docs/send-with-supabase-smtp)
- [AWS SES](https://docs.aws.amazon.com/ses/latest/dg/send-email-smtp.html)
- [Postmark](https://postmarkapp.com/developer/user-guide/send-email-with-smtp)
- [Twilio SendGrid](https://www.twilio.com/docs/sendgrid/for-developers/sending-email/getting-started-smtp)
- [ZeptoMail](https://www.zoho.com/zeptomail/help/smtp-home.html)
- [Brevo](https://help.brevo.com/hc/en-us/articles/7924908994450-Send-transactional-emails-using-Brevo-SMTP)

Once you've set up your account with an email sending service, head to the [Authentication settings page](https://supabase.com/dashboard/project/_/settings/auth) to enable and configure custom SMTP.

Once you save these settings, your project's Auth server will send messages to all addresses. To protect the reputation of your newly set up service a low rate-limit of 30 messages per hour is imposed. To adjust this to an acceptable value for your use case head to the [Rate Limits configuration page](https://supabase.com/dashboard/project/_/auth/rate-limits).

## Dealing with abuse: How to maintain the sending reputation of your SMTP server? [\#](https://supabase.com/docs/guides/auth/auth-smtp\#dealing-with-abuse-how-to-maintain-the-sending-reputation-of-your-smtp-server)

As you make your application known to the public and it grows in popularity, you can expect to see a few types of abuse that can negatively impact the reputation of your sending domain.

A common source of abuse is bots or attackers signing up users to your application.

They use lists of known email addresses to sign up users to your project with pre-determined passwords. These can vary in scale and intensity: sometimes the bots slowly send sign up requests over many months, or they send a lot of requests at once.

Usually the goal for this behavior is:

- To negatively affect your email sending reputation, after which they might ask for a ransom promising to stop the behavior.
- To cause a short-term or even long-term Denial of Service attack on your service, by preventing new account creation, signins with magic links or one-time passwords, or to severely impact important security flows in your application (such as reset password or forgot password).
- To force you to reduce the security posture of your project, such as by disabling email confirmations. At that point, they may target specific or a broad number of users by creating an account in their name. Then they can use social engineering techniques to trick them to use your application in such a way that both attacker and victim have access to the same account.

Mitigation strategies:

- [Configure CAPTCHA protection](https://supabase.com/docs/guides/auth/auth-captcha) for your project, which is the most effective way to control bots in this scenario. You can use CAPTCHA services which provide invisible challenges where real users won't be asked to solve puzzles most of the time.
- Prefer social login (OAuth) or SSO with SAML instead of email-based authentication flows in your apps.
- Prefer passwordless authentication (one-time password) as this limits the attacker's value to gain from this behavior.
- Do not disable email confirmations under pressure.

### Additional best practices [\#](https://supabase.com/docs/guides/auth/auth-smtp\#additional-best-practices)

**Set up and maintain DKIM, DMARC and SPF configurations.**

Work with your email sending service to configure [DKIM, DMARC and SPF](https://www.cloudflare.com/learning/email-security/dmarc-dkim-spf/) for your sending domain. This will significantly increase the deliverability of your messages.

**Set up a custom domain.**

Authentication messages often contain links to your project's Auth server. [Setting up a custom domain](https://supabase.com/docs/guides/platform/custom-domains) will reduce the likelihood of your messages being picked up as spam due to another Supabase project's bad reputation.

**Don't mix Auth emails with marketing emails.**

Use separate services for Auth and marketing messages. If the reputation of one falls, it won't affect your whole application or operation.

This includes:

- Use a separate sending domain for authentication -- `auth.example.com` and a separate domain for marketing `marketing.example.com`.
- Use a separate From address -- `no-reply@auth.example.com` vs `no-reply@marketing.example.com`.

**Have another SMTP service set up on stand-by.**

In case the primary SMTP service you're using is experiencing difficulty, or your account is under threat of being blocked due to spam, you have another service to quickly turn to.

**Use consistent branding and focused content.**

Make sure you've separated out authentication messages from marketing messages.

- Don't include promotional content as part of authentication messages.
- Avoid talking about what your application is inside authentication messages. This can be picked up by automated spam filters which will classify the message as marketing and increase its chances of being regarded as spam. This problem is especially apparent if your project is related to: Web3, Blockchain, AI, NFTs, Gambling, Pornography.
- Avoid taglines or other short-form marketing material in authentication messages.
- Reduce the number of links and call-to-actions in authentication messages.
- Change the authentication messages templates infrequently. Prefer a single big change over multiple smaller changes.
- Avoid A/B testing content in authentication messages.
- Use a separate base template (HTML) from your marketing messages.
- Avoid the use of email signatures in authentication messages. If you do, make sure the signatures are different in style and content from your marketing messages.
- Use short and to-the-point subject lines. Avoid or reduce the number of emojis in subjects.
- Reduce the number of images placed in authentication messages.
- Avoid including user-provided data such as names, usernames, email addresses or salutations in authentication messages. If you do, make sure they are sanitized.

**Prepare for large surges ahead of time.**

If you are planning on having a large surge of users coming at a specific time, work with your email sending service to adjust the rate limits and their expectations accordingly. Most email sending services dislike spikes in the number of messages being sent, and this may affect your sending reputation.

Consider implementing additional protections for such events:

- Build a queuing or waitlist system instead of allowing direct sign-up, which will help you control the number of messages being sent from the email sending service.
- Disable email-based sign ups for the event and use social login only. Alternatively you can deprioritize the email-based sign-up flows for the event by hiding them in the UI or making them harder to reach.

**Use the Send Email Auth Hook for more control.**

If you need more control over the sending process, instead of using a SMTP server you can use the [Send Email Auth Hook](https://supabase.com/docs/guides/auth/auth-hooks/send-email-hook). This can be useful in advanced scenarios such as:

- You want to use React or a different email templating engine.
- You want to use an email sending service that does not provide an SMTP service, or the non-SMTP API is more powerful.
- You want to queue up messages instead of sending them immediately, in an effort to smooth out spikes in email sending or do additional filtering (avoid repetitive messages).
- You want to use multiple email sending services to increase reliability (if primary service is unavailable, use backup service automatically).
- You want to use different email sending services based on the email address or user data (e.g. service A for users in the USA, service B for users in the EU, service C for users in China).
- You want to add or include additional email headers in messages, for tracking or other reasons.
- You want to add attachments to the messages (generally not recommended).
- You want to add [S/MIME signatures](https://en.wikipedia.org/wiki/S/MIME) to messages.
- You want to use an email server not open to the Internet, such as some corporate or government mail servers.

**Increase the duration of user sessions.**

Having short lived [user sessions](https://supabase.com/docs/guides/auth/sessions) can be problematic for email sending, as it forces active users to sign-in frequently, increasing the number of messages needed to be sent. Consider increasing the maximum duration of user sessions. If you do see an unnecessary increase in logins without a clear cause, check your frontend application for bugs.

If you are using a [SSR](https://supabase.com/docs/guides/auth/server-side) framework on the frontend and are seeing an increased number of user logins without a clear cause, check your set up. Make sure to keep the `@supabase/ssr` package up to date and closely follow the guides we publish. Make sure that the middleware components of your SSR frontend works as intended and matches the guides we've published. Sometimes a misplaced `return` or conditional can cause early session termination.

### Is this helpful?

NoYes

### On this page

[How to set up a custom SMTP server?](https://supabase.com/docs/guides/auth/auth-smtp#how-to-set-up-a-custom-smtp-server) [Dealing with abuse: How to maintain the sending reputation of your SMTP server?](https://supabase.com/docs/guides/auth/auth-smtp#dealing-with-abuse-how-to-maintain-the-sending-reputation-of-your-smtp-server) [Additional best practices](https://supabase.com/docs/guides/auth/auth-smtp#additional-best-practices)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_debugging_error_codes.md">
Auth

# Error Codes

## Learn about the Auth error codes and how to resolve them

* * *

## Auth error codes [\#](https://supabase.com/docs/guides/auth/debugging/error-codes\#auth-error-codes)

Supabase Auth can return various errors when using its API. This guide explains how to handle these errors effectively across different programming languages.

## Error types [\#](https://supabase.com/docs/guides/auth/debugging/error-codes\#error-types)

Supabase Auth errors are generally categorized into two main types:

- API Errors: Originate from the Supabase Auth API.
- Client Errors: Originate from the client library's state.

Client errors differ by language so do refer to the appropriate section below:

JavaScriptDartSwiftPythonKotlin

All errors originating from the `supabase.auth` namespace of the client library will be wrapped by the `AuthError` class.

Error objects are split in a few classes:

- `AuthApiError` \-\- errors which originate from the Supabase Auth API.
  - Use `isAuthApiError` instead of `instanceof` checks to see if an error you caught is of this type.
- `CustomAuthError` \-\- errors which generally originate from state in the client library.
  - Use the `name` property on the error to identify the class of error received.

Errors originating from the server API classed as `AuthApiError` always have a `code` property that can be used to identify the error returned by the server. The `status` property is also present, encoding the HTTP status code received in the response.

## HTTP status codes [\#](https://supabase.com/docs/guides/auth/debugging/error-codes\#http-status-codes)

Below are the most common HTTP status codes you might encounter, along with their meanings in the context of Supabase Auth:

### [403 Forbidden](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403) [\#](https://supabase.com/docs/guides/auth/debugging/error-codes\#403-forbidden)

Sent out in rare situations where a certain Auth feature is not available for the user, and you as the developer are not checking a precondition whether that API is available for the user.

### [422 Unprocessable Entity](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/422) [\#](https://supabase.com/docs/guides/auth/debugging/error-codes\#422-unprocessable-entity)

Sent out when the API request is accepted, but cannot be processed because the user or Auth server is in a state where it cannot satisfy the request.

### [429 Too Many Requests](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429) [\#](https://supabase.com/docs/guides/auth/debugging/error-codes\#429-too-many-requests)

Sent out when rate-limits are breached for an API. You should handle this status code often, especially in functions that authenticate a user.

### [500 Internal Server Error](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/500) [\#](https://supabase.com/docs/guides/auth/debugging/error-codes\#500-internal-server-error)

Indicate that the Auth server's service is degraded. Most often it points to issues in your database setup such as a misbehaving trigger on a schema, function, view or other database object.

### [501 Not Implemented](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/501) [\#](https://supabase.com/docs/guides/auth/debugging/error-codes\#501-not-implemented)

Sent out when a feature is not enabled on the Auth server, and you are trying to use an API which requires it.

## Auth error codes table [\#](https://supabase.com/docs/guides/auth/debugging/error-codes\#auth-error-codes-table)

The following table provides a comprehensive list of error codes you may encounter when working with Supabase Auth. Each error code is associated with a specific issue and includes a description to help you understand and resolve the problem efficiently.

To supplement HTTP status codes, Supabase Auth returns a string error code which gives you more insight into what went wrong. These codes are stable and can be used to present an internationalized message to your users.

| Code | Description |
| --- | --- |
| `anonymous_provider_disabled` | Anonymous sign-ins are disabled. |
| `bad_code_verifier` | Returned from the PKCE flow where the provided code verifier does not match the expected one. Indicates a bug in the implementation of the client library. |
| `bad_json` | Usually used when the HTTP body of the request is not valid JSON. |
| `bad_jwt` | JWT sent in the `Authorization` header is not valid. |
| `bad_oauth_callback` | OAuth callback from provider to Auth does not have all the required attributes (state). Indicates an issue with the OAuth provider or client library implementation. |
| `bad_oauth_state` | OAuth state (data echoed back by the OAuth provider to Supabase Auth) is not in the correct format. Indicates an issue with the OAuth provider integration. |
| `captcha_failed` | Captcha challenge could not be verified with the captcha provider. Check your captcha integration. |
| `conflict` | General database conflict, such as concurrent requests on resources that should not be modified concurrently. Can often occur when you have too many session refresh requests firing off at the same time for a user. Check your app for concurrency issues, and if detected, back off exponentially. |
| `email_address_invalid` | Example and test domains are currently not supported. Please use a different email address. |
| `email_address_not_authorized` | Email sending is not allowed for this address as your project is using the default SMTP service. Emails can only be sent to members in your Supabase organization. If you want to send emails to others, please set up a [custom SMTP provider](https://supabase.com/docs/guides/auth/auth-smtp). |
| `email_conflict_identity_not_deletable` | Unlinking this identity causes the user's account to change to an email address which is already used by another user account. Indicates an issue where the user has two different accounts using different primary email addresses. You may need to migrate user data to one of their accounts in this case. |
| `email_exists` | Email address already exists in the system. |
| `email_not_confirmed` | Signing in is not allowed for this user as the email address is not confirmed. |
| `email_provider_disabled` | Signups are disabled for email and password. |
| `flow_state_expired` | PKCE flow state to which the API request relates has expired. Ask the user to sign in again. |
| `flow_state_not_found` | PKCE flow state to which the API request relates no longer exists. Flow states expire after a while and are progressively cleaned up, which can cause this error. Retried requests can cause this error, as the previous request likely destroyed the flow state. Ask the user to sign in again. |
| `hook_payload_invalid_content_type` | Payload from Auth does not have a valid Content-Type header. |
| `hook_payload_over_size_limit` | Payload from Auth exceeds maximum size limit. |
| `hook_timeout` | Unable to reach hook within maximum time allocated. |
| `hook_timeout_after_retry` | Unable to reach hook after maximum number of retries. |
| `identity_already_exists` | The identity to which the API relates is already linked to a user. |
| `identity_not_found` | Identity to which the API call relates does not exist, such as when an identity is unlinked or deleted. |
| `insufficient_aal` | To call this API, the user must have a higher [Authenticator Assurance Level](https://supabase.com/docs/guides/auth/auth-mfa). To resolve, ask the user to solve an MFA challenge. |
| `invite_not_found` | Invite is expired or already used. |
| `invalid_credentials` | Login credentials or grant type not recognized. |
| `manual_linking_disabled` | Calling the `supabase.auth.linkUser()` and related APIs is not enabled on the Auth server. |
| `mfa_challenge_expired` | Responding to an MFA challenge should happen within a fixed time period. Request a new challenge when encountering this error. |
| `mfa_factor_name_conflict` | MFA factors for a single user should not have the same friendly name. |
| `mfa_factor_not_found` | MFA factor no longer exists. |
| `mfa_ip_address_mismatch` | The enrollment process for MFA factors must begin and end with the same IP address. |
| `mfa_phone_enroll_not_enabled` | Enrollment of MFA Phone factors is disabled. |
| `mfa_phone_verify_not_enabled` | Login via Phone factors and verification of new Phone factors is disabled. |
| `mfa_totp_enroll_not_enabled` | Enrollment of MFA TOTP factors is disabled. |
| `mfa_totp_verify_not_enabled` | Login via TOTP factors and verification of new TOTP factors is disabled. |
| `mfa_verification_failed` | MFA challenge could not be verified -- wrong TOTP code. |
| `mfa_verification_rejected` | Further MFA verification is rejected. Only returned if the [MFA verification attempt hook](https://supabase.com/docs/guides/auth/auth-hooks?language=add-admin-role#hook-mfa-verification-attempt) returns a reject decision. |
| `mfa_verified_factor_exists` | Verified phone factor already exists for a user. Unenroll existing verified phone factor to continue. |
| `mfa_web_authn_enroll_not_enabled` | Enrollment of MFA Web Authn factors is disabled. |
| `mfa_web_authn_verify_not_enabled` | Login via WebAuthn factors and verification of new WebAuthn factors is disabled. |
| `no_authorization` | This HTTP request requires an `Authorization` header, which is not provided. |
| `not_admin` | User accessing the API is not admin, i.e. the JWT does not contain a `role` claim that identifies them as an admin of the Auth server. |
| `oauth_provider_not_supported` | Using an OAuth provider which is disabled on the Auth server. |
| `otp_disabled` | Sign in with OTPs (magic link, email OTP) is disabled. Check your sever's configuration. |
| `otp_expired` | OTP code for this sign-in has expired. Ask the user to sign in again. |
| `over_email_send_rate_limit` | Too many emails have been sent to this email address. Ask the user to wait a while before trying again. |
| `over_request_rate_limit` | Too many requests have been sent by this client (IP address). Ask the user to try again in a few minutes. Sometimes can indicate a bug in your application that mistakenly sends out too many requests (such as a badly written [`useEffect` React hook](https://react.dev/reference/react/useEffect)). |
| `over_sms_send_rate_limit` | Too many SMS messages have been sent to this phone number. Ask the user to wait a while before trying again. |
| `phone_exists` | Phone number already exists in the system. |
| `phone_not_confirmed` | Signing in is not allowed for this user as the phone number is not confirmed. |
| `phone_provider_disabled` | Signups are disabled for phone and password. |
| `provider_disabled` | OAuth provider is disabled for use. Check your server's configuration. |
| `provider_email_needs_verification` | Not all OAuth providers verify their user's email address. Supabase Auth requires emails to be verified, so this error is sent out when a verification email is sent after completing the OAuth flow. |
| `reauthentication_needed` | A user needs to reauthenticate to change their password. Ask the user to reauthenticate by calling the `supabase.auth.reauthenticate()` API. |
| `reauthentication_not_valid` | Verifying a reauthentication failed, the code is incorrect. Ask the user to enter a new code. |
| `refresh_token_not_found` | Session containing the refresh token not found. |
| `refresh_token_already_used` | Refresh token has been revoked and falls outside the refresh token reuse interval. See the [documentation on sessions](https://supabase.com/docs/guides/auth/sessions) for further information. |
| `request_timeout` | Processing the request took too long. Retry the request. |
| `same_password` | A user that is updating their password must use a different password than the one currently used. |
| `saml_assertion_no_email` | SAML assertion (user information) was received after sign in, but no email address was found in it, which is required. Check the provider's attribute mapping and/or configuration. |
| `saml_assertion_no_user_id` | SAML assertion (user information) was received after sign in, but a user ID (called NameID) was not found in it, which is required. Check the SAML identity provider's configuration. |
| `saml_entity_id_mismatch` | (Admin API.) Updating the SAML metadata for a SAML identity provider is not possible, as the entity ID in the update does not match the entity ID in the database. This is equivalent to creating a new identity provider, and you should do that instead. |
| `saml_idp_already_exists` | (Admin API.) Adding a SAML identity provider that is already added. |
| `saml_idp_not_found` | SAML identity provider not found. Most often returned after IdP-initiated sign-in with an unregistered SAML identity provider in Supabase Auth. |
| `saml_metadata_fetch_failed` | (Admin API.) Adding or updating a SAML provider failed as its metadata could not be fetched from the provided URL. |
| `saml_provider_disabled` | Using [Enterprise SSO with SAML 2.0](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml) is not enabled on the Auth server. |
| `saml_relay_state_expired` | SAML relay state is an object that tracks the progress of a `supabase.auth.signInWithSSO()` request. The SAML identity provider should respond after a fixed amount of time, after which this error is shown. Ask the user to sign in again. |
| `saml_relay_state_not_found` | SAML relay states are progressively cleaned up after they expire, which can cause this error. Ask the user to sign in again. |
| `session_expired` | Session to which the API request relates has expired. This can occur if an inactivity timeout is configured, or the session entry has exceeded the configured timebox value. See the [documentation on sessions](https://supabase.com/docs/guides/auth/sessions) for more information. |
| `session_not_found` | Session to which the API request relates no longer exists. This can occur if the user has signed out, or the session entry in the database was deleted in some other way. |
| `signup_disabled` | Sign ups (new account creation) are disabled on the server. |
| `single_identity_not_deletable` | Every user must have at least one identity attached to it, so deleting (unlinking) an identity is not allowed if it's the only one for the user. |
| `sms_send_failed` | Sending an SMS message failed. Check your SMS provider configuration. |
| `sso_domain_already_exists` | (Admin API.) Only one SSO domain can be registered per SSO identity provider. |
| `sso_provider_not_found` | SSO provider not found. Check the arguments in `supabase.auth.signInWithSSO()`. |
| `too_many_enrolled_mfa_factors` | A user can only have a fixed number of enrolled MFA factors. |
| `unexpected_audience` | (Deprecated feature not available via Supabase client libraries.) The request's `X-JWT-AUD` claim does not match the JWT's audience. |
| `unexpected_failure` | Auth service is degraded or a bug is present, without a specific reason. |
| `user_already_exists` | User with this information (email address, phone number) cannot be created again as it already exists. |
| `user_banned` | User to which the API request relates has a `banned_until` property which is still active. No further API requests should be attempted until this field is cleared. |
| `user_not_found` | User to which the API request relates no longer exists. |
| `user_sso_managed` | When a user comes from SSO, certain fields of the user cannot be updated (like `email`). |
| `validation_failed` | Provided parameters are not in the expected format. |
| `weak_password` | User is signing up or changing their password without meeting the password strength criteria. Use the `AuthWeakPasswordError` class to access more information about what they need to do to make the password pass. |

## Best practices for error handling [\#](https://supabase.com/docs/guides/auth/debugging/error-codes\#best-practices-for-error-handling)

- Always use `error.code` and `error.name` to identify errors, not string matching on error messages.
- Avoid relying solely on HTTP status codes, as they may change unexpectedly.

### Is this helpful?

NoYes

### On this page

[Auth error codes](https://supabase.com/docs/guides/auth/debugging/error-codes#auth-error-codes) [Error types](https://supabase.com/docs/guides/auth/debugging/error-codes#error-types) [HTTP status codes](https://supabase.com/docs/guides/auth/debugging/error-codes#http-status-codes) [403 Forbidden](https://supabase.com/docs/guides/auth/debugging/error-codes#https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403) [422 Unprocessable Entity](https://supabase.com/docs/guides/auth/debugging/error-codes#https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/422) [429 Too Many Requests](https://supabase.com/docs/guides/auth/debugging/error-codes#https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429) [500 Internal Server Error](https://supabase.com/docs/guides/auth/debugging/error-codes#https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/500) [501 Not Implemented](https://supabase.com/docs/guides/auth/debugging/error-codes#https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/501) [Auth error codes table](https://supabase.com/docs/guides/auth/debugging/error-codes#auth-error-codes-table) [Best practices for error handling](https://supabase.com/docs/guides/auth/debugging/error-codes#best-practices-for-error-handling)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_enterprise_sso_auth_sso_saml.md">
Auth

# Single Sign-On with SAML 2.0 for Projects

* * *

Looking for guides on how to use Single Sign-On with the Supabase dashboard? Head on over to [Enable SSO for Your Organization](https://supabase.com/docs/guides/platform/sso).

Supabase Auth supports enterprise-level Single Sign-On (SSO) for any identity providers compatible with the SAML 2.0 protocol. This is a non-exclusive list of supported identity providers:

- Google Workspaces (formerly known as G Suite)
- Okta, Auth0
- Microsoft Active Directory, Azure Active Directory, Microsoft Entra
- PingIdentity
- OneLogin

If you're having issues with identity provider software not on this list, [open a support ticket](https://supabase.com/dashboard/support/new).

## Prerequisites [\#](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml\#prerequisites)

This guide requires the use of the [Supabase CLI](https://supabase.com/docs/guides/cli). Make sure you're using version v1.46.4 or higher. You can use `supabase -v` to see the currently installed version.
You can use the `supabase sso` [subcommands](https://supabase.com/docs/reference/cli/supabase-sso) to manage your project's configuration.

SAML 2.0 support is disabled by default on Supabase projects. You can configure this on the [Auth Providers](https://supabase.com/dashboard/project/_/auth/providers) page on your project.

Note that SAML 2.0 support is offered on plans Pro and above. Check the [Pricing](https://supabase.com/pricing) page for more information.

## Terminology [\#](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml\#terminology)

The number of SAML and SSO acronyms can often be overwhelming. Here's a glossary which you can refer back to at any time:

- **Identity Provider**, **IdP**, or **IDP**
An identity provider is a service that manages user accounts at a company or organization. It can verify the identity of a user and exchange that information with your Supabase project and other applications. It acts as a single source of truth for user identities and access rights. Commonly used identity providers are: Microsoft Active Directory (Azure AD, Microsoft Entra), Okta, Google Workspaces (G Suite), PingIdentity, OneLogin, and many others. There are also self-hosted and on-prem versions of identity providers, and sometimes they are accessible only by having access to a company VPN or being in a specific building.
- **Service Provider**, **SP**
This is the software that is asking for user information from an identity provider. In Supabase, this is your project's Auth server.
- **Assertion**
An assertion is a statement issued by an identity provider that contains information about a user.
- **`EntityID`**
A globally unique ID (usually a URL) that identifies an Identity Provider or Service Provider across the world.
- **`NameID`**
A unique ID (usually an email address) that identifies a user at an Identity Provider.
- **Metadata**
An XML document that describes the features and configuration of an Identity Provider or Service Provider. It can be as a standalone document or as a URL. Usually (but not always) the `EntityID` is the URL at which you can access the Metadata.
- **Certificate**
Supabase Auth (the Service Provider) trusts assertions from an Identity Provider based on the signature attached to the assertion. The signature is verified according to the certificate present in the Metadata.
- **Assertion Consumer Service (ACS) URL**
This is one of the most important SAML URLs. It is the URL where Supabase Auth will accept assertions from an identity provider. Basically, once the identity provider verifies the user's identity it will redirect to this URL and the redirect request will contain the assertion.
- **Binding (Redirect, POST, or Artifact)**
This is a description of the way an identity provider communicates with Supabase Auth. When using the Redirect binding, the communication occurs using HTTP 301 redirects. When it's `POST`, it's using `POST` requests sent with `<form>` elements on a page. When using Artifact, it's using a more secure exchange over a Redirect or `POST`.
- **`RelayState`**
State used by Supabase Auth to hold information about a request to verify the identity of a user.

## Important SAML 2.0 information [\#](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml\#important-saml-20-information)

Below is information about your project's SAML 2.0 configuration which you can share with the company or organization that you're trying to on-board.

| Name | Value |
| --- | --- |
| `EntityID` | `https://<project>.supabase.co/auth/v1/sso/saml/metadata` |
| Metadata URL | `https://<project>.supabase.co/auth/v1/sso/saml/metadata` |
| Metadata URL<br>(download) | `https://<project>.supabase.co/auth/v1/sso/saml/metadata?download=true` |
| ACS URL | `https://<project>.supabase.co/auth/v1/sso/saml/acs` |
| SLO URL | `https://<project>.supabase.co/auth/v1/sso/slo` |
| `NameID` | Required `emailAddress` or `persistent` |

Note that SLO (Single Logout) is not supported at this time with Supabase Auth as it is a rarely supported feature by identity providers. However, the URL is registered and advertised for when this does become available.

Append `?download=true` to the Metadata URL to download the Metadata XML file. This is useful in cases where the identity provider requires a file.

Alternatively, you can use the `supabase sso info --project-ref <your-project>` [command](https://supabase.com/docs/reference/cli/supabase-sso-info) to get setup information for your project.

### User accounts and identities [\#](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml\#user-accounts-and-identities)

User accounts and identities created via SSO differ from regular (email, phone, password, social login...) accounts in these ways:

- **No automatic linking.**
Each user account verified using a SSO identity provider will not be automatically linked to existing user accounts in the system. That is, if a user `valid.email@supabase.io` had signed up with a password, and then uses their company SSO login with your project, there will be two `valid.email@supabase.io` user accounts in the system.
- **Emails are not necessarily unique.**
Given the behavior with no automatic linking, email addresses are no longer a unique identifier for a user account. Always use the user's UUID to correctly reference user accounts.
- **Sessions may have a maximum duration.**
Depending on the configuration of the identity provider, a login session established with SSO may forcibly log out a user after a certain period of time.

### Row Level Security [\#](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml\#row-level-security)

You can use information about the SSO identity provider in Row Level Security policies.

Here are some commonly used statements to extract SSO related information from the user's JWT:

- `auth.jwt()#>>'{amr,0,method}'`
Returns the name of the last method used to verify the identity of this user. With SAML SSO this is `sso/saml`.
- `auth.jwt()#>>'{amr,0,provider}'`
Returns the UUID of the SSO identity provider used by the user to sign-in.
- `auth.jwt()#>>'{user_metadata,iss}'`
Returns the identity provider's SAML 2.0 `EntityID`

If you use [Multi-Factor Authentication](https://supabase.com/docs/guides/auth/auth-mfa) with SSO, the `amr` array may have a different method at index `0`!

A common use case with SSO is to use the UUID of the identity provider as the identifier for the organization the user belongs to -- frequently known as a tenant. By associating the identity provider's UUID with your tenants, you can use restrictive RLS policies to scope down actions and data that a user is able to access.

For example, let's say you have a table like:

`
create table organization_settings (
  -- the organization's unique ID
id uuid not null primary key,
  -- the organization's SSO identity provider
sso_provider_id uuid unique,
  -- name of the organization
name text,
  -- billing plan (paid, Free, Enterprise)
billing_plan text
);
`

You can use the information present in the user's JWT to scope down which rows from this table the user can see, without doing any additional user management:

`
CREATE POLICY "View organization settings."
ON organization_settings
AS RESTRICTIVE
USING (
    sso_provider_id = (select auth.jwt()#>>'{amr,0,provider}')
);
`

## Managing SAML 2.0 connections [\#](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml\#managing-saml-20-connections)

Once you've enabled SAML 2.0 support on your project via the [Auth Providers](https://supabase.com/dashboard/project/_/auth/providers) page in the dashboard, you can use the [Supabase CLI](https://supabase.com/docs/reference/cli/supabase-sso) to add, update, remove and view information about identity providers.

### Add a connection [\#](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml\#add-a-connection)

To establish a connection to a SAML 2.0 Identity Provider (IdP) you will need:

- A SAML 2.0 Metadata XML file, or a SAML 2.0 Metadata URL pointing to an XML file
- (Optional) Email domains that the organization's IdP uses
- (Optional) Attribute mappings between the user properties of the IdP and the claims stored by Supabase Auth

You should obtain the SAML 2.0 Metadata XML file or URL from the organization whose IdP you wish to connect. Most SAML 2.0 Identity Providers support the Metadata URL standard, and we recommend using a URL if this is available.

Commonly used SAML 2.0 Identity Providers that support Metadata URLs:

- Okta
- Azure AD (Microsoft Entra)
- PingIdentity

Commonly used SAML 2.0 Identity Providers that only support Metadata XML files:

- Google Workspaces (G Suite)
- Any self-hosted or on-prem identity provider behind a VPN

Once you've obtained the SAML 2.0 Metadata XML file or URL you can [establish a connection](https://supabase.com/docs/reference/cli/supabase-sso-add) with your project's Supabase Auth server by running:

`
supabase sso add --type saml --project-ref <your-project> \
  --metadata-url 'https://company.com/idp/saml/metadata' \
  --domains company.com
`

If you wish to use a Metadata XML file instead, you can use:

`
supabase sso add --type saml --project-ref <your-project> \
  --metadata-file /path/to/saml/metadata.xml \
  --domains company.com
`

This command will register a new identity provider with your project's Auth server. When successful, you will see the details of the provider such as it's SAML information and registered domains.

Note that only persons with write access to the project can register, update or remove identity providers.

Once you've added an identity provider, users who have access to it can sign in to your application. With SAML 2.0 there are two ways that users can sign in to your project:

- By signing-in from your application's user interface, commonly known as **SP (Service Provider) Initiated Flow**
- By clicking on an icon in the application menu on the company intranet or identity provider page, commonly known as **Identity Provider Initiated (IdP) Flow**

To initiate a sign-in request from your application's user interface (i.e. the SP Initiated Flow), you can use:

JavaScriptDartSwiftKotlin

`
supabase.auth.signInWithSSO({
domain: 'company.com',
})
`

Calling [`signInWithSSO`](https://supabase.com/docs/reference/javascript/auth-signinwithsso) starts the sign-in process using the identity provider registered for the `company.com` domain name. It is not required that identity providers be assigned one or multiple domain names, in which case you can use the provider's unique ID instead.

### Understanding attribute mappings [\#](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml\#understanding-attribute-mappings)

When a user signs in using the SAML 2.0 Single Sign-On protocol, an XML document called the SAML Assertion is exchanged between the identity provider and Supabase Auth.

This assertion contains information about the user's identity and other authentication information, such as:

- Unique ID of the user (called `NameID` in SAML)
- Email address
- Name of the user
- Department or organization
- Other attributes present in the users directory managed by the identity provider

With exception of the unique user ID, SAML does not require any other attributes in the assertion. Identity providers can be configured so that only select user information is shared with your project.

Your project can be configured to recognize these attributes and map them into your project's database using a JSON structure. This process is called attribute mapping, and varies according to the configuration of the identity provider.

For example, the following JSON structure configures attribute mapping for the `email` and `first_name` user identity properties.

`
{
"keys": {
    "email": {
      "name": "mail"
    },
    "first_name": {
      "name": "givenName"
    }
}
}
`

When creating or updating an identity provider with the [Supabase CLI](https://supabase.com/docs/guides/cli) you can include this JSON as a file with the `--attribute-mapping-file /path/to/attribute/mapping.json` flag.

For example, to change the attribute mappings to an existing provider you can use:

`
supabase sso update <provider-uuid> --project-ref <your-project> \
  --attribute-mapping-file /path/to/attribute/mapping.json
`

Given a SAML 2.0 assertion that includes these attributes:

`
<saml:AttributeStatement>
<!-- will be mapped to the email key -->
<saml:Attribute
    Name="mail"
    NameFormat="urn:oasis:names:tc:SAML:2.0:attrname-format:basic"
    >
    <saml:AttributeValue xsi:type="xs:string">
      valid.email@supabase.io
    </saml:AttributeValue>
</saml:Attribute>
<!-- will be mapped to the first_name key -->
<saml:Attribute
    Name="givenName"
    NameFormat="urn:oasis:names:tc:SAML:2.0:attrname-format:basic"
    >
    <saml:AttributeValue xsi:type="xs:string">
      Jane Doe
    </saml:AttributeValue>
</saml:Attribute>
</saml:AttributeStatement>
`

Will result in the following claims in the user's identity in the database and JWT:

`
{
"email": "valid.email@supabase.io",
"custom_claims": {
    "first_name": "Jane Doe"
}
}
`

Supabase Auth does not require specifying attribute mappings if you only need access to the user's email. It will attempt to find an email attribute specified in the assertion. All other properties will not be automatically included, and it is those you need to map.

At this time it is not possible to have users without an email address, so SAML assertions without one will be rejected.

Most SAML 2.0 identity providers use Lightweight Directory Access Protocol (LDAP) attribute names. However, due to their variability and complexity operators of identity providers are able to customize both the `Name` and attribute value that is sent to Supabase Auth in an assertion. Refer to the identity provider's documentation and contact the operator for details on what attributes are mapped for your project.

**Accessing the stored attributes**

The stored attributes, once mapped, show up in the access token (a JWT) of the user. If you need to look these values up in the database, you can find them in the `auth.identities` table under the `identity_data` JSON column. Identities created for SSO providers have `sso:<uuid-of-provider>` in the `provider` column, while `id` contains the unique `NameID` of the user account.

Furthermore, you can find the same identity data under `raw_app_meta_data` inside `auth.users`.

### Remove a connection [\#](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml\#remove-a-connection)

Once a connection to an identity provider is established, you can [remove it](https://supabase.com/docs/reference/cli/supabase-sso-remove) by running:

`
supabase sso remove <provider-id> --project-ref <your-project>
`

If successful, the details of the removed identity provider will be shown. All user accounts from that identity provider will be immediately logged out. User information will remain in the system, but it will no longer be possible for any of those accounts to be accessed in the future, even if you add the connection again.

If you need to reassign those user accounts to another identity provider, [open a support ticket](https://supabase.com/dashboard/support/new).
A [list of all](https://supabase.com/docs/reference/cli/supabase-sso-list) registered identity providers can be displayed by running:

`
supabase sso list --project-ref <your-project>
`

### Update a connection [\#](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml\#update-a-connection)

You may wish to update settings about a connection to a SAML 2.0 identity provider.

Commonly this is necessary when:

- Cryptographic keys are rotated or have expired
- Metadata URL has changed, but is the same identity provider
- Other SAML 2.0 Metadata attributes have changed, but it is still the same identity provider
- You are updating the domains or attribute mapping

You can use this command to [update](https://supabase.com/docs/reference/cli/supabase-sso-update) the configuration of an identity provider:

`
supabase sso update <provider-id> --project-ref <your-project>
`

Use `--help` to see all available flags.

It is not possible to change the unique SAML identifier of the identity provider, known as `EntityID`. Everything else can be updated. If the SAML `EntityID` of your identity provider has changed, it is regarded as a new identity provider and you will have to register it like a new connection.

### Retrieving information about a connection [\#](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml\#retrieving-information-about-a-connection)

You can always obtain a [list](https://supabase.com/docs/reference/cli/supabase-sso-list) of all registered providers using:

`
supabase sso list --project-ref <your-project>
`

This list will only include basic information about each provider. To see [all of the information](https://supabase.com/docs/reference/cli/supabase-sso-show) about a provider you can use:

`
supabase sso show <provider-id> --project-ref <your-project>
`

You can use the `-o json` flag to output the information as JSON, should you need to. Other formats may be supported, use `--help` to see all available options.

## Pricing [\#](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml\#pricing)

$0.015 per SSO MAU. You are only charged for usage exceeding your subscription plan's quota.

For a detailed breakdown of how charges are calculated, refer to [Manage Monthly Active SSO Users usage](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-sso).

## Frequently asked questions [\#](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml\#frequently-asked-questions)

### Publishing your application to an identity provider's marketplace [\#](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml\#publishing-your-application-to-an-identity-providers-marketplace)

Many cloud-based identity providers offer a marketplace where you can register your application for easy on-boarding with customers. When you use Supabase Auth's SAML 2.0 support you can register your project in any one of these marketplaces.

Refer to the relevant documentation for each cloud-based identity provider on how you can do this. Some common marketplaces are:

- [Okta Integration Network](https://developer.okta.com/docs/guides/build-sso-integration/saml2/main/)
- [Azure Active Directory App Gallery](https://learn.microsoft.com/en-us/azure/active-directory-b2c/publish-app-to-azure-ad-app-gallery)
- [Google Workspaces Pre-integrated SAML apps catalog](https://support.google.com/a/table/9217027)

### Why do some users get: SAML assertion does not contain email address? [\#](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml\#why-do-some-users-get-saml-assertion-does-not-contain-email-address)

Identity providers do not have to send back and email address for the user, though they often do. Supabase Auth requires that an email address is present.

The following list of commonly used SAML attribute names is inspected, in order of appearance, to discover the email address in the assertion:

- `urn:oid:0.9.2342.19200300.100.1.3`
- `http://schemas.xmlsoap.org/ws/2005/05/identity/claims/emailaddress`
- `http://schemas.xmlsoap.org/claims/EmailAddress`
- `mail`
- `email`

Finally if there is no such attribute, it will use the SAML `NameID` value but only if the format is advertised as `urn:oasis:names:tc:SAML:1.1:nameid-format:emailAddress`.

Should you run into this problem, it is most likely a misconfiguration issue **on the identity provider side.** Instruct your contact at the company to map the user's email address to one of the above listed attribute names, typically `email`.

### Accessing the private key used for SAML in your project [\#](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml\#accessing-the-private-key-used-for-saml-in-your-project)

At this time it is not possible to extract the RSA private key used by your project's Supabase Auth server. This is done to keep the private key as secure as possible, given that SAML does not offer an easy way to rotate keys without disrupting service. (Use a SAML 2.0 Metadata URL whenever possible for this reason!)

If you really need access to the key, [open a support ticket](https://supabase.com/dashboard/support/new) and we'll try to support you as best as possible.

### Is multi-tenant SSO with SAML supported? [\#](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml\#is-multi-tenant-sso-with-saml-supported)

Yes, Supabase supports multi-tenant Single Sign-On (SSO) using SAML 2.0. While the dashboard displays only one SAML field, you can set up multiple SAML connections using the Supabase CLI.
Each connection is assigned a unique `sso_provider_id`, which is included in the user's JWT and can be used in Row Level Security (RLS) policies. You can configure custom attribute mappings for each connection to include tenant-specific information, such as roles.
This setup allows you to implement multi-tenant SSO for multiple clients or organizations within a single application. For example, if you have an app with multiple clients using different Azure Active Directories, you can create separate SAML connections for each and use the `sso_provider_id` to manage access and apply appropriate security policies.

### Is multi-subdomain SSO with SAML supported? [\#](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml\#is-multi-subdomain-sso-with-saml-supported)

Yes, also referred to as [cross-origin authentication within the same site](https://web.dev/articles/same-site-same-origin). To redirect to a URL other than the [Site URL](https://supabase.com/docs/guides/auth/redirect-urls), following the SAML response from the IdP, the `redirectTo` option can be added to [`signInWithSSO`](https://supabase.com/docs/reference/javascript/auth-signinwithsso).

``
const { data, error } = await supabase.auth.signInWithSSO({
    domain: 'company.com'
      options: {
        redirectTo: `https://app.company.com/callback`,
      },
})
``

When redirecting to a URL other than the Site URL, a `/callback` endpoint is necessary to process the auth code from the IdP and exchange it for a session. This assumes the [Supabase SSR client](https://supabase.com/docs/guides/auth/server-side/creating-a-client) has already been configured.

SvelteKit

`
import { error, redirect } from '@sveltejs/kit'
import type { RequestHandler } from './$types'
export const GET: RequestHandler = async ({ url, locals }) => {
const code = url.searchParams.get('code')
if (!code) {
    error(400, 'No authorization code provided')
}
const { error: tokenExchangeError } = await locals.supabase.auth.exchangeCodeForSession(code)
if (tokenExchangeError) {
    error(400, 'Failed to exchange authorization code for session')
}
redirect(303, '/')
}
`

### Is this helpful?

NoYes

### On this page

[Prerequisites](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml#prerequisites) [Terminology](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml#terminology) [Important SAML 2.0 information](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml#important-saml-20-information) [User accounts and identities](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml#user-accounts-and-identities) [Row Level Security](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml#row-level-security) [Managing SAML 2.0 connections](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml#managing-saml-20-connections) [Add a connection](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml#add-a-connection) [Understanding attribute mappings](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml#understanding-attribute-mappings) [Remove a connection](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml#remove-a-connection) [Update a connection](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml#update-a-connection) [Retrieving information about a connection](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml#retrieving-information-about-a-connection) [Pricing](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml#pricing) [Frequently asked questions](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml#frequently-asked-questions) [Publishing your application to an identity provider's marketplace](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml#publishing-your-application-to-an-identity-providers-marketplace) [Why do some users get: SAML assertion does not contain email address?](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml#why-do-some-users-get-saml-assertion-does-not-contain-email-address) [Accessing the private key used for SAML in your project](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml#accessing-the-private-key-used-for-saml-in-your-project) [Is multi-tenant SSO with SAML supported?](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml#is-multi-tenant-sso-with-saml-supported) [Is multi-subdomain SSO with SAML supported?](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml#is-multi-subdomain-sso-with-saml-supported)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_enterprise_sso.md">
Auth

# Enterprise Single Sign-On

* * *

Supabase Auth supports building enterprise applications that require Single Sign-On (SSO) authentication [with SAML 2.0](https://supabase.com/docs/guides/auth/sso/auth-sso-saml).

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_general_configuration.md">
Auth

# General configuration

## General configuration options for Supabase Auth

* * *

This section covers the [general configuration options](https://supabase.com/dashboard/project/_/settings/auth) for Supabase Auth. If you are looking for another type of configuration, you may be interested in one of the following sections:

- [Provider-specific configuration](https://supabase.com/dashboard/project/_/auth/providers)
- [Rate limits](https://supabase.com/dashboard/project/_/auth/rate-limits)
- [Email Templates](https://supabase.com/dashboard/project/_/auth/templates)
- [Redirect URLs](https://supabase.com/dashboard/project/_/auth/url-configuration)
- [Auth Hooks](https://supabase.com/dashboard/project/_/auth/hooks)

Supabase Auth provides these [general configuration options](https://supabase.com/dashboard/project/_/settings/auth) to control user access to your application:

- **Allow new users to sign up**: Users will be able to sign up. If this config is disabled, only existing users can sign in.

- **Confirm Email**: Users will need to confirm their email address before signing in for the first time.
  - Having **Confirm Email** disabled assumes that the user's email does not need to be verified in order to login and implicitly confirms the user's email in the database.
  - This option can be found in the email provider under the provider-specific configuration.
- **Allow anonymous sign-ins**: Allow anonymous users to be created.

- **Allow manual linking**: Allow users to link their accounts manually.


### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_identities.md">
Auth

# Identities

* * *

An identity is an authentication method associated with a user. Supabase Auth supports the following types of identity:

- Email
- Phone
- OAuth
- SAML

A user can have more than one identity. Anonymous users have no identity until they link an identity to their user.

## The user identity object [\#](https://supabase.com/docs/guides/auth/identities\#the-user-identity-object)

The user identity object contains the following attributes:

| Attributes | Type | Description |
| --- | --- | --- |
| provider\_id | `string` | The provider id returned by the provider. If the provider is an OAuth provider, the id refers to the user's account with the OAuth provider. If the provider is `email` or `phone`, the id is the user's id from the `auth.users` table. |
| user\_id | `string` | The user's id that the identity is linked to. |
| identity\_data | `object` | The identity metadata. For OAuth and SAML identities, this contains information about the user from the provider. |
| id | `string` | The unique id of the identity. |
| provider | `string` | The provider name. |
| email | `string` | The email is a generated column that references the optional email property in the identity\_data |
| created\_at | `string` | The timestamp that the identity was created. |
| last\_sign\_in\_at | `string` | The timestamp that the identity was last used to sign in. |
| updated\_at | `string` | The timestamp that the identity was last updated. |

### Is this helpful?

NoYes

### On this page

[The user identity object](https://supabase.com/docs/guides/auth/identities#the-user-identity-object)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_jwts.md">
Auth

# JWTs

## JSON Web Tokens

* * *

A [JSON Web Token](https://jwt.io/introduction) is a type of data structure, represented as a string, that usually contains identity and authorization information about a user. It encodes information about its lifetime and is signed with a cryptographic key to make it tamper-resistant.

Supabase Access Tokens are JWTs. The JWT is sent along with every request to Supabase services. By verifying the token and inspecting the included claims, you can allow or deny access to resources. [Row Level Security](https://supabase.com/docs/guides/database/postgres/row-level-security) policies are based on the information present in JWTs.

## Encoding and signing JWTs [\#](https://supabase.com/docs/guides/auth/jwts\#encoding-and-signing-jwts)

JWTs are encoded and signed as follows.

The JSON object starts out looking something like this:

`
{
"sub": "0001",
"name": "Sam Vimes",
"iat": 1516239022,
"exp": 1518239022
}
`

`sub` is the "subject", which is usually the UUID of the user. `name` is self-explanatory, and `iat` is the Unix timestamp at which the token was created. Many JWTs will also have an `exp`, which is the date at which the token is set to expire and can no longer be used. These are some of the standard fields you may find in a JWT, but you can pretty much store whatever you want in there, for example:

`
{
"sub": "0002",
"name": "Vra Hrabnkov",
"iat": 1516239022,
"exp": 1518239022,
"theme": {
      "primary" : "#D80C14",
      "secondary" : "#FFFFFF"
}
}
`

Just note that the more data you store in your token, the longer the encoded string will be.

When we want to send the JWT to the user, we first encode the data using an algorithm such as `HS256`. There are many libraries (and several different algorithms) that can be used to do this encoding/decoding, such as [`jsonwebtoken`](https://www.npmjs.com/package/jsonwebtoken). The signing is as simple as:

`
// from https://replit.com/@awalias/jsonwebtokens#index.js
let token = jwt.sign({ name: 'Sam Vimes' }, 'some-secret')
`

And the resulting string will look like this:

`
eyJhbGciOiJIUzI1NiJ9
.eyJzdWIiOiIwMDAxIiwibmFtZSI6IlNhbSBWaW1lcyIsImlhdCI6MTUxNjIzOTAyMiwiZXhwIjoxNTE4MjM5MDIyfQ
.zMcHjKlkGhuVsiPIkyAkB2rjXzyzJsMMgpvEGvGtjvA
`

You will notice that the string is actually made up of three components:

The first segment `eyJhbGciOiJIUzI1NiJ9` is known as the "header", and when decoded just tells us which algorithm was used to do the encoding:

`
{
"alg": "HS256"
}
`

The second segment `eyJzdWIiOiIwMDAxIiwibmFtZSI6IlNhbSBWaW1lcyIsImlhdCI6MTUxNjIzOTAyMiwiZXhwIjoxNTE4MjM5MDIyfQ` contains our original payload:

`
{
"sub": "0001",
"name": "Sam Vimes",
"iat": 1516239022,
"exp": 1518239022
}
`

The last segment `zMcHjKlkGhuVsiPIkyAkB2rjXzyzJsMMgpvEGvGtjvA` is the signature itself, which is the part used by the website or service provider to verify that a token sent by some user is legitimate. It is produced in the first instance by running the cryptographic function HS256 on the following input:

`
HMACSHA256(
base64UrlEncode(header) + "." +
base64UrlEncode(payload)
<jwt_secret>
)
`

You can test out minting your own tokens on [https://jwt.io](https://jwt.io/).

It is important to note that anyone who possesses the `jwt_secret` here can create new tokens, and also verify existing ones. More advanced JWT algorithms use two secrets: one for the creation of tokens, and a separate one to verify the validity of signed tokens.

You might wonder why JWTs are so popular all of a sudden. The answer is that with the mass adoption of microservice architecture, we were in a situation where several distinct microservices (APIs, websites, servers, etc.) want to validate that a user is who they say they are, or are in other words a "logged-in" user. Traditional session tokens are no use here, since they would require each microservice to either maintain a record of currently valid session tokens or to query a central database each time a user wants to access a resource in order to check the validity of the session token  very inefficient indeed. JWT-based auth in this sense is decentralized, since anyone with the `jwt_secret` can verify a token without needing access to a centralized database.

Note: One downside of JWTs is that they are not easily voidable, unlike session tokens. If a JWT is leaked to a malicious actor, they will be able to redeem it anywhere until the expiry date is reached  unless of course the system owner updates the `jwt_secret` (which will of course invalidate _everyone's_ existing tokens).

## JWTs in Supabase [\#](https://supabase.com/docs/guides/auth/jwts\#jwts-in-supabase)

In Supabase we issue JWTs for three different purposes:

1. `anon key`: This key is used to bypass the Supabase API gateway and can be used in your client-side code.
2. `service role key`: This key has super admin rights and can bypass your Row Level Security. Do not put it in your client-side code. Keep it private.
3. `user specific jwts`: These are tokens we issue to users who log into your project/service/website. It's the modern equivalent of a session token, and can be used by a user to access content or permissions specific to them.

The first token here, the `anon key` token, is for developers to send along with their API requests whenever they want to interact with their Supabase database.

Let's say you want to read the names of all the rows in a table `colors`. We would make a request like:

`
curl 'https://xscduanzzfseqszwzhcy.supabase.co/rest/v1/colors?select=name' \
-H "apikey: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyb2xlIjoiYW5vbiIsImlhdCI6MTYxNDIwNTE3NCwiZXhwIjoxOTI5NzgxMTc0fQ.-NBR1WnZyQGpRLdXJfgfpszoZ0EeE6KHatJsDPLIX8c"
`

If we put this token into [https://jwt.io](https://jwt.io/), we see it decodes to:

`
{
"role": "anon",
"iss": "supabase",
"iat": 1614205174,
"exp": 1929781174
}
`

This JWT is signed by a `jwt_secret` specific to the developer's Supabase token (you can find this secret alongside this encoded "anon key" on your Dashboard under Settings > API page) and is required to get past the Supabase API gateway and access the developer's project.

The idea with this particular key is that it's safe to put into your client, meaning it's okay if your end users see this key  but _only_ if you first enable Row Level Security.

The second key, `service role key`, should only ever be used on one of your own servers or environments, and should never be shared with end users. You might use this token to do things like make batch inserts of data.

The `user access token` is the JWT issued when you call for example:

`
supabase.auth.signIn({
email: 'valid.email@supabase.io',
password: 'They_Live_1988!',
})
`

This token should be passed in addition to the `apikey` header as an `Authorization Bearer` header like:

`
curl 'https://xscduanzzfseqszwzhcy.supabase.co/rest/v1/colors?select=name' \
-H "apikey: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyb2xlIjoiYW5vbiIsImlhdCI6MTYxNDIwNTE3NCwiZXhwIjoxOTI5NzgxMTc0fQ.-NBR1WnZyQGpRLdXJfgfpszoZ0EeE6KHatJsDPLIX8c" \
-H "Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJhdXRoZW50aWNhdGVkIiwiZXhwIjoxNjE1ODI0Mzg4LCJzdWIiOiIwMzM0NzQ0YS1mMmEyLTRhYmEtOGM4YS02ZTc0OGY2MmExNzIiLCJlbWFpbCI6InNvbWVvbmVAZW1haWwuY29tIiwiYXBwX21ldGFkYXRhIjp7InByb3ZpZGVyIjoiZW1haWwifSwidXNlcl9tZXRhZGF0YSI6bnVsbCwicm9sZSI6ImF1dGhlbnRpY2F0ZWQifQ.I-_oSsJamtinGxniPETBf-ezAUwDW2sY9bJIThvdX9s"
`

You'll notice that this token is quite a bit longer, since it contains information specific to the user such as:

`
{
"aud": "authenticated",
"exp": 1615824388,
"sub": "0334744a-f2a2-4aba-8c8a-6e748f62a172",
"email": "valid.email@supabase.io",
"app_metadata": {
    "provider": "email"
},
"user_metadata": null,
"role": "authenticated"
}
`

If using the service role key, you'll need to pass it into both the `apikey` and `authorization` headers (again, only do this from a secure environment such as your own server):

`
curl "$YOUR_PROJECT_URL/rest/v1/colors?select=name" \
 -H "apikey: $YOUR_SERVICE_ROLE_KEY" \
 -H "authorization: Bearer $YOUR_SERVICE_ROLE_KEY"
`

Now that you understand what JWTs are and where they're used in Supabase, you can explore how to use them in combination with Row Level Security to start restricting access to certain tables, rows, and columns in your Postgres database.

## Resources [\#](https://supabase.com/docs/guides/auth/jwts\#resources)

- JWT debugger: [https://jwt.io/](https://jwt.io/)

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2Fv3Exg5YpJvE%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Encoding and signing JWTs](https://supabase.com/docs/guides/auth/jwts#encoding-and-signing-jwts) [JWTs in Supabase](https://supabase.com/docs/guides/auth/jwts#jwts-in-supabase) [Resources](https://supabase.com/docs/guides/auth/jwts#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_managing_user_data.md">
Auth

# User Management

## View, delete, and export user information.

* * *

You can view your users on the [Users page](https://supabase.com/dashboard/project/_/auth/users) of the Dashboard. You can also view the contents of the Auth schema in the [Table Editor](https://supabase.com/dashboard/project/_/editor).

## Accessing user data via API [\#](https://supabase.com/docs/guides/auth/managing-user-data\#accessing-user-data-via-api)

For security, the Auth schema is not exposed in the auto-generated API. If you want to access users data via the API, you can create your own user tables in the `public` schema.

Make sure to protect the table by enabling [Row Level Security](https://supabase.com/docs/guides/database/postgres/row-level-security). Reference the `auth.users` table to ensure data integrity. Specify `on delete cascade` in the reference. For example, a `public.profiles` table might look like this:

`
create table public.profiles (
id uuid not null references auth.users on delete cascade,
first_name text,
last_name text,
primary key (id)
);
alter table public.profiles enable row level security;
`

Only use primary keys as [foreign key references](https://www.postgresql.org/docs/current/tutorial-fk.html) for schemas and tables like `auth.users` which are managed by Supabase. Postgres lets you specify a foreign key reference for columns backed by a unique index (not necessarily primary keys).

Primary keys are **guaranteed not to change**. Columns, indices, constraints or other database objects managed by Supabase **may change at any time** and you should be careful when referencing them directly.

To update your `public.profiles` table every time a user signs up, set up a trigger. If the trigger fails, it could block signups, so test your code thoroughly.

`
-- inserts a row into public.profiles
create function public.handle_new_user()
returns trigger
language plpgsql
security definer set search_path = ''
as $$
begin
insert into public.profiles (id, first_name, last_name)
values (new.id, new.raw_user_meta_data ->> 'first_name', new.raw_user_meta_data ->> 'last_name');
return new;
end;
$$;
-- trigger the function every time a user is created
create trigger on_auth_user_created
after insert on auth.users
for each row execute procedure public.handle_new_user();
`

## Adding and retrieving user metadata [\#](https://supabase.com/docs/guides/auth/managing-user-data\#adding-and-retrieving-user-metadata)

You can assign metadata to users on sign up:

JavaScriptDartSwiftKotlin

`
const { data, error } = await supabase.auth.signUp({
email: 'valid.email@supabase.io',
password: 'example-password',
options: {
    data: {
      first_name: 'John',
      age: 27,
    },
},
})
`

User metadata is stored on the `raw_user_meta_data` column of the `auth.users` table. To view the metadata:

JavaScriptDartSwiftKotlin

`
const {
data: { user },
} = await supabase.auth.getUser()
let metadata = user.user_metadata
`

## Deleting users [\#](https://supabase.com/docs/guides/auth/managing-user-data\#deleting-users)

You may delete users directly or via the management console at Authentication > Users. Note that deleting a user from the `auth.users` table does not automatically sign out a user. As Supabase makes use of JSON Web Tokens (JWT), a user's JWT will remain "valid" until it has expired. Should you wish to immediately revoke access for a user, do consider making use of a Row Level Security policy as described below.

You cannot delete a user if they are the owner of any objects in Supabase Storage.

You will encounter an error when you try to delete an Auth user that owns any Storage objects. If this happens, try deleting all the objects for that user, or reassign ownership to another user.

## Exporting users [\#](https://supabase.com/docs/guides/auth/managing-user-data\#exporting-users)

As Supabase is built on top of Postgres, you can query the `auth.users` and `auth.identities` table via the `SQL Editor` tab to extract all users:

`
select * from auth.users;
`

You can then export the results as CSV.

### Is this helpful?

NoYes

### On this page

[Accessing user data via API](https://supabase.com/docs/guides/auth/managing-user-data#accessing-user-data-via-api) [Adding and retrieving user metadata](https://supabase.com/docs/guides/auth/managing-user-data#adding-and-retrieving-user-metadata) [Deleting users](https://supabase.com/docs/guides/auth/managing-user-data#deleting-users) [Exporting users](https://supabase.com/docs/guides/auth/managing-user-data#exporting-users)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_native_mobile_deep_linking.md">
Auth

# Native Mobile Deep Linking

## Set up Deep Linking for mobile applications.

* * *

Many Auth methods involve a redirect to your app. For example:

- Signup confirmation emails, Magic Link signins, and password reset emails contain a link that redirects to your app.
- In OAuth signins, an automatic redirect occurs to your app.

With Deep Linking, you can configure this redirect to open a specific page. This is necessary if, for example, you need to display a form for [password reset](https://supabase.com/docs/guides/auth/passwords#resetting-a-users-password-forgot-password), or to manually exchange a token hash.

## Setting up deep linking [\#](https://supabase.com/docs/guides/auth/native-mobile-deep-linking\#setting-up-deep-linking)

Expo React NativeFlutterSwiftAndroid Kotlin

To link to your development build or standalone app, you need to specify a custom URL scheme for your app. You can register a scheme in your app config (app.json, app.config.js) by adding a string under the `scheme` key:

`
{
"expo": {
    "scheme": "com.supabase"
}
}
`

In your project's [auth settings](https://supabase.com/dashboard/project/_/auth/url-configuration) add the redirect URL, e.g. `com.supabase://**`.

Finally, implement the OAuth and linking handlers. See the [supabase-js reference](https://supabase.com/docs/reference/javascript/initializing?example=react-native-options-async-storage) for instructions on initializing the supabase-js client in React Native.

./components/Auth.tsx

`
import { Button } from "react-native";
import { makeRedirectUri } from "expo-auth-session";
import * as QueryParams from "expo-auth-session/build/QueryParams";
import * as WebBrowser from "expo-web-browser";
import * as Linking from "expo-linking";
import { supabase } from "app/utils/supabase";
WebBrowser.maybeCompleteAuthSession(); // required for web only
const redirectTo = makeRedirectUri();
const createSessionFromUrl = async (url: string) => {
const { params, errorCode } = QueryParams.getQueryParams(url);
if (errorCode) throw new Error(errorCode);
const { access_token, refresh_token } = params;
if (!access_token) return;
const { data, error } = await supabase.auth.setSession({
    access_token,
    refresh_token,
});
if (error) throw error;
return data.session;
};
const performOAuth = async () => {
const { data, error } = await supabase.auth.signInWithOAuth({
    provider: "github",
    options: {
      redirectTo,
      skipBrowserRedirect: true,
    },
});
if (error) throw error;
const res = await WebBrowser.openAuthSessionAsync(
    data?.url ?? "",
    redirectTo
);
if (res.type === "success") {
    const { url } = res;
    await createSessionFromUrl(url);
}
};
const sendMagicLink = async () => {
const { error } = await supabase.auth.signInWithOtp({
    email: "valid.email@supabase.io",
    options: {
      emailRedirectTo: redirectTo,
    },
});
if (error) throw error;
// Email sent.
};
export default function Auth() {
// Handle linking into app from email app.
const url = Linking.useURL();
if (url) createSessionFromUrl(url);
return (
    <>
      <Button onPress={performOAuth} title="Sign in with Github" />
      <Button onPress={sendMagicLink} title="Send Magic Link" />
    </>
);
}
`

For the best user experience it is recommended to use universal links which require a more elaborate setup. You can find the detailed setup instructions in the [Expo docs](https://docs.expo.dev/guides/deep-linking/).

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2F8TZ6O1C8ujE%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Setting up deep linking](https://supabase.com/docs/guides/auth/native-mobile-deep-linking#setting-up-deep-linking)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_password_security.md">
Auth

# Password security

## Help your users to protect their password security

* * *

A password is more secure if it is harder to guess or brute-force. In theory, a password is harder to guess if it is longer. It is also harder to guess if it uses a larger set of characters (for example, digits, lowercase and uppercase letters, and symbols).

This table shows the _minimum_ number of guesses that need to be tried to access a user's account:

| Required characters | Length | Guesses |
| --- | --- | --- |
| Digits only | 8 | ~ 227 |
| Digits and letters | 8 | ~ 241 |
| Digits, lower and uppercase letters | 8 | ~ 248 |
| Digits, lower and uppercase letters, symbols | 8 | ~ 252 |

In reality though, passwords are not always generated at random. They often contain variations of names, words, dates, and common phrases. Malicious actors can use these properties to guess a password in fewer attempts.

There are hundreds of millions (and growing!) known passwords out there. Malicious actors can use these lists of leaked passwords to automate login attempts (known as credential stuffing) and steal or access sensitive user data.

## Password strength and leaked password protection [\#](https://supabase.com/docs/guides/auth/password-security\#password-strength-and-leaked-password-protection)

To help protect your users, Supabase Auth allows you fine-grained control over the strength of the passwords used on your project. You can configure these in your project's [Auth settings](https://supabase.com/dashboard/project/_/settings/auth):

- Set a large minimum password length. Anything less than 8 characters is not recommended.
- Set the required characters that must appear at least once in a user's password. Use the strongest option of requiring digits, lowercase and uppercase letters, and symbols.
- Prevent the use of leaked passwords. Supabase Auth uses the open-source [HaveIBeenPwned.org Pwned Passwords API](https://haveibeenpwned.com/Passwords) to reject passwords that have been leaked and are known by malicious actors.

## Additional recommendations [\#](https://supabase.com/docs/guides/auth/password-security\#additional-recommendations)

In addition to choosing suitable password strength settings and preventing the use of leaked passwords, consider asking your users to:

- Use a password manager to store and generate passwords.
- Avoid password reuse across websites and apps.
- Avoid using personal information in passwords.
- Use [Multi-Factor Authentication](https://supabase.com/docs/guides/auth/auth-mfa).

## Frequently asked questions [\#](https://supabase.com/docs/guides/auth/password-security\#frequently-asked-questions)

### How are passwords stored? [\#](https://supabase.com/docs/guides/auth/password-security\#how-are-passwords-stored)

Supabase Auth uses [bcrypt](https://en.wikipedia.org/wiki/Bcrypt), a strong password hashing function, to store hashes of users' passwords. Only hashed passwords are stored. You cannot impersonate a user with the password hash. Each hash is accompanied by a randomly generated salt parameter for extra security.

The hash is stored in the `encrypted_password` column of the `auth.users` table. The column's name is a misnomer (cryptographic hashing is not encryption), but is kept for backward compatibility.

### How will strengthened password requirements affect current users? [\#](https://supabase.com/docs/guides/auth/password-security\#how-will-strengthened-password-requirements-affect-current-users)

Existing users can still sign in with their current password even if it doesn't meet the new, strengthened password requirements. However, if their password falls short of these updated standards, they will encounter a `WeakPasswordError` during the `signInWithPassword` process, explaining why it's considered weak. This change is also applicable to new users and existing users changing their passwords, ensuring everyone adheres to the enhanced security standards.

### Is this helpful?

NoYes

### On this page

[Password strength and leaked password protection](https://supabase.com/docs/guides/auth/password-security#password-strength-and-leaked-password-protection) [Additional recommendations](https://supabase.com/docs/guides/auth/password-security#additional-recommendations) [Frequently asked questions](https://supabase.com/docs/guides/auth/password-security#frequently-asked-questions) [How are passwords stored?](https://supabase.com/docs/guides/auth/password-security#how-are-passwords-stored) [How will strengthened password requirements affect current users?](https://supabase.com/docs/guides/auth/password-security#how-will-strengthened-password-requirements-affect-current-users)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_passwords.md">
Auth

# Password-based Auth

## Allow users to sign in with a password connected to their email or phone number.

* * *

Users often expect to sign in to your site with a password. Supabase Auth helps you implement password-based auth safely, using secure configuration options and best practices for storing and verifying passwords.

Users can associate a password with their identity using their [email address](https://supabase.com/docs/guides/auth/passwords#with-email) or a [phone number](https://supabase.com/docs/guides/auth/passwords#with-phone).

## With email [\#](https://supabase.com/docs/guides/auth/passwords\#with-email)

### Enabling email and password-based authentication [\#](https://supabase.com/docs/guides/auth/passwords\#enabling-email-and-password-based-authentication)

Email authentication is enabled by default.

You can configure whether users need to verify their email to sign in. On hosted Supabase projects, this is true by default. On self-hosted projects or in local development, this is false by default.

Change this setting on the [Auth Providers page](https://supabase.com/dashboard/project/_/auth/providers) for hosted projects, or in the [configuration file](https://supabase.com/docs/guides/cli/config#auth.email.enable_confirmations) for self-hosted projects.

### Signing up with an email and password [\#](https://supabase.com/docs/guides/auth/passwords\#signing-up-with-an-email-and-password)

There are two possible flows for email signup: [implicit flow](https://supabase.com/docs/guides/auth/sessions#implicit-flow) and [PKCE flow](https://supabase.com/docs/guides/auth/sessions#pkce-flow). If you're using SSR, you're using the PKCE flow. If you're using client-only code, the default flow depends upon the client library. The implicit flow is the default in JavaScript and Dart, and the PKCE flow is the default in Swift.

The instructions in this section assume that email confirmations are enabled.

Implicit flowPKCE flow

The implicit flow only works for client-only apps. Your site directly receives the access token after the user confirms their email.

JavaScriptDartSwiftKotlinPython

To sign up the user, call [signUp()](https://supabase.com/docs/reference/javascript/auth-signup) with their email address and password.

You can optionally specify a URL to redirect to after the user clicks the confirmation link. This URL must be configured as a [Redirect URL](https://supabase.com/docs/guides/auth/redirect-urls), which you can do in the [dashboard](https://supabase.com/dashboard/project/_/auth/url-configuration) for hosted projects, or in the [configuration file](https://supabase.com/docs/guides/cli/config#auth.additional_redirect_urls) for self-hosted projects.

If you don't specify a redirect URL, the user is automatically redirected to your site URL. This defaults to `localhost:3000`, but you can also configure this.

`
async function signUpNewUser() {
const { data, error } = await supabase.auth.signUp({
    email: 'valid.email@supabase.io',
    password: 'example-password',
    options: {
      emailRedirectTo: 'https://example.com/welcome',
    },
})
}
`

### Signing in with an email and password [\#](https://supabase.com/docs/guides/auth/passwords\#signing-in-with-an-email-and-password)

JavaScriptDartSwiftKotlinPython

When your user signs in, call [`signInWithPassword()`](https://supabase.com/docs/reference/javascript/auth-signinwithpassword) with their email address and password:

`
async function signInWithEmail() {
const { data, error } = await supabase.auth.signInWithPassword({
    email: 'valid.email@supabase.io',
    password: 'example-password',
})
}
`

### Resetting a password [\#](https://supabase.com/docs/guides/auth/passwords\#resetting-a-password)

Implicit flowPKCE flow

#### Step 1: Create a reset password page [\#](https://supabase.com/docs/guides/auth/passwords\#step-1-create-a-reset-password-page)

Create a **reset password** page. This page should be publicly accessible.

Collect the user's email address and request a password reset email. Specify the redirect URL, which should point to the URL of a **change password** page. This URL needs to be configured in your [redirect URLs](https://supabase.com/docs/guides/auth/redirect-urls).

JavaScriptSwiftKotlinPython

`
await supabase.auth.resetPasswordForEmail('valid.email@supabase.io', {
redirectTo: 'http://example.com/account/update-password',
})
`

#### Step 2: Create a change password page [\#](https://supabase.com/docs/guides/auth/passwords\#step-2-create-a-change-password-page)

Create a **change password** page at the URL you specified in the previous step. This page should be accessible only to authenticated users.

Collect the user's new password and call `updateUser` to update their password.

JavaScriptSwiftKotlinPython

`
await supabase.auth.updateUser({ password: new_password })
`

### Email sending [\#](https://supabase.com/docs/guides/auth/passwords\#email-sending)

The signup confirmation and password reset flows require an SMTP server to send emails.

The Supabase platform comes with a default email-sending service for you to try out. The service has a rate limit of 2 emails per hour, and availability is on a best-effort basis. For production use, you should consider configuring a custom SMTP server.

Consider configuring a custom SMTP server for production.

See the [Custom SMTP guide](https://supabase.com/docs/guides/auth/auth-smtp) for instructions.

#### Local development with Inbucket [\#](https://supabase.com/docs/guides/auth/passwords\#local-development-with-inbucket)

You can test email flows on your local machine. The Supabase CLI automatically captures emails sent locally by using [Inbucket](https://github.com/inbucket/inbucket).

In your terminal, run `supabase status` to get the Inbucket URL. Go to this URL in your browser, and follow the instructions to find your emails.

## With phone [\#](https://supabase.com/docs/guides/auth/passwords\#with-phone)

You can use a user's mobile phone number as an identifier, instead of an email address, when they sign up with a password.

This practice is usually discouraged because phone networks recycle mobile phone numbers. Anyone receiving a recycled phone number gets access to the original user's account. To mitigate this risk, [implement MFA](https://supabase.com/docs/guides/auth/auth-mfa).

Protect users who use a phone number as a password-based auth identifier by enabling MFA.

### Enabling phone and password-based authentication [\#](https://supabase.com/docs/guides/auth/passwords\#enabling-phone-and-password-based-authentication)

Enable phone authentication on the [Auth Providers page](https://supabase.com/dashboard/project/_/auth/providers) for hosted Supabase projects.

For self-hosted projects or local development, use the [configuration file](https://supabase.com/docs/guides/cli/config#auth.sms.enable_signup). See the configuration variables namespaced under `auth.sms`.

If you want users to confirm their phone number on signup, you need to set up an SMS provider. Each provider has its own configuration. Supported providers include MessageBird, Twilio, Vonage, and TextLocal (community-supported).

### Configuring SMS Providers

![MessageBird Icon](https://supabase.com/docs/img/icons/messagebird-icon.svg)

##### MessageBird

![Twilio Icon](https://supabase.com/docs/img/icons/twilio-icon.svg)

##### Twilio

![Vonage Icon](https://supabase.com/docs/img/icons/vonage-icon-light.svg)

##### Vonage

![Textlocal (Community Supported) Icon](https://supabase.com/docs/img/icons/textlocal-icon.svg)

##### Textlocal (Community Supported)

### Signing up with a phone number and password [\#](https://supabase.com/docs/guides/auth/passwords\#signing-up-with-a-phone-number-and-password)

To sign up the user, call [`signUp()`](https://supabase.com/docs/reference/javascript/auth-signup) with their phone number and password:

JavaScriptSwiftKotlinPythonHTTP

`
const { data, error } = await supabase.auth.signUp({
phone: '+13334445555',
password: 'some-password',
})
`

If you have phone verification turned on, the user receives an SMS with a 6-digit pin that you must verify within 60 seconds:

JavaScriptSwiftKotlinPythonHTTP

You should present a form to the user so they can input the 6 digit pin, then send it along with the phone number to `verifyOtp`:

`
const {
data: { session },
error,
} = await supabase.auth.verifyOtp({
phone: '+13334445555',
token: '123456',
type: 'sms',
})
`

### Signing in a with a phone number and password [\#](https://supabase.com/docs/guides/auth/passwords\#signing-in-a-with-a-phone-number-and-password)

Call the function to sign in with the user's phone number and password:

JavaScriptSwiftKotlinPythonHTTP

`
const { user, error } = await supabase.auth.signInWithPassword({
phone: '+13334445555',
password: 'some-password',
})
`

### Is this helpful?

NoYes

### On this page

[With email](https://supabase.com/docs/guides/auth/passwords#with-email) [Enabling email and password-based authentication](https://supabase.com/docs/guides/auth/passwords#enabling-email-and-password-based-authentication) [Signing up with an email and password](https://supabase.com/docs/guides/auth/passwords#signing-up-with-an-email-and-password) [Signing in with an email and password](https://supabase.com/docs/guides/auth/passwords#signing-in-with-an-email-and-password) [Resetting a password](https://supabase.com/docs/guides/auth/passwords#resetting-a-password) [Email sending](https://supabase.com/docs/guides/auth/passwords#email-sending) [With phone](https://supabase.com/docs/guides/auth/passwords#with-phone) [Enabling phone and password-based authentication](https://supabase.com/docs/guides/auth/passwords#enabling-phone-and-password-based-authentication) [Signing up with a phone number and password](https://supabase.com/docs/guides/auth/passwords#signing-up-with-a-phone-number-and-password) [Signing in a with a phone number and password](https://supabase.com/docs/guides/auth/passwords#signing-in-a-with-a-phone-number-and-password)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_phone_login.md">
Auth

# Phone Login

* * *

Phone Login is a method of authentication that allows users to log in to a website or application without using a password. The user authenticates through a one-time password (OTP) sent via a channel (SMS or WhatsApp).

At this time, `WhatsApp` is only supported as a channel for the Twilio and Twilio Verify Providers.

Users can also log in with their phones using Native Mobile Login with the built-in identity provider. For Native Mobile Login with Android and iOS, see the [Social Login guides](https://supabase.com/docs/guides/auth/social-login).

Phone OTP login can:

- Improve the user experience by not requiring users to create and remember a password
- Increase security by reducing the risk of password-related security breaches
- Reduce support burden of dealing with password resets and other password-related flows

To keep SMS sending costs under control, make sure you adjust your project's rate limits and [configure CAPTCHA](https://supabase.com/docs/guides/auth/auth-captcha). See the [Production Checklist](https://supabase.com/docs/guides/platform/going-into-prod) to learn more.

Some countries have special regulations for services that send SMS messages to users, (e.g India's TRAI DLT regulations). Remember to look up and follow the regulations of countries where you operate.

## Enabling phone login [\#](https://supabase.com/docs/guides/auth/phone-login\#enabling-phone-login)

Enable phone authentication on the [Auth Providers page](https://supabase.com/dashboard/project/_/auth/providers) for hosted Supabase projects.

For self-hosted projects or local development, use the [configuration file](https://supabase.com/docs/guides/cli/config#auth.sms.enable_signup). See the configuration variables namespaced under `auth.sms`.

You also need to set up an SMS provider. Each provider has its own configuration. Supported providers include MessageBird, Twilio, Vonage, and TextLocal (community-supported).

### Configuring SMS Providers

![MessageBird Icon](https://supabase.com/docs/img/icons/messagebird-icon.svg)

##### MessageBird

![Twilio Icon](https://supabase.com/docs/img/icons/twilio-icon.svg)

##### Twilio

![Vonage Icon](https://supabase.com/docs/img/icons/vonage-icon-light.svg)

##### Vonage

![Textlocal (Community Supported) Icon](https://supabase.com/docs/img/icons/textlocal-icon.svg)

##### Textlocal (Community Supported)

By default, a user can only request an OTP once every 60 seconds and they expire after 1 hour.

## Signing in with phone OTP [\#](https://supabase.com/docs/guides/auth/phone-login\#signing-in-with-phone-otp)

With OTP, a user can sign in without setting a password on their account. They need to verify their phone number each time they sign in.

JavaScriptSwiftKotlinPythonHTTP

`
const { data, error } = await supabase.auth.signInWithOtp({
phone: '+13334445555',
})
`

The user receives an SMS with a 6-digit pin that you must verify within 60 seconds.

## Verifying a phone OTP [\#](https://supabase.com/docs/guides/auth/phone-login\#verifying-a-phone-otp)

To verify the one-time password (OTP) sent to the user's phone number, call [`verifyOtp()`](https://supabase.com/docs/reference/javascript/auth-verifyotp) with the phone number and OTP:

JavaScriptSwiftKotlinPythonHTTP

You should present a form to the user so they can input the 6 digit pin, then send it along with the phone number to `verifyOtp`:

`
const {
data: { session },
error,
} = await supabase.auth.verifyOtp({
phone: '13334445555',
token: '123456',
type: 'sms',
})
`

If successful the user will now be logged in and you should receive a valid session like:

`
{
"access_token": "<ACCESS_TOKEN>",
"token_type": "bearer",
"expires_in": 3600,
"refresh_token": "<REFRESH_TOKEN>"
}
`

The access token can be sent in the Authorization header as a Bearer token for any CRUD operations on supabase-js. See our guide on [Row Level Security](https://supabase.com/docs/guides/auth#row-level-security) for more info on restricting access on a user basis.

## Updating a phone number [\#](https://supabase.com/docs/guides/auth/phone-login\#updating-a-phone-number)

To update a user's phone number, the user must be logged in. Call [`updateUser()`](https://supabase.com/docs/reference/javascript/auth-updateuser) with their phone number:

JavaScriptSwiftKotlinPython

`
const { data, error } = await supabase.auth.updateUser({
phone: '123456789',
})
`

The user receives an SMS with a 6-digit pin that you must [verify](https://supabase.com/docs/guides/auth/phone-login#verifying-a-phone-otp) within 60 seconds.
Use the `phone_change` type when calling `verifyOTP` to update a users phone number.

### Is this helpful?

NoYes

### On this page

[Enabling phone login](https://supabase.com/docs/guides/auth/phone-login#enabling-phone-login) [Signing in with phone OTP](https://supabase.com/docs/guides/auth/phone-login#signing-in-with-phone-otp) [Verifying a phone OTP](https://supabase.com/docs/guides/auth/phone-login#verifying-a-phone-otp) [Updating a phone number](https://supabase.com/docs/guides/auth/phone-login#updating-a-phone-number)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_quickstarts_nextjs.md">
Auth

# Use Supabase Auth with Next.js

## Learn how to configure Supabase Auth for the Next.js App Router.

* * *

1

### Create a new Supabase project

Head over to [database.new](https://database.new/) and create a new Supabase project.

Your new database has a table for storing your users. You can see that this table is currently empty by running some SQL in the [SQL Editor](https://supabase.com/dashboard/project/_/sql/new).

SQL\_EDITOR

`
select * from auth.users;
`

2

### Create a Next.js app

Use the `create-next-app` command and the `with-supabase` template, to create a Next.js app pre-configured with:

- [Cookie-based Auth](https://supabase.com/docs/guides/auth/auth-helpers/nextjs)
- [TypeScript](https://www.typescriptlang.org/)
- [Tailwind CSS](https://tailwindcss.com/)

[See GitHub repo](https://github.com/vercel/next.js/tree/canary/examples/with-supabase)

Terminal

`
npx create-next-app -e with-supabase
`

3

### Declare Supabase Environment Variables

Rename `.env.local.example` to `.env.local` and populate with [your project's URL and Anon Key](https://supabase.com/dashboard/project/_/settings/api).

.env.local

`
NEXT_PUBLIC_SUPABASE_URL=your-project-url
NEXT_PUBLIC_SUPABASE_ANON_KEY=your-anon-key
`

4

### Start the app

Start the development server, go to [http://localhost:3000](http://localhost:3000/) in a browser, and you should see the contents of `app/page.tsx`.

To sign up a new user, navigate to [http://localhost:3000/sign-up](http://localhost:3000/sign-up), and click `Sign up`. _NOTE: .env.example must be renamed to .env.local before this route becomes available_

Terminal

`
npm run dev
`

## Learn more [\#](https://supabase.com/docs/guides/auth/quickstarts/nextjs\#learn-more)

- [Setting up Server-Side Auth for Next.js](https://supabase.com/docs/guides/auth/server-side/nextjs) for a Next.js deep dive
- [Supabase Auth docs](https://supabase.com/docs/guides/auth#authentication) for more Supabase authentication methods

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_quickstarts_react_native.md">
Auth

# Use Supabase Auth with React Native

## Learn how to use Supabase Auth with React Native

* * *

1

### Create a new Supabase project

[Launch a new project](https://supabase.com/dashboard) in the Supabase Dashboard.

Your new database has a table for storing your users. You can see that this table is currently empty by running some SQL in the [SQL Editor](https://supabase.com/dashboard/project/_/sql).

SQL\_EDITOR

`
select * from auth.users;
`

2

### Create a React app

Create a React app using the `create-expo-app` command.

Terminal

`
npx create-expo-app -t expo-template-blank-typescript my-app
`

3

### Install the Supabase client library

Install `supabase-js` and the required dependencies.

Terminal

`
cd my-app && npx expo install @supabase/supabase-js @react-native-async-storage/async-storage @rneui/themed react-native-url-polyfill
`

4

### Set up your login component

Create a helper file `lib/supabase.ts` that exports a Supabase client using your [Project URL and public API (anon) key](https://supabase.com/dashboard/project/_/settings/api).

lib/supabase.ts

``
import { AppState } from 'react-native'
import 'react-native-url-polyfill/auto'
import AsyncStorage from '@react-native-async-storage/async-storage'
import { createClient } from '@supabase/supabase-js'
const supabaseUrl = YOUR_REACT_NATIVE_SUPABASE_URL
const supabaseAnonKey = YOUR_REACT_NATIVE_SUPABASE_ANON_KEY
export const supabase = createClient(supabaseUrl, supabaseAnonKey, {
auth: {
    storage: AsyncStorage,
    autoRefreshToken: true,
    persistSession: true,
    detectSessionInUrl: false,
},
})
// Tells Supabase Auth to continuously refresh the session automatically
// if the app is in the foreground. When this is added, you will continue
// to receive `onAuthStateChange` events with the `TOKEN_REFRESHED` or
// `SIGNED_OUT` event if the user's session is terminated. This should
// only be registered once.
AppState.addEventListener('change', (state) => {
if (state === 'active') {
    supabase.auth.startAutoRefresh()
} else {
    supabase.auth.stopAutoRefresh()
}
})
``

5

### Create a login component

Let's set up a React Native component to manage logins and sign ups.

components/Auth.tsx

`
import React, { useState } from 'react'
import { Alert, StyleSheet, View } from 'react-native'
import { supabase } from '../lib/supabase'
import { Button, Input } from '@rneui/themed'
export default function Auth() {
const [email, setEmail] = useState('')
const [password, setPassword] = useState('')
const [loading, setLoading] = useState(false)
async function signInWithEmail() {
    setLoading(true)
    const { error } = await supabase.auth.signInWithPassword({
      email: email,
      password: password,
    })
    if (error) Alert.alert(error.message)
    setLoading(false)
}
async function signUpWithEmail() {
    setLoading(true)
    const {
      data: { session },
      error,
    } = await supabase.auth.signUp({
      email: email,
      password: password,
    })
    if (error) Alert.alert(error.message)
    if (!session) Alert.alert('Please check your inbox for email verification!')
    setLoading(false)
}
return (
    <View style={styles.container}>
      <View style={[styles.verticallySpaced, styles.mt20]}>
        <Input
          label="Email"
          leftIcon={{ type: 'font-awesome', name: 'envelope' }}
          onChangeText={(text) => setEmail(text)}
          value={email}
          placeholder="email@address.com"
          autoCapitalize={'none'}
        />
      </View>
      <View style={styles.verticallySpaced}>
        <Input
          label="Password"
          leftIcon={{ type: 'font-awesome', name: 'lock' }}
          onChangeText={(text) => setPassword(text)}
          value={password}
          secureTextEntry={true}
          placeholder="Password"
          autoCapitalize={'none'}
        />
      </View>
      <View style={[styles.verticallySpaced, styles.mt20]}>
        <Button title="Sign in" disabled={loading} onPress={() => signInWithEmail()} />
      </View>
      <View style={styles.verticallySpaced}>
        <Button title="Sign up" disabled={loading} onPress={() => signUpWithEmail()} />
      </View>
    </View>
)
}
const styles = StyleSheet.create({
container: {
    marginTop: 40,
    padding: 12,
},
verticallySpaced: {
    paddingTop: 4,
    paddingBottom: 4,
    alignSelf: 'stretch',
},
mt20: {
    marginTop: 20,
},
})
`

6

### Add the Auth component to your app

Add the `Auth` component to your `App.tsx` file. If the user is logged in, print the user id to the screen.

App.tsx

`
import 'react-native-url-polyfill/auto'
import { useState, useEffect } from 'react'
import { supabase } from './lib/supabase'
import Auth from './components/Auth'
import { View, Text } from 'react-native'
import { Session } from '@supabase/supabase-js'
export default function App() {
const [session, setSession] = useState<Session | null>(null)
useEffect(() => {
    supabase.auth.getSession().then(({ data: { session } }) => {
      setSession(session)
    })
    supabase.auth.onAuthStateChange((_event, session) => {
      setSession(session)
    })
}, [])
return (
    <View>
      <Auth />
      {session && session.user && <Text>{session.user.id}</Text>}
    </View>
)
}
`

7

### Start the app

Start the app, and follow the instructions in the terminal.

Terminal

`
npm start
`

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_quickstarts_react.md">
Auth

# Use Supabase Auth with React

## Learn how to use Supabase Auth with React.js.

* * *

1

### Create a new Supabase project

[Launch a new project](https://supabase.com/dashboard) in the Supabase Dashboard.

Your new database has a table for storing your users. You can see that this table is currently empty by running some SQL in the [SQL Editor](https://supabase.com/dashboard/project/_/sql).

SQL\_EDITOR

`
select * from auth.users;
`

2

### Create a React app

Create a React app using the `create-react-app` command.

Terminal

`
npx create-react-app my-app
`

3

### Install the Supabase client library

The fastest way to get started is to use Supabase's `auth-ui-react` library which provides a convenient interface for working with Supabase Auth from a React app.

Navigate to the React app and install the Supabase libraries.

Terminal

`
cd my-app && npm install @supabase/supabase-js @supabase/auth-ui-react @supabase/auth-ui-shared
`

4

### Set up your login component

In `App.js`, create a Supabase client using your [Project URL and public API (anon) key](https://supabase.com/dashboard/project/_/settings/api).

You can configure the Auth component to display whenever there is no session inside `supabase.auth.getSession()`

src/App.js

`
import './index.css'
import { useState, useEffect } from 'react'
import { createClient } from '@supabase/supabase-js'
import { Auth } from '@supabase/auth-ui-react'
import { ThemeSupa } from '@supabase/auth-ui-shared'
const supabase = createClient('https://<project>.supabase.co', '<your-anon-key>')
export default function App() {
    const [session, setSession] = useState(null)
    useEffect(() => {
      supabase.auth.getSession().then(({ data: { session } }) => {
        setSession(session)
      })
      const {
        data: { subscription },
      } = supabase.auth.onAuthStateChange((_event, session) => {
        setSession(session)
      })
      return () => subscription.unsubscribe()
    }, [])
    if (!session) {
      return (<Auth supabaseClient={supabase} appearance={{ theme: ThemeSupa }} />)
    }
    else {
      return (<div>Logged in!</div>)
    }
}
`

5

### Start the app

Start the app, go to [http://localhost:3000](http://localhost:3000/) in a browser, and open the browser console and you should be able to log in.

Terminal

`
npm start
`

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_rate_limits.md">
Auth

# Rate limits

## Rate limits protect your services from abuse

* * *

Supabase Auth enforces rate limits on endpoints to prevent abuse. Some rate limits are [customizable](https://supabase.com/dashboard/project/_/auth/rate-limits).

| Endpoint | Path | Limited By | Rate Limit |
| --- | --- | --- | --- |
| All endpoints that send emails | `/auth/v1/signup` `/auth/v1/recover` `/auth/v1/user` [1](https://supabase.com/docs/guides/auth/rate-limits#user-content-fn-1) | Sum of combined requests | Defaults to 4 emails per hour as of 14th July 2023. As of 21 Oct 2023, this has been updated to 2 emails per hour. You can only change this with your own custom SMTP setup. |
| All endpoints that send One-Time-Passwords (OTP) | `/auth/v1/otp` | Sum of combined requests | Defaults to 30 OTPs per hour. Is customizable. |
| Send OTPs or magiclinks | `/auth/v1/otp` | Last request | Defaults to 60 seconds window before a new request is allowed. Is customizable. |
| Signup confirmation request | `/auth/v1/signup` | Last request | Defaults to 60 seconds window before a new request is allowed. Is customizable. |
| Password Reset Request | `/auth/v1/recover` | Last request | Defaults to 60 seconds window before a new request is allowed. Is customizable. |
| Verification requests | `/auth/v1/verify` | IP Address | 360 requests per hour (with bursts up to 30 requests) |
| Token refresh requests | `/auth/v1/token` | IP Address | 1800 requests per hour (with bursts up to 30 requests) |
| Create or Verify an MFA challenge | `/auth/v1/factors/:id/challenge` `/auth/v1/factors/:id/verify` | IP Address | 15 requests per hour (with bursts up to  requests) |
| Anonymous sign-ins | `/auth/v1/signup` [2](https://supabase.com/docs/guides/auth/rate-limits#user-content-fn-2) | IP Address | 30 requests per hour (with bursts up to 30 requests) |

## Footnotes [\#](https://supabase.com/docs/guides/auth/rate-limits\#footnote-label)

1. The rate limit is only applied on `/auth/v1/user` if this endpoint is called to update the user's email address. [](https://supabase.com/docs/guides/auth/rate-limits#user-content-fnref-1)

2. The rate limit is only applied on `/auth/v1/signup` if this endpoint is called without passing in an email or phone number in the request body. [](https://supabase.com/docs/guides/auth/rate-limits#user-content-fnref-2)


### Is this helpful?

NoYes

### On this page

[Footnotes](https://supabase.com/docs/guides/auth/rate-limits#footnote-label)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_redirect_urls.md">
Auth

# Redirect URLs

## Set up redirect urls with Supabase Auth.

* * *

## Overview [\#](https://supabase.com/docs/guides/auth/redirect-urls\#overview)

When using [passwordless sign-ins](https://supabase.com/docs/reference/javascript/auth-signinwithotp) or [third-party providers](https://supabase.com/docs/reference/javascript/auth-signinwithoauth#sign-in-using-a-third-party-provider-with-redirect), the Supabase client library methods provide a `redirectTo` parameter to specify where to redirect the user to after authentication. By default, the user will be redirected to the [`SITE_URL`](https://supabase.com/docs/guides/auth/redirect-urls) but you can modify the `SITE_URL` or add additional redirect URLs to the allow list. Once you've added necessary URLs to the allow list, you can specify the URL you want the user to be redirected to in the `redirectTo` parameter.

To edit the allow list, go to the [URL Configuration](https://supabase.com/dashboard/project/_/auth/url-configuration) page. In local development or self-hosted projects, use the [configuration file](https://supabase.com/docs/guides/cli/config#auth.additional_redirect_urls).

## Use wildcards in redirect URLs [\#](https://supabase.com/docs/guides/auth/redirect-urls\#use-wildcards-in-redirect-urls)

Supabase allows you to specify wildcards when adding redirect URLs to the [allow list](https://supabase.com/dashboard/project/_/auth/url-configuration). You can use wildcard match patterns to support preview URLs from providers like Netlify and Vercel.

| Wildcard | Description |
| --- | --- |
| `*` | matches any sequence of non-separator characters |
| `**` | matches any sequence of characters |
| `?` | matches any single non-separator character |
| `c` | matches character c (c != `*`, `**`, `?`, `\`, `[`, `{`, `}`) |\
| `\c` | matches character c |\
| `[!{ character-range }]` | matches any sequence of characters not in the `{ character-range }`. For example, `[!a-z]` will not match any characters ranging from a-z. |\
\
The separator characters in a URL are defined as `.` and `/`. Use [this tool](https://www.digitalocean.com/community/tools/glob?comments=true&glob=http%3A%2F%2Flocalhost%3A3000%2F%2A%2A&matches=false&tests=http%3A%2F%2Flocalhost%3A3000&tests=http%3A%2F%2Flocalhost%3A3000%2F&tests=http%3A%2F%2Flocalhost%3A3000%2F%3Ftest%3Dtest&tests=http%3A%2F%2Flocalhost%3A3000%2Ftest-test%3Ftest%3Dtest&tests=http%3A%2F%2Flocalhost%3A3000%2Ftest%2Ftest%3Ftest%3Dtest) to test your patterns.\
\
##### Recommendation\
\
While the "globstar" ( `**`) is useful for local development and preview URLs, we recommend setting the exact redirect URL path for your site URL in production.\
\
### Redirect URL examples with wildcards [\#](https://supabase.com/docs/guides/auth/redirect-urls\#redirect-url-examples-with-wildcards)\
\
| Redirect URL | Description |\
| --- | --- |\
| `http://localhost:3000/*` | matches `http://localhost:3000/foo`, `http://localhost:3000/bar` but not `http://localhost:3000/foo/bar` or `http://localhost:3000/foo/` (note the trailing slash) |\
| `http://localhost:3000/**` | matches `http://localhost:3000/foo`, `http://localhost:3000/bar` and `http://localhost:3000/foo/bar` |\
| `http://localhost:3000/?` | matches `http://localhost:3000/a` but not `http://localhost:3000/foo` |\
| `http://localhost:3000/[!a-z]` | matches `http://localhost:3000/1` but not `http://localhost:3000/a` |\
\
## Netlify preview URLs [\#](https://supabase.com/docs/guides/auth/redirect-urls\#netlify-preview-urls)\
\
For deployments with Netlify, set the `SITE_URL` to your official site URL. Add the following additional redirect URLs for local development and deployment previews:\
\
- `http://localhost:3000/**`\
- `https://**--my_org.netlify.app/**`\
\
## Vercel preview URLs [\#](https://supabase.com/docs/guides/auth/redirect-urls\#vercel-preview-urls)\
\
For deployments with Vercel, set the `SITE_URL` to your official site URL. Add the following additional redirect URLs for local development and deployment previews:\
\
- `http://localhost:3000/**`\
- `https://*-<team-or-account-slug>.vercel.app/**`\
\
Vercel provides an environment variable for the URL of the deployment called `NEXT_PUBLIC_VERCEL_URL`. See the [Vercel docs](https://vercel.com/docs/concepts/projects/environment-variables#system-environment-variables) for more details. You can use this variable to dynamically redirect depending on the environment. You should also set the value of the environment variable called NEXT\_PUBLIC\_SITE\_URL, this should be set to your site URL in production environment to ensure that redirects function correctly.\
\
``\
const getURL = () => {\
let url =\
    process?.env?.NEXT_PUBLIC_SITE_URL ?? // Set this to your site URL in production env.\
    process?.env?.NEXT_PUBLIC_VERCEL_URL ?? // Automatically set by Vercel.\
    'http://localhost:3000/'\
// Make sure to include `https://` when not localhost.\
url = url.startsWith('http') ? url : `https://${url}`\
// Make sure to include a trailing `/`.\
url = url.endsWith('/') ? url : `${url}/`\
return url\
}\
const { data, error } = await supabase.auth.signInWithOAuth({\
provider: 'github',\
options: {\
    redirectTo: getURL(),\
},\
})\
``\
\
## Email templates when using `redirectTo` [\#](https://supabase.com/docs/guides/auth/redirect-urls\#email-templates-when-using-redirectto)\
\
When using a `redirectTo` option, you may need to replace the `{{ .SiteURL }}` with `{{ .RedirectTo }}` in your email templates. See the [Email Templates guide](https://supabase.com/docs/guides/auth/auth-email-templates) for more information.\
\
For example, change the following:\
\
`\
<!-- Old -->\
<a href="{{ .SiteURL }}/auth/confirm?token_hash={{ .TokenHash }}&type=email">Confirm your mail</a>\
<!-- New -->\
<a href="{{ .RedirectTo }}/auth/confirm?token_hash={{ .TokenHash }}&type=email"\
>Confirm your mail</a\
>\
`\
\
## Mobile deep linking URIs [\#](https://supabase.com/docs/guides/auth/redirect-urls\#mobile-deep-linking-uris)\
\
For mobile applications you can use deep linking URIs. For example, for your `SITE_URL` you can specify something like `com.supabase://login-callback/` and for additional redirect URLs something like `com.supabase.staging://login-callback/` if needed.\
\
Read more about deep linking and find code examples for different frameworks [here](https://supabase.com/docs/guides/auth/native-mobile-deep-linking).\
\
## Error handling [\#](https://supabase.com/docs/guides/auth/redirect-urls\#error-handling)\
\
When authentication fails, the user will still be redirected to the redirect URL provided. However, the error details will be returned as query fragments in the URL. You can parse these query fragments and show a custom error message to the user. For example:\
\
`\
const params = new URLSearchParams(window.location.hash.slice())\
if (params.get('error_code').startsWith('4')) {\
// show error message if error is a 4xx error\
window.alert(params.get('error_description'))\
}\
`\
\
### Is this helpful?\
\
NoYes\
\
### On this page\
\
[Overview](https://supabase.com/docs/guides/auth/redirect-urls#overview) [Use wildcards in redirect URLs](https://supabase.com/docs/guides/auth/redirect-urls#use-wildcards-in-redirect-urls) [Redirect URL examples with wildcards](https://supabase.com/docs/guides/auth/redirect-urls#redirect-url-examples-with-wildcards) [Netlify preview URLs](https://supabase.com/docs/guides/auth/redirect-urls#netlify-preview-urls) [Vercel preview URLs](https://supabase.com/docs/guides/auth/redirect-urls#vercel-preview-urls) [Email templates when using redirectTo](https://supabase.com/docs/guides/auth/redirect-urls#email-templates-when-using-redirectto) [Mobile deep linking URIs](https://supabase.com/docs/guides/auth/redirect-urls#mobile-deep-linking-uris) [Error handling](https://supabase.com/docs/guides/auth/redirect-urls#error-handling)\
\
1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)\
\
\
\
   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings\
\
\
\
\
\
   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_server_side_advanced_guide.md">
Auth

# Advanced guide

## Details about SSR Auth flows and implementation for advanced users.

* * *

When a user authenticates with Supabase Auth, two pieces of information are issued by the server:

1. **Access token** in the form of a JWT.
2. **Refresh token** which is a randomly generated string.

The default behavior if you're not using SSR is to store this information in local storage. Local storage isn't accessible by the server, so for SSR, the tokens instead need to be stored in a secure cookie. The cookie can then be passed back and forth between your app code in the client and your app code in the server.

If you're not using SSR, you might also be using the [implicit flow](https://supabase.com/docs/guides/auth/sessions/implicit-flow) to get the access and refresh tokens. The server can't access the tokens in this flow, so for SSR, you should change to the [PKCE flow](https://supabase.com/docs/guides/auth/sessions/pkce-flow). You can change the flow type when initiating your Supabase client if your client library provides this option.

In the `@supabase/ssr` package, Supabase clients are initiated to use the PKCE flow by default. They are also automatically configured to handle the saving and retrieval of session information in cookies.

## How it works [\#](https://supabase.com/docs/guides/auth/server-side/advanced-guide\#how-it-works)

In the PKCE flow, a redirect is made to your app, with an Auth Code contained in the URL. When you exchange this code using `exchangeCodeForSession`, you receive the session information, which contains the access and refresh tokens.

To maintain the session, these tokens must be stored in a storage medium securely shared between client and server, which is traditionally cookies. Whenever the session is refreshed, the auth and refresh tokens in the shared storage medium must be updated. Supabase client libraries provide a customizable `storage` option when a client is initiated, allowing you to change where tokens are stored.

For an implementation example, see the [@supabase/ssr](https://github.com/supabase/auth-helpers/blob/main/packages/ssr/src/index.ts) package.

## Frequently asked questions [\#](https://supabase.com/docs/guides/auth/server-side/advanced-guide\#frequently-asked-questions)

### No session on the server side with Next.js route prefetching? [\#](https://supabase.com/docs/guides/auth/server-side/advanced-guide\#no-session-on-the-server-side-with-nextjs-route-prefetching)

When you use route prefetching in Next.js using `<Link href="/...">` components or the `Router.push()` APIs can send server-side requests before the browser processes the access and refresh tokens. This means that those requests may not have any cookies set and your server code will render unauthenticated content.

To improve experience for your users, we recommend redirecting users to one specific page after sign-in that does not include any route prefetching from Next.js. Once the Supabase client library running in the browser has obtained the access and refresh tokens from the URL fragment, you can send users to any pages that use prefetching.

### How do I make the cookies `HttpOnly`? [\#](https://supabase.com/docs/guides/auth/server-side/advanced-guide\#how-do-i-make-the-cookies-httponly-)

This is not necessary. Both the access token and refresh token are designed to be passed around to different components in your application. The browser-based side of your application needs access to the refresh token to properly maintain a browser session anyway.

### My server is getting invalid refresh token errors. What's going on? [\#](https://supabase.com/docs/guides/auth/server-side/advanced-guide\#my-server-is-getting-invalid-refresh-token-errors-whats-going-on)

It is likely that the refresh token sent from the browser to your server is stale. Make sure the `onAuthStateChange` listener callback is free of bugs and is registered relatively early in your application's lifetime

When you receive this error on the server-side, try to defer rendering to the browser where the client library can access an up-to-date refresh token and present the user with a better experience.

### Should I set a shorter `Max-Age` parameter on the cookies? [\#](https://supabase.com/docs/guides/auth/server-side/advanced-guide\#should-i-set-a-shorter-max-age-parameter-on-the-cookies)

The `Max-Age` or `Expires` cookie parameters only control whether the browser sends the value to the server. Since a refresh token represents the long-lived authentication session of the user on that browser, setting a short `Max-Age` or `Expires` parameter on the cookies only results in a degraded user experience.

The only way to ensure that a user has logged out or their session has ended is to get the user's details with `getUser()`.

### What should I use for the `SameSite` property? [\#](https://supabase.com/docs/guides/auth/server-side/advanced-guide\#what-should-i-use-for-the-samesite-property)

Make sure you [understand the behavior of the property in different situations](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Set-Cookie/SameSite) as some properties can degrade the user experience.

A good default is to use `Lax` which sends cookies when users are navigating to your site. Cookies typically require the `Secure` attribute, which only sends them over HTTPS. However, this can be a problem when developing on `localhost`.

### Can I use server-side rendering with a CDN or cache? [\#](https://supabase.com/docs/guides/auth/server-side/advanced-guide\#can-i-use-server-side-rendering-with-a-cdn-or-cache)

Yes, but you need to be careful to include at least the refresh token cookie value in the cache key. Otherwise you may be accidentally serving pages with data belonging to different users!

Also be sure you set proper cache control headers. We recommend invalidating cache keys every hour or less.

### Which authentication flows have PKCE support? [\#](https://supabase.com/docs/guides/auth/server-side/advanced-guide\#which-authentication-flows-have-pkce-support)

At present, PKCE is supported on the Magic Link, OAuth, Sign Up, and Password Recovery routes. These correspond to the `signInWithOtp`, `signInWithOAuth`, `signUp`, and `resetPasswordForEmail` methods on the Supabase client library. When using PKCE with Phone and Email OTPs, there is no behavior change with respect to the implicit flow - an access token will be returned in the body when a request is successful.

### Is this helpful?

NoYes

### On this page

[How it works](https://supabase.com/docs/guides/auth/server-side/advanced-guide#how-it-works) [Frequently asked questions](https://supabase.com/docs/guides/auth/server-side/advanced-guide#frequently-asked-questions) [No session on the server side with Next.js route prefetching?](https://supabase.com/docs/guides/auth/server-side/advanced-guide#no-session-on-the-server-side-with-nextjs-route-prefetching) [How do I make the cookies HttpOnly?](https://supabase.com/docs/guides/auth/server-side/advanced-guide#how-do-i-make-the-cookies-httponly-) [My server is getting invalid refresh token errors. What's going on?](https://supabase.com/docs/guides/auth/server-side/advanced-guide#my-server-is-getting-invalid-refresh-token-errors-whats-going-on) [Should I set a shorter Max-Age parameter on the cookies?](https://supabase.com/docs/guides/auth/server-side/advanced-guide#should-i-set-a-shorter-max-age-parameter-on-the-cookies) [What should I use for the SameSite property?](https://supabase.com/docs/guides/auth/server-side/advanced-guide#what-should-i-use-for-the-samesite-property) [Can I use server-side rendering with a CDN or cache?](https://supabase.com/docs/guides/auth/server-side/advanced-guide#can-i-use-server-side-rendering-with-a-cdn-or-cache) [Which authentication flows have PKCE support?](https://supabase.com/docs/guides/auth/server-side/advanced-guide#which-authentication-flows-have-pkce-support)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_server_side_creating_a_client.md">
Auth

# Creating a Supabase client for SSR

## Configure your Supabase client to use cookies

* * *

To use Server-Side Rendering (SSR) with Supabase, you need to configure your Supabase client to use cookies. The `@supabase/ssr` package helps you do this for JavaScript/TypeScript applications.

## Install [\#](https://supabase.com/docs/guides/auth/server-side/creating-a-client\#install)

Install the `@supabase/ssr` and `@supabase/supabase-js` packages:

npmyarnpnpm

`
npm install @supabase/ssr @supabase/supabase-js
`

## Set environment variables [\#](https://supabase.com/docs/guides/auth/server-side/creating-a-client\#set-environment-variables)

In your environment variables file, set your Supabase URL and Supabase Anon Key:

###### Project URL

No project found

To get your Project URL, [log in](https://supabase.com/dashboard).

###### Anon key

No project found

To get your Anon key, [log in](https://supabase.com/dashboard).

Next.jsSvelteKitAstroRemixExpressHono

.env.local

`
NEXT_PUBLIC_SUPABASE_URL=your_supabase_project_url
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_supabase_anon_key
`

## Create a client [\#](https://supabase.com/docs/guides/auth/server-side/creating-a-client\#create-a-client)

You'll need some one-time setup code to configure your Supabase client to use cookies. Once your utility code is set up, you can use your new `createClient` utility functions to get a properly configured Supabase client.

Use the browser client in code that runs on the browser, and the server client in code that runs on the server.

Next.jsSvelteKitAstroRemixExpressHono

The following code samples are for App Router. For help with Pages Router, see the [Next.js Server-Side Auth guide](https://supabase.com/docs/guides/auth/server-side/nextjs?queryGroups=router&router=pages).

Client-sideServer-sideMiddleware

## Next steps [\#](https://supabase.com/docs/guides/auth/server-side/creating-a-client\#next-steps)

- Implement [Authentication using Email and Password](https://supabase.com/docs/guides/auth/server-side/email-based-auth-with-pkce-flow-for-ssr)
- Implement [Authentication using OAuth](https://supabase.com/docs/guides/auth/server-side/oauth-with-pkce-flow-for-ssr)
- [Learn more about SSR](https://supabase.com/docs/guides/auth/server-side-rendering)

### Is this helpful?

NoYes

### On this page

[Install](https://supabase.com/docs/guides/auth/server-side/creating-a-client#install) [Set environment variables](https://supabase.com/docs/guides/auth/server-side/creating-a-client#set-environment-variables) [Create a client](https://supabase.com/docs/guides/auth/server-side/creating-a-client#create-a-client) [Next steps](https://supabase.com/docs/guides/auth/server-side/creating-a-client#next-steps)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_server_side_migrating_to_ssr_from_auth_helpers.md">
Auth

# Migrating to the SSR package from Auth Helpers

* * *

The new `ssr` package takes the core concepts of the Auth Helpers and makes them available to any server language or framework. This page will guide you through migrating from the Auth Helpers package to `ssr`.

### Replacing Supabase packages [\#](https://supabase.com/docs/guides/auth/server-side/migrating-to-ssr-from-auth-helpers\#replacing-supabase-packages)

Next.jsSvelteKitRemix

`
npm uninstall @supabase/auth-helpers-nextjs
`

`
npm install @supabase/ssr
`

### Creating a client [\#](https://supabase.com/docs/guides/auth/server-side/migrating-to-ssr-from-auth-helpers\#creating-a-client)

The new `ssr` package exports two functions for creating a Supabase client. The `createBrowserClient` function is used in the client, and the `createServerClient` function is used in the server.

Check out the [Creating a client](https://supabase.com/docs/guides/auth/server-side/creating-a-client) page for examples of creating a client in your framework.

## Next steps [\#](https://supabase.com/docs/guides/auth/server-side/migrating-to-ssr-from-auth-helpers\#next-steps)

- Implement [Authentication using Email and Password](https://supabase.com/docs/guides/auth/server-side/email-based-auth-with-pkce-flow-for-ssr)
- Implement [Authentication using OAuth](https://supabase.com/docs/guides/auth/server-side/oauth-with-pkce-flow-for-ssr)
- [Learn more about SSR](https://supabase.com/docs/guides/auth/server-side-rendering)

### Is this helpful?

NoYes

### On this page

[Replacing Supabase packages](https://supabase.com/docs/guides/auth/server-side/migrating-to-ssr-from-auth-helpers#replacing-supabase-packages) [Creating a client](https://supabase.com/docs/guides/auth/server-side/migrating-to-ssr-from-auth-helpers#creating-a-client) [Next steps](https://supabase.com/docs/guides/auth/server-side/migrating-to-ssr-from-auth-helpers#next-steps)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_server_side_nextjs.md">
Auth

# Setting up Server-Side Auth for Next.js

* * *

Next.js comes in two flavors: the [App Router](https://nextjs.org/docs/app) and the [Pages Router](https://nextjs.org/docs/pages). You can set up Server-Side Auth with either strategy. You can even use both in the same application.

App RouterPages RouterHybrid router strategies

1

### Install Supabase packages

Install the `@supabase/supabase-js` package and the helper `@supabase/ssr` package.

`
npm install @supabase/supabase-js @supabase/ssr
`

2

### Set up environment variables

Create a `.env.local` file in your project root directory.

Fill in your `NEXT_PUBLIC_SUPABASE_URL` and `NEXT_PUBLIC_SUPABASE_ANON_KEY`:

###### Project URL

No project found

To get your Project URL, [log in](https://supabase.com/dashboard).

###### Anon key

No project found

To get your Anon key, [log in](https://supabase.com/dashboard).

.env.local

`
NEXT_PUBLIC_SUPABASE_URL=<your_supabase_project_url>
NEXT_PUBLIC_SUPABASE_ANON_KEY=<your_supabase_anon_key>
`

3

### Write utility functions to create Supabase clients

To access Supabase from your Next.js app, you need 2 types of Supabase clients:

1. **Client Component client** \- To access Supabase from Client Components, which run in the browser.
2. **Server Component client** \- To access Supabase from Server Components, Server Actions, and Route Handlers, which run only on the server.

Create a `utils/supabase` folder with a file for each type of client. Then copy the utility functions for each client type.

What does the \`cookies\` object do?

Do I need to create a new client for every route?

utils/supabase/client.ts

utils/supabase/server.ts

`
import { createBrowserClient } from '@supabase/ssr'
export function createClient() {
return createBrowserClient(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!
)
}
`

4

### Hook up middleware

Create a `middleware.ts` file at the root of your project.

Since Server Components can't write cookies, you need middleware to refresh expired Auth tokens and store them.

The middleware is responsible for:

1. Refreshing the Auth token (by calling `supabase.auth.getUser`).
2. Passing the refreshed Auth token to Server Components, so they don't attempt to refresh the same token themselves. This is accomplished with `request.cookies.set`.
3. Passing the refreshed Auth token to the browser, so it replaces the old token. This is accomplished with `response.cookies.set`.

Copy the middleware code for your app.

Add a [matcher](https://nextjs.org/docs/app/building-your-application/routing/middleware#matching-paths) so the middleware doesn't run on routes that don't access Supabase.

Be careful when protecting pages. The server gets the user session from the cookies, which can be spoofed by anyone.

Always use `supabase.auth.getUser()` to protect pages and user data.

_Never_ trust `supabase.auth.getSession()` inside server code such as middleware. It isn't guaranteed to revalidate the Auth token.

It's safe to trust `getUser()` because it sends a request to the Supabase Auth server every time to revalidate the Auth token.

middleware.ts

utils/supabase/middleware.ts

`
import { type NextRequest } from 'next/server'
import { updateSession } from '@/utils/supabase/middleware'
export async function middleware(request: NextRequest) {
return await updateSession(request)
}
export const config = {
matcher: [\
    /*\
     * Match all request paths except for the ones starting with:\
     * - _next/static (static files)\
     * - _next/image (image optimization files)\
     * - favicon.ico (favicon file)\
     * Feel free to modify this pattern to include more paths.\
     */\
    '/((?!_next/static|_next/image|favicon.ico|.*\\.(?:svg|png|jpg|jpeg|gif|webp)$).*)',\
],
}
`

5

### Create a login page

Create a login page for your app. Use a Server Action to call the Supabase signup function.

Since Supabase is being called from an Action, use the client defined in `@/utils/supabase/server.ts`.

Note that `cookies` is called before any calls to Supabase, which opts fetch calls out of Next.js's caching. This is important for authenticated data fetches, to ensure that users get access only to their own data.

See the Next.js docs to learn more about [opting out of data caching](https://nextjs.org/docs/app/building-your-application/data-fetching/fetching-caching-and-revalidating#opting-out-of-data-caching).

app/login/page.tsx

app/login/actions.ts

app/error/page.tsx

`
import { login, signup } from './actions'
export default function LoginPage() {
return (
    <form>
      <label htmlFor="email">Email:</label>
      <input id="email" name="email" type="email" required />
      <label htmlFor="password">Password:</label>
      <input id="password" name="password" type="password" required />
      <button formAction={login}>Log in</button>
      <button formAction={signup}>Sign up</button>
    </form>
)
}
`

6

### Change the Auth confirmation path

If you have email confirmation turned on (the default), a new user will receive an email confirmation after signing up.

Change the email template to support a server-side authentication flow.

Go to the [Auth templates](https://supabase.com/dashboard/project/_/auth/templates) page in your dashboard. In the `Confirm signup` template, change `{{ .ConfirmationURL }}` to `{{ .SiteURL }}/auth/confirm?token_hash={{ .TokenHash }}&type=email`.

7

### Create a route handler for Auth confirmation

Create a Route Handler for `auth/confirm`. When a user clicks their confirmation email link, exchange their secure code for an Auth token.

Since this is a Router Handler, use the Supabase client from `@/utils/supabase/server.ts`.

app/auth/confirm/route.ts

`
import { type EmailOtpType } from '@supabase/supabase-js'
import { type NextRequest } from 'next/server'
import { createClient } from '@/utils/supabase/server'
import { redirect } from 'next/navigation'
export async function GET(request: NextRequest) {
const { searchParams } = new URL(request.url)
const token_hash = searchParams.get('token_hash')
const type = searchParams.get('type') as EmailOtpType | null
const next = searchParams.get('next') ?? '/'
if (token_hash && type) {
    const supabase = await createClient()
    const { error } = await supabase.auth.verifyOtp({
      type,
      token_hash,
    })
    if (!error) {
      // redirect user to specified redirect URL or root of app
      redirect(next)
    }
}
// redirect the user to an error page with some instructions
redirect('/error')
}
`

8

### Access user info from Server Component

Server Components can read cookies, so you can get the Auth status and user info.

Since you're calling Supabase from a Server Component, use the client created in `@/utils/supabase/server.ts`.

Create a `private` page that users can only access if they're logged in. The page displays their email.

Be careful when protecting pages. The server gets the user session from the cookies, which can be spoofed by anyone.

Always use `supabase.auth.getUser()` to protect pages and user data.

_Never_ trust `supabase.auth.getSession()` inside Server Components. It isn't guaranteed to revalidate the Auth token.

It's safe to trust `getUser()` because it sends a request to the Supabase Auth server every time to revalidate the Auth token.

app/private/page.tsx

`
import { redirect } from 'next/navigation'
import { createClient } from '@/utils/supabase/server'
export default async function PrivatePage() {
const supabase = await createClient()
const { data, error } = await supabase.auth.getUser()
if (error || !data?.user) {
    redirect('/login')
}
return <p>Hello {data.user.email}</p>
}
`

## Congratulations [\#](https://supabase.com/docs/guides/auth/server-side/nextjs\#congratulations)

You're done! To recap, you've successfully:

- Called Supabase from a Server Action.
- Called Supabase from a Server Component.
- Set up a Supabase client utility to call Supabase from a Client Component. You can use this if you need to call Supabase from a Client Component, for example to set up a realtime subscription.
- Set up middleware to automatically refresh the Supabase Auth session.

You can now use any Supabase features from your client or server code!

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_server_side_sveltekit.md">
Auth

# Setting up Server-Side Auth for SvelteKit

* * *

Set up Server-Side Auth to use cookie-based authentication with SvelteKit.

1

### Install Supabase packages

Install the `@supabase/supabase-js` package and the helper `@supabase/ssr` package.

`
npm install @supabase/supabase-js @supabase/ssr
`

2

### Set up environment variables

Create a `.env.local` file in your project root directory.

Fill in your `PUBLIC_SUPABASE_URL` and `PUBLIC_SUPABASE_ANON_KEY`:

###### Project URL

No project found

To get your Project URL, [log in](https://supabase.com/dashboard).

###### Anon key

No project found

To get your Anon key, [log in](https://supabase.com/dashboard).

.env.local

`
PUBLIC_SUPABASE_URL=<your_supabase_project_url>
PUBLIC_SUPABASE_ANON_KEY=<your_supabase_anon_key>
`

3

### Set up server-side hooks

Set up server-side hooks in `src/hooks.server.ts`. The hooks:

- Create a request-specific Supabase client, using the user credentials from the request cookie. This client is used for server-only code.
- Check user authentication.
- Guard protected pages.

src/hooks.server.ts

``
import { createServerClient } from '@supabase/ssr'
import { type Handle, redirect } from '@sveltejs/kit'
import { sequence } from '@sveltejs/kit/hooks'
import { PUBLIC_SUPABASE_URL, PUBLIC_SUPABASE_ANON_KEY } from '$env/static/public'
const supabase: Handle = async ({ event, resolve }) => {
/**
* Creates a Supabase client specific to this server request.
*
* The Supabase client gets the Auth token from the request cookies.
*/
event.locals.supabase = createServerClient(PUBLIC_SUPABASE_URL, PUBLIC_SUPABASE_ANON_KEY, {
    cookies: {
      getAll: () => event.cookies.getAll(),
      /**
       * SvelteKit's cookies API requires `path` to be explicitly set in
       * the cookie options. Setting `path` to `/` replicates previous/
       * standard behavior.
       */
      setAll: (cookiesToSet) => {
        cookiesToSet.forEach(({ name, value, options }) => {
          event.cookies.set(name, value, { ...options, path: '/' })
        })
      },
    },
})
/**
* Unlike `supabase.auth.getSession()`, which returns the session _without_
* validating the JWT, this function also calls `getUser()` to validate the
* JWT before returning the session.
*/
event.locals.safeGetSession = async () => {
    const {
      data: { session },
    } = await event.locals.supabase.auth.getSession()
    if (!session) {
      return { session: null, user: null }
    }
    const {
      data: { user },
      error,
    } = await event.locals.supabase.auth.getUser()
    if (error) {
      // JWT validation has failed
      return { session: null, user: null }
    }
    return { session, user }
}
return resolve(event, {
    filterSerializedResponseHeaders(name) {
      /**
       * Supabase libraries use the `content-range` and `x-supabase-api-version`
       * headers, so we need to tell SvelteKit to pass it through.
       */
      return name === 'content-range' || name === 'x-supabase-api-version'
    },
})
}
const authGuard: Handle = async ({ event, resolve }) => {
const { session, user } = await event.locals.safeGetSession()
event.locals.session = session
event.locals.user = user
if (!event.locals.session && event.url.pathname.startsWith('/private')) {
    redirect(303, '/auth')
}
if (event.locals.session && event.url.pathname === '/auth') {
    redirect(303, '/private')
}
return resolve(event)
}
export const handle: Handle = sequence(supabase, authGuard)
``

4

### Create TypeScript definitions

To prevent TypeScript errors, add type definitions for the new `event.locals` properties.

src/app.d.ts

`
import type { Session, SupabaseClient, User } from '@supabase/supabase-js'
import type { Database } from './database.types.ts' // import generated types
declare global {
namespace App {
    // interface Error {}
    interface Locals {
      supabase: SupabaseClient<Database>
      safeGetSession: () => Promise<{ session: Session | null; user: User | null }>
      session: Session | null
      user: User | null
    }
    interface PageData {
      session: Session | null
    }
    // interface PageState {}
    // interface Platform {}
}
}
export {}
`

5

### Create a Supabase client in your root layout

Create a Supabase client in your root `+layout.ts`. This client can be used to access Supabase from the client or the server. In order to get access to the Auth token on the server, use a `+layout.server.ts` file to pass in the session from `event.locals`.

src/routes/+layout.ts

src/routes/+layout.server.ts

``
import { createBrowserClient, createServerClient, isBrowser } from '@supabase/ssr'
import { PUBLIC_SUPABASE_ANON_KEY, PUBLIC_SUPABASE_URL } from '$env/static/public'
import type { LayoutLoad } from './$types'
export const load: LayoutLoad = async ({ data, depends, fetch }) => {
/**
* Declare a dependency so the layout can be invalidated, for example, on
* session refresh.
*/
depends('supabase:auth')
const supabase = isBrowser()
    ? createBrowserClient(PUBLIC_SUPABASE_URL, PUBLIC_SUPABASE_ANON_KEY, {
        global: {
          fetch,
        },
      })
    : createServerClient(PUBLIC_SUPABASE_URL, PUBLIC_SUPABASE_ANON_KEY, {
        global: {
          fetch,
        },
        cookies: {
          getAll() {
            return data.cookies
          },
        },
      })
/**
* It's fine to use `getSession` here, because on the client, `getSession` is
* safe, and on the server, it reads `session` from the `LayoutData`, which
* safely checked the session using `safeGetSession`.
*/
const {
    data: { session },
} = await supabase.auth.getSession()
const {
    data: { user },
} = await supabase.auth.getUser()
return { session, supabase, user }
}
``

6

### Listen to Auth events

Set up a listener for Auth events on the client, to handle session refreshes and signouts.

src/routes/+layout.svelte

`
<script>
import { invalidate } from '$app/navigation'
import { onMount } from 'svelte'
let { data, children } = $props()
let { session, supabase } = $derived(data)
onMount(() => {
    const { data } = supabase.auth.onAuthStateChange((_, newSession) => {
      if (newSession?.expires_at !== session?.expires_at) {
        invalidate('supabase:auth')
      }
    })
    return () => data.subscription.unsubscribe()
})
</script>
{@render children()}
`

7

### Create your first page

Create your first page. This example page calls Supabase from the server to get a list of countries from the database.

This is an example of a public page that uses publicly readable data.

To populate your database, run the [colors quickstart](https://supabase.com/dashboard/project/_/sql/quickstarts) from your dashboard.

src/routes/+page.server.ts

src/routes/+page.svelte

`
import type { PageServerLoad } from './$types'
export const load: PageServerLoad = async ({ locals: { supabase } }) => {
const { data: colors } = await supabase.from('colors').select('name').limit(5).order('name')
return { colors: colors ?? [] }
}
`

8

### Change the Auth confirmation path

If you have email confirmation turned on (the default), a new user will receive an email confirmation after signing up.

Change the email template to support a server-side authentication flow.

Go to the [Auth templates](https://supabase.com/dashboard/project/_/auth/templates) page in your dashboard. In the `Confirm signup` template, change `{{ .ConfirmationURL }}` to `{{ .SiteURL }}/auth/confirm?token_hash={{ .TokenHash }}&type=email`.

9

### Create a login page

Next, create a login page to let users sign up and log in.

src/routes/auth/+page.server.ts

src/routes/auth/+page.svelte

src/routes/auth/+layout.svelte

src/routes/auth/error/+page.svelte

`
import { redirect } from '@sveltejs/kit'
import type { Actions } from './$types'
export const actions: Actions = {
signup: async ({ request, locals: { supabase } }) => {
    const formData = await request.formData()
    const email = formData.get('email') as string
    const password = formData.get('password') as string
    const { error } = await supabase.auth.signUp({ email, password })
    if (error) {
      console.error(error)
      redirect(303, '/auth/error')
    } else {
      redirect(303, '/')
    }
},
login: async ({ request, locals: { supabase } }) => {
    const formData = await request.formData()
    const email = formData.get('email') as string
    const password = formData.get('password') as string
    const { error } = await supabase.auth.signInWithPassword({ email, password })
    if (error) {
      console.error(error)
      redirect(303, '/auth/error')
    } else {
      redirect(303, '/private')
    }
},
}
`

10

### Create the signup confirmation route

Finish the signup flow by creating the API route to handle email verification.

src/routes/auth/confirm/+server.ts

``
import type { EmailOtpType } from '@supabase/supabase-js'
import { redirect } from '@sveltejs/kit'
import type { RequestHandler } from './$types'
export const GET: RequestHandler = async ({ url, locals: { supabase } }) => {
const token_hash = url.searchParams.get('token_hash')
const type = url.searchParams.get('type') as EmailOtpType | null
const next = url.searchParams.get('next') ?? '/'
/**
* Clean up the redirect URL by deleting the Auth flow parameters.
*
* `next` is preserved for now, because it's needed in the error case.
*/
const redirectTo = new URL(url)
redirectTo.pathname = next
redirectTo.searchParams.delete('token_hash')
redirectTo.searchParams.delete('type')
if (token_hash && type) {
    const { error } = await supabase.auth.verifyOtp({ type, token_hash })
    if (!error) {
      redirectTo.searchParams.delete('next')
      redirect(303, redirectTo)
    }
}
redirectTo.pathname = '/auth/error'
redirect(303, redirectTo)
}
``

11

### Create private routes

Create private routes that can only be accessed by authenticated users. The routes in the `private` directory are protected by the route guard in `hooks.server.ts`.

To ensure that `hooks.server.ts` runs for every nested path, put a `+layout.server.ts` file in the `private` directory. This file can be empty, but must exist to protect routes that don't have their own `+layout|page.server.ts`.

src/routes/private/+layout.server.ts

src/routes/private/+layout.svelte

SQL

src/routes/private/+page.server.ts

src/routes/private/+page.svelte

``
/**
* This file is necessary to ensure protection of all routes in the `private`
* directory. It makes the routes in this directory _dynamic_ routes, which
* send a server request, and thus trigger `hooks.server.ts`.
**/
``

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_server_side.md">
Auth

# Server-Side Rendering

## How SSR works with Supabase Auth.

* * *

SSR frameworks move rendering and data fetches to the server, to reduce client bundle size and execution time.

Supabase Auth is fully compatible with SSR. You need to make a few changes to the configuration of your Supabase client, to store the user session in cookies instead of local storage. After setting up your Supabase client, follow the instructions for any flow in the How-To guides.

Make sure to use the PKCE flow instructions where those differ from the implicit flow instructions. If no difference is mentioned, don't worry about this.

## `@supabase/ssr` [\#](https://supabase.com/docs/guides/auth/server-side\#supabasessr)

We have developed an [`@supabase/ssr`](https://www.npmjs.com/package/@supabase/ssr) package to make setting up the Supabase client as simple as possible. This package is currently in beta. Adoption is recommended but be aware that the API is still unstable and may have breaking changes in the future.

If you're currently using the [Auth Helpers package](https://github.com/supabase/auth-helpers), the [docs are still available](https://supabase.com/docs/guides/auth/auth-helpers), however we recommend migrating to the new `@supabase/ssr` package as this will be the recommended path moving forward.

## Framework quickstarts [\#](https://supabase.com/docs/guides/auth/server-side\#framework-quickstarts)

[![Next.js](https://supabase.com/docs/img/icons/nextjs-icon.svg)\\
\\
Next.js\\
\\
Automatically configure Supabase in Next.js to use cookies, making your user and their session available on the client and server.](https://supabase.com/docs/guides/auth/server-side/nextjs) [![SvelteKit](https://supabase.com/docs/img/icons/svelte-icon.svg)\\
\\
SvelteKit\\
\\
Automatically configure Supabase in SvelteKit to use cookies, making your user and their session available on the client and server.](https://supabase.com/docs/guides/auth/server-side/sveltekit)

### Is this helpful?

NoYes

### On this page

[@supabase/ssr](https://supabase.com/docs/guides/auth/server-side#supabasessr) [Framework quickstarts](https://supabase.com/docs/guides/auth/server-side#framework-quickstarts)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_sessions_implicit_flow.md">
Auth

# Implicit flow

## About authenticating with implicit flow.

* * *

The implicit flow is one of two ways that a user can authenticate and your app can receive the necessary access and refresh tokens.

The flow is an implementation detail handled for you by Supabase Auth, but understanding the difference between implicit and [PKCE flow](https://supabase.com/docs/guides/auth/sessions/pkce-flow) is important for understanding the difference between client-only and server-side auth.

## How it works [\#](https://supabase.com/docs/guides/auth/sessions/implicit-flow\#how-it-works)

After a successful signin, the user is redirected to your app with a URL that looks like this:

`
https://yourapp.com/...#access_token=<...>&refresh_token=<...>&...
`

The access and refresh tokens are contained in the URL fragment.

The client libraries:

- Detect this type of URL
- Extract the access token, refresh token, and some extra information
- Persist this information to local storage for further use by the library and your app

## Limitations [\#](https://supabase.com/docs/guides/auth/sessions/implicit-flow\#limitations)

The implicit flow only works on the client. Web browsers do not send the URL fragment to the server by design. This is a security feature:

- You may be hosting your single-page app on a third-party server. The third-party service shouldn't get access to your user's credentials.
- Even if the server is under your direct control, `GET` requests and their full URLs are often logged. This approach avoids leaking credentials in request or access logs.

If you wish to obtain the access token and refresh token on a server, use the [PKCE flow](https://supabase.com/docs/guides/auth/sessions/pkce-flow).

### Is this helpful?

NoYes

### On this page

[How it works](https://supabase.com/docs/guides/auth/sessions/implicit-flow#how-it-works) [Limitations](https://supabase.com/docs/guides/auth/sessions/implicit-flow#limitations)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_sessions_pkce_flow.md">
Auth

# PKCE flow

## About authenticating with PKCE flow.

* * *

The Proof Key for Code Exchange (PKCE) flow is one of two ways that a user can authenticate and your app can receive the necessary access and refresh tokens.

The flow is an implementation detail handled for you by Supabase Auth, but understanding the difference between PKCE and [implicit flow](https://supabase.com/docs/guides/auth/sessions/implicit-flow) is important for understanding the difference between client-only and server-side auth.

## How it works [\#](https://supabase.com/docs/guides/auth/sessions/pkce-flow\#how-it-works)

After a successful verification, the user is redirected to your app with a URL that looks like this:

`
https://yourapp.com/...?code=<...>
`

The `code` parameter is commonly known as the Auth Code and can be exchanged for an access token by calling `exchangeCodeForSession(code)`.

For security purposes, the code has a validity of 5 minutes and can only be exchanged for an access token once. You will need to restart the authentication flow from scratch if you wish to obtain a new access token.

As the flow is run server side, `localStorage` may not be available. You may configure the client library to use a custom storage adapter and an alternate backing storage such as cookies by setting the `storage` option to an object with the following methods:

`
const customStorageAdapter: SupportedStorage = {
    getItem: (key) => {
    if (!supportsLocalStorage()) {
        // Configure alternate storage
        return null
    }
    return globalThis.localStorage.getItem(key)
    },
    setItem: (key, value) => {
    if (!supportsLocalStorage()) {
        // Configure alternate storage here
        return
    }
    globalThis.localStorage.setItem(key, value)
    },
    removeItem: (key) => {
    if (!supportsLocalStorage()) {
        // Configure alternate storage here
        return
    }
    globalThis.localStorage.removeItem(key)
    },
}
`

You may also configure the client library to automatically exchange it for a session after a successful redirect. This can be done by setting the `detectSessionInUrl` option to `true`.

Putting it all together, your client library initialization may look like this:

`
const supabase = createClient(
        'https://xyzcompany.supabase.co',
        'public-anon-key',
        {
        ...
        auth: {
            ...
            detectSessionInUrl: true,
            flowType: 'pkce',
            storage: customStorageAdapter,
        }
        ...
        }
)
`

## Limitations [\#](https://supabase.com/docs/guides/auth/sessions/pkce-flow\#limitations)

Behind the scenes, the code exchange requires a code verifier. Both the code in the URL and the code verifier are sent back to the Auth server for a successful exchange.

The code verifier is created and stored locally when the Auth flow is first initiated. That means the code exchange must be initiated on the same browser and device where the flow was started.

## Resources [\#](https://supabase.com/docs/guides/auth/sessions/pkce-flow\#resources)

- [OAuth 2.0 guide](https://oauth.net/2/pkce/) to PKCE flow

### Is this helpful?

NoYes

### On this page

[How it works](https://supabase.com/docs/guides/auth/sessions/pkce-flow#how-it-works) [Limitations](https://supabase.com/docs/guides/auth/sessions/pkce-flow#limitations) [Resources](https://supabase.com/docs/guides/auth/sessions/pkce-flow#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_sessions.md">
Auth

# User sessions

* * *

Supabase Auth provides fine-grained control over your user's sessions.

Some security sensitive applications, or those that need to be SOC 2, HIPAA, PCI-DSS or ISO27000 compliant will require some sort of additional session controls to enforce timeouts or provide additional security guarantees. Supabase Auth makes it easy to build compliant applications.

## What is a session? [\#](https://supabase.com/docs/guides/auth/sessions\#what-is-a-session)

A session is created when a user signs in. By default, it lasts indefinitely and a user can have an unlimited number of active sessions on as many devices.

A session is represented by the Supabase Auth access token in the form of a JWT, and a refresh token which is a unique string.

Access tokens are designed to be short lived, usually between 5 minutes and 1 hour while refresh tokens never expire but can only be used once. You can exchange a refresh token only once to get a new access and refresh token pair.

This process is called **refreshing the session.**

A session terminates, depending on configuration, when:

- The user clicks sign out.
- The user changes their password or performs a security sensitive action.
- It times out due to inactivity.
- It reaches its maximum lifetime.
- A user signs in on another device.

## Access token (JWT) claims [\#](https://supabase.com/docs/guides/auth/sessions\#access-token-jwt-claims)

Every access token contains a `session_id` claim, a UUID, uniquely identifying the session of the user. You can correlate this ID with the primary key of the `auth.sessions` table.

## Initiating a session [\#](https://supabase.com/docs/guides/auth/sessions\#initiating-a-session)

A session is initiated when a user signs in. The session is stored in the `auth.sessions` table, and your app should receive the access and refresh tokens.

There are two flows for initiating a session and receiving the tokens:

- [Implicit flow](https://supabase.com/docs/guides/auth/sessions/implicit-flow)
- [PKCE flow](https://supabase.com/docs/guides/auth/sessions/pkce-flow)

## Limiting session lifetime and number of allowed sessions per user [\#](https://supabase.com/docs/guides/auth/sessions\#limiting-session-lifetime-and-number-of-allowed-sessions-per-user)

This feature is only available on Pro Plans and up.

Supabase Auth can be configured to limit the lifetime of a user's session. By default, all sessions are active until the user signs out or performs some other action that terminates a session.

In some applications, it's useful or required for security to ensure that users authenticate often, or that sessions are not left active on devices for too long.

There are three ways to limit the lifetime of a session:

- Time-boxed sessions, which terminate after a fixed amount of time.
- Set an inactivity timeout, which terminates sessions that haven't been refreshed within the timeout duration.
- Enforce a single-session per user, which only keeps the most recently active session.

To make sure that users are required to re-authenticate periodically, you can set a positive value for the **Time-box user sessions** option in the [Auth settings](https://supabase.com/dashboard/project/_/settings/auth) for your project.

To make sure that sessions expire after a period of inactivity, you can set a positive duration for the **Inactivity timeout** option in the [Auth settings](https://supabase.com/dashboard/project/_/settings/auth).

You can also enforce only one active session per user per device or browser. When this is enabled, the session from the most recent sign in will remain active, while the rest are terminated. Enable this via the _Single session per user_ option in the [Auth settings](https://supabase.com/dashboard/project/_/settings/auth).

Sessions are not proactively destroyed when you change these settings, but rather the check is enforced whenever a session is refreshed next. This can confuse developers because the actual duration of a session is the configured timeout plus the JWT expiration time. For single session per user, the effect will only be noticed at intervals of the JWT expiration time. Make sure you adjust this setting depending on your needs. We do not recommend going below 5 minutes for the JWT expiration time.

Otherwise sessions are progressively deleted from the database 24 hours after they expire, which prevents you from causing a high load on your project by accident and allows you some freedom to undo changes without adversely affecting all users.

## Frequently asked questions [\#](https://supabase.com/docs/guides/auth/sessions\#frequently-asked-questions)

### What are recommended values for access token (JWT) expiration? [\#](https://supabase.com/docs/guides/auth/sessions\#what-are-recommended-values-for-access-token-jwt-expiration)

Most applications should use the default expiration time of 1 hour. This can be customized in your project's [Auth settings](https://supabase.com/dashboard/project/_/settings/auth) in the Advanced Settings section.

Setting a value over 1 hour is generally discouraged for security reasons, but it may make sense in certain situations.

Values below 5 minutes, and especially below 2 minutes, should not be used in most situations because:

- The shorter the expiration time, the more frequently refresh tokens are used, which increases the load on the Auth server.
- Time is not absolute. Servers can often be off sync for tens of seconds, but user devices like laptops, desktops or mobile devices can sometimes be off by minutes or even hours. Having too short expiration time can cause difficult-to-debug errors due to clock skew.
- Supabase's client libraries always try to refresh the session ahead of time, which won't be possible if the expiration time is too short.
- Access tokens should generally be valid for at least as long as the longest running request in your application. This helps you avoid issues where the access token becomes invalid midway through processing.

### What is refresh token reuse detection and what does it protect from? [\#](https://supabase.com/docs/guides/auth/sessions\#what-is-refresh-token-reuse-detection-and-what-does-it-protect-from)

As your users continue using your app, refresh tokens are being constantly exchanged for new access tokens.

The general rule is that a refresh token can only be used once. However, strictly enforcing this can cause certain issues to arise. There are two exceptions to this design to prevent the early and unexpected termination of user's sessions:

- A refresh token can be used more than once within a defined reuse interval. By default this is 10 seconds and we do not recommend changing this value. This exception is granted for legitimate situations such as:
  - Using server-side rendering where the same refresh token needs to be reused on the server and soon after on the client
  - To allow some leeway for bugs or issues with serializing access to the refresh token request
- If the parent of the currently active refresh token for the user's session is being used, the active token will be returned. This exception solves an important and often common situation:
  - All clients such as browsers, mobile or desktop apps, and even some servers are inherently unreliable due to network issues. A request does not indicate that they received a response or even processed the response they received.
  - If a refresh token is revoked after being used only once, and the response wasn't received and processed by the client, when the client comes back online, it will attempt to use the refresh token that was already used. Since this might happen outside of the reuse interval, it can cause sudden and unexpected session termination.

Should the reuse attempt not fall under these two exceptions, the whole session is regarded as terminated and all refresh tokens belonging to it are marked as revoked. You can disable this behavior in the Advanced Settings of the [Auth settings](https://supabase.com/dashboard/project/_/settings/auth) page, though it is generally not recommended.

The purpose of this mechanism is to guard against potential security issues where a refresh token could have been stolen from the user, for example by exposing it accidentally in logs that leak (like logging cookies, request bodies or URL params) or via vulnerable third-party servers. It does not guard against the case where a user's session is stolen from their device.

### What are the benefits of using access and refresh tokens instead of traditional sessions? [\#](https://supabase.com/docs/guides/auth/sessions\#what-are-the-benefits-of-using-access-and-refresh-tokens-instead-of-traditional-sessions)

Traditionally user sessions were implemented by using a unique string stored in cookies that identified the authorization that the user had on a specific browser. Applications would use this unique string to constantly fetch the attached user information on every API call.

This approach has some tradeoffs compared to using a JWT-based approach:

- If the authentication server or its database crashes or is unavailable for even a few seconds, the whole application goes down. Scheduling maintenance or dealing with transient errors becomes very challenging.
- A failing authentication server can cause a chain of failures across other systems and APIs, paralyzing the whole application system.
- All requests that require authentication has to be routed through the authentication, which adds an additional latency overhead to all requests.

Supabase Auth prefers a JWT-based approach using access and refresh tokens are because the session information is encoded in a short-lived token -- the access token -- which can be transferred across APIs and systems without relying on the availability or performance of a central server. An application can thus tolerate transient failures or performance issues a lot better. By trying to refresh the access token ahead of time, your application can safely continue to function even with larger outages.

It's better for cost optimization and scaling as well, as the authentication system's servers and database only handle traffic for this use case.

### How to ensure an access token (JWT) cannot be used after a user signs out [\#](https://supabase.com/docs/guides/auth/sessions\#how-to-ensure-an-access-token-jwt-cannot-be-used-after-a-user-signs-out)

Most applications rarely need such strong guarantees. Consider adjusting the JWT expiry time to an acceptable value. If this is still necessary, you should try to use this validation logic only for the most sensitive actions within your application.

When a user signs out, the sessions affected by the logout are removed from the database entirely. You can check that the `session_id` claim in the JWT corresponds to a row in the `auth.sessions` table. If such a row does not exist, it means that the user has logged out.

Note that sessions are not proactively terminated when their maximum lifetime (time-box) or inactivity timeout are reached. These sessions are cleaned up progressively 24 hours after reaching that status. This allows you to tweak the values or roll back changes without causing unintended user friction.

### Using HTTP-only cookies to store access and refresh tokens [\#](https://supabase.com/docs/guides/auth/sessions\#using-http-only-cookies-to-store-access-and-refresh-tokens)

This is possible, but only for apps that use the traditional server-only web app approach where all of the application logic is implemented on the server and it returns rendered HTML only.

If your app uses any client side JavaScript to build a rich user experience, using HTTP-Only cookies is not feasible since only your server will be able to read and refresh the session of the user. The browser will not have access to the access and refresh tokens.

Because of this, the Supabase JavaScript libraries provide only limited support. You can override the `storage` option when creating the Supabase client **on the server** to store the values in cookies or your preferred storage choice, for example:

`
import { createClient } from '@supabase/supabase-js'
const supabase = createClient(SUPABASE_URL, SUPABASE_ANON_KEY, {
auth: {
    storage: customStorageObject,
},
})
`

The `customStorageObject` should implement the `getItem`, `setItem`, and `removeItem` methods from the [`Storage` interface](https://developer.mozilla.org/en-US/docs/Web/API/Storage). Async versions of these methods are also supported.

When using cookies to store access and refresh tokens, make sure that the [`Expires` or `Max-Age` attributes](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Set-Cookie#attributes) of the cookies is set to a timestamp very far into the future. Browsers will clear the cookies, but the session will remain active in Supabase Auth. Therefore it's best to let Supabase Auth control the validity of these tokens and instruct the browser to always store the cookies indefinitely.

### Is this helpful?

NoYes

### On this page

[What is a session?](https://supabase.com/docs/guides/auth/sessions#what-is-a-session) [Access token (JWT) claims](https://supabase.com/docs/guides/auth/sessions#access-token-jwt-claims) [Initiating a session](https://supabase.com/docs/guides/auth/sessions#initiating-a-session) [Limiting session lifetime and number of allowed sessions per user](https://supabase.com/docs/guides/auth/sessions#limiting-session-lifetime-and-number-of-allowed-sessions-per-user) [Frequently asked questions](https://supabase.com/docs/guides/auth/sessions#frequently-asked-questions) [What are recommended values for access token (JWT) expiration?](https://supabase.com/docs/guides/auth/sessions#what-are-recommended-values-for-access-token-jwt-expiration) [What is refresh token reuse detection and what does it protect from?](https://supabase.com/docs/guides/auth/sessions#what-is-refresh-token-reuse-detection-and-what-does-it-protect-from) [What are the benefits of using access and refresh tokens instead of traditional sessions?](https://supabase.com/docs/guides/auth/sessions#what-are-the-benefits-of-using-access-and-refresh-tokens-instead-of-traditional-sessions) [How to ensure an access token (JWT) cannot be used after a user signs out](https://supabase.com/docs/guides/auth/sessions#how-to-ensure-an-access-token-jwt-cannot-be-used-after-a-user-signs-out) [Using HTTP-only cookies to store access and refresh tokens](https://supabase.com/docs/guides/auth/sessions#using-http-only-cookies-to-store-access-and-refresh-tokens)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_signout.md">
Auth

# Signing out

## Signing out a user

* * *

Signing out a user works the same way no matter what method they used to sign in.

Call the sign out method from the client library. It removes the active session and clears Auth data from the storage medium.

JavaScriptDartSwiftKotlinPython

`
async function signOut() {
const { error } = await supabase.auth.signOut()
}
`

## Sign out and scopes [\#](https://supabase.com/docs/guides/auth/signout\#sign-out-and-scopes)

Supabase Auth allows you to specify three different scopes for when a user invokes the [sign out API](https://supabase.com/docs/reference/javascript/auth-signout) in your application:

- `global` (default) when all sessions active for the user are terminated.
- `local` which only terminates the current session for the user but keep sessions on other devices or browsers active.
- `others` to terminate all but the current session for the user.

You can invoke these by providing the `scope` option:

JavaScriptDartKotlin

`
// defaults to the global scope
await supabase.auth.signOut()
// sign out from the current session only
await supabase.auth.signOut({ scope: 'local' })
`

Upon sign out, all refresh tokens and potentially other database objects related to the affected sessions are destroyed and the client library removes the session stored in the local storage medium.

Access Tokens of revoked sessions remain valid until their expiry time, encoded in the `exp` claim. The user won't be immediately logged out and will only be logged out when the Access Token expires.

### Is this helpful?

NoYes

### On this page

[Sign out and scopes](https://supabase.com/docs/guides/auth/signout#sign-out-and-scopes)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_social_login_auth_apple.md">
Auth

# Login with Apple

* * *

Supabase Auth supports using [Sign in with Apple](https://developer.apple.com/sign-in-with-apple/) on the web and in native apps for iOS, macOS, watchOS or tvOS.

## Overview [\#](https://supabase.com/docs/guides/auth/social-login/auth-apple\#overview)

To support Sign in with Apple, you need to configure the [Apple provider in the Supabase dashboard](https://supabase.com/dashboard/project/_/auth/providers) for your project.

There are three general ways to use Sign in with Apple, depending on the application you're trying to build:

- Sign in on the web or in web-based apps
  - Using an OAuth flow initiated by Supabase Auth using the [Sign in with Apple REST API](https://developer.apple.com/documentation/sign_in_with_apple/sign_in_with_apple_rest_api).
  - Using [Sign in with Apple JS](https://developer.apple.com/documentation/sign_in_with_apple/sign_in_with_apple_js) directly in the browser, usually suitable for websites.
- Sign in natively inside iOS, macOS, watchOS or tvOS apps using [Apple's Authentication Services](https://developer.apple.com/documentation/authenticationservices)

In some cases you're able to use the OAuth flow within web-based native apps such as with [React Native](https://reactnative.dev/), [Expo](https://expo.dev/) or other similar frameworks. It is best practice to use native Sign in with Apple capabilities on those platforms instead.

When developing with Expo, you can test Sign in with Apple via the Expo Go app, in all other cases you will need to obtain an [Apple Developer](https://developer.apple.com/) account to enable the capability.

WebExpo React NativeFlutterSwiftKotlin

## Using the OAuth flow for web [\#](https://supabase.com/docs/guides/auth/social-login/auth-apple\#using-the-oauth-flow-for-web)

Sign in with Apple's OAuth flow is designed for web or browser based sign in methods. It can be used on web-based apps as well as websites, though some users can benefit by using Sign in with Apple JS directly.

Behind the scenes, Supabase Auth uses the [REST APIs](https://developer.apple.com/documentation/sign_in_with_apple/sign_in_with_apple_rest_api) provided by Apple.

Make sure you're using the right `supabase` client in the following code.

If you're not using Server-Side Rendering or cookie-based Auth, you can directly use the `createClient` from `@supabase/supabase-js`. If you're using Server-Side Rendering, see the [Server-Side Auth guide](https://supabase.com/docs/guides/auth/server-side/creating-a-client) for instructions on creating your Supabase client.

To initiate sign in, you can use the `signInWithOAuth()` method from the Supabase JavaScript library:

`
supabase.auth.signInWithOAuth({
provider: 'apple',
})
`

This call takes the user to Apple's consent screen. Once the flow ends, the user's profile information is exchanged and validated with Supabase Auth before it redirects back to your web application with an access and refresh token representing the user's session.

For a PKCE flow, for example in Server-Side Auth, you need an extra step to handle the code exchange. When calling `signInWithOAuth`, provide a `redirectTo` URL which points to a callback route. This redirect URL should be added to your [redirect allow list](https://supabase.com/docs/guides/auth/redirect-urls).

ClientServer

In the browser, `signInWithOAuth` automatically redirects to the OAuth provider's authentication endpoint, which then redirects to your endpoint.

``
await supabase.auth.signInWithOAuth({
provider,
options: {
    redirectTo: `http://example.com/auth/callback`,
},
})
``

At the callback endpoint, handle the code exchange to save the user session.

Next.jsSvelteKitAstroRemixExpress

Create a new file at `app/auth/callback/route.ts` and populate with the following:

app/auth/callback/route.ts

``
import { NextResponse } from 'next/server'
// The client you created from the Server-Side Auth instructions
import { createClient } from '@/utils/supabase/server'
export async function GET(request: Request) {
const { searchParams, origin } = new URL(request.url)
const code = searchParams.get('code')
// if "next" is in param, use it as the redirect URL
const next = searchParams.get('next') ?? '/'
if (code) {
    const supabase = await createClient()
    const { error } = await supabase.auth.exchangeCodeForSession(code)
    if (!error) {
      const forwardedHost = request.headers.get('x-forwarded-host') // original origin before load balancer
      const isLocalEnv = process.env.NODE_ENV === 'development'
      if (isLocalEnv) {
        // we can be sure that there is no load balancer in between, so no need to watch for X-Forwarded-Host
        return NextResponse.redirect(`${origin}${next}`)
      } else if (forwardedHost) {
        return NextResponse.redirect(`https://${forwardedHost}${next}`)
      } else {
        return NextResponse.redirect(`${origin}${next}`)
      }
    }
}
// return the user to an error page with instructions
return NextResponse.redirect(`${origin}/auth/auth-code-error`)
}
``

### Configuration [\#](https://supabase.com/docs/guides/auth/social-login/auth-apple\#configuration-web)

You will require the following information:

1. Your Apple Developer account's **Team ID**, which is an alphanumeric string of 10 characters that uniquely identifies the developer of the app. It's often accessible in the upper right-side menu on the Apple Developer Console.
2. Register email sources for _Sign in with Apple for Email Communication_ which can be found in the [Services](https://developer.apple.com/account/resources/services/list) section of the Apple Developer Console.
3. An **App ID** which uniquely identifies the app you are building. You can create a new App ID from the [Identifiers](https://developer.apple.com/account/resources/identifiers/list/bundleId) section in the Apple Developer Console (use the filter menu in the upper right side to see all App IDs). These usually are a reverse domain name string, for example `com.example.app`. Make sure you configure Sign in with Apple once you create an App ID in the Capabilities list. At this time Supabase Auth does not support Server-to-Server notification endpoints, so you should leave that setting blank. (In the past App IDs were referred to as _bundle IDs._)
4. A **Services ID** which uniquely identifies the web services provided by the app you registered in the previous step. You can create a new Services ID from the [Identifiers](https://developer.apple.com/account/resources/identifiers/list/serviceId) section in the Apple Developer Console (use the filter menu in the upper right side to see all Services IDs). These usually are a reverse domain name string, for example `com.example.app.web`.
5. Configure Website URLs for the newly created **Services ID**. The web domain you should use is the domain your Supabase project is hosted on. This is usually `<project-id>.supabase.co` while the redirect URL is `https://<project-id>.supabase.co/auth/v1/callback`.
6. Create a signing **Key** in the [Keys](https://developer.apple.com/account/resources/authkeys/list) section of the Apple Developer Console. You can use this key to generate a secret key using the tool below, which is added to your Supabase project's Auth configuration. Make sure you safely store the `AuthKey_XXXXXXXXXX.p8` file. If you ever lose access to it, or make it public accidentally, revoke it from the Apple Developer Console and create a new one immediately. You will have to generate a new secret key using this file every 6 months, so make sure you schedule a recurring meeting in your calendar!
7. Finally, add the information you configured above to the [Apple provider configuration in the Supabase dashboard](https://supabase.com/dashboard/project/_/auth/providers).

Use this tool to generate a new Apple client secret. No keys leave your browser! Be aware that this tool does not currently work in Safari, so use Firefox or a Chrome-based browser instead.

Account IDrequired

Found in the upper-right corner of Apple Developer Center.

Service IDrequired

Found under Certificates, Identifiers & Profiles in Apple Developer Center.

Key ID(optional)

If the file you select does not preserve the original name from Apple Developer Center, please enter the key ID.

Generate Secret Key

## Using sign in with Apple JS [\#](https://supabase.com/docs/guides/auth/social-login/auth-apple\#using-sign-in-with-apple-js)

[Sign in with Apple JS](https://developer.apple.com/documentation/sign_in_with_apple/sign_in_with_apple_js) is an official Apple framework for authenticating Apple users on websites. Although it can be used in web-based apps, those use cases will benefit more with the OAuth flow described above. We recommend using this method on classic websites only.

You can use the `signInWithIdToken()` method from the Supabase JavaScript library on the website to obtain an access and refresh token once the user has given consent using Sign in with Apple JS:

`
function signIn() {
const data = await AppleID.auth.signIn()
await supabase.auth.signInWithIdToken({
    provider: 'apple',
    token: data.id_token,
    nonce: '<nonce used in AppleID.auth.init>',
})
}
`

Alternatively, you can use the `AppleIDSignInOnSuccess` event with the `usePopup` option:

`
// Listen for authorization success.
document.addEventListener('AppleIDSignInOnSuccess', async (event) => {
await supabase.auth.signInWithIdToken({
    provider: 'apple',
    token: event.data.id_token,
    nonce: '<value used in appleid-signin-nonce meta tag>',
})
})
`

Make sure you request for the scope `name email` when initializing the library.

### Configuration [\#](https://supabase.com/docs/guides/auth/social-login/auth-apple\#configuration-apple-js)

To use Sign in with Apple JS you need to configure these options:

1. Have an **App ID** which uniquely identifies the app you are building. You can create a new App ID from the [Identifiers](https://developer.apple.com/account/resources/identifiers/list/bundleId) section in the Apple Developer Console (use the filter menu in the upper right side to see all App IDs). These usually are a reverse domain name string, for example `com.example.app`. Make sure you configure Sign in with Apple for the App ID you created or already have, in the Capabilities list. At this time Supabase Auth does not support Server-to-Server notification endpoints, so you should leave that setting blank. (In the past App IDs were referred to as _bundle IDs._)
2. Obtain a **Services ID** attached to the App ID that uniquely identifies the website. Use this value as the client ID when initializing Sign in with Apple JS. You can create a new Services ID from the [Identifiers](https://developer.apple.com/account/resources/identifiers/list/serviceId) section in the Apple Developer Console (use the filter menu in the upper right side to see all Services IDs). These usually are a reverse domain name string, for example `com.example.app.website`.
3. Configure Website URLs for the newly created **Services ID**. The web domain you should use is the domain your website is hosted on. The redirect URL must also point to a page on your website that will receive the callback from Apple.
4. Register the Services ID you created to your project's [Apple provider configuration in the Supabase dashboard](https://supabase.com/dashboard/project/_/auth/providers) under _Client IDs_.

If you're using Sign in with Apple JS you do not need to configure the OAuth settings.

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2F-tpcZzTdvN0%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Overview](https://supabase.com/docs/guides/auth/social-login/auth-apple#overview) [Using the OAuth flow for web](https://supabase.com/docs/guides/auth/social-login/auth-apple#using-the-oauth-flow-for-web) [Configuration](https://supabase.com/docs/guides/auth/social-login/auth-apple#configuration-web) [Using sign in with Apple JS](https://supabase.com/docs/guides/auth/social-login/auth-apple#using-sign-in-with-apple-js) [Configuration](https://supabase.com/docs/guides/auth/social-login/auth-apple#configuration-apple-js)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_social_login_auth_azure.md">
Auth

# Login with Azure (Microsoft)

* * *

To enable Azure (Microsoft) Auth for your project, you need to set up an Azure OAuth application and add the application credentials to your Supabase Dashboard.

## Overview [\#](https://supabase.com/docs/guides/auth/social-login/auth-azure\#overview)

Setting up OAuth with Azure consists of four broad steps:

- Create an OAuth application under Azure Entra ID.
- Add a secret to the application.
- Add the Supabase Auth callback URL to the allowlist in the OAuth application in Azure.
- Configure the client ID and secret of the OAuth application within the Supabase Auth dashboard.

## Access your Azure Developer account [\#](https://supabase.com/docs/guides/auth/social-login/auth-azure\#access-your-azure-developer-account)

- Go to [portal.azure.com](https://portal.azure.com/#home).
- Login and select Microsoft Entra ID under the list of Azure Services.

## Register an application [\#](https://supabase.com/docs/guides/auth/social-login/auth-azure\#register-an-application)

- Under Microsoft Entra ID, select _App registrations_ in the side panel and select _New registration._
- Choose a name and select your preferred option for the supported account types.
- Specify a _Web_ _Redirect URI_. It should look like this: `https://<project-ref>.supabase.co/auth/v1/callback`
- Finally, select _Register_ at the bottom of the screen.

![Register an application.](https://supabase.com/docs/img/guides/auth-azure/azure-register-app.png)

## Obtain a client ID and secret [\#](https://supabase.com/docs/guides/auth/social-login/auth-azure\#obtain-a-client-id-and-secret)

- Once your app has been registered, the client ID can be found under the [list of app registrations](https://portal.azure.com/#blade/Microsoft_AAD_IAM/ActiveDirectoryMenuBlade/RegisteredApps) under the column titled _Application (client) ID_.
- You can also find it in the app overview screen.
- Place the Client ID in the Azure configuration screen in the Supabase Auth dashboard.

![Obtain the client ID](https://supabase.com/docs/img/guides/auth-azure/azure-client-id.png)

- Select _Add a certificate or secret_ in the app overview screen and open the _Client secrets_ tab.
- Select _New client secret_ to create a new client secret.
- Choose a preferred expiry time of the secret. Make sure you record this in your calendar days in advance so you have enough time to create a new one without suffering from any downtime.
- Once the secret is generated place the _Value_ column (not _Secret ID_) in the Azure configuration screen in the Supabase Auth dashboard.

![Obtain the client secret](https://supabase.com/docs/img/guides/auth-azure/azure-client-secret.png)

## Guarding against unverified email domains [\#](https://supabase.com/docs/guides/auth/social-login/auth-azure\#guarding-against-unverified-email-domains)

Microsoft Entra ID can send out unverified email domains in certain cases. This may open up your project to a vulnerability where a malicious user can impersonate already existing accounts on your project.

This only applies in at least one of these cases:

- You have configured the `authenticationBehaviors` setting of your OAuth application to allow unverified email domains
- You are using an OAuth app configured as single-tenant in the supported account types
- Your OAuth app was created before June 20th 2023 after Microsoft announced this vulnerability, and the app had used unverified emails prior

This means that most OAuth apps _are not susceptible_ to this vulnerability.

Despite this, we recommend configuring the [optional `xms_edov` claim](https://learn.microsoft.com/en-us/azure/active-directory/develop/migrate-off-email-claim-authorization#using-the-xms_edov-optional-claim-to-determine-email-verification-status-and-migrate-users) on the OAuth app. This claim allows Supabase Auth to identify with certainty whether the email address sent over by Microsoft Entra ID is verified or not.

Configure this in the following way:

- Select the _App registrations_ menu in Microsoft Entra ID on the Azure portal.
- Select the OAuth app.
- Select the _Manifest_ menu in the sidebar.
- Make a backup of the JSON just in case.
- Identify the `optionalClaims` key.
- Edit it by specifying the following object:


`
"optionalClaims": {
        "idToken": [\
            {\
                "name": "xms_edov",\
                "source": null,\
                "essential": false,\
                "additionalProperties": []\
            },\
            {\
                "name": "email",\
                "source": null,\
                "essential": false,\
                "additionalProperties": []\
            }\
        ],
        "accessToken": [\
            {\
                "name": "xms_edov",\
                "source": null,\
                "essential": false,\
                "additionalProperties": []\
            }\
        ],
        "saml2Token": []
},
`

- Select _Save_ to apply the new configuration.

## Configure a tenant URL (optional) [\#](https://supabase.com/docs/guides/auth/social-login/auth-azure\#configure-a-tenant-url-optional)

A Microsoft Entra tenant is the directory of users who are allowed to access your project. This section depends on what your OAuth registration uses for _Supported account types._

By default, Supabase Auth uses the _common_ Microsoft tenant ( `https://login.microsoftonline.com/common`) which generally allows any Microsoft account to sign in to your project. Microsoft Entra further limits what accounts can access your project depending on the type of OAuth application you registered.

If your app is registered as _Personal Microsoft accounts only_ for the _Supported account types_ set Microsoft tenant to _consumers_ ( `https://login.microsoftonline.com/consumers`).

If your app is registered as _My organization only_ for the _Supported account types_ you may want to configure Supabase Auth with the organization's tenant URL. This will use the tenant's authorization flows instead, and will limit access at the Supabase Auth level to Microsoft accounts arising from only the specified tenant.

Configure this by storing a value under _Azure Tenant URL_ in the Supabase Auth provider configuration page for Azure that has the following format `https://login.microsoftonline.com/<tenant-id>`.

## Add login code to your client app [\#](https://supabase.com/docs/guides/auth/social-login/auth-azure\#add-login-code-to-your-client-app)

Supabase Auth requires that Azure returns a valid email address. Therefore you must request the `email` scope in the `signInWithOAuth` method.

JavaScriptFlutterKotlin

Make sure you're using the right `supabase` client in the following code.

If you're not using Server-Side Rendering or cookie-based Auth, you can directly use the `createClient` from `@supabase/supabase-js`. If you're using Server-Side Rendering, see the [Server-Side Auth guide](https://supabase.com/docs/guides/auth/server-side/creating-a-client) for instructions on creating your Supabase client.

When your user signs in, call [`signInWithOAuth()`](https://supabase.com/docs/reference/javascript/auth-signinwithoauth) with `azure` as the `provider`:

`
async function signInWithAzure() {
const { data, error } = await supabase.auth.signInWithOAuth({
    provider: 'azure',
    options: {
      scopes: 'email',
    },
})
}
`

For a PKCE flow, for example in Server-Side Auth, you need an extra step to handle the code exchange. When calling `signInWithOAuth`, provide a `redirectTo` URL which points to a callback route. This redirect URL should be added to your [redirect allow list](https://supabase.com/docs/guides/auth/redirect-urls).

ClientServer

In the browser, `signInWithOAuth` automatically redirects to the OAuth provider's authentication endpoint, which then redirects to your endpoint.

``
await supabase.auth.signInWithOAuth({
provider,
options: {
    redirectTo: `http://example.com/auth/callback`,
},
})
``

At the callback endpoint, handle the code exchange to save the user session.

Next.jsSvelteKitAstroRemixExpress

Create a new file at `app/auth/callback/route.ts` and populate with the following:

app/auth/callback/route.ts

``
import { NextResponse } from 'next/server'
// The client you created from the Server-Side Auth instructions
import { createClient } from '@/utils/supabase/server'
export async function GET(request: Request) {
const { searchParams, origin } = new URL(request.url)
const code = searchParams.get('code')
// if "next" is in param, use it as the redirect URL
const next = searchParams.get('next') ?? '/'
if (code) {
    const supabase = await createClient()
    const { error } = await supabase.auth.exchangeCodeForSession(code)
    if (!error) {
      const forwardedHost = request.headers.get('x-forwarded-host') // original origin before load balancer
      const isLocalEnv = process.env.NODE_ENV === 'development'
      if (isLocalEnv) {
        // we can be sure that there is no load balancer in between, so no need to watch for X-Forwarded-Host
        return NextResponse.redirect(`${origin}${next}`)
      } else if (forwardedHost) {
        return NextResponse.redirect(`https://${forwardedHost}${next}`)
      } else {
        return NextResponse.redirect(`${origin}${next}`)
      }
    }
}
// return the user to an error page with instructions
return NextResponse.redirect(`${origin}/auth/auth-code-error`)
}
``

JavaScriptFlutterKotlin

When your user signs out, call [signOut()](https://supabase.com/docs/reference/javascript/auth-signout) to remove them from the browser session and any objects from localStorage:

`
async function signOut() {
const { error } = await supabase.auth.signOut()
}
`

## Obtain the provider refresh token [\#](https://supabase.com/docs/guides/auth/social-login/auth-azure\#obtain-the-provider-refresh-token)

Azure OAuth2.0 doesn't return the `provider_refresh_token` by default. If you need the `provider_refresh_token` returned, you will need to include the following scope:

JavaScriptFlutterKotlin

`
async function signInWithAzure() {
const { data, error } = await supabase.auth.signInWithOAuth({
    provider: 'azure',
    options: {
      scopes: 'offline_access',
    },
})
}
`

## Resources [\#](https://supabase.com/docs/guides/auth/social-login/auth-azure\#resources)

- [Azure Developer Account](https://portal.azure.com/)
- [GitHub Discussion](https://github.com/supabase/gotrue/pull/54#issuecomment-757043573)
- [Potential Risk of Privilege Escalation in Azure AD Applications](https://msrc.microsoft.com/blog/2023/06/potential-risk-of-privilege-escalation-in-azure-ad-applications/)

### Is this helpful?

NoYes

### On this page

[Overview](https://supabase.com/docs/guides/auth/social-login/auth-azure#overview) [Access your Azure Developer account](https://supabase.com/docs/guides/auth/social-login/auth-azure#access-your-azure-developer-account) [Register an application](https://supabase.com/docs/guides/auth/social-login/auth-azure#register-an-application) [Obtain a client ID and secret](https://supabase.com/docs/guides/auth/social-login/auth-azure#obtain-a-client-id-and-secret) [Guarding against unverified email domains](https://supabase.com/docs/guides/auth/social-login/auth-azure#guarding-against-unverified-email-domains) [Configure a tenant URL (optional)](https://supabase.com/docs/guides/auth/social-login/auth-azure#configure-a-tenant-url-optional) [Add login code to your client app](https://supabase.com/docs/guides/auth/social-login/auth-azure#add-login-code-to-your-client-app) [Obtain the provider refresh token](https://supabase.com/docs/guides/auth/social-login/auth-azure#obtain-the-provider-refresh-token) [Resources](https://supabase.com/docs/guides/auth/social-login/auth-azure#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_social_login_auth_bitbucket.md">
Auth

# Login with Bitbucket

* * *

To enable Bitbucket Auth for your project, you need to set up a Bitbucket OAuth application and add the application credentials to your Supabase Dashboard.

## Overview [\#](https://supabase.com/docs/guides/auth/social-login/auth-bitbucket\#overview)

Setting up Bitbucket logins for your application consists of 3 parts:

- Create and configure a Bitbucket OAuth Consumer on [Bitbucket](https://bitbucket.org/)
- Add your Bitbucket OAuth Consumer keys to your [Supabase Project](https://supabase.com/dashboard)
- Add the login code to your [Supabase JS Client App](https://github.com/supabase/supabase-js)

## Access your Bitbucket account [\#](https://supabase.com/docs/guides/auth/social-login/auth-bitbucket\#access-your-bitbucket-account)

- Go to [bitbucket.org](https://bitbucket.org/).
- Click on `Login` at the top right to log in.

![Bitbucket Developer Portal.](https://supabase.com/docs/img/guides/auth-bitbucket/bitbucket-portal.png)

## Find your callback URL [\#](https://supabase.com/docs/guides/auth/social-login/auth-bitbucket\#find-your-callback-url)

The next step requires a callback URL, which looks like this: `https://<project-ref>.supabase.co/auth/v1/callback`

- Go to your [Supabase Project Dashboard](https://supabase.com/dashboard)
- Click on the `Authentication` icon in the left sidebar
- Click on [`Providers`](https://supabase.com/dashboard/project/_/auth/providers) under the Configuration section
- Click on **Bitbucket** from the accordion list to expand and you'll find your **Callback URL**, you can click `Copy` to copy it to the clipboard

For testing OAuth locally with the Supabase CLI please see the [local development docs](https://supabase.com/docs/guides/cli/local-development#use-auth-locally).

## Create a Bitbucket OAuth app [\#](https://supabase.com/docs/guides/auth/social-login/auth-bitbucket\#create-a-bitbucket-oauth-app)

- Click on your profile icon at the bottom left
- Click on `All Workspaces`
- Select a workspace and click on it to select it
- Click on `Settings` on the left
- Click on `OAuth consumers` on the left under `Apps and Features` (near the bottom)
- Click `Add Consumer` at the top
- Enter the name of your app under `Name`
- In `Callback URL`, type the callback URL of your app
- Check the permissions you need (Email, Read should be enough)
- Click `Save` at the bottom
- Click on your app name (the name of your new OAuth Consumer)
- Copy your `Key` ( `client_key`) and `Secret` ( `client_secret`) codes

## Add your Bitbucket credentials into your Supabase project [\#](https://supabase.com/docs/guides/auth/social-login/auth-bitbucket\#add-your-bitbucket-credentials-into-your-supabase-project)

- Go to your [Supabase Project Dashboard](https://supabase.com/dashboard)
- In the left sidebar, click the `Authentication` icon (near the top)
- Click on [`Providers`](https://supabase.com/dashboard/project/_/auth/providers) under the Configuration section
- Click on **Bitbucket** from the accordion list to expand and turn **Bitbucket Enabled** to ON
- Enter your **Bitbucket Client ID** and **Bitbucket Client Secret** saved in the previous step
- Click `Save`

## Add login code to your client app [\#](https://supabase.com/docs/guides/auth/social-login/auth-bitbucket\#add-login-code-to-your-client-app)

JavaScriptFlutterKotlin

Make sure you're using the right `supabase` client in the following code.

If you're not using Server-Side Rendering or cookie-based Auth, you can directly use the `createClient` from `@supabase/supabase-js`. If you're using Server-Side Rendering, see the [Server-Side Auth guide](https://supabase.com/docs/guides/auth/server-side/creating-a-client) for instructions on creating your Supabase client.

When your user signs in, call [`signInWithOAuth()`](https://supabase.com/docs/reference/javascript/auth-signinwithoauth) with `bitbucket` as the `provider`:

`
async function signInWithBitbucket() {
const { data, error } = await supabase.auth.signInWithOAuth({
    provider: 'bitbucket',
})
}
`

For a PKCE flow, for example in Server-Side Auth, you need an extra step to handle the code exchange. When calling `signInWithOAuth`, provide a `redirectTo` URL which points to a callback route. This redirect URL should be added to your [redirect allow list](https://supabase.com/docs/guides/auth/redirect-urls).

ClientServer

In the browser, `signInWithOAuth` automatically redirects to the OAuth provider's authentication endpoint, which then redirects to your endpoint.

``
await supabase.auth.signInWithOAuth({
provider,
options: {
    redirectTo: `http://example.com/auth/callback`,
},
})
``

At the callback endpoint, handle the code exchange to save the user session.

Next.jsSvelteKitAstroRemixExpress

Create a new file at `app/auth/callback/route.ts` and populate with the following:

app/auth/callback/route.ts

``
import { NextResponse } from 'next/server'
// The client you created from the Server-Side Auth instructions
import { createClient } from '@/utils/supabase/server'
export async function GET(request: Request) {
const { searchParams, origin } = new URL(request.url)
const code = searchParams.get('code')
// if "next" is in param, use it as the redirect URL
const next = searchParams.get('next') ?? '/'
if (code) {
    const supabase = await createClient()
    const { error } = await supabase.auth.exchangeCodeForSession(code)
    if (!error) {
      const forwardedHost = request.headers.get('x-forwarded-host') // original origin before load balancer
      const isLocalEnv = process.env.NODE_ENV === 'development'
      if (isLocalEnv) {
        // we can be sure that there is no load balancer in between, so no need to watch for X-Forwarded-Host
        return NextResponse.redirect(`${origin}${next}`)
      } else if (forwardedHost) {
        return NextResponse.redirect(`https://${forwardedHost}${next}`)
      } else {
        return NextResponse.redirect(`${origin}${next}`)
      }
    }
}
// return the user to an error page with instructions
return NextResponse.redirect(`${origin}/auth/auth-code-error`)
}
``

JavaScriptFlutterKotlin

When your user signs out, call [signOut()](https://supabase.com/docs/reference/javascript/auth-signout) to remove them from the browser session and any objects from localStorage:

`
async function signOut() {
const { error } = await supabase.auth.signOut()
}
`

## Resources [\#](https://supabase.com/docs/guides/auth/social-login/auth-bitbucket\#resources)

- [Supabase - Get started for free](https://supabase.com/)
- [Supabase JS Client](https://github.com/supabase/supabase-js)
- [Bitbucket Account](https://bitbucket.org/)

### Is this helpful?

NoYes

### On this page

[Overview](https://supabase.com/docs/guides/auth/social-login/auth-bitbucket#overview) [Access your Bitbucket account](https://supabase.com/docs/guides/auth/social-login/auth-bitbucket#access-your-bitbucket-account) [Find your callback URL](https://supabase.com/docs/guides/auth/social-login/auth-bitbucket#find-your-callback-url) [Create a Bitbucket OAuth app](https://supabase.com/docs/guides/auth/social-login/auth-bitbucket#create-a-bitbucket-oauth-app) [Add your Bitbucket credentials into your Supabase project](https://supabase.com/docs/guides/auth/social-login/auth-bitbucket#add-your-bitbucket-credentials-into-your-supabase-project) [Add login code to your client app](https://supabase.com/docs/guides/auth/social-login/auth-bitbucket#add-login-code-to-your-client-app) [Resources](https://supabase.com/docs/guides/auth/social-login/auth-bitbucket#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_social_login_auth_discord.md">
Auth

# Login with Discord

* * *

To enable Discord Auth for your project, you need to set up a Discord Application and add the Application OAuth credentials to your Supabase Dashboard.

## Overview [\#](https://supabase.com/docs/guides/auth/social-login/auth-discord\#overview)

Setting up Discord logins for your application consists of 3 parts:

- Create and configure a Discord Application [Discord Developer Portal](https://discord.com/developers)
- Add your Discord OAuth Consumer keys to your [Supabase Project](https://supabase.com/dashboard)
- Add the login code to your [Supabase JS Client App](https://github.com/supabase/supabase-js)

## Access your Discord account [\#](https://supabase.com/docs/guides/auth/social-login/auth-discord\#access-your-discord-account)

- Go to [discord.com](https://discord.com/).
- Click on `Login` at the top right to log in.

![Discord Portal.](https://supabase.com/docs/img/guides/auth-discord/discord-portal.png)

- Once logged in, go to [discord.com/developers](https://discord.com/developers).

![Discord Portal.](https://supabase.com/docs/img/guides/auth-discord/discord-developer-portal.png)

## Find your callback URL [\#](https://supabase.com/docs/guides/auth/social-login/auth-discord\#find-your-callback-url)

The next step requires a callback URL, which looks like this: `https://<project-ref>.supabase.co/auth/v1/callback`

- Go to your [Supabase Project Dashboard](https://supabase.com/dashboard)
- Click on the `Authentication` icon in the left sidebar
- Click on [`Providers`](https://supabase.com/dashboard/project/_/auth/providers) under the Configuration section
- Click on **Discord** from the accordion list to expand and you'll find your **Callback URL**, you can click `Copy` to copy it to the clipboard

For testing OAuth locally with the Supabase CLI please see the [local development docs](https://supabase.com/docs/guides/cli/local-development#use-auth-locally).

## Create a Discord application [\#](https://supabase.com/docs/guides/auth/social-login/auth-discord\#create-a-discord-application)

- Click on `New Application` at the top right.
- Enter the name of your application and click `Create`.
- Click on `OAuth2` under `Settings` in the left side panel.
- Click `Add Redirect` under `Redirects`.
- Type or paste your `callback URL` into the `Redirects` box.
- Click `Save Changes` at the bottom.
- Copy your `Client ID` and `Client Secret` under `Client information`.

## Add your Discord credentials into your Supabase project [\#](https://supabase.com/docs/guides/auth/social-login/auth-discord\#add-your-discord-credentials-into-your-supabase-project)

- Go to your [Supabase Project Dashboard](https://supabase.com/dashboard)
- In the left sidebar, click the `Authentication` icon (near the top)
- Click on [`Providers`](https://supabase.com/dashboard/project/_/auth/providers) under the Configuration section
- Click on **Discord** from the accordion list to expand and turn **Discord Enabled** to ON
- Enter your **Discord Client ID** and **Discord Client Secret** saved in the previous step
- Click `Save`

## Add login code to your client app [\#](https://supabase.com/docs/guides/auth/social-login/auth-discord\#add-login-code-to-your-client-app)

JavaScriptFlutterKotlin

Make sure you're using the right `supabase` client in the following code.

If you're not using Server-Side Rendering or cookie-based Auth, you can directly use the `createClient` from `@supabase/supabase-js`. If you're using Server-Side Rendering, see the [Server-Side Auth guide](https://supabase.com/docs/guides/auth/server-side/creating-a-client) for instructions on creating your Supabase client.

When your user signs in, call [`signInWithOAuth()`](https://supabase.com/docs/reference/javascript/auth-signinwithoauth) with `discord` as the `provider`:

`
async function signInWithDiscord() {
const { data, error } = await supabase.auth.signInWithOAuth({
    provider: 'discord',
})
}
`

For a PKCE flow, for example in Server-Side Auth, you need an extra step to handle the code exchange. When calling `signInWithOAuth`, provide a `redirectTo` URL which points to a callback route. This redirect URL should be added to your [redirect allow list](https://supabase.com/docs/guides/auth/redirect-urls).

ClientServer

In the browser, `signInWithOAuth` automatically redirects to the OAuth provider's authentication endpoint, which then redirects to your endpoint.

``
await supabase.auth.signInWithOAuth({
provider,
options: {
    redirectTo: `http://example.com/auth/callback`,
},
})
``

At the callback endpoint, handle the code exchange to save the user session.

Next.jsSvelteKitAstroRemixExpress

Create a new file at `app/auth/callback/route.ts` and populate with the following:

app/auth/callback/route.ts

``
import { NextResponse } from 'next/server'
// The client you created from the Server-Side Auth instructions
import { createClient } from '@/utils/supabase/server'
export async function GET(request: Request) {
const { searchParams, origin } = new URL(request.url)
const code = searchParams.get('code')
// if "next" is in param, use it as the redirect URL
const next = searchParams.get('next') ?? '/'
if (code) {
    const supabase = await createClient()
    const { error } = await supabase.auth.exchangeCodeForSession(code)
    if (!error) {
      const forwardedHost = request.headers.get('x-forwarded-host') // original origin before load balancer
      const isLocalEnv = process.env.NODE_ENV === 'development'
      if (isLocalEnv) {
        // we can be sure that there is no load balancer in between, so no need to watch for X-Forwarded-Host
        return NextResponse.redirect(`${origin}${next}`)
      } else if (forwardedHost) {
        return NextResponse.redirect(`https://${forwardedHost}${next}`)
      } else {
        return NextResponse.redirect(`${origin}${next}`)
      }
    }
}
// return the user to an error page with instructions
return NextResponse.redirect(`${origin}/auth/auth-code-error`)
}
``

If your user is already signed in, Discord prompts the user again for authorization.

JavaScriptFlutterKotlin

When your user signs out, call [signOut()](https://supabase.com/docs/reference/javascript/auth-signout) to remove them from the browser session and any objects from localStorage:

`
async function signOut() {
const { error } = await supabase.auth.signOut()
}
`

## Resources [\#](https://supabase.com/docs/guides/auth/social-login/auth-discord\#resources)

- [Supabase - Get started for free](https://supabase.com/)
- [Supabase JS Client](https://github.com/supabase/supabase-js)
- [Discord Account](https://discord.com/)
- [Discord Developer Portal](https://discord.com/developers)

### Is this helpful?

NoYes

### On this page

[Overview](https://supabase.com/docs/guides/auth/social-login/auth-discord#overview) [Access your Discord account](https://supabase.com/docs/guides/auth/social-login/auth-discord#access-your-discord-account) [Find your callback URL](https://supabase.com/docs/guides/auth/social-login/auth-discord#find-your-callback-url) [Create a Discord application](https://supabase.com/docs/guides/auth/social-login/auth-discord#create-a-discord-application) [Add your Discord credentials into your Supabase project](https://supabase.com/docs/guides/auth/social-login/auth-discord#add-your-discord-credentials-into-your-supabase-project) [Add login code to your client app](https://supabase.com/docs/guides/auth/social-login/auth-discord#add-login-code-to-your-client-app) [Resources](https://supabase.com/docs/guides/auth/social-login/auth-discord#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_social_login_auth_facebook.md">
Auth

# Login with Facebook

* * *

To enable Facebook Auth for your project, you need to set up a Facebook OAuth application and add the application credentials to your Supabase Dashboard.

## Overview [\#](https://supabase.com/docs/guides/auth/social-login/auth-facebook\#overview)

Setting up Facebook logins for your application consists of 3 parts:

- Create and configure a Facebook Application on the [Facebook Developers Site](https://developers.facebook.com/)
- Add your Facebook keys to your [Supabase Project](https://supabase.com/dashboard)
- Add the login code to your [Supabase JS Client App](https://github.com/supabase/supabase-js)

## Access your Facebook Developer account [\#](https://supabase.com/docs/guides/auth/social-login/auth-facebook\#access-your-facebook-developer-account)

- Go to [developers.facebook.com](https://developers.facebook.com/).
- Click on `Log In` at the top right to log in.

![Facebook Developer Portal.](https://supabase.com/docs/img/guides/auth-facebook/facebook-portal.png)

## Create a Facebook app [\#](https://supabase.com/docs/guides/auth/social-login/auth-facebook\#create-a-facebook-app)

- Click on `My Apps` at the top right.
- Click `Create App` near the top right.
- Select your app type and click `Continue`.
- Fill in your app information, then click `Create App`.
- This should bring you to the screen: `Add Products to Your App`. (Alternatively you can click on `Add Product` in the left sidebar to get to this screen.)

The next step requires a callback URL, which looks like this: `https://<project-ref>.supabase.co/auth/v1/callback`

- Go to your [Supabase Project Dashboard](https://supabase.com/dashboard)
- Click on the `Authentication` icon in the left sidebar
- Click on [`Providers`](https://supabase.com/dashboard/project/_/auth/providers) under the Configuration section
- Click on **Facebook** from the accordion list to expand and you'll find your **Callback URL**, you can click `Copy` to copy it to the clipboard

For testing OAuth locally with the Supabase CLI please see the [local development docs](https://supabase.com/docs/guides/cli/local-development#use-auth-locally).

## Set up Facebook login for your Facebook app [\#](https://supabase.com/docs/guides/auth/social-login/auth-facebook\#set-up-facebook-login-for-your-facebook-app)

From the `Add Products to your App` screen:

- Click `Setup` under `Facebook Login`
- Skip the Quickstart screen, instead, in the left sidebar, click `Settings` under `Facebook Login`
- Enter your callback URI under `Valid OAuth Redirect URIs` on the `Facebook Login Settings` page
- Enter this in the `Valid OAuth Redirect URIs` box
- Click `Save Changes` at the bottom right

Be aware that you have to set the right use case permissions to enable Third party applications to read the email address. To do so:

Under `Build Your App`, click on `Use Cases` screen. From there, do the following steps:

- Click the Edit button in `Authentication and Account Creation` on the right side. This action will lead to the other page.
- `public_profile` is set by default, so make sure it and `email` have status of **Ready for testing** in the redirected page.
- If not, click the **Add** button in email on right side.

## Copy your Facebook app ID and secret [\#](https://supabase.com/docs/guides/auth/social-login/auth-facebook\#copy-your-facebook-app-id-and-secret)

- Click `Settings / Basic` in the left sidebar
- Copy your App ID from the top of the `Basic Settings` page
- Under `App Secret` click `Show` then copy your secret
- Make sure all required fields are completed on this screen.

## Enter your Facebook app ID and secret into your Supabase project [\#](https://supabase.com/docs/guides/auth/social-login/auth-facebook\#enter-your-facebook-app-id-and-secret-into-your-supabase-project)

- Go to your [Supabase Project Dashboard](https://supabase.com/dashboard)
- In the left sidebar, click the `Authentication` icon (near the top)
- Click on [`Providers`](https://supabase.com/dashboard/project/_/auth/providers) under the Configuration section
- Click on **Facebook** from the accordion list to expand and turn **Facebook Enabled** to ON
- Enter your **Facebook Client ID** and **Facebook Client Secret** saved in the previous step
- Click `Save`

## Add login code to your client app [\#](https://supabase.com/docs/guides/auth/social-login/auth-facebook\#add-login-code-to-your-client-app)

JavaScriptFlutterSwiftKotlin

Make sure you're using the right `supabase` client in the following code.

If you're not using Server-Side Rendering or cookie-based Auth, you can directly use the `createClient` from `@supabase/supabase-js`. If you're using Server-Side Rendering, see the [Server-Side Auth guide](https://supabase.com/docs/guides/auth/server-side/creating-a-client) for instructions on creating your Supabase client.

When your user signs in, call [`signInWithOAuth()`](https://supabase.com/docs/reference/javascript/auth-signinwithoauth) with `facebook` as the `provider`:

`
async function signInWithFacebook() {
const { data, error } = await supabase.auth.signInWithOAuth({
    provider: 'facebook',
})
}
`

For a PKCE flow, for example in Server-Side Auth, you need an extra step to handle the code exchange. When calling `signInWithOAuth`, provide a `redirectTo` URL which points to a callback route. This redirect URL should be added to your [redirect allow list](https://supabase.com/docs/guides/auth/redirect-urls).

ClientServer

In the browser, `signInWithOAuth` automatically redirects to the OAuth provider's authentication endpoint, which then redirects to your endpoint.

``
await supabase.auth.signInWithOAuth({
provider,
options: {
    redirectTo: `http://example.com/auth/callback`,
},
})
``

At the callback endpoint, handle the code exchange to save the user session.

Next.jsSvelteKitAstroRemixExpress

Create a new file at `app/auth/callback/route.ts` and populate with the following:

app/auth/callback/route.ts

``
import { NextResponse } from 'next/server'
// The client you created from the Server-Side Auth instructions
import { createClient } from '@/utils/supabase/server'
export async function GET(request: Request) {
const { searchParams, origin } = new URL(request.url)
const code = searchParams.get('code')
// if "next" is in param, use it as the redirect URL
const next = searchParams.get('next') ?? '/'
if (code) {
    const supabase = await createClient()
    const { error } = await supabase.auth.exchangeCodeForSession(code)
    if (!error) {
      const forwardedHost = request.headers.get('x-forwarded-host') // original origin before load balancer
      const isLocalEnv = process.env.NODE_ENV === 'development'
      if (isLocalEnv) {
        // we can be sure that there is no load balancer in between, so no need to watch for X-Forwarded-Host
        return NextResponse.redirect(`${origin}${next}`)
      } else if (forwardedHost) {
        return NextResponse.redirect(`https://${forwardedHost}${next}`)
      } else {
        return NextResponse.redirect(`${origin}${next}`)
      }
    }
}
// return the user to an error page with instructions
return NextResponse.redirect(`${origin}/auth/auth-code-error`)
}
``

JavaScriptFlutterSwiftKotlin

When your user signs out, call [signOut()](https://supabase.com/docs/reference/javascript/auth-signout) to remove them from the browser session and any objects from localStorage:

`
async function signOut() {
const { error } = await supabase.auth.signOut()
}
`

Now, you should be able to login with Facebook and alert you to `Submit for Login Review` when users try to sign into your app. Follow the instructions there to make your app go live for full features and products.
You can read more about App Review [here](https://developers.facebook.com/docs/app-review/).

## Resources [\#](https://supabase.com/docs/guides/auth/social-login/auth-facebook\#resources)

- [Supabase - Get started for free](https://supabase.com/)
- [Supabase JS Client](https://github.com/supabase/supabase-js)
- [Facebook Developers Dashboard](https://developers.facebook.com/)

### Is this helpful?

NoYes

### On this page

[Overview](https://supabase.com/docs/guides/auth/social-login/auth-facebook#overview) [Access your Facebook Developer account](https://supabase.com/docs/guides/auth/social-login/auth-facebook#access-your-facebook-developer-account) [Create a Facebook app](https://supabase.com/docs/guides/auth/social-login/auth-facebook#create-a-facebook-app) [Set up Facebook login for your Facebook app](https://supabase.com/docs/guides/auth/social-login/auth-facebook#set-up-facebook-login-for-your-facebook-app) [Copy your Facebook app ID and secret](https://supabase.com/docs/guides/auth/social-login/auth-facebook#copy-your-facebook-app-id-and-secret) [Enter your Facebook app ID and secret into your Supabase project](https://supabase.com/docs/guides/auth/social-login/auth-facebook#enter-your-facebook-app-id-and-secret-into-your-supabase-project) [Add login code to your client app](https://supabase.com/docs/guides/auth/social-login/auth-facebook#add-login-code-to-your-client-app) [Resources](https://supabase.com/docs/guides/auth/social-login/auth-facebook#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_social_login_auth_figma.md">
Auth

# Login with Figma

* * *

To enable Figma Auth for your project, you need to set up a Figma OAuth application and add the application credentials to your Supabase Dashboard.

## Overview [\#](https://supabase.com/docs/guides/auth/social-login/auth-figma\#overview)

Setting up Figma logins for your application consists of 3 parts:

- Create and configure a Figma App on the [Figma Developers page](https://www.figma.com/developers).
- Add your Figma `client_id` and `client_secret` to your [Supabase Project](https://app.supabase.com/).
- Add the login code to your [Supabase JS Client App](https://github.com/supabase/supabase-js).

## Access the Figma Developers page [\#](https://supabase.com/docs/guides/auth/social-login/auth-figma\#access-the-figma-developers-page)

- Go to the [Figma Developers page](https://www.figma.com/developers)
- Click on `My apps` at the top right
- Log in (if necessary)

![Figma Developers page](https://supabase.com/docs/img/guides/auth-figma/figma_developers_page.png)

## Find your callback URL [\#](https://supabase.com/docs/guides/auth/social-login/auth-figma\#find-your-callback-url)

The next step requires a callback URL, which looks like this: `https://<project-ref>.supabase.co/auth/v1/callback`

- Go to your [Supabase Project Dashboard](https://supabase.com/dashboard)
- Click on the `Authentication` icon in the left sidebar
- Click on [`Providers`](https://supabase.com/dashboard/project/_/auth/providers) under the Configuration section
- Click on **Figma** from the accordion list to expand and you'll find your **Callback URL**, you can click `Copy` to copy it to the clipboard

For testing OAuth locally with the Supabase CLI please see the [local development docs](https://supabase.com/docs/guides/cli/local-development#use-auth-locally).

## Create a Figma OAuth app [\#](https://supabase.com/docs/guides/auth/social-login/auth-figma\#create-a-figma-oauth-app)

- Enter your `App name`, `Website URL` and upload your app logo
- Click on `Add callback`
- Add your `Callback URL`
- Click on `Save`

![Create Figma app](https://supabase.com/docs/img/guides/auth-figma/figma_create_app.png)

- Copy and save your newly-generated `Client ID`
- Copy and save your newly-generated `Client Secret`

![Get Figma app credentials](https://supabase.com/docs/img/guides/auth-figma/figma_app_credentials.png)

## Enter your Figma credentials into your Supabase project [\#](https://supabase.com/docs/guides/auth/social-login/auth-figma\#enter-your-figma-credentials-into-your-supabase-project)

- Go to your [Supabase Project Dashboard](https://supabase.com/dashboard)
- In the left sidebar, click the `Authentication` icon (near the top)
- Click on [`Providers`](https://supabase.com/dashboard/project/_/auth/providers) under the Configuration section
- Click on **Figma** from the accordion list to expand and turn **Figma Enabled** to ON
- Enter your **Figma Client ID** and **Figma Client Secret** saved in the previous step
- Click `Save`

## Add login code to your client app [\#](https://supabase.com/docs/guides/auth/social-login/auth-figma\#add-login-code-to-your-client-app)

JavaScriptFlutterKotlin

Make sure you're using the right `supabase` client in the following code.

If you're not using Server-Side Rendering or cookie-based Auth, you can directly use the `createClient` from `@supabase/supabase-js`. If you're using Server-Side Rendering, see the [Server-Side Auth guide](https://supabase.com/docs/guides/auth/server-side/creating-a-client) for instructions on creating your Supabase client.

When your user signs in, call [`signInWithOAuth()`](https://supabase.com/docs/reference/javascript/auth-signinwithoauth) with `figma` as the `provider`:

`
async function signInWithFigma() {
const { data, error } = await supabase.auth.signInWithOAuth({
    provider: 'figma',
})
}
`

For a PKCE flow, for example in Server-Side Auth, you need an extra step to handle the code exchange. When calling `signInWithOAuth`, provide a `redirectTo` URL which points to a callback route. This redirect URL should be added to your [redirect allow list](https://supabase.com/docs/guides/auth/redirect-urls).

ClientServer

In the browser, `signInWithOAuth` automatically redirects to the OAuth provider's authentication endpoint, which then redirects to your endpoint.

``
await supabase.auth.signInWithOAuth({
provider,
options: {
    redirectTo: `http://example.com/auth/callback`,
},
})
``

At the callback endpoint, handle the code exchange to save the user session.

Next.jsSvelteKitAstroRemixExpress

Create a new file at `app/auth/callback/route.ts` and populate with the following:

app/auth/callback/route.ts

``
import { NextResponse } from 'next/server'
// The client you created from the Server-Side Auth instructions
import { createClient } from '@/utils/supabase/server'
export async function GET(request: Request) {
const { searchParams, origin } = new URL(request.url)
const code = searchParams.get('code')
// if "next" is in param, use it as the redirect URL
const next = searchParams.get('next') ?? '/'
if (code) {
    const supabase = await createClient()
    const { error } = await supabase.auth.exchangeCodeForSession(code)
    if (!error) {
      const forwardedHost = request.headers.get('x-forwarded-host') // original origin before load balancer
      const isLocalEnv = process.env.NODE_ENV === 'development'
      if (isLocalEnv) {
        // we can be sure that there is no load balancer in between, so no need to watch for X-Forwarded-Host
        return NextResponse.redirect(`${origin}${next}`)
      } else if (forwardedHost) {
        return NextResponse.redirect(`https://${forwardedHost}${next}`)
      } else {
        return NextResponse.redirect(`${origin}${next}`)
      }
    }
}
// return the user to an error page with instructions
return NextResponse.redirect(`${origin}/auth/auth-code-error`)
}
``

JavaScriptFlutterKotlin

When your user signs out, call [signOut()](https://supabase.com/docs/reference/javascript/auth-signout) to remove them from the browser session and any objects from localStorage:

`
async function signOut() {
const { error } = await supabase.auth.signOut()
}
`

## Resources [\#](https://supabase.com/docs/guides/auth/social-login/auth-figma\#resources)

- [Supabase - Get started for free](https://supabase.com/)
- [Supabase JS Client](https://github.com/supabase/supabase-js)
- [Figma Developers page](https://www.figma.com/developers)

### Is this helpful?

NoYes

### On this page

[Overview](https://supabase.com/docs/guides/auth/social-login/auth-figma#overview) [Access the Figma Developers page](https://supabase.com/docs/guides/auth/social-login/auth-figma#access-the-figma-developers-page) [Find your callback URL](https://supabase.com/docs/guides/auth/social-login/auth-figma#find-your-callback-url) [Create a Figma OAuth app](https://supabase.com/docs/guides/auth/social-login/auth-figma#create-a-figma-oauth-app) [Enter your Figma credentials into your Supabase project](https://supabase.com/docs/guides/auth/social-login/auth-figma#enter-your-figma-credentials-into-your-supabase-project) [Add login code to your client app](https://supabase.com/docs/guides/auth/social-login/auth-figma#add-login-code-to-your-client-app) [Resources](https://supabase.com/docs/guides/auth/social-login/auth-figma#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_social_login_auth_github.md">
Auth

# Login with GitHub

* * *

To enable GitHub Auth for your project, you need to set up a GitHub OAuth application and add the application credentials to your Supabase Dashboard.

## Overview [\#](https://supabase.com/docs/guides/auth/social-login/auth-github\#overview)

Setting up GitHub logins for your application consists of 3 parts:

- Create and configure a GitHub OAuth App on [GitHub](https://github.com/)
- Add your GitHub OAuth keys to your [Supabase Project](https://supabase.com/dashboard)
- Add the login code to your [Supabase JS Client App](https://github.com/supabase/supabase-js)

## Find your callback URL [\#](https://supabase.com/docs/guides/auth/social-login/auth-github\#find-your-callback-url)

The next step requires a callback URL, which looks like this: `https://<project-ref>.supabase.co/auth/v1/callback`

- Go to your [Supabase Project Dashboard](https://supabase.com/dashboard)
- Click on the `Authentication` icon in the left sidebar
- Click on [`Providers`](https://supabase.com/dashboard/project/_/auth/providers) under the Configuration section
- Click on **GitHub** from the accordion list to expand and you'll find your **Callback URL**, you can click `Copy` to copy it to the clipboard

For testing OAuth locally with the Supabase CLI please see the [local development docs](https://supabase.com/docs/guides/cli/local-development#use-auth-locally).

## Register a new OAuth application on GitHub [\#](https://supabase.com/docs/guides/auth/social-login/auth-github\#register-a-new-oauth-application-on-github)

- Navigate to the [OAuth apps page](https://github.com/settings/developers)
- Click `Register a new application`. If you've created an app before, click `New OAuth App` here.
- In `Application name`, type the name of your app.
- In `Homepage URL`, type the full URL to your app's website.
- In `Authorization callback URL`, type the callback URL of your app.
- Leave `Enable Device Flow` unchecked.
- Click `Register Application`.

Copy your new OAuth credentials

- Copy and save your `Client ID`.
- Click `Generate a new client secret`.
- Copy and save your `Client secret`.

## Enter your GitHub credentials into your Supabase project [\#](https://supabase.com/docs/guides/auth/social-login/auth-github\#enter-your-github-credentials-into-your-supabase-project)

- Go to your [Supabase Project Dashboard](https://supabase.com/dashboard)
- In the left sidebar, click the `Authentication` icon (near the top)
- Click on [`Providers`](https://supabase.com/dashboard/project/_/auth/providers) under the Configuration section
- Click on **GitHub** from the accordion list to expand and turn **GitHub Enabled** to ON
- Enter your **GitHub Client ID** and **GitHub Client Secret** saved in the previous step
- Click `Save`

## Add login code to your client app [\#](https://supabase.com/docs/guides/auth/social-login/auth-github\#add-login-code-to-your-client-app)

JavaScriptFlutterSwiftKotlin

Make sure you're using the right `supabase` client in the following code.

If you're not using Server-Side Rendering or cookie-based Auth, you can directly use the `createClient` from `@supabase/supabase-js`. If you're using Server-Side Rendering, see the [Server-Side Auth guide](https://supabase.com/docs/guides/auth/server-side/creating-a-client) for instructions on creating your Supabase client.

When your user signs in, call [`signInWithOAuth()`](https://supabase.com/docs/reference/javascript/auth-signinwithoauth) with `github` as the `provider`:

`
async function signInWithGithub() {
const { data, error } = await supabase.auth.signInWithOAuth({
    provider: 'github',
})
}
`

For a PKCE flow, for example in Server-Side Auth, you need an extra step to handle the code exchange. When calling `signInWithOAuth`, provide a `redirectTo` URL which points to a callback route. This redirect URL should be added to your [redirect allow list](https://supabase.com/docs/guides/auth/redirect-urls).

ClientServer

In the browser, `signInWithOAuth` automatically redirects to the OAuth provider's authentication endpoint, which then redirects to your endpoint.

``
await supabase.auth.signInWithOAuth({
provider,
options: {
    redirectTo: `http://example.com/auth/callback`,
},
})
``

At the callback endpoint, handle the code exchange to save the user session.

Next.jsSvelteKitAstroRemixExpress

Create a new file at `app/auth/callback/route.ts` and populate with the following:

app/auth/callback/route.ts

``
import { NextResponse } from 'next/server'
// The client you created from the Server-Side Auth instructions
import { createClient } from '@/utils/supabase/server'
export async function GET(request: Request) {
const { searchParams, origin } = new URL(request.url)
const code = searchParams.get('code')
// if "next" is in param, use it as the redirect URL
const next = searchParams.get('next') ?? '/'
if (code) {
    const supabase = await createClient()
    const { error } = await supabase.auth.exchangeCodeForSession(code)
    if (!error) {
      const forwardedHost = request.headers.get('x-forwarded-host') // original origin before load balancer
      const isLocalEnv = process.env.NODE_ENV === 'development'
      if (isLocalEnv) {
        // we can be sure that there is no load balancer in between, so no need to watch for X-Forwarded-Host
        return NextResponse.redirect(`${origin}${next}`)
      } else if (forwardedHost) {
        return NextResponse.redirect(`https://${forwardedHost}${next}`)
      } else {
        return NextResponse.redirect(`${origin}${next}`)
      }
    }
}
// return the user to an error page with instructions
return NextResponse.redirect(`${origin}/auth/auth-code-error`)
}
``

JavaScriptFlutterKotlin

When your user signs out, call [signOut()](https://supabase.com/docs/reference/javascript/auth-signout) to remove them from the browser session and any objects from localStorage:

`
async function signOut() {
const { error } = await supabase.auth.signOut()
}
`

## Resources [\#](https://supabase.com/docs/guides/auth/social-login/auth-github\#resources)

- [Supabase - Get started for free](https://supabase.com/)
- [Supabase JS Client](https://github.com/supabase/supabase-js)
- [GitHub Developer Settings](https://github.com/settings/developers)

### Is this helpful?

NoYes

### On this page

[Overview](https://supabase.com/docs/guides/auth/social-login/auth-github#overview) [Find your callback URL](https://supabase.com/docs/guides/auth/social-login/auth-github#find-your-callback-url) [Register a new OAuth application on GitHub](https://supabase.com/docs/guides/auth/social-login/auth-github#register-a-new-oauth-application-on-github) [Enter your GitHub credentials into your Supabase project](https://supabase.com/docs/guides/auth/social-login/auth-github#enter-your-github-credentials-into-your-supabase-project) [Add login code to your client app](https://supabase.com/docs/guides/auth/social-login/auth-github#add-login-code-to-your-client-app) [Resources](https://supabase.com/docs/guides/auth/social-login/auth-github#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_social_login_auth_gitlab.md">
Auth

# Login with GitLab

* * *

To enable GitLab Auth for your project, you need to set up a GitLab OAuth application and add the application credentials to your Supabase Dashboard.

## Overview [\#](https://supabase.com/docs/guides/auth/social-login/auth-gitlab\#overview)

Setting up GitLab logins for your application consists of 3 parts:

- Create and configure a GitLab Application on [GitLab](https://gitlab.com/)
- Add your GitLab Application keys to your [Supabase Project](https://supabase.com/dashboard)
- Add the login code to your [Supabase JS Client App](https://github.com/supabase/supabase-js)

## Access your GitLab account [\#](https://supabase.com/docs/guides/auth/social-login/auth-gitlab\#access-your-gitlab-account)

- Go to [gitlab.com](https://gitlab.com/).
- Click on `Login` at the top right to log in.

![GitLab Developer Portal.](https://supabase.com/docs/img/guides/auth-gitlab/gitlab-portal.png)

## Find your callback URL [\#](https://supabase.com/docs/guides/auth/social-login/auth-gitlab\#find-your-callback-url)

The next step requires a callback URL, which looks like this: `https://<project-ref>.supabase.co/auth/v1/callback`

- Go to your [Supabase Project Dashboard](https://supabase.com/dashboard)
- Click on the `Authentication` icon in the left sidebar
- Click on [`Providers`](https://supabase.com/dashboard/project/_/auth/providers) under the Configuration section
- Click on **GitLab** from the accordion list to expand and you'll find your **Callback URL**, you can click `Copy` to copy it to the clipboard

For testing OAuth locally with the Supabase CLI please see the [local development docs](https://supabase.com/docs/guides/cli/local-development#use-auth-locally).

## Create your GitLab application [\#](https://supabase.com/docs/guides/auth/social-login/auth-gitlab\#create-your-gitlab-application)

- Click on your `profile logo` (avatar) in the top-right corner.
- Select `Edit profile`.
- In the left sidebar, select Applications.
- Enter the name of the application.
- In the `Redirect URI` box, type the callback URL of your app.
- Check the box next to `Confidential` (make sure it is checked).
- Check the scope named `read_user` (this is the only required scope).
- Click `Save Application` at the bottom.
- Copy and save your `Application ID` ( `client_id`) and `Secret` ( `client_secret`) which you'll need later.

## Add your GitLab credentials into your Supabase project [\#](https://supabase.com/docs/guides/auth/social-login/auth-gitlab\#add-your-gitlab-credentials-into-your-supabase-project)

- Go to your [Supabase Project Dashboard](https://supabase.com/dashboard)
- In the left sidebar, click the `Authentication` icon (near the top)
- Click on [`Providers`](https://supabase.com/dashboard/project/_/auth/providers) under the Configuration section
- Click on **GitLab** from the accordion list to expand and turn **GitLab Enabled** to ON
- Enter your **GitLab Client ID** and **GitLab Client Secret** saved in the previous step
- Click `Save`

## Add login code to your client app [\#](https://supabase.com/docs/guides/auth/social-login/auth-gitlab\#add-login-code-to-your-client-app)

JavaScriptFlutterKotlin

Make sure you're using the right `supabase` client in the following code.

If you're not using Server-Side Rendering or cookie-based Auth, you can directly use the `createClient` from `@supabase/supabase-js`. If you're using Server-Side Rendering, see the [Server-Side Auth guide](https://supabase.com/docs/guides/auth/server-side/creating-a-client) for instructions on creating your Supabase client.

When your user signs in, call [`signInWithOAuth()`](https://supabase.com/docs/reference/javascript/auth-signinwithoauth) with `gitlab` as the `provider`:

`
async function signInWithGitLab() {
const { data, error } = await supabase.auth.signInWithOAuth({
    provider: 'gitlab',
})
}
`

For a PKCE flow, for example in Server-Side Auth, you need an extra step to handle the code exchange. When calling `signInWithOAuth`, provide a `redirectTo` URL which points to a callback route. This redirect URL should be added to your [redirect allow list](https://supabase.com/docs/guides/auth/redirect-urls).

ClientServer

In the browser, `signInWithOAuth` automatically redirects to the OAuth provider's authentication endpoint, which then redirects to your endpoint.

``
await supabase.auth.signInWithOAuth({
provider,
options: {
    redirectTo: `http://example.com/auth/callback`,
},
})
``

At the callback endpoint, handle the code exchange to save the user session.

Next.jsSvelteKitAstroRemixExpress

Create a new file at `app/auth/callback/route.ts` and populate with the following:

app/auth/callback/route.ts

``
import { NextResponse } from 'next/server'
// The client you created from the Server-Side Auth instructions
import { createClient } from '@/utils/supabase/server'
export async function GET(request: Request) {
const { searchParams, origin } = new URL(request.url)
const code = searchParams.get('code')
// if "next" is in param, use it as the redirect URL
const next = searchParams.get('next') ?? '/'
if (code) {
    const supabase = await createClient()
    const { error } = await supabase.auth.exchangeCodeForSession(code)
    if (!error) {
      const forwardedHost = request.headers.get('x-forwarded-host') // original origin before load balancer
      const isLocalEnv = process.env.NODE_ENV === 'development'
      if (isLocalEnv) {
        // we can be sure that there is no load balancer in between, so no need to watch for X-Forwarded-Host
        return NextResponse.redirect(`${origin}${next}`)
      } else if (forwardedHost) {
        return NextResponse.redirect(`https://${forwardedHost}${next}`)
      } else {
        return NextResponse.redirect(`${origin}${next}`)
      }
    }
}
// return the user to an error page with instructions
return NextResponse.redirect(`${origin}/auth/auth-code-error`)
}
``

JavaScriptFlutterKotlin

When your user signs out, call [signOut()](https://supabase.com/docs/reference/javascript/auth-signout) to remove them from the browser session and any objects from localStorage:

`
async function signOut() {
const { error } = await supabase.auth.signOut()
}
`

## Resources [\#](https://supabase.com/docs/guides/auth/social-login/auth-gitlab\#resources)

- [Supabase - Get started for free](https://supabase.com/)
- [Supabase JS Client](https://github.com/supabase/supabase-js)
- [GitLab Account](https://gitlab.com/)

### Is this helpful?

NoYes

### On this page

[Overview](https://supabase.com/docs/guides/auth/social-login/auth-gitlab#overview) [Access your GitLab account](https://supabase.com/docs/guides/auth/social-login/auth-gitlab#access-your-gitlab-account) [Find your callback URL](https://supabase.com/docs/guides/auth/social-login/auth-gitlab#find-your-callback-url) [Create your GitLab application](https://supabase.com/docs/guides/auth/social-login/auth-gitlab#create-your-gitlab-application) [Add your GitLab credentials into your Supabase project](https://supabase.com/docs/guides/auth/social-login/auth-gitlab#add-your-gitlab-credentials-into-your-supabase-project) [Add login code to your client app](https://supabase.com/docs/guides/auth/social-login/auth-gitlab#add-login-code-to-your-client-app) [Resources](https://supabase.com/docs/guides/auth/social-login/auth-gitlab#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_social_login_auth_google.md">
Auth

# Login with Google

* * *

Supabase Auth supports Sign in with Google for the web, native Android applications, and Chrome extensions.

## Prerequisites [\#](https://supabase.com/docs/guides/auth/social-login/auth-google\#prerequisites)

- A Google Cloud project. Go to the [Google Cloud Platform](https://console.cloud.google.com/home/dashboard) and create a new project if necessary.

## Configuration [\#](https://supabase.com/docs/guides/auth/social-login/auth-google\#configuration)

To support Sign In with Google, you need to configure the Google provider for your Supabase project.

WebExpo React NativeFlutterSwiftAndroid (Kotlin)Chrome Extensions

For web applications, you can set up your signin button two different ways:

- Use your own [application code](https://supabase.com/docs/guides/auth/social-login/auth-google#application-code) for the button.
- Use [Google's pre-built sign-in or One Tap flows](https://supabase.com/docs/guides/auth/social-login/auth-google#google-pre-built).

### Application code configuration [\#](https://supabase.com/docs/guides/auth/social-login/auth-google\#application-code-configuration)

To use your own application code:

1. In the Google Cloud console, go to the [Consent Screen configuration page](https://console.cloud.google.com/apis/credentials/consent). The consent screen is the view shown to your users when they consent to signing in to your app.

2. Under **Authorized domains**, add your Supabase project's domain, which has the form `<PROJECT_ID>.supabase.co`.

3. Configure the following non-sensitive scopes:
   - `.../auth/userinfo.email`
   - `...auth/userinfo.profile`
   - `openid`
4. Go to the [API Credentials page](https://console.cloud.google.com/apis/credentials).

5. Click `Create credentials` and choose `OAuth Client ID`.

6. For application type, choose `Web application`.

7. Under **Authorized JavaScript origins**, add your site URL.

8. Under **Authorized redirect URLs**, enter the callback URL from the [Supabase dashboard](https://supabase.com/dashboard/project/_/auth/providers). Expand the Google Auth Provider section to display it.





The redirect URL is visible to your users. You can customize it by configuring [custom domains](https://supabase.com/docs/guides/platform/custom-domains).

9. When you finish configuring your credentials, you will be shown your client ID and secret. Add these to the [Google Auth Provider section of the Supabase Dashboard](https://supabase.com/dashboard/project/_/auth/providers).





In local development, you can add the client ID and secret to your `config.toml` file.


### Google pre-built configuration [\#](https://supabase.com/docs/guides/auth/social-login/auth-google\#google-pre-built-configuration)

To use Google's pre-built signin buttons:

1. In the Google Cloud console, go to the [Consent Screen configuration page](https://console.cloud.google.com/apis/credentials/consent). The consent screen is the view shown to your users when they consent to signing in to your app.
2. Configure the screen to your liking, making sure you add links to your app's privacy policy and terms of service.
3. Go to the [API Credentials page](https://console.cloud.google.com/apis/credentials).
4. Click `Create credentials` and choose `OAuth Client ID`.
5. For application type, choose `Web application`.
6. Under **Authorized JavaScript origins** and **Authorized redirect URLs**, add your site URL. This is the URL of the website where the signin button will appear, _not_ your Supabase project domain. If you're testing in localhost, ensure that you have `http://localhost` set in the **Authorized JavaScript origins** section as well. This is important when integrating with Google One-Tap to ensure you can use it locally.
7. When you finish configuring your credentials, you will be shown your client ID. Add this to the **Client IDs** field in the [Google Auth Provider section of the Supabase Dashboard](https://supabase.com/dashboard/project/_/auth/providers). Leave the OAuth client ID and secret blank. You don't need them when using Google's pre-built approach.

## Signing users in [\#](https://supabase.com/docs/guides/auth/social-login/auth-google\#signing-users-in)

WebExpo React NativeFlutterAndroid (Kotlin)Chrome Extensions

### Application code [\#](https://supabase.com/docs/guides/auth/social-login/auth-google\#application-code)

To use your own application code for the signin button, call the `signInWithOAuth` method (or the equivalent for your language).

Make sure you're using the right `supabase` client in the following code.

If you're not using Server-Side Rendering or cookie-based Auth, you can directly use the `createClient` from `@supabase/supabase-js`. If you're using Server-Side Rendering, see the [Server-Side Auth guide](https://supabase.com/docs/guides/auth/server-side/creating-a-client) for instructions on creating your Supabase client.

`
supabase.auth.signInWithOAuth({
provider: 'google',
})
`

For an implicit flow, that's all you need to do. The user will be taken to Google's consent screen, and finally redirected to your app with an access and refresh token pair representing their session.

For a PKCE flow, for example in Server-Side Auth, you need an extra step to handle the code exchange. When calling `signInWithOAuth`, provide a `redirectTo` URL which points to a callback route. This redirect URL should be added to your [redirect allow list](https://supabase.com/docs/guides/auth/redirect-urls).

ClientServer

In the browser, `signInWithOAuth` automatically redirects to the OAuth provider's authentication endpoint, which then redirects to your endpoint.

``
await supabase.auth.signInWithOAuth({
provider,
options: {
    redirectTo: `http://example.com/auth/callback`,
},
})
``

At the callback endpoint, handle the code exchange to save the user session.

Next.jsSvelteKitAstroRemixExpress

Create a new file at `app/auth/callback/route.ts` and populate with the following:

app/auth/callback/route.ts

``
import { NextResponse } from 'next/server'
// The client you created from the Server-Side Auth instructions
import { createClient } from '@/utils/supabase/server'
export async function GET(request: Request) {
const { searchParams, origin } = new URL(request.url)
const code = searchParams.get('code')
// if "next" is in param, use it as the redirect URL
const next = searchParams.get('next') ?? '/'
if (code) {
    const supabase = await createClient()
    const { error } = await supabase.auth.exchangeCodeForSession(code)
    if (!error) {
      const forwardedHost = request.headers.get('x-forwarded-host') // original origin before load balancer
      const isLocalEnv = process.env.NODE_ENV === 'development'
      if (isLocalEnv) {
        // we can be sure that there is no load balancer in between, so no need to watch for X-Forwarded-Host
        return NextResponse.redirect(`${origin}${next}`)
      } else if (forwardedHost) {
        return NextResponse.redirect(`https://${forwardedHost}${next}`)
      } else {
        return NextResponse.redirect(`${origin}${next}`)
      }
    }
}
// return the user to an error page with instructions
return NextResponse.redirect(`${origin}/auth/auth-code-error`)
}
``

After a successful code exchange, the user's session will be saved to cookies.

### Saving Google tokens [\#](https://supabase.com/docs/guides/auth/social-login/auth-google\#saving-google-tokens)

The tokens saved by your application are the Supabase Auth tokens. Your app might additionally need the Google OAuth 2.0 tokens to access Google services on the user's behalf.

On initial login, you can extract the `provider_token` from the session and store it in a secure storage medium. The session is available in the returned data from `signInWithOAuth` (implicit flow) and `exchangeCodeForSession` (PKCE flow).

Google does not send out a refresh token by default, so you will need to pass parameters like these to `signInWithOAuth()` in order to extract the `provider_refresh_token`:

`
const { data, error } = await supabase.auth.signInWithOAuth({
provider: 'google',
options: {
    queryParams: {
      access_type: 'offline',
      prompt: 'consent',
    },
},
})
`

### Google pre-built [\#](https://supabase.com/docs/guides/auth/social-login/auth-google\#google-pre-built)

Most web apps and websites can utilize Google's [personalized sign-in buttons](https://developers.google.com/identity/gsi/web/guides/personalized-button), [One Tap](https://developers.google.com/identity/gsi/web/guides/features) or [automatic sign-in](https://developers.google.com/identity/gsi/web/guides/automatic-sign-in-sign-out) for the best user experience.

1. Load the Google client library in your app by including the third-party script:



`
<script src="https://accounts.google.com/gsi/client" async></script>
`

2. Use the [HTML Code Generator](https://developers.google.com/identity/gsi/web/tools/configurator) to customize the look, feel, features and behavior of the Sign in with Google button.

3. Pick the _Swap to JavaScript callback_ option, and input the name of your callback function. This function will receive a [`CredentialResponse`](https://developers.google.com/identity/gsi/web/reference/js-reference#CredentialResponse) when sign in completes.

To make your app compatible with Chrome's third-party-cookie phase-out, make sure to set `data-use_fedcm_for_prompt` to `true`.

Your final HTML code might look something like this:



`
<div
id="g_id_onload"
data-client_id="<client ID>"
data-context="signin"
data-ux_mode="popup"
data-callback="handleSignInWithGoogle"
data-nonce=""
data-auto_select="true"
data-itp_support="true"
data-use_fedcm_for_prompt="true"
></div>
<div
class="g_id_signin"
data-type="standard"
data-shape="pill"
data-theme="outline"
data-text="signin_with"
data-size="large"
data-logo_alignment="left"
></div>
`

4. Create a `handleSignInWithGoogle` function that takes the `CredentialResponse` and passes the included token to Supabase. The function needs to be available in the global scope for Google's code to find it.



`
async function handleSignInWithGoogle(response) {
const { data, error } = await supabase.auth.signInWithIdToken({
       provider: 'google',
       token: response.credential,
})
}
`

5. _(Optional)_ Configure a nonce. The use of a nonce is recommended for extra security, but optional. The nonce should be generated randomly each time, and it must be provided in both the `data-nonce` attribute of the HTML code and the options of the callback function.



`
async function handleSignInWithGoogle(response) {
const { data, error } = await supabase.auth.signInWithIdToken({
       provider: 'google',
       token: response.credential,
       nonce: '<NONCE>',
})
}
`



Note that the nonce should be the same in both places, but because Supabase Auth expects the provider to hash it (SHA-256, hexadecimal representation), you need to provide a hashed version to Google and a non-hashed version to `signInWithIdToken`.

You can get both versions by using the in-built `crypto` library:



`
// Adapted from https://developer.mozilla.org/en-US/docs/Web/API/SubtleCrypto/digest#converting_a_digest_to_a_hex_string
const nonce = btoa(String.fromCharCode(...crypto.getRandomValues(new Uint8Array(32))))
const encoder = new TextEncoder()
const encodedNonce = encoder.encode(nonce)
crypto.subtle.digest('SHA-256', encodedNonce).then((hashBuffer) => {
const hashArray = Array.from(new Uint8Array(hashBuffer))
const hashedNonce = hashArray.map((b) => b.toString(16).padStart(2, '0')).join('')
})
// Use 'hashedNonce' when making the authentication request to Google
// Use 'nonce' when invoking the supabase.auth.signInWithIdToken() method
`


### One-tap with Next.js [\#](https://supabase.com/docs/guides/auth/social-login/auth-google\#one-tap-with-nextjs)

If you're integrating Google One-Tap with your Next.js application, you can refer to the example below to get started:

`
'use client'
import Script from 'next/script'
import { createClient } from '@/utils/supabase/client'
import { CredentialResponse } from 'google-one-tap'
import { useRouter } from 'next/navigation'
import { useEffect } from 'react'
const OneTapComponent = () => {
const supabase = createClient()
const router = useRouter()
// generate nonce to use for google id token sign-in
const generateNonce = async (): Promise<string[]> => {
    const nonce = btoa(String.fromCharCode(...crypto.getRandomValues(new Uint8Array(32))))
    const encoder = new TextEncoder()
    const encodedNonce = encoder.encode(nonce)
    const hashBuffer = await crypto.subtle.digest('SHA-256', encodedNonce)
    const hashArray = Array.from(new Uint8Array(hashBuffer))
    const hashedNonce = hashArray.map((b) => b.toString(16).padStart(2, '0')).join('')
    return [nonce, hashedNonce]
}
useEffect(() => {
    const initializeGoogleOneTap = () => {
      console.log('Initializing Google One Tap')
      window.addEventListener('load', async () => {
        const [nonce, hashedNonce] = await generateNonce()
        console.log('Nonce: ', nonce, hashedNonce)
        // check if there's already an existing session before initializing the one-tap UI
        const { data, error } = await supabase.auth.getSession()
        if (error) {
          console.error('Error getting session', error)
        }
        if (data.session) {
          router.push('/')
          return
        }
        /* global google */
        google.accounts.id.initialize({
          client_id: process.env.NEXT_PUBLIC_GOOGLE_CLIENT_ID,
          callback: async (response: CredentialResponse) => {
            try {
              // send id token returned in response.credential to supabase
              const { data, error } = await supabase.auth.signInWithIdToken({
                provider: 'google',
                token: response.credential,
                nonce,
              })
              if (error) throw error
              console.log('Session data: ', data)
              console.log('Successfully logged in with Google One Tap')
              // redirect to protected page
              router.push('/')
            } catch (error) {
              console.error('Error logging in with Google One Tap', error)
            }
          },
          nonce: hashedNonce,
          // with chrome's removal of third-party cookiesm, we need to use FedCM instead (https://developers.google.com/identity/gsi/web/guides/fedcm-migration)
          use_fedcm_for_prompt: true,
        })
        google.accounts.id.prompt() // Display the One Tap UI
      })
    }
    initializeGoogleOneTap()
    return () => window.removeEventListener('load', initializeGoogleOneTap)
}, [])
return (
    <>
      <Script src="https://accounts.google.com/gsi/client" />
      <div id="oneTap" className="fixed top-0 right-0 z-[100]" />
    </>
)
}
export default OneTapComponent
`

## Google consent screen [\#](https://supabase.com/docs/guides/auth/social-login/auth-google\#google-consent-screen)

![Google Consent Screen](https://supabase.com/docs/img/guides/auth-google/auth-google-consent-screen.png)

By default, the Google consent screen shows the root domain of the callback URL, where Google will send the authentication response. With Supabase Auth, it is your Supabase project's domain `(https://<your-project-ref>.supabase.co)`.

If that is not preferable, you can use a [Custom Domain](https://supabase.com/docs/guides/platform/custom-domains) with your Supabase project. You can use it as your project's domain when creating the Supabase client in your application and initiating the authentication flow. It will then show up in the Google consent screen. If you want your app name and the logo on the consent screen, [you must submit your app to Google for verification](https://support.google.com/cloud/answer/10311615).

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2FvojHmGUGUGc%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Prerequisites](https://supabase.com/docs/guides/auth/social-login/auth-google#prerequisites) [Configuration](https://supabase.com/docs/guides/auth/social-login/auth-google#configuration) [Application code configuration](https://supabase.com/docs/guides/auth/social-login/auth-google#application-code-configuration) [Google pre-built configuration](https://supabase.com/docs/guides/auth/social-login/auth-google#google-pre-built-configuration) [Signing users in](https://supabase.com/docs/guides/auth/social-login/auth-google#signing-users-in) [Application code](https://supabase.com/docs/guides/auth/social-login/auth-google#application-code) [Saving Google tokens](https://supabase.com/docs/guides/auth/social-login/auth-google#saving-google-tokens) [Google pre-built](https://supabase.com/docs/guides/auth/social-login/auth-google#google-pre-built) [One-tap with Next.js](https://supabase.com/docs/guides/auth/social-login/auth-google#one-tap-with-nextjs) [Google consent screen](https://supabase.com/docs/guides/auth/social-login/auth-google#google-consent-screen)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_social_login_auth_kakao.md">
Auth

# Login with Kakao

* * *

To enable Kakao Auth for your project, you need to set up an Kakao OAuth application and add the application credentials to your Supabase Dashboard.

## Overview [\#](https://supabase.com/docs/guides/auth/social-login/auth-kakao\#overview)

Kakao OAuth consists of six broad steps:

- Create and configure your app in the [Kakao Developer Portal](https://developers.kakao.com/).
- Obtaining a `REST API key` \- this will serve as the `client_id`.
- Generating the `Client secret code` \- this will serve as the `client_secret`.
- Additional configurations on Kakao Developers Portal.
- Add your `client id` and `client secret` keys to your [Supabase Project](https://supabase.com/dashboard).
- Add the login code to your [Supabase JS Client App](https://github.com/supabase/supabase-js).

## Access your Kakao Developer account [\#](https://supabase.com/docs/guides/auth/social-login/auth-kakao\#access-your-kakao-developer-account)

- Go to [Kakao Developers Portal](https://developers.kakao.com/).
- Click on `Login` at the top right to log in.

![Kakao Developers Portal.](https://supabase.com/docs/img/guides/auth-kakao/kakao-developers-page.png)

## Create and configure your app [\#](https://supabase.com/docs/guides/auth/social-login/auth-kakao\#create-and-configure-your-app)

- Go to `My Application`.
- Click on `Add an application` at the top.
- Fill out your app information:
  - App icon.
  - App name.
  - Company name.
- Click `Save` at the bottom right.

## Obtain a REST API key [\#](https://supabase.com/docs/guides/auth/social-login/auth-kakao\#obtain-a-rest-api-key)

This will serve as the `client_id` when you make API calls to authenticate the user.

- Go to `My Application`.
- Click on your app.
- You will be redirected to `Summary` tab of your app.
- In the `App Keys` section you will see `REST API key` \-\- this ID will become your `client_id` later.

## Find your callback URL [\#](https://supabase.com/docs/guides/auth/social-login/auth-kakao\#find-your-callback-url)

The next step requires a callback URL, which looks like this: `https://<project-ref>.supabase.co/auth/v1/callback`

- Go to your [Supabase Project Dashboard](https://supabase.com/dashboard)
- Click on the `Authentication` icon in the left sidebar
- Click on [`Providers`](https://supabase.com/dashboard/project/_/auth/providers) under the Configuration section
- Click on **Kakao** from the accordion list to expand and you'll find your **Callback URL**, you can click `Copy` to copy it to the clipboard

For testing OAuth locally with the Supabase CLI please see the [local development docs](https://supabase.com/docs/guides/cli/local-development#use-auth-locally).

\- To add callback URL on Kakao, go to `Product settings` >
`Kakao Login` \> `Redirect URI`.

## Generate and activate a `client_secret` [\#](https://supabase.com/docs/guides/auth/social-login/auth-kakao\#generate-and-activate-a-clientsecret)

- Go to `Product settings` \> `Kakao Login` \> `Security`.
- Click on the `Kakao Login` switch to enable Kakao Login.
- Click on `generate code` at the bottom to generate the `Client secret code` \-\- this will serve as a `client_secret` for your Supabase project.
- Make sure you enabled `Client secret code` by selecting `enable` from the `Activation state` section.

## Additional configurations on Kakao Developers portal [\#](https://supabase.com/docs/guides/auth/social-login/auth-kakao\#additional-configurations-on-kakao-developers-portal)

- Make sure the Kakao Login is enabled in the `Kakao Login` tab.
- Set following scopes under the "Consent Items": account\_email, profile\_image, profile\_nickname

![Consent items needs to be set.](https://supabase.com/docs/img/guides/auth-kakao/kakao-developers-consent-items-set.png)

## Add your OAuth credentials to Supabase [\#](https://supabase.com/docs/guides/auth/social-login/auth-kakao\#add-your-oauth-credentials-to-supabase)

- Go to your [Supabase Project Dashboard](https://supabase.com/dashboard)
- In the left sidebar, click the `Authentication` icon (near the top)
- Click on [`Providers`](https://supabase.com/dashboard/project/_/auth/providers) under the Configuration section
- Click on **Kakao** from the accordion list to expand and turn **Kakao Enabled** to ON
- Enter your **Kakao Client ID** and **Kakao Client Secret** saved in the previous step
- Click `Save`

## Add login code to your client app [\#](https://supabase.com/docs/guides/auth/social-login/auth-kakao\#add-login-code-to-your-client-app)

JavaScriptFlutterKotlin

Make sure you're using the right `supabase` client in the following code.

If you're not using Server-Side Rendering or cookie-based Auth, you can directly use the `createClient` from `@supabase/supabase-js`. If you're using Server-Side Rendering, see the [Server-Side Auth guide](https://supabase.com/docs/guides/auth/server-side/creating-a-client) for instructions on creating your Supabase client.

When your user signs in, call [`signInWithOAuth()`](https://supabase.com/docs/reference/javascript/auth-signinwithoauth) with `kakao` as the `provider`:

`
async function signInWithKakao() {
const { data, error } = await supabase.auth.signInWithOAuth({
    provider: 'kakao',
})
}
`

For a PKCE flow, for example in Server-Side Auth, you need an extra step to handle the code exchange. When calling `signInWithOAuth`, provide a `redirectTo` URL which points to a callback route. This redirect URL should be added to your [redirect allow list](https://supabase.com/docs/guides/auth/redirect-urls).

ClientServer

In the browser, `signInWithOAuth` automatically redirects to the OAuth provider's authentication endpoint, which then redirects to your endpoint.

``
await supabase.auth.signInWithOAuth({
provider,
options: {
    redirectTo: `http://example.com/auth/callback`,
},
})
``

At the callback endpoint, handle the code exchange to save the user session.

Next.jsSvelteKitAstroRemixExpress

Create a new file at `app/auth/callback/route.ts` and populate with the following:

app/auth/callback/route.ts

``
import { NextResponse } from 'next/server'
// The client you created from the Server-Side Auth instructions
import { createClient } from '@/utils/supabase/server'
export async function GET(request: Request) {
const { searchParams, origin } = new URL(request.url)
const code = searchParams.get('code')
// if "next" is in param, use it as the redirect URL
const next = searchParams.get('next') ?? '/'
if (code) {
    const supabase = await createClient()
    const { error } = await supabase.auth.exchangeCodeForSession(code)
    if (!error) {
      const forwardedHost = request.headers.get('x-forwarded-host') // original origin before load balancer
      const isLocalEnv = process.env.NODE_ENV === 'development'
      if (isLocalEnv) {
        // we can be sure that there is no load balancer in between, so no need to watch for X-Forwarded-Host
        return NextResponse.redirect(`${origin}${next}`)
      } else if (forwardedHost) {
        return NextResponse.redirect(`https://${forwardedHost}${next}`)
      } else {
        return NextResponse.redirect(`${origin}${next}`)
      }
    }
}
// return the user to an error page with instructions
return NextResponse.redirect(`${origin}/auth/auth-code-error`)
}
``

JavaScriptFlutterKotlin

When your user signs out, call [signOut()](https://supabase.com/docs/reference/javascript/auth-signout) to remove them from the browser session and any objects from localStorage:

`
async function signOut() {
const { error } = await supabase.auth.signOut()
}
`

## Using Kakao Login JS SDK [\#](https://supabase.com/docs/guides/auth/social-login/auth-kakao\#using-kakao-login-js-sdk)

[Kakao Login JS SDK](https://developers.kakao.com/docs/latest/en/kakaologin/js) is an official Kakao SDK for authenticating Kakao users on websites.

Exchange the [authorization code returned by Kakao API](https://developers.kakao.com/docs/latest/en/kakaologin/rest-api#request-code) for an [ID Token](https://developers.kakao.com/docs/latest/en/kakaologin/common#login-with-oidc).

For example, this code shows a how to get ID Token:

`
const requestUrl = new URL(request.url);
const code = requestUrl.searchParams.get('code');
if (code) {
const res = await fetch('https://kauth.kakao.com/oauth/token', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8',
    },
    body: new URLSearchParams({
      grant_type: 'authorization_code',
      client_id: '<CLIENT_ID>',
      redirect_uri: '<url>/api/auth/kakao/oidc',
      code,
      client_secret: '<CLIENT_SECRET>',
    }),
});
const {id_token} = await res.json();
}
`

Use the ID Token to sign in:

`
const res = await auth.signInWithIdToken({
provider: 'kakao',
token: id_token,
});
`

### Configuration [\#](https://supabase.com/docs/guides/auth/social-login/auth-kakao\#configuration)

1. Set 'State' to 'ON' under [OpenID Connect Activation](https://developers.kakao.com/docs/latest/en/kakaologin/prerequisite#activate-oidc) on Kakao Developers portal Application Dashboard.
2. Add `openid` to [scope](https://developers.kakao.com/docs/latest/en/kakaologin/common#additional-consent-scope) along with the scope values you wish to obtain consent for.

## Resources [\#](https://supabase.com/docs/guides/auth/social-login/auth-kakao\#resources)

- [Kakao Developers Portal](https://developers.kakao.com/).

### Is this helpful?

NoYes

### On this page

[Overview](https://supabase.com/docs/guides/auth/social-login/auth-kakao#overview) [Access your Kakao Developer account](https://supabase.com/docs/guides/auth/social-login/auth-kakao#access-your-kakao-developer-account) [Create and configure your app](https://supabase.com/docs/guides/auth/social-login/auth-kakao#create-and-configure-your-app) [Obtain a REST API key](https://supabase.com/docs/guides/auth/social-login/auth-kakao#obtain-a-rest-api-key) [Find your callback URL](https://supabase.com/docs/guides/auth/social-login/auth-kakao#find-your-callback-url) [Generate and activate a client\_secret](https://supabase.com/docs/guides/auth/social-login/auth-kakao#generate-and-activate-a-clientsecret) [Additional configurations on Kakao Developers portal](https://supabase.com/docs/guides/auth/social-login/auth-kakao#additional-configurations-on-kakao-developers-portal) [Add your OAuth credentials to Supabase](https://supabase.com/docs/guides/auth/social-login/auth-kakao#add-your-oauth-credentials-to-supabase) [Add login code to your client app](https://supabase.com/docs/guides/auth/social-login/auth-kakao#add-login-code-to-your-client-app) [Using Kakao Login JS SDK](https://supabase.com/docs/guides/auth/social-login/auth-kakao#using-kakao-login-js-sdk) [Configuration](https://supabase.com/docs/guides/auth/social-login/auth-kakao#configuration) [Resources](https://supabase.com/docs/guides/auth/social-login/auth-kakao#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_social_login_auth_keycloak.md">
Auth

# Login with Keycloak

* * *

To enable Keycloak Auth for your project, you need to set up an Keycloak OAuth application and add the application credentials to your Supabase Dashboard.

## Overview [\#](https://supabase.com/docs/guides/auth/social-login/auth-keycloak\#overview)

To get started with Keycloak, you can run it in a docker container with: `docker run -p 8080:8080 -e KEYCLOAK_ADMIN=admin -e KEYCLOAK_ADMIN_PASSWORD=admin quay.io/keycloak/keycloak:latest start-dev`

This guide will be assuming that you are running Keycloak in a docker container as described in the command above.

Keycloak OAuth consists of five broad steps:

- Create a new client in your specified Keycloak realm.
- Obtain the `issuer` from the "OpenID Endpoint Configuration". This will be used as the `Keycloak URL`.
- Ensure that the new client has the "Client Protocol" set to `openid-connect` and the "Access Type" is set to "confidential".
- The `Client ID` of the client created will be used as the `client id`.
- Obtain the `Secret` from the credentials tab which will be used as the `client secret`.
- Add the callback URL of your application to your allowlist.

## Access your Keycloak admin console [\#](https://supabase.com/docs/guides/auth/social-login/auth-keycloak\#access-your-keycloak-admin-console)

- Login by visiting [`http://localhost:8080`](http://localhost:8080/) and clicking on "Administration Console".

## Create a Keycloak realm [\#](https://supabase.com/docs/guides/auth/social-login/auth-keycloak\#create-a-keycloak-realm)

- Once you've logged in to the Keycloak console, you can add a realm from the side panel. The default realm should be named "Master".
- After you've added a new realm, you can retrieve the `issuer` from the "OpenID Endpoint Configuration" endpoint. The `issuer` will be used as the `Keycloak URL`.
- You can find this endpoint from the realm settings under the "General Tab" or visit [`http://localhost:8080/realms/my_realm_name/.well-known/openid-configuration`](http://localhost:8080/realms/my_realm_name/.well-known/openid-configuration)

![Add a Keycloak Realm.](https://supabase.com/docs/img/guides/auth-keycloak/keycloak-create-realm.png)

## Create a Keycloak client [\#](https://supabase.com/docs/guides/auth/social-login/auth-keycloak\#create-a-keycloak-client)

The "Client ID" of the created client will serve as the `client_id` when you make API calls to authenticate the user.

![Add a Keycloak client](https://supabase.com/docs/img/guides/auth-keycloak/keycloak-add-client.png)

## Client settings [\#](https://supabase.com/docs/guides/auth/social-login/auth-keycloak\#client-settings)

After you've created the client successfully, ensure that you set the following settings:

1. The "Client Protocol" should be set to `openid-connect`.
2. The "Access Type" should be set to "confidential".
3. The "Valid Redirect URIs" should be set to: `https://<project-ref>.supabase.co/auth/v1/callback`.

![Obtain the client id, set the client protocol and access type](https://supabase.com/docs/img/guides/auth-keycloak/keycloak-client-id.png)![Set redirect uri](https://supabase.com/docs/img/guides/auth-keycloak/keycloak-redirect-uri.png)

## Obtain the client secret [\#](https://supabase.com/docs/guides/auth/social-login/auth-keycloak\#obtain-the-client-secret)

This will serve as the `client_secret` when you make API calls to authenticate the user.
Under the "Credentials" tab, the `Secret` value will be used as the `client secret`.

![Obtain the client secret](https://supabase.com/docs/img/guides/auth-keycloak/keycloak-client-secret.png)

## Add login code to your client app [\#](https://supabase.com/docs/guides/auth/social-login/auth-keycloak\#add-login-code-to-your-client-app)

Since Keycloak version 22, the `openid` scope must be passed. Add this to the [`supabase.auth.signInWithOAuth()`](https://supabase.com/docs/reference/javascript/auth-signinwithoauth) method.

JavaScriptFlutterKotlin

Make sure you're using the right `supabase` client in the following code.

If you're not using Server-Side Rendering or cookie-based Auth, you can directly use the `createClient` from `@supabase/supabase-js`. If you're using Server-Side Rendering, see the [Server-Side Auth guide](https://supabase.com/docs/guides/auth/server-side/creating-a-client) for instructions on creating your Supabase client.

When your user signs in, call [`signInWithOAuth()`](https://supabase.com/docs/reference/javascript/auth-signinwithoauth) with `keycloak` as the `provider`:

`
async function signInWithKeycloak() {
const { data, error } = await supabase.auth.signInWithOAuth({
    provider: 'keycloak',
    options: {
      scopes: 'openid',
    },
})
}
`

For a PKCE flow, for example in Server-Side Auth, you need an extra step to handle the code exchange. When calling `signInWithOAuth`, provide a `redirectTo` URL which points to a callback route. This redirect URL should be added to your [redirect allow list](https://supabase.com/docs/guides/auth/redirect-urls).

ClientServer

In the browser, `signInWithOAuth` automatically redirects to the OAuth provider's authentication endpoint, which then redirects to your endpoint.

``
await supabase.auth.signInWithOAuth({
provider,
options: {
    redirectTo: `http://example.com/auth/callback`,
},
})
``

At the callback endpoint, handle the code exchange to save the user session.

Next.jsSvelteKitAstroRemixExpress

Create a new file at `app/auth/callback/route.ts` and populate with the following:

app/auth/callback/route.ts

``
import { NextResponse } from 'next/server'
// The client you created from the Server-Side Auth instructions
import { createClient } from '@/utils/supabase/server'
export async function GET(request: Request) {
const { searchParams, origin } = new URL(request.url)
const code = searchParams.get('code')
// if "next" is in param, use it as the redirect URL
const next = searchParams.get('next') ?? '/'
if (code) {
    const supabase = await createClient()
    const { error } = await supabase.auth.exchangeCodeForSession(code)
    if (!error) {
      const forwardedHost = request.headers.get('x-forwarded-host') // original origin before load balancer
      const isLocalEnv = process.env.NODE_ENV === 'development'
      if (isLocalEnv) {
        // we can be sure that there is no load balancer in between, so no need to watch for X-Forwarded-Host
        return NextResponse.redirect(`${origin}${next}`)
      } else if (forwardedHost) {
        return NextResponse.redirect(`https://${forwardedHost}${next}`)
      } else {
        return NextResponse.redirect(`${origin}${next}`)
      }
    }
}
// return the user to an error page with instructions
return NextResponse.redirect(`${origin}/auth/auth-code-error`)
}
``

JavaScriptFlutterKotlin

When your user signs out, call [signOut()](https://supabase.com/docs/reference/javascript/auth-signout) to remove them from the browser session and any objects from localStorage:

`
async function signOut() {
const { error } = await supabase.auth.signOut()
}
`

## Resources [\#](https://supabase.com/docs/guides/auth/social-login/auth-keycloak\#resources)

- You can find the Keycloak OpenID endpoint configuration under the realm settings.
![Keycloak OpenID Endpoint Configuration](https://supabase.com/docs/img/guides/auth-keycloak/keycloak-openid-endpoint-config.png)

### Is this helpful?

NoYes

### On this page

[Overview](https://supabase.com/docs/guides/auth/social-login/auth-keycloak#overview) [Access your Keycloak admin console](https://supabase.com/docs/guides/auth/social-login/auth-keycloak#access-your-keycloak-admin-console) [Create a Keycloak realm](https://supabase.com/docs/guides/auth/social-login/auth-keycloak#create-a-keycloak-realm) [Create a Keycloak client](https://supabase.com/docs/guides/auth/social-login/auth-keycloak#create-a-keycloak-client) [Client settings](https://supabase.com/docs/guides/auth/social-login/auth-keycloak#client-settings) [Obtain the client secret](https://supabase.com/docs/guides/auth/social-login/auth-keycloak#obtain-the-client-secret) [Add login code to your client app](https://supabase.com/docs/guides/auth/social-login/auth-keycloak#add-login-code-to-your-client-app) [Resources](https://supabase.com/docs/guides/auth/social-login/auth-keycloak#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_social_login_auth_linkedin.md">
Auth

# Login with LinkedIn

* * *

To enable LinkedIn Auth for your project, you need to set up a LinkedIn OAuth application and add the application credentials to your Supabase Dashboard.

## Overview [\#](https://supabase.com/docs/guides/auth/social-login/auth-linkedin\#overview)

Setting up LinkedIn logins for your application consists of 3 parts:

- Create and configure a LinkedIn Project and App on the [LinkedIn Developer Dashboard](https://www.linkedin.com/developers/apps).
- Add your _LinkedIn (OIDC)_ `client_id` and `client_secret` to your [Supabase Project](https://supabase.com/dashboard).
- Add the login code to your [Supabase JS Client App](https://github.com/supabase/supabase-js).

## Access your LinkedIn Developer account [\#](https://supabase.com/docs/guides/auth/social-login/auth-linkedin\#access-your-linkedin-developer-account)

- Go to [LinkedIn Developer Dashboard](https://www.linkedin.com/developers/apps).
- Log in (if necessary.)

![LinkedIn Developer Portal](https://supabase.com/docs/img/guides/auth-linkedin/linkedin_developers_page.png)

## Find your callback URL [\#](https://supabase.com/docs/guides/auth/social-login/auth-linkedin\#find-your-callback-url)

The next step requires a callback URL, which looks like this: `https://<project-ref>.supabase.co/auth/v1/callback`

- Go to your [Supabase Project Dashboard](https://supabase.com/dashboard)
- Click on the `Authentication` icon in the left sidebar
- Click on [`Providers`](https://supabase.com/dashboard/project/_/auth/providers) under the Configuration section
- Click on **LinkedIn** from the accordion list to expand and you'll find your **Callback URL**, you can click `Copy` to copy it to the clipboard

For testing OAuth locally with the Supabase CLI please see the [local development docs](https://supabase.com/docs/guides/cli/local-development#use-auth-locally).

## Create a LinkedIn OAuth app [\#](https://supabase.com/docs/guides/auth/social-login/auth-linkedin\#create-a-linkedin-oauth-app)

- Go to [LinkedIn Developer Dashboard](https://www.linkedin.com/developers/apps).
- Click on `Create App` at the top right
- Enter your `LinkedIn Page` and `App Logo`
- Save your app
- Click `Products` from the top menu
- Look for `Sign In with LinkedIn using OpenID Connect` and click on Request Access
- Click `Auth` from the top menu
- Add your `Redirect URL` to the `Authorized Redirect URLs for your app` section
- Copy and save your newly-generated `Client ID`
- Copy and save your newly-generated `Client Secret`

Ensure that the appropriate scopes have been added under OAuth 2.0 Scopes at the bottom of the `Auth` screen.

![Required OAuth 2.0 Scopes](https://supabase.com/docs/img/guides/auth-linkedin/oauth-scopes.png)

## Enter your LinkedIn (OIDC) credentials into your Supabase project [\#](https://supabase.com/docs/guides/auth/social-login/auth-linkedin\#enter-your-linkedin-oidc-credentials-into-your-supabase-project)

- Go to your [Supabase Project Dashboard](https://supabase.com/dashboard)
- In the left sidebar, click the `Authentication` icon (near the top)
- Click on [`Providers`](https://supabase.com/dashboard/project/_/auth/providers) under the Configuration section
- Click on **LinkedIn (OIDC)** from the accordion list to expand and turn **LinkedIn (OIDC) Enabled** to ON
- Enter your **LinkedIn (OIDC) Client ID** and **LinkedIn (OIDC) Client Secret** saved in the previous step
- Click `Save`

## Add login code to your client app [\#](https://supabase.com/docs/guides/auth/social-login/auth-linkedin\#add-login-code-to-your-client-app)

JavaScriptFlutterKotlin

Make sure you're using the right `supabase` client in the following code.

If you're not using Server-Side Rendering or cookie-based Auth, you can directly use the `createClient` from `@supabase/supabase-js`. If you're using Server-Side Rendering, see the [Server-Side Auth guide](https://supabase.com/docs/guides/auth/server-side/creating-a-client) for instructions on creating your Supabase client.

When your user signs in, call [`signInWithOAuth()`](https://supabase.com/docs/reference/javascript/auth-signinwithoauth) with `linkedin_oidc` as the `provider`:

`
async function signInWithLinkedIn() {
const { data, error } = await supabase.auth.signInWithOAuth({
    provider: 'linkedin_oidc',
})
}
`

For a PKCE flow, for example in Server-Side Auth, you need an extra step to handle the code exchange. When calling `signInWithOAuth`, provide a `redirectTo` URL which points to a callback route. This redirect URL should be added to your [redirect allow list](https://supabase.com/docs/guides/auth/redirect-urls).

ClientServer

In the browser, `signInWithOAuth` automatically redirects to the OAuth provider's authentication endpoint, which then redirects to your endpoint.

``
await supabase.auth.signInWithOAuth({
provider,
options: {
    redirectTo: `http://example.com/auth/callback`,
},
})
``

At the callback endpoint, handle the code exchange to save the user session.

Next.jsSvelteKitAstroRemixExpress

Create a new file at `app/auth/callback/route.ts` and populate with the following:

app/auth/callback/route.ts

``
import { NextResponse } from 'next/server'
// The client you created from the Server-Side Auth instructions
import { createClient } from '@/utils/supabase/server'
export async function GET(request: Request) {
const { searchParams, origin } = new URL(request.url)
const code = searchParams.get('code')
// if "next" is in param, use it as the redirect URL
const next = searchParams.get('next') ?? '/'
if (code) {
    const supabase = await createClient()
    const { error } = await supabase.auth.exchangeCodeForSession(code)
    if (!error) {
      const forwardedHost = request.headers.get('x-forwarded-host') // original origin before load balancer
      const isLocalEnv = process.env.NODE_ENV === 'development'
      if (isLocalEnv) {
        // we can be sure that there is no load balancer in between, so no need to watch for X-Forwarded-Host
        return NextResponse.redirect(`${origin}${next}`)
      } else if (forwardedHost) {
        return NextResponse.redirect(`https://${forwardedHost}${next}`)
      } else {
        return NextResponse.redirect(`${origin}${next}`)
      }
    }
}
// return the user to an error page with instructions
return NextResponse.redirect(`${origin}/auth/auth-code-error`)
}
``

JavaScriptFlutterKotlin

When your user signs out, call [signOut()](https://supabase.com/docs/reference/javascript/auth-signout) to remove them from the browser session and any objects from localStorage:

`
async function signOut() {
const { error } = await supabase.auth.signOut()
}
`

## LinkedIn Open ID Connect (OIDC) [\#](https://supabase.com/docs/guides/auth/social-login/auth-linkedin\#linkedin-open-id-connect-oidc)

We will be replacing the _LinkedIn_ provider with a new _LinkedIn (OIDC)_ provider to support recent changes to the LinkedIn [OAuth APIs](https://learn.microsoft.com/en-us/linkedin/shared/authentication/authorization-code-flow?context=linkedin%2Fcontext&tabs=HTTPS1). The new provider utilizes the [Open ID Connect standard](https://learn.microsoft.com/en-us/linkedin/consumer/integrations/self-serve/sign-in-with-linkedin-v2#validating-id-tokens). In view of this change, we have disabled edits on the _LinkedIn_ provider and will be removing it effective 4th January 2024. Developers with LinkedIn OAuth Applications created prior to 1st August 2023 should create a new OAuth application [via the steps outlined above](https://supabase.com/docs/guides/auth/social-login/auth-linkedin#create-a-linkedin-oauth-app) and migrate their credentials from the _LinkedIn_ provider to the _LinkedIn (OIDC)_ provider. Alternatively, you can also head to the `Products` section and add the newly release `Sign In with LinkedIn using OpenID Connect` to your existing OAuth application.

Developers using the Supabase CLI to test their LinkedIn OAuth application should also update their `config.toml` to make use of the new provider:

`
[auth.external.linkedin_oidc]
enabled = true
client_id = ...
secret = ...
`

Do reach out to support if you have any concerns around this change.

## Resources [\#](https://supabase.com/docs/guides/auth/social-login/auth-linkedin\#resources)

- [Supabase - Get started for free](https://supabase.com/)
- [Supabase JS Client](https://github.com/supabase/supabase-js)
- [LinkedIn Developer Dashboard](https://api.linkedin.com/apps)

### Is this helpful?

NoYes

### On this page

[Overview](https://supabase.com/docs/guides/auth/social-login/auth-linkedin#overview) [Access your LinkedIn Developer account](https://supabase.com/docs/guides/auth/social-login/auth-linkedin#access-your-linkedin-developer-account) [Find your callback URL](https://supabase.com/docs/guides/auth/social-login/auth-linkedin#find-your-callback-url) [Create a LinkedIn OAuth app](https://supabase.com/docs/guides/auth/social-login/auth-linkedin#create-a-linkedin-oauth-app) [Enter your LinkedIn (OIDC) credentials into your Supabase project](https://supabase.com/docs/guides/auth/social-login/auth-linkedin#enter-your-linkedin-oidc-credentials-into-your-supabase-project) [Add login code to your client app](https://supabase.com/docs/guides/auth/social-login/auth-linkedin#add-login-code-to-your-client-app) [LinkedIn Open ID Connect (OIDC)](https://supabase.com/docs/guides/auth/social-login/auth-linkedin#linkedin-open-id-connect-oidc) [Resources](https://supabase.com/docs/guides/auth/social-login/auth-linkedin#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_social_login_auth_notion.md">
Auth

# Login with Notion

* * *

To enable Notion Auth for your project, you need to set up a Notion Application and add the Application OAuth credentials to your Supabase Dashboard.

## Overview [\#](https://supabase.com/docs/guides/auth/social-login/auth-notion\#overview)

Setting up Notion logins for your application consists of 3 parts:

- Create and configure a Notion Application [Notion Developer Portal](https://www.notion.so/my-integrations)
- Retrieve your OAuth client ID and OAuth client secret and add them to your [Supabase Project](https://supabase.com/dashboard)
- Add the login code to your [Supabase JS Client App](https://github.com/supabase/supabase-js)

## Create your notion integration [\#](https://supabase.com/docs/guides/auth/social-login/auth-notion\#create-your-notion-integration)

- Go to [developers.notion.com](https://developers.notion.com/).

- Click "View my integrations" and login.
![notion.so](https://supabase.com/docs/img/guides/auth-notion/notion.png)

- Once logged in, go to [notion.so/my-integrations](https://notion.so/my-integrations) and create a new integration.

- When creating your integration, ensure that you select "Public integration" under "Integration type" and "Read user information including email addresses" under "Capabilities".

- You will need to add a redirect URI, see [Add the redirect URI](https://supabase.com/docs/guides/auth/social-login/auth-notion#add-the-redirect-uri)

- Once you've filled in the necessary fields, click "Submit" to finish creating the integration.


![notion.so](https://supabase.com/docs/img/guides/auth-notion/notion-developer.png)

## Add the redirect URI [\#](https://supabase.com/docs/guides/auth/social-login/auth-notion\#add-the-redirect-uri)

- After selecting "Public integration", you should see an option to add "Redirect URIs".

![notion.so](https://supabase.com/docs/img/guides/auth-notion/notion-redirect-uri.png)

The next step requires a callback URL, which looks like this: `https://<project-ref>.supabase.co/auth/v1/callback`

- Go to your [Supabase Project Dashboard](https://supabase.com/dashboard)
- Click on the `Authentication` icon in the left sidebar
- Click on [`Providers`](https://supabase.com/dashboard/project/_/auth/providers) under the Configuration section
- Click on **Notion** from the accordion list to expand and you'll find your **Callback URL**, you can click `Copy` to copy it to the clipboard

For testing OAuth locally with the Supabase CLI please see the [local development docs](https://supabase.com/docs/guides/cli/local-development#use-auth-locally).

## Add your Notion credentials into your Supabase project [\#](https://supabase.com/docs/guides/auth/social-login/auth-notion\#add-your-notion-credentials-into-your-supabase-project)

- Once you've created your notion integration, you should be able to retrieve the "OAuth client ID" and "OAuth client secret" from the "OAuth Domain and URIs" tab.

![notion.so](https://supabase.com/docs/img/guides/auth-notion/notion-creds.png)

- Go to your [Supabase Project Dashboard](https://supabase.com/dashboard)
- In the left sidebar, click the `Authentication` icon (near the top)
- Click on [`Providers`](https://supabase.com/dashboard/project/_/auth/providers) under the Configuration section
- Click on **Notion** from the accordion list to expand and turn **Notion Enabled** to ON
- Enter your **Notion Client ID** and **Notion Client Secret** saved in the previous step
- Click `Save`

## Add login code to your client app [\#](https://supabase.com/docs/guides/auth/social-login/auth-notion\#add-login-code-to-your-client-app)

JavaScriptFlutterKotlin

Make sure you're using the right `supabase` client in the following code.

If you're not using Server-Side Rendering or cookie-based Auth, you can directly use the `createClient` from `@supabase/supabase-js`. If you're using Server-Side Rendering, see the [Server-Side Auth guide](https://supabase.com/docs/guides/auth/server-side/creating-a-client) for instructions on creating your Supabase client.

When your user signs in, call [`signInWithOAuth()`](https://supabase.com/docs/reference/javascript/auth-signinwithoauth) with `notion` as the `provider`:

`
async function signInWithNotion() {
const { data, error } = await supabase.auth.signInWithOAuth({
    provider: 'notion',
})
}
`

For a PKCE flow, for example in Server-Side Auth, you need an extra step to handle the code exchange. When calling `signInWithOAuth`, provide a `redirectTo` URL which points to a callback route. This redirect URL should be added to your [redirect allow list](https://supabase.com/docs/guides/auth/redirect-urls).

ClientServer

In the browser, `signInWithOAuth` automatically redirects to the OAuth provider's authentication endpoint, which then redirects to your endpoint.

``
await supabase.auth.signInWithOAuth({
provider,
options: {
    redirectTo: `http://example.com/auth/callback`,
},
})
``

At the callback endpoint, handle the code exchange to save the user session.

Next.jsSvelteKitAstroRemixExpress

Create a new file at `app/auth/callback/route.ts` and populate with the following:

app/auth/callback/route.ts

``
import { NextResponse } from 'next/server'
// The client you created from the Server-Side Auth instructions
import { createClient } from '@/utils/supabase/server'
export async function GET(request: Request) {
const { searchParams, origin } = new URL(request.url)
const code = searchParams.get('code')
// if "next" is in param, use it as the redirect URL
const next = searchParams.get('next') ?? '/'
if (code) {
    const supabase = await createClient()
    const { error } = await supabase.auth.exchangeCodeForSession(code)
    if (!error) {
      const forwardedHost = request.headers.get('x-forwarded-host') // original origin before load balancer
      const isLocalEnv = process.env.NODE_ENV === 'development'
      if (isLocalEnv) {
        // we can be sure that there is no load balancer in between, so no need to watch for X-Forwarded-Host
        return NextResponse.redirect(`${origin}${next}`)
      } else if (forwardedHost) {
        return NextResponse.redirect(`https://${forwardedHost}${next}`)
      } else {
        return NextResponse.redirect(`${origin}${next}`)
      }
    }
}
// return the user to an error page with instructions
return NextResponse.redirect(`${origin}/auth/auth-code-error`)
}
``

JavaScriptFlutterKotlin

When your user signs out, call [signOut()](https://supabase.com/docs/reference/javascript/auth-signout) to remove them from the browser session and any objects from localStorage:

`
async function signOut() {
const { error } = await supabase.auth.signOut()
}
`

## Resources [\#](https://supabase.com/docs/guides/auth/social-login/auth-notion\#resources)

- [Supabase - Get started for free](https://supabase.com/)
- [Supabase JS Client](https://github.com/supabase/supabase-js)
- [Notion Account](https://notion.so/)
- [Notion Developer Portal](https://www.notion.so/my-integrations)

### Is this helpful?

NoYes

### On this page

[Overview](https://supabase.com/docs/guides/auth/social-login/auth-notion#overview) [Create your notion integration](https://supabase.com/docs/guides/auth/social-login/auth-notion#create-your-notion-integration) [Add the redirect URI](https://supabase.com/docs/guides/auth/social-login/auth-notion#add-the-redirect-uri) [Add your Notion credentials into your Supabase project](https://supabase.com/docs/guides/auth/social-login/auth-notion#add-your-notion-credentials-into-your-supabase-project) [Add login code to your client app](https://supabase.com/docs/guides/auth/social-login/auth-notion#add-login-code-to-your-client-app) [Resources](https://supabase.com/docs/guides/auth/social-login/auth-notion#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_social_login_auth_slack.md">
Auth

# Login with Slack

* * *

To enable Slack Auth for your project, you need to set up a Slack OAuth application and add the application credentials to your Supabase Dashboard.

## Overview [\#](https://supabase.com/docs/guides/auth/social-login/auth-slack\#overview)

We will be replacing the existing Slack provider with a new Slack (OIDC) provider. Developers with Slack OAuth Applications created prior to 24th June 2024 should create a new application and migrate their credentials from the Slack provider to the Slack (OIDC) provider. Existing OAuth Applications built with the old Slack provider will continue to work up till 10th October. You can refer to the [**list of supported scopes**](https://api.slack.com/scopes?filter=user) for the new Slack (OIDC) User.

Setting up Slack logins for your application consists of 3 parts:

- Create and configure a Slack Project and App on the [Slack Developer Dashboard](https://api.slack.com/apps).
- Add your Slack `API Key` and `API Secret Key` to your [Supabase Project](https://supabase.com/dashboard).
- Add the login code to your [Supabase JS Client App](https://github.com/supabase/supabase-js).

## Access your Slack Developer account [\#](https://supabase.com/docs/guides/auth/social-login/auth-slack\#access-your-slack-developer-account)

- Go to [api.slack.com](https://api.slack.com/apps).
- Click on `Your Apps` at the top right to log in.

![Slack Developer Portal.](https://supabase.com/docs/img/guides/auth-slack/slack-portal.png)

## Find your callback URL [\#](https://supabase.com/docs/guides/auth/social-login/auth-slack\#find-your-callback-url)

The next step requires a callback URL, which looks like this: `https://<project-ref>.supabase.co/auth/v1/callback`

- Go to your [Supabase Project Dashboard](https://supabase.com/dashboard)
- Click on the `Authentication` icon in the left sidebar
- Click on [`Providers`](https://supabase.com/dashboard/project/_/auth/providers) under the Configuration section
- Click on **Slack** from the accordion list to expand and you'll find your **Callback URL**, you can click `Copy` to copy it to the clipboard

For testing OAuth locally with the Supabase CLI please see the [local development docs](https://supabase.com/docs/guides/cli/local-development#use-auth-locally).

## Create a Slack OAuth app [\#](https://supabase.com/docs/guides/auth/social-login/auth-slack\#create-a-slack-oauth-app)

- Go to [api.slack.com](https://api.slack.com/apps).
- Click on `Create New App`

Under `Create an app...`:

- Click `From scratch`
- Type the name of your app
- Select your `Slack Workspace`
- Click `Create App`

Under `App Credentials`:

- Copy and save your newly-generated `Client ID`
- Copy and save your newly-generated `Client Secret`

Under the sidebar, select `OAuth & Permissions` and look for `Redirect URLs`:

- Click `Add New Redirect URL`
- Paste your `Callback URL` then click `Add`
- Click `Save URLs`

Under `Scopes`:

- Add the following scopes under the `User Token Scopes`: `profile`, `email`, `openid`. These scopes are the default scopes that Supabase Auth uses to request for user information. Do not add other scopes as [Sign In With Slack only supports `profile`, `email`, `openid`](https://api.slack.com/authentication/sign-in-with-slack#request).

## Enter your Slack credentials into your Supabase project [\#](https://supabase.com/docs/guides/auth/social-login/auth-slack\#enter-your-slack-credentials-into-your-supabase-project)

- Go to your [Supabase Project Dashboard](https://supabase.com/dashboard)
- In the left sidebar, click the `Authentication` icon (near the top)
- Click on [`Providers`](https://supabase.com/dashboard/project/_/auth/providers) under the Configuration section
- Click on **Slack** from the accordion list to expand and turn **Slack Enabled** to ON
- Enter your **Slack Client ID** and **Slack Client Secret** saved in the previous step
- Click `Save`

## Add login code to your client app [\#](https://supabase.com/docs/guides/auth/social-login/auth-slack\#add-login-code-to-your-client-app)

JavaScriptFlutterKotlin

Make sure you're using the right `supabase` client in the following code.

If you're not using Server-Side Rendering or cookie-based Auth, you can directly use the `createClient` from `@supabase/supabase-js`. If you're using Server-Side Rendering, see the [Server-Side Auth guide](https://supabase.com/docs/guides/auth/server-side/creating-a-client) for instructions on creating your Supabase client.

When your user signs in, call [`signInWithOAuth()`](https://supabase.com/docs/reference/javascript/auth-signinwithoauth) with `slack_oidc` as the `provider`:

`
async function signInWithSlack() {
const { data, error } = await supabase.auth.signInWithOAuth({
    provider: 'slack_oidc',
})
}
`

For a PKCE flow, for example in Server-Side Auth, you need an extra step to handle the code exchange. When calling `signInWithOAuth`, provide a `redirectTo` URL which points to a callback route. This redirect URL should be added to your [redirect allow list](https://supabase.com/docs/guides/auth/redirect-urls).

ClientServer

In the browser, `signInWithOAuth` automatically redirects to the OAuth provider's authentication endpoint, which then redirects to your endpoint.

``
await supabase.auth.signInWithOAuth({
provider,
options: {
    redirectTo: `http://example.com/auth/callback`,
},
})
``

At the callback endpoint, handle the code exchange to save the user session.

Next.jsSvelteKitAstroRemixExpress

Create a new file at `app/auth/callback/route.ts` and populate with the following:

app/auth/callback/route.ts

``
import { NextResponse } from 'next/server'
// The client you created from the Server-Side Auth instructions
import { createClient } from '@/utils/supabase/server'
export async function GET(request: Request) {
const { searchParams, origin } = new URL(request.url)
const code = searchParams.get('code')
// if "next" is in param, use it as the redirect URL
const next = searchParams.get('next') ?? '/'
if (code) {
    const supabase = await createClient()
    const { error } = await supabase.auth.exchangeCodeForSession(code)
    if (!error) {
      const forwardedHost = request.headers.get('x-forwarded-host') // original origin before load balancer
      const isLocalEnv = process.env.NODE_ENV === 'development'
      if (isLocalEnv) {
        // we can be sure that there is no load balancer in between, so no need to watch for X-Forwarded-Host
        return NextResponse.redirect(`${origin}${next}`)
      } else if (forwardedHost) {
        return NextResponse.redirect(`https://${forwardedHost}${next}`)
      } else {
        return NextResponse.redirect(`${origin}${next}`)
      }
    }
}
// return the user to an error page with instructions
return NextResponse.redirect(`${origin}/auth/auth-code-error`)
}
``

JavaScriptFlutterKotlin

When your user signs out, call [signOut()](https://supabase.com/docs/reference/javascript/auth-signout) to remove them from the browser session and any objects from localStorage:

`
async function signOut() {
const { error } = await supabase.auth.signOut()
}
`

## Resources [\#](https://supabase.com/docs/guides/auth/social-login/auth-slack\#resources)

- [Supabase - Get started for free](https://supabase.com/)
- [Supabase JS Client](https://github.com/supabase/supabase-js)
- [Slack Developer Dashboard](https://api.slack.com/apps)

### Is this helpful?

NoYes

### On this page

[Overview](https://supabase.com/docs/guides/auth/social-login/auth-slack#overview) [Access your Slack Developer account](https://supabase.com/docs/guides/auth/social-login/auth-slack#access-your-slack-developer-account) [Find your callback URL](https://supabase.com/docs/guides/auth/social-login/auth-slack#find-your-callback-url) [Create a Slack OAuth app](https://supabase.com/docs/guides/auth/social-login/auth-slack#create-a-slack-oauth-app) [Enter your Slack credentials into your Supabase project](https://supabase.com/docs/guides/auth/social-login/auth-slack#enter-your-slack-credentials-into-your-supabase-project) [Add login code to your client app](https://supabase.com/docs/guides/auth/social-login/auth-slack#add-login-code-to-your-client-app) [Resources](https://supabase.com/docs/guides/auth/social-login/auth-slack#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_social_login_auth_spotify.md">
Auth

# Login with Spotify

* * *

To enable Spotify Auth for your project, you need to set up a Spotify OAuth application and add the application credentials to your Supabase Dashboard.

## Overview [\#](https://supabase.com/docs/guides/auth/social-login/auth-spotify\#overview)

Setting up Spotify logins for your application consists of 3 parts:

- Create and configure a Spotify Project and App on the [Spotify Developer Dashboard](https://developer.spotify.com/dashboard/).
- Add your Spotify `API Key` and `API Secret Key` to your [Supabase Project](https://supabase.com/dashboard).
- Add the login code to your [Supabase JS Client App](https://github.com/supabase/supabase-js).

## Access your Spotify Developer account [\#](https://supabase.com/docs/guides/auth/social-login/auth-spotify\#access-your-spotify-developer-account)

- Log into [Spotify](https://spotify.com/)
- Access the [Spotify Developer Dashboard](https://developer.spotify.com/dashboard)

![Spotify Developer Portal.](https://supabase.com/docs/img/guides/auth-spotify/spotify-portal.png)

## Find your callback URL [\#](https://supabase.com/docs/guides/auth/social-login/auth-spotify\#find-your-callback-url)

The next step requires a callback URL, which looks like this: `https://<project-ref>.supabase.co/auth/v1/callback`

- Go to your [Supabase Project Dashboard](https://supabase.com/dashboard)
- Click on the `Authentication` icon in the left sidebar
- Click on [`Providers`](https://supabase.com/dashboard/project/_/auth/providers) under the Configuration section
- Click on **Spotify** from the accordion list to expand and you'll find your **Callback URL**, you can click `Copy` to copy it to the clipboard

For testing OAuth locally with the Supabase CLI please see the [local development docs](https://supabase.com/docs/guides/cli/local-development#use-auth-locally).

## Create a Spotify OAuth app [\#](https://supabase.com/docs/guides/auth/social-login/auth-spotify\#create-a-spotify-oauth-app)

- Log into [Spotify](https://spotify.com/).
- Go to the [Spotify Developer Dashboard](https://developer.spotify.com/dashboard)
- Click `Create an App`
- Type your `App name`
- Type your `App description`
- Check the box to agree with the `Developer TOS and Branding Guidelines`
- Click `Create`
- Save your `Client ID`
- Save your `Client Secret`
- Click `Edit Settings`

Under `Redirect URIs`:

- Paste your Supabase Callback URL in the box
- Click `Add`
- Click `Save` at the bottom

## Enter your Spotify credentials into your Supabase project [\#](https://supabase.com/docs/guides/auth/social-login/auth-spotify\#enter-your-spotify-credentials-into-your-supabase-project)

- Go to your [Supabase Project Dashboard](https://supabase.com/dashboard)
- In the left sidebar, click the `Authentication` icon (near the top)
- Click on [`Providers`](https://supabase.com/dashboard/project/_/auth/providers) under the Configuration section
- Click on **Spotify** from the accordion list to expand and turn **Spotify Enabled** to ON
- Enter your **Spotify Client ID** and **Spotify Client Secret** saved in the previous step
- Click `Save`

## Add login code to your client app [\#](https://supabase.com/docs/guides/auth/social-login/auth-spotify\#add-login-code-to-your-client-app)

The following outlines the steps to sign in using Spotify with Supabase Auth.

1. Call the signin method from the client library.
2. The user is redirected to the Spotify login page.
3. After completing the sign-in process, the user will be redirected to your app with an error that says the email address needs to be confirmed. Simultaneously the user receives a confirmation email from Supabase Auth.
4. The user clicks the confirmation link in the email.
5. The user is brought back to the app and is now signed in.

JavaScriptFlutterKotlin

Make sure you're using the right `supabase` client in the following code.

If you're not using Server-Side Rendering or cookie-based Auth, you can directly use the `createClient` from `@supabase/supabase-js`. If you're using Server-Side Rendering, see the [Server-Side Auth guide](https://supabase.com/docs/guides/auth/server-side/creating-a-client) for instructions on creating your Supabase client.

When your user signs in, call [`signInWithOAuth()`](https://supabase.com/docs/reference/javascript/auth-signinwithoauth) with `spotify` as the `provider`:

`
async function signInWithSpotify() {
const { data, error } = await supabase.auth.signInWithOAuth({
    provider: 'spotify',
})
}
`

For a PKCE flow, for example in Server-Side Auth, you need an extra step to handle the code exchange. When calling `signInWithOAuth`, provide a `redirectTo` URL which points to a callback route. This redirect URL should be added to your [redirect allow list](https://supabase.com/docs/guides/auth/redirect-urls).

ClientServer

In the browser, `signInWithOAuth` automatically redirects to the OAuth provider's authentication endpoint, which then redirects to your endpoint.

``
await supabase.auth.signInWithOAuth({
provider,
options: {
    redirectTo: `http://example.com/auth/callback`,
},
})
``

At the callback endpoint, handle the code exchange to save the user session.

Next.jsSvelteKitAstroRemixExpress

Create a new file at `app/auth/callback/route.ts` and populate with the following:

app/auth/callback/route.ts

``
import { NextResponse } from 'next/server'
// The client you created from the Server-Side Auth instructions
import { createClient } from '@/utils/supabase/server'
export async function GET(request: Request) {
const { searchParams, origin } = new URL(request.url)
const code = searchParams.get('code')
// if "next" is in param, use it as the redirect URL
const next = searchParams.get('next') ?? '/'
if (code) {
    const supabase = await createClient()
    const { error } = await supabase.auth.exchangeCodeForSession(code)
    if (!error) {
      const forwardedHost = request.headers.get('x-forwarded-host') // original origin before load balancer
      const isLocalEnv = process.env.NODE_ENV === 'development'
      if (isLocalEnv) {
        // we can be sure that there is no load balancer in between, so no need to watch for X-Forwarded-Host
        return NextResponse.redirect(`${origin}${next}`)
      } else if (forwardedHost) {
        return NextResponse.redirect(`https://${forwardedHost}${next}`)
      } else {
        return NextResponse.redirect(`${origin}${next}`)
      }
    }
}
// return the user to an error page with instructions
return NextResponse.redirect(`${origin}/auth/auth-code-error`)
}
``

JavaScriptFlutterKotlin

When your user signs out, call [signOut()](https://supabase.com/docs/reference/javascript/auth-signout) to remove them from the browser session and any objects from localStorage:

`
async function signOut() {
const { error } = await supabase.auth.signOut()
}
`

## Resources [\#](https://supabase.com/docs/guides/auth/social-login/auth-spotify\#resources)

- [Supabase - Get started for free](https://supabase.com/)
- [Supabase JS Client](https://github.com/supabase/supabase-js)
- [Spotify Developer Dashboard](https://developer.spotify.com/dashboard/)

### Is this helpful?

NoYes

### On this page

[Overview](https://supabase.com/docs/guides/auth/social-login/auth-spotify#overview) [Access your Spotify Developer account](https://supabase.com/docs/guides/auth/social-login/auth-spotify#access-your-spotify-developer-account) [Find your callback URL](https://supabase.com/docs/guides/auth/social-login/auth-spotify#find-your-callback-url) [Create a Spotify OAuth app](https://supabase.com/docs/guides/auth/social-login/auth-spotify#create-a-spotify-oauth-app) [Enter your Spotify credentials into your Supabase project](https://supabase.com/docs/guides/auth/social-login/auth-spotify#enter-your-spotify-credentials-into-your-supabase-project) [Add login code to your client app](https://supabase.com/docs/guides/auth/social-login/auth-spotify#add-login-code-to-your-client-app) [Resources](https://supabase.com/docs/guides/auth/social-login/auth-spotify#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_social_login_auth_twitch.md">
Auth

# Login with Twitch

* * *

To enable Twitch Auth for your project, you need to set up a Twitch Application and add the Application OAuth credentials to your Supabase Dashboard.

## Overview [\#](https://supabase.com/docs/guides/auth/social-login/auth-twitch\#overview)

Setting up Twitch logins for your application consists of 3 parts:

- Create and configure a Twitch Application [Twitch Developer Console](https://dev.twitch.tv/console)
- Add your Twitch OAuth Consumer keys to your [Supabase Project](https://supabase.com/dashboard)
- Add the login code to your [Supabase JS Client App](https://github.com/supabase/supabase-js)

## Access your Twitch Developer account [\#](https://supabase.com/docs/guides/auth/social-login/auth-twitch\#access-your-twitch-developer-account)

- Go to [dev.twitch.tv](https://dev.twitch.tv/).
- Click on `Log in with Twitch` at the top right to log in.
- If you have not already enabled 2-Factor Authentication for your Twitch Account, you will need to do that at [Twitch Security Settings](https://www.twitch.tv/settings/security) before you can continue.

![Twitch Developer Page](https://supabase.com/docs/img/guides/auth-twitch/twitch-developer-page.png)

- Once logged in, go to the [Twitch Developer Console](https://dev.twitch.tv/console).

![Twitch Developer Console](https://supabase.com/docs/img/guides/auth-twitch/twitch-console.png)

## Find your callback URL [\#](https://supabase.com/docs/guides/auth/social-login/auth-twitch\#find-your-callback-url)

The next step requires a callback URL, which looks like this: `https://<project-ref>.supabase.co/auth/v1/callback`

- Go to your [Supabase Project Dashboard](https://supabase.com/dashboard)
- Click on the `Authentication` icon in the left sidebar
- Click on [`Providers`](https://supabase.com/dashboard/project/_/auth/providers) under the Configuration section
- Click on **Twitch** from the accordion list to expand and you'll find your **Callback URL**, you can click `Copy` to copy it to the clipboard

For testing OAuth locally with the Supabase CLI please see the [local development docs](https://supabase.com/docs/guides/cli/local-development#use-auth-locally).

## Create a Twitch application [\#](https://supabase.com/docs/guides/auth/social-login/auth-twitch\#create-a-twitch-application)

![Twitch Developer Console](https://supabase.com/docs/img/guides/auth-twitch/twitch-console.png)

- Click on `+ Register Your Application` at the top right.

![Register Application](https://supabase.com/docs/img/guides/auth-twitch/twitch-register-your-application.png)

- Enter the name of your application.
- Type or paste your `OAuth Redirect URL` (the callback URL from the previous step.)
- Select a category for your app.
- Check the CAPTCHA box and click `Create`.

## Retrieve your Twitch OAuth client ID and client secret [\#](https://supabase.com/docs/guides/auth/social-login/auth-twitch\#retrieve-your-twitch-oauth-client-id-and-client-secret)

- Click `Manage` at the right of your application entry in the list.

![Twitch Applications List](https://supabase.com/docs/img/guides/auth-twitch/twitch-applications-list.png)

- Copy your Client ID.
- Click `New Secret` to create a new Client Secret.
- Copy your Client Secret.

![Get Client ID and Secret](https://supabase.com/docs/img/guides/auth-twitch/twitch-get-keys.png)

## Add your Twitch credentials into your Supabase project [\#](https://supabase.com/docs/guides/auth/social-login/auth-twitch\#add-your-twitch-credentials-into-your-supabase-project)

- Go to your [Supabase Project Dashboard](https://supabase.com/dashboard)
- In the left sidebar, click the `Authentication` icon (near the top)
- Click on [`Providers`](https://supabase.com/dashboard/project/_/auth/providers) under the Configuration section
- Click on **Twitch** from the accordion list to expand and turn **Twitch Enabled** to ON
- Enter your **Twitch Client ID** and **Twitch Client Secret** saved in the previous step
- Click `Save`

## Add login code to your client app [\#](https://supabase.com/docs/guides/auth/social-login/auth-twitch\#add-login-code-to-your-client-app)

JavaScriptFlutterKotlin

Make sure you're using the right `supabase` client in the following code.

If you're not using Server-Side Rendering or cookie-based Auth, you can directly use the `createClient` from `@supabase/supabase-js`. If you're using Server-Side Rendering, see the [Server-Side Auth guide](https://supabase.com/docs/guides/auth/server-side/creating-a-client) for instructions on creating your Supabase client.

When your user signs in, call [`signInWithOAuth()`](https://supabase.com/docs/reference/javascript/auth-signinwithoauth) with `twitch` as the `provider`:

`
async function signInWithTwitch() {
const { data, error } = await supabase.auth.signInWithOAuth({
    provider: 'twitch',
})
}
`

For a PKCE flow, for example in Server-Side Auth, you need an extra step to handle the code exchange. When calling `signInWithOAuth`, provide a `redirectTo` URL which points to a callback route. This redirect URL should be added to your [redirect allow list](https://supabase.com/docs/guides/auth/redirect-urls).

ClientServer

In the browser, `signInWithOAuth` automatically redirects to the OAuth provider's authentication endpoint, which then redirects to your endpoint.

``
await supabase.auth.signInWithOAuth({
provider,
options: {
    redirectTo: `http://example.com/auth/callback`,
},
})
``

At the callback endpoint, handle the code exchange to save the user session.

Next.jsSvelteKitAstroRemixExpress

Create a new file at `app/auth/callback/route.ts` and populate with the following:

app/auth/callback/route.ts

``
import { NextResponse } from 'next/server'
// The client you created from the Server-Side Auth instructions
import { createClient } from '@/utils/supabase/server'
export async function GET(request: Request) {
const { searchParams, origin } = new URL(request.url)
const code = searchParams.get('code')
// if "next" is in param, use it as the redirect URL
const next = searchParams.get('next') ?? '/'
if (code) {
    const supabase = await createClient()
    const { error } = await supabase.auth.exchangeCodeForSession(code)
    if (!error) {
      const forwardedHost = request.headers.get('x-forwarded-host') // original origin before load balancer
      const isLocalEnv = process.env.NODE_ENV === 'development'
      if (isLocalEnv) {
        // we can be sure that there is no load balancer in between, so no need to watch for X-Forwarded-Host
        return NextResponse.redirect(`${origin}${next}`)
      } else if (forwardedHost) {
        return NextResponse.redirect(`https://${forwardedHost}${next}`)
      } else {
        return NextResponse.redirect(`${origin}${next}`)
      }
    }
}
// return the user to an error page with instructions
return NextResponse.redirect(`${origin}/auth/auth-code-error`)
}
``

JavaScriptFlutterKotlin

When your user signs out, call [signOut()](https://supabase.com/docs/reference/javascript/auth-signout) to remove them from the browser session and any objects from localStorage:

`
async function signOut() {
const { error } = await supabase.auth.signOut()
}
`

## Resources [\#](https://supabase.com/docs/guides/auth/social-login/auth-twitch\#resources)

- [Supabase - Get started for free](https://supabase.com/)
- [Supabase JS Client](https://github.com/supabase/supabase-js)
- [Twitch Account](https://twitch.tv/)
- [Twitch Developer Console](https://dev.twitch.tv/console)

### Is this helpful?

NoYes

### On this page

[Overview](https://supabase.com/docs/guides/auth/social-login/auth-twitch#overview) [Access your Twitch Developer account](https://supabase.com/docs/guides/auth/social-login/auth-twitch#access-your-twitch-developer-account) [Find your callback URL](https://supabase.com/docs/guides/auth/social-login/auth-twitch#find-your-callback-url) [Create a Twitch application](https://supabase.com/docs/guides/auth/social-login/auth-twitch#create-a-twitch-application) [Retrieve your Twitch OAuth client ID and client secret](https://supabase.com/docs/guides/auth/social-login/auth-twitch#retrieve-your-twitch-oauth-client-id-and-client-secret) [Add your Twitch credentials into your Supabase project](https://supabase.com/docs/guides/auth/social-login/auth-twitch#add-your-twitch-credentials-into-your-supabase-project) [Add login code to your client app](https://supabase.com/docs/guides/auth/social-login/auth-twitch#add-login-code-to-your-client-app) [Resources](https://supabase.com/docs/guides/auth/social-login/auth-twitch#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_social_login_auth_twitter.md">
Auth

# Login with Twitter

* * *

To enable Twitter Auth for your project, you need to set up a Twitter OAuth application and add the application credentials in the Supabase Dashboard.

## Overview [\#](https://supabase.com/docs/guides/auth/social-login/auth-twitter\#overview)

Setting up Twitter logins for your application consists of 3 parts:

- Create and configure a Twitter Project and App on the [Twitter Developer Dashboard](https://developer.twitter.com/en/portal/dashboard).
- Add your Twitter `API Key` and `API Secret Key` to your [Supabase Project](https://supabase.com/dashboard).
- Add the login code to your [Supabase JS Client App](https://github.com/supabase/supabase-js).

## Access your Twitter Developer account [\#](https://supabase.com/docs/guides/auth/social-login/auth-twitter\#access-your-twitter-developer-account)

- Go to [developer.twitter.com](https://developer.twitter.com/).
- Click on `Sign in` at the top right to log in.

![Twitter Developer Portal.](https://supabase.com/docs/img/guides/auth-twitter/twitter-portal.png)

## Find your callback URL [\#](https://supabase.com/docs/guides/auth/social-login/auth-twitter\#find-your-callback-url)

The next step requires a callback URL, which looks like this: `https://<project-ref>.supabase.co/auth/v1/callback`

- Go to your [Supabase Project Dashboard](https://supabase.com/dashboard)
- Click on the `Authentication` icon in the left sidebar
- Click on [`Providers`](https://supabase.com/dashboard/project/_/auth/providers) under the Configuration section
- Click on **Twitter** from the accordion list to expand and you'll find your **Callback URL**, you can click `Copy` to copy it to the clipboard

For testing OAuth locally with the Supabase CLI please see the [local development docs](https://supabase.com/docs/guides/cli/local-development#use-auth-locally).

## Create a Twitter OAuth app [\#](https://supabase.com/docs/guides/auth/social-login/auth-twitter\#create-a-twitter-oauth-app)

- Click `+ Create Project`.
  - Enter your project name, click `Next`.
  - Select your use case, click `Next`.
  - Enter a description for your project, click `Next`.
  - Enter a name for your app, click `Next`.
  - Copy and save your `API Key` (this is your `client_id`).
  - Copy and save your `API Secret Key` (this is your `client_secret`).
  - Click on `App settings` to proceed to next steps.
- At the bottom, you will find `User authentication settings`. Click on `Set up`.
- Under `User authentication settings`, you can configure `App permissions`.
- Make sure you turn ON `Request email from users`.
- Select `Web App...` as the `Type of App`.
- Under `App info` configure the following.
  - Enter your `Callback URL`. Check the **Find your callback URL** section above to learn how to obtain your callback URL.
  - Enter your `Website URL` (tip: try `http://127.0.0.1:port` or `http://www.localhost:port` during development)
  - Enter your `Terms of service URL`.
  - Enter your `Privacy policy URL`.
- Click `Save`.

## Enter your Twitter credentials into your Supabase project [\#](https://supabase.com/docs/guides/auth/social-login/auth-twitter\#enter-your-twitter-credentials-into-your-supabase-project)

- Go to your [Supabase Project Dashboard](https://supabase.com/dashboard)
- In the left sidebar, click the `Authentication` icon (near the top)
- Click on [`Providers`](https://supabase.com/dashboard/project/_/auth/providers) under the Configuration section
- Click on **Twitter** from the accordion list to expand and turn **Twitter Enabled** to ON
- Enter your **Twitter Client ID** and **Twitter Client Secret** saved in the previous step
- Click `Save`

## Add login code to your client app [\#](https://supabase.com/docs/guides/auth/social-login/auth-twitter\#add-login-code-to-your-client-app)

JavaScriptFlutterKotlin

Make sure you're using the right `supabase` client in the following code.

If you're not using Server-Side Rendering or cookie-based Auth, you can directly use the `createClient` from `@supabase/supabase-js`. If you're using Server-Side Rendering, see the [Server-Side Auth guide](https://supabase.com/docs/guides/auth/server-side/creating-a-client) for instructions on creating your Supabase client.

When your user signs in, call [`signInWithOAuth()`](https://supabase.com/docs/reference/javascript/auth-signinwithoauth) with `twitter` as the `provider`:

`
async function signInWithTwitter() {
const { data, error } = await supabase.auth.signInWithOAuth({
    provider: 'twitter',
})
}
`

For a PKCE flow, for example in Server-Side Auth, you need an extra step to handle the code exchange. When calling `signInWithOAuth`, provide a `redirectTo` URL which points to a callback route. This redirect URL should be added to your [redirect allow list](https://supabase.com/docs/guides/auth/redirect-urls).

ClientServer

In the browser, `signInWithOAuth` automatically redirects to the OAuth provider's authentication endpoint, which then redirects to your endpoint.

``
await supabase.auth.signInWithOAuth({
provider,
options: {
    redirectTo: `http://example.com/auth/callback`,
},
})
``

At the callback endpoint, handle the code exchange to save the user session.

Next.jsSvelteKitAstroRemixExpress

Create a new file at `app/auth/callback/route.ts` and populate with the following:

app/auth/callback/route.ts

``
import { NextResponse } from 'next/server'
// The client you created from the Server-Side Auth instructions
import { createClient } from '@/utils/supabase/server'
export async function GET(request: Request) {
const { searchParams, origin } = new URL(request.url)
const code = searchParams.get('code')
// if "next" is in param, use it as the redirect URL
const next = searchParams.get('next') ?? '/'
if (code) {
    const supabase = await createClient()
    const { error } = await supabase.auth.exchangeCodeForSession(code)
    if (!error) {
      const forwardedHost = request.headers.get('x-forwarded-host') // original origin before load balancer
      const isLocalEnv = process.env.NODE_ENV === 'development'
      if (isLocalEnv) {
        // we can be sure that there is no load balancer in between, so no need to watch for X-Forwarded-Host
        return NextResponse.redirect(`${origin}${next}`)
      } else if (forwardedHost) {
        return NextResponse.redirect(`https://${forwardedHost}${next}`)
      } else {
        return NextResponse.redirect(`${origin}${next}`)
      }
    }
}
// return the user to an error page with instructions
return NextResponse.redirect(`${origin}/auth/auth-code-error`)
}
``

JavaScriptFlutterKotlin

When your user signs out, call [signOut()](https://supabase.com/docs/reference/javascript/auth-signout) to remove them from the browser session and any objects from localStorage:

`
async function signOut() {
const { error } = await supabase.auth.signOut()
}
`

## Resources [\#](https://supabase.com/docs/guides/auth/social-login/auth-twitter\#resources)

- [Supabase - Get started for free](https://supabase.com/)
- [Supabase JS Client](https://github.com/supabase/supabase-js)
- [Twitter Developer Dashboard](https://developer.twitter.com/en/portal/dashboard)

### Is this helpful?

NoYes

### On this page

[Overview](https://supabase.com/docs/guides/auth/social-login/auth-twitter#overview) [Access your Twitter Developer account](https://supabase.com/docs/guides/auth/social-login/auth-twitter#access-your-twitter-developer-account) [Find your callback URL](https://supabase.com/docs/guides/auth/social-login/auth-twitter#find-your-callback-url) [Create a Twitter OAuth app](https://supabase.com/docs/guides/auth/social-login/auth-twitter#create-a-twitter-oauth-app) [Enter your Twitter credentials into your Supabase project](https://supabase.com/docs/guides/auth/social-login/auth-twitter#enter-your-twitter-credentials-into-your-supabase-project) [Add login code to your client app](https://supabase.com/docs/guides/auth/social-login/auth-twitter#add-login-code-to-your-client-app) [Resources](https://supabase.com/docs/guides/auth/social-login/auth-twitter#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_social_login_auth_workos.md">
Auth

# SSO and Social Login with WorkOS

* * *

## Use Social Login with WorkOS [\#](https://supabase.com/docs/guides/auth/social-login/auth-workos\#use-social-login-with-workos)

### Step 1. Create a WorkOS organization [\#](https://supabase.com/docs/guides/auth/social-login/auth-workos\#step-1-create-a-workos-organization)

Log in to the WorkOS dashboard and visit the Organizations tab to create an organization.
![Create an Organization](https://supabase.com/docs/img/guides/auth-workos/workos-create-organization.png)

Alternatively, you can [create an organization via the WorkOS API](https://workos.com/docs/reference/organization/create).

## Step 2. Obtain your `Client ID` and `WORKOS_API_KEY` values [\#](https://supabase.com/docs/guides/auth/social-login/auth-workos\#step-2-obtain-your-client-id-and-workosapikey-values)

![Get your Environment's Client ID and Secret](https://supabase.com/docs/img/guides/auth-workos/workos-dashboard-get-client-id-and-key.png)

Visit the getting started page of the [WorkOS Dashboard](https://dashboard.workos.com/get-started). Copy the following values from the Quickstart panel:

- `WORKOS_CLIENT_ID`
- `WORKOS_API_KEY`

You must be signed in to see these values.

## Step 3. Add your WorkOS credentials to your Supabase project [\#](https://supabase.com/docs/guides/auth/social-login/auth-workos\#step-3-add-your-workos-credentials-to-your-supabase-project)

![Enter your WorkOS application details in your Supabase app's auth provider settings panel](https://supabase.com/docs/img/guides/auth-workos/supabase-workos-configuration.png)

1. Go to your Supabase Project Dashboard.
2. In the left sidebar, click the Authentication icon (near the top).
3. Click on Providers under the Configuration section.
4. Click on WorkOS from the accordion list to expand.
5. Toggle the `WorkOS Enabled` switch to ON.
6. Enter `https://api.workos.com` in the WorkOS URL field.
7. Enter your WorkOS Client ID and WorkOS Client Secret saved in the previous step.
8. Copy the `Callback URL (for OAuth)` value from the form and save it somewhere handy.
9. Click Save.

## Step 4. Set your Supabase redirect URI in the WorkOS Dashboard [\#](https://supabase.com/docs/guides/auth/social-login/auth-workos\#step-4-set-your-supabase-redirect-uri-in-the-workos-dashboard)

Visit the WorkOS dashboard and click the redirects button in the left navigation panel.

On the redirects page, enter your Supabase project's `Callback URL (for OAuth)` which you saved in the previous step, as shown below:

![Set your Supbase project redirect URL in the WorkOS dashboard](https://supabase.com/docs/img/guides/auth-workos/workos-set-supabase-redirect.png)

## Step 5. Add login code to your client app [\#](https://supabase.com/docs/guides/auth/social-login/auth-workos\#step-5-add-login-code-to-your-client-app)

When a user signs in, call `signInWithOAuth` with `workos` as the provider.

`
async function signInWithWorkOS() {
const { data, error } = await supabase.auth.signInWithOAuth({
    provider: 'workos',
    options: {
      redirectTo: 'http://example.com/auth/v1/callback', // Make sure your redirect URL is configured in the Supabase Dashboard Auth settings
      queryParams: {
        connection: '<connection_id>',
      },
    },
})
if (data.url) {
    redirect(data.url) // use the redirect API for your server or framework
}
}
`

You can find your `connection_id` in the WorkOS dashboard under the Organizations tab. Select your organization and then click View connection.

Within your specified callback URL, you'll exchange the code for a logged-in user profile:

auth/v1/callback/route.ts

``
import { NextResponse } from 'next/server'
import { createClient } from '@/utils/supabase/server'
export async function GET(request: Request) {
const { searchParams, origin } = new URL(request.url)
const code = searchParams.get('code')
// if "next" is in param, use it as the redirect URL
const next = searchParams.get('next') ?? '/'
if (code) {
    const supabase = await createClient()
    const { error } = await supabase.auth.exchangeCodeForSession(code)
    if (!error) {
      const forwardedHost = request.headers.get('x-forwarded-host') // original origin before load balancer
      const isLocalEnv = process.env.NODE_ENV === 'development'
      if (isLocalEnv) {
        // we can be sure that there is no load balancer in between, so no need to watch for X-Forwarded-Host
        return NextResponse.redirect(`${origin}${next}`)
      } else if (forwardedHost) {
        return NextResponse.redirect(`https://${forwardedHost}${next}`)
      } else {
        return NextResponse.redirect(`${origin}${next}`)
      }
    }
}
// return the user to an error page with instructions
return NextResponse.redirect(`${origin}/auth/auth-code-error`)
}
``

## Resources [\#](https://supabase.com/docs/guides/auth/social-login/auth-workos\#resources)

- [WorkOS Documentation](https://workos.com/docs/sso/guide)

### Is this helpful?

NoYes

### On this page

[Use Social Login with WorkOS](https://supabase.com/docs/guides/auth/social-login/auth-workos#use-social-login-with-workos) [Step 1. Create a WorkOS organization](https://supabase.com/docs/guides/auth/social-login/auth-workos#step-1-create-a-workos-organization) [Step 2. Obtain your Client ID and WORKOS\_API\_KEY values](https://supabase.com/docs/guides/auth/social-login/auth-workos#step-2-obtain-your-client-id-and-workosapikey-values) [Step 3. Add your WorkOS credentials to your Supabase project](https://supabase.com/docs/guides/auth/social-login/auth-workos#step-3-add-your-workos-credentials-to-your-supabase-project) [Step 4. Set your Supabase redirect URI in the WorkOS Dashboard](https://supabase.com/docs/guides/auth/social-login/auth-workos#step-4-set-your-supabase-redirect-uri-in-the-workos-dashboard) [Step 5. Add login code to your client app](https://supabase.com/docs/guides/auth/social-login/auth-workos#step-5-add-login-code-to-your-client-app) [Resources](https://supabase.com/docs/guides/auth/social-login/auth-workos#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_social_login_auth_zoom.md">
Auth

# Login with Zoom

* * *

To enable Zoom Auth for your project, you need to set up a Zoom OAuth application and add the application credentials to your Supabase Dashboard.

## Overview [\#](https://supabase.com/docs/guides/auth/social-login/auth-zoom\#overview)

Setting up Zoom logins for your application consists of 3 parts:

- Create and configure a Zoom OAuth App on [Zoom App Marketplace](https://marketplace.zoom.us/)
- Add your Zoom OAuth keys to your [Supabase Project](https://supabase.com/dashboard)
- Add the login code to your [Supabase JS Client App](https://github.com/supabase/supabase-js)

## Access your Zoom Developer account [\#](https://supabase.com/docs/guides/auth/social-login/auth-zoom\#access-your-zoom-developer-account)

- Go to [marketplace.zoom.us](https://marketplace.zoom.us/).
- Click on `Sign In` at the top right to log in.

![Zoom Developer Portal.](https://supabase.com/docs/img/guides/auth-zoom/zoom-portal.png)

## Find your callback URL [\#](https://supabase.com/docs/guides/auth/social-login/auth-zoom\#find-your-callback-url)

The next step requires a callback URL, which looks like this: `https://<project-ref>.supabase.co/auth/v1/callback`

- Go to your [Supabase Project Dashboard](https://supabase.com/dashboard)
- Click on the `Authentication` icon in the left sidebar
- Click on [`Providers`](https://supabase.com/dashboard/project/_/auth/providers) under the Configuration section
- Click on **Zoom** from the accordion list to expand and you'll find your **Callback URL**, you can click `Copy` to copy it to the clipboard

For testing OAuth locally with the Supabase CLI please see the [local development docs](https://supabase.com/docs/guides/cli/local-development#use-auth-locally).

## Create a Zoom OAuth app [\#](https://supabase.com/docs/guides/auth/social-login/auth-zoom\#create-a-zoom-oauth-app)

- Go to [marketplace.zoom.us](https://marketplace.zoom.us/).
- Click on `Sign In` at the top right to log in.
- Click `Build App` (from the dropdown Develop)
- In the OAuth card, click `Create`
- Type the name of your app
- Choose app type
- Click `Create`

Under `App credentials`

- Copy and save your `Client ID`.
- Copy and save your `Client secret`.
- Add your `Callback URL` in the OAuth allow list.

Under `Redirect URL for OAuth`

- Paste your `Callback URL`

Under `Scopes`

- Click on `Add scopes`
- Click on `User`
- Choose `user:read`
- Click `Done`
- Click `Continue`

## Enter your Zoom credentials into your Supabase project [\#](https://supabase.com/docs/guides/auth/social-login/auth-zoom\#enter-your-zoom-credentials-into-your-supabase-project)

- Go to your [Supabase Project Dashboard](https://supabase.com/dashboard)
- In the left sidebar, click the `Authentication` icon (near the top)
- Click on [`Providers`](https://supabase.com/dashboard/project/_/auth/providers) under the Configuration section
- Click on **Zoom** from the accordion list to expand and turn **Zoom Enabled** to ON
- Enter your **Zoom Client ID** and **Zoom Client Secret** saved in the previous step
- Click `Save`

## Add login code to your client app [\#](https://supabase.com/docs/guides/auth/social-login/auth-zoom\#add-login-code-to-your-client-app)

JavaScriptFlutterKotlin

Make sure you're using the right `supabase` client in the following code.

If you're not using Server-Side Rendering or cookie-based Auth, you can directly use the `createClient` from `@supabase/supabase-js`. If you're using Server-Side Rendering, see the [Server-Side Auth guide](https://supabase.com/docs/guides/auth/server-side/creating-a-client) for instructions on creating your Supabase client.

When your user signs in, call [`signInWithOAuth()`](https://supabase.com/docs/reference/javascript/auth-signinwithoauth) with `zoom` as the `provider`:

`
async function signInWithZoom() {
const { data, error } = await supabase.auth.signInWithOAuth({
    provider: 'zoom',
})
}
`

For a PKCE flow, for example in Server-Side Auth, you need an extra step to handle the code exchange. When calling `signInWithOAuth`, provide a `redirectTo` URL which points to a callback route. This redirect URL should be added to your [redirect allow list](https://supabase.com/docs/guides/auth/redirect-urls).

ClientServer

In the browser, `signInWithOAuth` automatically redirects to the OAuth provider's authentication endpoint, which then redirects to your endpoint.

``
await supabase.auth.signInWithOAuth({
provider,
options: {
    redirectTo: `http://example.com/auth/callback`,
},
})
``

At the callback endpoint, handle the code exchange to save the user session.

Next.jsSvelteKitAstroRemixExpress

Create a new file at `app/auth/callback/route.ts` and populate with the following:

app/auth/callback/route.ts

``
import { NextResponse } from 'next/server'
// The client you created from the Server-Side Auth instructions
import { createClient } from '@/utils/supabase/server'
export async function GET(request: Request) {
const { searchParams, origin } = new URL(request.url)
const code = searchParams.get('code')
// if "next" is in param, use it as the redirect URL
const next = searchParams.get('next') ?? '/'
if (code) {
    const supabase = await createClient()
    const { error } = await supabase.auth.exchangeCodeForSession(code)
    if (!error) {
      const forwardedHost = request.headers.get('x-forwarded-host') // original origin before load balancer
      const isLocalEnv = process.env.NODE_ENV === 'development'
      if (isLocalEnv) {
        // we can be sure that there is no load balancer in between, so no need to watch for X-Forwarded-Host
        return NextResponse.redirect(`${origin}${next}`)
      } else if (forwardedHost) {
        return NextResponse.redirect(`https://${forwardedHost}${next}`)
      } else {
        return NextResponse.redirect(`${origin}${next}`)
      }
    }
}
// return the user to an error page with instructions
return NextResponse.redirect(`${origin}/auth/auth-code-error`)
}
``

JavaScriptFlutterKotlin

When your user signs out, call [signOut()](https://supabase.com/docs/reference/javascript/auth-signout) to remove them from the browser session and any objects from localStorage:

`
async function signOut() {
const { error } = await supabase.auth.signOut()
}
`

## Resources [\#](https://supabase.com/docs/guides/auth/social-login/auth-zoom\#resources)

- [Supabase - Get started for free](https://supabase.com/)
- [Supabase JS Client](https://github.com/supabase/supabase-js)
- [Zoom App Marketplace](https://marketplace.zoom.us/)

### Is this helpful?

NoYes

### On this page

[Overview](https://supabase.com/docs/guides/auth/social-login/auth-zoom#overview) [Access your Zoom Developer account](https://supabase.com/docs/guides/auth/social-login/auth-zoom#access-your-zoom-developer-account) [Find your callback URL](https://supabase.com/docs/guides/auth/social-login/auth-zoom#find-your-callback-url) [Create a Zoom OAuth app](https://supabase.com/docs/guides/auth/social-login/auth-zoom#create-a-zoom-oauth-app) [Enter your Zoom credentials into your Supabase project](https://supabase.com/docs/guides/auth/social-login/auth-zoom#enter-your-zoom-credentials-into-your-supabase-project) [Add login code to your client app](https://supabase.com/docs/guides/auth/social-login/auth-zoom#add-login-code-to-your-client-app) [Resources](https://supabase.com/docs/guides/auth/social-login/auth-zoom#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_social_login.md">
Auth

# Social Login

* * *

Social Login (OAuth) is an open standard for authentication that allows users to log in to one website or application using their credentials from another website or application. OAuth allows users to grant third-party applications access to their online accounts without sharing their passwords.
OAuth is commonly used for things like logging in to a social media account from a third-party app. It is a secure and convenient way to authenticate users and share information between applications.

## Benefits [\#](https://supabase.com/docs/guides/auth/social-login\#benefits)

There are several reasons why you might want to add social login to your applications:

- **Improved user experience**: Users can register and log in to your application using their existing social media accounts, which can be faster and more convenient than creating a new account from scratch. This makes it easier for users to access your application, improving their overall experience.

- **Better user engagement**: You can access additional data and insights about your users, such as their interests, demographics, and social connections. This can help you tailor your content and marketing efforts to better engage with your users and provide a more personalized experience.

- **Increased security**: Social login can improve the security of your application by leveraging the security measures and authentication protocols of the social media platforms that your users are logging in with. This can help protect against unauthorized access and account takeovers.


## Set up a social provider with Supabase Auth [\#](https://supabase.com/docs/guides/auth/social-login\#set-up-a-social-provider-with-supabase-auth)

Supabase supports a suite of social providers. Follow these guides to configure a social provider for your platform.

[![Google Icon](https://supabase.com/docs/img/icons/google-icon.svg)\\
\\
**Google**](https://supabase.com/docs/guides/auth/social-login/auth-google) [![Facebook Icon](https://supabase.com/docs/img/icons/facebook-icon.svg)\\
\\
**Facebook**](https://supabase.com/docs/guides/auth/social-login/auth-facebook) [![Apple Icon](https://supabase.com/docs/img/icons/apple-icon.svg)\\
\\
**Apple**](https://supabase.com/docs/guides/auth/social-login/auth-apple) [![Azure (Microsoft) Icon](https://supabase.com/docs/img/icons/microsoft-icon.svg)\\
\\
**Azure (Microsoft)**](https://supabase.com/docs/guides/auth/social-login/auth-azure) [![Twitter Icon](https://supabase.com/docs/img/icons/twitter-icon-light.svg)\\
\\
**Twitter**](https://supabase.com/docs/guides/auth/social-login/auth-twitter) [![GitHub Icon](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
**GitHub**](https://supabase.com/docs/guides/auth/social-login/auth-github) [![Gitlab Icon](https://supabase.com/docs/img/icons/gitlab-icon.svg)\\
\\
**Gitlab**](https://supabase.com/docs/guides/auth/social-login/auth-gitlab) [![Bitbucket Icon](https://supabase.com/docs/img/icons/bitbucket-icon.svg)\\
\\
**Bitbucket**](https://supabase.com/docs/guides/auth/social-login/auth-bitbucket) [![Discord Icon](https://supabase.com/docs/img/icons/discord-icon.svg)\\
\\
**Discord**](https://supabase.com/docs/guides/auth/social-login/auth-discord) [![Figma Icon](https://supabase.com/docs/img/icons/figma-icon.svg)\\
\\
**Figma**](https://supabase.com/docs/guides/auth/social-login/auth-figma) [![Kakao Icon](https://supabase.com/docs/img/icons/kakao-icon.svg)\\
\\
**Kakao**](https://supabase.com/docs/guides/auth/social-login/auth-kakao) [![Keycloak Icon](https://supabase.com/docs/img/icons/keycloak-icon.svg)\\
\\
**Keycloak**](https://supabase.com/docs/guides/auth/social-login/auth-keycloak) [![LinkedIn Icon](https://supabase.com/docs/img/icons/linkedin-icon.svg)\\
\\
**LinkedIn**](https://supabase.com/docs/guides/auth/social-login/auth-linkedin) [![Notion Icon](https://supabase.com/docs/img/icons/notion-icon.svg)\\
\\
**Notion**](https://supabase.com/docs/guides/auth/social-login/auth-notion) [![Slack Icon](https://supabase.com/docs/img/icons/slack-icon.svg)\\
\\
**Slack**](https://supabase.com/docs/guides/auth/social-login/auth-slack) [![Spotify Icon](https://supabase.com/docs/img/icons/spotify-icon.svg)\\
\\
**Spotify**](https://supabase.com/docs/guides/auth/social-login/auth-spotify) [![Twitch Icon](https://supabase.com/docs/img/icons/twitch-icon.svg)\\
\\
**Twitch**](https://supabase.com/docs/guides/auth/social-login/auth-twitch) [![WorkOS Icon](https://supabase.com/docs/img/icons/workos-icon.svg)\\
\\
**WorkOS**](https://supabase.com/docs/guides/auth/social-login/auth-workos) [![Zoom Icon](https://supabase.com/docs/img/icons/zoom-icon.svg)\\
\\
**Zoom**](https://supabase.com/docs/guides/auth/social-login/auth-zoom)

## Provider tokens [\#](https://supabase.com/docs/guides/auth/social-login\#provider-tokens)

You can use the provider token and provider refresh token returned to make API calls to the OAuth provider. For example, you can use the Google provider token to access Google APIs on behalf of your user.

Supabase Auth does not manage refreshing the provider token for the user. Your application will need to use the provider refresh token to obtain a new provider token. If no provider refresh token is returned, then it could mean one of the following:

- The OAuth provider does not return a refresh token
- Additional scopes need to be specified in order for the OAuth provider to return a refresh token.

Provider tokens are intentionally not stored in your project's database. This is because provider tokens give access to potentially sensitive user data in third-party systems. Different applications have different needs, and one application's OAuth scopes may be significantly more permissive than another. If you want to use the provider token outside of the browser that completed the OAuth flow, it is recommended to send it to a trusted and secure server you control.

### Is this helpful?

NoYes

### On this page

[Benefits](https://supabase.com/docs/guides/auth/social-login#benefits) [Set up a social provider with Supabase Auth](https://supabase.com/docs/guides/auth/social-login#set-up-a-social-provider-with-supabase-auth) [Provider tokens](https://supabase.com/docs/guides/auth/social-login#provider-tokens)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_third_party_auth0.md">
Auth

# Auth0

## Use Auth0 with your Supabase project

* * *

Auth0 can be used as a third-party authentication provider alongside Supabase Auth, or standalone, with your Supabase project.

## Getting started [\#](https://supabase.com/docs/guides/auth/third-party/auth0\#getting-started)

1. First you need to add an integration to connect your Supabase project with your Auth0 tenant. You will need your tenant ID (and in some cases region ID).
2. Add a new Third-party Auth integration in your project's [Authentication settings](https://supabase.com/dashboard/project/_/settings/auth).
3. Assign the `role: 'authenticated'` custom claim to all JWTs by using an Auth0 Action.
4. Finally setup the Supabase client in your application.

## Setup the Supabase client library [\#](https://supabase.com/docs/guides/auth/third-party/auth0\#setup-the-supabase-client-library)

TypeScriptSwift (iOS)FlutterKotlin

`
import { createClient } from '@supabase/supabase-js'
import Auth0Client from '@auth0/auth0-spa-js'
const auth0 = new Auth0Client({
domain: '<AUTH0_DOMAIN>',
clientId: '<AUTH0_CLIENT_ID>',
authorizationParams: {
    redirect_uri: '<MY_CALLBACK_URL>',
},
})
const supabase = createClient('https://<supabase-project>.supabase.co', 'SUPABASE_ANON_KEY', {
accessToken: async () => {
    const accessToken = await auth0.getTokenSilently()
    // Alternatively you can use (await auth0.getIdTokenClaims()).__raw to
    // use an ID token instead.
    return accessToken
},
})
`

## Add a new Third-Party Auth integration to your project [\#](https://supabase.com/docs/guides/auth/third-party/auth0\#add-a-new-third-party-auth-integration-to-your-project)

In the dashboard navigate to your project's [Authentication settings](https://supabase.com/dashboard/project/_/settings/auth) and find the Third-Party Auth section to add a new integration.

In the CLI add the following config to your `supabase/config.toml` file:

`
[auth.third_party.auth0]
enabled = true
tenant = "<id>"
tenant_region = "<region>" # if your tenant has a region
`

## Use an Auth0 Action to assign the authenticated role [\#](https://supabase.com/docs/guides/auth/third-party/auth0\#use-an-auth0-action-to-assign-the-authenticated-role)

Your Supabase project inspects the `role` claim present in all JWTs sent to it, to assign the correct Postgres role when using the Data API, Storage or Realtime authorization.

By default, Auth0 JWTs (both access token and ID token) do not contain a `role` claim in them. If you were to send such a JWT to your Supabase project, the `anon` role would be assigned when executing the Postgres query. Most of your app's logic will be accessible by the `authenticated` role.

A recommended approach to do this is to configure the [`onExecutePostLogin` Auth0 Action](https://auth0.com/docs/secure/tokens/json-web-tokens/create-custom-claims#create-custom-claims) which will add the custom claim:

`
exports.onExecutePostLogin = async (event, api) => {
api.accessToken.setCustomClaim('role', 'authenticated')
}
`

## Limitations [\#](https://supabase.com/docs/guides/auth/third-party/auth0\#limitations)

At this time, Auth0 tenants with the following [signing algorithms](https://auth0.com/docs/get-started/applications/signing-algorithms) are not supported:

- HS256 (HMAC with SHA-256) -- also known as symmetric JWTs
- PS256 (RSA-PSS with SHA-256)

### Is this helpful?

NoYes

### On this page

[Getting started](https://supabase.com/docs/guides/auth/third-party/auth0#getting-started) [Setup the Supabase client library](https://supabase.com/docs/guides/auth/third-party/auth0#setup-the-supabase-client-library) [Add a new Third-Party Auth integration to your project](https://supabase.com/docs/guides/auth/third-party/auth0#add-a-new-third-party-auth-integration-to-your-project) [Use an Auth0 Action to assign the authenticated role](https://supabase.com/docs/guides/auth/third-party/auth0#use-an-auth0-action-to-assign-the-authenticated-role) [Limitations](https://supabase.com/docs/guides/auth/third-party/auth0#limitations)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_third_party_aws_cognito.md">
Auth

# Amazon Cognito (Amplify)

## Use Amazon Cognito via Amplify or standalone with your Supabase project

* * *

Amazon Cognito User Pools (via AWS Amplify or on its own) can be used as a third-party authentication provider alongside Supabase Auth, or standalone, with your Supabase project.

## Getting started [\#](https://supabase.com/docs/guides/auth/third-party/aws-cognito\#getting-started)

1. First you need to add an integration to connect your Supabase project with your Amazon Cognito User Pool. You will need the pool's ID and region.
2. Add a new Third-party Auth integration in your project's [Authentication settings](https://supabase.com/dashboard/project/_/settings/auth) or configure it in the CLI.
3. Assign the `role: 'authenticated'` custom claim to all JWTs by using a Pre-Token Generation Trigger.
4. Finally setup the Supabase client in your application.

## Setup the Supabase client library [\#](https://supabase.com/docs/guides/auth/third-party/aws-cognito\#setup-the-supabase-client-library)

TypeScript (Amplify)Swift (iOS)FlutterKotlin

`
import { fetchAuthSession, Hub } from 'aws-amplify/auth'
const supabase = createClient('https://<supabase-project>.supabase.co', 'SUPABASE_ANON_KEY', {
accessToken: async () => {
    const tokens = await fetchAuthSession()
    // Alternatively you can use tokens?.idToken instead.
    return tokens?.accessToken
},
})
// if you're using Realtime you also need to set up a listener for Cognito auth changes
Hub.listen('auth', () => {
fetchAuthSession().then((tokens) => supabase.realtime.setAuth(tokens?.accessToken))
})
`

## Add a new Third-Party Auth integration to your project [\#](https://supabase.com/docs/guides/auth/third-party/aws-cognito\#add-a-new-third-party-auth-integration-to-your-project)

In the dashboard navigate to your project's [Authentication settings](https://supabase.com/dashboard/project/_/settings/auth) and find the Third-Party Auth section to add a new integration.

In the CLI add the following config to your `supabase/config.toml` file:

`
[auth.third_party.aws_cognito]
enabled = true
user_pool_id = "<id>"
user_pool_region = "<region>"
`

## Use a pre-token generation trigger to assign the authenticated role [\#](https://supabase.com/docs/guides/auth/third-party/aws-cognito\#use-a-pre-token-generation-trigger-to-assign-the-authenticated-role)

Your Supabase project inspects the `role` claim present in all JWTs sent to it, to assign the correct Postgres role when using the Data API, Storage or Realtime authorization.

By default, Amazon Cognito JWTs (both ID token and access tokens) do not contain a `role` claim in them. If you were to send such a JWT to your Supabase project, the `anon` role would be assigned when executing the Postgres query. Most of your app's logic will be accessible by the `authenticated` role.

A recommended approach to do this is to configure a [Pre-Token Generation Trigger](https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-lambda-pre-token-generation.html) either `V1_0` (ID token only) or `V2_0` (both access and ID token). To do this you will need to create a new Lambda function (in any language and runtime) and assign it to the [Amazon Cognito User Pool's Lambda Triggers configuration](https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-identity-pools-working-with-aws-lambda-triggers.html). For example, the Lambda function should look similar to this:

Node.js

`
export const handler = async (event) => {
event.response = {
    claimsOverrideDetails: {
      claimsToAddOrOverride: {
        role: 'authenticated',
      },
    },
}
return event
}
`

### Is this helpful?

NoYes

### On this page

[Getting started](https://supabase.com/docs/guides/auth/third-party/aws-cognito#getting-started) [Setup the Supabase client library](https://supabase.com/docs/guides/auth/third-party/aws-cognito#setup-the-supabase-client-library) [Add a new Third-Party Auth integration to your project](https://supabase.com/docs/guides/auth/third-party/aws-cognito#add-a-new-third-party-auth-integration-to-your-project) [Use a pre-token generation trigger to assign the authenticated role](https://supabase.com/docs/guides/auth/third-party/aws-cognito#use-a-pre-token-generation-trigger-to-assign-the-authenticated-role)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_third_party_firebase_auth.md">
Auth

# Firebase Auth

## Use Firebase Auth with your Supabase project

* * *

Firebase Auth can be used as a third-party authentication provider alongside Supabase Auth, or standalone, with your Supabase project.

## Getting started [\#](https://supabase.com/docs/guides/auth/third-party/firebase-auth\#getting-started)

1. First you need to add an integration to connect your Supabase project with your Firebase project. You will need to get the Project ID in the [Firebase Console](https://console.firebase.google.com/u/0/project/_/settings/general).
2. Add a new Third-party Auth integration in your project's [Authentication settings](https://supabase.com/dashboard/project/_/settings/auth).
3. If you are using Third Party Auth when self hosting, create and attach restrictive RLS policies to all tables in your public schema, Storage and Realtime to **prevent unauthorized access from unrelated Firebase projects**.
4. Assign the `role: 'authenticated'` [custom user claim](https://firebase.google.com/docs/auth/admin/custom-claims) to all your users.
5. Finally set up the Supabase client in your application.

## Setup the Supabase client library [\#](https://supabase.com/docs/guides/auth/third-party/firebase-auth\#setup-the-supabase-client-library)

TypeScriptFlutterSwift (iOS)Kotlin (Android)Kotlin (Multiplatform)

Creating a client for the Web is as easy as passing the `accessToken` async function. This function should [return the Firebase Auth JWT of the current user](https://firebase.google.com/docs/auth/admin/verify-id-tokens#web) (or null if no such user) is found.

`
import { createClient } from '@supabase/supabase-js'
const supabase = createClient('https://<supabase-project>.supabase.co', 'SUPABASE_ANON_KEY', {
accessToken: async () => {
    return await firebase.auth().currentUser?.getIdToken(/* forceRefresh */ false)) ?? null
},
})
`

Make sure the all users in your application have the `role: 'authenticated'` [custom claim](https://firebase.google.com/docs/auth/admin/custom-claims) set. If you're using the `onCreate` Cloud Function to add this custom claim to newly signed up users, you will need to call `getIdToken(/* forceRefresh */ true)` immediately after sign up as the `onCreate` function does not run synchronously.

## Add a new Third-Party Auth integration to your project [\#](https://supabase.com/docs/guides/auth/third-party/firebase-auth\#add-a-new-third-party-auth-integration-to-your-project)

In the dashboard navigate to your project's [Authentication settings](https://supabase.com/dashboard/project/_/settings/auth) and find the Third-Party Auth section to add a new integration.

In the CLI add the following config to your `supabase/config.toml` file:

`
[auth.third_party.firebase]
enabled = true
project_id = "<id>"
`

## Adding an extra layer of security to your project's RLS policies (self-hosting only) [\#](https://supabase.com/docs/guides/auth/third-party/firebase-auth\#adding-an-extra-layer-of-security-to-your-projects-rls-policies-self-hosting-only)

**Follow this section carefully to prevent unauthorized access to your project's data when self-hosting.**

When using the Supabase hosted platform, following this step is optional.

Firebase Auth uses a single set of JWT signing keys for all projects. This means that JWTs issued from an unrelated Firebase project to yours could access data in your Supabase project.

When using the Supabase hosted platform, JWTs coming from Firebase project IDs you have not registered will be rejected before they reach your database. When self-hosting implementing this mechanism is your responsibility. An easy way to guard against this is to create and maintain the following RLS policies for **all of your tables in the `public` schema**. You should also attach this policy to [Storage](https://supabase.com/docs/guides/storage/security/access-control) buckets or [Realtime](https://supabase.com/docs/guides/realtime/authorization) channels.

It's recommended you use a [restrictive Postgres Row-Level Security policy](https://www.postgresql.org/docs/current/sql-createpolicy.html).

Restrictive RLS policies differ from regular (or permissive) policies in that they use the `as restrictive` clause when being defined. They do not grant permissions, but rather restrict any existing or future permissions. They're great for cases like this where the technical limitations of Firebase Auth remain separate from your app's logic.

Postgres has two types of policies: permissive and restrictive. This example uses restrictive policies so make sure you don't omit the `as restrictive` clause.

This is an example of such an RLS policy that will restrict access to only your project's (denoted with `<firebase-project-id>`) users, and not any other Firebase project.

`
create policy "Restrict access to Supabase Auth and Firebase Auth for project ID <firebase-project-id>"
on table_name
as restrictive
to authenticated
using (
    (auth.jwt()->>'iss' = 'https://<project-ref>.supabase.co/auth/v1')
    or
    (
        auth.jwt()->>'iss' = 'https://securetoken.google.com/<firebase-project-id>'
        and
        auth.jwt()->>'aud' = '<firebase-project-id>'
     )
);
`

If you have a lot of tables in your app, or need to manage complex RLS policies for [Storage](https://supabase.com/docs/guides/storage) or [Realtime](https://supabase.com/docs/guides/realtime) it can be useful to define a [stable Postgres function](https://www.postgresql.org/docs/current/xfunc-volatility.html) that performs the check to cut down on duplicate code. For example:

`
create function public.is_supabase_or_firebase_project_jwt()
returns bool
language sql
stable
returns null on null input
return (
    (auth.jwt()->>'iss' = 'https://<project-ref>.supabase.co/auth/v1')
    or
    (
        auth.jwt()->>'iss' = concat('https://securetoken.google.com/<firebase-project-id>')
        and
        auth.jwt()->>'aud' = '<firebase-project-id>'
     )
);
`

Make sure you substitute `<project-ref>` with your Supabase project's ID and the `<firebase-project-id>` to your Firebase Project ID. Then the restrictive policies on all your tables, buckets and channels can be simplified to be:

`
create policy "Restrict access to correct Supabase and Firebase projects"
on table_name
as restrictive
to authenticated
using ((select public.is_supabase_or_firebase_project_jwt()) is true);
`

## Assign the "role" custom claim [\#](https://supabase.com/docs/guides/auth/third-party/firebase-auth\#assign-the-role-custom-claim)

Your Supabase project inspects the `role` claim present in all JWTs sent to it, to assign the correct Postgres role when using the Data API, Storage or Realtime authorization.

By default, Firebase JWTs do not contain a `role` claim in them. If you were to send such a JWT to your Supabase project, the `anon` role would be assigned when executing the Postgres query. Most of your app's logic will be accessible by the `authenticated` role.

### Use Firebase Authentication functions to assign the authenticated role [\#](https://supabase.com/docs/guides/auth/third-party/firebase-auth\#use-firebase-authentication-functions-to-assign-the-authenticated-role)

You have two choices to set up a Firebase Authentication function depending on your Firebase project's configuration:

1. Easiest: Use a [blocking Firebase Authentication function](https://firebase.google.com/docs/auth/extend-with-blocking-functions) but this is only available if your project uses [Firebase Authentication with Identity Platform](https://cloud.google.com/security/products/identity-platform).
2. Manually assign the custom claims to all users with the [admin SDK](https://firebase.google.com/docs/auth/admin/custom-claims#set_and_validate_custom_user_claims_via_the_admin_sdk) and define an [`onCreate` Firebase Authentication Cloud Function](https://firebase.google.com/docs/auth/extend-with-functions) to persist the role to all newly created users.

Node.js (Blocking Functions Gen 2)Python (Blocking Functions Gen 2)onCreate Cloud Function in Node.js

``
import { beforeUserCreated, beforeUserSignedIn } from 'firebase-functions/v2/identity'
export const beforecreated = beforeUserCreated((event) => {
return {
    customClaims: {
      // The Supabase project will use this role to assign the `authenticated`
      // Postgres role.
      role: 'authenticated',
    },
}
})
export const beforesignedin = beforeUserSignedIn((event) => {
return {
    customClaims: {
      // The Supabase project will use this role to assign the `authenticated`
      // Postgres role.
      role: 'authenticated',
    },
}
})
``

Note that instead of using `customClaims` you can instead use `sessionClaims`. The difference is that `session_claims` are not saved in the Firebase user profile, but remain valid for as long as the user is signed in.

Finally deploy your functions for the changes to take effect:

`
firebase deploy --only functions
`

Note that these functions are only called on new sign-ups and sign-ins. Existing users will not have these claims in their ID tokens. You will need to use the admin SDK to assign the role custom claim to all users. Make sure you do this after the blocking Firebase Authentication functions as described above are deployed.

### Use the admin SDK to assign the role custom claim to all users [\#](https://supabase.com/docs/guides/auth/third-party/firebase-auth\#use-the-admin-sdk-to-assign-the-role-custom-claim-to-all-users)

You need to run a script that will assign the `role: 'authenticated'` custom claim to all of your existing Firebase Authentication users. You can do this by combining the [list users](https://firebase.google.com/docs/auth/admin/manage-users#list_all_users) and [set custom user claims](https://firebase.google.com/docs/auth/admin/create-custom-tokens) admin APIs. An example script is provided below:

`
'use strict';
const { initializeApp } = require('firebase-admin/app');
const { getAuth } = require('firebase-admin/auth');
initializeApp();
async function setRoleCustomClaim() => {
let nextPageToken = undefined
do {
    const listUsersResult = await getAuth().listUsers(1000, nextPageToken)
    nextPageToken = listUsersResult.pageToken
    await Promise.all(listUsersResult.users.map(async (userRecord) => {
      try {
        await getAuth().setCustomUserClaims(userRecord.id, {
          role: 'authenticated'
        })
      } catch (error) {
        console.error('Failed to set custom role for user', userRecord.id)
      }
    })
} while (nextPageToken);
};
setRoleCustomClaim().then(() => process.exit(0))
`

After all users have received the `role: 'authenticated'` claim, it will appear in all newly issued ID tokens for the user.

### Is this helpful?

NoYes

### On this page

[Getting started](https://supabase.com/docs/guides/auth/third-party/firebase-auth#getting-started) [Setup the Supabase client library](https://supabase.com/docs/guides/auth/third-party/firebase-auth#setup-the-supabase-client-library) [Add a new Third-Party Auth integration to your project](https://supabase.com/docs/guides/auth/third-party/firebase-auth#add-a-new-third-party-auth-integration-to-your-project) [Adding an extra layer of security to your project's RLS policies (self-hosting only)](https://supabase.com/docs/guides/auth/third-party/firebase-auth#adding-an-extra-layer-of-security-to-your-projects-rls-policies-self-hosting-only) [Assign the "role" custom claim](https://supabase.com/docs/guides/auth/third-party/firebase-auth#assign-the-role-custom-claim) [Use Firebase Authentication functions to assign the authenticated role](https://supabase.com/docs/guides/auth/third-party/firebase-auth#use-firebase-authentication-functions-to-assign-the-authenticated-role) [Use the admin SDK to assign the role custom claim to all users](https://supabase.com/docs/guides/auth/third-party/firebase-auth#use-the-admin-sdk-to-assign-the-role-custom-claim-to-all-users)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_third_party_overview.md">
Auth

# Third-party auth

## First-class support for authentication providers

* * *

Supabase has first-class support for these third-party authentication providers:

- [Firebase Auth](https://supabase.com/docs/guides/auth/third-party/firebase-auth)
- [Auth0](https://supabase.com/docs/guides/auth/third-party/auth0)
- [AWS Cognito (with or without AWS Amplify)](https://supabase.com/docs/guides/auth/third-party/aws-cognito)

You can use these providers alongside Supabase Auth, or on their own, to access the [Data API (REST and GraphQL)](https://supabase.com/docs/guides/database), [Storage](https://supabase.com/docs/guides/storage), [Realtime](https://supabase.com/docs/guides/storage) and [Functions](https://supabase.com/docs/guides/functions) from your existing apps.

If you already have production apps using one of these authentication providers, and would like to use a Supabase feature, you no longer need to migrate your users to Supabase Auth or use workarounds like translating JWTs into the Supabase Auth format and using your project's signing secret.

## How does it work? [\#](https://supabase.com/docs/guides/auth/third-party/overview\#how-does-it-work)

To use Supabase products like Data APIs for your Postgres database, Storage or Realtime, you often need to send access tokens or JWTs via the Supabase client libraries or via the REST API. Third-party auth support means that when you add a new integration with one of these providers, the API will trust JWTs issued by the provider similar to how it trusts JWTs issued by Supabase Auth.

This is made possible if the providers are using JWTs signed with asymmetric keys, which means that the Supabase APIs will be able to only verify but not create JWTs.

## Limitations [\#](https://supabase.com/docs/guides/auth/third-party/overview\#limitations)

There are some limitations you should be aware of when using third-party authentication providers with Supabase.

1. The third-party provider must use asymmetrically signed JWTs (exposed as an OIDC Issuer Discovery URL by the third-party authentication provider). Using symmetrically signed JWTs is not possible at this time.
2. The JWT signing keys from the third-party provider are stored in the configuration of your project, and are checked for changes periodically. If you are rotating your keys (when supported) allow up to 30 minutes for the change to be picked up.
3. It is not possible to disable Supabase Auth at this time.

## Pricing [\#](https://supabase.com/docs/guides/auth/third-party/overview\#pricing)

$0.00325 per Third-Party MAU. You are only charged for usage exceeding your subscription plan's quota.

For a detailed breakdown of how charges are calculated, refer to [Manage Monthly Active Third-Party Users usage](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-third-party).

### Is this helpful?

NoYes

### On this page

[How does it work?](https://supabase.com/docs/guides/auth/third-party/overview#how-does-it-work) [Limitations](https://supabase.com/docs/guides/auth/third-party/overview#limitations) [Pricing](https://supabase.com/docs/guides/auth/third-party/overview#pricing)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth_users.md">
Auth

# Users

* * *

A **user** in Supabase Auth is someone with a user ID, stored in the Auth schema. Once someone is a user, they can be issued an Access Token, which can be used to access Supabase endpoints. The token is tied to the user, so you can restrict access to resources via [RLS policies](https://supabase.com/docs/guides/database/postgres/row-level-security).

## Permanent and anonymous users [\#](https://supabase.com/docs/guides/auth/users\#permanent-and-anonymous-users)

Supabase distinguishes between permanent and anonymous users.

- **Permanent users** are tied to a piece of Personally Identifiable Information (PII), such as an email address, a phone number, or a third-party identity. They can use these identities to sign back into their account after signing out.
- **Anonymous users** aren't tied to any identities. They have a user ID and a personalized Access Token, but they have no way of signing back in as the same user if they are signed out.

Anonymous users are useful for:

- E-commerce applications, to create shopping carts before checkout
- Full-feature demos without collecting personal information
- Temporary or throw-away accounts

See the [Anonymous Signins guide](https://supabase.com/docs/guides/auth/auth-anonymous) to learn more about anonymous users.

##### Anonymous users do not use the anon role

Just like permanent users, anonymous users use the **authenticated** role for database access.

The **anon** role is for those who aren't signed in at all and are not tied to any user ID. We refer to these as unauthenticated or public users.

## The user object [\#](https://supabase.com/docs/guides/auth/users\#the-user-object)

The user object stores all the information related to a user in your application. The user object can be retrieved using one of these methods:

1. [`supabase.auth.getUser()`](https://supabase.com/docs/reference/javascript/auth-getuser)
2. Retrieve a user object as an admin using [`supabase.auth.admin.getUserById()`](https://supabase.com/docs/reference/javascript/auth-admin-listusers)

A user can sign in with one of the following methods:

- Password-based method (with email or phone)
- Passwordless method (with email or phone)
- OAuth
- SAML SSO

An identity describes the authentication method that a user can use to sign in. A user can have multiple identities. These are the types of identities supported:

- Email
- Phone
- OAuth
- SAML

A user with an email or phone identity will be able to sign in with either a password or passwordless method (e.g. use a one-time password (OTP) or magic link). By default, a user with an unverified email or phone number will not be able to sign in.

The user object contains the following attributes:

| Attributes | Type | Description |
| --- | --- | --- |
| id | `string` | The unique id of the identity of the user. |
| aud | `string` | The audience claim. |
| role | `string` | The role claim used by Postgres to perform Row Level Security (RLS) checks. |
| email | `string` | The user's email address. |
| email\_confirmed\_at | `string` | The timestamp that the user's email was confirmed. If null, it means that the user's email is not confirmed. |
| phone | `string` | The user's phone number. |
| phone\_confirmed\_at | `string` | The timestamp that the user's phone was confirmed. If null, it means that the user's phone is not confirmed. |
| confirmed\_at | `string` | The timestamp that either the user's email or phone was confirmed. If null, it means that the user does not have a confirmed email address and phone number. |
| last\_sign\_in\_at | `string` | The timestamp that the user last signed in. |
| app\_metadata | `object` | The `provider` attribute indicates the first provider that the user used to sign up with. The `providers` attribute indicates the list of providers that the user can use to login with. |
| user\_metadata | `object` | Defaults to the first provider's identity data but can contain additional custom user metadata if specified. Refer to [**User Identity**](https://supabase.com/docs/guides/auth/auth-identity-linking#the-user-identity) for more information about the identity object. |
| identities | `UserIdentity[]` | Contains an object array of identities linked to the user. |
| created\_at | `string` | The timestamp that the user was created. |
| updated\_at | `string` | The timestamp that the user was last updated. |
| is\_anonymous | `boolean` | Is true if the user is an anonymous user. |

## Resources [\#](https://supabase.com/docs/guides/auth/users\#resources)

- [User Management guide](https://supabase.com/docs/guides/auth/managing-user-data)

### Is this helpful?

NoYes

### On this page

[Permanent and anonymous users](https://supabase.com/docs/guides/auth/users#permanent-and-anonymous-users) [The user object](https://supabase.com/docs/guides/auth/users#the-user-object) [Resources](https://supabase.com/docs/guides/auth/users#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_auth.md">
Auth

# Auth

## Use Supabase to authenticate and authorize your users.

* * *

Supabase Auth makes it easy to implement authentication and authorization in your app. We provide client SDKs and API endpoints to help you create and manage users.

Your users can use many popular Auth methods, including password, magic link, one-time password (OTP), social login, and single sign-on (SSO).

## About authentication and authorization [\#](https://supabase.com/docs/guides/auth\#about-authentication-and-authorization)

Authentication and authorization are the core responsibilities of any Auth system.

- **Authentication** means checking that a user is who they say they are.
- **Authorization** means checking what resources a user is allowed to access.

Supabase Auth uses [JSON Web Tokens (JWTs)](https://supabase.com/docs/guides/auth/jwts) for authentication. Auth integrates with Supabase's database features, making it easy to use [Row Level Security (RLS)](https://supabase.com/docs/guides/database/postgres/row-level-security) for authorization.

## The Supabase ecosystem [\#](https://supabase.com/docs/guides/auth\#the-supabase-ecosystem)

You can use Supabase Auth as a standalone product, but it's also built to integrate with the Supabase ecosystem.

Auth uses your project's Postgres database under the hood, storing user data and other Auth information in a special schema. You can connect this data to your own tables using triggers and foreign key references.

Auth also enables access control to your database's automatically generated [REST API](https://supabase.com/docs/guides/api). When using Supabase SDKs, your data requests are automatically sent with the user's Auth Token. The Auth Token scopes database access on a row-by-row level when used along with [RLS policies](https://supabase.com/docs/guides/database/postgres/row-level-security).

## Providers [\#](https://supabase.com/docs/guides/auth\#providers)

Supabase Auth works with many popular Auth methods, including Social and Phone Auth using third-party providers. See the following sections for a list of supported third-party providers.

### Social Auth [\#](https://supabase.com/docs/guides/auth\#social-auth)

[![Apple Icon](https://supabase.com/docs/img/icons/apple-icon.svg)\\
\\
**Apple**](https://supabase.com/docs/guides/auth/social-login/auth-apple) [![Azure (Microsoft) Icon](https://supabase.com/docs/img/icons/microsoft-icon.svg)\\
\\
**Azure (Microsoft)**](https://supabase.com/docs/guides/auth/social-login/auth-azure) [![Bitbucket Icon](https://supabase.com/docs/img/icons/bitbucket-icon.svg)\\
\\
**Bitbucket**](https://supabase.com/docs/guides/auth/social-login/auth-bitbucket) [![Discord Icon](https://supabase.com/docs/img/icons/discord-icon.svg)\\
\\
**Discord**](https://supabase.com/docs/guides/auth/social-login/auth-discord) [![Facebook Icon](https://supabase.com/docs/img/icons/facebook-icon.svg)\\
\\
**Facebook**](https://supabase.com/docs/guides/auth/social-login/auth-facebook) [![Figma Icon](https://supabase.com/docs/img/icons/figma-icon.svg)\\
\\
**Figma**](https://supabase.com/docs/guides/auth/social-login/auth-figma) [![GitHub Icon](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
**GitHub**](https://supabase.com/docs/guides/auth/social-login/auth-github) [![GitLab Icon](https://supabase.com/docs/img/icons/gitlab-icon.svg)\\
\\
**GitLab**](https://supabase.com/docs/guides/auth/social-login/auth-gitlab) [![Google Icon](https://supabase.com/docs/img/icons/google-icon.svg)\\
\\
**Google**](https://supabase.com/docs/guides/auth/social-login/auth-google) [![Kakao Icon](https://supabase.com/docs/img/icons/kakao-icon.svg)\\
\\
**Kakao**](https://supabase.com/docs/guides/auth/social-login/auth-kakao) [![Keycloak Icon](https://supabase.com/docs/img/icons/keycloak-icon.svg)\\
\\
**Keycloak**](https://supabase.com/docs/guides/auth/social-login/auth-keycloak) [![LinkedIn Icon](https://supabase.com/docs/img/icons/linkedin-icon.svg)\\
\\
**LinkedIn**](https://supabase.com/docs/guides/auth/social-login/auth-linkedin) [![Notion Icon](https://supabase.com/docs/img/icons/notion-icon.svg)\\
\\
**Notion**](https://supabase.com/docs/guides/auth/social-login/auth-notion) [![Slack Icon](https://supabase.com/docs/img/icons/slack-icon.svg)\\
\\
**Slack**](https://supabase.com/docs/guides/auth/social-login/auth-slack) [![Spotify Icon](https://supabase.com/docs/img/icons/spotify-icon.svg)\\
\\
**Spotify**](https://supabase.com/docs/guides/auth/social-login/auth-spotify) [![Twitter Icon](https://supabase.com/docs/img/icons/twitter-icon-light.svg)\\
\\
**Twitter**](https://supabase.com/docs/guides/auth/social-login/auth-twitter) [![Twitch Icon](https://supabase.com/docs/img/icons/twitch-icon.svg)\\
\\
**Twitch**](https://supabase.com/docs/guides/auth/social-login/auth-twitch) [![WorkOS Icon](https://supabase.com/docs/img/icons/workos-icon.svg)\\
\\
**WorkOS**](https://supabase.com/docs/guides/auth/social-login/auth-workos) [![Zoom Icon](https://supabase.com/docs/img/icons/zoom-icon.svg)\\
\\
**Zoom**](https://supabase.com/docs/guides/auth/social-login/auth-zoom)

### Phone Auth [\#](https://supabase.com/docs/guides/auth\#phone-auth)

[![MessageBird Icon](https://supabase.com/docs/img/icons/messagebird-icon.svg)\\
\\
**MessageBird**](https://supabase.com/docs/guides/auth/phone-login?showSmsProvider=MessageBird) [![Twilio Icon](https://supabase.com/docs/img/icons/twilio-icon.svg)\\
\\
**Twilio**](https://supabase.com/docs/guides/auth/phone-login?showSmsProvider=Twilio) [![Vonage Icon](https://supabase.com/docs/img/icons/vonage-icon-light.svg)\\
\\
**Vonage**](https://supabase.com/docs/guides/auth/phone-login?showSmsProvider=Vonage)

## Pricing [\#](https://supabase.com/docs/guides/auth\#pricing)

Charges apply to Monthly Active Users (MAU), Monthly Active Third-Party Users (Third-Party MAU), and Monthly Active SSO Users (SSO MAU) and Advanced MFA Add-ons. For a detailed breakdown of how these charges are calculated, refer to the following pages:

- [Pricing MAU](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users)
- [Pricing Third-Party MAU](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-third-party)
- [Pricing SSO MAU](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-sso)
- [Advanced MFA - Phone](https://supabase.com/docs/guides/platform/manage-your-usage/advanced-mfa-phone)

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2F6ow_jW4epf8%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[About authentication and authorization](https://supabase.com/docs/guides/auth#about-authentication-and-authorization) [The Supabase ecosystem](https://supabase.com/docs/guides/auth#the-supabase-ecosystem) [Providers](https://supabase.com/docs/guides/auth#providers) [Social Auth](https://supabase.com/docs/guides/auth#social-auth) [Phone Auth](https://supabase.com/docs/guides/auth#phone-auth) [Pricing](https://supabase.com/docs/guides/auth#pricing)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_cron_install.md">
Cron

# Install

* * *

Install the Supabase Cron Postgres Module to begin scheduling recurring Jobs.

DashboardSQL

1. Go to the [Cron Postgres Module](https://supabase.com/dashboard/project/_/integrations/cron/overview) under Integrations in the Dashboard.
2. Enable the `pg_cron` extension.

## Uninstall [\#](https://supabase.com/docs/guides/cron/install\#uninstall)

Uninstall Supabase Cron by disabling the `pg_cron` extension:

`
drop extension if exists pg_cron;
`

Disabling the `pg_cron` extension will permanently delete all Jobs.

### Is this helpful?

NoYes

### On this page

[Uninstall](https://supabase.com/docs/guides/cron/install#uninstall)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_cron_quickstart.md">
Cron

# Quickstart

* * *

Job names are case sensitive and cannot be edited once created.

Attempting to create a second Job with the same name (and case) will overwrite the first Job.

## Schedule a job [\#](https://supabase.com/docs/guides/cron/quickstart\#schedule-a-job)

DashboardSQL

1. Go to the [Jobs](https://supabase.com/dashboard/project/_/integrations/cron/jobs) section to schedule your first Job.
2. Click on `Create job` button or navigate to the new Cron Job form [here](https://supabase.com/dashboard/project/_/integrations/cron/jobs?dialog-shown=true).
3. Name your Cron Job.
4. Choose a schedule for your Job by inputting cron syntax (refer to the syntax chart in the form) or natural language.
5. Input SQL snippet or select a Database function, HTTP request, or Supabase Edge Function.

![Cron Create](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fdatabase%2Fcron%2Fcron-create.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

Cron syntax

You can input seconds for your Job schedule interval as long as you're on Postgres version 15.1.1.61 or later.

## Edit a job [\#](https://supabase.com/docs/guides/cron/quickstart\#edit-a-job)

DashboardSQL

1. Go to the [Jobs](https://supabase.com/dashboard/project/_/integrations/cron/jobs) section and find the Job you'd like to edit.
2. Click on the three vertical dots menu on the right side of the Job and click `Edit cron job`.
3. Make your changes and then click `Save cron job`.

![Cron Edit](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fdatabase%2Fcron%2Fcron-edit.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

## Activate/Deactivate a job [\#](https://supabase.com/docs/guides/cron/quickstart\#activatedeactivate-a-job)

DashboardSQL

1. Go to the [Jobs](https://supabase.com/dashboard/project/_/integrations/cron/jobs) section and find the Job you'd like to unschedule.
2. Toggle the `Active`/ `Inactive` switch next to Job name.

![Cron Toggle](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fdatabase%2Fcron%2Fcron-toggle.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

## Unschedule a job [\#](https://supabase.com/docs/guides/cron/quickstart\#unschedule-a-job)

DashboardSQL

1. Go to the [Jobs](https://supabase.com/dashboard/project/_/integrations/cron/jobs) section and find the Job you'd like to delete.
2. Click on the three vertical dots menu on the right side of the Job and click `Delete cron job`.
3. Confirm deletion by entering the Job name.

![Cron Unschedule](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fdatabase%2Fcron%2Fcron-unschedule.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

## Inspecting job runs [\#](https://supabase.com/docs/guides/cron/quickstart\#inspecting-job-runs)

DashboardSQL

1. Go to the [Jobs](https://supabase.com/dashboard/project/_/integrations/cron/jobs) section and find the Job you want to see the runs of.
2. Click on the `History` button next to the Job name.

![Cron Job Runs](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fdatabase%2Fcron%2Fcron-history.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

## Examples [\#](https://supabase.com/docs/guides/cron/quickstart\#examples)

### Delete data every week [\#](https://supabase.com/docs/guides/cron/quickstart\#delete-data-every-week)

Delete old data every Saturday at 3:30AM (GMT):

`
select cron.schedule (
'saturday-cleanup', -- name of the cron job
'30 3 * * 6', -- Saturday at 3:30AM (GMT)
$$ delete from events where event_time < now() - interval '1 week' $$
);
`

### Run a vacuum every day [\#](https://supabase.com/docs/guides/cron/quickstart\#run-a-vacuum-every-day)

Vacuum every day at 3:00AM (GMT):

`
select cron.schedule('nightly-vacuum', '0 3 * * *', 'VACUUM');
`

### Call a database function every 5 minutes [\#](https://supabase.com/docs/guides/cron/quickstart\#call-a-database-function-every-5-minutes)

Create a [`hello_world()`](https://supabase.com/docs/guides/database/functions?language=sql#simple-functions) database function and then call it every 5 minutes:

`
select cron.schedule('call-db-function', '*/5 * * * *', 'SELECT hello_world()');
`

### Call a database stored procedure [\#](https://supabase.com/docs/guides/cron/quickstart\#call-a-database-stored-procedure)

To use a stored procedure, you can call it like this:

`
select cron.schedule('call-db-procedure', '*/5 * * * *', 'CALL my_procedure()');
`

### Invoke Supabase Edge Function every 30 seconds [\#](https://supabase.com/docs/guides/cron/quickstart\#invoke-supabase-edge-function-every-30-seconds)

Make a POST request to a Supabase Edge Function every 30 seconds:

`
select
cron.schedule(
    'invoke-function-every-half-minute',
    '30 seconds',
    $$
    select
      net.http_post(
          url:='https://project-ref.supabase.co/functions/v1/function-name',
          headers:=jsonb_build_object('Content-Type','application/json', 'Authorization', 'Bearer ' || 'YOUR_ANON_KEY'),
          body:=jsonb_build_object('time', now() ),
          timeout_milliseconds:=5000
      ) as request_id;
    $$
);
`

This requires the [`pg_net` extension](https://supabase.com/docs/guides/database/extensions/pg_net) to be enabled.

## Caution: Scheduling system maintenance [\#](https://supabase.com/docs/guides/cron/quickstart\#caution-scheduling-system-maintenance)

Be extremely careful when setting up Jobs for system maintenance tasks as they can have unintended consequences.

For instance, scheduling a command to terminate idle connections with `pg_terminate_backend(pid)` can disrupt critical background processes like nightly backups. Often, there is an existing Postgres setting, such as `idle_session_timeout`, that can perform these common maintenance tasks without the risk.

Reach out to [Supabase Support](https://supabase.com/support) if you're unsure if that applies to your use case.

### Is this helpful?

NoYes

### On this page

[Schedule a job](https://supabase.com/docs/guides/cron/quickstart#schedule-a-job) [Edit a job](https://supabase.com/docs/guides/cron/quickstart#edit-a-job) [Activate/Deactivate a job](https://supabase.com/docs/guides/cron/quickstart#activatedeactivate-a-job) [Unschedule a job](https://supabase.com/docs/guides/cron/quickstart#unschedule-a-job) [Inspecting job runs](https://supabase.com/docs/guides/cron/quickstart#inspecting-job-runs) [Examples](https://supabase.com/docs/guides/cron/quickstart#examples) [Delete data every week](https://supabase.com/docs/guides/cron/quickstart#delete-data-every-week) [Run a vacuum every day](https://supabase.com/docs/guides/cron/quickstart#run-a-vacuum-every-day) [Call a database function every 5 minutes](https://supabase.com/docs/guides/cron/quickstart#call-a-database-function-every-5-minutes) [Call a database stored procedure](https://supabase.com/docs/guides/cron/quickstart#call-a-database-stored-procedure) [Invoke Supabase Edge Function every 30 seconds](https://supabase.com/docs/guides/cron/quickstart#invoke-supabase-edge-function-every-30-seconds) [Caution: Scheduling system maintenance](https://supabase.com/docs/guides/cron/quickstart#caution-scheduling-system-maintenance)

![Cron Create](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fdatabase%2Fcron%2Fcron-create.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![Cron Edit](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fdatabase%2Fcron%2Fcron-edit.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![Cron Unschedule](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fdatabase%2Fcron%2Fcron-unschedule.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![Cron Job Runs](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fdatabase%2Fcron%2Fcron-history.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![Cron Toggle](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fdatabase%2Fcron%2Fcron-toggle.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_cron.md">
Cron

# Cron

## Schedule Recurring Jobs with Cron Syntax in Postgres

* * *

Supabase Cron is a Postgres Module that simplifies scheduling recurring Jobs with cron syntax and monitoring Job runs inside Postgres.

Cron Jobs can be created via SQL or the Cron interface inside of Supabase Dashboard and can run anywhere from every second to once a year depending on your use case.

Every Job can run SQL snippets or database functions with zero network latency or make an HTTP request, such as invoking a Supabase Edge Function, with ease.

For best performance, we recommend no more than 8 Jobs run concurrently. Each Job should run no more than 10 minutes.

## How does Cron work? [\#](https://supabase.com/docs/guides/cron\#how-does-cron-work)

Under the hood, Supabase Cron uses the [`pg_cron`](https://github.com/citusdata/pg_cron) Postgres database extension which is the scheduling and execution engine for your Jobs.

`pg_cron` is not fully supported on Fly Postgres. Learn more about [Fly Postgres limitations](https://supabase.com/docs/guides/platform/fly-postgres#limitations).

The extension creates a `cron` schema in your database and all Jobs are stored on the `cron.job` table. Every Job's run and its status is recorded on the `cron.job_run_details` table.

The Supabase Dashboard provides and interface for you to schedule Jobs and monitor Job runs. You can also do the same with SQL.

## Resources [\#](https://supabase.com/docs/guides/cron\#resources)

- [`pg_cron` GitHub Repository](https://github.com/citusdata/pg_cron)

### Is this helpful?

NoYes

### On this page

[How does Cron work?](https://supabase.com/docs/guides/cron#how-does-cron-work) [Resources](https://supabase.com/docs/guides/cron#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_arrays.md">
Database

# Working With Arrays

* * *

Postgres supports flexible [array types](https://www.postgresql.org/docs/12/arrays.html). These arrays are also supported in the Supabase Dashboard and in the JavaScript API.

## Create a table with an array column [\#](https://supabase.com/docs/guides/database/arrays\#create-a-table-with-an-array-column)

Create a test table with a text array (an array of strings):

DashboardSQL

1. Go to the [Table editor](https://supabase.com/dashboard/project/_/editor) page in the Dashboard.
2. Click **New Table** and create a table with the name `arraytest`.
3. Click **Save**.
4. Click **New Column** and create a column with the name `textarray`, type `text`, and select **Define as array**.
5. Click **Save**.

## Insert a record with an array value [\#](https://supabase.com/docs/guides/database/arrays\#insert-a-record-with-an-array-value)

DashboardSQLJavaScriptSwiftPython

1. Go to the [Table editor](https://supabase.com/dashboard/project/_/editor) page in the Dashboard.
2. Select the `arraytest` table.
3. Click **Insert row** and add `["Harry", "Larry", "Moe"]`.
4. Click **Save.**

## View the results [\#](https://supabase.com/docs/guides/database/arrays\#view-the-results)

DashboardSQL

1. Go to the [Table editor](https://supabase.com/dashboard/project/_/editor) page in the Dashboard.
2. Select the `arraytest` table.

You should see:

`
| id  | textarray               |
| --- | ----------------------- |
| 1   | ["Harry","Larry","Moe"] |
`

## Query array data [\#](https://supabase.com/docs/guides/database/arrays\#query-array-data)

Postgres uses 1-based indexing (e.g., `textarray[1]` is the first item in the array).

SQLJavaScriptSwift

To select the first item from the array and get the total length of the array:

`
SELECT textarray[1], array_length(textarray, 1) FROM arraytest;
`

returns:

`
| textarray | array_length |
| --------- | ------------ |
| Harry     | 3            |
`

## Resources [\#](https://supabase.com/docs/guides/database/arrays\#resources)

- [Supabase JS Client](https://github.com/supabase/supabase-js)
- [Supabase - Get started for free](https://supabase.com/)
- [Postgres Arrays](https://www.postgresql.org/docs/15/arrays.html)

### Is this helpful?

NoYes

### On this page

[Create a table with an array column](https://supabase.com/docs/guides/database/arrays#create-a-table-with-an-array-column) [Insert a record with an array value](https://supabase.com/docs/guides/database/arrays#insert-a-record-with-an-array-value) [View the results](https://supabase.com/docs/guides/database/arrays#view-the-results) [Query array data](https://supabase.com/docs/guides/database/arrays#query-array-data) [Resources](https://supabase.com/docs/guides/database/arrays#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_beekeeper_studio.md">
Database

# Connecting with Beekeeper Studio

* * *

[`Beekeeper Studio Community`](https://www.beekeeperstudio.io/get-community) is a free GUI tool for interacting with databases.

1

### Create a new connection

In Beekeeper, create a new Postgres connection.

![Postgres connection](https://supabase.com/docs/img/guides/database/connecting-to-postgres/beekeeper-studio/new-connection.png)

2

### Get your connection credentials

Get your connection credentials from the [`Database Settings`](https://supabase.com/dashboard/project/_/settings/database). You will need:

- host
- username
- password
- port

Add your credentials to Beekeeper's connection form

![Credentials](https://supabase.com/docs/img/guides/database/connecting-to-postgres/beekeeper-studio/beekeeper-credentials.png)

3

### Download your SSL Certificate

Download your SSL certificate from the Dashboard's [`Database Settings`](https://supabase.com/dashboard/project/_/settings/database)![SSL](https://supabase.com/docs/img/guides/database/connecting-to-postgres/beekeeper-studio/certificate.png)

Add your SSL to the connection form
![SSL](https://supabase.com/docs/img/guides/database/connecting-to-postgres/beekeeper-studio/certificate-beekeeper.png)

4

### Test and connect

Test your connection and then connect

![SSL](https://supabase.com/docs/img/guides/database/connecting-to-postgres/beekeeper-studio/connect.png)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_connecting_to_postgres.md">
Database

# Connect to your database

## Connect to Postgres from your frontend, backend, or serverless environment

* * *

## Quick summary [\#](https://supabase.com/docs/guides/database/connecting-to-postgres\#quick-summary)

How you connect to your database depends on where you're connecting from:

- For frontend applications, use the [Data API](https://supabase.com/docs/guides/database/connecting-to-postgres#data-apis-and-client-libraries)
- For Postgres clients, use a connection string
  - For single sessions (for example, database GUIs) or Postgres native commands (for example, using client applications like [pg\_dump](https://www.postgresql.org/docs/current/app-pgdump.html) or specifying connections for [replication](https://supabase.com/docs/guides/database/postgres/setup-replication-external)) use the [direct connection string](https://supabase.com/docs/guides/database/connecting-to-postgres#direct-connection) if your environment supports IPv6
  - For persistent clients, and support for both IPv4 and IPv6, use [Supavisor session mode](https://supabase.com/docs/guides/database/connecting-to-postgres#supavisor-session-mode)
  - For temporary clients (for example, serverless or edge functions) use [Supavisor transaction mode](https://supabase.com/docs/guides/database/connecting-to-postgres#supavisor-transaction-mode)

## Quickstarts [\#](https://supabase.com/docs/guides/database/connecting-to-postgres\#quickstarts)

[Prisma](https://supabase.com/docs/guides/database/prisma) [Drizzle](https://supabase.com/docs/guides/database/drizzle) [Postgres.js](https://supabase.com/docs/guides/database/postgres-js) [pgAdmin](https://supabase.com/docs/guides/database/pgadmin) [PSQL](https://supabase.com/docs/guides/database/psql) [DBeaver](https://supabase.com/docs/guides/database/dbeaver) [Metabase](https://supabase.com/docs/guides/database/metabase) [Beekeeper Studio](https://supabase.com/docs/guides/database/beekeeper-studio)

## Data APIs and client libraries [\#](https://supabase.com/docs/guides/database/connecting-to-postgres\#data-apis-and-client-libraries)

The Data APIs allow you to interact with your database using REST or GraphQL requests. You can use these APIs to fetch and insert data from the frontend, as long as you have [RLS](https://supabase.com/docs/guides/database/postgres/row-level-security) enabled.

- [REST](https://supabase.com/docs/guides/api)
- [GraphQL](https://supabase.com/docs/guides/graphql/api)

For convenience, you can also use the Supabase client libraries, which wrap the Data APIs with a developer-friendly interface and automatically handle authentication:

- [JavaScript](https://supabase.com/docs/reference/javascript)
- [Flutter](https://supabase.com/docs/reference/dart)
- [Swift](https://supabase.com/docs/reference/swift)
- [Python](https://supabase.com/docs/reference/python)
- [C#](https://supabase.com/docs/reference/csharp)
- [Kotlin](https://supabase.com/docs/reference/kotlin)

## Direct connection [\#](https://supabase.com/docs/guides/database/connecting-to-postgres\#direct-connection)

The direct connection string connects directly to your Postgres instance. It is ideal for persistent servers, such as virtual machines (VMs) and long-lasting containers. Examples include AWS EC2 machines, Fly.io VMs, and DigitalOcean Droplets.

Direct connections use IPv6 by default. If your environment doesn't support IPv6, use [Supavisor session mode](https://supabase.com/docs/guides/database/connecting-to-postgres#supavisor-session-mode) or get the [IPv4 add-on](https://supabase.com/docs/guides/platform/ipv4-address).

The connection string looks like this:

`
postgresql://postgres:[YOUR-PASSWORD]@db.apbkobhfnmcqqzqeeqss.supabase.co:5432/postgres
`

Get your project's direct string from the [Database Settings](https://supabase.com/dashboard/project/_/settings/database) page:

1. Go to the `Settings` section.
2. Click `Database`.
3. Under `Connection string`, make sure `Display connection pooler` is unchecked. Copy the URI.

## Shared pooler [\#](https://supabase.com/docs/guides/database/connecting-to-postgres\#shared-pooler)

Every Supabase project includes a free, shared connection pooler. This is ideal for persistent servers when IPv6 is not supported.

### Supavisor session mode [\#](https://supabase.com/docs/guides/database/connecting-to-postgres\#supavisor-session-mode)

The session mode connection string connects to your Postgres instance via a proxy.

The connection string looks like this:

`
postgres://postgres.apbkobhfnmcqqzqeeqss:[YOUR-PASSWORD]@aws-0-[REGION].pooler.supabase.com:5432/postgres
`

Get your project's session mode string from the [Database Settings](https://supabase.com/dashboard/project/_/settings/database) page:

1. Go to the `Settings` section.
2. Click `Database`.
3. Under `Connection string`, make sure `Display connection pooler` is checked and `Session mode` is selected. Copy the URI.

### Supavisor transaction mode [\#](https://supabase.com/docs/guides/database/connecting-to-postgres\#supavisor-transaction-mode)

The transaction mode connection string connects to your Postgres instance via a proxy which serves as a connection pooler. This is ideal for serverless or edge functions, which require many transient connections.

Transaction mode does not support [prepared statements](https://postgresql.org/docs/current/sql-prepare.html). To avoid errors, [turn off prepared statements](https://github.com/orgs/supabase/discussions/28239) for your connection library.

The connection string looks like this:

`
postgres://postgres.apbkobhfnmcqqzqeeqss:[YOUR-PASSWORD]@aws-0-[REGION].pooler.supabase.com:6543/postgres
`

Get your project's transaction mode string from the [Database Settings](https://supabase.com/dashboard/project/_/settings/database) page:

1. Go to the `Settings` section.
2. Click `Database`.
3. Under `Connection string`, make sure `Display connection pooler` is checked and `Transaction mode` is selected. Copy the URI.

## Dedicated pooler [\#](https://supabase.com/docs/guides/database/connecting-to-postgres\#dedicated-pooler)

The Dedicated Pooler is a [PgBouncer](https://www.pgbouncer.org/) instance that's co-located with your Postgres database. This will require you to connect with IPv6 or, if that's not an option, you can use the [IPv4 add-on](https://supabase.com/docs/guides/platform/ipv4-address).

## More about connection pooling [\#](https://supabase.com/docs/guides/database/connecting-to-postgres\#more-about-connection-pooling)

Connection pooling improves database performance by reusing existing connections between queries. This reduces the overhead of establishing connections and improves scalability.

You can use an application-side pooler or a server-side pooler (Supabase automatically provides one called Supavisor), depending on whether your backend is persistent or serverless.

### Application-side poolers [\#](https://supabase.com/docs/guides/database/connecting-to-postgres\#application-side-poolers)

Application-side poolers are built into connection libraries and API servers, such as Prisma, SQLAlchemy, and PostgREST. They maintain several active connections with Postgres or a server-side pooler, reducing the overhead of establishing connections between queries. When deploying to static architecture, such as long-standing containers or VMs, application-side poolers are satisfactory on their own.

### Serverside poolers [\#](https://supabase.com/docs/guides/database/connecting-to-postgres\#serverside-poolers)

Postgres connections are like a WebSocket. Once established, they are preserved until the client (application server) disconnects. A server might only make a single 10 ms query, but needlessly reserve its database connection for seconds or longer.

Serverside-poolers, such as Supabase's [Supavisor](https://github.com/supabase/supavisor) in transaction mode, sit between clients and the database and can be thought of as load balancers for Postgres connections.

![New migration files trigger migrations on the preview instance.](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fdatabase%2Fconnecting-to-postgres%2Fhow-connection-pooling-works--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

Connecting to the database directly vs using a Connection Pooler

They maintain hot connections with the database and intelligently share them with clients only when needed, maximizing the amount of queries a single connection can service. They're best used to manage queries from auto-scaling systems, such as edge and serverless functions.

## Connecting with SSL [\#](https://supabase.com/docs/guides/database/connecting-to-postgres\#connecting-with-ssl)

You should connect to your database using SSL wherever possible, to prevent snooping and man-in-the-middle attacks.

You can obtain your connection info and Server root certificate from your application's dashboard:

![Connection Info and Certificate.](https://supabase.com/docs/img/database/database-settings-ssl.png)

## Resources [\#](https://supabase.com/docs/guides/database/connecting-to-postgres\#resources)

- [Connection management](https://supabase.com/docs/guides/database/connection-management)

### Is this helpful?

NoYes

### On this page

[Quick summary](https://supabase.com/docs/guides/database/connecting-to-postgres#quick-summary) [Quickstarts](https://supabase.com/docs/guides/database/connecting-to-postgres#quickstarts) [Data APIs and client libraries](https://supabase.com/docs/guides/database/connecting-to-postgres#data-apis-and-client-libraries) [Direct connection](https://supabase.com/docs/guides/database/connecting-to-postgres#direct-connection) [Shared pooler](https://supabase.com/docs/guides/database/connecting-to-postgres#shared-pooler) [Supavisor session mode](https://supabase.com/docs/guides/database/connecting-to-postgres#supavisor-session-mode) [Supavisor transaction mode](https://supabase.com/docs/guides/database/connecting-to-postgres#supavisor-transaction-mode) [Dedicated pooler](https://supabase.com/docs/guides/database/connecting-to-postgres#dedicated-pooler) [More about connection pooling](https://supabase.com/docs/guides/database/connecting-to-postgres#more-about-connection-pooling) [Application-side poolers](https://supabase.com/docs/guides/database/connecting-to-postgres#application-side-poolers) [Serverside poolers](https://supabase.com/docs/guides/database/connecting-to-postgres#serverside-poolers) [Connecting with SSL](https://supabase.com/docs/guides/database/connecting-to-postgres#connecting-with-ssl) [Resources](https://supabase.com/docs/guides/database/connecting-to-postgres#resources)

![New migration files trigger migrations on the preview instance.](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fdatabase%2Fconnecting-to-postgres%2Fhow-connection-pooling-works--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_connection_management.md">
Database

# Connection management

## Using your connections resourcefully

* * *

## Connections [\#](https://supabase.com/docs/guides/database/connection-management\#connections)

Every [Compute Add-On](https://supabase.com/docs/guides/platform/compute-add-ons) has a pre-configured direct connection count and Supavisor pool size. This guide discusses ways to observe and manage them resourcefully.

### Configuring Supavisor's pool size [\#](https://supabase.com/docs/guides/database/connection-management\#configuring-supavisors-pool-size)

You can change how many database connections Supavisor can manage by altering the pool size in the "Connection pooling configuration" section of the [Database Settings](https://supabase.com/dashboard/project/_/settings/database):

![Connection Info and Certificate.](https://supabase.com/docs/img/database/pool-size.png)

The general rule is that if you are heavily using the PostgREST database API, you should be conscientious about raising your pool size past 40%. Otherwise, you can commit 80% to the pool. This leaves adequate room for the Authentication server and other utilities.

These numbers are generalizations and depends on other Supabase products that you use and the extent of their usage. The actual values depend on your concurrent peak connection usage. For instance, if you were only using 80 connections in a week period and your database max connections is set to 500, then realistically you could allocate the difference of 420 (minus a reasonable buffer) to service more demand.

## Monitoring connections [\#](https://supabase.com/docs/guides/database/connection-management\#monitoring-connections)

### Capturing historical usage [\#](https://supabase.com/docs/guides/database/connection-management\#capturing-historical-usage)

Supabase offers a Grafana Dashboard that records and visualizes over 200 project metrics, including connections. For setup instructions, check the [metrics docs](https://supabase.com/docs/guides/platform/metrics).

Its "Client Connections" graph displays connections for both Supavisor and Postgres
![client connection graph](https://supabase.com/docs/img/database/grafana-connections.png)

### Observing live connections [\#](https://supabase.com/docs/guides/database/connection-management\#observing-live-connections)

`pg_stat_activity` is a special view that keeps track of processes being run by your database, including live connections. It's particularly useful for determining if idle clients are hogging connection slots.

Query to get all live connections:

`
SELECT
pg_stat_activity.pid as connection_id,
ssl,
datname as database,
usename as connected_role,
application_name,
client_addr as IP,
query,
query_start,
state,
backend_start
FROM pg_stat_ssl
JOIN pg_stat_activity
ON pg_stat_ssl.pid = pg_stat_activity.pid;
`

Interpreting the query:

| Column | Description |
| --- | --- |
| `connection_id` | connection id |
| `ssl` | Indicates if SSL is in use |
| `database` | Name of the connected database (usually `postgres`) |
| `usename` | Role of the connected user |
| `application_name` | Name of the connecting application |
| `client_addr` | IP address of the connecting server |
| `query` | Last query executed by the connection |
| `query_start` | Time when the last query was executed |
| `state` | Querying state: active or idle |
| `backend_start` | Timestamp of the connection's establishment |

The username can be used to identify the source:

| Role | API/Tool |
| --- | --- |
| `supabase_admin` | Used by Supabase for monitoring and by Realtime |
| `authenticator` | Data API (PostgREST) |
| `supabase_auth_admin` | Auth |
| `supabase_storage_admin` | Storage |
| `supabase_replication_admin` | Synchronizes Read Replicas |
| `postgres` | Supabase Dashboard and External Tools (e.g., Prisma, SQLAlchemy, PSQL...) |
| Custom roles defined by user | External Tools (e.g., Prisma, SQLAlchemy, PSQL...) |

### Is this helpful?

NoYes

### On this page

[Connections](https://supabase.com/docs/guides/database/connection-management#connections) [Configuring Supavisor's pool size](https://supabase.com/docs/guides/database/connection-management#configuring-supavisors-pool-size) [Monitoring connections](https://supabase.com/docs/guides/database/connection-management#monitoring-connections) [Capturing historical usage](https://supabase.com/docs/guides/database/connection-management#capturing-historical-usage) [Observing live connections](https://supabase.com/docs/guides/database/connection-management#observing-live-connections)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_custom_postgres_config.md">
Database

# Customizing Postgres configs

* * *

Each Supabase project is a pre-configured Postgres cluster. You can override some configuration settings to suit your needs. This is an advanced topic, and we don't recommend touching these settings unless it is necessary.

Customizing Postgres configurations provides _advanced_ control over your database, but inappropriate settings can lead to severe performance degradation or project instability.

### Viewing settings [\#](https://supabase.com/docs/guides/database/custom-postgres-config\#viewing-settings)

To list all Postgres settings and their descriptions, run:

`
select * from pg_settings;
`

## Configurable settings [\#](https://supabase.com/docs/guides/database/custom-postgres-config\#configurable-settings)

### User-context settings [\#](https://supabase.com/docs/guides/database/custom-postgres-config\#user-context-settings)

The [`pg_settings`](https://www.postgresql.org/docs/current/view-pg-settings.html) table's `context` column specifies the requirements for changing a setting. By default, those with a `user` context can be changed at the `role` or `database` level with [SQL](https://supabase.com/dashboard/project/_/sql/).

To list all user-context settings, run:

`
select * from pg_settings where context = 'user';
`

As an example, the `statement_timeout` setting can be altered:

`
alter database "postgres" set "statement_timeout" TO '60s';
`

To verify the change, execute:

`
show "statement_timeout";
`

### Superuser settings [\#](https://supabase.com/docs/guides/database/custom-postgres-config\#superuser-settings)

Some settings can only be modified by a superuser. Supabase pre-enables the [`supautils` extension](https://supabase.com/blog/roles-postgres-hooks#setting-up-the-supautils-extension), which allows the `postgres` role to retain certain superuser privileges. It enables modification of the below reserved configurations at the `role` level:

| Setting | Description |
| --- | --- |
| `auto_explain.log_min_duration` | Logs query plans taking longer than this duration. |
| `auto_explain.log_nested_statements` | Log nested statements' plans. |
| `log_min_messages` | Minimum severity level of messages to log. |
| `pg_net.ttl` | Sets how long the [pg\_net extension](https://supabase.com/docs/guides/database/extensions/pg_net) saves responses |
| `pg_net.batch_size` | Sets how many requests the [pg\_net extension](https://supabase.com/docs/guides/database/extensions/pg_net) can make per second |
| `pgaudit.*` | Configures the [PGAudit extension](https://supabase.com/docs/guides/database/extensions/pgaudit). The `log_parameter` is still restricted to protect secrets |
| `pgrst.*` | [`PostgREST` settings](https://docs.postgrest.org/en/stable/references/configuration.html#db-aggregates-enabled) |
| `plan_filter.*` | Configures the [pg\_plan\_filter extension](https://supabase.com/docs/guides/database/extensions/pg_plan_filter) |
| `session_replication_role` | Sets the session's behavior for triggers and rewrite rules. |
| `track_io_timing` | Collects timing statistics for database I/O activity. |

For example, to enable `log_nested_statements` for the `postgres` role, execute:

`
alter role "postgres" set "auto_explain.log_nested_statements" to 'on';
`

To view the change:

`
select
rolname,
rolconfig
from pg_roles
where rolname = 'postgres';
`

### CLI configurable settings [\#](https://supabase.com/docs/guides/database/custom-postgres-config\#cli-configurable-settings)

While many Postgres parameters are configurable directly, some configurations can be changed with the Supabase CLI at the [`system`](https://www.postgresql.org/docs/current/config-setting.html#CONFIG-SETTING-SQL) level.

CLI changes permanently overwrite default settings, so `reset all` and `set to default` commands won't revert to the original values.

In order to overwrite the default settings, you must have `Owner` or `Administrator` privileges within your organizations.

#### CLI supported parameters [\#](https://supabase.com/docs/guides/database/custom-postgres-config\#cli-supported-parameters)

If a setting you need is not yet configurable, [share your use case with us](https://supabase.com/dashboard/support/new)! Let us know what setting you'd like to control, and we'll consider adding support in future updates.

The following parameters are available for overrides:

01. [effective\_cache\_size](https://www.postgresql.org/docs/current/runtime-config-query.html#GUC-EFFECTIVE-CACHE-SIZE)
02. [logical\_decoding\_work\_mem](https://www.postgresql.org/docs/current/runtime-config-resource.html#GUC-LOGICAL-DECODING-WORK-MEM) (CLI only)
03. [maintenance\_work\_mem](https://www.postgresql.org/docs/current/runtime-config-resource.html#GUC-MAINTENANCE-WORK-MEM)
04. [max\_connections](https://www.postgresql.org/docs/current/runtime-config-connection.html#GUC-MAX-CONNECTIONS) (CLI only)
05. [max\_locks\_per\_transaction](https://www.postgresql.org/docs/current/runtime-config-locks.html#GUC-MAX-LOCKS-PER-TRANSACTION) (CLI only)
06. [max\_parallel\_maintenance\_workers](https://www.postgresql.org/docs/current/runtime-config-resource.html#GUC-MAX-PARALLEL-MAINTENANCE-WORKERS)
07. [max\_parallel\_workers\_per\_gather](https://www.postgresql.org/docs/current/runtime-config-resource.html#GUC-MAX-PARALLEL-WORKERS-PER-GATHER)
08. [max\_parallel\_workers](https://www.postgresql.org/docs/current/runtime-config-resource.html#GUC-MAX-PARALLEL-WORKERS)
09. [max\_replication\_slots](https://www.postgresql.org/docs/current/runtime-config-replication.html#GUC-MAX-REPLICATION-SLOTS) (CLI only)
10. [max\_slot\_wal\_keep\_size](https://www.postgresql.org/docs/current/runtime-config-replication.html#GUC-MAX-SLOT-WAL-KEEP-SIZE) (CLI only)
11. [max\_standby\_archive\_delay](https://www.postgresql.org/docs/current/runtime-config-replication.html#GUC-MAX-STANDBY-ARCHIVE-DELAY) (CLI only)
12. [max\_standby\_streaming\_delay](https://www.postgresql.org/docs/current/runtime-config-replication.html#GUC-MAX-STANDBY-STREAMING-DELAY) (CLI only)
13. [max\_wal\_size](https://www.postgresql.org/docs/current/runtime-config-wal.html#GUC-MAX-WAL-SIZE) (CLI only)
14. [max\_wal\_senders](https://www.postgresql.org/docs/current/runtime-config-replication.html#GUC-MAX-WAL-SENDERS) (CLI only)
15. [max\_worker\_processes](https://www.postgresql.org/docs/current/runtime-config-resource.html#GUC-MAX-WORKER-PROCESSES) (CLI only)
16. [session\_replication\_role](https://www.postgresql.org/docs/current/runtime-config-client.html#GUC-SESSION-REPLICATION-ROLE)
17. [shared\_buffers](https://www.postgresql.org/docs/current/runtime-config-resource.html#GUC-SHARED-BUFFERS) (CLI only)
18. [statement\_timeout](https://www.postgresql.org/docs/current/runtime-config-client.html#GUC-STATEMENT-TIMEOUT)
19. [track\_activity\_query\_size](https://www.postgresql.org/docs/current/runtime-config-statistics.html#GUC-TRACK-ACTIVITY-QUERY-SIZE)
20. [track\_commit\_timestamp](https://www.postgresql.org/docs/current/runtime-config-replication.html#GUC-TRACK-COMMIT-TIMESTAMP)
21. [wal\_keep\_size](https://www.postgresql.org/docs/current/runtime-config-replication.html#GUC-WAL-KEEP-SIZE) (CLI only)
22. [wal\_sender\_timeout](https://www.postgresql.org/docs/current/runtime-config-replication.html#GUC-WAL-SENDER-TIMEOUT) (CLI only)
23. [work\_mem](https://www.postgresql.org/docs/current/runtime-config-resource.html#GUC-WORK-MEM)

#### Managing Postgres configuration with the CLI [\#](https://supabase.com/docs/guides/database/custom-postgres-config\#managing-postgres-configuration-with-the-cli)

To start:

1. [Install](https://supabase.com/docs/guides/resources/supabase-cli) Supabase CLI 1.69.0+.
2. [Log in](https://supabase.com/docs/guides/cli/local-development#log-in-to-the-supabase-cli) to your Supabase account using the CLI.

To update Postgres configurations, use the [`postgres config`](https://supabase.com/docs/reference/cli/supabase-postgres-config) command:

`
supabase --experimental \
--project-ref <project-ref> \
postgres-config update --config shared_buffers=250MB
`

By default, the CLI will merge any provided config overrides with any existing ones. The `--replace-existing-overrides` flag can be used to instead force all existing overrides to be replaced with the ones being provided:

`
supabase --experimental \
--project-ref <project-ref> \
postgres-config update --config max_parallel_workers=3 \
--replace-existing-overrides
`

To delete specific configuration overrides, use the `postgres-config delete` command:

`
supabase --experimental \
--project-ref <project-ref> \
postgres-config delete --config shared_buffers,work_mem
`

By default, changing the configuration, whether by updating or deleting, causes the database and all associated read replicas to restart. You can use the `--no-restart` flag to prevent this behavior, and attempt to reload the updated configuration without a restart. Refer to the Postgres documentation to determine if a given parameter can be reloaded without a restart.

##### Read Replicas and Custom Config

Postgres requires several parameters to be synchronized between the Primary cluster and [Read Replicas](https://supabase.com/docs/guides/platform/read-replicas).

By default, Supabase ensures that this propagation is executed correctly. However, if the `--no-restart` behavior is used in conjunction with parameters that cannot be reloaded without a restart, the user is responsible for ensuring that both the primaries and the read replicas get restarted in a timely manner to ensure a stable running state. Leaving the configuration updated, but not utilized (via a restart) in such a case can result in read replica failure if the primary, or a read replica, restarts in isolation (e.g. due to an out-of-memory event, or hardware failure).

`
supabase --experimental \
--project-ref <project-ref> \
postgres-config delete --config shared_buffers --no-restart
`

### Resetting to default config [\#](https://supabase.com/docs/guides/database/custom-postgres-config\#resetting-to-default-config)

To reset a setting to its default value at the database level:

`
-- reset a single setting at the database level
alter database "postgres" set "<setting_name>" to default;
-- reset all settings at the database level
alter database "postgres" reset all;
`

For `role` level configurations, you can run:

`
alter role "<role_name>" set "<setting_name>" to default;
`

### Considerations [\#](https://supabase.com/docs/guides/database/custom-postgres-config\#considerations)

1. Changes through the CLI might restart the database causing momentary disruption to existing database connections; in most cases this should not take more than a few seconds. However, you can use the --no-restart flag to bypass the restart and keep the connections intact. Keep in mind that this depends on the specific configuration changes you're making. if the change requires a restart, using the --no-restart flag will prevent the restart but you won't see those changes take effect until a restart is manually triggered. Additionally, some parameters are required to be the same on Primary and Read Replicas; not restarting in these cases can result in read replica failure if the Primary/Read Replicas restart in isolation.
2. Custom Postgres Config will always override the default optimizations generated by Supabase. When changing compute add-ons, you should also review and update your custom Postgres Config to ensure they remain compatible and effective with the updated compute.
3. Some parameters (e.g. `wal_keep_size`) can increase disk utilization, triggering disk expansion, which in turn can lead to [increases in your bill](https://supabase.com/docs/guides/platform/compute-add-ons#disk-io).

### Is this helpful?

NoYes

### On this page

[Viewing settings](https://supabase.com/docs/guides/database/custom-postgres-config#viewing-settings) [Configurable settings](https://supabase.com/docs/guides/database/custom-postgres-config#configurable-settings) [User-context settings](https://supabase.com/docs/guides/database/custom-postgres-config#user-context-settings) [Superuser settings](https://supabase.com/docs/guides/database/custom-postgres-config#superuser-settings) [CLI configurable settings](https://supabase.com/docs/guides/database/custom-postgres-config#cli-configurable-settings) [Resetting to default config](https://supabase.com/docs/guides/database/custom-postgres-config#resetting-to-default-config) [Considerations](https://supabase.com/docs/guides/database/custom-postgres-config#considerations)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_dbeaver.md">
Database

# Connecting with DBeaver

* * *

If you do not have DBeaver, you can download it from its [website](https://dbeaver.io/download/).

1

### Create a new database connection

Create a new database connection

![new database connection](https://supabase.com/docs/img/guides/database/connecting-to-postgres/dbeaver/new_database_connection.png)

2

### Select PostgreSQL

![Selection Menu](https://supabase.com/docs/img/guides/database/connecting-to-postgres/dbeaver/select_postgres.png)

3

### Get Your Credentials

Inside the Dashboard's [Database Settings](https://supabase.com/dashboard/project/_/settings/database), note your session mode's:

- host
- username

You will also need your database's password. If you forgot it, you can generate a new one in the settings.

If you're in an [IPv6 environment](https://github.com/orgs/supabase/discussions/27034) or have the IPv4 Add-On, you can use the direct connection string instead of Supavisor in Session mode.

![database credentials](https://supabase.com/docs/img/guides/database/connecting-to-postgres/dbeaver/session_mode.png)

4

### Fill out credentials

In DBeaver's Main menu, add your host, username, and password

![filling out form](https://supabase.com/docs/img/guides/database/connecting-to-postgres/dbeaver/filling_credentials.png)

5

### Download certificate

In the [Database Settings](https://supabase.com/dashboard/project/_/settings/database), download your SSL certificate.

![filling out form](https://supabase.com/docs/img/guides/database/connecting-to-postgres/dbeaver/certificate.png)

6

### Secure your connection

In DBeaver's SSL tab, add your SSL certificate

![filling out form](https://supabase.com/docs/img/guides/database/connecting-to-postgres/dbeaver/ssl_tab.png)

7

### Connect

Test your connection and then click finish. You should now be able to interact with your database with DBeaver

![connected dashboard](https://supabase.com/docs/img/guides/database/connecting-to-postgres/dbeaver/finished.png)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_debugging_performance.md">
Database

# Debugging performance issues

## Debug slow-running queries using the Postgres execution planner.

* * *

`explain()` is a method that provides the Postgres `EXPLAIN` execution plan of a query. It is a powerful tool for debugging slow queries and understanding how Postgres will execute a given query. This feature is applicable to any query, including those made through `rpc()` or write operations.

## Enabling `explain()` [\#](https://supabase.com/docs/guides/database/debugging-performance\#enabling-explain)

`explain()` is disabled by default to protect sensitive information about your database structure and operations. We recommend using `explain()` in a non-production environment. Run the following SQL to enable `explain()`:

`
-- enable explain
alter role authenticator
set pgrst.db_plan_enabled to 'true';
-- reload the config
notify pgrst, 'reload config';
`

## Using `explain()` [\#](https://supabase.com/docs/guides/database/debugging-performance\#using-explain)

To get the execution plan of a query, you can chain the `explain()` method to a Supabase query:

`
const { data, error } = await supabase
.from('instruments')
.select()
.explain()
`

### Example data [\#](https://supabase.com/docs/guides/database/debugging-performance\#example-data)

To illustrate, consider the following setup of a `instruments` table:

`
create table instruments (
id int8 primary key,
name text
);
insert into books
(id, name)
values
(1, 'violin'),
(2, 'viola'),
(3, 'cello');
`

### Expected response [\#](https://supabase.com/docs/guides/database/debugging-performance\#expected-response)

The response would typically look like this:

`
Aggregate  (cost=33.34..33.36 rows=1 width=112)
  ->  Limit  (cost=0.00..18.33 rows=1000 width=40)
        ->  Seq Scan on instruments  (cost=0.00..22.00 rows=1200 width=40)
`

By default, the execution plan is returned in TEXT format. However, you can also retrieve it as JSON by specifying the `format` parameter.

## Production use with pre-request protection [\#](https://supabase.com/docs/guides/database/debugging-performance\#production-use-with-pre-request-protection)

If you need to enable `explain()` in a production environment, ensure you protect your database by restricting access to the `explain()` feature. You can do so by using a pre-request function that filters requests based on the IP address:

`
create or replace function filter_plan_requests()
returns void as $$
declare
headers   json := current_setting('request.headers', true)::json;
client_ip text := coalesce(headers->>'cf-connecting-ip', '');
accept    text := coalesce(headers->>'accept', '');
your_ip   text := '123.123.123.123'; -- replace this with your IP
begin
if accept like 'application/vnd.pgrst.plan%' and client_ip != your_ip then
    raise insufficient_privilege using
      message = 'Not allowed to use application/vnd.pgrst.plan';
end if;
end; $$ language plpgsql;
alter role authenticator set pgrst.db_pre_request to 'filter_plan_requests';
notify pgrst, 'reload config';
`

Replace `'123.123.123.123'` with your actual IP address.

## Disabling explain [\#](https://supabase.com/docs/guides/database/debugging-performance\#disabling-explain)

To disable the `explain()` method after use, execute the following SQL commands:

`
-- disable explain
alter role authenticator
set pgrst.db_plan_enabled to 'false';
-- if you used the above pre-request
alter role authenticator
set pgrst.db_pre_request to '';
-- reload the config
notify pgrst, 'reload config';
`

### Is this helpful?

NoYes

### On this page

[Enabling explain()](https://supabase.com/docs/guides/database/debugging-performance#enabling-explain) [Using explain()](https://supabase.com/docs/guides/database/debugging-performance#using-explain) [Example data](https://supabase.com/docs/guides/database/debugging-performance#example-data) [Expected response](https://supabase.com/docs/guides/database/debugging-performance#expected-response) [Production use with pre-request protection](https://supabase.com/docs/guides/database/debugging-performance#production-use-with-pre-request-protection) [Disabling explain](https://supabase.com/docs/guides/database/debugging-performance#disabling-explain)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_drizzle.md">
Database

# Drizzle

* * *

### Connecting with Drizzle [\#](https://supabase.com/docs/guides/database/drizzle\#connecting-with-drizzle)

[Drizzle ORM](https://github.com/drizzle-team/drizzle-orm) is a TypeScript ORM for SQL databases designed with maximum type safety in mind. You can use their ORM to connect to your database.

If you plan on solely using Drizzle instead of the Supabase Data API (PostgREST), you can turn off the latter in the [API Settings](https://supabase.com/dashboard/project/_/settings/api).

1

### Install

Install Drizzle and related dependencies.

`
npm i drizzle-orm postgres
npm i -D drizzle-kit
`

2

### Create your models

Create a `schema.ts` file and define your models.

schema.ts

`
import { pgTable, serial, text, varchar } from "drizzle-orm/pg-core";
export const users = pgTable('users', {
id: serial('id').primaryKey(),
fullName: text('full_name'),
phone: varchar('phone', { length: 256 }),
});
`

3

### Connect

Connect to your database using the Connection Pooler.

In your [`Database Settings`](https://supabase.com/dashboard/project/_/settings/database), make sure `Use connection pooler` is checked, then copy the URI and save it as the `DATABASE_URL` environment variable. Remember to replace the password placeholder with your actual database password.

db.ts

`
import 'dotenv/config'
import { drizzle } from 'drizzle-orm/postgres-js'
import postgres from 'postgres'
const connectionString = process.env.DATABASE_URL
// Disable prefetch as it is not supported for "Transaction" pool mode
export const client = postgres(connectionString, { prepare: false })
export const db = drizzle(client);
`

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_extensions_http.md">
Database

# http: RESTful Client

* * *

The `http` extension allows you to call RESTful endpoints within Postgres.

## Quick demo [\#](https://supabase.com/docs/guides/database/extensions/http\#quick-demo)

Using PostgreSQL functions to call an API with Supabase - YouTube

Supabase

45.5K subscribers

[Using PostgreSQL functions to call an API with Supabase](https://www.youtube.com/watch?v=rARgrELRCwY)

Supabase

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=rARgrELRCwY "Watch on YouTube")

## Overview [\#](https://supabase.com/docs/guides/database/extensions/http\#overview)

Let's cover some basic concepts:

- REST: stands for REpresentational State Transfer. It's a way to request data from external services.
- RESTful APIs are servers which accept HTTP "calls". The calls are typically:
  - `GET`  Read only access to a resource.
  - `POST`  Creates a new resource.
  - `DELETE`  Removes a resource.
  - `PUT`  Updates an existing resource or creates a new resource.

You can use the `http` extension to make these network requests from Postgres.

## Usage [\#](https://supabase.com/docs/guides/database/extensions/http\#usage)

### Enable the extension [\#](https://supabase.com/docs/guides/database/extensions/http\#enable-the-extension)

DashboardSQL

1. Go to the [Database](https://supabase.com/dashboard/project/_/database/tables) page in the Dashboard.
2. Click on **Extensions** in the sidebar.
3. Search for `http` and enable the extension.

### Available functions [\#](https://supabase.com/docs/guides/database/extensions/http\#available-functions)

While the main usage is `http('http_request')`, there are 5 wrapper functions for specific functionality:

- `http_get()`
- `http_post()`
- `http_put()`
- `http_delete()`
- `http_head()`

### Returned values [\#](https://supabase.com/docs/guides/database/extensions/http\#returned-values)

A successful call to a web URL from the `http` extension returns a record with the following fields:

- `status`: integer
- `content_type`: character varying
- `headers`: http\_header\[\]
- `content`: character varying. Typically you would want to cast this to `jsonb` using the format `content::jsonb`

## Examples [\#](https://supabase.com/docs/guides/database/extensions/http\#examples)

### Simple `GET` example [\#](https://supabase.com/docs/guides/database/extensions/http\#simple-get-example)

`
select
"status", "content"::jsonb
from
http_get('https://jsonplaceholder.typicode.com/todos/1');
`

### Simple `POST` example [\#](https://supabase.com/docs/guides/database/extensions/http\#simple-post-example)

`
select
"status", "content"::jsonb
from
http_post(
    'https://jsonplaceholder.typicode.com/posts',
    '{ "title": "foo", "body": "bar", "userId": 1 }',
    'application/json'
);
`

## Resources [\#](https://supabase.com/docs/guides/database/extensions/http\#resources)

- Official [`http` GitHub Repository](https://github.com/pramsey/pgsql-http)

### Is this helpful?

NoYes

### On this page

[Quick demo](https://supabase.com/docs/guides/database/extensions/http#quick-demo) [Overview](https://supabase.com/docs/guides/database/extensions/http#overview) [Usage](https://supabase.com/docs/guides/database/extensions/http#usage) [Enable the extension](https://supabase.com/docs/guides/database/extensions/http#enable-the-extension) [Available functions](https://supabase.com/docs/guides/database/extensions/http#available-functions) [Returned values](https://supabase.com/docs/guides/database/extensions/http#returned-values) [Examples](https://supabase.com/docs/guides/database/extensions/http#examples) [Simple GET example](https://supabase.com/docs/guides/database/extensions/http#simple-get-example) [Simple POST example](https://supabase.com/docs/guides/database/extensions/http#simple-post-example) [Resources](https://supabase.com/docs/guides/database/extensions/http#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_extensions_hypopg.md">
Database

# HypoPG: Hypothetical indexes

* * *

`HypoPG` is Postgres extension for creating hypothetical/virtual indexes. HypoPG allows users to rapidly create hypothetical/virtual indexes that have no resource cost (CPU, disk, memory) that are visible to the Postgres query planner.

The motivation for HypoPG is to allow users to quickly search for an index to improve a slow query without consuming server resources or waiting for them to build.

## Enable the extension [\#](https://supabase.com/docs/guides/database/extensions/hypopg\#enable-the-extension)

DashboardSQL

1. Go to the [Database](https://supabase.com/dashboard/project/_/database/tables) page in the Dashboard.
2. Click on **Extensions** in the sidebar.
3. Search for `hypopg` and enable the extension.

### Speeding up a query [\#](https://supabase.com/docs/guides/database/extensions/hypopg\#speeding-up-a-query)

Given the following table and a simple query to select from the table by `id`:

`
create table account (
id int,
address text
);
insert into account(id, address)
select
id,
id || ' main street'
from
generate_series(1, 10000) id;
`

We can generate an explain plan for a description of how the Postgres query planner
intends to execute the query.

`
explain select * from account where id=1;
                      QUERY PLAN
-------------------------------------------------------
Seq Scan on account  (cost=0.00..180.00 rows=1 width=13)
Filter: (id = 1)
(2 rows)
`

Using HypoPG, we can create a hypothetical index on the `account(id)` column to check if it would be useful to the query planner and then re-run the explain plan.

Note that the virtual indexes created by HypoPG are only visible in the Postgres connection that they were created in. Supabase connects to Postgres through a connection pooler so the `hypopg_create_index` statement and the `explain` statement should be executed in a single query.

`
select * from hypopg_create_index('create index on account(id)');
explain select * from account where id=1;
                                     QUERY PLAN
------------------------------------------------------------------------------------
Index Scan using <13504>btree_account_id on hypo  (cost=0.29..8.30 rows=1 width=13)
Index Cond: (id = 1)
(2 rows)
`

The query plan has changed from a `Seq Scan` to an `Index Scan` using the newly created virtual index, so we may choose to create a real version of the index to improve performance on the target query:

`
create index on account(id);
`

## Functions [\#](https://supabase.com/docs/guides/database/extensions/hypopg\#functions)

- [`hypo_create_index(text)`](https://hypopg.readthedocs.io/en/rel1_stable/usage.html#create-a-hypothetical-index): A function to create a hypothetical index.
- [`hypopg_list_indexes`](https://hypopg.readthedocs.io/en/rel1_stable/usage.html#manipulate-hypothetical-indexes): A View that lists all hypothetical indexes that have been created.
- [`hypopg()`](https://hypopg.readthedocs.io/en/rel1_stable/usage.html#manipulate-hypothetical-indexes): A function that lists all hypothetical indexes that have been created with the same format as `pg_index`.
- [`hypopg_get_index_def(oid)`](https://hypopg.readthedocs.io/en/rel1_stable/usage.html#manipulate-hypothetical-indexes): A function to display the `create index` statement that would create the index.
- [`hypopg_get_relation_size(oid)`](https://hypopg.readthedocs.io/en/rel1_stable/usage.html#manipulate-hypothetical-indexes): A function to estimate how large a hypothetical index would be.
- [`hypopg_drop_index(oid)`](https://hypopg.readthedocs.io/en/rel1_stable/usage.html#manipulate-hypothetical-indexes): A function to remove a given hypothetical index by `oid`.
- [`hypopg_reset()`](https://hypopg.readthedocs.io/en/rel1_stable/usage.html#manipulate-hypothetical-indexes): A function to remove all hypothetical indexes.

## Resources [\#](https://supabase.com/docs/guides/database/extensions/hypopg\#resources)

- Official [HypoPG documentation](https://hypopg.readthedocs.io/en/rel1_stable/)

### Is this helpful?

NoYes

### On this page

[Enable the extension](https://supabase.com/docs/guides/database/extensions/hypopg#enable-the-extension) [Speeding up a query](https://supabase.com/docs/guides/database/extensions/hypopg#speeding-up-a-query) [Functions](https://supabase.com/docs/guides/database/extensions/hypopg#functions) [Resources](https://supabase.com/docs/guides/database/extensions/hypopg#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_extensions_index_advisor.md">
Database

# index\_advisor: query optimization

* * *

[Index advisor](https://github.com/supabase/index_advisor) is a Postgres extension for recommending indexes to improve query performance.

Features:

- Supports generic parameters e.g. `$1`, `$2`
- Supports materialized views
- Identifies tables/columns obfuscated by views
- Skips duplicate indexes

`index_advisor` is accessible directly through Supabase Studio by navigating to the [Query Performance Report](https://supabase.com/dashboard/project/_/advisors/query-performance) and selecting a query and then the "indexes" tab.

![Supabase Studio index_advisor integration.](https://supabase.com/docs/img/index_advisor_studio.png)

Alternatively, you can use index\_advisor directly via SQL.

For example:

`
select
    *
from
index_advisor('select book.id from book where title = $1');
startup_cost_before | startup_cost_after | total_cost_before | total_cost_after |                  index_statements                   | errors
---------------------+--------------------+-------------------+------------------+-----------------------------------------------------+--------
0.00                | 1.17               | 25.88             | 6.40             | {"CREATE INDEX ON public.book USING btree (title)"},| {}
(1 row)
`

## Installation [\#](https://supabase.com/docs/guides/database/extensions/index_advisor\#installation)

To get started, enable index\_advisor by running

`
create extension index_advisor;
`

## API [\#](https://supabase.com/docs/guides/database/extensions/index_advisor\#api)

Index advisor exposes a single function `index_advisor(query text)` that accepts a query and searches for a set of SQL DDL `create index` statements that improve the query's execution time.

The function's signature is:

`
index_advisor(query text)
returns
    table  (
        startup_cost_before jsonb,
        startup_cost_after jsonb,
        total_cost_before jsonb,
        total_cost_after jsonb,
        index_statements text[],
        errors text[]
    )
`

## Usage [\#](https://supabase.com/docs/guides/database/extensions/index_advisor\#usage)

As a minimal example, the `index_advisor` function can be given a single table query with a filter on an unindexed column.

`
create extension if not exists index_advisor cascade;
create table book(
id int primary key,
title text not null
);
select
*
from
index_advisor('select book.id from book where title = $1');
startup_cost_before | startup_cost_after | total_cost_before | total_cost_after |                  index_statements                   | errors
---------------------+--------------------+-------------------+------------------+-----------------------------------------------------+--------
0.00                | 1.17               | 25.88             | 6.40             | {"CREATE INDEX ON public.book USING btree (title)"},| {}
(1 row)
`

and will return a row recommending an index on the unindexed column.

More complex queries may generate additional suggested indexes:

`
create extension if not exists index_advisor cascade;
create table author(
    id serial primary key,
    name text not null
);
create table publisher(
    id serial primary key,
    name text not null,
    corporate_address text
);
create table book(
    id serial primary key,
    author_id int not null references author(id),
    publisher_id int not null references publisher(id),
    title text
);
create table review(
    id serial primary key,
    book_id int references book(id),
    body text not null
);
select
    *
from
    index_advisor('
        select
            book.id,
            book.title,
            publisher.name as publisher_name,
            author.name as author_name,
            review.body review_body
        from
            book
            join publisher
                on book.publisher_id = publisher.id
            join author
                on book.author_id = author.id
            join review
                on book.id = review.book_id
        where
            author.id = $1
            and publisher.id = $2
    ');
startup_cost_before | startup_cost_after | total_cost_before | total_cost_after |                  index_statements                         | errors
---------------------+--------------------+-------------------+------------------+-----------------------------------------------------------+--------
27.26               | 12.77              | 68.48             | 42.37            | {"CREATE INDEX ON public.book USING btree (author_id)",   | {}
                                                                                    "CREATE INDEX ON public.book USING btree (publisher_id)",
                                                                                    "CREATE INDEX ON public.review USING btree (book_id)"}
(3 rows)
`

## Limitations [\#](https://supabase.com/docs/guides/database/extensions/index_advisor\#limitations)

- index\_advisor will only recommend single column, B-tree indexes. More complex indexes will be supported in future releases.
- when a generic argument's type is not discernible from context, an error is returned in the `errors` field. To resolve those errors, add explicit type casting to the argument. e.g. `$1::int`.

## Resources [\#](https://supabase.com/docs/guides/database/extensions/index_advisor\#resources)

- [`index_advisor`](https://github.com/supabase/index_advisor) repo

### Is this helpful?

NoYes

### On this page

[Installation](https://supabase.com/docs/guides/database/extensions/index_advisor#installation) [API](https://supabase.com/docs/guides/database/extensions/index_advisor#api) [Usage](https://supabase.com/docs/guides/database/extensions/index_advisor#usage) [Limitations](https://supabase.com/docs/guides/database/extensions/index_advisor#limitations) [Resources](https://supabase.com/docs/guides/database/extensions/index_advisor#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_extensions_pg_cron.md">
Database

# pg\_cron: Schedule Recurring Jobs with Cron Syntax in Postgres

* * *

See the [Supabase Cron docs](https://supabase.com/docs/guides/cron).

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_extensions_pg_graphql.md">
Database

# pg\_graphql: GraphQL for PostgreSQL

* * *

[pg\_graphql](https://supabase.github.io/pg_graphql/) is Postgres extension for interacting with the database using [GraphQL](https://graphql.org/) instead of SQL.

The extension reflects a GraphQL schema from the existing SQL schema and exposes it through a SQL function, `graphql.resolve(...)`. This enables any programming language that can connect to Postgres to query the database via GraphQL with no additional servers, processes, or libraries.

The `pg_graphql` resolve method is designed to interop with [PostgREST](https://postgrest.org/en/stable/index.html), the tool that underpins the Supabase API, such that the `graphql.resolve` function can be called via RPC to safely and performantly expose the GraphQL API over HTTP/S.

For more information about how the SQL schema is reflected into a GraphQL schema, see the [pg\_graphql API docs](https://supabase.github.io/pg_graphql/api/).

## Enable the extension [\#](https://supabase.com/docs/guides/database/extensions/pg_graphql\#enable-the-extension)

DashboardSQL

1. Go to the [Database](https://supabase.com/dashboard/project/_/database/tables) page in the Dashboard.
2. Click on **Extensions** in the sidebar.
3. Search for "pg\_graphql" and enable the extension.

## Usage [\#](https://supabase.com/docs/guides/database/extensions/pg_graphql\#usage)

Given a table

`
create table "Blog"(
id serial primary key,
name text not null,
description text
);
insert into "Blog"(name)
values ('My Blog');
`

The reflected GraphQL schema can be queried immediately as

`
select
graphql.resolve($$
    {
      blogCollection(first: 1) {
        edges {
          node {
            id,
            name
          }
        }
      }
    }
$$);
`

returning the JSON

`
{
"data": {
    "blogCollection": {
      "edges": [\
        {\
          "node": {\
            "id": 1\
            "name": "My Blog"\
          }\
        }\
      ]
    }
}
}
`

Note that `pg_graphql` fully supports schema introspection so you can connect any GraphQL IDE or schema inspection tool to see the full set of fields and arguments available in the API.

## API [\#](https://supabase.com/docs/guides/database/extensions/pg_graphql\#api)

- [`graphql.resolve`](https://supabase.github.io/pg_graphql/sql_interface/): A SQL function for executing GraphQL queries.

## Resources [\#](https://supabase.com/docs/guides/database/extensions/pg_graphql\#resources)

- Official [`pg_graphql` documentation](https://github.com/supabase/pg_graphql)

### Is this helpful?

NoYes

### On this page

[Enable the extension](https://supabase.com/docs/guides/database/extensions/pg_graphql#enable-the-extension) [Usage](https://supabase.com/docs/guides/database/extensions/pg_graphql#usage) [API](https://supabase.com/docs/guides/database/extensions/pg_graphql#api) [Resources](https://supabase.com/docs/guides/database/extensions/pg_graphql#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_extensions_pg_hashids.md">
Database

# pg\_hashids: Short UIDs

* * *

[pg\_hashids](https://github.com/iCyberon/pg_hashids) provides a secure way to generate short, unique, non-sequential ids from numbers. The hashes are intended to be small, easy-to-remember identifiers that can be used to obfuscate data (optionally) with a password, alphabet, and salt. For example, you may wish to hide data like user IDs, order numbers, or tracking codes in favor of `pg_hashid`'s unique identifiers.

## Enable the extension [\#](https://supabase.com/docs/guides/database/extensions/pg_hashids\#enable-the-extension)

DashboardSQL

1. Go to the [Database](https://supabase.com/dashboard/project/_/database/tables) page in the Dashboard.
2. Click on **Extensions** in the sidebar.
3. Search for "pg\_hashids" and enable the extension.

## Usage [\#](https://supabase.com/docs/guides/database/extensions/pg_hashids\#usage)

Suppose we have a table that stores order information, and we want to give customers a unique identifier without exposing the sequential `id` column. To do this, we can use `pg_hashid`'s `id_encode` function.

`
create table orders (
id serial primary key,
description text,
price_cents bigint
);
insert into orders (description, price_cents)
values ('a book', 9095);
select
id,
id_encode(id) as short_id,
description,
price_cents
from
orders;
id | short_id | description | price_cents
----+----------+-------------+-------------
1 | jR       | a book      |        9095
(1 row)
`

To reverse the `short_id` back into an `id`, there is an equivalent function named `id_decode`.

## Resources [\#](https://supabase.com/docs/guides/database/extensions/pg_hashids\#resources)

- Official [pg\_hashids documentation](https://github.com/iCyberon/pg_hashids)

### Is this helpful?

NoYes

### On this page

[Enable the extension](https://supabase.com/docs/guides/database/extensions/pg_hashids#enable-the-extension) [Usage](https://supabase.com/docs/guides/database/extensions/pg_hashids#usage) [Resources](https://supabase.com/docs/guides/database/extensions/pg_hashids#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_extensions_pg_jsonschema.md">
Database

# pg\_jsonschema: JSON Schema Validation

* * *

[JSON Schema](https://json-schema.org/) is a language for annotating and validating JSON documents. [`pg_jsonschema`](https://github.com/supabase/pg_jsonschema) is a Postgres extension that adds the ability to validate PostgreSQL's built-in `json` and `jsonb` data types against JSON Schema documents.

## Enable the extension [\#](https://supabase.com/docs/guides/database/extensions/pg_jsonschema\#enable-the-extension)

DashboardSQL

1. Go to the [Database](https://supabase.com/dashboard/project/_/database/tables) page in the Dashboard.
2. Click on **Extensions** in the sidebar.
3. Search for `pg_jsonschema` and enable the extension.

## Functions [\#](https://supabase.com/docs/guides/database/extensions/pg_jsonschema\#functions)

- [`json_matches_schema(schema json, instance json)`](https://github.com/supabase/pg_jsonschema#api): Checks if a `json` _instance_ conforms to a JSON Schema _schema_.
- [`jsonb_matches_schema(schema json, instance jsonb)`](https://github.com/supabase/pg_jsonschema#api): Checks if a `jsonb` _instance_ conforms to a JSON Schema _schema_.

## Usage [\#](https://supabase.com/docs/guides/database/extensions/pg_jsonschema\#usage)

Since `pg_jsonschema` exposes its utilities as functions, we can execute them with a select statement:

`
select
extensions.json_matches_schema(
    schema := '{"type": "object"}',
    instance := '{}'
);
`

`pg_jsonschema` is generally used in tandem with a [check constraint](https://www.postgresql.org/docs/current/ddl-constraints.html) as a way to constrain the contents of a json/b column to match a JSON Schema.

`
create table customer(
    id serial primary key,
    ...
    metadata json,
    check (
        json_matches_schema(
            '{
                "type": "object",
                "properties": {
                    "tags": {
                        "type": "array",
                        "items": {
                            "type": "string",
                            "maxLength": 16
                        }
                    }
                }
            }',
            metadata
        )
    )
);
-- Example: Valid Payload
insert into customer(metadata)
values ('{"tags": ["vip", "darkmode-ui"]}');
-- Result:
--   INSERT 0 1
-- Example: Invalid Payload
insert into customer(metadata)
values ('{"tags": [1, 3]}');
-- Result:
--   ERROR:  new row for relation "customer" violates check constraint "customer_metadata_check"
--   DETAIL:  Failing row contains (2, {"tags": [1, 3]}).
`

## Resources [\#](https://supabase.com/docs/guides/database/extensions/pg_jsonschema\#resources)

- Official [`pg_jsonschema` documentation](https://github.com/supabase/pg_jsonschema)

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2FamJo48ChLGs%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Enable the extension](https://supabase.com/docs/guides/database/extensions/pg_jsonschema#enable-the-extension) [Functions](https://supabase.com/docs/guides/database/extensions/pg_jsonschema#functions) [Usage](https://supabase.com/docs/guides/database/extensions/pg_jsonschema#usage) [Resources](https://supabase.com/docs/guides/database/extensions/pg_jsonschema#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_extensions_pg_net.md">
Database

# pg\_net: Async Networking

* * *

The pg\_net API is in beta. Functions signatures may change.

[pg\_net](https://github.com/supabase/pg_net/) enables Postgres to make asynchronous HTTP/HTTPS requests in SQL. It differs from the [`http`](https://supabase.com/docs/guides/database/extensions/http) extension in that it is asynchronous by default. This makes it useful in blocking functions (like triggers).

It eliminates the need for servers to continuously poll for database changes and instead allows the database to proactively notify external resources about significant events.

## Enable the extension [\#](https://supabase.com/docs/guides/database/extensions/pg_net\#enable-the-extension)

DashboardSQL

1. Go to the [Database](https://supabase.com/dashboard/project/_/database/tables) page in the Dashboard.
2. Click on **Extensions** in the sidebar.
3. Search for "pg\_net" and enable the extension.

## `http_get` [\#](https://supabase.com/docs/guides/database/extensions/pg_net\#httpget)

Creates an HTTP GET request returning the request's ID. HTTP requests are not started until the transaction is committed.

### Signature [\#](https://supabase.com/docs/guides/database/extensions/pg_net\#get-signature)

This is a Postgres [SECURITY DEFINER](https://supabase.com/docs/guides/database/postgres/row-level-security#use-security-definer-functions) function.

``
net.http_get(
    -- url for the request
    url text,
    -- key/value pairs to be url encoded and appended to the `url`
    params jsonb default '{}'::jsonb,
    -- key/values to be included in request headers
    headers jsonb default '{}'::jsonb,
    -- the maximum number of milliseconds the request may take before being canceled
    timeout_milliseconds int default 2000
)
    -- request_id reference
    returns bigint
    strict
    volatile
    parallel safe
    language plpgsql
``

### Usage [\#](https://supabase.com/docs/guides/database/extensions/pg_net\#get-usage)

`
select
    net.http_get('https://news.ycombinator.com')
    as request_id;
request_id
----------
         1
(1 row)
`

## `http_post` [\#](https://supabase.com/docs/guides/database/extensions/pg_net\#httppost)

Creates an HTTP POST request with a JSON body, returning the request's ID. HTTP requests are not started until the transaction is committed.

The body's character set encoding matches the database's `server_encoding` setting.

### Signature [\#](https://supabase.com/docs/guides/database/extensions/pg_net\#post-signature)

This is a Postgres [SECURITY DEFINER](https://supabase.com/docs/guides/database/postgres/row-level-security#use-security-definer-functions) function

``
net.http_post(
    -- url for the request
    url text,
    -- body of the POST request
    body jsonb default '{}'::jsonb,
    -- key/value pairs to be url encoded and appended to the `url`
    params jsonb default '{}'::jsonb,
    -- key/values to be included in request headers
    headers jsonb default '{"Content-Type": "application/json"}'::jsonb,
    -- the maximum number of milliseconds the request may take before being canceled
    timeout_milliseconds int default 2000
)
    -- request_id reference
    returns bigint
    volatile
    parallel safe
    language plpgsql
``

### Usage [\#](https://supabase.com/docs/guides/database/extensions/pg_net\#post-usage)

`
select
    net.http_post(
        url:='https://httpbin.org/post',
        body:='{"hello": "world"}'::jsonb
    ) as request_id;
request_id
----------
         1
(1 row)
`

## `http_delete` [\#](https://supabase.com/docs/guides/database/extensions/pg_net\#httpdelete)

Creates an HTTP DELETE request, returning the request's ID. HTTP requests are not started until the transaction is committed.

### Signature [\#](https://supabase.com/docs/guides/database/extensions/pg_net\#post-signature)

This is a Postgres [SECURITY DEFINER](https://supabase.com/docs/guides/database/postgres/row-level-security#use-security-definer-functions) function

``
net.http_delete(
    -- url for the request
    url text,
    -- key/value pairs to be url encoded and appended to the `url`
    params jsonb default '{}'::jsonb,
    -- key/values to be included in request headers
    headers jsonb default '{}'::jsonb,
    -- the maximum number of milliseconds the request may take before being canceled
    timeout_milliseconds int default 2000
)
    -- request_id reference
    returns bigint
    strict
    volatile
    parallel safe
    language plpgsql
    security definer
``

### Usage [\#](https://supabase.com/docs/guides/database/extensions/pg_net\#delete-usage)

`
select
    net.http_delete(
        'https://dummy.restapiexample.com/api/v1/delete/2'
    ) as request_id;
----------
         1
(1 row)
`

## Analyzing responses [\#](https://supabase.com/docs/guides/database/extensions/pg_net\#analyzing-responses)

Waiting requests are stored in the `net.http_request_queue` table. Upon execution, they are deleted.

`
CREATE UNLOGGED TABLE
    net.http_request_queue (
        id bigint NOT NULL DEFAULT nextval('net.http_request_queue_id_seq'::regclass),
        method text NOT NULL,
        url text NOT NULL,
        headers jsonb NOT NULL,
        body bytea NULL,
        timeout_milliseconds integer NOT NULL
    )
`

Once a response is returned, by default, it is stored for 6 hours in the `net._http_response` table.

`
CREATE UNLOGGED TABLE
    net._http_response (
        id bigint NULL,
        status_code integer NULL,
        content_type text NULL,
        headers jsonb NULL,
        content text NULL,
        timed_out boolean NULL,
        error_msg text NULL,
        created timestamp with time zone NOT NULL DEFAULT now()
    )
`

The responses can be observed with the following query:

`
select * from net._http_response;
`

The data can also be observed in the `net` schema with the [Supabase Dashboard's SQL Editor](https://supabase.com/dashboard/project/_/editor)

## Debugging requests [\#](https://supabase.com/docs/guides/database/extensions/pg_net\#debugging-requests)

### Inspecting request data [\#](https://supabase.com/docs/guides/database/extensions/pg_net\#inspecting-request-data)

The [Postman Echo API](https://documenter.getpostman.com/view/5025623/SWTG5aqV) returns a response with the same body and content
as the request. It can be used to inspect the data being sent.

Sending a post request to the echo API

`
select
    net.http_post(
        url := 'https://postman-echo.com/post',
        body := '{"key1": "value", "key2": 5}'::jsonb
    ) as request_id;
`

Inspecting the echo API response content to ensure it contains the right body

`
select
    "content"
from net._http_response
where id = <request_id>
-- returns information about the request
-- including the body sent: {"key": "value", "key": 5}
`

Alternatively, by wrapping a request in a [database function](https://supabase.com/docs/guides/database/functions), sent row data can be logged or returned for inspection and debugging.

`
create or replace function debugging_example (row_id int)
returns jsonb as $$
declare
    -- Store payload data
    row_data_var jsonb;
begin
    -- Retrieve row data and convert to JSON
    select to_jsonb("<example_table>".*) into row_data_var
    from "<example_table>"
    where "<example_table>".id = row_id;
    -- Initiate HTTP POST request to URL
    perform
        net.http_post(
            url := 'https://postman-echo.com/post',
            -- Use row data as payload
            body := row_data_var
        ) as request_id;
    -- Optionally Log row data or other data for inspection in Supabase Dashboard's Postgres Logs
    raise log 'Logging an entire row as JSON (%)', row_data_var;
    -- return row data to inspect
    return row_data_var;
-- Handle exceptions here if needed
exception
    when others then
        raise exception 'An error occurred: %', SQLERRM;
end;
$$ language plpgsql;
-- calling function
select debugging_example(<row_id>);
`

### Inspecting failed requests [\#](https://supabase.com/docs/guides/database/extensions/pg_net\#inspecting-failed-requests)

Finds all failed requests

`
select
*
from net._http_response
where "status_code" >= 400 or "error_msg" is not null
order by "created" desc;
`

## Configuration [\#](https://supabase.com/docs/guides/database/extensions/pg_net\#configuration)

##### Must be on pg\_net v0.12.0 or above to reconfigure

Supabase supports reconfiguring pg\*net starting from v0.12.0+. For the latest release, initiate a Postgres upgrade in the [Infrastructure Settings](https://supabase.com/dashboard/project/*/settings/infrastructure).

The extension is configured to reliably execute up to 200 requests per second. The response messages are stored for only 6 hours to prevent needless buildup. The default behavior can be modified by rewriting config variables.

### Get current settings [\#](https://supabase.com/docs/guides/database/extensions/pg_net\#get-current-settings)

`
select
"name",
"setting"
from pg_settings
where "name" like 'pg_net%';
`

### Alter settings [\#](https://supabase.com/docs/guides/database/extensions/pg_net\#alter-settings)

Change variables:

`
alter role "postgres" set pg_net.ttl to '24 hours';
alter role "postgres" set pg_net.batch_size to 500;
`

Then reload the settings and restart the `pg_net` background worker with:

`
select net.worker_restart();
`

## Examples [\#](https://supabase.com/docs/guides/database/extensions/pg_net\#examples)

### Invoke a Supabase Edge Function [\#](https://supabase.com/docs/guides/database/extensions/pg_net\#invoke-a-supabase-edge-function)

Make a POST request to a Supabase Edge Function with auth header and JSON body payload:

`
select
    net.http_post(
        url:='https://project-ref.supabase.co/functions/v1/function-name',
        headers:='{"Content-Type": "application/json", "Authorization": "Bearer <YOUR_ANON_KEY>"}'::jsonb,
        body:='{"name": "pg_net"}'::jsonb
    ) as request_id;
`

### Call an endpoint every minute with [pg\_cron](https://supabase.com/docs/guides/database/extensions/pgcron) [\#](https://supabase.com/docs/guides/database/extensions/pg_net\#call-an-endpoint-every-minute-with-pgcron)

The pg\_cron extension enables Postgres to become its own cron server. With it you can schedule regular calls with up to a minute precision to endpoints.

`
select cron.schedule(
	'cron-job-name',
	'* * * * *', -- Executes every minute (cron syntax)
	$$
	    -- SQL query
	    select "net"."http_post"(
            -- URL of Edge function
            url:='https://project-ref.supabase.co/functions/v1/function-name',
            headers:='{"Authorization": "Bearer <YOUR_ANON_KEY>"}'::jsonb,
            body:='{"name": "pg_net"}'::jsonb
	    ) as "request_id";
	$$
);
`

### Execute pg\_net in a trigger [\#](https://supabase.com/docs/guides/database/extensions/pg_net\#execute-pgnet-in-a-trigger)

Make a call to an external endpoint when a trigger event occurs.

`
-- function called by trigger
create or replace function <function_name>()
    returns trigger
    language plpgSQL
as $$
begin
    -- calls pg_net function net.http_post
    -- sends request to postman API
    perform "net"."http_post"(
      'https://postman-echo.com/post'::text,
      jsonb_build_object(
        'old_row', to_jsonb(old.*),
        'new_row', to_jsonb(new.*)
      ),
      headers:='{"Content-Type": "application/json"}'::jsonb
    ) as request_id;
    return new;
END $$;
-- trigger for table update
create trigger <trigger_name>
    after update on <table_name>
    for each row
    execute function <function_name>();
`

### Send multiple table rows in one request [\#](https://supabase.com/docs/guides/database/extensions/pg_net\#send-multiple-table-rows-in-one-request)

`
with "selected_table_rows" as (
    select
        -- Converts all the rows into a JSONB array
        jsonb_agg(to_jsonb(<table_name>.*)) as JSON_payload
    from <table_name>
    -- good practice to LIMIT the max amount of rows
)
select
    net.http_post(
        url := 'https://postman-echo.com/post'::text,
        body := JSON_payload
    ) AS request_id
FROM "selected_table_rows";
`

More examples can be seen on the [Extension's GitHub page](https://github.com/supabase/pg_net/)

## Limitations [\#](https://supabase.com/docs/guides/database/extensions/pg_net\#limitations)

- To improve speed and performance, the requests and responses are stored in [unlogged tables](https://pgpedia.info/u/unlogged-table.html), which are not preserved during a crash or unclean shutdown.
- By default, response data is saved for only 6 hours
- Can only make POST requests with JSON data. No other data formats are supported
- Intended to handle at most 200 requests per second. Increasing the rate can introduce instability
- Does not have support for PATCH/PUT requests
- Can only work with one database at a time. It defaults to the `postgres` database.

## Resources [\#](https://supabase.com/docs/guides/database/extensions/pg_net\#resources)

- Source code: [github.com/supabase/pg\_net](https://github.com/supabase/pg_net/)
- Official Docs: [github.com/supabase/pg\_net](https://github.com/supabase/pg_net/)

### Is this helpful?

NoYes

### On this page

[Enable the extension](https://supabase.com/docs/guides/database/extensions/pg_net#enable-the-extension) [http\_get](https://supabase.com/docs/guides/database/extensions/pg_net#httpget) [Signature](https://supabase.com/docs/guides/database/extensions/pg_net#get-signature) [Usage](https://supabase.com/docs/guides/database/extensions/pg_net#get-usage) [http\_post](https://supabase.com/docs/guides/database/extensions/pg_net#httppost) [Signature](https://supabase.com/docs/guides/database/extensions/pg_net#post-signature) [Usage](https://supabase.com/docs/guides/database/extensions/pg_net#post-usage) [http\_delete](https://supabase.com/docs/guides/database/extensions/pg_net#httpdelete) [Signature](https://supabase.com/docs/guides/database/extensions/pg_net#post-signature) [Usage](https://supabase.com/docs/guides/database/extensions/pg_net#delete-usage) [Analyzing responses](https://supabase.com/docs/guides/database/extensions/pg_net#analyzing-responses) [Debugging requests](https://supabase.com/docs/guides/database/extensions/pg_net#debugging-requests) [Inspecting request data](https://supabase.com/docs/guides/database/extensions/pg_net#inspecting-request-data) [Inspecting failed requests](https://supabase.com/docs/guides/database/extensions/pg_net#inspecting-failed-requests) [Configuration](https://supabase.com/docs/guides/database/extensions/pg_net#configuration) [Get current settings](https://supabase.com/docs/guides/database/extensions/pg_net#get-current-settings) [Alter settings](https://supabase.com/docs/guides/database/extensions/pg_net#alter-settings) [Examples](https://supabase.com/docs/guides/database/extensions/pg_net#examples) [Invoke a Supabase Edge Function](https://supabase.com/docs/guides/database/extensions/pg_net#invoke-a-supabase-edge-function) [Call an endpoint every minute with pg\_cron](https://supabase.com/docs/guides/database/extensions/pg_net#https://supabase.com/docs/guides/database/extensions/pgcron) [Execute pg\_net in a trigger](https://supabase.com/docs/guides/database/extensions/pg_net#execute-pgnet-in-a-trigger) [Send multiple table rows in one request](https://supabase.com/docs/guides/database/extensions/pg_net#send-multiple-table-rows-in-one-request) [Limitations](https://supabase.com/docs/guides/database/extensions/pg_net#limitations) [Resources](https://supabase.com/docs/guides/database/extensions/pg_net#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_extensions_pg_plan_filter.md">
Database

# pg\_plan\_filter: Restrict Total Cost

* * *

[`pg_plan_filter`](https://github.com/pgexperts/pg_plan_filter) is Postgres extension to block execution of statements where query planner's estimate of the total cost exceeds a threshold. This is intended to give database administrators a way to restrict the contribution an individual query has on database load.

## Enable the extension [\#](https://supabase.com/docs/guides/database/extensions/pg_plan_filter\#enable-the-extension)

`pg_plan_filter` can be enabled on a per connection basis:

`
load 'plan_filter';
`

or for all connections:

`
alter database some_db set session_preload_libraries = 'plan_filter';
`

## API [\#](https://supabase.com/docs/guides/database/extensions/pg_plan_filter\#api)

`plan_filter.statement_cost_limit`: restricts the maximum total cost for executed statements
`plan_filter.limit_select_only`: restricts to `select` statements

Note that `limit_select_only = true` is not the same as read-only because `select` statements may modify data, for example, through a function call.

## Example [\#](https://supabase.com/docs/guides/database/extensions/pg_plan_filter\#example)

To demonstrate total cost filtering, we'll compare how `plan_filter.statement_cost_limit` treats queries that are under and over its cost limit. First, we set up a table with some data:

`
create table book(
id int primary key
);
-- CREATE TABLE
insert into book(id) select * from generate_series(1, 10000);
-- INSERT 0 10000
`

Next, we can review the explain plans for a single record select, and a whole table select.

`
explain select * from book where id =1;
                                QUERY PLAN
---------------------------------------------------------------------------
Index Only Scan using book_pkey on book  (cost=0.28..2.49 rows=1 width=4)
Index Cond: (id = 1)
(2 rows)
explain select * from book;
                       QUERY PLAN
---------------------------------------------------------
Seq Scan on book  (cost=0.00..135.00 rows=10000 width=4)
(1 row)
`

Now we can choose a `statement_cost_filter` value between the total cost for the single select (2.49) and the whole table select (135.0) so one statement will succeed and one will fail.

`
load 'plan_filter';
set plan_filter.statement_cost_limit = 50; -- between 2.49 and 135.0
select * from book where id = 1;
id
----
1
(1 row)
-- SUCCESS
`

`
select * from book;
ERROR:  plan cost limit exceeded
HINT:  The plan for your query shows that it would probably have an excessive run time. This may be due to a logic error in the SQL, or it maybe just a very costly query. Rewrite your query or increase the configuration parameter "plan_filter.statement_cost_limit".
-- FAILURE
`

## Resources [\#](https://supabase.com/docs/guides/database/extensions/pg_plan_filter\#resources)

- Official [`pg_plan_filter` documentation](https://github.com/pgexperts/pg_plan_filter)

### Is this helpful?

NoYes

### On this page

[Enable the extension](https://supabase.com/docs/guides/database/extensions/pg_plan_filter#enable-the-extension) [API](https://supabase.com/docs/guides/database/extensions/pg_plan_filter#api) [Example](https://supabase.com/docs/guides/database/extensions/pg_plan_filter#example) [Resources](https://supabase.com/docs/guides/database/extensions/pg_plan_filter#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_extensions_pg_repack.md">
Database

# pg\_repack: Physical storage optimization and maintenance

* * *

[pg\_repack](https://github.com/reorg/pg_repack) is a Postgres extension to remove bloat from tables and indexes, and optionally restore the physical order of clustered indexes. Unlike CLUSTER and VACUUM FULL, pg\_repack runs "online" and does not hold a exclusive locks on the processed tables that could prevent ongoing database operations. pg\_repack's efficiency is comparable to using CLUSTER directly.

pg\_repack provides the following methods to optimize physical storage:

- Online CLUSTER: ordering table data by cluster index in a non-blocking way
- Ordering table data by specified columns
- Online VACUUM FULL: packing rows only in a non-blocking way
- Rebuild or relocate only the indexes of a table

pg\_repack has 2 components, the database extension and a client-side CLI to control it.

## Requirements [\#](https://supabase.com/docs/guides/database/extensions/pg_repack\#requirements)

- A target table must have a PRIMARY KEY, or a UNIQUE total index on a NOT NULL column.
- Performing a full-table repack requires free disk space about twice as large as the target table and its indexes.

pg\_repack requires the Postgres superuser role by default. That role is not available to users on the Supabase platform. To avoid that requirement, use the `-k` or `--no-superuser-check` flags on every `pg_repack` CLI command.

The first version of pg\_repack with full support for non-superuser repacking is 1.5.2. You can check the version installed on your Supabase instance using

`
select default_version
from pg_available_extensions
where name = 'pg_repack';
`

If pg\_repack is not present, or the version is < 1.5.2, [upgrade to the latest version](https://supabase.com/docs/guides/platform/upgrading) of Supabase to gain access.

## Usage [\#](https://supabase.com/docs/guides/database/extensions/pg_repack\#usage)

### Enable the extension [\#](https://supabase.com/docs/guides/database/extensions/pg_repack\#enable-the-extension)

Get started with pg\_repack by enabling the extension in the Supabase Dashboard.

DashboardSQL

1. Go to the [Database](https://supabase.com/dashboard/project/_/database/tables) page in the Dashboard.
2. Click on **Extensions** in the sidebar.
3. Search for "pg\_repack" and enable the extension.

### Install the CLI [\#](https://supabase.com/docs/guides/database/extensions/pg_repack\#install-the-cli)

Select an option from the pg\_repack docs to [install the client CLI](https://reorg.github.io/pg_repack/#download).

### Syntax [\#](https://supabase.com/docs/guides/database/extensions/pg_repack\#syntax)

All pg\_repack commands should include the `-k` flag to skip the client-side superuser check.

`
pg_repack -k [OPTION]... [DBNAME]
`

## Example [\#](https://supabase.com/docs/guides/database/extensions/pg_repack\#example)

Perform an online `VACUUM FULL` on the tables `public.foo` and `public.bar` in the database `postgres`:

`
pg_repack -k -h db.<PROJECT_REF>.supabase.co -p 5432 -U postgres -d postgres --no-order --table public.foo --table public.bar
`

See the [official pg\_repack documentation](https://reorg.github.io/pg_repack/) for the full list of options.

## Limitations [\#](https://supabase.com/docs/guides/database/extensions/pg_repack\#limitations)

- pg\_repack cannot reorganize temporary tables.
- pg\_repack cannot cluster tables by GiST indexes.
- You cannot perform DDL commands of the target tables except VACUUM or ANALYZE while pg\_repack is working.
pg\_repack holds an ACCESS SHARE lock on the target table to enforce this restriction.

## Resources [\#](https://supabase.com/docs/guides/database/extensions/pg_repack\#resources)

- [Official pg\_repack documentation](https://reorg.github.io/pg_repack/)

### Is this helpful?

NoYes

### On this page

[Requirements](https://supabase.com/docs/guides/database/extensions/pg_repack#requirements) [Usage](https://supabase.com/docs/guides/database/extensions/pg_repack#usage) [Enable the extension](https://supabase.com/docs/guides/database/extensions/pg_repack#enable-the-extension) [Install the CLI](https://supabase.com/docs/guides/database/extensions/pg_repack#install-the-cli) [Syntax](https://supabase.com/docs/guides/database/extensions/pg_repack#syntax) [Example](https://supabase.com/docs/guides/database/extensions/pg_repack#example) [Limitations](https://supabase.com/docs/guides/database/extensions/pg_repack#limitations) [Resources](https://supabase.com/docs/guides/database/extensions/pg_repack#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_extensions_pg_stat_statements.md">
Database

# pg\_stat\_statements: Query Performance Monitoring

* * *

`pg_stat_statements` is a database extension that exposes a view, of the same name, to track statistics about SQL statements executed on the database. The following table shows some of the available statistics and metadata:

| Column Name | Column Type | Description |
| --- | --- | --- |
| `userid` | `oid` (references `pg_authid.oid`) | OID of user who executed the statement |
| `dbid` | `oid` (references `pg_database.oid`) | OID of database in which the statement was executed |
| `toplevel` | `bool` | True if the query was executed as a top-level statement (always true if pg\_stat\_statements.track is set to top) |
| `queryid` | `bigint` | Hash code to identify identical normalized queries. |
| `query` | `text` | Text of a representative statement |
| `plans` | `bigint` | Number of times the statement was planned (if pg\_stat\_statements.track\_planning is enabled, otherwise zero) |
| `total_plan_time` | `double precision` | Total time spent planning the statement, in milliseconds (if pg\_stat\_statements.track\_planning is enabled, otherwise zero) |
| `min_plan_time` | `double precision` | Minimum time spent planning the statement, in milliseconds (if pg\_stat\_statements.track\_planning is enabled, otherwise zero) |

A full list of statistics is available in the [pg\_stat\_statements docs](https://www.postgresql.org/docs/current/pgstatstatements.html).

For more information on query optimization, check out the [query performance guide](https://supabase.com/docs/guides/platform/performance#examining-query-performance).

## Enable the extension [\#](https://supabase.com/docs/guides/database/extensions/pg_stat_statements\#enable-the-extension)

DashboardSQL

1. Go to the [Database](https://supabase.com/dashboard/project/_/database/tables) page in the Dashboard.
2. Click on **Extensions** in the sidebar.
3. Search for "pg\_stat\_statements" and enable the extension.

## Inspecting activity [\#](https://supabase.com/docs/guides/database/extensions/pg_stat_statements\#inspecting-activity)

A common use for `pg_stat_statements` is to track down expensive or slow queries. The `pg_stat_statements` view contains a row for each executed query with statistics inlined. For example, you can leverage the statistics to identify frequently executed and slow queries against a given table.

`
select
	calls,
	mean_exec_time,
	max_exec_time,
	total_exec_time,
	stddev_exec_time,
	query
from
	pg_stat_statements
where
    calls > 50                   -- at least 50 calls
    and mean_exec_time > 2.0     -- averaging at least 2ms/call
    and total_exec_time > 60000  -- at least one minute total server time spent
    and query ilike '%user_in_organization%' -- filter to queries that touch the user_in_organization table
order by
	calls desc
`

From the results, we can make an informed decision about which queries to optimize or index.

## Resources [\#](https://supabase.com/docs/guides/database/extensions/pg_stat_statements\#resources)

- Official [pg\_stat\_statements documentation](https://www.postgresql.org/docs/current/pgstatstatements.html)

### Is this helpful?

NoYes

### On this page

[Enable the extension](https://supabase.com/docs/guides/database/extensions/pg_stat_statements#enable-the-extension) [Inspecting activity](https://supabase.com/docs/guides/database/extensions/pg_stat_statements#inspecting-activity) [Resources](https://supabase.com/docs/guides/database/extensions/pg_stat_statements#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_extensions_pgaudit.md">
Database

# PGAudit: Postgres Auditing

* * *

[PGAudit](https://www.pgaudit.org/) extends Postgres's built-in logging abilities. It can be used to selectively track activities within your database.

This helps you with:

- **Compliance**: Meeting audit requirements for regulations
- **Security**: Detecting suspicious database activity
- **Troubleshooting**: Identifying and fixing database issues

## Enable the extension [\#](https://supabase.com/docs/guides/database/extensions/pgaudit\#enable-the-extension)

DashboardSQL

1. Go to the [Database](https://supabase.com/dashboard/project/_/database/tables) page in the Dashboard.
2. Click on **Extensions** in the sidebar.
3. Search for `pgaudit` and enable the extension.

## Configure the extension [\#](https://supabase.com/docs/guides/database/extensions/pgaudit\#configure-the-extension)

PGAudit can be configured with different levels of precision.

**PGAudit logging precision:**

- **[Session](https://supabase.com/docs/guides/database/extensions/pgaudit#session-logging):** Logs activity within a connection, such as a [psql](https://supabase.com/docs/guides/database/connecting-to-postgres#connecting-with-psql) connection.
- **[User](https://supabase.com/docs/guides/database/extensions/pgaudit#user-logging):** Logs activity by a particular database user (for example, `anon` or `postgres`).
- **[Global](https://supabase.com/docs/guides/database/extensions/pgaudit#global-logging):** Logs activity across the entire database.
- **[Object](https://supabase.com/docs/guides/database/extensions/pgaudit#object-logging):** Logs events related to specific database objects (for example, the auth.users table).

Although Session, User, and Global modes differ in their precision, they're all considered variants of **Session Mode** and are configured with the same input categories.

### Session mode categories [\#](https://supabase.com/docs/guides/database/extensions/pgaudit\#session-mode-categories)

These modes can monitor predefined categories of database operations:

| Category | What it Logs | Description |
| --- | --- | --- |
| `read` | Data retrieval (SELECT, COPY) | Tracks what data is being accessed. |
| `write` | Data modification (INSERT, DELETE, UPDATE, TRUNCATE, COPY) | Tracks changes made to your database. |
| `function` | FUNCTION, PROCEDURE, and DO/END block executions | Tracks routine/function executions |
| `role` | User management actions (CREATE, DROP, ALTER on users and privileges) | Tracks changes to user permissions and access. |
| `ddl` | Schema changes (CREATE, DROP, ALTER statements) | Monitors modifications to your database structure (tables, indexes, etc.). |
| `misc` | Less common commands (FETCH, CHECKPOINT) | Captures obscure actions for deeper analysis if needed. |
| `all` | Everything above | Comprehensive logging for complete audit trails. |

Below is a limited example of how to assign PGAudit to monitor specific categories.

`
-- log all CREATE, ALTER, and DROP events
... pgaudit.log = 'ddl';
-- log all CREATE, ALTER, DROP, and SELECT events
... pgaudit.log = 'read, ddl';
-- log nothing
... pgaudit.log = 'none';
`

### Session logging [\#](https://supabase.com/docs/guides/database/extensions/pgaudit\#session-logging)

When you are connecting in a session environment, such as a [psql](https://supabase.com/docs/guides/database/connecting-to-postgres#connecting-with-psql) connection, you can configure PGAudit to record events initiated within the session.

The [Dashboard](https://supabase.com/dashboard/project/_) is a transactional environment and won't sustain a session.

Inside a session, by default, PGAudit will log nothing:

`
-- returns 'none'
show pgaudit.log;
`

In the session, you can `set` the `pgaudit.log` variable to record events:

`
-- log CREATE, ALTER, and DROP events
set pgaudit.log = 'ddl';
-- log all CREATE, ALTER, DROP, and SELECT events
set pgaudit.log = 'read, ddl';
-- log nothing
set pgaudit.log = 'none';
`

### User logging [\#](https://supabase.com/docs/guides/database/extensions/pgaudit\#user-logging)

There are some cases where you may want to monitor a database user's actions. For instance, let's say you connected your database to [Zapier](https://supabase.com/partners/integrations/zapier) and created a custom role for it to use:

`
create user "zapier" with password '<new password>';
`

You may want to log all actions initiated by `zapier`, which can be done with the following command:

`
alter role "zapier" set pgaudit.log to 'all';
`

To remove the settings, execute the following code:

`
-- disables role's log
alter role "zapier" set pgaudit.log to 'none';
-- check to make sure the changes are finalized:
select
rolname,
rolconfig
from pg_roles
where rolname = 'zapier';
-- should return a rolconfig path with "pgaudit.log=none" present
`

### Global logging [\#](https://supabase.com/docs/guides/database/extensions/pgaudit\#global-logging)

Use global logging cautiously. It can generate many logs and make it difficult to find important events. Consider limiting the scope of what is logged by using session, user, or object logging where possible.

The below SQL configures PGAudit to record all events associated with the `postgres` role. Since it has extensive privileges, this effectively monitors all database activity.

`
alter role "postgres" set pgaudit.log to 'all';
`

To check if the `postgres` role is auditing, execute the following command:

`
select
rolname,
rolconfig
from pg_roles
where rolname = 'postgres';
-- should return a rolconfig path with "pgaudit.log=all" present
`

To remove the settings, execute the following code:

`
alter role "postgres" set pgaudit.log to 'none';
`

### Object logging [\#](https://supabase.com/docs/guides/database/extensions/pgaudit\#object-logging)

To fine-tune what object events PGAudit will record, you must create a custom database role with limited permissions:

`
create role "some_audit_role" noinherit;
`

No other Postgres user can assume or login via this role. It solely exists to securely define what PGAudit will record.

Once the role is created, you can direct PGAudit to log by assigning it to the `pgaudit.role` variable:

`
alter role "postgres" set pgaudit.role to 'some_audit_role';
`

You can then assign the role to monitor only approved object events, such as `select` statements that include a specific table:

`
grant select on random_table to "some_audit_role";
`

With this privilege granted, PGAudit will record all select statements that reference the `random_table`, regardless of _who_ or _what_ actually initiated the event. All assignable privileges can be viewed in the [Postgres documentation](https://www.postgresql.org/docs/current/ddl-priv.html).

If you would no longer like to use object logging, you will need to unassign the `pgaudit.role` variable:

`
-- change pgaudit.role to no longer reference some_audit_role
alter role "postgres" set pgaudit.role to '';
-- view if pgaudit.role changed with the following command:
select
rolname,
rolconfig
from pg_roles
where rolname = 'postgres';
-- should return a rolconfig path with "pgaudit.role="
`

## Interpreting Audit Logs [\#](https://supabase.com/docs/guides/database/extensions/pgaudit\#interpreting-audit-logs)

PGAudit was designed for storing logs as CSV files with the following headers:

Referenced from the [PGAudit official docs](https://github.com/pgaudit/pgaudit/blob/master/README.md#format)

| header | Description |
| --- | --- |
| AUDIT\_TYPE | SESSION or OBJECT |
| STATEMENT\_ID | Unique statement ID for this session. Sequential even if some statements are not logged. |
| SUBSTATEMENT\_ID | Sequential ID for each sub-statement within the main statement. Continuous even if some are not logged. |
| CLASS | ..., READ, ROLE (see pgaudit.log). |
| COMMAND | ..., ALTER TABLE, SELECT. |
| OBJECT\_TYPE | TABLE, INDEX, VIEW, etc. Available for SELECT, DML, and most DDL statements. |
| OBJECT\_NAME | The fully qualified object name (for example, public.account). Available for SELECT, DML, and most DDL. |
| STATEMENT | Statement executed on the backend. |
| PARAMETER | If pgaudit.log\_parameter is set, this field contains the statement parameters as quoted CSV, or <none>. Otherwise, it's <not logged>. |

A log made from the following create statement:

`
create table account (
id int primary key,
name text,
description text
);
`

Generates the following log in the [Dashboard's Postgres Logs](https://supabase.com/dashboard/project/_/logs/postgres-logs):

`
AUDIT: SESSION,1,1,DDL,CREATE TABLE,TABLE,public.account,create table account(
id int,
name text,
description text
); <not logged>
`

## Finding and filtering audit logs [\#](https://supabase.com/docs/guides/database/extensions/pgaudit\#finding-and-filtering-audit-logs)

Logs generated by PGAudit can be found in [Postgres Logs](https://supabase.com/dashboard/project/_/logs/postgres-logs?s=AUDIT). To find a specific log, you can use the log explorer. Below is a basic example to extract logs referencing `CREATE TABLE` events

`
select
cast(t.timestamp as datetime) as timestamp,
event_message
from
postgres_logs as t
cross join unnest(metadata) as m
cross join unnest(m.parsed) as p
where event_message like 'AUDIT%CREATE TABLE%'
order by timestamp desc
limit 100;
`

## Practical examples [\#](https://supabase.com/docs/guides/database/extensions/pgaudit\#practical-examples)

### Monitoring API events [\#](https://supabase.com/docs/guides/database/extensions/pgaudit\#monitoring-api-events)

API requests are already recorded in the [API Edge Network](https://supabase.com/dashboard/project/_/logs/edge-logs) logs.

To monitor all writes initiated by the PostgREST API roles:

`
alter role "authenticator" set pgaudit.log to 'write';
-- the above is the practical equivalent to:
-- alter role "anon" set pgaudit.log TO 'write';
-- alter role "authenticated" set pgaudit.log TO 'write';
-- alter role "service_role" set pgaudit.log TO 'write';
`

### Monitoring the `auth.users` table [\#](https://supabase.com/docs/guides/database/extensions/pgaudit\#monitoring-the-authusers-table)

In the worst case scenario, where a privileged roles' password is exposed, you can use PGAudit to monitor if the `auth.users` table was targeted. It should be stated that API requests are already monitored in the [API Edge Network](https://supabase.com/dashboard/project/_/logs/edge-logs) and this is more about providing greater clarity about what is happening at the database level.

Logging `auth.user` should be done in Object Mode and requires a custom role:

`
-- create logging role
create role "auth_auditor" noinherit;
-- give role permission to observe relevant table events
grant select on auth.users to "auth_auditor";
grant delete on auth.users to "auth_auditor";
-- assign auth_auditor to pgaudit.role
alter role "postgres" set pgaudit.role to 'auth_auditor';
`

With the above code, any query involving reading or deleting from the auth.users table will be logged.

## Best practices [\#](https://supabase.com/docs/guides/database/extensions/pgaudit\#best-practices)

### Disabling excess logging [\#](https://supabase.com/docs/guides/database/extensions/pgaudit\#disabling-excess-logging)

PGAudit, if not configured mindfully, can log all database events, including background tasks. This can generate an undesirably large amount of logs in a few hours.

The first step to solve this problem is to identify which database users PGAudit is observing:

`
-- find all users monitored by pgaudit
select
rolname,
rolconfig
from pg_roles
where
exists (
    select
      1
    from UNNEST(rolconfig) as c
    where c like '%pgaudit.role%' or c like '%pgaudit.log%'
);
`

To prevent PGAudit from monitoring the problematic roles, you'll want to change their `pgaudit.log` values to `none` and `pgaudit.role` values to `empty quotes ''`

`
  -- Use to disable object level logging
alter role "<role name>" set pgaudit.role to '';
  -- Use to disable global and user level logging
alter role "<role name>" set pgaudit.log to 'none';
`

## FAQ [\#](https://supabase.com/docs/guides/database/extensions/pgaudit\#faq)

#### Using PGAudit to debug database functions [\#](https://supabase.com/docs/guides/database/extensions/pgaudit\#using-pgaudit-to-debug-database-functions)

Technically yes, but it is not the best approach. It is better to check out our [function debugging guide](https://supabase.com/docs/guides/database/functions#general-logging) instead.

#### Downloading database logs [\#](https://supabase.com/docs/guides/database/extensions/pgaudit\#downloading-database-logs)

In the [Logs Dashboard](https://supabase.com/dashboard/project/_/logs/postgres-logs) you can download logs as CSVs.

#### Logging observed table rows [\#](https://supabase.com/docs/guides/database/extensions/pgaudit\#logging-observed-table-rows)

By default, PGAudit records queries, but not the returned rows. You can modify this behavior with the `pgaudit.log_rows` variable:

`
--enable
alter role "postgres" set pgaudit.log_rows to 'on';
-- disable
alter role "postgres" set pgaudit.log_rows to 'off';
`

You should not do this unless you are _absolutely_ certain it is necessary for your use case. It can expose sensitive values to your logs that ideally should not be preserved. Furthermore, if done in excess, it can noticeably reduce database performance.

#### Logging function parameters [\#](https://supabase.com/docs/guides/database/extensions/pgaudit\#logging-function-parameters)

We don't currently support configuring `pgaudit.log_parameter` because it may log secrets in encrypted columns if you are using [pgsodium](https://supabase.com/docs/guides/database/extensions/pgsodium) or [Vault](https://supabase.com/docs/guides/database/vault).

You can upvote this [feature request](https://github.com/orgs/supabase/discussions/20183) with your use-case if you'd like this restriction lifted.

#### Does PGAudit support system wide configurations? [\#](https://supabase.com/docs/guides/database/extensions/pgaudit\#does-pgaudit-support-system-wide-configurations)

PGAudit allows settings to be applied to 3 different database scopes:

| Scope | Description | Configuration File/Command |
| --- | --- | --- |
| System | Entire server | ALTER SYSTEM commands |
| Database | Specific database | ALTER DATABASE commands |
| Role | Specific user/role | ALTER ROLE commands |

Supabase limits full privileges for file system and database variables, meaning PGAudit modifications can only occur at the role level. Assigning PGAudit to the `postgres` role grants it nearly complete visibility into the database, making role-level adjustments a practical alternative to configuring at the database or system level.

PGAudit's [official documentation](https://www.pgaudit.org/) focuses on system and database level configs, but its docs officially supports role level configs, too.

## Resources [\#](https://supabase.com/docs/guides/database/extensions/pgaudit\#resources)

- [Official `PGAudit` documentation](https://www.pgaudit.org/)
- [Database Function Logging](https://supabase.com/docs/guides/database/functions#general-logging)
- [Supabase Logging](https://supabase.com/docs/guides/platform/logs)
- [Self-Hosting Logs](https://supabase.com/docs/reference/self-hosting-analytics/introduction)

### Is this helpful?

NoYes

### On this page

[Enable the extension](https://supabase.com/docs/guides/database/extensions/pgaudit#enable-the-extension) [Configure the extension](https://supabase.com/docs/guides/database/extensions/pgaudit#configure-the-extension) [Session mode categories](https://supabase.com/docs/guides/database/extensions/pgaudit#session-mode-categories) [Session logging](https://supabase.com/docs/guides/database/extensions/pgaudit#session-logging) [User logging](https://supabase.com/docs/guides/database/extensions/pgaudit#user-logging) [Global logging](https://supabase.com/docs/guides/database/extensions/pgaudit#global-logging) [Object logging](https://supabase.com/docs/guides/database/extensions/pgaudit#object-logging) [Interpreting Audit Logs](https://supabase.com/docs/guides/database/extensions/pgaudit#interpreting-audit-logs) [Finding and filtering audit logs](https://supabase.com/docs/guides/database/extensions/pgaudit#finding-and-filtering-audit-logs) [Practical examples](https://supabase.com/docs/guides/database/extensions/pgaudit#practical-examples) [Monitoring API events](https://supabase.com/docs/guides/database/extensions/pgaudit#monitoring-api-events) [Monitoring the auth.users table](https://supabase.com/docs/guides/database/extensions/pgaudit#monitoring-the-authusers-table) [Best practices](https://supabase.com/docs/guides/database/extensions/pgaudit#best-practices) [Disabling excess logging](https://supabase.com/docs/guides/database/extensions/pgaudit#disabling-excess-logging) [FAQ](https://supabase.com/docs/guides/database/extensions/pgaudit#faq) [Resources](https://supabase.com/docs/guides/database/extensions/pgaudit#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_extensions_pgjwt.md">
Database

# pgjwt: JSON Web Tokens

* * *

The [`pgjwt`](https://github.com/michelp/pgjwt) (PostgreSQL JSON Web Token) extension allows you to create and parse [JSON Web Tokens (JWTs)](https://en.wikipedia.org/wiki/JSON_Web_Token) within a PostgreSQL database. JWTs are commonly used for authentication and authorization in web applications and services.

## Enable the extension [\#](https://supabase.com/docs/guides/database/extensions/pgjwt\#enable-the-extension)

DashboardSQL

1. Go to the [Database](https://supabase.com/dashboard/project/_/database/tables) page in the Dashboard.
2. Click on **Extensions** in the sidebar.
3. Search for `pgjwt` and enable the extension.

## API [\#](https://supabase.com/docs/guides/database/extensions/pgjwt\#api)

- [`sign(payload json, secret text, algorithm text default 'HSA256')`](https://github.com/michelp/pgjwt#usage): Signs a JWT containing _payload_ with _secret_ using _algorithm_.
- [`verify(token text, secret text, algorithm text default 'HSA256')`](https://github.com/michelp/pgjwt#usage): Decodes a JWT _token_ that was signed with _secret_ using _algorithm_.

Where:

- `payload` is an encrypted JWT represented as a string.
- `secret` is the private/secret passcode which is used to sign the JWT and verify its integrity.
- `algorithm` is the method used to sign the JWT using the secret.
- `token` is an encrypted JWT represented as a string.

## Usage [\#](https://supabase.com/docs/guides/database/extensions/pgjwt\#usage)

Once the extension is installed, you can use its functions to create and parse JWTs. Here's an example of how you can use the `sign` function to create a JWT:

`
select
extensions.sign(
    payload   := '{"sub":"1234567890","name":"John Doe","iat":1516239022}',
    secret    := 'secret',
    algorithm := 'HS256'
);
`

The `pgjwt_encode` function returns a string that represents the JWT, which can then be safely transmitted between parties.

`
              sign
---------------------------------
eyJhbGciOiJIUzI1NiIsInR5cCI6IkpX
VCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiw
ibmFtZSI6IkpvaG4gRG9lIiwiaWF0Ijo
xNTE2MjM5MDIyfQ.XbPfbIHMI6arZ3Y9
22BhjWgQzWXcXNrz0ogtVhfEd2o
(1 row)
`

To parse a JWT and extract its claims, you can use the `verify` function. Here's an example:

`
select
extensions.verify(
    token := 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJuYW1lIjoiRm9vIn0.Q8hKjuadCEhnCPuqIj9bfLhTh_9QSxshTRsA5Aq4IuM',
    secret    := 'secret',
    algorithm := 'HS256'
);
`

Which returns the decoded contents and some associated metadata.

`
           header            |    payload     | valid
-----------------------------+----------------+-------
{"alg":"HS256","typ":"JWT"} | {"name":"Foo"} | t
(1 row)
`

## Resources [\#](https://supabase.com/docs/guides/database/extensions/pgjwt\#resources)

- Official [`pgjwt` documentation](https://github.com/michelp/pgjwt)

### Is this helpful?

NoYes

### On this page

[Enable the extension](https://supabase.com/docs/guides/database/extensions/pgjwt#enable-the-extension) [API](https://supabase.com/docs/guides/database/extensions/pgjwt#api) [Usage](https://supabase.com/docs/guides/database/extensions/pgjwt#usage) [Resources](https://supabase.com/docs/guides/database/extensions/pgjwt#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_extensions_pgmq.md">
Database

# pgmq: Queues

* * *

See the [Supabase Queues docs](https://supabase.com/docs/guides/queues).

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_extensions_pgroonga.md">
Database

# PGroonga: Multilingual Full Text Search

* * *

`PGroonga` is a Postgres extension adding a full text search indexing method based on [Groonga](https://groonga.org/). While native Postgres supports full text indexing, it is limited to alphabet and digit based languages. `PGroonga` offers a wider range of character support making it viable for a superset of languages supported by Postgres including Japanese, Chinese, etc.

## Enable the extension [\#](https://supabase.com/docs/guides/database/extensions/pgroonga\#enable-the-extension)

DashboardSQL

1. Go to the [Database](https://supabase.com/dashboard/project/_/database/tables) page in the Dashboard.
2. Click on **Extensions** in the sidebar.
3. Search for `pgroonga` and enable the extension.

## Creating a full text search index [\#](https://supabase.com/docs/guides/database/extensions/pgroonga\#creating-a-full-text-search-index)

Given a table with a `text` column:

`
create table memos (
id serial primary key,
content text
);
`

We can index the column for full text search with a `pgroonga` index:

`
create index ix_memos_content ON memos USING pgroonga(content);
`

To test the full text index, we'll add some data.

`
insert into memos(content)
values
('PostgreSQL is a relational database management system.'),
('Groonga is a fast full text search engine that supports all languages.'),
('PGroonga is a PostgreSQL extension that uses Groonga as index.'),
('There is groonga command.');
`

The Postgres query planner is smart enough to know that, for extremely small tables, it's faster to scan the whole table rather than loading an index. To force the index to be used, we can disable sequential scans:

`
-- For testing only. Don't do this in production
set enable_seqscan = off;
`

Now if we run an explain plan on a query filtering on `memos.content`:

`
explain select * from memos where content like '%engine%';
                               QUERY PLAN
-----------------------------------------------------------------------------
Index Scan using ix_memos_content on memos  (cost=0.00..1.11 rows=1 width=36)
Index Cond: (content ~~ '%engine%'::text)
(2 rows)
`

The `pgroonga` index is used to retrieve the result set:

`
| id  | content                                                                  |
| --- | ------------------------------------------------------------------------ |
| 2   | 'Groonga is a fast full text search engine that supports all languages.' |
`

## Full text search [\#](https://supabase.com/docs/guides/database/extensions/pgroonga\#full-text-search)

The `&@~` operator performs full text search. It returns any matching results. Unlike `LIKE` operator, `pgroonga` can search any text that contains the keyword case insensitive.

Take the following example:

`
select * from memos where content &@~ 'groonga';
`

And the result:

`
id | content
----+------------------------------------------------------------------------
2 | Groonga is a fast full text search engine that supports all languages.
3 | PGroonga is a PostgreSQL extension that uses Groonga as index.
4 | There is groonga command.
(3 rows)
`

### Match all search words [\#](https://supabase.com/docs/guides/database/extensions/pgroonga\#match-all-search-words)

To find all memos where content contains BOTH of the words `postgres` and `pgroonga`, we can just use space to separate each words:

`
select * from memos where content &@~ 'postgres pgroonga';
`

And the result:

`
id | content
----+----------------------------------------------------------------
3 | PGroonga is a PostgreSQL extension that uses Groonga as index.
(1 row)
`

### Match any search words [\#](https://supabase.com/docs/guides/database/extensions/pgroonga\#match-any-search-words)

To find all memos where content contain ANY of the words `postgres` or `pgroonga`, use the upper case `OR`:

`
select * from memos where content &@~ 'postgres OR pgroonga';
`

And the result:

`
id | content
----+----------------------------------------------------------------
1 | PostgreSQL is a relational database management system.
3 | PGroonga is a PostgreSQL extension that uses Groonga as index.
(2 rows)
`

### Search that matches words with negation [\#](https://supabase.com/docs/guides/database/extensions/pgroonga\#search-that-matches-words-with-negation)

To find all memos where content contain the word `postgres` but not `pgroonga`, use `-` symbol:

`
select * from memos where content &@~ 'postgres -pgroonga';
`

And the result:

`
id | content
----+--------------------------------------------------------
1 | PostgreSQL is a relational database management system.
(1 row)
`

## Resources [\#](https://supabase.com/docs/guides/database/extensions/pgroonga\#resources)

- Official [PGroonga documentation](https://pgroonga.github.io/tutorial/)

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2FMmmv9g_MiBA%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Enable the extension](https://supabase.com/docs/guides/database/extensions/pgroonga#enable-the-extension) [Creating a full text search index](https://supabase.com/docs/guides/database/extensions/pgroonga#creating-a-full-text-search-index) [Full text search](https://supabase.com/docs/guides/database/extensions/pgroonga#full-text-search) [Match all search words](https://supabase.com/docs/guides/database/extensions/pgroonga#match-all-search-words) [Match any search words](https://supabase.com/docs/guides/database/extensions/pgroonga#match-any-search-words) [Search that matches words with negation](https://supabase.com/docs/guides/database/extensions/pgroonga#search-that-matches-words-with-negation) [Resources](https://supabase.com/docs/guides/database/extensions/pgroonga#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_extensions_pgrouting.md">
Database

# pgrouting: Geospatial Routing

* * *

[`pgRouting`](http://pgrouting.org/) is Postgres and [PostGIS](http://postgis.net/) extension adding geospatial routing functionality.

The core functionality of `pgRouting` is a set of path finding algorithms including:

- All Pairs Shortest Path, Johnsons Algorithm
- All Pairs Shortest Path, Floyd-Warshall Algorithm
- Shortest Path A\*
- Bi-directional Dijkstra Shortest Path
- Bi-directional A\* Shortest Path
- Shortest Path Dijkstra
- Driving Distance
- K-Shortest Path, Multiple Alternative Paths
- K-Dijkstra, One to Many Shortest Path
- Traveling Sales Person
- Turn Restriction Shortest Path (TRSP)

## Enable the extension [\#](https://supabase.com/docs/guides/database/extensions/pgrouting\#enable-the-extension)

DashboardSQL

1. Go to the [Database](https://supabase.com/dashboard/project/_/database/tables) page in the Dashboard.
2. Click on **Extensions** in the sidebar.
3. Search for `pgrouting` and enable the extension.

## Example [\#](https://supabase.com/docs/guides/database/extensions/pgrouting\#example)

As an example, we'll solve the [traveling salesperson problem](https://en.wikipedia.org/wiki/Travelling_salesman_problem) using the `pgRouting`'s `pgr_TSPeuclidean` function from some PostGIS coordinates.

A summary of the traveling salesperson problem is, given a set of city coordinates, solve for a path that goes through each city and minimizes the total distance traveled.

First we populate a table with some X, Y coordinates

`
create table wi29 (
id bigint,
x float,
y float,
geom geometry
);
insert into wi29 (id, x, y)
values
(1,20833.3333,17100.0000),
(2,20900.0000,17066.6667),
(3,21300.0000,13016.6667),
(4,21600.0000,14150.0000),
(5,21600.0000,14966.6667),
(6,21600.0000,16500.0000),
(7,22183.3333,13133.3333),
(8,22583.3333,14300.0000),
(9,22683.3333,12716.6667),
(10,23616.6667,15866.6667),
(11,23700.0000,15933.3333),
(12,23883.3333,14533.3333),
(13,24166.6667,13250.0000),
(14,25149.1667,12365.8333),
(15,26133.3333,14500.0000),
(16,26150.0000,10550.0000),
(17,26283.3333,12766.6667),
(18,26433.3333,13433.3333),
(19,26550.0000,13850.0000),
(20,26733.3333,11683.3333),
(21,27026.1111,13051.9444),
(22,27096.1111,13415.8333),
(23,27153.6111,13203.3333),
(24,27166.6667,9833.3333),
(25,27233.3333,10450.0000),
(26,27233.3333,11783.3333),
(27,27266.6667,10383.3333),
(28,27433.3333,12400.0000),
(29,27462.5000,12992.2222);
`

Next we use the `pgr_TSPeuclidean` function to find the best path.

`
select
    *
from
     pgr_TSPeuclidean($$select * from wi29$$)
`

`
seq | node |       cost       |     agg_cost
-----+------+------------------+------------------
1 |    1 |                0 |                0
2 |    2 |  74.535614157127 |  74.535614157127
3 |    6 | 900.617093380362 | 975.152707537489
4 |   10 | 2113.77757765045 | 3088.93028518793
5 |   11 | 106.718669615254 | 3195.64895480319
6 |   12 | 1411.95293791574 | 4607.60189271893
7 |   13 | 1314.23824873744 | 5921.84014145637
8 |   14 | 1321.76283931305 | 7243.60298076942
9 |   17 | 1202.91366735569 |  8446.5166481251
10 |   18 | 683.333268292684 | 9129.84991641779
11 |   15 | 1108.05137466134 | 10237.9012910791
12 |   19 | 772.082339448903 |  11009.983630528
13 |   22 | 697.666150054665 | 11707.6497805827
14 |   23 | 220.141999627513 | 11927.7917802102
15 |   21 | 197.926372783442 | 12125.7181529937
16 |   29 | 440.456596290771 | 12566.1747492844
17 |   28 | 592.939989005405 | 13159.1147382898
18 |   26 | 648.288376333318 | 13807.4031146231
19 |   20 | 509.901951359278 | 14317.3050659824
20 |   25 | 1330.83095428717 | 15648.1360202696
21 |   27 |  74.535658878487 | 15722.6716791481
22 |   24 | 559.016994374947 |  16281.688673523
23 |   16 | 1243.87392358622 | 17525.5625971092
24 |    9 |  4088.0585364911 | 21613.6211336004
25 |    7 |  650.85409697993 | 22264.4752305803
26 |    3 | 891.004385199336 | 23155.4796157796
27 |    4 | 1172.36699411442 |  24327.846609894
28 |    8 | 994.708187806297 | 25322.5547977003
29 |    5 | 1188.01888359478 | 26510.5736812951
30 |    1 | 2266.91173136004 | 28777.4854126552
`

## Resources [\#](https://supabase.com/docs/guides/database/extensions/pgrouting\#resources)

- Official [`pgRouting` documentation](https://docs.pgrouting.org/latest/en/index.html)

### Is this helpful?

NoYes

### On this page

[Enable the extension](https://supabase.com/docs/guides/database/extensions/pgrouting#enable-the-extension) [Example](https://supabase.com/docs/guides/database/extensions/pgrouting#example) [Resources](https://supabase.com/docs/guides/database/extensions/pgrouting#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_extensions_pgsodium.md">
Database

# pgsodium (pending deprecation): Encryption Features

* * *

Supabase DOES NOT RECOMMEND any new usage of [`pgsodium`](https://github.com/michelp/pgsodium).

The [`pgsodium`](https://github.com/michelp/pgsodium) extension is expected to go through a deprecation cycle in the near future. We will reach out to owners of impacted projects to assist with migrations away from [`pgsodium`](https://github.com/michelp/pgsodium) once the deprecation process begins.

The [Vault extension](https://supabase.com/docs/guides/database/vault) wont be impacted. Its internal implementation will shift away from pgsodium, but the interface and API will remain unchanged.

[`pgsodium`](https://github.com/michelp/pgsodium) is a Postgres extension which provides SQL access to [`libsodium`'s](https://doc.libsodium.org/) high-level cryptographic algorithms.

Supabase previously documented two features derived from pgsodium. Namely [Server Key Management](https://github.com/michelp/pgsodium#server-key-management) and [Transparent Column Encryption](https://github.com/michelp/pgsodium#transparent-column-encryption). At this time, we do not recommend using either on the Supabase platform due to their high level of operational complexity and misconfiguration risk.

Note that Supabase projects are encrypted at rest by default which likely is sufficient for your compliance needs e.g. SOC2 & HIPAA.

## Get the root encryption key for your Supabase project [\#](https://supabase.com/docs/guides/database/extensions/pgsodium\#get-the-root-encryption-key-for-your-supabase-project)

Encryption requires keys. Keeping the keys in the same database as the encrypted data would be unsafe. For more information about managing the `pgsodium` root encryption key on your Supabase project see **[encryption key location](https://supabase.com/docs/guides/database/vault#encryption-key-location)**. This key is required to decrypt values stored in [Supabase Vault](https://supabase.com/docs/guides/database/vault) and data encrypted with Transparent Column Encryption.

## Resources [\#](https://supabase.com/docs/guides/database/extensions/pgsodium\#resources)

- [Supabase Vault](https://supabase.com/docs/guides/database/vault)
- Read more about Supabase Vault in the [blog post](https://supabase.com/blog/vault-now-in-beta)
- [Supabase Vault on GitHub](https://github.com/supabase/vault)

## Resources [\#](https://supabase.com/docs/guides/database/extensions/pgsodium\#resources)

- Official [`pgsodium` documentation](https://github.com/michelp/pgsodium)

### Is this helpful?

NoYes

### On this page

[Get the root encryption key for your Supabase project](https://supabase.com/docs/guides/database/extensions/pgsodium#get-the-root-encryption-key-for-your-supabase-project) [Resources](https://supabase.com/docs/guides/database/extensions/pgsodium#resources) [Resources](https://supabase.com/docs/guides/database/extensions/pgsodium#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_extensions_pgtap.md">
Database

# pgTAP: Unit Testing

* * *

`pgTAP` is a unit testing extension for Postgres.

## Overview [\#](https://supabase.com/docs/guides/database/extensions/pgtap\#overview)

Let's cover some basic concepts:

- Unit tests: allow you to test small parts of a system (like a database table!).
- TAP: stands for [Test Anything Protocol](http://testanything.org/). It is an framework which aims to simplify the error reporting during testing.

## Enable the extension [\#](https://supabase.com/docs/guides/database/extensions/pgtap\#enable-the-extension)

DashboardSQL

1. Go to the [Database](https://supabase.com/dashboard/project/_/database/tables) page in the Dashboard.
2. Click on **Extensions** in the sidebar.
3. Search for `pgtap` and enable the extension.

## Testing tables [\#](https://supabase.com/docs/guides/database/extensions/pgtap\#testing-tables)

`
begin;
select plan( 1 );
select has_table( 'profiles' );
select * from finish();
rollback;
`

API:

- [`has_table()`](https://pgtap.org/documentation.html#has_table): Tests whether or not a table exists in the database
- [`has_index()`](https://pgtap.org/documentation.html#has_index): Checks for the existence of a named index associated with the named table.
- [`has_relation()`](https://pgtap.org/documentation.html#has_relation): Tests whether or not a relation exists in the database.

## Testing columns [\#](https://supabase.com/docs/guides/database/extensions/pgtap\#testing-columns)

`
begin;
select plan( 2 );
select has_column( 'profiles', 'id' ); -- test that the "id" column exists in the "profiles" table
select col_is_pk( 'profiles', 'id' ); -- test that the "id" column is a primary key
select * from finish();
rollback;
`

API:

- [`has_column()`](https://pgtap.org/documentation.html#has_column): Tests whether or not a column exists in a given table, view, materialized view or composite type.
- [`col_is_pk()`](https://pgtap.org/documentation.html#col_is_pk): Tests whether the specified column or columns in a table is/are the primary key for that table.

## Testing RLS policies [\#](https://supabase.com/docs/guides/database/extensions/pgtap\#testing-rls-policies)

`
begin;
select plan( 1 );
select policies_are(
'public',
'profiles',
ARRAY [\
    'Profiles are public', -- Test that there is a policy called  "Profiles are public" on the "profiles" table.\
    'Profiles can only be updated by the owner'  -- Test that there is a policy called  "Profiles can only be updated by the owner" on the "profiles" table.\
]
);
select * from finish();
rollback;
`

API:

- [`policies_are()`](https://pgtap.org/documentation.html#policies_are): Tests that all of the policies on the named table are only the policies that should be on that table.
- [`policy_roles_are()`](https://pgtap.org/documentation.html#policy_roles_are): Tests whether the roles to which policy applies are only the roles that should be on that policy.
- [`policy_cmd_is()`](https://pgtap.org/documentation.html#policy_cmd_is): Tests whether the command to which policy applies is same as command that is given in function arguments.

You can also use the `results_eq()` method to test that a Policy returns the correct data:

`
begin;
select plan( 1 );
select results_eq(
    'select * from profiles()',
    $$VALUES ( 1, 'Anna'), (2, 'Bruce'), (3, 'Caryn')$$,
    'profiles() should return all users'
);
select * from finish();
rollback;
`

API:

- [`results_eq()`](https://pgtap.org/documentation.html#results_eq)
- [`results_ne()`](https://pgtap.org/documentation.html#results_ne)

## Testing functions [\#](https://supabase.com/docs/guides/database/extensions/pgtap\#testing-functions)

`
prepare hello_expr as select 'hello'
begin;
select plan(3);
-- You'll need to create a hello_world and is_even function
select function_returns( 'hello_world', 'text' );                   -- test if the function "hello_world" returns text
select function_returns( 'is_even', ARRAY['integer'], 'boolean' );  -- test if the function "is_even" returns a boolean
select results_eq('select * from hello_world()', 'hello_expr');          -- test if the function "hello_world" returns "hello"
select * from finish();
rollback;
`

API:

- [`function_returns()`](https://pgtap.org/documentation.html#function_returns): Tests that a particular function returns a particular data type
- [`is_definer()`](https://pgtap.org/documentation.html#is_definer): Tests that a function is a security definer (that is, a `setuid` function).

## Resources [\#](https://supabase.com/docs/guides/database/extensions/pgtap\#resources)

- Official [`pgTAP` documentation](https://pgtap.org/)

### Is this helpful?

NoYes

### On this page

[Overview](https://supabase.com/docs/guides/database/extensions/pgtap#overview) [Enable the extension](https://supabase.com/docs/guides/database/extensions/pgtap#enable-the-extension) [Testing tables](https://supabase.com/docs/guides/database/extensions/pgtap#testing-tables) [Testing columns](https://supabase.com/docs/guides/database/extensions/pgtap#testing-columns) [Testing RLS policies](https://supabase.com/docs/guides/database/extensions/pgtap#testing-rls-policies) [Testing functions](https://supabase.com/docs/guides/database/extensions/pgtap#testing-functions) [Resources](https://supabase.com/docs/guides/database/extensions/pgtap#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_extensions_pgvector.md">
Database

# pgvector: Embeddings and vector similarity

* * *

[pgvector](https://github.com/pgvector/pgvector/) is a Postgres extension for vector similarity search. It can also be used for storing [embeddings](https://supabase.com/blog/openai-embeddings-postgres-vector).

The name of pgvector's Postgres extension is [vector](https://github.com/pgvector/pgvector/blob/258eaf58fdaff1843617ff59ea855e0768243fe9/README.md?plain=1#L64).

Learn more about Supabase's [AI & Vector](https://supabase.com/docs/guides/ai) offering.

## Concepts [\#](https://supabase.com/docs/guides/database/extensions/pgvector\#concepts)

### Vector similarity [\#](https://supabase.com/docs/guides/database/extensions/pgvector\#vector-similarity)

Vector similarity refers to a measure of the similarity between two related items. For example, if you have a list of products, you can use vector similarity to find similar products. To do this, you need to convert each product into a "vector" of numbers, using a mathematical model. You can use a similar model for text, images, and other types of data. Once all of these vectors are stored in the database, you can use vector similarity to find similar items.

### Embeddings [\#](https://supabase.com/docs/guides/database/extensions/pgvector\#embeddings)

This is particularly useful if you're building on top of OpenAI's [GPT-3](https://openai.com/blog/gpt-3-apps/). You can create and store [embeddings](https://supabase.com/docs/guides/ai/quickstarts/generate-text-embeddings) for retrieval augmented generation.

## Usage [\#](https://supabase.com/docs/guides/database/extensions/pgvector\#usage)

### Enable the extension [\#](https://supabase.com/docs/guides/database/extensions/pgvector\#enable-the-extension)

DashboardSQL

1. Go to the [Database](https://supabase.com/dashboard/project/_/database/tables) page in the Dashboard.
2. Click on **Extensions** in the sidebar.
3. Search for "vector" and enable the extension.

## Usage [\#](https://supabase.com/docs/guides/database/extensions/pgvector\#usage)

### Create a table to store vectors [\#](https://supabase.com/docs/guides/database/extensions/pgvector\#create-a-table-to-store-vectors)

`
create table posts (
id serial primary key,
title text not null,
body text not null,
embedding vector(384)
);
`

### Storing a vector / embedding [\#](https://supabase.com/docs/guides/database/extensions/pgvector\#storing-a-vector--embedding)

In this example we'll generate a vector using Transformer.js, then store it in the database using the Supabase client.

`
import { pipeline } from '@xenova/transformers'
const generateEmbedding = await pipeline('feature-extraction', 'Supabase/gte-small')
const title = 'First post!'
const body = 'Hello world!'
// Generate a vector using Transformers.js
const output = await generateEmbedding(body, {
pooling: 'mean',
normalize: true,
})
// Extract the embedding output
const embedding = Array.from(output.data)
// Store the vector in Postgres
const { data, error } = await supabase.from('posts').insert({
title,
body,
embedding,
})
`

## Specific usage cases [\#](https://supabase.com/docs/guides/database/extensions/pgvector\#specific-usage-cases)

### Queries with filtering [\#](https://supabase.com/docs/guides/database/extensions/pgvector\#queries-with-filtering)

If you use an IVFFlat or HNSW index and naively filter the results based on the value of another column, you may get fewer rows returned than requested.

For example, the following query may return fewer than 5 rows, even if 5 corresponding rows exist in the database. This is because the embedding index may not return 5 rows matching the filter.

`
SELECT * FROM items WHERE category_id = 123 ORDER BY embedding <-> '[3,1,2]' LIMIT 5;
`

To get the exact number of requested rows, use [iterative search](https://github.com/pgvector/pgvector/?tab=readme-ov-file#iterative-index-scans) to continue scanning the index until enough results are found.

## More pgvector and Supabase resources [\#](https://supabase.com/docs/guides/database/extensions/pgvector\#more-pgvector-and-supabase-resources)

- [Supabase Clippy: ChatGPT for Supabase Docs](https://supabase.com/blog/chatgpt-supabase-docs)
- [Storing OpenAI embeddings in Postgres with pgvector](https://supabase.com/blog/openai-embeddings-postgres-vector)
- [A ChatGPT Plugins Template built with Supabase Edge Runtime](https://supabase.com/blog/building-chatgpt-plugins-template)
- [Template for building your own custom ChatGPT style doc search](https://github.com/supabase-community/nextjs-openai-doc-search)

### Is this helpful?

NoYes

### On this page

[Concepts](https://supabase.com/docs/guides/database/extensions/pgvector#concepts) [Vector similarity](https://supabase.com/docs/guides/database/extensions/pgvector#vector-similarity) [Embeddings](https://supabase.com/docs/guides/database/extensions/pgvector#embeddings) [Usage](https://supabase.com/docs/guides/database/extensions/pgvector#usage) [Enable the extension](https://supabase.com/docs/guides/database/extensions/pgvector#enable-the-extension) [Usage](https://supabase.com/docs/guides/database/extensions/pgvector#usage) [Create a table to store vectors](https://supabase.com/docs/guides/database/extensions/pgvector#create-a-table-to-store-vectors) [Storing a vector / embedding](https://supabase.com/docs/guides/database/extensions/pgvector#storing-a-vector--embedding) [Specific usage cases](https://supabase.com/docs/guides/database/extensions/pgvector#specific-usage-cases) [Queries with filtering](https://supabase.com/docs/guides/database/extensions/pgvector#queries-with-filtering) [More pgvector and Supabase resources](https://supabase.com/docs/guides/database/extensions/pgvector#more-pgvector-and-supabase-resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_extensions_plpgsql_check.md">
Database

# plpgsql\_check: PL/pgSQL Linter

* * *

[plpgsql\_check](https://github.com/okbob/plpgsql_check) is a Postgres extension that lints plpgsql for syntax, semantic and other related issues. The tool helps developers to identify and correct errors before executing the code. plpgsql\_check is most useful for developers who are working with large or complex SQL codebases, as it can help identify and resolve issues early in the development cycle.

## Enable the extension [\#](https://supabase.com/docs/guides/database/extensions/plpgsql_check\#enable-the-extension)

DashboardSQL

1. Go to the [Database](https://supabase.com/dashboard/project/_/database/tables) page in the Dashboard.
2. Click on **Extensions** in the sidebar.
3. Search for "plpgsql\_check" and enable the extension.

## API [\#](https://supabase.com/docs/guides/database/extensions/plpgsql_check\#api)

- [`plpgsql_check_function( ... )`](https://github.com/okbob/plpgsql_check#active-mode): Scans a function for errors.

`plpgsql_check_function` is highly customizable. For a complete list of available arguments see [the docs](https://github.com/okbob/plpgsql_check#arguments)

## Usage [\#](https://supabase.com/docs/guides/database/extensions/plpgsql_check\#usage)

To demonstrate `plpgsql_check` we can create a function with a known error. In this case we create a function `some_func`, that references a non-existent column `place.created_at`.

``
create table place(
x float,
y float
);
create or replace function public.some_func()
returns void
language plpgsql
as $$
declare
rec record;
begin
for rec in select * from place
loop
    -- Bug: There is no column `created_at` on table `place`
    raise notice '%', rec.created_at;
end loop;
end;
$$;
``

Note that executing the function would not catch the invalid reference error because the `loop` does not execute if no rows are present in the table.

`
select public.some_func();
some_func

(1 row)
`

Now we can use plpgsql\_check's `plpgsql_check_function` function to identify the known error.

`
select plpgsql_check_function('public.some_func()');
                   plpgsql_check_function
------------------------------------------------------------
error:42703:8:RAISE:record "rec" has no field "created_at"
Context: SQL expression "rec.created_at"
`

## Resources [\#](https://supabase.com/docs/guides/database/extensions/plpgsql_check\#resources)

- Official [`plpgsql_check` documentation](https://github.com/okbob/plpgsql_check)

### Is this helpful?

NoYes

### On this page

[Enable the extension](https://supabase.com/docs/guides/database/extensions/plpgsql_check#enable-the-extension) [API](https://supabase.com/docs/guides/database/extensions/plpgsql_check#api) [Usage](https://supabase.com/docs/guides/database/extensions/plpgsql_check#usage) [Resources](https://supabase.com/docs/guides/database/extensions/plpgsql_check#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_extensions_plv8.md">
Database

# plv8: JavaScript Language

* * *

The `plv8` extension allows you use JavaScript within Postgres.

## Overview [\#](https://supabase.com/docs/guides/database/extensions/plv8\#overview)

While Postgres natively runs SQL, it can also run other procedural languages.
`plv8` allows you to run JavaScript code - specifically any code that runs on the [V8 JavaScript engine](https://v8.dev/).

It can be used for database functions, triggers, queries and more.

## Enable the extension [\#](https://supabase.com/docs/guides/database/extensions/plv8\#enable-the-extension)

DashboardSQL

1. Go to the [Database](https://supabase.com/dashboard/project/_/database/tables) page in the Dashboard.
2. Click on **Extensions** in the sidebar.
3. Search for "plv8" and enable the extension.

## Create `plv8` functions [\#](https://supabase.com/docs/guides/database/extensions/plv8\#create-plv8-functions)

Functions written in `plv8` are written just like any other Postgres functions, only
with the `language` identifier set to `plv8`.

`
create or replace function function_name()
returns void as $$
    // V8 JavaScript
    // code
    // here
$$ language plv8;
`

You can call `plv8` functions like any other Postgres function:

SQLJavaScriptKotlin

`
select function_name();
`

## Examples [\#](https://supabase.com/docs/guides/database/extensions/plv8\#examples)

### Scalar functions [\#](https://supabase.com/docs/guides/database/extensions/plv8\#scalar-functions)

A [scalar function](https://plv8.github.io/#scalar-function-calls) is anything that takes in some user input and returns a single result.

``
create or replace function hello_world(name text)
returns text as $$
    let output = `Hello, ${name}!`;
    return output;
$$ language plv8;
``

### Executing SQL [\#](https://supabase.com/docs/guides/database/extensions/plv8\#executing-sql)

You can execute SQL within `plv8` code using the [`plv8.execute` function](https://plv8.github.io/#plv8-execute).

`
create or replace function update_user(id bigint, first_name text)
returns smallint as $$
    var num_affected = plv8.execute(
        'update profiles set first_name = $1 where id = $2',
        [first_name, id]
    );
    return num_affected;
$$ language plv8;
`

### Set-returning functions [\#](https://supabase.com/docs/guides/database/extensions/plv8\#set-returning-functions)

A [set-returning function](https://plv8.github.io/#set-returning-function-calls) is anything that returns a full set of results - for example, rows in a table.

`
create or replace function get_messages()
returns setof messages as $$
    var json_result = plv8.execute(
        'select * from messages'
    );
    return json_result;
$$ language plv8;
select * from get_messages();
`

## Resources [\#](https://supabase.com/docs/guides/database/extensions/plv8\#resources)

- Official [`plv8` documentation](https://plv8.github.io/)
- [plv8 GitHub Repository](https://github.com/plv8/plv8)

### Is this helpful?

NoYes

### On this page

[Overview](https://supabase.com/docs/guides/database/extensions/plv8#overview) [Enable the extension](https://supabase.com/docs/guides/database/extensions/plv8#enable-the-extension) [Create plv8 functions](https://supabase.com/docs/guides/database/extensions/plv8#create-plv8-functions) [Examples](https://supabase.com/docs/guides/database/extensions/plv8#examples) [Scalar functions](https://supabase.com/docs/guides/database/extensions/plv8#scalar-functions) [Executing SQL](https://supabase.com/docs/guides/database/extensions/plv8#executing-sql) [Set-returning functions](https://supabase.com/docs/guides/database/extensions/plv8#set-returning-functions) [Resources](https://supabase.com/docs/guides/database/extensions/plv8#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_extensions_postgis.md">
Database

# PostGIS: Geo queries

* * *

[PostGIS](https://postgis.net/) is a Postgres extension that allows you to interact with Geo data within Postgres. You can sort your data by geographic location, get data within certain geographic boundaries, and do much more with it.

## Overview [\#](https://supabase.com/docs/guides/database/extensions/postgis\#overview)

While you may be able to store simple lat/long geographic coordinates as a set of decimals, it does not scale very well when you try to query through a large data set. PostGIS comes with special data types that are efficient, and indexable for high scalability.

The additional data types that PostGIS provides include [Point](https://postgis.net/docs/using_postgis_dbmanagement.html#Point), [Polygon](https://postgis.net/docs/using_postgis_dbmanagement.html#Polygon), [LineString](https://postgis.net/docs/using_postgis_dbmanagement.html#LineString), and many more to represent different types of geographical data. In this guide, we will mainly focus on how to interact with `Point` type, which represents a single set of latitude and longitude. If you are interested in digging deeper, you can learn more about different data types on the [data management section of PostGIS docs](https://postgis.net/docs/using_postgis_dbmanagement.html).

## Enable the extension [\#](https://supabase.com/docs/guides/database/extensions/postgis\#enable-the-extension)

You can get started with PostGIS by enabling the PostGIS extension in your Supabase dashboard.

DashboardSQL

1. Go to the [Database](https://supabase.com/dashboard/project/_/database/tables) page in the Dashboard.
2. Click on **Extensions** in the sidebar.
3. Search for `postgis` and enable the extension.
4. In the confirmation prompt select "Create a new schema" and name it `gis` for example.

## Examples [\#](https://supabase.com/docs/guides/database/extensions/postgis\#examples)

Now that we are ready to get started with PostGIS, lets create a table and see how we can utilize PostGIS for some typical use cases. Lets imagine we are creating a simple restaurant-searching app.

Lets create our table. Each row represents a restaurant with its location stored in `location` column as a `Point` type.

`
create table if not exists public.restaurants (
	id int generated by default as identity primary key,
	name text not null,
	location gis.geography(POINT) not null
);
`

We can then set a [spatial index](https://postgis.net/docs/using_postgis_dbmanagement.html#build-indexes) on the `location` column of this table.

`
create index restaurants_geo_index
on public.restaurants
using GIST (location);
`

### Inserting data [\#](https://supabase.com/docs/guides/database/extensions/postgis\#inserting-data)

You can insert geographical data through SQL or through our API.

DataSQLJavaScriptDartSwiftKotlin

#### Restaurants

| id | name | location |
| --- | --- | --- |
| 1 | Supa Burger | lat: 40.807416, long: -73.946823 |
| 2 | Supa Pizza | lat: 40.807475, long: -73.94581 |
| 3 | Supa Taco | lat: 40.80629, long: -73.945826 |

Notice the order in which you pass the latitude and longitude. Longitude comes first, and is because longitude represents the x-axis of the location. Another thing to watch for is when inserting data from the client library, there is no comma between the two values, just a single space.

At this point, if you go into your Supabase dashboard and look at the data, you will notice that the value of the `location` column looks something like this.

`
0101000020E6100000A4DFBE0E9C91614044FAEDEBC0494240
`

We can query the `restaurants` table directly, but it will return the `location` column in the format you see above.
We will create [database functions](https://supabase.com/docs/guides/database/functions) so that we can use the [st\_y()](https://postgis.net/docs/ST_Y.html) and [st\_x()](https://postgis.net/docs/ST_X.html) function to convert it back to lat and long floating values.

### Order by distance [\#](https://supabase.com/docs/guides/database/extensions/postgis\#order-by-distance)

Sorting datasets from closest to farthest, sometimes called nearest-neighbor sort, is a very common use case in Geo-queries. PostGIS can handle it with the use of the [`<->`](https://postgis.net/docs/geometry_distance_knn.html) operator. `<->` operator returns the two-dimensional distance between two geometries and will utilize the spatial index when used within `order by` clause. You can create the following database function to sort the restaurants from closest to farthest by passing the current locations as parameters.

`
create or replace function nearby_restaurants(lat float, long float)
returns table (id public.restaurants.id%TYPE, name public.restaurants.name%TYPE, lat float, long float, dist_meters float)
set search_path = ''
language sql
as $$
select id, name, gis.st_y(location::gis.geometry) as lat, gis.st_x(location::gis.geometry) as long, gis.st_distance(location, gis.st_point(long, lat)::gis.geography) as dist_meters
from public.restaurants
order by location operator(gis.<->) gis.st_point(long, lat)::gis.geography;
$$;
`

Before being able to call this function from our client we need to grant access to our `gis` schema:

`
grant usage on schema gis to anon, authenticated;
`

Now you can call this function from your client using `rpc()` like this:

JavaScriptDartSwiftKotlinResult

`
const { data, error } = await supabase.rpc('nearby_restaurants', {
lat: 40.807313,
long: -73.946713,
})
`

### Finding all data points within a bounding box [\#](https://supabase.com/docs/guides/database/extensions/postgis\#finding-all-data-points-within-a-bounding-box)

![Searching within a bounding box of a map](https://supabase.com/docs/img/guides/database/extensions/postgis/map.png)

When you are working on a map-based application where the user scrolls through your map, you might want to load the data that lies within the bounding box of the map every time your users scroll. PostGIS can return the rows that are within the bounding box just by supplying the bottom left and the top right coordinates. Lets look at what the function would look like:

`
create or replace function restaurants_in_view(min_lat float, min_long float, max_lat float, max_long float)
returns table (id public.restaurants.id%TYPE, name public.restaurants.name%TYPE, lat float, long float)
set search_path to ''
language sql
as $$
	select id, name, gis.st_y(location::gis.geometry) as lat, gis.st_x(location::gis.geometry) as long
	from public.restaurants
	where location operator(gis.&&) gis.ST_SetSRID(gis.ST_MakeBox2D(gis.ST_Point(min_long, min_lat), gis.ST_Point(max_long, max_lat)), 4326)
$$;
`

The [`&&`](https://postgis.net/docs/geometry_overlaps.html) operator used in the `where` statement here returns a boolean of whether the bounding box of the two geometries intersect or not. We are basically creating a bounding box from the two points and finding those points that fall under the bounding box. We are also utilizing a few different PostGIS functions:

- [ST\_MakeBox2D](https://postgis.net/docs/ST_MakeBox2D.html): Creates a 2-dimensional box from two points.
- [ST\_SetSRID](https://postgis.net/docs/ST_SetSRID.html): Sets the [SRID](https://postgis.net/docs/manual-dev/using_postgis_dbmanagement.html#spatial_ref_sys), which is an identifier of what coordinate system to use for the geometry. 4326 is the standard longitude and latitude coordinate system.

You can call this function from your client using `rpc()` like this:

JavaScriptDartSwiftKotlinResult

`
const { data, error } = await supabase.rpc('restaurants_in_view', {
min_lat: 40.807,
min_long: -73.946,
max_lat: 40.808,
max_long: -73.945,
})
`

## Troubleshooting [\#](https://supabase.com/docs/guides/database/extensions/postgis\#troubleshooting)

The [official PostGIS documentation](https://postgis.net/documentation/tips/tip-move-postgis-schema/) for relocating the schema will cause issues for Supabase projects. These issues might not be apparent immediately but will eventually surface. To relocate your schema, use the following steps instead.

As of PostGIS 2.3 or newer, the PostGIS extension is no longer relocatable from one schema to another. If you need to move it from one schema to another for any reason (e.g. from the public schema to the extensions schema for security reasons), you would normally run a ALTER EXTENSION to relocate the schema. However, you will now to do the following steps:

1. Backup your Database to prevent data loss - You can do this through the [CLI](https://supabase.com/docs/reference/cli/supabase-db-dump) or Postgres backup tools such as [pg\_dumpall](https://www.postgresql.org/docs/current/backup-dump.html#BACKUP-DUMP-ALL)

2. Drop all dependencies you created and the PostGIS extension - `DROP EXTENSION postgis CASCADE;`

3. Enable PostGIS extension in the new schema - `CREATE EXTENSION postgis SCHEMA extensions;`

4. Restore dropped data via the Backup if necessary from step 1 with your tool of choice.


## Resources [\#](https://supabase.com/docs/guides/database/extensions/postgis\#resources)

- [Official PostGIS documentation](https://postgis.net/documentation/)

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2FagFsGDJxjwA%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Overview](https://supabase.com/docs/guides/database/extensions/postgis#overview) [Enable the extension](https://supabase.com/docs/guides/database/extensions/postgis#enable-the-extension) [Examples](https://supabase.com/docs/guides/database/extensions/postgis#examples) [Inserting data](https://supabase.com/docs/guides/database/extensions/postgis#inserting-data) [Order by distance](https://supabase.com/docs/guides/database/extensions/postgis#order-by-distance) [Finding all data points within a bounding box](https://supabase.com/docs/guides/database/extensions/postgis#finding-all-data-points-within-a-bounding-box) [Troubleshooting](https://supabase.com/docs/guides/database/extensions/postgis#troubleshooting) [Resources](https://supabase.com/docs/guides/database/extensions/postgis#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_extensions_postgres_fdw.md">
Database

# postgres\_fdw

* * *

The extension enables Postgres to query tables and views on a remote Postgres server.

## Enable the extension [\#](https://supabase.com/docs/guides/database/extensions/postgres_fdw\#enable-the-extension)

DashboardSQL

1. Go to the [Database](https://supabase.com/dashboard/project/_/database/tables) page in the Dashboard.
2. Click on **Extensions** in the sidebar.
3. Search for "postgres\_fdw" and enable the extension.

## Create a connection to another database [\#](https://supabase.com/docs/guides/database/extensions/postgres_fdw\#create-a-connection-to-another-database)

1

### Create a foreign server

Define the remote database address

`
    create server "<foreign_server_name>"
    foreign data wrapper postgres_fdw
    options (
        host '<host>',
        port '<port>',
        dbname '<dbname>'
    );
`

2

### Create a server mapping

Set the user credentials for the remote server

`
create user mapping for "<dbname>"
server "<foreign_server_name>"
options (
    user '<db_user>',
    password '<password>'
);
`

3

### Import tables

Import tables from the foreign database

Example: Import all tables from a schema

`
import foreign schema "<foreign_schema>"
from server "<foreign_server>"
into "<host_schema>";
`

Example: Import specific tables

`
import foreign schema "<foreign_schema>"
limit to (
    "<table_name1>",
    "<table_name2>"
)
from server "<foreign_server>"
into "<host_schema>";
`

4

### Query foreign table

`
select * from "<foreign_table>"
`

### Configuring execution options [\#](https://supabase.com/docs/guides/database/extensions/postgres_fdw\#configuring-execution-options)

#### Fetch\_size [\#](https://supabase.com/docs/guides/database/extensions/postgres_fdw\#fetchsize)

Maximum rows fetched per operation. For example, fetching 200 rows with `fetch_size` set to 100 requires 2 requests.

`
alter server "<foreign_server_name>"
options (fetch_size '10000');
`

#### Batch\_size [\#](https://supabase.com/docs/guides/database/extensions/postgres_fdw\#batchsize)

Maximum rows inserted per cycle. For example, inserting 200 rows with `batch_size` set to 100 requires 2 requests.

`
alter server "<foreign_server_name>"
options (batch_size '1000');
`

#### Extensions [\#](https://supabase.com/docs/guides/database/extensions/postgres_fdw\#extensions)

Lists shared extensions. Without them, queries involving unlisted extension functions or operators may fail or omit references.

`
alter server "<foreign_server_name>"
options (extensions 'vector, postgis');
`

For more server options, check the extension's [official documentation](https://www.postgresql.org/docs/current/postgres-fdw.html#POSTGRES-FDW)

## Resources [\#](https://supabase.com/docs/guides/database/extensions/postgres_fdw\#resources)

- Official [`postgres_fdw` documentation](https://www.postgresql.org/docs/current/postgres-fdw.html#POSTGRES-FDW)

### Is this helpful?

NoYes

### On this page

[Enable the extension](https://supabase.com/docs/guides/database/extensions/postgres_fdw#enable-the-extension) [Create a connection to another database](https://supabase.com/docs/guides/database/extensions/postgres_fdw#create-a-connection-to-another-database) [Configuring execution options](https://supabase.com/docs/guides/database/extensions/postgres_fdw#configuring-execution-options) [Resources](https://supabase.com/docs/guides/database/extensions/postgres_fdw#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_extensions_rum.md">
Database

# RUM: improved inverted index for full-text search based on GIN index

* * *

[RUM](https://github.com/postgrespro/rum) is an extension which adds a RUM index to Postgres.

RUM index is based on GIN that stores additional per-entry information in a posting tree. For example, positional information of lexemes or timestamps. In comparison to GIN it can use this information to make faster index-only scans for:

- Phrase search
- Text search with ranking by text distance operator
- Text `SELECT` s with ordering by some non-indexed additional column e.g. by timestamp.

RUM works best in scenarios when the possible keys are highly repeatable. I.e. all texts are composed of a
limited amount of words, so per-lexeme indexing gives significant speed-up in searching texts containing word
combinations or phrases.

Main operators for ordering are:

`tsvector` `<=>` `tsquery` \| `float4` \| Distance between `tsvector` and `tsquery`.
value `<=>` value \| `float8` \| Distance between two values.

Where value is `timestamp`, `timestamptz`, `int2`, `int4`, `int8`, `float4`, `float8`, `money` and `oid`

## Usage [\#](https://supabase.com/docs/guides/database/extensions/rum\#usage)

### Enable the extension [\#](https://supabase.com/docs/guides/database/extensions/rum\#enable-the-extension)

You can get started with rum by enabling the extension in your Supabase dashboard.

DashboardSQL

1. Go to the [Database](https://supabase.com/dashboard/project/_/database/tables) page in the Dashboard.
2. Click on **Extensions** in the sidebar.
3. Search for "rum" and enable the extension.

### Syntax [\#](https://supabase.com/docs/guides/database/extensions/rum\#syntax)

#### For type: `tsvector` [\#](https://supabase.com/docs/guides/database/extensions/rum\#for-type-tsvector)

To understand the following you may need first to see [Official Postgres documentation on text\\
search](https://www.postgresql.org/docs/current/functions-textsearch.html)

`rum_tsvector_ops`

`
CREATE TABLE test_rum(t text, a tsvector);
CREATE TRIGGER tsvectorupdate
BEFORE UPDATE OR INSERT ON test_rum
FOR EACH ROW EXECUTE PROCEDURE tsvector_update_trigger('a', 'pg_catalog.english', 't');
INSERT INTO test_rum(t) VALUES ('The situation is most beautiful');
INSERT INTO test_rum(t) VALUES ('It is a beautiful');
INSERT INTO test_rum(t) VALUES ('It looks like a beautiful place');
CREATE INDEX rumidx ON test_rum USING rum (a rum_tsvector_ops);
`

And we can execute `tsvector` selects with ordering by text distance operator:

``
SELECT t, a `<=>` to_tsquery('english', 'beautiful | place') AS rank
    FROM test_rum
    WHERE a @@ to_tsquery('english', 'beautiful | place')
    ORDER BY a `<=>` to_tsquery('english', 'beautiful | place');
                t                |  rank
---------------------------------+---------
It looks like a beautiful place | 8.22467
The situation is most beautiful | 16.4493
It is a beautiful               | 16.4493
(3 rows)
``

`rum_tsvector_addon_ops`

`
CREATE TABLE tsts (id int, t tsvector, d timestamp);
CREATE INDEX tsts_idx ON tsts USING rum (t rum_tsvector_addon_ops, d)
    WITH (attach = 'd', to = 't');
`

Now we can execute the selects with ordering distance operator on attached column:

``
SELECT id, d, d `<=>` '2016-05-16 14:21:25' FROM tsts WHERE t @@ 'wr&qh' ORDER BY d `<=>` '2016-05-16 14:21:25' LIMIT 5;
id  |                d                |   ?column?
-----+---------------------------------+---------------
355 | Mon May 16 14:21:22.326724 2016 |      2.673276
354 | Mon May 16 13:21:22.326724 2016 |   3602.673276
371 | Tue May 17 06:21:22.326724 2016 |  57597.326724
406 | Wed May 18 17:21:22.326724 2016 | 183597.326724
415 | Thu May 19 02:21:22.326724 2016 | 215997.326724
(5 rows)
``

#### For type: `anyarray` [\#](https://supabase.com/docs/guides/database/extensions/rum\#for-type-anyarray)

`rum_anyarray_ops`

This operator class stores `anyarray` elements with length of the array. It supports operators `&&`, `@>`, `<@`, `=`, `%` operators. It also supports ordering by `<=>` operator.

`
CREATE TABLE test_array (i int2[]);
INSERT INTO test_array VALUES ('{}'), ('{0}'), ('{1,2,3,4}'), ('{1,2,3}'), ('{1,2}'), ('{1}');
CREATE INDEX idx_array ON test_array USING rum (i rum_anyarray_ops);
`

Now we can execute the query using index scan:

``
SELECT * FROM test_array WHERE i && '{1}' ORDER BY i `<=>` '{1}' ASC;
     i
-----------
{1}
{1,2}
{1,2,3}
{1,2,3,4}
(4 rows)
``

`rum_anyarray_addon_ops`

The does the same with `anyarray` index as `rum_tsvector_addon_ops` i.e. allows to order select results using distance
operator by attached column.

## Limitations [\#](https://supabase.com/docs/guides/database/extensions/rum\#limitations)

`RUM` has slower build and insert times than `GIN` due to:

1. It is bigger due to the additional attributes stored in the index.
2. It uses generic WAL records.

## Resources [\#](https://supabase.com/docs/guides/database/extensions/rum\#resources)

- [Official RUM documentation](https://github.com/postgrespro/rum)

### Is this helpful?

NoYes

### On this page

[Usage](https://supabase.com/docs/guides/database/extensions/rum#usage) [Enable the extension](https://supabase.com/docs/guides/database/extensions/rum#enable-the-extension) [Syntax](https://supabase.com/docs/guides/database/extensions/rum#syntax) [Limitations](https://supabase.com/docs/guides/database/extensions/rum#limitations) [Resources](https://supabase.com/docs/guides/database/extensions/rum#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_extensions_timescaledb.md">
Database

# timescaledb: Time-Series data

* * *

[`timescaledb`](https://docs.timescale.com/timescaledb/latest/) is a Postgres extension designed for improved handling of time-series data. It provides a scalable, high-performance solution for storing and querying time-series data on top of a standard Postgres database.

`timescaledb` uses a time-series-aware storage model and indexing techniques to improve performance of Postgres in working with time-series data. The extension divides data into chunks based on time intervals, allowing it to scale efficiently, especially for large data sets. The data is then compressed, optimized for write-heavy workloads, and partitioned for parallel processing. `timescaledb` also includes a set of functions, operators, and indexes that work with time-series data to reduce query times, and make data easier to work with.

Supabase projects come with [TimescaleDB Apache 2 Edition](https://docs.timescale.com/about/latest/timescaledb-editions/#timescaledb-apache-2-edition). Functionality only available under the Community Edition is not available.

## Enable the extension [\#](https://supabase.com/docs/guides/database/extensions/timescaledb\#enable-the-extension)

DashboardSQL

1. Go to the [Database](https://supabase.com/dashboard/project/_/database/tables) page in the Dashboard.
2. Click on **Extensions** in the sidebar.
3. Search for `timescaledb` and enable the extension.

## Usage [\#](https://supabase.com/docs/guides/database/extensions/timescaledb\#usage)

To demonstrate how `timescaledb` works, let's consider a simple example where we have a table that stores temperature data from different sensors. We will create a table named "temperatures" and store data for two sensors.

First we create a hypertable, which is a virtual table that is partitioned into chunks based on time intervals. The hypertable acts as a proxy for the actual table and makes it easy to query and manage time-series data.

`
create table temperatures (
time timestamptz not null,
sensor_id int not null,
temperature double precision not null
);
select create_hypertable('temperatures', 'time');
`

Next, we can populate some values

`
insert into temperatures (time, sensor_id, temperature)
values
    ('2023-02-14 09:00:00', 1, 23.5),
    ('2023-02-14 09:00:00', 2, 21.2),
    ('2023-02-14 09:05:00', 1, 24.5),
    ('2023-02-14 09:05:00', 2, 22.3),
    ('2023-02-14 09:10:00', 1, 25.1),
    ('2023-02-14 09:10:00', 2, 23.9),
    ('2023-02-14 09:15:00', 1, 24.9),
    ('2023-02-14 09:15:00', 2, 22.7),
    ('2023-02-14 09:20:00', 1, 24.7),
    ('2023-02-14 09:20:00', 2, 23.5);
`

And finally we can query the table using `timescaledb`'s `time_bucket` function to divide the time-series into intervals of the specified size (in this case, 1 hour) averaging the `temperature` reading within each group.

`
select
    time_bucket('1 hour', time) AS hour,
    avg(temperature) AS average_temperature
from
    temperatures
where
    sensor_id = 1
    and time > NOW() - interval '1 hour'
group by
    hour;
`

## Resources [\#](https://supabase.com/docs/guides/database/extensions/timescaledb\#resources)

- Official [`timescaledb` documentation](https://docs.timescale.com/timescaledb/latest/)

### Is this helpful?

NoYes

### On this page

[Enable the extension](https://supabase.com/docs/guides/database/extensions/timescaledb#enable-the-extension) [Usage](https://supabase.com/docs/guides/database/extensions/timescaledb#usage) [Resources](https://supabase.com/docs/guides/database/extensions/timescaledb#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_extensions_uuid_ossp.md">
Database

# uuid-ossp: Unique Identifiers

* * *

The `uuid-ossp` extension can be used to generate a `UUID`.

## Overview [\#](https://supabase.com/docs/guides/database/extensions/uuid-ossp\#overview)

A `UUID` is a "Universally Unique Identifier" and it is, for practical purposes, unique.
This makes them particularly well suited as Primary Keys. It is occasionally referred to as a `GUID`, which stands for "Globally Unique Identifier".

## Enable the extension [\#](https://supabase.com/docs/guides/database/extensions/uuid-ossp\#enable-the-extension)

**Note**:
Currently `uuid-ossp` extension is enabled by default and cannot be disabled.

DashboardSQL

1. Go to the [Database](https://supabase.com/dashboard/project/_/database/tables) page in the Dashboard.
2. Click on **Extensions** in the sidebar.
3. Search for `uuid-ossp` and enable the extension.

## The `uuid` type [\#](https://supabase.com/docs/guides/database/extensions/uuid-ossp\#the-uuid-type)

Once the extension is enabled, you now have access to a `uuid` type.

## `uuid_generate_v1()` [\#](https://supabase.com/docs/guides/database/extensions/uuid-ossp\#uuidgeneratev1)

Creates a UUID value based on the combination of computers MAC address, current timestamp, and a random value.

UUIDv1 leaks identifiable details, which might make it unsuitable for certain security-sensitive applications.

## `uuid_generate_v4()` [\#](https://supabase.com/docs/guides/database/extensions/uuid-ossp\#uuidgeneratev4)

Creates UUID values based solely on random numbers. You can also use Postgres's built-in [`gen_random_uuid()`](https://www.postgresql.org/docs/current/functions-uuid.html) function to generate a UUIDv4.

## Examples [\#](https://supabase.com/docs/guides/database/extensions/uuid-ossp\#examples)

### Within a query [\#](https://supabase.com/docs/guides/database/extensions/uuid-ossp\#within-a-query)

`
select uuid_generate_v4();
`

### As a primary key [\#](https://supabase.com/docs/guides/database/extensions/uuid-ossp\#as-a-primary-key)

Automatically create a unique, random ID in a table:

`
create table contacts (
id uuid default uuid_generate_v4(),
first_name text,
last_name text,
primary key (id)
);
`

## Resources [\#](https://supabase.com/docs/guides/database/extensions/uuid-ossp\#resources)

- [Choosing a Postgres Primary Key](https://supabase.com/blog/choosing-a-postgres-primary-key)
- [The Basics Of Postgres `UUID` Data Type](https://www.postgresqltutorial.com/postgresql-uuid/)

### Is this helpful?

NoYes

### On this page

[Overview](https://supabase.com/docs/guides/database/extensions/uuid-ossp#overview) [Enable the extension](https://supabase.com/docs/guides/database/extensions/uuid-ossp#enable-the-extension) [The uuid type](https://supabase.com/docs/guides/database/extensions/uuid-ossp#the-uuid-type) [uuid\_generate\_v1()](https://supabase.com/docs/guides/database/extensions/uuid-ossp#uuidgeneratev1) [uuid\_generate\_v4()](https://supabase.com/docs/guides/database/extensions/uuid-ossp#uuidgeneratev4) [Examples](https://supabase.com/docs/guides/database/extensions/uuid-ossp#examples) [Within a query](https://supabase.com/docs/guides/database/extensions/uuid-ossp#within-a-query) [As a primary key](https://supabase.com/docs/guides/database/extensions/uuid-ossp#as-a-primary-key) [Resources](https://supabase.com/docs/guides/database/extensions/uuid-ossp#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_extensions_wrappers_overview.md">
Database

# Foreign Data Wrappers

## Connecting to external systems using Postgres Foreign Data Wrappers.

* * *

Foreign Data Wrappers (FDW) are a core feature of Postgres that allow you to access and query data stored in external data sources as if they were native Postgres tables.

Postgres includes several built-in foreign data wrappers, such as [`postgres_fdw`](https://www.postgresql.org/docs/current/postgres-fdw.html) for accessing other Postgres databases, and [`file_fdw`](https://www.postgresql.org/docs/current/file-fdw.html) for reading data from files. Supabase extends this feature to query other databases or any other external systems. We do this with our open source [Wrappers](https://github.com/supabase/wrappers) framework. In these guides we'll refer to them as "Wrappers", Foreign Data Wrappers, or FDWs. They are conceptually the same thing.

## Concepts [\#](https://supabase.com/docs/guides/database/extensions/wrappers/overview\#concepts)

Wrappers introduce some new terminology and different workflows.

![Foreign Data Wrappers (FDW)](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fdatabase%2Fforeign-data-wrappers%2Fextracting-data--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Remote servers [\#](https://supabase.com/docs/guides/database/extensions/wrappers/overview\#remote-servers)

A Remote Server is an external database, API, or any system containing data that you want to query from your Postgres database. Examples include:

- An external database, like Postgres or Firebase.
- A remote data warehouse, like ClickHouse, BigQuery, or Snowflake.
- An API, like Stripe or GitHub.

It's possible to connect to multiple remote servers of the same type. For example, you can connect to two different Firebase projects within the same Supabase database.

### Foreign tables [\#](https://supabase.com/docs/guides/database/extensions/wrappers/overview\#foreign-tables)

A table in your database which maps to some data inside a Remote Server.

Examples:

- An `analytics` table which maps to a table inside your data warehouse.
- A `subscriptions` table which maps to your Stripe subscriptions.
- A `collections` table which maps to a Firebase collection.

Although a foreign table behaves like any other table, the data is not stored inside your database. The data remains inside the Remote Server.

### ETL with Wrappers [\#](https://supabase.com/docs/guides/database/extensions/wrappers/overview\#etl-with-wrappers)

ETL stands for Extract, Transform, Load. It's an established process for moving data from one system to another. For example, it's common to move data from a production database to a data warehouse.

There are many popular ETL tools, such as [Fivetran](https://fivetran.com/) and [Airbyte](https://airbyte.io/).

Wrappers provide an alternative to these tools. You can use SQL to move data from one table to another:

`
-- Copy data from your production database to your
-- data warehouse for the last 24 hours:
insert into warehouse.analytics
select * from public.analytics
where ts > (now() - interval '1 DAY');
`

This approach provides several benefits:

1. **Simplicity:** the Wrappers API is just SQL, so data engineers don't need to learn new tools and languages.
2. **Save on time:** avoid setting up additional data pipelines.
3. **Save on Data Engineering costs:** less infrastructure to be managed.

One disadvantage is that Wrappers are not as feature-rich as ETL tools. They also couple the ETL process to your database.

### On-demand ETL with Wrappers [\#](https://supabase.com/docs/guides/database/extensions/wrappers/overview\#on-demand-etl-with-wrappers)

Supabase extends the ETL concept with real-time data access. Instead of moving gigabytes of data from one system to another before you can query it, you can instead query the data directly from the remote server. This additional option, "Query", extends the ETL process and is called [QETL](https://www.sciencedirect.com/science/article/abs/pii/S0169023X1730438X) (pronounced "kettle"): Query, Extract, Transform, Load.

`
-- Get all purchases for a user from your data warehouse:
select
auth.users.id as user_id,
warehouse.orders.id as order_id
from
warehouse.orders
join
auth.users on auth.users.id = warehouse.orders.user_id
where
auth.users.id = '<some_user_id>';
`

This approach has several benefits:

1. **On-demand:** analytical data is immediately available within your application with no additional infrastructure.
2. **Always in sync:** since the data is queried directly from the remote server, it's always up-to-date.
3. **Integrated:** large datasets are available within your application, and can be joined with your operational/transactional data.
4. **Save on bandwidth:** only extract/load what you need.

### Batch ETL with Wrappers [\#](https://supabase.com/docs/guides/database/extensions/wrappers/overview\#batch-etl-with-wrappers)

A common use case for Wrappers is to extract data from a production database and load it into a data warehouse. This can be done within your database using [pg\_cron](https://supabase.com/docs/guides/database/extensions/pg_cron). For example, you can schedule a job to run every night to extract data from your production database and load it into your data warehouse.

`
-- Every day at 3am, copy data from your
-- production database to your data warehouse:
select cron.schedule(
'nightly-etl',
'0 3 * * *',
$$
    insert into warehouse.analytics
    select * from public.analytics
    where ts > (now() - interval '1 DAY');
$$
);
`

![FDW with pg_cron](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fdatabase%2Fforeign-data-wrappers%2Fextracting-data-pgcron--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

This process can be taxing on your database if you are moving large amounts of data. Often, it's better to use an external tool for batch ETL, such as [Fivetran](https://fivetran.com/) or [Airbyte](https://airbyte.io/).

### WebAssembly Wrappers [\#](https://supabase.com/docs/guides/database/extensions/wrappers/overview\#webassembly-wrappers)

WebAssembly (Wasm) is a binary instruction format that enables high-performance execution of code on the web. Wrappers now includes a Wasm runtime, which provides a sandboxed execution environment, to run Wasm foreign data wrappers. Combined Wrappers with Wasm, developing and distributing new FDW becomes much easier and you can even build your own Wasm FDW and use it on Supabase platform.

To learn more about Wasm FDW, visit [Wrappers official documentation](https://supabase.github.io/wrappers/).

## Security [\#](https://supabase.com/docs/guides/database/extensions/wrappers/overview\#security)

Foreign Data Wrappers do not provide Row Level Security, thus it is not advised to expose them via your API. Wrappers should _always_ be stored in a private schema. For example, if you are connecting to your Stripe account, you should create a `stripe` schema to store all of your foreign tables inside. This schema should _not_ be added to the Additional Schemas setting in the API section.

If you want to expose any of the foreign table columns to your public API, you can create a [Database Function with security definer](https://supabase.com/docs/guides/database/functions#security-definer-vs-invoker) in the `public` schema, and then you can interact with your foreign table through API. For better access control, the function should have appropriate filters on the foreign table to apply security rules based on your business needs.

As an example, go to [SQL Editor](https://supabase.com/dashboard/project/_/sql/new) and then follow below steps,

1. Create a Stripe Products foreign table:



`
create foreign table stripe.stripe_products (
id text,
name text,
active bool,
default_price text,
description text,
created timestamp,
updated timestamp,
attrs jsonb
)
server stripe_fdw_server
options (
       object 'products',
       rowid_column 'id'
);
`

2. Create a security definer function that queries the foreign table and filters on the name prefix parameter:



`
create function public.get_stripe_products(name_prefix text)
returns table (
id text,
name text,
active boolean,
default_price text,
description text
)
language plpgsql
security definer set search_path = ''
as $$
begin
return query
select
       t.id,
       t.name,
       t.active,
       t.default_price,
       t.description
from
       stripe.stripe_products t
where
       t.name like name_prefix || '%'
;
end;
$$;
`

3. Restrict the function execution to a specific role only, for example, the authenticated users:





By default, the function created can be executed by any roles like `anon`, that means the
foreign table is public accessible. Always limit the function execution permission to
appropriate roles.







`
   -- revoke public execute permission
revoke execute on function public.get_stripe_products from public;
revoke execute on function public.get_stripe_products from anon;
   -- grant execute permission to a specific role only
grant execute on function public.get_stripe_products to authenticated;
`


Once the preceding steps are finished, the function can be invoked from Supabase client to query the foreign table:

`
const { data, error } = await supabase
.rpc('get_stripe_products', { name_prefix: 'Test' })
.select('*')
if (error) console.error(error)
else console.log(data)
`

## Resources [\#](https://supabase.com/docs/guides/database/extensions/wrappers/overview\#resources)

- Official [`supabase/wrappers` documentation](https://supabase.github.io/wrappers/)

### Is this helpful?

NoYes

### On this page

[Concepts](https://supabase.com/docs/guides/database/extensions/wrappers/overview#concepts) [Remote servers](https://supabase.com/docs/guides/database/extensions/wrappers/overview#remote-servers) [Foreign tables](https://supabase.com/docs/guides/database/extensions/wrappers/overview#foreign-tables) [ETL with Wrappers](https://supabase.com/docs/guides/database/extensions/wrappers/overview#etl-with-wrappers) [On-demand ETL with Wrappers](https://supabase.com/docs/guides/database/extensions/wrappers/overview#on-demand-etl-with-wrappers) [Batch ETL with Wrappers](https://supabase.com/docs/guides/database/extensions/wrappers/overview#batch-etl-with-wrappers) [WebAssembly Wrappers](https://supabase.com/docs/guides/database/extensions/wrappers/overview#webassembly-wrappers) [Security](https://supabase.com/docs/guides/database/extensions/wrappers/overview#security) [Resources](https://supabase.com/docs/guides/database/extensions/wrappers/overview#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings


![Foreign Data Wrappers (FDW)](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fdatabase%2Fforeign-data-wrappers%2Fextracting-data--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![FDW with pg_cron](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fdatabase%2Fforeign-data-wrappers%2Fextracting-data-pgcron--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)
</file>

<file path="supabase_com_docs_guides_database_extensions.md">
Database

# Postgres Extensions Overview

* * *

Extensions are exactly as they sound - they "extend" the database with functionality which isn't part of the Postgres core.
Supabase has pre-installed some of the most useful open source extensions.

### Enable and disable extensions [\#](https://supabase.com/docs/guides/database/extensions\#enable-and-disable-extensions)

DashboardSQL

1. Go to the [Database](https://supabase.com/dashboard/project/_/database/tables) page in the Dashboard.
2. Click **Extensions** in the sidebar.
3. Enable or disable an extension.

Most extensions are installed under the `extensions` schema, which is accessible to public by default. To avoid namespace pollution, we do not recommend creating other entities in the `extensions` schema.

If you need to restrict user access to tables managed by extensions, we recommend creating a separate schema for installing that specific extension.

Some extensions can only be created under a specific schema, for example, `postgis_tiger_geocoder` extension creates a schema named `tiger`. Before enabling such extensions, make sure you have not created a conflicting schema with the same name.

In addition to the pre-configured extensions, you can also install your own SQL extensions directly in the database using Supabase's SQL editor. The SQL code for the extensions, including plpgsql extensions, can be added through the SQL editor.

### Upgrade extensions [\#](https://supabase.com/docs/guides/database/extensions\#upgrade-extensions)

If a new version of an extension becomes available on Supabase, you need to initiate a software upgrade in the [Infrastructure Settings](https://supabase.com/dashboard/project/_/settings/infrastructure) to access it. Software upgrades can also be initiated by restarting your server in the [General Settings](https://supabase.com/dashboard/project/_/settings/general).

### Full list of extensions [\#](https://supabase.com/docs/guides/database/extensions\#full-list-of-extensions)

Supabase is pre-configured with over 50 extensions. You can also install your own SQL extensions directly in the database through our SQL editor.

Search extensions

### Filter

- AI
- Admin
- Audit
- Cryptography
- Data Type
- Dataset
- Geo
- Index
- Language
- Notifications
- Search
- Testing
- Time Series
- Utility

Reset

[address\_standardizer\\
\\
Used to parse an address into constituent elements. Generally used to support geocoding address normalization step.](https://postgis.net/docs/manual-2.5/Address_Standardizer.html) [address\_standardizer\_data\_us\\
\\
Address Standardizer US dataset example](https://postgis.net/docs/manual-2.5/Address_Standardizer.html) [amcheck\\
\\
Functions for verifying relation integrity](https://www.postgresql.org/docs/current/amcheck.html) [autoinc\\
\\
Functions for autoincrementing fields](https://www.postgresql.org/docs/current/contrib-spi.html#id-1.11.7.50.6) [bloom\\
\\
Bloom access method - signature file based index](https://www.postgresql.org/docs/current/bloom.html) [btree\_gin\\
\\
Support for indexing common datatypes in GIN](https://www.postgresql.org/docs/current/btree-gin.html) [btree\_gist\\
\\
Support for indexing common datatypes in GiST](https://www.postgresql.org/docs/current/btree-gist.html) [citext\\
\\
Data type for case-insensitive character strings](https://www.postgresql.org/docs/current/citext.html) [cube\\
\\
Data type for multidimensional cubes](https://www.postgresql.org/docs/current/cube.html) [dblink\\
\\
Connect to other PostgreSQL databases from within a database](https://www.postgresql.org/docs/current/contrib-dblink-function.html) [dict\_int\\
\\
Text search dictionary template for integers](https://www.postgresql.org/docs/current/dict-int.html) [dict\_xsyn\\
\\
Text search dictionary template for extended synonym processing](https://www.postgresql.org/docs/current/dict-xsyn.html) [earthdistance\\
\\
Calculate great-circle distances on the surface of the Earth](https://www.postgresql.org/docs/current/earthdistance.html) [fuzzystrmatch\\
\\
Determine similarities and distance between strings](https://www.postgresql.org/docs/current/fuzzystrmatch.html) [hstore\\
\\
Data type for storing sets of (key, value) pairs](https://www.postgresql.org/docs/current/hstore.html) [hypopg\\
\\
Hypothetical indexes for PostgreSQL](https://supabase.com/docs/guides/database/extensions/hypopg) [http\\
\\
HTTP client for PostgreSQL, allows web page retrieval inside the database.](https://supabase.com/docs/guides/database/extensions/http) [insert\_username\\
\\
Functions for tracking who changed a table](https://www.postgresql.org/docs/current/contrib-spi.html#id-1.11.7.50.7) [old\_snapshot\\
\\
Utilities in support of old\_snapshot\_threshold](https://www.postgresql.org/docs/current/oldsnapshot.html) [index\_advisor\\
\\
Optimize query performance with automatic index recommendation](https://supabase.com/docs/guides/database/extensions/index_advisor) [intarray\\
\\
Functions, operators, and index support for 1-D arrays of integers](https://www.postgresql.org/docs/current/intarray.html) [isn\\
\\
Data types for international product numbering standards](https://www.postgresql.org/docs/current/isn.html) [lo\\
\\
Large Object maintenance](https://www.postgresql.org/docs/current/lo.html) [ltree\\
\\
Data type for hierarchical tree-like structures](https://www.postgresql.org/docs/current/ltree.html) [moddatetime\\
\\
Functions for tracking last modification time](https://www.postgresql.org/docs/current/contrib-spi.html#id-1.11.7.50.8) [pg\_cron\\
\\
Job scheduler for PostgreSQL](https://supabase.com/docs/guides/database/extensions/pg_cron) [pg\_freespacemap\\
\\
Examine the free space map (FSM)](https://www.postgresql.org/docs/current/pgfreespacemap.html) [pg\_graphql\\
\\
Pg\_graphql: GraphQL support](https://supabase.com/docs/guides/database/extensions/pg_graphql) [pg\_hashids\\
\\
Pg\_hashids](https://supabase.com/docs/guides/database/extensions/pg_hashids) [pg\_jsonschema\\
\\
Pg\_jsonschema](https://supabase.com/docs/guides/database/extensions/pg_jsonschema) [pg\_net\\
\\
Async HTTP](https://supabase.com/docs/guides/database/extensions/pg_net) [pg\_prewarm\\
\\
Prewarm relation data](https://www.postgresql.org/docs/current/pgprewarm.html) [pg\_stat\_statements\\
\\
Track execution statistics of all SQL statements executed](https://supabase.com/docs/guides/database/extensions/pg_stat_statements) [pg\_surgery\\
\\
Extension to perform surgery on a damaged relation](https://www.postgresql.org/docs/current/pgsurgery.html) [pg\_trgm\\
\\
Text similarity measurement and index searching based on trigrams](https://www.postgresql.org/docs/current/pgtrgm.html) [pgaudit\\
\\
Provides auditing functionality](https://supabase.com/docs/guides/database/extensions/pgaudit) [pg\_walinspect\\
\\
Functions to inspect contents of PostgreSQL Write-Ahead Log](https://www.postgresql.org/docs/current/pgwalinspect.html) [pgcrypto\\
\\
Cryptographic functions](https://www.postgresql.org/docs/current/pgcrypto.html) [pgjwt\\
\\
JSON Web Token API for Postgresql](https://supabase.com/docs/guides/database/extensions/pgjwt) [pgroonga\\
\\
Super fast and all languages supported full text search index based on Groonga](https://supabase.com/docs/guides/database/extensions/pgroonga) [pgroonga\_database\\
\\
PGroonga database management module](https://pgroonga.github.io/reference/modules/pgroonga-database.html) [pgrouting\\
\\
PgRouting Extension](https://supabase.com/docs/guides/database/extensions/pgrouting) [pgrowlocks\\
\\
Show row-level locking information](https://www.postgresql.org/docs/current/pgrowlocks.html) [pgsodium\\
\\
Postgres extension for libsodium functions](https://supabase.com/docs/guides/database/extensions/pgsodium) [pgstattuple\\
\\
Show tuple-level statistics](https://www.postgresql.org/docs/current/pgstattuple.html) [pgtap\\
\\
Unit testing for PostgreSQL](https://supabase.com/docs/guides/database/extensions/pgtap) [plcoffee\\
\\
PL/CoffeeScript (v8) trusted procedural language](https://github.com/plv8/plv8/blob/master/doc/plv8.md#coffeescript-extension) [pljava\\
\\
PL/Java procedural language (https://tada.github.io/pljava/)](https://tada.github.io/pljava/) [plls\\
\\
PL/LiveScript (v8) trusted procedural language](https://github.com/plv8/plv8/blob/master/doc/plv8.md#livescript-extension) [plpgsql\\
\\
PL/pgSQL procedural language](https://www.postgresql.org/docs/current/plpgsql.html) [plpgsql\_check\\
\\
Extended check for plpgsql functions](https://supabase.com/docs/guides/database/extensions/plpgsql_check) [plv8\\
\\
PL/JavaScript (v8) trusted procedural language](https://supabase.com/docs/guides/database/extensions/plv8) [postgis\\
\\
PostGIS geometry and geography spatial types and functions](https://supabase.com/docs/guides/database/extensions/postgis) [postgres\_fdw\\
\\
Foreign-data wrapper for remote PostgreSQL servers](https://supabase.com/docs/guides/database/extensions/postgres_fdw) [refint\\
\\
Functions for implementing referential integrity (obsolete)](https://www.postgresql.org/docs/current/contrib-spi.html#id-1.11.7.50.5) [rum\\
\\
GIN-like index for text search](https://supabase.com/docs/guides/database/extensions/rum) [seg\\
\\
Data type for representing line segments or floating-point intervals](https://www.postgresql.org/docs/current/seg.html) [sslinfo\\
\\
Information about SSL certificates](https://www.postgresql.org/docs/current/sslinfo.html) [tablefunc\\
\\
Functions that manipulate whole tables, including crosstab](https://www.postgresql.org/docs/current/tablefunc.html) [tcn\\
\\
Triggered change notifications](https://www.postgresql.org/docs/current/tcn.html) [timescaledb\\
\\
Enables scalable inserts and complex queries for time-series data](https://supabase.com/docs/guides/database/extensions/timescaledb) [tsm\_system\_rows\\
\\
TABLESAMPLE method which accepts number of rows as a limit](https://www.postgresql.org/docs/current/tsm-system-rows.html) [tsm\_system\_time\\
\\
TABLESAMPLE method which accepts time in milliseconds as a limit](https://www.postgresql.org/docs/current/tsm-system-time.html) [unaccent\\
\\
Text search dictionary that removes accents](https://www.postgresql.org/docs/current/unaccent.html) [uuid-ossp\\
\\
Generate universally unique identifiers (UUIDs)](https://supabase.com/docs/guides/database/extensions/uuid-ossp) [vector\\
\\
Vector data type with similarity search](https://supabase.com/docs/guides/database/extensions/pgvector) [pg\_repack\\
\\
Optimize physical storage and remove bloat from tables and indexes](https://supabase.com/docs/guides/database/extensions/pg_repack) [wrappers\\
\\
Foreign data wrappers developed by Supabase](https://supabase.com/docs/guides/database/extensions/wrappers/overview)

### Is this helpful?

NoYes

### On this page

[Enable and disable extensions](https://supabase.com/docs/guides/database/extensions#enable-and-disable-extensions) [Upgrade extensions](https://supabase.com/docs/guides/database/extensions#upgrade-extensions) [Full list of extensions](https://supabase.com/docs/guides/database/extensions#full-list-of-extensions)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_full_text_search.md">
Database

# Full Text Search

## How to use full text search in PostgreSQL.

* * *

Postgres has built-in functions to handle `Full Text Search` queries. This is like a "search engine" within Postgres.

How to use textSearch to perform full text search - SupabaseTips - YouTube

Supabase

45.5K subscribers

[How to use textSearch to perform full text search - SupabaseTips](https://www.youtube.com/watch?v=b-mgca_2Oe4)

Supabase

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=b-mgca_2Oe4 "Watch on YouTube")

## Preparation [\#](https://supabase.com/docs/guides/database/full-text-search\#preparation)

For this guide we'll use the following example data:

DataSQL

| id | title | author | description |
| --- | --- | --- | --- |
| 1 | The Poky Little Puppy | Janette Sebring Lowrey | Puppy is slower than other, bigger animals. |
| 2 | The Tale of Peter Rabbit | Beatrix Potter | Rabbit eats some vegetables. |
| 3 | Tootle | Gertrude Crampton | Little toy train has big dreams. |
| 4 | Green Eggs and Ham | Dr. Seuss | Sam has changing food preferences and eats unusually colored food. |
| 5 | Harry Potter and the Goblet of Fire | J.K. Rowling | Fourth year of school starts, big drama ensues. |

## Usage [\#](https://supabase.com/docs/guides/database/full-text-search\#usage)

The functions we'll cover in this guide are:

### `to_tsvector()` [\#](https://supabase.com/docs/guides/database/full-text-search\#to-tsvector)

Converts your data into searchable tokens. `to_tsvector()` stands for "to text search vector." For example:

`
select to_tsvector('green eggs and ham');
-- Returns 'egg':2 'green':1 'ham':4
`

Collectively these tokens are called a "document" which Postgres can use for comparisons.

### `to_tsquery()` [\#](https://supabase.com/docs/guides/database/full-text-search\#to-tsquery)

Converts a query string into tokens to match. `to_tsquery()` stands for "to text search query."

This conversion step is important because we will want to "fuzzy match" on keywords.
For example if a user searches for `eggs`, and a column has the value `egg`, we probably still want to return a match.

### Match: `@@` [\#](https://supabase.com/docs/guides/database/full-text-search\#match)

The `@@` symbol is the "match" symbol for Full Text Search. It returns any matches between a `to_tsvector` result and a `to_tsquery` result.

Take the following example:

SQLJavaScriptDartSwiftKotlinPython

`
select *
from books
where title = 'Harry';
`

The equality symbol above ( `=`) is very "strict" on what it matches. In a full text search context, we might want to find all "Harry Potter" books and so we can rewrite the
example above:

SQLJavaScriptDartSwiftKotlin

`
select *
from books
where to_tsvector(title) @@ to_tsquery('Harry');
`

## Basic full text queries [\#](https://supabase.com/docs/guides/database/full-text-search\#basic-full-text-queries)

### Search a single column [\#](https://supabase.com/docs/guides/database/full-text-search\#search-a-single-column)

To find all `books` where the `description` contain the word `big`:

SQLJavaScriptDartSwiftKotlinPythonData

`
select
*
from
books
where
to_tsvector(description)
@@ to_tsquery('big');
`

### Search multiple columns [\#](https://supabase.com/docs/guides/database/full-text-search\#search-multiple-columns)

Right now there is no direct way to use JavaScript or Dart to search through multiple columns but you can do it by creating [computed columns](https://postgrest.org/en/stable/api.html#computed-virtual-columns) on the database.

To find all `books` where `description` or `title` contain the word `little`:

SQLJavaScriptDartSwiftKotlinPythonData

`
select
*
from
books
where
to_tsvector(description || ' ' || title) -- concat columns, but be sure to include a space to separate them!
@@ to_tsquery('little');
`

### Match all search words [\#](https://supabase.com/docs/guides/database/full-text-search\#match-all-search-words)

To find all `books` where `description` contains BOTH of the words `little` and `big`, we can use the `&` symbol:

SQLJavaScriptDartSwiftKotlinPythonData

`
select
*
from
books
where
to_tsvector(description)
@@ to_tsquery('little & big'); -- use & for AND in the search query
`

### Match any search words [\#](https://supabase.com/docs/guides/database/full-text-search\#match-any-search-words)

To find all `books` where `description` contain ANY of the words `little` or `big`, use the `|` symbol:

SQLJavaScriptDartSwiftKotlinPythonData

`
select
*
from
books
where
to_tsvector(description)
@@ to_tsquery('little | big'); -- use | for OR in the search query
`

Notice how searching for `big` includes results with the word `bigger` (or `biggest`, etc).

## Partial search [\#](https://supabase.com/docs/guides/database/full-text-search\#partial-search)

Partial search is particularly useful when you want to find matches on substrings within your data.

### Implementing partial search [\#](https://supabase.com/docs/guides/database/full-text-search\#implementing-partial-search)

You can use the `:*` syntax with `to_tsquery()`. Here's an example that searches for any book titles beginning with "Lit":

`
select title from books where to_tsvector(title) @@ to_tsquery('Lit:*');
`

### Extending functionality with RPC [\#](https://supabase.com/docs/guides/database/full-text-search\#extending-functionality-with-rpc)

To make the partial search functionality accessible through the API, you can wrap the search logic in a stored procedure.

After creating this function, you can invoke it from your application using the SDK for your platform. Here's an example:

SQLJavaScriptDartSwiftKotlinPython

`
create or replace function search_books_by_title_prefix(prefix text)
returns setof books AS $$
begin
return query
select * from books where to_tsvector('english', title) @@ to_tsquery(prefix || ':*');
end;
$$ language plpgsql;
`

This function takes a prefix parameter and returns all books where the title contains a word starting with that prefix. The `:*` operator is used to denote a prefix match in the `to_tsquery()` function.

## Handling spaces in queries [\#](https://supabase.com/docs/guides/database/full-text-search\#handling-spaces-in-queries)

When you want the search term to include a phrase or multiple words, you can concatenate words using a `+` as a placeholder for space:

`
select * from search_books_by_title_prefix('Little+Puppy');
`

## Creating indexes [\#](https://supabase.com/docs/guides/database/full-text-search\#creating-indexes)

Now that we have Full Text Search working, let's create an `index`. This will allow Postgres to "build" the documents preemptively so that they
don't need to be created at the time we execute the query. This will make our queries much faster.

### Searchable columns [\#](https://supabase.com/docs/guides/database/full-text-search\#searchable-columns)

Let's create a new column `fts` inside the `books` table to store the searchable index of the `title` and `description` columns.

We can use a special feature of Postgres called
[Generated Columns](https://www.postgresql.org/docs/current/ddl-generated-columns.html)
to ensure that the index is updated any time the values in the `title` and `description` columns change.

SQLData

`
alter table
books
add column
fts tsvector generated always as (to_tsvector('english', description || ' ' || title)) stored;
create index books_fts on books using gin (fts); -- generate the index
select id, fts
from books;
`

### Search using the new column [\#](https://supabase.com/docs/guides/database/full-text-search\#search-using-the-new-column)

Now that we've created and populated our index, we can search it using the same techniques as before:

SQLJavaScriptDartSwiftKotlinPythonData

`
select
*
from
books
where
fts @@ to_tsquery('little & big');
`

## Query operators [\#](https://supabase.com/docs/guides/database/full-text-search\#query-operators)

Visit [Postgres: Text Search Functions and Operators](https://www.postgresql.org/docs/current/functions-textsearch.html)
to learn about additional query operators you can use to do more advanced `full text queries`, such as:

### Proximity: `<->` [\#](https://supabase.com/docs/guides/database/full-text-search\#proximity)

The proximity symbol is useful for searching for terms that are a certain "distance" apart.
For example, to find the phrase `big dreams`, where the a match for "big" is followed immediately by a match for "dreams":

SQLJavaScriptDartSwiftKotlinPython

`
select
*
from
books
where
to_tsvector(description) @@ to_tsquery('big <-> dreams');
`

We can also use the `<->` to find words within a certain distance of each other. For example to find `year` and `school` within 2 words of each other:

SQLJavaScriptDartSwiftKotlinPython

`
select
*
from
books
where
to_tsvector(description) @@ to_tsquery('year <2> school');
`

### Negation: `!` [\#](https://supabase.com/docs/guides/database/full-text-search\#negation)

The negation symbol can be used to find phrases which _don't_ contain a search term.
For example, to find records that have the word `big` but not `little`:

SQLJavaScriptDartSwiftKotlinPython

`
select
*
from
books
where
to_tsvector(description) @@ to_tsquery('big & !little');
`

## Resources [\#](https://supabase.com/docs/guides/database/full-text-search\#resources)

- [Postgres: Text Search Functions and Operators](https://www.postgresql.org/docs/12/functions-textsearch.html)

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2Fb-mgca_2Oe4%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Preparation](https://supabase.com/docs/guides/database/full-text-search#preparation) [Usage](https://supabase.com/docs/guides/database/full-text-search#usage) [to\_tsvector()](https://supabase.com/docs/guides/database/full-text-search#to-tsvector) [to\_tsquery()](https://supabase.com/docs/guides/database/full-text-search#to-tsquery) [Match: @@](https://supabase.com/docs/guides/database/full-text-search#match) [Basic full text queries](https://supabase.com/docs/guides/database/full-text-search#basic-full-text-queries) [Search a single column](https://supabase.com/docs/guides/database/full-text-search#search-a-single-column) [Search multiple columns](https://supabase.com/docs/guides/database/full-text-search#search-multiple-columns) [Match all search words](https://supabase.com/docs/guides/database/full-text-search#match-all-search-words) [Match any search words](https://supabase.com/docs/guides/database/full-text-search#match-any-search-words) [Partial search](https://supabase.com/docs/guides/database/full-text-search#partial-search) [Implementing partial search](https://supabase.com/docs/guides/database/full-text-search#implementing-partial-search) [Extending functionality with RPC](https://supabase.com/docs/guides/database/full-text-search#extending-functionality-with-rpc) [Handling spaces in queries](https://supabase.com/docs/guides/database/full-text-search#handling-spaces-in-queries) [Creating indexes](https://supabase.com/docs/guides/database/full-text-search#creating-indexes) [Searchable columns](https://supabase.com/docs/guides/database/full-text-search#searchable-columns) [Search using the new column](https://supabase.com/docs/guides/database/full-text-search#search-using-the-new-column) [Query operators](https://supabase.com/docs/guides/database/full-text-search#query-operators) [Proximity: <->](https://supabase.com/docs/guides/database/full-text-search#proximity) [Negation: !](https://supabase.com/docs/guides/database/full-text-search#negation) [Resources](https://supabase.com/docs/guides/database/full-text-search#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_functions.md">
Database

# Database Functions

* * *

Postgres has built-in support for [SQL functions](https://www.postgresql.org/docs/current/sql-createfunction.html).
These functions live inside your database, and they can be [used with the API](https://supabase.com/docs/reference/javascript/rpc).

## Quick demo [\#](https://supabase.com/docs/guides/database/functions\#quick-demo)

Create PostgreSQL Functions with Supabase - YouTube

Supabase

45.5K subscribers

[Create PostgreSQL Functions with Supabase](https://www.youtube.com/watch?v=MJZCCpCYEqk)

Supabase

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=MJZCCpCYEqk "Watch on YouTube")

## Getting started [\#](https://supabase.com/docs/guides/database/functions\#getting-started)

Supabase provides several options for creating database functions. You can use the Dashboard or create them directly using SQL.
We provide a SQL editor within the Dashboard, or you can [connect](https://supabase.com/docs/guides/database/connecting-to-postgres) to your database
and run the SQL queries yourself.

1. Go to the "SQL editor" section.
2. Click "New Query".
3. Enter the SQL to create or replace your Database function.
4. Click "Run" or cmd+enter (ctrl+enter).

## Simple functions [\#](https://supabase.com/docs/guides/database/functions\#simple-functions)

Let's create a basic Database Function which returns a string "hello world".

`
create or replace function hello_world() -- 1
returns text -- 2
language sql -- 3
as $$  -- 4
select 'hello world';  -- 5
$$; --6
`

Show/Hide Details

At it's most basic a function has the following parts:

1. `create or replace function hello_world()`: The function declaration, where `hello_world` is the name of the function. You can use either `create` when creating a new function or `replace` when replacing an existing function. Or you can use `create or replace` together to handle either.
2. `returns text`: The type of data that the function returns. If it returns nothing, you can `returns void`.
3. `language sql`: The language used inside the function body. This can also be a procedural language: `plpgsql`, `plv8`, `plpython`, etc.
4. `as $$`: The function wrapper. Anything enclosed inside the `$$` symbols will be part of the function body.
5. `select 'hello world';`: A simple function body. The final `select` statement inside a function body will be returned if there are no statements following it.
6. `$$;`: The closing symbols of the function wrapper.

After the Function is created, we have several ways of "executing" the function - either directly inside the database using SQL, or with one of the client libraries.

SQLJavaScriptDartSwiftKotlinPython

`
select hello_world();
`

## Returning data sets [\#](https://supabase.com/docs/guides/database/functions\#returning-data-sets)

Database Functions can also return data sets from [Tables](https://supabase.com/docs/guides/database/tables) or Views.

For example, if we had a database with some Star Wars data inside:

DataSQL

#### Planets

`
| id  | name     |
| --- | -------- |
| 1   | Tatooine |
| 2   | Alderaan |
| 3   | Kashyyyk |
`

#### People

`
| id  | name             | planet_id |
| --- | ---------------- | --------- |
| 1   | Anakin Skywalker | 1         |
| 2   | Luke Skywalker   | 1         |
| 3   | Princess Leia    | 2         |
| 4   | Chewbacca        | 3         |
`

We could create a function which returns all the planets:

`
create or replace function get_planets()
returns setof planets
language sql
as $$
select * from planets;
$$;
`

Because this function returns a table set, we can also apply filters and selectors. For example, if we only wanted the first planet:

SQLJavaScriptDartSwiftKotlinPython

`
select *
from get_planets()
where id = 1;
`

## Passing parameters [\#](https://supabase.com/docs/guides/database/functions\#passing-parameters)

Let's create a Function to insert a new planet into the `planets` table and return the new ID. Note that this time we're using the `plpgsql` language.

`
create or replace function add_planet(name text)
returns bigint
language plpgsql
as $$
declare
new_row bigint;
begin
insert into planets(name)
values (add_planet.name)
returning id into new_row;
return new_row;
end;
$$;
`

Once again, you can execute this function either inside your database using a `select` query, or with the client libraries:

SQLJavaScriptDartSwiftKotlinPython

`
select * from add_planet('Jakku');
`

## Suggestions [\#](https://supabase.com/docs/guides/database/functions\#suggestions)

### Database Functions vs Edge Functions [\#](https://supabase.com/docs/guides/database/functions\#database-functions-vs-edge-functions)

For data-intensive operations, use Database Functions, which are executed within your database
and can be called remotely using the [REST and GraphQL API](https://supabase.com/docs/guides/api).

For use-cases which require low-latency, use [Edge Functions](https://supabase.com/docs/guides/functions), which are globally-distributed and can be written in Typescript.

### Security `definer` vs `invoker` [\#](https://supabase.com/docs/guides/database/functions\#security-definer-vs-invoker)

Postgres allows you to specify whether you want the function to be executed as the user _calling_ the function ( `invoker`), or as the _creator_ of the function ( `definer`). For example:

`
create function hello_world()
returns text
language plpgsql
security definer set search_path = ''
as $$
begin
select 'hello world';
end;
$$;
`

It is best practice to use `security invoker` (which is also the default). If you ever use `security definer`, you _must_ set the `search_path`.
This limits the potential damage if you allow access to schemas which the user executing the function should not have.

### Function privileges [\#](https://supabase.com/docs/guides/database/functions\#function-privileges)

By default, database functions can be executed by any role. There are two main ways to restrict this:

1. On a case-by-case basis. Specifically revoke permissions for functions you want to protect. Execution needs to be revoked for both `public` and the role you're restricting:



`
revoke execute on function public.hello_world from public;
revoke execute on function public.hello_world from anon;
`

2. Restrict function execution by default. Specifically _grant_ access when you want a function to be executable by a specific role.

To restrict all existing functions, revoke execution permissions from both `public` _and_ the role you want to restrict:



`
revoke execute on all functions in schema public from public;
revoke execute on all functions in schema public from anon, authenticated;
`



To restrict all new functions, change the default privileges for both `public` _and_ the role you want to restrict:



`
alter default privileges in schema public revoke execute on functions from public;
alter default privileges in schema public revoke execute on functions from anon, authenticated;
`



You can then regrant permissions for a specific function to a specific role:



`
grant execute on function public.hello_world to authenticated;
`


### Debugging functions [\#](https://supabase.com/docs/guides/database/functions\#debugging-functions)

You can add logs to help you debug functions. This is especially recommended for complex functions.

Good targets to log include:

- Values of (non-sensitive) variables
- Returned results from queries

#### General logging [\#](https://supabase.com/docs/guides/database/functions\#general-logging)

To create custom logs in the [Dashboard's Postgres Logs](https://supabase.com/dashboard/project/_/logs/postgres-logs), you can use the `raise` keyword. By default, there are 3 observed severity levels:

- `log`
- `warning`
- `exception` (error level)

`
create function logging_example(
log_message text,
warning_message text,
error_message text
)
returns void
language plpgsql
as $$
begin
raise log 'logging message: %', log_message;
raise warning 'logging warning: %', warning_message;
  -- immediately ends function and reverts transaction
raise exception 'logging error: %', error_message;
end;
$$;
select logging_example('LOGGED MESSAGE', 'WARNING MESSAGE', 'ERROR MESSAGE');
`

#### Error handling [\#](https://supabase.com/docs/guides/database/functions\#error-handling)

You can create custom errors with the `raise exception` keywords.

A common pattern is to throw an error when a variable doesn't meet a condition:

`
create or replace function error_if_null(some_val text)
returns text
language plpgsql
as $$
begin
  -- error if some_val is null
if some_val is null then
    raise exception 'some_val should not be NULL';
end if;
  -- return some_val if it is not null
return some_val;
end;
$$;
select error_if_null(null);
`

Value checking is common, so Postgres provides a shorthand: the `assert` keyword. It uses the following format:

`
-- throw error when condition is false
assert <some condition>, 'message';
`

Below is an example

`
create function assert_example(name text)
returns uuid
language plpgsql
as $$
declare
student_id uuid;
begin
  -- save a user's id into the user_id variable
select
    id into student_id
from attendance_table
where student = name;
  -- throw an error if the student_id is null
assert student_id is not null, 'assert_example() ERROR: student not found';
  -- otherwise, return the user's id
return student_id;
end;
$$;
select assert_example('Harry Potter');
`

Error messages can also be captured and modified with the `exception` keyword:

`
create function error_example()
returns void
language plpgsql
as $$
begin
  -- fails: cannot read from nonexistent table
select * from table_that_does_not_exist;
exception
      when others then
          raise exception 'An error occurred in function <function name>: %', sqlerrm;
end;
$$;
`

#### Advanced logging [\#](https://supabase.com/docs/guides/database/functions\#advanced-logging)

For more complex functions or complicated debugging, try logging:

- Formatted variables
- Individual rows
- Start and end of function calls

`
create or replace function advanced_example(num int default 10)
returns text
language plpgsql
as $$
declare
    var1 int := 20;
    var2 text;
begin
    -- Logging start of function
    raise log 'logging start of function call: (%)', (select now());
    -- Logging a variable from a SELECT query
    select
      col_1 into var1
    from some_table
    limit 1;
    raise log 'logging a variable (%)', var1;
    -- It is also possible to avoid using variables, by returning the values of your query to the log
    raise log 'logging a query with a single return value(%)', (select col_1 from some_table limit 1);
    -- If necessary, you can even log an entire row as JSON
    raise log 'logging an entire row as JSON (%)', (select to_jsonb(some_table.*) from some_table limit 1);
    -- When using INSERT or UPDATE, the new value(s) can be returned
    -- into a variable.
    -- When using DELETE, the deleted value(s) can be returned.
    -- All three operations use "RETURNING value(s) INTO variable(s)" syntax
    insert into some_table (col_2)
    values ('new val')
    returning col_2 into var2;
    raise log 'logging a value from an INSERT (%)', var2;
    return var1 || ',' || var2;
exception
    -- Handle exceptions here if needed
    when others then
        raise exception 'An error occurred in function <advanced_example>: %', sqlerrm;
end;
$$;
select advanced_example();
`

## Resources [\#](https://supabase.com/docs/guides/database/functions\#resources)

- Official Client libraries: [JavaScript](https://supabase.com/docs/reference/javascript/rpc) and [Flutter](https://supabase.com/docs/reference/dart/rpc)
- Community client libraries: [github.com/supabase-community](https://github.com/supabase-community)
- Postgres Official Docs: [Chapter 9. Functions and Operators](https://www.postgresql.org/docs/current/functions.html)
- Postgres Reference: [CREATE FUNCTION](https://www.postgresql.org/docs/9.1/sql-createfunction.html)

## Deep dive [\#](https://supabase.com/docs/guides/database/functions\#deep-dive)

### Create Database Functions [\#](https://supabase.com/docs/guides/database/functions\#create-database-functions)

Create PostgreSQL Functions with Supabase - YouTube

Supabase

45.5K subscribers

[Create PostgreSQL Functions with Supabase](https://www.youtube.com/watch?v=MJZCCpCYEqk)

Supabase

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=MJZCCpCYEqk "Watch on YouTube")

### Call Database Functions using JavaScript [\#](https://supabase.com/docs/guides/database/functions\#call-database-functions-using-javascript)

Call Postgres functions from JavaScript with RPC - YouTube

Supabase

45.5K subscribers

[Call Postgres functions from JavaScript with RPC](https://www.youtube.com/watch?v=I6nnp9AINJk)

Supabase

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=I6nnp9AINJk "Watch on YouTube")

### Using Database Functions to call an external API [\#](https://supabase.com/docs/guides/database/functions\#using-database-functions-to-call-an-external-api)

Using PostgreSQL functions to call an API with Supabase - YouTube

Supabase

45.5K subscribers

[Using PostgreSQL functions to call an API with Supabase](https://www.youtube.com/watch?v=rARgrELRCwY)

Supabase

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=rARgrELRCwY "Watch on YouTube")

### Is this helpful?

NoYes

### On this page

[Quick demo](https://supabase.com/docs/guides/database/functions#quick-demo) [Getting started](https://supabase.com/docs/guides/database/functions#getting-started) [Simple functions](https://supabase.com/docs/guides/database/functions#simple-functions) [Returning data sets](https://supabase.com/docs/guides/database/functions#returning-data-sets) [Passing parameters](https://supabase.com/docs/guides/database/functions#passing-parameters) [Suggestions](https://supabase.com/docs/guides/database/functions#suggestions) [Database Functions vs Edge Functions](https://supabase.com/docs/guides/database/functions#database-functions-vs-edge-functions) [Security definer vs invoker](https://supabase.com/docs/guides/database/functions#security-definer-vs-invoker) [Function privileges](https://supabase.com/docs/guides/database/functions#function-privileges) [Debugging functions](https://supabase.com/docs/guides/database/functions#debugging-functions) [Resources](https://supabase.com/docs/guides/database/functions#resources) [Deep dive](https://supabase.com/docs/guides/database/functions#deep-dive) [Create Database Functions](https://supabase.com/docs/guides/database/functions#create-database-functions) [Call Database Functions using JavaScript](https://supabase.com/docs/guides/database/functions#call-database-functions-using-javascript) [Using Database Functions to call an external API](https://supabase.com/docs/guides/database/functions#using-database-functions-to-call-an-external-api)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_hardening_data_api.md">
Database

# Hardening the Data API

* * *

Your database's automatically generated Data API exposes the `public` schema by default. If your `public` schema is used by other tools as a default space, you might want to lock down this schema. This helps prevent accidental exposure of data that's automatically added to `public`.

There are two levels of security hardening for the Data API:

- Disabling the Data API entirely. This is recommended if you _never_ need to access your database via Supabase client libraries or the REST and GraphQL endpoints.
- Removing the `public` schema from the Data API and replacing it with a custom schema (such as `api`).

## Disabling the Data API [\#](https://supabase.com/docs/guides/database/hardening-data-api\#disabling-the-data-api)

You can disable the Data API entirely if you never intend to use the Supabase client libraries or the REST and GraphQL data endpoints. For example, if you only access your database via a direct connection on the server, disabling the Data API gives you the greatest layer of protection.

1. Go to [API Settings](https://supabase.com/dashboard/project/_/settings/api) in the Supabase Dashboard.
2. Under **Data API Settings**, toggle **Enable Data API** off.

## Exposing a custom schema instead of `public` [\#](https://supabase.com/docs/guides/database/hardening-data-api\#exposing-a-custom-schema-instead-of-public)

If you want to use the Data API but with increased security, you can expose a custom schema instead of `public`. By not using `public`, which is often used as a default space and has laxer default permissions, you get more conscious control over your exposed data.

Any data, views, or functions that should be exposed need to be deliberately put within your custom schema (which we will call `api`), rather than ending up there by default.

### Step 1: Remove `public` from exposed schemas [\#](https://supabase.com/docs/guides/database/hardening-data-api\#step-1-remove-public-from-exposed-schemas)

1. Go to [**API Settings**](https://supabase.com/dashboard/project/_/settings/api) in the Supabase Dashboard.
2. Under **Data API Settings**, remove `public` from **Exposed schemas**. Also remove `public` from **Extra search path**.
3. Click **Save**.
4. Go to [**Database Extensions**](https://supabase.com/dashboard/project/_/database/extensions) and disable the `pg_graphql` extension.

### Step 2: Create an `api` schema and expose it [\#](https://supabase.com/docs/guides/database/hardening-data-api\#step-2-create-an-api-schema-and-expose-it)

1. Connect to your database. You can use `psql`, the [Supabase SQL Editor](https://supabase.com/dashboard/project/_/sql), or the Postgres client of your choice.

2. Create a new schema named `api`:



`
create schema if not exists api;
`

3. Grant the `anon` and `authenticated` roles usage on this schema.



`
grant usage on schema api to anon, authenticated;
`

4. Go to [API Settings](https://supabase.com/dashboard/project/_/settings/api) in the Supabase Dashboard.

5. Under **Data API Settings**, add `api` to **Exposed schemas**. Make sure it is the first schema in the list, so that it will be searched first by default.

6. Under these new settings, `anon` and `authenticated` can execute functions defined in the `api` schema, but they have no automatic permissions on any tables. On a table-by-table basis, you can grant them permissions. For example:



`
grant select on table api.<your_table> to anon;
grant select, insert, update, delete on table api.<your_table> to authenticated;
`


### Is this helpful?

NoYes

### On this page

[Disabling the Data API](https://supabase.com/docs/guides/database/hardening-data-api#disabling-the-data-api) [Exposing a custom schema instead of public](https://supabase.com/docs/guides/database/hardening-data-api#exposing-a-custom-schema-instead-of-public) [Step 1: Remove public from exposed schemas](https://supabase.com/docs/guides/database/hardening-data-api#step-1-remove-public-from-exposed-schemas) [Step 2: Create an api schema and expose it](https://supabase.com/docs/guides/database/hardening-data-api#step-2-create-an-api-schema-and-expose-it)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_import_data.md">
Database

# Import data into Supabase

* * *

You can import data into Supabase in multiple ways. The best method depends on your data size and app requirements.

If you're working with small datasets in development, you can experiment quickly using CSV import in the Supabase dashboard. If you're working with a large dataset in production, you should plan your data import to minimize app latency and ensure data integrity.

## How to import data into Supabase [\#](https://supabase.com/docs/guides/database/import-data\#how-to-import-data-into-supabase)

You have multiple options for importing your data into Supabase:

1. [CSV import via the Supabase dashboard](https://supabase.com/docs/guides/database/import-data#option-1-csv-import-via-supabase-dashboard)
2. [Bulk import using `pgloader`](https://supabase.com/docs/guides/database/import-data#option-2-bulk-import-using-pgloader)
3. [Using the Postgres `COPY` command](https://supabase.com/docs/guides/database/import-data#option-3-using-postgres-copy-command)
4. [Using the Supabase API](https://supabase.com/docs/guides/database/import-data#option-4-using-the-supabase-api)

If you're importing a large dataset or importing data into production, plan ahead and [prepare your database](https://supabase.com/docs/guides/database/import-data#preparing-to-import-data).

### Option 1: CSV import via Supabase dashboard [\#](https://supabase.com/docs/guides/database/import-data\#option-1-csv-import-via-supabase-dashboard)

Supabase dashboard provides a user-friendly way to import data. However, for very large datasets, this method may not be the most efficient choice, given the size limit is 100MB. It's generally better suited for smaller datasets and quick data imports. Consider using alternative methods like pgloader for large-scale data imports.

1. Navigate to the relevant table in the [Table Editor.](https://supabase.com/dashboard/project/_/editor)
2. Click on Insert then choose "Import Data from CSV" and follow the on-screen instructions to upload your CSV file.

### Option 2: Bulk import using pgloader [\#](https://supabase.com/docs/guides/database/import-data\#option-2-bulk-import-using-pgloader)

[pgloader](https://pgloader.io/) is a powerful tool for efficiently importing data into a Postgres database that supports a wide range of source database engines, including MySQL and MS SQL.

You can use it in conjunction with Supabase by following these steps:

1. Install pgloader on your local machine or a server. For more info, you can refer to the [official pgloader installation page](https://pgloader.readthedocs.io/en/latest/install.html).



`
$ apt-get install pgloader
`

2. Create a configuration file that specifies the source data and the target Supabase database (e.g., config.load).
Here's an example configuration file:



`
LOAD DATABASE
       FROM sourcedb://USER:PASSWORD@HOST/SOURCE_DB
       INTO postgres://postgres.xxxx:password@xxxx.pooler.supabase.com:6543/postgres
ALTER SCHEMA 'public' OWNER TO 'postgres';
set wal_buffers = '64MB', max_wal_senders = 0, statement_timeout = 0, work_mem to '2GB';
`



Customize the source and Supabase database URL and options to fit your specific use case:
   - `wal_buffers`: This parameter is set to '64MB' to allocate 64 megabytes of memory for write-ahead logging buffers. A larger value can help improve write performance by caching more data in memory before writing it to disk. This can be useful during data import operations to speed up the writing of transaction logs.
   - `max_wal_senders`: It is set to 0, to disable replication connections. This is done during the data import process to prevent replication-related conflicts and issues.
   - `statement_timeout`: The value is set to 0, which means it's disabled, allowing SQL statements to run without a time limit.
   - `work_mem`: It is set to '2GB', allocating 2 GB of memory for query operations. This enhances the performance of complex queries by allowing larger in-memory datasets.
3. Run pgloader with the configuration file.



`
pgloader config.load
`


For databases using the Postgres engine, we recommend using the [pg\_dump](https://www.postgresql.org/docs/current/app-pgdump.html) and [psql](https://www.postgresql.org/docs/current/app-psql.html) command line tools.

### Option 3: Using Postgres copy command [\#](https://supabase.com/docs/guides/database/import-data\#option-3-using-postgres-copy-command)

Read more about [Bulk data loading.](https://supabase.com/docs/guides/database/tables#bulk-data-loading)

### Option 4: Using the Supabase API [\#](https://supabase.com/docs/guides/database/import-data\#option-4-using-the-supabase-api)

The Supabase API allows you to programmatically import data into your tables. You can use various client libraries to interact with the API and perform data import operations. This approach is useful when you need to automate data imports, and it gives you fine-grained control over the process. Refer to our [API guide](https://supabase.com/docs/guides/api) for more details.

When importing data via the Supabase API, it's advisable to refrain from bulk imports. This helps ensure a smooth data transfer process and prevents any potential disruptions.

Read more about [Rate Limiting, Resource Allocation, & Abuse Prevention.](https://supabase.com/docs/guides/platform/going-into-prod#rate-limiting-resource-allocation--abuse-prevention)

## Preparing to import data [\#](https://supabase.com/docs/guides/database/import-data\#preparing-to-import-data)

Large data imports can affect your database performance. Failed imports can also cause data corruption. Importing data is a safe and common operation, but you should plan ahead if you're importing a lot of data, or if you're working in a production environment.

### 1\. Back up your data [\#](https://supabase.com/docs/guides/database/import-data\#1-back-up-your-data)

Backups help you restore your data if something goes wrong. Databases on Pro, Team and Enterprise Plans are automatically backed up on schedule, but you can also take your own backup. See [Database Backups](https://supabase.com/docs/guides/platform/backups) for more information.

### 2\. Increase statement timeouts [\#](https://supabase.com/docs/guides/database/import-data\#2-increase-statement-timeouts)

By default, Supabase enforces query statement timeouts to ensure fair resource allocation and prevent long-running queries from affecting the overall system. When importing large datasets, you may encounter timeouts. To address this:

- **Increase the Statement Timeout**: You can adjust the statement timeout for your session or connection to accommodate longer-running queries. Be cautious when doing this, as excessively long queries can negatively impact system performance. Read more about [Statement Timeouts](https://supabase.com/docs/guides/database/postgres/configuration).

### 3\. Estimate your required disk size [\#](https://supabase.com/docs/guides/database/import-data\#3-estimate-your-required-disk-size)

Large datasets consume disk space. Ensure your Supabase project has sufficient disk capacity to accommodate the imported data. If you know how big your database is going to be, you can manually increase the size in your [projects database settings](https://supabase.com/dashboard/project/_/settings/database).

Read more about[disk management](https://supabase.com/docs/guides/platform/database-size#disk-management).

### 4\. Disable triggers [\#](https://supabase.com/docs/guides/database/import-data\#4-disable-triggers)

When importing large datasets, it's often beneficial to disable triggers temporarily. Triggers can significantly slow down the import process, especially if they involve complex logic or referential integrity checks. After the import, you can re-enable the triggers.

To disable triggers, use the following SQL commands:

`
-- Disable triggers on a specific table
ALTER TABLE table_name DISABLE TRIGGER ALL;
-- To re-enable triggers
ALTER TABLE table_name ENABLE TRIGGER ALL;
`

### 5\. Rebuild indices after data import is complete [\#](https://supabase.com/docs/guides/database/import-data\#5-rebuild-indices-after-data-import-is-complete)

Indexing is crucial for query performance, but building indices while importing a large dataset can be time-consuming. Consider building or rebuilding indices after the data import is complete. This approach can significantly speed up the import process and reduce the overall time required.

To build an index after the data import:

`
-- Create an index on a table
create index index_name on table_name (column_name);
`

Read more about [Managing Indexes in Postgres](https://supabase.com/docs/guides/database/postgres/indexes).

### Is this helpful?

NoYes

### On this page

[How to import data into Supabase](https://supabase.com/docs/guides/database/import-data#how-to-import-data-into-supabase) [Option 1: CSV import via Supabase dashboard](https://supabase.com/docs/guides/database/import-data#option-1-csv-import-via-supabase-dashboard) [Option 2: Bulk import using pgloader](https://supabase.com/docs/guides/database/import-data#option-2-bulk-import-using-pgloader) [Option 3: Using Postgres copy command](https://supabase.com/docs/guides/database/import-data#option-3-using-postgres-copy-command) [Option 4: Using the Supabase API](https://supabase.com/docs/guides/database/import-data#option-4-using-the-supabase-api) [Preparing to import data](https://supabase.com/docs/guides/database/import-data#preparing-to-import-data) [1\. Back up your data](https://supabase.com/docs/guides/database/import-data#1-back-up-your-data) [2\. Increase statement timeouts](https://supabase.com/docs/guides/database/import-data#2-increase-statement-timeouts) [3\. Estimate your required disk size](https://supabase.com/docs/guides/database/import-data#3-estimate-your-required-disk-size) [4\. Disable triggers](https://supabase.com/docs/guides/database/import-data#4-disable-triggers) [5\. Rebuild indices after data import is complete](https://supabase.com/docs/guides/database/import-data#5-rebuild-indices-after-data-import-is-complete)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_inspect.md">
Database

# Debugging and monitoring

* * *

Database performance is a large topic and many factors can contribute. Some of the most common causes of poor performance include:

- An inefficiently designed schema
- Inefficiently designed queries
- A lack of indexes causing slower than required queries over large tables
- Unused indexes causing slow `INSERT`, `UPDATE` and `DELETE` operations
- Not enough compute resources, such as memory, causing your database to go to disk for results too often
- Lock contention from multiple queries operating on highly utilized tables
- Large amount of bloat on your tables causing poor query planning

You can examine your database and queries for these issues using either the [Supabase CLI](https://supabase.com/docs/guides/local-development/cli/getting-started) or SQL.

## Using the CLI [\#](https://supabase.com/docs/guides/database/inspect\#using-the-cli)

The Supabase CLI comes with a range of tools to help inspect your Postgres instances for potential issues. The CLI gets the information from [Postgres internals](https://www.postgresql.org/docs/current/internals.html). Therefore, most tools provided are compatible with any Postgres databases regardless if they are a Supabase project or not.

You can find installation instructions for the the Supabase CLI [here](https://supabase.com/docs/guides/cli).

### The `inspect db` command [\#](https://supabase.com/docs/guides/database/inspect\#the-inspect-db-command)

The inspection tools for your Postgres database are under then `inspect db` command. You can get a full list of available commands by running `supabase inspect db help`.

`
$ supabase inspect db help
Tools to inspect your Supabase database
Usage:
supabase inspect db [command]
Available Commands:
bloat                Estimates space allocated to a relation that is full of dead tuples
blocking             Show queries that are holding locks and the queries that are waiting for them to be released
cache-hit            Show cache hit rates for tables and indices
...
`

### Connect to any Postgres database [\#](https://supabase.com/docs/guides/database/inspect\#connect-to-any-postgres-database)

Most inspection commands are Postgres agnostic. You can run inspection routines on any Postgres database even if it is not a Supabase project by providing a connection string via `--db-url`.

For example you can connect to your local Postgres instance:

`
supabase --db-url postgresql://postgres:postgres@localhost:5432/postgres inspect db bloat
`

### Connect to a Supabase instance [\#](https://supabase.com/docs/guides/database/inspect\#connect-to-a-supabase-instance)

Working with Supabase, you can link the Supabase CLI with your project:

`
supabase link --project-ref <project-id>
`

Then the CLI will automatically connect to your Supabase project whenever you are in the project folder and you no longer need to provide `db-url`.

### Inspection commands [\#](https://supabase.com/docs/guides/database/inspect\#inspection-commands)

Below are the `db` inspection commands provided, grouped by different use cases.

Some commands might require `pg_stat_statements` to be enabled or a specific Postgres version to be used.

#### Disk storage [\#](https://supabase.com/docs/guides/database/inspect\#disk-storage)

These commands are handy if you are running low on disk storage:

- [bloat](https://supabase.com/docs/reference/cli/supabase-inspect-db-bloat) \- estimates the amount of wasted space
- [vacuum-stats](https://supabase.com/docs/reference/cli/supabase-inspect-db-vacuum-stats) \- gives information on waste collection routines
- [table-record-counts](https://supabase.com/docs/reference/cli/supabase-inspect-db-table-record-counts) \- estimates the number of records per table
- [table-sizes](https://supabase.com/docs/reference/cli/supabase-inspect-db-table-sizes) \- shows the sizes of tables
- [index-sizes](https://supabase.com/docs/reference/cli/supabase-inspect-db-index-sizes) \- shows the sizes of individual index
- [table-index-sizes](https://supabase.com/docs/reference/cli/supabase-inspect-db-table-index-sizes) \- shows the sizes of indexes for each table

#### Query performance [\#](https://supabase.com/docs/guides/database/inspect\#query-performance)

The commands below are useful if your Postgres database consumes a lot of resources like CPU, RAM or Disk IO. You can also use them to investigate slow queries.

- [cache-hit](https://supabase.com/docs/reference/cli/supabase-inspect-db-cache-hit) \- shows how efficient your cache usage is overall
- [unused-indexes](https://supabase.com/docs/reference/cli/supabase-inspect-db-unused-indexes) \- shows indexes with low index scans
- [index-usage](https://supabase.com/docs/reference/cli/supabase-inspect-db-index-usage) \- shows information about the efficiency of indexes
- [seq-scans](https://supabase.com/docs/reference/cli/supabase-inspect-db-seq-scans) \- show number of sequential scans recorded against all tables
- [long-running-queries](https://supabase.com/docs/reference/cli/supabase-inspect-db-long-running-queries) \- shows long running queries that are executing right now
- [outliers](https://supabase.com/docs/reference/cli/supabase-inspect-db-outliers) \- shows queries with high execution time but low call count and queries with high proportion of execution time spent on synchronous I/O

#### Locks [\#](https://supabase.com/docs/guides/database/inspect\#locks)

- [locks](https://supabase.com/docs/reference/cli/supabase-inspect-db-locks) \- shows statements which have taken out an exclusive lock on a relation
- [blocking](https://supabase.com/docs/reference/cli/supabase-inspect-db-blocking) \- shows statements that are waiting for locks to be released

#### Connections [\#](https://supabase.com/docs/guides/database/inspect\#connections)

- [role-connections](https://supabase.com/docs/reference/cli/supabase-inspect-db-role-connections) \- shows number of active connections for all database roles (Supabase-specific command)
- [replication-slots](https://supabase.com/docs/reference/cli/supabase-inspect-db-replication-slots) \- shows information about replication slots on the database

### Notes on `pg_stat_statements` [\#](https://supabase.com/docs/guides/database/inspect\#notes-on-pgstatstatements)

Following commands require `pg_stat_statements` to be enabled: calls, locks, cache-hit, blocking, unused-indexes, index-usage, bloat, outliers, table-record-counts, replication-slots, seq-scans, vacuum-stats, long-running-queries.

When using `pg_stat_statements` also take note that it only stores the latest 5,000 statements. Moreover, consider resetting the analysis after optimizing any queries by running `select pg_stat_statements_reset();`

Learn more about pg\_stats [here](https://supabase.com/docs/guides/database/extensions/pg_stat_statements).

## Using SQL [\#](https://supabase.com/docs/guides/database/inspect\#using-sql)

If you're seeing an `insufficient privilege` error when viewing the Query Performance page from the dashboard, run this command:

`
$ grant pg_read_all_stats to postgres;
`

### Postgres cumulative statistics system [\#](https://supabase.com/docs/guides/database/inspect\#postgres-cumulative-statistics-system)

Postgres collects data about its own operations using the [cumulative statistics system](https://www.postgresql.org/docs/current/monitoring-stats.html). In addition to this, every Supabase project has the [pg\_stat\_statements extension](https://supabase.com/docs/guides/database/extensions/pg_stat_statements) enabled by default. This extension records query execution performance details and is the best way to find inefficient queries. This information can be combined with the Postgres query plan analyzer to develop more efficient queries.

Here are some example queries to get you started.

### Most frequently called queries [\#](https://supabase.com/docs/guides/database/inspect\#most-frequently-called-queries)

`
select
auth.rolname,
statements.query,
statements.calls,
  -- -- Postgres 13, 14, 15
statements.total_exec_time + statements.total_plan_time as total_time,
statements.min_exec_time + statements.min_plan_time as min_time,
statements.max_exec_time + statements.max_plan_time as max_time,
statements.mean_exec_time + statements.mean_plan_time as mean_time,
  -- -- Postgres <= 12
  -- total_time,
  -- min_time,
  -- max_time,
  -- mean_time,
statements.rows / statements.calls as avg_rows
from
pg_stat_statements as statements
inner join pg_authid as auth on statements.userid = auth.oid
order by statements.calls desc
limit 100;
`

This query shows:

- query statistics, ordered by the number of times each query has been executed
- the role that ran the query
- the number of times it has been called
- the average number of rows returned
- the cumulative total time the query has spent running
- the min, max and mean query times.

This provides useful information about the queries you run most frequently. Queries that have high `max_time` or `mean_time` times and are being called often can be good candidates for optimization.

### Slowest queries by execution time [\#](https://supabase.com/docs/guides/database/inspect\#slowest-queries-by-execution-time)

`
select
auth.rolname,
statements.query,
statements.calls,
  -- -- Postgres 13, 14, 15
statements.total_exec_time + statements.total_plan_time as total_time,
statements.min_exec_time + statements.min_plan_time as min_time,
statements.max_exec_time + statements.max_plan_time as max_time,
statements.mean_exec_time + statements.mean_plan_time as mean_time,
  -- -- Postgres <= 12
  -- total_time,
  -- min_time,
  -- max_time,
  -- mean_time,
statements.rows / statements.calls as avg_rows
from
pg_stat_statements as statements
inner join pg_authid as auth on statements.userid = auth.oid
order by max_time desc
limit 100;
`

This query will show you statistics about queries ordered by the maximum execution time. It is similar to the query above ordered by calls, but this one highlights outliers that may have high executions times. Queries which have high or mean execution times are good candidates for optimization.

### Most time consuming queries [\#](https://supabase.com/docs/guides/database/inspect\#most-time-consuming-queries)

`
select
auth.rolname,
statements.query,
statements.calls,
statements.total_exec_time + statements.total_plan_time as total_time,
to_char(
    (
      (statements.total_exec_time + statements.total_plan_time) / sum(
        statements.total_exec_time + statements.total_plan_time
      ) over ()
    ) * 100,
    'FM90D0'
) || '%' as prop_total_time
from
pg_stat_statements as statements
inner join pg_authid as auth on statements.userid = auth.oid
order by total_time desc
limit 100;
`

This query will show you statistics about queries ordered by the cumulative total execution time. It shows the total time the query has spent running as well as the proportion of total execution time the query has taken up.

Queries which are the most time consuming are not necessarily bad, you may have a very efficient and frequently ran queries that end up taking a large total % time, but it can be useful to help spot queries that are taking up more time than they should.

### Hit rate [\#](https://supabase.com/docs/guides/database/inspect\#hit-rate)

Generally for most applications a small percentage of data is accessed more regularly than the rest. To make sure that your regularly accessed data is available, Postgres tracks your data access patterns and keeps this in its [shared\_buffers](https://www.postgresql.org/docs/15/runtime-config-resource.html#RUNTIME-CONFIG-RESOURCE-MEMORY) cache.

Applications with lower cache hit rates generally perform more poorly since they have to hit the disk to get results rather than serving them from memory. Very poor hit rates can also cause you to burst past your [Disk IO limits](https://supabase.com/docs/guides/database/compute-add-ons#disk-io) causing significant performance issues.

You can view your cache and index hit rate by executing the following query:

`
select
'index hit rate' as name,
(sum(idx_blks_hit)) / nullif(sum(idx_blks_hit + idx_blks_read), 0) * 100 as ratio
from pg_statio_user_indexes
union all
select
'table hit rate' as name,
sum(heap_blks_hit) / nullif(sum(heap_blks_hit) + sum(heap_blks_read), 0) * 100 as ratio
from pg_statio_user_tables;
`

This shows the ratio of data blocks fetched from the Postgres [shared\_buffers](https://www.postgresql.org/docs/15/runtime-config-resource.html#RUNTIME-CONFIG-RESOURCE-MEMORY) cache against the data blocks that were read from disk/OS cache.

If either of your index or table hit rate are < 99% then this can indicate your compute plan is too small for your current workload and you would benefit from more memory. [Upgrading your compute](https://supabase.com/docs/guides/database/compute-add-ons) is easy and can be done from your [project dashboard](https://supabase.com/dashboard/project/_/settings/compute-and-disk).

### Optimizing poor performing queries [\#](https://supabase.com/docs/guides/database/inspect\#optimizing-poor-performing-queries)

Postgres has built in tooling to help you optimize poorly performing queries. You can use the [query plan analyzer](https://www.postgresql.org/docs/current/sql-explain.html) on any expensive queries that you have identified:

`
explain analyze <query-statement-here>;
`

When you include `analyze` in the explain statement, the database attempts to execute the query and provides a detailed query plan along with actual execution times. So, be careful using `explain analyze` with `insert`/ `update`/ `delete` queries, because the query will actually run, and could have unintended side-effects.

If you run just `explain` without the `analyze` keyword, the database will only perform query planning without actually executing the query. This approach can be beneficial when you want to inspect the query plan without affecting the database or if you encounter timeouts in your queries.

Using the query plan analyzer to optimize your queries is a large topic, with a number of online resources available:

- [Official docs.](https://www.postgresql.org/docs/current/using-explain.html)
- [The Art of PostgreSQL.](https://theartofpostgresql.com/explain-plan-visualizer/)
- [Postgres Wiki.](https://wiki.postgresql.org/wiki/Using_EXPLAIN)
- [Enterprise DB.](https://www.enterprisedb.com/blog/postgresql-query-optimization-performance-tuning-with-explain-analyze)

You can pair the information available from `pg_stat_statements` with the detailed system metrics available [via your metrics endpoint](https://supabase.com/docs/guides/platform/metrics) to better understand the behavior of your DB and the queries you're executing against it.

### Is this helpful?

NoYes

### On this page

[Using the CLI](https://supabase.com/docs/guides/database/inspect#using-the-cli) [The inspect db command](https://supabase.com/docs/guides/database/inspect#the-inspect-db-command) [Connect to any Postgres database](https://supabase.com/docs/guides/database/inspect#connect-to-any-postgres-database) [Connect to a Supabase instance](https://supabase.com/docs/guides/database/inspect#connect-to-a-supabase-instance) [Inspection commands](https://supabase.com/docs/guides/database/inspect#inspection-commands) [Notes on pg\_stat\_statements](https://supabase.com/docs/guides/database/inspect#notes-on-pgstatstatements) [Using SQL](https://supabase.com/docs/guides/database/inspect#using-sql) [Postgres cumulative statistics system](https://supabase.com/docs/guides/database/inspect#postgres-cumulative-statistics-system) [Most frequently called queries](https://supabase.com/docs/guides/database/inspect#most-frequently-called-queries) [Slowest queries by execution time](https://supabase.com/docs/guides/database/inspect#slowest-queries-by-execution-time) [Most time consuming queries](https://supabase.com/docs/guides/database/inspect#most-time-consuming-queries) [Hit rate](https://supabase.com/docs/guides/database/inspect#hit-rate) [Optimizing poor performing queries](https://supabase.com/docs/guides/database/inspect#optimizing-poor-performing-queries)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_joins_and_nesting.md">
Database

# Querying Joins and Nested tables

* * *

The data APIs automatically detect relationships between Postgres tables. Since Postgres is a relational database, this is a very common scenario.

## One-to-many joins [\#](https://supabase.com/docs/guides/database/joins-and-nesting\#one-to-many-joins)

Let's use an example database that stores `orchestral_sections` and `instruments`:

TablesSQL

**Orchestral sections**

| `id` | `name` |
| --- | --- |
| 1 | strings |
| 2 | woodwinds |

**Instruments**

| `id` | `name` | `section_id` |
| --- | --- | --- |
| 1 | violin | 1 |
| 2 | viola | 1 |
| 3 | flute | 2 |
| 4 | oboe | 2 |

The APIs will automatically detect relationships based on the foreign keys:

JavaScriptDartSwiftKotlinPythonGraphQLURL

``
const { data, error } = await supabase.from('orchestral_sections').select(`
id,
name,
instruments ( id, name )
`)
``

### TypeScript types for joins [\#](https://supabase.com/docs/guides/database/joins-and-nesting\#typescript-types-for-joins)

`supabase-js` always returns a `data` object (for success), and an `error` object (for unsuccessful requests).

These helper types provide the result types from any query, including nested types for database joins.

Given the following schema with a relation between orchestral sections and instruments:

`
create table orchestral_sections (
"id" serial primary key,
"name" text
);
create table instruments (
"id" serial primary key,
"name" text,
"section_id" int references "orchestral_sections"
);
`

We can get the nested `SectionsWithInstruments` type like this:

``
import { QueryResult, QueryData, QueryError } from '@supabase/supabase-js'
const sectionsWithInstrumentsQuery = supabase.from('orchestral_sections').select(`
id,
name,
instruments (
    id,
    name
)
`)
type SectionsWithInstruments = QueryData<typeof sectionsWithInstrumentsQuery>
const { data, error } = await sectionsWithInstrumentsQuery
if (error) throw error
const sectionsWithInstruments: SectionsWithInstruments = data
``

## Many-to-many joins [\#](https://supabase.com/docs/guides/database/joins-and-nesting\#many-to-many-joins)

The data APIs will detect many-to-many joins. For example, if you have a database which stored teams of users (where each user could belong to many teams):

`
create table users (
"id" serial primary key,
"name" text
);
create table teams (
"id" serial primary key,
"team_name" text
);
create table members (
"user_id" int references users,
"team_id" int references teams,
primary key (user_id, team_id)
);
`

In these cases you don't need to explicitly define the joining table (members). If we wanted to fetch all the teams and the members in each team:

JavaScriptDartSwiftKotlinPythonGraphQLURL

``
const { data, error } = await supabase.from('teams').select(`
id,
team_name,
users ( id, name )
`)
``

## Specifying the `ON` clause for joins with multiple foreign keys [\#](https://supabase.com/docs/guides/database/joins-and-nesting\#specifying-the-on-clause-for-joins-with-multiple-foreign-keys)

For example, if you have a project that tracks when employees check in and out of work shifts:

`
-- Employees
create table users (
"id" serial primary key,
"name" text
);
-- Badge scans
create table scans (
"id" serial primary key,
"user_id" int references users,
"badge_scan_time" timestamp
);
-- Work shifts
create table shifts (
"id" serial primary key,
"user_id" int references users,
"scan_id_start" int references scans, -- clocking in
"scan_id_end" int references scans, -- clocking out
"attendance_status" text
);
`

In this case, you need to explicitly define the join because the joining column on `shifts` is ambiguous as they are both referencing the `scans` table.

To fetch all the `shifts` with `scan_id_start` and `scan_id_end` related to a specific `scan`, use the following syntax:

JavaScriptDartSwiftKotlinPythonGraphQL

``
const { data, error } = await supabase.from('shifts').select(
`
    *,
    start_scan:scans!scan_id_start (
      id,
      user_id,
      badge_scan_time
    ),
end_scan:scans!scan_id_end (
     id,
     user_id,
     badge_scan_time
    )
`
)
``

### Is this helpful?

NoYes

### On this page

[One-to-many joins](https://supabase.com/docs/guides/database/joins-and-nesting#one-to-many-joins) [TypeScript types for joins](https://supabase.com/docs/guides/database/joins-and-nesting#typescript-types-for-joins) [Many-to-many joins](https://supabase.com/docs/guides/database/joins-and-nesting#many-to-many-joins) [Specifying the ON clause for joins with multiple foreign keys](https://supabase.com/docs/guides/database/joins-and-nesting#specifying-the-on-clause-for-joins-with-multiple-foreign-keys)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_json.md">
Database

# Managing JSON and unstructured data

## Using the JSON data type in Postgres.

* * *

Postgres supports storing and querying unstructured data.

## JSON vs JSONB [\#](https://supabase.com/docs/guides/database/json\#json-vs-jsonb)

Postgres supports two types of JSON columns: `json` (stored as a string) and `jsonb` (stored as a binary). The recommended type is `jsonb` for almost all cases.

- `json` stores an exact copy of the input text. Database functions must reparse the content on each execution.
- `jsonb` stores database in a decomposed binary format. While this makes it slightly slower to input due to added conversion overhead, it is significantly faster to process, since no reparsing is needed.

## When to use JSON/JSONB [\#](https://supabase.com/docs/guides/database/json\#when-to-use-jsonjsonb)

Generally you should use a `jsonb` column when you have data that is unstructured or has a variable schema. For example, if you wanted to store responses for various webhooks, you might not know the format of the response when creating the table. Instead, you could store the `payload` as a `jsonb` object in a single column.

Don't go overboard with `json/jsonb` columns. They are a useful tool, but most of the benefits of a relational database come from the ability to query and join structured data, and the referential integrity that brings.

## Create JSONB columns [\#](https://supabase.com/docs/guides/database/json\#create-jsonb-columns)

`json/jsonb` is just another "data type" for Postgres columns. You can create a `jsonb` column in the same way you would create a `text` or `int` column:

SQLDashboard

`
create table books (
id serial primary key,
title text,
author text,
metadata jsonb
);
`

## Inserting JSON data [\#](https://supabase.com/docs/guides/database/json\#inserting-json-data)

You can insert JSON data in the same way that you insert any other data. The data must be valid JSON.

SQLDashboardJavaScriptDartSwiftKotlinPython

`
insert into books
(title, author, metadata)
values
(
    'The Poky Little Puppy',
    'Janette Sebring Lowrey',
    '{"description":"Puppy is slower than other, bigger animals.","price":5.95,"ages":[3,6]}'
),
(
    'The Tale of Peter Rabbit',
    'Beatrix Potter',
    '{"description":"Rabbit eats some vegetables.","price":4.49,"ages":[2,5]}'
),
(
    'Tootle',
    'Gertrude Crampton',
    '{"description":"Little toy train has big dreams.","price":3.99,"ages":[2,5]}'
),
(
    'Green Eggs and Ham',
    'Dr. Seuss',
    '{"description":"Sam has changing food preferences and eats unusually colored food.","price":7.49,"ages":[4,8]}'
),
(
    'Harry Potter and the Goblet of Fire',
    'J.K. Rowling',
    '{"description":"Fourth year of school starts, big drama ensues.","price":24.95,"ages":[10,99]}'
);
`

## Query JSON data [\#](https://supabase.com/docs/guides/database/json\#query-json-data)

Querying JSON data is similar to querying other data, with a few other features to access nested values.

Postgres support a range of [JSON functions and operators](https://www.postgresql.org/docs/current/functions-json.html). For example, the `->` operator returns values as `jsonb` data. If you want the data returned as `text`, use the `->>` operator.

SQLJavaScriptSwiftKotlinPythonResult

`
select
title,
metadata ->> 'description' as description, -- returned as text
metadata -> 'price' as price,
metadata -> 'ages' -> 0 as low_age,
metadata -> 'ages' -> 1 as high_age
from books;
`

## Validating JSON data [\#](https://supabase.com/docs/guides/database/json\#validating-json-data)

Supabase provides the [`pg_jsonschema` extension](https://supabase.com/docs/guides/database/extensions/pg_jsonschema) that adds the ability to validate `json` and `jsonb` data types against [JSON Schema](https://json-schema.org/) documents.

Once you have enabled the extension, you can add a "check constraint" to your table to validate the JSON data:

`
create table customers (
id serial primary key,
metadata json
);
alter table customers
add constraint check_metadata check (
json_matches_schema(
    '{
        "type": "object",
        "properties": {
            "tags": {
                "type": "array",
                "items": {
                    "type": "string",
                    "maxLength": 16
                }
            }
        }
    }',
    metadata
)
);
`

## Resources [\#](https://supabase.com/docs/guides/database/json\#resources)

- [Postgres: JSON Functions and Operators](https://www.postgresql.org/docs/current/functions-json.html)
- [Postgres JSON types](https://www.postgresql.org/docs/current/datatype-json.html)

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2FnxeUiRz4G-M%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[JSON vs JSONB](https://supabase.com/docs/guides/database/json#json-vs-jsonb) [When to use JSON/JSONB](https://supabase.com/docs/guides/database/json#when-to-use-jsonjsonb) [Create JSONB columns](https://supabase.com/docs/guides/database/json#create-jsonb-columns) [Inserting JSON data](https://supabase.com/docs/guides/database/json#inserting-json-data) [Query JSON data](https://supabase.com/docs/guides/database/json#query-json-data) [Validating JSON data](https://supabase.com/docs/guides/database/json#validating-json-data) [Resources](https://supabase.com/docs/guides/database/json#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_metabase.md">
Database

# Connecting to Metabase

* * *

[`Metabase`](https://www.metabase.com/) is an Open Source data visualization tool. You can use it to explore your data stored in Supabase.

1

### Register

Create a [Metabase account](https://store.metabase.com/checkout) or deploy locally with [Docker](https://www.docker.com/products/docker-desktop/)

Deploying with Docker:

`
docker pull metabase/metabase:latest
`

Then run:

`
docker run -d -p 3000:3000 --name metabase metabase/metabase
`

The server should be available at [`http://localhost:3000/setup`](http://localhost:3000/setup)

2

### Connect to Postgres

Connect your Postgres server to Metabase.

- On your project dashboard click on [Connect](https://supabase.com/dashboard/project/_?showConnect=true)
- View parameters under Direct Connection
- Enter your database credentials into Metabase

Example credentials:
![Name Postgres Server.](https://supabase.com/docs/img/guides/database/connecting-to-postgres/metabase/add-pg-server.png)

3

### Explore

Explore your data in Metabase

![explore data](https://supabase.com/docs/img/guides/database/connecting-to-postgres/metabase/explore.png)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_orioledb.md">
Database

# OrioleDB Overview

* * *

The [OrioleDB](https://www.orioledb.com/) Postgres extension provides a drop-in replacement storage engine for the default heap storage method. It is designed to improve Postgres' scalability and performance.

OrioleDB addresses PostgreSQL's scalability limitations by removing bottlenecks in the shared memory cache under high concurrency. It also optimizes write-ahead-log (WAL) insertion through row-level WAL logging. These changes lead to significant improvements in the industry standard TPC-C benchmark, which approximates a real-world transactional workload. The following benchmark was performed on a c7g.metal instance and shows OrioleDB's performance outperforming the default Postgres heap method with a 3.3x speedup.

![TPC-C (warehouses = 500)](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fdatabase%2Forioledb-tpc-c-500-warehouse.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

OrioleDB is in active development and currently has [certain limitations](https://www.orioledb.com/docs/usage/getting-started#current-limitations). Currently, only B-tree indexes are supported, so features like pg\_vector's HNSW indexes are not yet available. An Index Access Method bridge to unlock support for all index types used with heap storage is under active development. In the Supabase OrioleDB image the default storage method has been updated to use OrioleDB, granting better performance out of the box.

## Concepts [\#](https://supabase.com/docs/guides/database/orioledb\#concepts)

### Index-organized tables [\#](https://supabase.com/docs/guides/database/orioledb\#index-organized-tables)

OrioleDB uses index-organized tables, where table data is stored in the index structure. This design eliminates the need for separate heap storage, reduces overhead and improves lookup performance for primary key queries.

### No buffer mapping [\#](https://supabase.com/docs/guides/database/orioledb\#no-buffer-mapping)

In-memory pages are connected to the storage pages using direct links. This allows OrioleDB to bypass PostgreSQL's shared buffer pool and eliminate the associated complexity and contention in buffer mapping.

### Undo log [\#](https://supabase.com/docs/guides/database/orioledb\#undo-log)

Multi-Version Concurrency Control (MVCC) is implemented using an undo log. The undo log stores previous row versions and transaction information, which enables consistent reads while removing the need for table vacuuming completely.

### Copy-on-write checkpoints [\#](https://supabase.com/docs/guides/database/orioledb\#copy-on-write-checkpoints)

OrioleDB implements copy-on-write checkpoints to persist data efficiently. This approach writes only modified data during a checkpoint, reducing the I/O overhead compared to traditional Postgres checkpointing and allowing row-level WAL logging.

## Usage [\#](https://supabase.com/docs/guides/database/orioledb\#usage)

### Creating OrioleDB project [\#](https://supabase.com/docs/guides/database/orioledb\#creating-orioledb-project)

You can get started with OrioleDB by enabling the extension in your Supabase dashboard.
To get started with OrioleDB you need to [create a new Supabase project](https://supabase.com/dashboard/new/_) and choose `OrioleDB Public Alpha` Postgres version.

![Creating OrioleDB project](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fdatabase%2Forioledb-creating-project--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Creating tables [\#](https://supabase.com/docs/guides/database/orioledb\#creating-tables)

To create a table using the OrioleDB storage engine just execute the standard `CREATE TABLE` statement. By default it will create a table using OrioleDB storage engine. For example:

`
-- Create a table
create table blog_post (
id int8 not null,
title text not null,
body text not null,
author text not null,
published_at timestamptz not null default CURRENT_TIMESTAMP,
views bigint not null,
primary key (id)
);
`

### Creating indexes [\#](https://supabase.com/docs/guides/database/orioledb\#creating-indexes)

OrioleDB tables always have a primary key. If it wasn't defined explicitly, a hidden primary key is created using the `ctid` column.
Additionally you can create secondary indexes.

Currently, only B-tree indexes are supported, so features like pg\_vector's HNSW indexes are not yet available.

`
-- Create an index
create index blog_post_published_at on blog_post (published_at);
create index blog_post_views on blog_post (views) where (views > 1000);
`

### Data manipulation [\#](https://supabase.com/docs/guides/database/orioledb\#data-manipulation)

You can query and modify data in OrioleDB tables using standard SQL statements, including `SELECT`, `INSERT`, `UPDATE`, `DELETE` and `INSERT ... ON CONFLICT`.

`
INSERT INTO blog_post (id, title, body, author, views)
VALUES (1, 'Hello, World!', 'This is my first blog post.', 'John Doe', 1000);
SELECT * FROM blog_post ORDER BY published_at DESC LIMIT 10;
id      title                 body               author           published_at           views

1  Hello, World!  This is my first blog post.  John Doe  2024-11-15 12:04:18.756824+01   1000
`

### Viewing query plans [\#](https://supabase.com/docs/guides/database/orioledb\#viewing-query-plans)

You can see the execution plan using standard `EXPLAIN` statement.

`
EXPLAIN SELECT * FROM blog_post ORDER BY published_at DESC LIMIT 10;
                                                 QUERY PLAN

Limit  (cost=0.15..1.67 rows=10 width=120)
   ->  Index Scan Backward using blog_post_published_at on blog_post  (cost=0.15..48.95 rows=320 width=120)
EXPLAIN SELECT * FROM blog_post WHERE id = 1;
                                    QUERY PLAN

Index Scan using blog_post_pkey on blog_post  (cost=0.15..8.17 rows=1 width=120)
Index Cond: (id = 1)
EXPLAIN (ANALYZE, BUFFERS) SELECT * FROM blog_post ORDER BY published_at DESC LIMIT 10;
                                                                      QUERY PLAN

Limit  (cost=0.15..1.67 rows=10 width=120) (actual time=0.052..0.054 rows=1 loops=1)
   ->  Index Scan Backward using blog_post_published_at on blog_post  (cost=0.15..48.95 rows=320 width=120) (actual time=0.050..0.052 rows=1 loops=1)
Planning Time: 0.186 ms
Execution Time: 0.088 ms
`

## Resources [\#](https://supabase.com/docs/guides/database/orioledb\#resources)

- [Official OrioleDB documentation](https://www.orioledb.com/docs)
- [OrioleDB GitHub repository](https://github.com/orioledb/orioledb)

### Is this helpful?

NoYes

### On this page

[Concepts](https://supabase.com/docs/guides/database/orioledb#concepts) [Index-organized tables](https://supabase.com/docs/guides/database/orioledb#index-organized-tables) [No buffer mapping](https://supabase.com/docs/guides/database/orioledb#no-buffer-mapping) [Undo log](https://supabase.com/docs/guides/database/orioledb#undo-log) [Copy-on-write checkpoints](https://supabase.com/docs/guides/database/orioledb#copy-on-write-checkpoints) [Usage](https://supabase.com/docs/guides/database/orioledb#usage) [Creating OrioleDB project](https://supabase.com/docs/guides/database/orioledb#creating-orioledb-project) [Creating tables](https://supabase.com/docs/guides/database/orioledb#creating-tables) [Creating indexes](https://supabase.com/docs/guides/database/orioledb#creating-indexes) [Data manipulation](https://supabase.com/docs/guides/database/orioledb#data-manipulation) [Viewing query plans](https://supabase.com/docs/guides/database/orioledb#viewing-query-plans) [Resources](https://supabase.com/docs/guides/database/orioledb#resources)

![Creating OrioleDB project](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fdatabase%2Forioledb-creating-project--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![TPC-C (warehouses = 500)](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fdatabase%2Forioledb-tpc-c-500-warehouse.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_overview.md">
Database

# Database

* * *

Every Supabase project comes with a full [Postgres](https://www.postgresql.org/) database, a free and open source database which is considered one of the world's most stable and advanced databases.

## Features [\#](https://supabase.com/docs/guides/database/overview\#features)

### Table view [\#](https://supabase.com/docs/guides/database/overview\#table-view)

You don't have to be a database expert to start using Supabase. Our table view makes Postgres as easy to use as a spreadsheet.

![Table View.](https://supabase.com/docs/img/table-view.png)

### Relationships [\#](https://supabase.com/docs/guides/database/overview\#relationships)

Dig into the relationships within your data.

### Clone tables [\#](https://supabase.com/docs/guides/database/overview\#clone-tables)

You can duplicate your tables, just like you would inside a spreadsheet.

### The SQL editor [\#](https://supabase.com/docs/guides/database/overview\#the-sql-editor)

Supabase comes with a SQL Editor. You can also save your favorite queries to run later!

### Additional features [\#](https://supabase.com/docs/guides/database/overview\#additional-features)

- Supabase extends Postgres with realtime functionality using our [Realtime Server](https://github.com/supabase/realtime).
- Every project is a full Postgres database, with `postgres` level access.
- Supabase manages your database backups.
- Import data directly from a CSV or excel spreadsheet.

Database backups **do not** include objects stored via the Storage API, as the database only includes metadata about these objects. Restoring an old backup does not restore objects that have been deleted since then.

### Extensions [\#](https://supabase.com/docs/guides/database/overview\#extensions)

To expand the functionality of your Postgres database, you can use extensions.
You can enable Postgres extensions with the click of a button within the Supabase dashboard.

[Learn more](https://supabase.com/docs/guides/database/extensions) about all the extensions provided on Supabase.

## Terminology [\#](https://supabase.com/docs/guides/database/overview\#terminology)

### Postgres or PostgreSQL? [\#](https://supabase.com/docs/guides/database/overview\#postgres-or-postgresql)

PostgreSQL the database was derived from the POSTGRES Project, a package written at the University of California at Berkeley in 1986.This package included a query language called "PostQUEL".

In 1994, Postgres95 was built on top of POSTGRES code, adding an SQL language interpreter as a replacement for PostQUEL.

Eventually, Postgres95 was renamed to PostgreSQL to reflect the SQL query capability.
After this, many people referred to it as Postgres since it's less prone to confusion. Supabase is all about simplicity, so we also refer to it as Postgres.

## Tips [\#](https://supabase.com/docs/guides/database/overview\#tips)

Read about resetting your database password [here](https://supabase.com/docs/guides/database/managing-passwords) and changing the timezone of your server [here](https://supabase.com/docs/guides/database/managing-timezones).

## Next steps [\#](https://supabase.com/docs/guides/database/overview\#next-steps)

- Read more about [Postgres](https://www.postgresql.org/about/)
- Sign in: [supabase.com/dashboard](https://supabase.com/dashboard)

### Is this helpful?

NoYes

### On this page

[Features](https://supabase.com/docs/guides/database/overview#features) [Table view](https://supabase.com/docs/guides/database/overview#table-view) [Relationships](https://supabase.com/docs/guides/database/overview#relationships) [Clone tables](https://supabase.com/docs/guides/database/overview#clone-tables) [The SQL editor](https://supabase.com/docs/guides/database/overview#the-sql-editor) [Additional features](https://supabase.com/docs/guides/database/overview#additional-features) [Extensions](https://supabase.com/docs/guides/database/overview#extensions) [Terminology](https://supabase.com/docs/guides/database/overview#terminology) [Postgres or PostgreSQL?](https://supabase.com/docs/guides/database/overview#postgres-or-postgresql) [Tips](https://supabase.com/docs/guides/database/overview#tips) [Next steps](https://supabase.com/docs/guides/database/overview#next-steps)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_partitions.md">
Database

# Partitioning tables

* * *

Table partitioning is a technique that allows you to divide a large table into smaller, more manageable parts called partitions.

![multi database](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fdatabase%2Fpartitions-light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

Each partition contains a subset of the data based on a specified criteria, such as a range of values or a specific condition. Partitioning can significantly improve query performance and simplify data management for large datasets.

## Benefits of table partitioning [\#](https://supabase.com/docs/guides/database/partitions\#benefits-of-table-partitioning)

- **Improved query performance:** allows queries to target specific partitions, reducing the amount of data scanned and improving query execution time.
- **Scalability:** With partitioning, you can add or remove partitions as your data grows or changes, enabling better scalability and flexibility.
- **Efficient data management:** simplifies tasks such as data loading, archiving, and deletion by operating on smaller partitions instead of the entire table.
- **Enhanced maintenance operations:** can optimize vacuuming and indexing, leading to faster maintenance tasks.

## Partitioning methods [\#](https://supabase.com/docs/guides/database/partitions\#partitioning-methods)

Postgres supports various partitioning methods based on how you want to partition your data. The commonly used methods are:

1. **Range Partitioning**: Data is divided into partitions based on a specified range of values. For example, you can partition a sales table by date, where each partition represents a specific time range (e.g., one partition for each month).
2. **List Partitioning**: Data is divided into partitions based on a specified list of values. For instance, you can partition a customer table by region, where each partition contains customers from a specific region (e.g., one partition for customers in the US, another for customers in Europe).
3. **Hash Partitioning**: Data is distributed across partitions using a hash function. This method provides a way to evenly distribute data among partitions, which can be useful for load balancing. However, it doesn't allow direct querying based on specific values.

## Creating partitioned tables [\#](https://supabase.com/docs/guides/database/partitions\#creating-partitioned-tables)

Let's consider an example of range partitioning for a sales table based on the order date. We'll create monthly partitions to store data for each month:

`
create table sales (
    id bigint generated by default as identity,
    order_date date not null,
    customer_id bigint,
    amount bigint,
    -- We need to include all the
    -- partitioning columns in constraints:
    primary key (order_date, id)
)
partition by range (order_date);
create table sales_2000_01
	partition of sales
for values from ('2000-01-01') to ('2000-02-01');
create table sales_2000_02
	partition of sales
	for values from ('2000-02-01') to ('2000-03-01');
`

To create a partitioned table you append `partition by range (<column_name>)` to the table creation statement. The column that you are partitioning with _must_ be included in any unique index, which is the reason why we specify a composite primary key here ( `primary key (order_date, id)`).

## Querying partitioned tables [\#](https://supabase.com/docs/guides/database/partitions\#querying-partitioned-tables)

To query a partitioned table, you have two options:

1. Querying the parent table
2. Querying specific partitions

### Querying the parent table [\#](https://supabase.com/docs/guides/database/partitions\#querying-the-parent-table)

When you query the parent table, Postgres automatically routes the query to the relevant partitions based on the conditions specified in the query. This allows you to retrieve data from all partitions simultaneously.

Example:

`
select *
from sales
where order_date >= '2000-01-01' and order_date < '2000-03-01';
`

This query will retrieve data from both the `sales_2000_01` and `sales_2000_02` partitions.

### Querying specific partitions [\#](https://supabase.com/docs/guides/database/partitions\#querying-specific-partitions)

If you only need to retrieve data from a specific partition, you can directly query that partition instead of the parent table. This approach is useful when you want to target a specific range or condition within a partition.

`
select *
from sales_2000_02;
`

This query will retrieve data only from the `sales_2000_02` partition.

## When to partition your tables [\#](https://supabase.com/docs/guides/database/partitions\#when-to-partition-your-tables)

There is no real threshold to determine when you should use partitions. Partitions introduce complexity, and complexity should be avoided until it's needed. A few guidelines:

- If you are considering performance, avoid partitions until you see performance degradation on non-partitioned tables.
- If you are using partitions as a management tool, it's fine to create the partitions any time.
- If you don't know how you should partition your data, then it's probably too early.

## Examples [\#](https://supabase.com/docs/guides/database/partitions\#examples)

Here are simple examples for each of the partitioning types in Postgres.

### Range partitioning [\#](https://supabase.com/docs/guides/database/partitions\#range-partitioning)

Let's consider a range partitioning example for a table that stores sales data based on the order date. We'll create monthly partitions to store data for each month.

In this example, the **`sales`** table is partitioned into two partitions: **`sales_january`** and **`sales_february`**. The data in these partitions is based on the specified range of order dates:

`
create table sales (
    id bigint generated by default as identity,
    order_date date not null,
    customer_id bigint,
    amount bigint,
    -- We need to include all the
    -- partitioning columns in constraints:
    primary key (order_date, id)
)
partition by range (order_date);
create table sales_2000_01
	partition of sales
for values from ('2000-01-01') to ('2000-02-01');
create table sales_2000_02
	partition of sales
	for values from ('2000-02-01') to ('2000-03-01');
`

### List partitioning [\#](https://supabase.com/docs/guides/database/partitions\#list-partitioning)

Let's consider a list partitioning example for a table that stores customer data based on their region. We'll create partitions to store customers from different regions.

In this example, the **`customers`** table is partitioned into two partitions: `customers_americas` and `customers_asia`. The data in these partitions is based on the specified list of regions:

`
-- Create the partitioned table
create table customers (
    id bigint generated by default as identity,
    name text,
    country text,
    -- We need to include all the
    -- partitioning columns in constraints:
    primary key (country, id)
)
partition by list(country);
create table customers_americas
	partition of customers
	for values in ('US', 'CANADA');
create table customers_asia
	partition of customers
for values in ('INDIA', 'CHINA', 'JAPAN');
`

### Hash partitioning [\#](https://supabase.com/docs/guides/database/partitions\#hash-partitioning)

You can use hash partitioning to evenly distribute data.

In this example, the **`products`** table is partitioned into two partitions: `products_one` and `products_two`. The data is distributed across these partitions using a hash function:

`
create table products (
    id bigint generated by default as identity,
    name text,
    category text,
    price bigint
)
partition by hash (id);
create table products_one
	partition of products
for values with (modulus 2, remainder 1);
create table products_two
	partition of products
for values with (modulus 2, remainder 0);
`

## Other tools [\#](https://supabase.com/docs/guides/database/partitions\#other-tools)

There are several other tools available for Postgres partitioning, most notably [pg\_partman](https://github.com/pgpartman/pg_partman). Native partitioning was introduced in Postgres 10 and is generally thought to have better performance.

### Is this helpful?

NoYes

### On this page

[Benefits of table partitioning](https://supabase.com/docs/guides/database/partitions#benefits-of-table-partitioning) [Partitioning methods](https://supabase.com/docs/guides/database/partitions#partitioning-methods) [Creating partitioned tables](https://supabase.com/docs/guides/database/partitions#creating-partitioned-tables) [Querying partitioned tables](https://supabase.com/docs/guides/database/partitions#querying-partitioned-tables) [Querying the parent table](https://supabase.com/docs/guides/database/partitions#querying-the-parent-table) [Querying specific partitions](https://supabase.com/docs/guides/database/partitions#querying-specific-partitions) [When to partition your tables](https://supabase.com/docs/guides/database/partitions#when-to-partition-your-tables) [Examples](https://supabase.com/docs/guides/database/partitions#examples) [Range partitioning](https://supabase.com/docs/guides/database/partitions#range-partitioning) [List partitioning](https://supabase.com/docs/guides/database/partitions#list-partitioning) [Hash partitioning](https://supabase.com/docs/guides/database/partitions#hash-partitioning) [Other tools](https://supabase.com/docs/guides/database/partitions#other-tools)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_pgadmin.md">
Database

# Connecting with pgAdmin

* * *

[`pgAdmin`](https://www.pgadmin.org/) is a GUI tool for managing Postgres databases. You can use it to connect to your database via SSL.

1

### Register

Register a new Postgres server.

![Register a new postgres server.](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fdatabase%2Fconnecting-to-postgres%2Fpgadmin%2Fregister-server-pgAdmin--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

2

### Name

Name your server.

![Name Postgres Server.](https://supabase.com/docs/img/guides/database/connecting-to-postgres/pgadmin/name-pg-server.png)

3

### Connect

Add the connection info. Go to your [`Database Settings`](https://supabase.com/dashboard/project/_/settings/database). Make sure `Use connection pooling` is enabled. Switch the connection mode to `Session` and copy your connection parameters. Fill in your Database password that you made when creating your project (It can be reset in Database Settings above if you don't have it).

![Add Connection Info.](https://supabase.com/docs/img/guides/database/connecting-to-postgres/pgadmin/add-pg-server-conn-info.png)

4

### SSL

Download your SSL certificate from Dashboard's [`Database Settings`](https://supabase.com/dashboard/project/_/settings/database).

In pgAdmin, navigate to the Parameters tab and select connection parameter as Root Certificate. Next navigate to the Root certificate input, it will open up a file-picker modal. Select the certificate you downloaded earlier and save the server details. pgAdmin should now be able to connect to your Postgres via SSL.

![Add Connection Info.](https://supabase.com/docs/img/guides/database/connecting-to-postgres/pgadmin/database-settings-host.png)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_postgres_cascade_deletes.md">
Database

# Cascade Deletes

* * *

There are 5 options for foreign key constraint deletes:

1. **CASCADE:** When a row is deleted from the parent table, all related rows in the child tables are deleted as well.
2. **RESTRICT:** When a row is deleted from the parent table, the delete operation is aborted if there are any related rows in the child tables.
3. **SET NULL:** When a row is deleted from the parent table, the values of the foreign key columns in the child tables are set to NULL.
4. **SET DEFAULT:** When a row is deleted from the parent table, the values of the foreign key columns in the child tables are set to their default values.
5. **NO ACTION:** This option is similar to RESTRICT, but it also has the option to be deferred to the end of a transaction. This means that other cascading deletes can run first, and then this delete constraint will only throw an error if there is referenced data remaining _at the end of the transaction_.

These options can be specified when defining a foreign key constraint using the "ON DELETE" clause. For example, the following SQL statement creates a foreign key constraint with the `CASCADE` option:

`
alter table child_table
add constraint fk_parent foreign key (parent_id) references parent_table (id)
on delete cascade;
`

This means that when a row is deleted from the `parent_table`, all related rows in the `child_table` will be deleted as well.

## `RESTRICT` vs `NO ACTION` [\#](https://supabase.com/docs/guides/database/postgres/cascade-deletes\#restrict-vs-no-action)

The difference between `NO ACTION` and `RESTRICT` is subtle and can be a bit confusing.

Both `NO ACTION` and `RESTRICT` are used to prevent deletion of a row in a parent table if there are related rows in a child table. However, there is a subtle difference in how they behave.

When a foreign key constraint is defined with the option `RESTRICT`, it means that if a row in the parent table is deleted, the database will immediately raise an error and prevent the deletion of the row in the parent table. The database will not delete, update or set to NULL any rows in the referenced tables.

When a foreign key constraint is defined with the option `NO ACTION`, it means that if a row in the parent table is deleted, the database will also raise an error and prevent the deletion of the row in the parent table. However unlike `RESTRICT`, `NO ACTION` has the option defer the check using `INITIALLY DEFERRED`. This will only raise the above error _if_ the referenced rows still exist at the end of the transaction.

The difference from `RESTRICT` is that a constraint marked as `NO ACTION INITIALLY DEFERRED` is deferred until the end of the transaction, rather than running immediately. If, for example there is another foreign key constraint between the same tables marked as `CASCADE`, the cascade will occur first and delete the referenced rows, and no error will be thrown by the deferred constraint. Otherwise if there are still rows referencing the parent row by the end of the transaction, an error will be raised just like before. Just like `RESTRICT`, the database will not delete, update or set to NULL any rows in the referenced tables.

In practice, you can use either `NO ACTION` or `RESTRICT` depending on your needs. `NO ACTION` is the default behavior if you do not specify anything. If you prefer to defer the check until the end of the transaction, use `NO ACTION INITIALLY DEFERRED`.

## Example [\#](https://supabase.com/docs/guides/database/postgres/cascade-deletes\#example)

Let's further illustrate the difference with an example. We'll use the following data:

`grandparent`

| id | name |
| --- | --- |
| 1 | Elizabeth |

`parent`

| id | name | `parent_id` |
| --- | --- | --- |
| 1 | Charles | 1 |
| 2 | Diana | 1 |

`child`

| id | name | father | mother |
| --- | --- | --- | --- |
| 1 | William | 1 | 2 |

To create these tables and their data, we run:

`
create table grandparent (
id serial primary key,
name text
);
create table parent (
id serial primary key,
name text,
parent_id integer references grandparent (id)
    on delete cascade
);
create table child (
id serial primary key,
name text,
father integer references parent (id)
    on delete restrict
);
insert into grandparent
(id, name)
values
(1, 'Elizabeth');
insert into parent
(id, name, parent_id)
values
(1, 'Charles', 1);
insert into parent
(id, name, parent_id)
values
(2, 'Diana', 1);
-- We'll just link the father for now
insert into child
(id, name, father)
values
(1, 'William', 1);
`

### `RESTRICT` [\#](https://supabase.com/docs/guides/database/postgres/cascade-deletes\#restrict)

`RESTRICT` will prevent a delete and raise an error:

`
postgres=# delete from grandparent;
ERROR: update or delete on table "parent" violates foreign key constraint "child_father_fkey" on table "child"
DETAIL: Key (id)=(1) is still referenced from table "child".
`

Even though the foreign key constraint between parent and grandparent is `CASCADE`, the constraint between child and father is `RESTRICT`. Therefore an error is raised and no records are deleted.

### `NO ACTION` [\#](https://supabase.com/docs/guides/database/postgres/cascade-deletes\#no-action)

Let's change the child-father relationship to `NO ACTION`:

`
alter table child
drop constraint child_father_fkey;
alter table child
add constraint child_father_fkey foreign key (father) references parent (id)
on delete no action;
`

We see that `NO ACTION` will also prevent a delete and raise an error:

`
postgres=# delete from grandparent;
ERROR: update or delete on table "parent" violates foreign key constraint "child_father_fkey" on table "child"
DETAIL: Key (id)=(1) is still referenced from table "child".
`

### `NO ACTION INITIALLY DEFERRED` [\#](https://supabase.com/docs/guides/database/postgres/cascade-deletes\#no-action-initially-deferred)

We'll change the foreign key constraint between child and father to be `NO ACTION INITIALLY DEFERRED`:

`
alter table child
drop constraint child_father_fkey;
alter table child
add constraint child_father_fkey foreign key (father) references parent (id)
on delete no action initially deferred;
`

Here you will see that `INITIALLY DEFFERED` seems to operate like `NO ACTION` or `RESTRICT`. When we run a delete, it seems to make no difference:

`
postgres=# delete from grandparent;
ERROR: update or delete on table "parent" violates foreign key constraint "child_father_fkey" on table "child"
DETAIL: Key (id)=(1) is still referenced from table "child".
`

But, when we combine it with _other_ constraints, then any other constraints take precedence. For example, let's run the same but add a `mother` column that has a `CASCADE` delete:

`
alter table child
add column mother integer references parent (id)
on delete cascade;
update child
set mother = 2
where id = 1;
`

Then let's run a delete on the `grandparent` table:

`
postgres=# delete from grandparent;
DELETE 1
postgres=# select * from parent;
id | name | parent_id
----+------+-----------
(0 rows)
postgres=# select * from child;
id | name | father | mother
----+------+--------+--------
(0 rows)
`

The `mother` deletion took precedence over the `father`, and so William was deleted. After William was deleted, there was no reference to Charles and so he was free to be deleted, even though previously he wasn't (without `INITIALLY DEFERRED`).

### Is this helpful?

NoYes

### On this page

[RESTRICT vs NO ACTION](https://supabase.com/docs/guides/database/postgres/cascade-deletes#restrict-vs-no-action) [Example](https://supabase.com/docs/guides/database/postgres/cascade-deletes#example) [RESTRICT](https://supabase.com/docs/guides/database/postgres/cascade-deletes#restrict) [NO ACTION](https://supabase.com/docs/guides/database/postgres/cascade-deletes#no-action) [NO ACTION INITIALLY DEFERRED](https://supabase.com/docs/guides/database/postgres/cascade-deletes#no-action-initially-deferred)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_postgres_column_level_security.md">
Database

# Column Level Security

* * *

PostgreSQL's [Row Level Security (RLS)](https://www.postgresql.org/docs/current/ddl-rowsecurity.html) gives you granular control over who can access rows of data. However, it doesn't give you control over which columns they can access within rows. Sometimes you want to restrict access to specific columns in your database. Column Level Privileges allows you to do just that.

This is an advanced feature. We do not recommend using column-level privileges for most users.
Instead, we recommend using RLS policies in combination with a dedicated table for handling user
roles.

## Policies at the row level [\#](https://supabase.com/docs/guides/database/postgres/column-level-security\#policies-at-the-row-level)

Policies in Row Level Security (RLS) are used to restrict access to rows in a table. Think of them like adding a `WHERE` clause to every query.

For example, let's assume you have a `posts` table with the following columns:

- `id`
- `user_id`
- `title`
- `content`
- `created_at`
- `updated_at`

You can restrict updates to just the user who created it using [RLS](https://supabase.com/docs/guides/auth#row-level-security), with the following policy:

`
create policy "Allow update for owners" on posts for
update
using ((select auth.uid()) = user_id);
`

However, this gives the post owner full access to update the row, including all of the columns.

## Privileges at the column level [\#](https://supabase.com/docs/guides/database/postgres/column-level-security\#privileges-at-the-column-level)

To restrict access to columns, you can use [Privileges](https://www.postgresql.org/docs/current/ddl-priv.html).

There are two types of privileges in Postgres:

1. **table-level**: Grants the privilege on all columns in the table.
2. **column-level** Grants the privilege on a specific column in the table.

You can have both types of privileges on the same table. If you have both, and you revoke the column-level privilege, the table-level privilege will still be in effect.

By default, our table will have a table-level `UPDATE` privilege, which means that the `authenticated` role can update all the columns in the table.

`
revoke
update
on table public.posts
from
authenticated;
grant
update
(title, content) on table public.posts to authenticated;
`

In the above example, we are revoking the table-level `UPDATE` privilege from the `authenticated` role and granting a column-level `UPDATE` privilege on just the `title` and `content` columns.

If we want to restrict access to updating the `title` column:

`
revoke
update
(title) on table public.posts
from
authenticated;
`

This time, we are revoking the column-level `UPDATE` privilege of the `title` column from the `authenticated` role. We didn't need to revoke the table-level `UPDATE` privilege because it's already revoked.

## Manage column privileges in the Dashboard [\#](https://supabase.com/docs/guides/database/postgres/column-level-security\#manage-column-privileges-in-the-dashboard)

You can view and edit the privileges in the [Supabase Studio](https://supabase.com/dashboard/project/_/database/column-privileges).

![Column level privileges](https://supabase.com/docs/img/guides/privileges/column-level-privileges-2.png)

## Manage column privileges in migrations [\#](https://supabase.com/docs/guides/database/postgres/column-level-security\#manage-column-privileges-in-migrations)

While you can manage privileges directly from the Dashboard, as your project grows you may want to manage them in your migrations. Read about database migrations in the [Local Development](https://supabase.com/docs/guides/deployment/database-migrations) guide.

1

### Create a migration file

To get started, generate a [new migration](https://supabase.com/docs/reference/cli/supabase-migration-new) to store the SQL needed to create your table along with row and column-level privileges.

`
supabase migration new create_posts_table
`

2

### Add the SQL to your migration file

This creates a new migration: supabase/migrations/<timestamp>
\_create\_posts\_table.sql.

To that file, add the SQL to create this `posts` table with row and column-level privileges.

`
create table
posts (
id bigint primary key generated always as identity,
user_id text,
title text,
content text,
created_at timestamptz default now()
updated_at timestamptz default now()
);
-- Add row-level security
create policy "Allow update for owners" on posts for
update
using ((select auth.uid()) = user_id);
-- Add column-level security
revoke
update
(title) on table public.posts
from
authenticated;
`

## Considerations when using column-level privileges [\#](https://supabase.com/docs/guides/database/postgres/column-level-security\#considerations-when-using-column-level-privileges)

- If you turn off a column privilege you won't be able to use that column at all.
- All operations (insert, update, delete) as well as using `select *` will fail.

### Is this helpful?

NoYes

### On this page

[Policies at the row level](https://supabase.com/docs/guides/database/postgres/column-level-security#policies-at-the-row-level) [Privileges at the column level](https://supabase.com/docs/guides/database/postgres/column-level-security#privileges-at-the-column-level) [Manage column privileges in the Dashboard](https://supabase.com/docs/guides/database/postgres/column-level-security#manage-column-privileges-in-the-dashboard) [Manage column privileges in migrations](https://supabase.com/docs/guides/database/postgres/column-level-security#manage-column-privileges-in-migrations) [Considerations when using column-level privileges](https://supabase.com/docs/guides/database/postgres/column-level-security#considerations-when-using-column-level-privileges)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_postgres_configuration.md">
Database

# Database configuration

## Updating the default configuration for your Postgres database.

* * *

Postgres provides a set of sensible defaults for you database size. In some cases, these defaults can be updated. We do not recommend changing these defaults unless you know what you're doing.

## Timeouts [\#](https://supabase.com/docs/guides/database/postgres/configuration\#timeouts)

See the [Timeouts](https://supabase.com/docs/guides/database/postgres/timeouts) section.

## Statement optimization [\#](https://supabase.com/docs/guides/database/postgres/configuration\#statement-optimization)

All Supabase projects come with the [`pg_stat_statements`](https://www.postgresql.org/docs/current/pgstatstatements.html) extension installed, which tracks planning and execution statistics for all statements executed against it. These statistics can be used in order to diagnose the performance of your project.

This data can further be used in conjunction with the [`explain`](https://www.postgresql.org/docs/current/using-explain.html) functionality of Postgres to optimize your usage.

## Managing timezones [\#](https://supabase.com/docs/guides/database/postgres/configuration\#managing-timezones)

Every Supabase database is set to UTC timezone by default. We strongly recommend keeping it this way, even if your users are in a different location.
This is because it makes it much easier to calculate differences between timezones if you adopt the mental model that everything in your database is in UTC time.

### Change timezone [\#](https://supabase.com/docs/guides/database/postgres/configuration\#change-timezone)

SQL

`
alter database postgres
set timezone to 'America/New_York';
`

### Full list of timezones [\#](https://supabase.com/docs/guides/database/postgres/configuration\#full-list-of-timezones)

Get a full list of timezones supported by your database. This will return the following columns:

- `name`: Time zone name
- `abbrev`: Time zone abbreviation
- `utc_offset`: Offset from UTC (positive means east of Greenwich)
- `is_dst`: True if currently observing daylight savings

SQL

`
select name, abbrev, utc_offset, is_dst
from pg_timezone_names()
order by name;
`

### Search for a specific timezone [\#](https://supabase.com/docs/guides/database/postgres/configuration\#search-for-a-specific-timezone)

Use `ilike` (case insensitive search) to find specific timezones.

SQL

`
select *
from pg_timezone_names()
where name ilike '%york%';
`

### Is this helpful?

NoYes

### On this page

[Timeouts](https://supabase.com/docs/guides/database/postgres/configuration#timeouts) [Statement optimization](https://supabase.com/docs/guides/database/postgres/configuration#statement-optimization) [Managing timezones](https://supabase.com/docs/guides/database/postgres/configuration#managing-timezones) [Change timezone](https://supabase.com/docs/guides/database/postgres/configuration#change-timezone) [Full list of timezones](https://supabase.com/docs/guides/database/postgres/configuration#full-list-of-timezones) [Search for a specific timezone](https://supabase.com/docs/guides/database/postgres/configuration#search-for-a-specific-timezone)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_postgres_custom_claims_and_role_based_access_control_rbac.md">
Database

# Custom Claims & Role-based Access Control (RBAC)

* * *

Custom Claims are special attributes attached to a user that you can use to control access to portions of your application. For example:

`
{
"user_role": "admin",
"plan": "TRIAL",
"user_level": 100,
"group_name": "Super Guild!",
"joined_on": "2022-05-20T14:28:18.217Z",
"group_manager": false,
"items": ["toothpick", "string", "ring"]
}
`

To implement Role-Based Access Control (RBAC) with `custom claims`, use a [Custom Access Token Auth Hook](https://supabase.com/docs/guides/auth/auth-hooks#hook-custom-access-token). This hook runs before a token is issued. You can use it to add additional claims to the user's JWT.

This guide uses the [Slack Clone example](https://github.com/supabase/supabase/tree/master/examples/slack-clone/nextjs-slack-clone) to demonstrate how to add a `user_role` claim and use it in your [Row Level Security (RLS) policies](https://supabase.com/docs/guides/database/postgres/row-level-security).

## Create a table to track user roles and permissions [\#](https://supabase.com/docs/guides/database/postgres/custom-claims-and-role-based-access-control-rbac\#create-a-table-to-track-user-roles-and-permissions)

In this example, you will implement two user roles with specific permissions:

- `moderator`: A moderator can delete all messages but not channels.
- `admin`: An admin can delete all messages and channels.

supabase/migrations/init.sql

`
-- Custom types
create type public.app_permission as enum ('channels.delete', 'messages.delete');
create type public.app_role as enum ('admin', 'moderator');
-- USER ROLES
create table public.user_roles (
id        bigint generated by default as identity primary key,
user_id   uuid references auth.users on delete cascade not null,
role      app_role not null,
unique (user_id, role)
);
comment on table public.user_roles is 'Application roles for each user.';
-- ROLE PERMISSIONS
create table public.role_permissions (
id           bigint generated by default as identity primary key,
role         app_role not null,
permission   app_permission not null,
unique (role, permission)
);
comment on table public.role_permissions is 'Application permissions for each role.';
`

For the [full schema](https://github.com/supabase/supabase/blob/master/examples/slack-clone/nextjs-slack-clone/README.md), see the example application on [GitHub](https://github.com/supabase/supabase/tree/master/examples/slack-clone/nextjs-slack-clone).

You can now manage your roles and permissions in SQL. For example, to add the mentioned roles and permissions from above, run:

supabase/seed.sql

`
insert into public.role_permissions (role, permission)
values
('admin', 'channels.delete'),
('admin', 'messages.delete'),
('moderator', 'messages.delete');
`

## Create Auth Hook to apply user role [\#](https://supabase.com/docs/guides/database/postgres/custom-claims-and-role-based-access-control-rbac\#create-auth-hook-to-apply-user-role)

The [Custom Access Token Auth Hook](https://supabase.com/docs/guides/auth/auth-hooks#hook-custom-access-token) runs before a token is issued. You can use it to edit the JWT.

PL/pgSQL (best performance)JavaScript (PLV8)

supabase/migrations/auth\_hook.sql

`
-- Create the auth hook function
create or replace function public.custom_access_token_hook(event jsonb)
returns jsonb
language plpgsql
stable
as $$
declare
    claims jsonb;
    user_role public.app_role;
begin
    -- Fetch the user role in the user_roles table
    select role into user_role from public.user_roles where user_id = (event->>'user_id')::uuid;
    claims := event->'claims';
    if user_role is not null then
      -- Set the claim
      claims := jsonb_set(claims, '{user_role}', to_jsonb(user_role));
    else
      claims := jsonb_set(claims, '{user_role}', 'null');
    end if;
    -- Update the 'claims' object in the original event
    event := jsonb_set(event, '{claims}', claims);
    -- Return the modified or original event
    return event;
end;
$$;
grant usage on schema public to supabase_auth_admin;
grant execute
on function public.custom_access_token_hook
to supabase_auth_admin;
revoke execute
on function public.custom_access_token_hook
from authenticated, anon, public;
grant all
on table public.user_roles
to supabase_auth_admin;
revoke all
on table public.user_roles
from authenticated, anon, public;
create policy "Allow auth admin to read user roles" ON public.user_roles
as permissive for select
to supabase_auth_admin
using (true)
`

### Enable the hook [\#](https://supabase.com/docs/guides/database/postgres/custom-claims-and-role-based-access-control-rbac\#enable-the-hook)

In the dashboard, navigate to [`Authentication > Hooks (Beta)`](https://supabase.com/dashboard/project/_/auth/hooks) and select the appropriate Postgres function from the dropdown menu.

When developing locally, follow the [local development](https://supabase.com/docs/guides/auth/auth-hooks#local-development) instructions.

To learn more about Auth Hooks, see the [Auth Hooks docs](https://supabase.com/docs/guides/auth/auth-hooks).

## Accessing custom claims in RLS policies [\#](https://supabase.com/docs/guides/database/postgres/custom-claims-and-role-based-access-control-rbac\#accessing-custom-claims-in-rls-policies)

To utilize Role-Based Access Control (RBAC) in Row Level Security (RLS) policies, create an `authorize` method that reads the user's role from their JWT and checks the role's permissions:

supabase/migrations/init.sql

`
create or replace function public.authorize(
requested_permission app_permission
)
returns boolean as $$
declare
bind_permissions int;
user_role public.app_role;
begin
  -- Fetch user role once and store it to reduce number of calls
select (auth.jwt() ->> 'user_role')::public.app_role into user_role;
select count(*)
into bind_permissions
from public.role_permissions
where role_permissions.permission = requested_permission
    and role_permissions.role = user_role;
return bind_permissions > 0;
end;
$$ language plpgsql stable security definer set search_path = '';
`

You can read more about using functions in RLS policies in the [RLS guide](https://supabase.com/docs/guides/database/postgres/row-level-security#using-functions).

You can then use the `authorize` method within your RLS policies. For example, to enable the desired delete access, you would add the following policies:

`
create policy "Allow authorized delete access" on public.channels for delete to authenticated using ( (SELECT authorize('channels.delete')) );
create policy "Allow authorized delete access" on public.messages for delete to authenticated using ( (SELECT authorize('messages.delete')) );
`

## Accessing custom claims in your application [\#](https://supabase.com/docs/guides/database/postgres/custom-claims-and-role-based-access-control-rbac\#accessing-custom-claims-in-your-application)

The auth hook will only modify the access token JWT but not the auth response. Therefore, to access the custom claims in your application, e.g. your browser client, or server-side middleware, you will need to decode the `access_token` JWT on the auth session.

In a JavaScript client application you can for example use the [`jwt-decode` package](https://www.npmjs.com/package/jwt-decode):

`
import { jwtDecode } from 'jwt-decode'
const { subscription: authListener } = supabase.auth.onAuthStateChange(async (event, session) => {
if (session) {
    const jwt = jwtDecode(session.access_token)
    const userRole = jwt.user_role
}
})
`

For server-side logic you can use packages like [`express-jwt`](https://github.com/auth0/express-jwt), [`koa-jwt`](https://github.com/stiang/koa-jwt), [`PyJWT`](https://github.com/jpadilla/pyjwt), [dart\_jsonwebtoken](https://pub.dev/packages/dart_jsonwebtoken), [Microsoft.AspNetCore.Authentication.JwtBearer](https://www.nuget.org/packages/Microsoft.AspNetCore.Authentication.JwtBearer), etc.

## Conclusion [\#](https://supabase.com/docs/guides/database/postgres/custom-claims-and-role-based-access-control-rbac\#conclusion)

You now have a robust system in place to manage user roles and permissions within your database that automatically propagates to Supabase Auth.

## More resources [\#](https://supabase.com/docs/guides/database/postgres/custom-claims-and-role-based-access-control-rbac\#more-resources)

- [Auth Hooks](https://supabase.com/docs/guides/auth/auth-hooks)
- [Row Level Security](https://supabase.com/docs/guides/database/postgres/row-level-security)
- [RLS Functions](https://supabase.com/docs/guides/database/postgres/row-level-security#using-functions)
- [Next.js Slack Clone Example](https://github.com/supabase/supabase/tree/master/examples/slack-clone/nextjs-slack-clone)

### Is this helpful?

NoYes

### On this page

[Create a table to track user roles and permissions](https://supabase.com/docs/guides/database/postgres/custom-claims-and-role-based-access-control-rbac#create-a-table-to-track-user-roles-and-permissions) [Create Auth Hook to apply user role](https://supabase.com/docs/guides/database/postgres/custom-claims-and-role-based-access-control-rbac#create-auth-hook-to-apply-user-role) [Enable the hook](https://supabase.com/docs/guides/database/postgres/custom-claims-and-role-based-access-control-rbac#enable-the-hook) [Accessing custom claims in RLS policies](https://supabase.com/docs/guides/database/postgres/custom-claims-and-role-based-access-control-rbac#accessing-custom-claims-in-rls-policies) [Accessing custom claims in your application](https://supabase.com/docs/guides/database/postgres/custom-claims-and-role-based-access-control-rbac#accessing-custom-claims-in-your-application) [Conclusion](https://supabase.com/docs/guides/database/postgres/custom-claims-and-role-based-access-control-rbac#conclusion) [More resources](https://supabase.com/docs/guides/database/postgres/custom-claims-and-role-based-access-control-rbac#more-resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_postgres_dropping_all_tables_in_schema.md">
Database

# Drop all tables in a PostgreSQL schema

* * *

Execute the following query to drop all tables in a given schema.
Replace `my-schema-name` with the name of your schema. In Supabase, the default schema is `public`.

This deletes all tables and their associated data. Ensure you have a recent [backup](https://supabase.com/docs/guides/platform/backups) before proceeding.

`
do $$ declare
    r record;
begin
    for r in (select tablename from pg_tables where schemaname = 'my-schema-name') loop
        execute 'drop table if exists ' || quote_ident(r.tablename) || ' cascade';
    end loop;
end $$;
`

This query works by listing out all the tables in the given schema and then executing a `drop table` for each (hence the `for... loop`).

You can run this query using the [SQL Editor](https://supabase.com/dashboard/project/_/sql) in the Supabase Dashboard, or via `psql` if you're [connecting directly to the database](https://supabase.com/docs/guides/database/connecting-to-postgres#direct-connections).

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_postgres_enums.md">
Database

# Managing Enums in Postgres

* * *

Enums in Postgres are a custom data type. They allow you to define a set of values (or labels) that a column can hold. They are useful when you have a fixed set of possible values for a column.

## Creating enums [\#](https://supabase.com/docs/guides/database/postgres/enums\#creating-enums)

You can define a Postgres Enum using the `create type` statement. Here's an example:

`
create type mood as enum (
'happy',
'sad',
'excited',
'calm'
);
`

In this example, we've created an Enum called "mood" with four possible values.

## When to use enums [\#](https://supabase.com/docs/guides/database/postgres/enums\#when-to-use-enums)

There is a lot of overlap between Enums and foreign keys. Both can be used to define a set of values for a column. However, there are some advantages to using Enums:

- Performance: You can query a single table instead of finding the value from a lookup table.
- Simplicity: Generally the SQL is easier to read and write.

There are also some disadvantages to using Enums:

- Limited Flexibility: Adding and removing values requires modifying the database schema (i.e.: using migrations) rather than adding data to a table.
- Maintenance Overhead: Enum types require ongoing maintenance. If your application's requirements change frequently, maintaining enums can become burdensome.

In general you should only use Enums when the list of values is small, fixed, and unlikely to change often. Things like "a list of continents" or "a list of departments" are good candidates for Enums.

## Using enums in tables [\#](https://supabase.com/docs/guides/database/postgres/enums\#using-enums-in-tables)

To use the Enum in a table, you can define a column with the Enum type. For example:

`
create table person (
id serial primary key,
name text,
current_mood mood
);
`

Here, the `current_mood` column can only have values from the "mood" Enum.

### Inserting data with enums [\#](https://supabase.com/docs/guides/database/postgres/enums\#inserting-data-with-enums)

You can insert data into a table with Enum columns by specifying one of the Enum values:

`
insert into person
(name, current_mood)
values
('Alice', 'happy');
`

### Querying data with enums [\#](https://supabase.com/docs/guides/database/postgres/enums\#querying-data-with-enums)

When querying data, you can filter and compare Enum values as usual:

`
select *
from person
where current_mood = 'sad';
`

## Managing enums [\#](https://supabase.com/docs/guides/database/postgres/enums\#managing-enums)

You can manage your Enums using the `alter type` statement. Here are some examples:

### Updating enum values [\#](https://supabase.com/docs/guides/database/postgres/enums\#updating-enum-values)

You can update the value of an Enum column:

`
update person
set current_mood = 'excited'
where name = 'Alice';
`

### Adding enum values [\#](https://supabase.com/docs/guides/database/postgres/enums\#adding-enum-values)

To add new values to an existing Postgres Enum, you can use the `ALTER TYPE` statement. Here's how you can do it:

Let's say you have an existing Enum called `mood`, and you want to add a new value, `content`:

`
alter type mood add value 'content';
`

### Removing enum values [\#](https://supabase.com/docs/guides/database/postgres/enums\#removing-enum-values)

Even though it is possible, it is unsafe to remove enum values once they have been created. It's better to leave the enum value in place.

Read the [Postgres mailing list](https://www.postgresql.org/message-id/21012.1459434338%40sss.pgh.pa.us) for more information:

There is no `ALTER TYPE DELETE VALUE` in Postgres. Even if you delete every occurrence of an Enum value within a table (and vacuumed away those rows), the target value could still exist in upper index pages. If you delete the `pg_enum` entry you'll break the index.

### Getting a list of enum values [\#](https://supabase.com/docs/guides/database/postgres/enums\#getting-a-list-of-enum-values)

Check your existing Enum values by querying the enum\_range function:

`
select enum_range(null::mood);
`

## Resources [\#](https://supabase.com/docs/guides/database/postgres/enums\#resources)

- Official Postgres Docs: [Enumerated Types](https://www.postgresql.org/docs/current/datatype-enum.html)

### Is this helpful?

NoYes

### On this page

[Creating enums](https://supabase.com/docs/guides/database/postgres/enums#creating-enums) [When to use enums](https://supabase.com/docs/guides/database/postgres/enums#when-to-use-enums) [Using enums in tables](https://supabase.com/docs/guides/database/postgres/enums#using-enums-in-tables) [Inserting data with enums](https://supabase.com/docs/guides/database/postgres/enums#inserting-data-with-enums) [Querying data with enums](https://supabase.com/docs/guides/database/postgres/enums#querying-data-with-enums) [Managing enums](https://supabase.com/docs/guides/database/postgres/enums#managing-enums) [Updating enum values](https://supabase.com/docs/guides/database/postgres/enums#updating-enum-values) [Adding enum values](https://supabase.com/docs/guides/database/postgres/enums#adding-enum-values) [Removing enum values](https://supabase.com/docs/guides/database/postgres/enums#removing-enum-values) [Getting a list of enum values](https://supabase.com/docs/guides/database/postgres/enums#getting-a-list-of-enum-values) [Resources](https://supabase.com/docs/guides/database/postgres/enums#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_postgres_first_row_in_group.md">
Database

# Select first row for each group in PostgreSQL

* * *

Given a table `seasons`:

| id | team | points |
| --- | :-: | --: |
| 1 | Liverpool | 82 |
| 2 | Liverpool | 84 |
| 3 | Brighton | 34 |
| 4 | Brighton | 28 |
| 5 | Liverpool | 79 |

We want to find the rows containing the maximum number of points _per team_.

The expected output we want is:

| id | team | points |
| --- | :-: | --: |
| 3 | Brighton | 34 |
| 2 | Liverpool | 84 |

From the [SQL Editor](https://supabase.com/dashboard/project/_/sql), you can run a query like:

`
select distinct
on (team) id,
team,
points
from
seasons
order BY
id,
points desc,
team;
`

The important bits here are:

- The `desc` keyword to order the `points` from highest to lowest.
- The `distinct` keyword that tells Postgres to only return a single row per team.

This query can also be executed via `psql` or any other query editor if you prefer to [connect directly to the database](https://supabase.com/docs/guides/database/connecting-to-postgres#direct-connections).

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_postgres_indexes.md">
Database

# Managing Indexes in PostgreSQL

* * *

An index makes your Postgres queries faster. The index is like a "table of contents" for your data - a reference list which allows queries to quickly locate a row in a given table without needing to scan the entire table (which in large tables can take a long time).

Indexes can be structured in a few different ways. The type of index chosen depends on the values you are indexing. By far the most common index type, and the default in Postgres, is the B-Tree. A B-Tree is the generalized form of a binary search tree, where nodes can have more than two children.

Even though indexes improve query performance, the Postgres query planner may not always make use of a given index when choosing which optimizations to make. Additionally indexes come with some overhead - additional writes and increased storage - so it's useful to understand how and when to use indexes, if at all.

## Create an index [\#](https://supabase.com/docs/guides/database/postgres/indexes\#create-an-index)

Let's take an example table:

`
create table persons (
id bigint generated by default as identity primary key,
age int,
height int,
weight int,
name text,
deceased boolean
);
`

All the queries in this guide can be run using the [SQL Editor](https://supabase.com/dashboard/project/_/sql) in the Supabase Dashboard, or via `psql` if you're [connecting directly to the database](https://supabase.com/docs/guides/database/connecting-to-postgres#direct-connections).

We might want to frequently query users based on their age:

`
select name from persons where age = 32;
`

Without an index, Postgres will scan every row in the table to find equality matches on age.

You can verify this by doing an explain on the query:

`
explain select name from persons where age = 32;
`

Outputs:

`
Seq Scan on persons  (cost=0.00..22.75 rows=x width=y)
Filter: (age = 32)
`

To add a simple B-Tree index you can run:

`
create index idx_persons_age on persons (age);
`

It can take a long time to build indexes on large datasets and the default behaviour of `create index` is to lock the table from writes.

Luckily Postgres provides us with `create index concurrently` which prevents blocking writes on the table, but does take a bit longer to build.

Here is a simplified diagram of the index we just created (note that in practice, nodes actually have more than two children).

![B-Tree index example in Postgres](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fdatabase%2Fmanaging-indexes%2Fcreating-indexes--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

You can see that in any large data set, traversing the index to locate a given value can be done in much less operations (O(log n)) than compared to scanning the table one value at a time from top to bottom (O(n)).

## Partial indexes [\#](https://supabase.com/docs/guides/database/postgres/indexes\#partial-indexes)

If you are frequently querying a subset of rows then it may be more efficient to build a partial index. In our example, perhaps we only want to match on `age` where `deceased is false`. We could build a partial index:

`
create index idx_living_persons_age on persons (age)
where deceased is false;
`

## Ordering indexes [\#](https://supabase.com/docs/guides/database/postgres/indexes\#ordering-indexes)

By default B-Tree indexes are sorted in ascending order, but sometimes you may want to provide a different ordering. Perhaps our application has a page featuring the top 10 oldest people. Here we would want to sort in descending order, and include `NULL` values last. For this we can use:

`
create index idx_persons_age_desc on persons (age desc nulls last);
`

## Reindexing [\#](https://supabase.com/docs/guides/database/postgres/indexes\#reindexing)

After a while indexes can become stale and may need rebuilding. Postgres provides a `reindex` command for this, but due to Postgres locks being placed on the index during this process, you may want to make use of the `concurrent` keyword.

`
reindex index concurrently idx_persons_age;
`

Alternatively you can reindex all indexes on a particular table:

`
reindex table concurrently persons;
`

Take note that `reindex` can be used inside a transaction, but `reindex [index/table] concurrently` cannot.

## Index Advisor [\#](https://supabase.com/docs/guides/database/postgres/indexes\#index-advisor)

Indexes can improve query performance of your tables as they grow. The Supabase Dashboard offers an Index Advisor, which suggests potential indexes to add to your tables.

For more information on the Index Advisor and its suggestions, see the [`index_advisor` extension](https://supabase.com/docs/guides/database/extensions/index_advisor).

To use the Dashboard Index Advisor:

1. Go to the [Query Performance](https://supabase.com/dashboard/project/_/advisors/query-performance) page.
2. Click on a query to bring up the Details side panel.
3. Select the Indexes tab.
4. Enable Index Advisor if prompted.

### Understanding Index Advisor results [\#](https://supabase.com/docs/guides/database/postgres/indexes\#understanding-index-advisor-results)

The Indexes tab shows the existing indexes used in the selected query. Note that indexes suggested in the "New Index Recommendations" section may not be used when you create them. Postgres' query planner may intentionally ignore an available index if it determines that the query will be faster without. For example, on a small table, a sequential scan might be faster than an index scan. In that case, the planner will switch to using the index as the table size grows, helping to future proof the query.

If additional indexes might improve your query, the Index Advisor shows the suggested indexes with the estimated improvement in startup and total costs:

- Startup cost is the cost to fetch the first row
- Total cost is the cost to fetch all the rows

Costs are in arbitrary units, where a single sequential page read costs 1.0 units.

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2FbBu_V8CfWgM%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Create an index](https://supabase.com/docs/guides/database/postgres/indexes#create-an-index) [Partial indexes](https://supabase.com/docs/guides/database/postgres/indexes#partial-indexes) [Ordering indexes](https://supabase.com/docs/guides/database/postgres/indexes#ordering-indexes) [Reindexing](https://supabase.com/docs/guides/database/postgres/indexes#reindexing) [Index Advisor](https://supabase.com/docs/guides/database/postgres/indexes#index-advisor) [Understanding Index Advisor results](https://supabase.com/docs/guides/database/postgres/indexes#understanding-index-advisor-results)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings


![B-Tree index example in Postgres](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fdatabase%2Fmanaging-indexes%2Fcreating-indexes--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)
</file>

<file path="supabase_com_docs_guides_database_postgres_js.md">
Database

# Postgres.js

* * *

### Connecting with Postgres.js [\#](https://supabase.com/docs/guides/database/postgres-js\#connecting-with-postgresjs)

[Postgres.js](https://github.com/porsager/postgres) is a full-featured Postgres client for Node.js and Deno.

1

### Install

Install Postgres.js and related dependencies.

`
npm i postgres
`

2

### Connect

Create a `db.js` file with the connection details.

To get your connection details, go to your [`Database Settings`](https://supabase.com/dashboard/project/_/settings/database). Make sure `Use connection pooling` is enabled. Choose `Transaction Mode` if you're on a platform with transient connections, such as a serverless function, and `Session Mode` if you have a long-lived connection. Copy the URI and save it as the environment variable `DATABASE_URL`.

`
// db.js
import postgres from 'postgres'
const connectionString = process.env.DATABASE_URL
const sql = postgres(connectionString)
export default sql
`

3

### Execute commands

Use the connection to execute commands.

``
import sql from './db.js'
async function getUsersOver(age) {
const users = await sql`
    select name, age
    from users
    where age > ${ age }
`
// users = Result [{ name: "Walter", age: 80 }, { name: 'Murray', age: 68 }, ...]
return users
}
``

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_postgres_roles_superuser.md">
Database

# Roles, superuser access and unsupported operations

* * *

Supabase provides the default `postgres` role to all instances deployed. Superuser access is not given as it allows destructive operations to be performed on the database.

To ensure you are not impacted by this, additional privileges are granted to the `postgres` user to allow it to run some operations that are normally restricted to superusers.

However, this does mean that some operations, that typically require `superuser` privileges, are not available on Supabase. These are documented below:

## Unsupported operations [\#](https://supabase.com/docs/guides/database/postgres/roles-superuser\#unsupported-operations)

- `CREATE SUBSCRIPTION`
- `CREATE EVENT TRIGGER`
- `COPY ... FROM PROGRAM`
- `ALTER USER ... WITH SUPERUSER`

### Is this helpful?

NoYes

### On this page

[Unsupported operations](https://supabase.com/docs/guides/database/postgres/roles-superuser#unsupported-operations)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_postgres_roles.md">
Database

# Postgres Roles

## Managing access to your Postgres database and configuring permissions.

* * *

Postgres manages database access permissions using the concept of roles. Generally you wouldn't use these roles for your own application - they are mostly for configuring _system access_ to your database. If you want to configure _application access_, then you should use [Row Level Security](https://supabase.com/docs/guides/database/postgres/row-level-security) (RLS). You can also implement [Role-based Access Control](https://supabase.com/docs/guides/database/postgres/custom-claims-and-role-based-access-control-rbac) on top of RLS.

## Users vs roles [\#](https://supabase.com/docs/guides/database/postgres/roles\#users-vs-roles)

In Postgres, roles can function as users or groups of users. Users are roles with login privileges, while groups (also known as role groups) are roles that don't have login privileges but can be used to manage permissions for multiple users.

## Creating roles [\#](https://supabase.com/docs/guides/database/postgres/roles\#creating-roles)

You can create a role using the `create role` command:

`
create role "role_name";
`

## Creating users [\#](https://supabase.com/docs/guides/database/postgres/roles\#creating-users)

Roles and users are essentially the same in Postgres, however if you want to use password-logins for a specific role, then you can use `WITH LOGIN PASSWORD`:

`
create role "role_name" with login password 'extremely_secure_password';
`

## Passwords [\#](https://supabase.com/docs/guides/database/postgres/roles\#passwords)

Your Postgres database is the core of your Supabase project, so it's important that every role has a strong, secure password at all times. Here are some tips for creating a secure password:

- Use a password manager to generate it.
- Make a long password (12 characters at least).
- Don't use any common dictionary words.
- Use both upper and lower case characters, numbers, and special symbols.

### Special symbols in passwords [\#](https://supabase.com/docs/guides/database/postgres/roles\#special-symbols-in-passwords)

If you use special symbols in your Postgres password, you must remember to [percent-encode](https://en.wikipedia.org/wiki/Percent-encoding) your password later if using the Postgres connection string, for example, `postgresql://postgres.projectref:p%3Dword@aws-0-us-east-1.pooler.supabase.com:6543/postgres`

### Changing your project password [\#](https://supabase.com/docs/guides/database/postgres/roles\#changing-your-project-password)

When you created your project you were also asked to enter a password. This is actually the password for the `postgres` role in your database. You can update this from the Dashboard under the [database settings](https://supabase.com/dashboard/project/_/settings/database) page. You should _never_ give this to third-party service unless you absolutely trust them. Instead, we recommend that you create a new user for every service that you want to give access too. This will also help you with debugging - you can see every query that each role is executing in your database within `pg_stat_statements`.

Changing the password does not result in any downtime. All connected services, such as PostgREST, PgBouncer, and other Supabase managed services, are automatically updated to use the latest password to ensure availability. However, if you have any external services connecting to the Supabase database using hardcoded username/password credentials, a manual update will be required.

## Granting permissions [\#](https://supabase.com/docs/guides/database/postgres/roles\#granting-permissions)

Roles can be granted various permissions on database objects using the `GRANT` command. Permissions include `SELECT`, `INSERT`, `UPDATE`, and `DELETE`. You can configure access to almost any object inside your database - including tables, views, functions, and triggers.

## Revoking permissions [\#](https://supabase.com/docs/guides/database/postgres/roles\#revoking-permissions)

Permissions can be revoked using the `REVOKE` command:

`
REVOKE permission_type ON object_name FROM role_name;
`

## Role hierarchy [\#](https://supabase.com/docs/guides/database/postgres/roles\#role-hierarchy)

Roles can be organized in a hierarchy, where one role can inherit permissions from another. This simplifies permission management, as you can define permissions at a higher level and have them automatically apply to all child roles.

### Role inheritance [\#](https://supabase.com/docs/guides/database/postgres/roles\#role-inheritance)

To create a role hierarchy, you first need to create the parent and child roles. The child role will inherit permissions from its parent. Child roles can be added using the INHERIT option when creating the role:

`
create role "child_role_name" inherit "parent_role_name";
`

### Preventing inheritance [\#](https://supabase.com/docs/guides/database/postgres/roles\#preventing-inheritance)

In some cases, you might want to prevent a role from having a child relationship (typically superuser roles). You can prevent inheritance relations using `NOINHERIT`:

`
alter role "child_role_name" noinherit;
`

## Supabase roles [\#](https://supabase.com/docs/guides/database/postgres/roles\#supabase-roles)

Postgres comes with a set of [predefined roles](https://www.postgresql.org/docs/current/predefined-roles.html). Supabase extends this with a default set of roles which are configured on your database when you start a new project:

### `postgres` [\#](https://supabase.com/docs/guides/database/postgres/roles\#postgres)

The default Postgres role. This has admin privileges.

### `anon` [\#](https://supabase.com/docs/guides/database/postgres/roles\#anon)

For unauthenticated, public access. This is the role which the API (PostgREST) will use when a user _is not_ logged in.

### `authenticator` [\#](https://supabase.com/docs/guides/database/postgres/roles\#authenticator)

A special role for the API (PostgREST). It has very limited access, and is used to validate a JWT and then
"change into" another role determined by the JWT verification.

### `authenticated` [\#](https://supabase.com/docs/guides/database/postgres/roles\#authenticated)

For "authenticated access." This is the role which the API (PostgREST) will use when a user _is_ logged in.

### `service_role` [\#](https://supabase.com/docs/guides/database/postgres/roles\#servicerole)

For elevated access. This role is used by the API (PostgREST) to bypass Row Level Security.

### `supabase_auth_admin` [\#](https://supabase.com/docs/guides/database/postgres/roles\#supabaseauthadmin)

Used by the Auth middleware to connect to the database and run migration. Access is scoped to the `auth` schema.

### `supabase_storage_admin` [\#](https://supabase.com/docs/guides/database/postgres/roles\#supabasestorageadmin)

Used by the Auth middleware to connect to the database and run migration. Access is scoped to the `storage` schema.

### `dashboard_user` [\#](https://supabase.com/docs/guides/database/postgres/roles\#dashboarduser)

For running commands via the Supabase UI.

### `supabase_admin` [\#](https://supabase.com/docs/guides/database/postgres/roles\#supabaseadmin)

An internal role Supabase uses for administrative tasks, such as running upgrades and automations.

## Resources [\#](https://supabase.com/docs/guides/database/postgres/roles\#resources)

- Official Postgres docs: [Database Roles](https://www.postgresql.org/docs/current/database-roles.html)
- Official Postgres docs: [Role Membership](https://www.postgresql.org/docs/current/role-membership.html)
- Official Postgres docs: [Function Permissions](https://www.postgresql.org/docs/current/perm-functions.html)

### Is this helpful?

NoYes

### On this page

[Users vs roles](https://supabase.com/docs/guides/database/postgres/roles#users-vs-roles) [Creating roles](https://supabase.com/docs/guides/database/postgres/roles#creating-roles) [Creating users](https://supabase.com/docs/guides/database/postgres/roles#creating-users) [Passwords](https://supabase.com/docs/guides/database/postgres/roles#passwords) [Special symbols in passwords](https://supabase.com/docs/guides/database/postgres/roles#special-symbols-in-passwords) [Changing your project password](https://supabase.com/docs/guides/database/postgres/roles#changing-your-project-password) [Granting permissions](https://supabase.com/docs/guides/database/postgres/roles#granting-permissions) [Revoking permissions](https://supabase.com/docs/guides/database/postgres/roles#revoking-permissions) [Role hierarchy](https://supabase.com/docs/guides/database/postgres/roles#role-hierarchy) [Role inheritance](https://supabase.com/docs/guides/database/postgres/roles#role-inheritance) [Preventing inheritance](https://supabase.com/docs/guides/database/postgres/roles#preventing-inheritance) [Supabase roles](https://supabase.com/docs/guides/database/postgres/roles#supabase-roles) [postgres](https://supabase.com/docs/guides/database/postgres/roles#postgres) [anon](https://supabase.com/docs/guides/database/postgres/roles#anon) [authenticator](https://supabase.com/docs/guides/database/postgres/roles#authenticator) [authenticated](https://supabase.com/docs/guides/database/postgres/roles#authenticated) [service\_role](https://supabase.com/docs/guides/database/postgres/roles#servicerole) [supabase\_auth\_admin](https://supabase.com/docs/guides/database/postgres/roles#supabaseauthadmin) [supabase\_storage\_admin](https://supabase.com/docs/guides/database/postgres/roles#supabasestorageadmin) [dashboard\_user](https://supabase.com/docs/guides/database/postgres/roles#dashboarduser) [supabase\_admin](https://supabase.com/docs/guides/database/postgres/roles#supabaseadmin) [Resources](https://supabase.com/docs/guides/database/postgres/roles#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_postgres_row_level_security.md">
Database

# Row Level Security

## Secure your data using Postgres Row Level Security.

* * *

When you need granular authorization rules, nothing beats Postgres's [Row Level Security (RLS)](https://www.postgresql.org/docs/current/ddl-rowsecurity.html).

## Row Level Security in Supabase [\#](https://supabase.com/docs/guides/database/postgres/row-level-security\#row-level-security-in-supabase)

Supabase allows convenient and secure data access from the browser, as long as you enable RLS.

RLS _must_ always be enabled on any tables stored in an exposed schema. By default, this is the `public` schema.

RLS is enabled by default on tables created with the Table Editor in the dashboard. If you create one in raw SQL or with the SQL editor, remember to enable RLS yourself:

`
alter table <schema_name>.<table_name>
enable row level security;
`

RLS is incredibly powerful and flexible, allowing you to write complex SQL rules that fit your unique business needs. RLS can be combined with [Supabase Auth](https://supabase.com/docs/guides/auth) for end-to-end user security from the browser to the database.

RLS is a Postgres primitive and can provide " [defense in depth](https://en.wikipedia.org/wiki/Defense_in_depth_(computing))" to protect your data from malicious actors even when accessed through third-party tooling.

## Policies [\#](https://supabase.com/docs/guides/database/postgres/row-level-security\#policies)

[Policies](https://www.postgresql.org/docs/current/sql-createpolicy.html) are Postgres's rule engine. Policies are easy to understand once you get the hang of them. Each policy is attached to a table, and the policy is executed every time a table is accessed.

You can just think of them as adding a `WHERE` clause to every query. For example a policy like this ...

`
create policy "Individuals can view their own todos."
on todos for select
using ( (select auth.uid()) = user_id );
`

.. would translate to this whenever a user tries to select from the todos table:

`
select *
from todos
where auth.uid() = todos.user_id;
-- Policy is implicitly added.
`

## Enabling Row Level Security [\#](https://supabase.com/docs/guides/database/postgres/row-level-security\#enabling-row-level-security)

You can enable RLS for any table using the `enable row level security` clause:

`
alter table "table_name" enable row level security;
`

Once you have enabled RLS, no data will be accessible via the [API](https://supabase.com/docs/guides/api) when using the public `anon` key, until you create policies.

## Authenticated and unauthenticated roles [\#](https://supabase.com/docs/guides/database/postgres/row-level-security\#authenticated-and-unauthenticated-roles)

Supabase maps every request to one of the roles:

- `anon`: an unauthenticated request (the user is not logged in)
- `authenticated`: an authenticated request (the user is logged in)

These are actually [Postgres Roles](https://supabase.com/docs/guides/database/postgres/roles). You can use these roles within your Policies using the `TO` clause:

`
create policy "Profiles are viewable by everyone"
on profiles for select
to authenticated, anon
using ( true );
-- OR
create policy "Public profiles are viewable only by authenticated users"
on profiles for select
to authenticated
using ( true );
`

##### Anonymous user vs the anon key

Using the `anon` Postgres role is different from an [anonymous user](https://supabase.com/docs/guides/auth/auth-anonymous) in Supabase Auth. An anonymous user assumes the `authenticated` role to access the database and can be differentiated from a permanent user by checking the `is_anonymous` claim in the JWT.

## Creating policies [\#](https://supabase.com/docs/guides/database/postgres/row-level-security\#creating-policies)

Policies are SQL logic that you attach to a Postgres table. You can attach as many policies as you want to each table.

Supabase provides some [helpers](https://supabase.com/docs/guides/database/postgres/row-level-security#helper-functions) that simplify RLS if you're using Supabase Auth. We'll use these helpers to illustrate some basic policies:

### SELECT policies [\#](https://supabase.com/docs/guides/database/postgres/row-level-security\#select-policies)

You can specify select policies with the `using` clause.

Let's say you have a table called `profiles` in the public schema and you want to enable read access to everyone.

`
-- 1. Create table
create table profiles (
id uuid primary key,
user_id references auth.users,
avatar_url text
);
-- 2. Enable RLS
alter table profiles enable row level security;
-- 3. Create Policy
create policy "Public profiles are visible to everyone."
on profiles for select
to anon         -- the Postgres Role (recommended)
using ( true ); -- the actual Policy
`

Alternatively, if you only wanted users to be able to see their own profiles:

`
create policy "User can see their own profile only."
on profiles
for select using ( (select auth.uid()) = user_id );
`

### INSERT policies [\#](https://supabase.com/docs/guides/database/postgres/row-level-security\#insert-policies)

You can specify insert policies with the `with check` clause. The `with check` expression ensures that any new row data adheres to the policy constraints.

Let's say you have a table called `profiles` in the public schema and you only want users to be able to create a profile for themselves. In that case, we want to check their User ID matches the value that they are trying to insert:

`
-- 1. Create table
create table profiles (
id uuid primary key,
user_id uuid references auth.users,
avatar_url text
);
-- 2. Enable RLS
alter table profiles enable row level security;
-- 3. Create Policy
create policy "Users can create a profile."
on profiles for insert
to authenticated                          -- the Postgres Role (recommended)
with check ( (select auth.uid()) = user_id );      -- the actual Policy
`

### UPDATE policies [\#](https://supabase.com/docs/guides/database/postgres/row-level-security\#update-policies)

You can specify update policies by combining both the `using` and `with check` expressions.

The `using` clause represents the condition that must be true for the update to be allowed, and `with check` clause ensures that the updates made adhere to the policy constraints.

Let's say you have a table called `profiles` in the public schema and you only want users to be able to update their own profile.

You can create a policy where the `using` clause checks if the user owns the profile being updated. And the `with check` clause ensures that, in the resultant row, users do not change the `user_id` to a value that is not equal to their User ID, maintaining that the modified profile still meets the ownership condition.

`
-- 1. Create table
create table profiles (
id uuid primary key,
user_id uuid references auth.users,
avatar_url text
);
-- 2. Enable RLS
alter table profiles enable row level security;
-- 3. Create Policy
create policy "Users can update their own profile."
on profiles for update
to authenticated                    -- the Postgres Role (recommended)
using ( (select auth.uid()) = user_id )       -- checks if the existing row complies with the policy expression
with check ( (select auth.uid()) = user_id ); -- checks if the new row complies with the policy expression
`

If no `with check` expression is defined, then the `using` expression will be used both to determine which rows are visible (normal USING case) and which new rows will be allowed to be added (WITH CHECK case).

To perform an `UPDATE` operation, a corresponding [`SELECT` policy](https://supabase.com/docs/guides/database/postgres/row-level-security#select-policies) is required. Without a `SELECT` policy, the `UPDATE` operation will not work as expected.

### DELETE policies [\#](https://supabase.com/docs/guides/database/postgres/row-level-security\#delete-policies)

You can specify delete policies with the `using` clause.

Let's say you have a table called `profiles` in the public schema and you only want users to be able to delete their own profile:

`
-- 1. Create table
create table profiles (
id uuid primary key,
user_id uuid references auth.users,
avatar_url text
);
-- 2. Enable RLS
alter table profiles enable row level security;
-- 3. Create Policy
create policy "Users can delete a profile."
on profiles for delete
to authenticated                     -- the Postgres Role (recommended)
using ( (select auth.uid()) = user_id );      -- the actual Policy
`

### Views [\#](https://supabase.com/docs/guides/database/postgres/row-level-security\#views)

Views bypass RLS by default because they are usually created with the `postgres` user. This is a feature of Postgres, which automatically creates views with `security definer`.

In Postgres 15 and above, you can make a view obey the RLS policies of the underlying tables when invoked by `anon` and `authenticated` roles by setting `security_invoker = true`.

`
create view <VIEW_NAME>
with(security_invoker = true)
as select <QUERY>
`

In older versions of Postgres, protect your views by revoking access from the `anon` and `authenticated` roles, or by putting them in an unexposed schema.

## Helper functions [\#](https://supabase.com/docs/guides/database/postgres/row-level-security\#helper-functions)

Supabase provides some helper functions that make it easier to write Policies.

### `auth.uid()` [\#](https://supabase.com/docs/guides/database/postgres/row-level-security\#authuid)

Returns the ID of the user making the request.

### `auth.jwt()` [\#](https://supabase.com/docs/guides/database/postgres/row-level-security\#authjwt)

Not all information present in the JWT should be used in RLS policies. For instance, creating an RLS policy that relies on the `user_metadata` claim can create security issues in your application as this information can be modified by authenticated end users.

Returns the JWT of the user making the request. Anything that you store in the user's `raw_app_meta_data` column or the `raw_user_meta_data` column will be accessible using this function. It's important to know the distinction between these two:

- `raw_user_meta_data` \- can be updated by the authenticated user using the `supabase.auth.update()` function. It is not a good place to store authorization data.
- `raw_app_meta_data` \- cannot be updated by the user, so it's a good place to store authorization data.

The `auth.jwt()` function is extremely versatile. For example, if you store some team data inside `app_metadata`, you can use it to determine whether a particular user belongs to a team. For example, if this was an array of IDs:

`
create policy "User is in team"
on my_table
to authenticated
using ( team_id in (select auth.jwt() -> 'app_metadata' -> 'teams'));
`

Keep in mind that a JWT is not always "fresh". In the example above, even if you remove a user from a team and update the `app_metadata` field, that will not be reflected using `auth.jwt()` until the user's JWT is refreshed.

Also, if you are using Cookies for Auth, then you must be mindful of the JWT size. Some browsers are limited to 4096 bytes for each cookie, and so the total size of your JWT should be small enough to fit inside this limitation.

### MFA [\#](https://supabase.com/docs/guides/database/postgres/row-level-security\#mfa)

The `auth.jwt()` function can be used to check for [Multi-Factor Authentication](https://supabase.com/docs/guides/auth/auth-mfa#enforce-rules-for-mfa-logins). For example, you could restrict a user from updating their profile unless they have at least 2 levels of authentication (Assurance Level 2):

`
create policy "Restrict updates."
on profiles
as restrictive
for update
to authenticated using (
(select auth.jwt()->>'aal') = 'aal2'
);
`

## Bypassing Row Level Security [\#](https://supabase.com/docs/guides/database/postgres/row-level-security\#bypassing-row-level-security)

Supabase provides special "Service" keys, which can be used to bypass RLS. These should never be used in the browser or exposed to customers, but they are useful for administrative tasks.

Supabase will adhere to the RLS policy of the signed-in user, even if the client library is initialized with a Service Key.

You can also create new [Postgres Roles](https://supabase.com/docs/guides/database/postgres/roles) which can bypass Row Level Security using the "bypass RLS" privilege:

`
alter role "role_name" with bypassrls;
`

This can be useful for system-level access. You should _never_ share login credentials for any Postgres Role with this privilege.

## RLS performance recommendations [\#](https://supabase.com/docs/guides/database/postgres/row-level-security\#rls-performance-recommendations)

Every authorization system has an impact on performance. While row level security is powerful, the performance impact is important to keep in mind. This is especially true for queries that scan every row in a table - like many `select` operations, including those using limit, offset, and ordering.

Based on a series of [tests](https://github.com/GaryAustin1/RLS-Performance), we have a few recommendations for RLS:

### Add indexes [\#](https://supabase.com/docs/guides/database/postgres/row-level-security\#add-indexes)

Make sure you've added [indexes](https://supabase.com/docs/guides/database/postgres/indexes) on any columns used within the Policies which are not already indexed (or primary keys). For a Policy like this:

`
create policy "rls_test_select" on test_table
to authenticated
using ( (select auth.uid()) = user_id );
`

You can add an index like:

`
create index userid
on test_table
using btree (user_id);
`

#### Benchmarks [\#](https://supabase.com/docs/guides/database/postgres/row-level-security\#benchmarks)

| Test | Before (ms) | After (ms) | % Improvement | Change |
| --- | --- | --- | --- | --- |
| [test1-indexed](https://github.com/GaryAustin1/RLS-Performance/tree/main/tests/test1-indexed) | 171 | < 0.1 | 99.94% | Before:<br>No index<br>After:<br>`user_id` indexed |

### Call functions with `select` [\#](https://supabase.com/docs/guides/database/postgres/row-level-security\#call-functions-with-select)

You can use `select` statement to improve policies that use functions. For example, instead of this:

`
create policy "rls_test_select" on test_table
to authenticated
using ( auth.uid() = user_id );
`

You can do:

`
create policy "rls_test_select" on test_table
to authenticated
using ( (select auth.uid()) = user_id );
`

This method works well for JWT functions like `auth.uid()` and `auth.jwt()` as well as `security definer` Functions. Wrapping the function causes an `initPlan` to be run by the Postgres optimizer, which allows it to "cache" the results per-statement, rather than calling the function on each row.

You can only use this technique if the results of the query or function do not change based on the row data.

#### Benchmarks [\#](https://supabase.com/docs/guides/database/postgres/row-level-security\#benchmarks)

| Test | Before (ms) | After (ms) | % Improvement | Change |
| --- | --- | --- | --- | --- |
| [test2a-wrappedSQL-uid](https://github.com/GaryAustin1/RLS-Performance/tree/main/tests/test2a-wrappedSQL-uid()) | 179 | 9 | 94.97% | Before:<br>`auth.uid() = user_id`<br>After:<br>`(select auth.uid()) = user_id` |
| [test2b-wrappedSQL-isadmin](https://github.com/GaryAustin1/RLS-Performance/tree/main/tests/test2b-wrappedSQL-isadmin()) | 11,000 | 7 | 99.94% | Before:<br>`is_admin()` _table join_<br>After:<br>`(select is_admin())` _table join_ |
| [test2c-wrappedSQL-two-functions](https://github.com/GaryAustin1/RLS-Performance/tree/main/tests/test2c-wrappedSQL-two-functions) | 11,000 | 10 | 99.91% | Before:<br>`is_admin() OR auth.uid() = user_id`<br>After:<br>`(select is_admin()) OR (select auth.uid() = user_id)` |
| [test2d-wrappedSQL-sd-fun](https://github.com/GaryAustin1/RLS-Performance/tree/main/tests/test2d-wrappedSQL-sd-fun) | 178,000 | 12 | 99.993% | Before:<br>`has_role() = role`<br>After:<br>(select has\_role()) = role |
| [test2e-wrappedSQL-sd-fun-array](https://github.com/GaryAustin1/RLS-Performance/tree/main/tests/test2e-wrappedSQL-sd-fun-array) | 173000 | 16 | 99.991% | Before:<br>`team_id=any(user_teams())`<br>After:<br>team\_id=any(array(select user\_teams())) |

### Add filters to every query [\#](https://supabase.com/docs/guides/database/postgres/row-level-security\#add-filters-to-every-query)

Policies are "implicit where clauses," so it's common to run `select` statements without any filters. This is a bad pattern for performance. Instead of doing this (JS client example):

`
const { data } = supabase
.from('table')
.select()
`

You should always add a filter:

`
const { data } = supabase
.from('table')
.select()
.eq('user_id', userId)
`

Even though this duplicates the contents of the Policy, Postgres can use the filter to construct a better query plan.

#### Benchmarks [\#](https://supabase.com/docs/guides/database/postgres/row-level-security\#benchmarks)

| Test | Before (ms) | After (ms) | % Improvement | Change |
| --- | --- | --- | --- | --- |
| [test3-addfilter](https://github.com/GaryAustin1/RLS-Performance/tree/main/tests/test3-addfilter) | 171 | 9 | 94.74% | Before:<br>`auth.uid() = user_id`<br>After:<br>add `.eq` or `where` on `user_id` |

### Use security definer functions [\#](https://supabase.com/docs/guides/database/postgres/row-level-security\#use-security-definer-functions)

A "security definer" function runs using the same role that _created_ the function. This means that if you create a role with a superuser (like `postgres`), then that function will have `bypassrls` privileges. For example, if you had a policy like this:

`
create policy "rls_test_select" on test_table
to authenticated
using (
exists (
    select 1 from roles_table
    where (select auth.uid()) = user_id and role = 'good_role'
)
);
`

We can instead create a `security definer` function which can scan `roles_table` without any RLS penalties:

`
create function private.has_good_role()
returns boolean
language plpgsql
security definer -- will run as the creator
as $$
begin
return exists (
    select 1 from roles_table
    where (select auth.uid()) = user_id and role = 'good_role'
);
end;
$$;
-- Update our policy to use this function:
create policy "rls_test_select"
on test_table
to authenticated
using ( private.has_good_role() );
`

Security-definer functions should never be created in a schema in the "Exposed schemas" inside your [API settings](https://supabase.com/dashboard/project/_/settings/api) \`.

### Minimize joins [\#](https://supabase.com/docs/guides/database/postgres/row-level-security\#minimize-joins)

You can often rewrite your Policies to avoid joins between the source and the target table. Instead, try to organize your policy to fetch all the relevant data from the target table into an array or set, then you can use an `IN` or `ANY` operation in your filter.

For example, this is an example of a slow policy which joins the source `test_table` to the target `team_user`:

`
create policy "rls_test_select" on test_table
to authenticated
using (
(select auth.uid()) in (
    select user_id
    from team_user
    where team_user.team_id = team_id -- joins to the source "test_table.team_id"
)
);
`

We can rewrite this to avoid this join, and instead select the filter criteria into a set:

`
create policy "rls_test_select" on test_table
to authenticated
using (
team_id in (
    select team_id
    from team_user
    where user_id = (select auth.uid()) -- no join
)
);
`

In this case you can also consider [using a `security definer` function](https://supabase.com/docs/guides/database/postgres/row-level-security#use-security-definer-functions) to bypass RLS on the join table:

If the list exceeds 1000 items, a different approach may be needed or you may need to analyze the approach to ensure that the performance is acceptable.

#### Benchmarks [\#](https://supabase.com/docs/guides/database/postgres/row-level-security\#benchmarks)

| Test | Before (ms) | After (ms) | % Improvement | Change |
| --- | --- | --- | --- | --- |
| [test5-fixed-join](https://github.com/GaryAustin1/RLS-Performance/tree/main/tests/test5-fixed-join) | 9,000 | 20 | 99.78% | Before:<br>`auth.uid()` in table join on col<br>After:<br>col in table join on `auth.uid()` |

### Specify roles in your policies [\#](https://supabase.com/docs/guides/database/postgres/row-level-security\#specify-roles-in-your-policies)

Always use the Role of inside your policies, specified by the `TO` operator. For example, instead of this query:

`
create policy "rls_test_select" on rls_test
using ( auth.uid() = user_id );
`

Use:

`
create policy "rls_test_select" on rls_test
to authenticated
using ( (select auth.uid()) = user_id );
`

This prevents the policy `( (select auth.uid()) = user_id )` from running for any `anon` users, since the execution stops at the `to authenticated` step.

#### Benchmarks [\#](https://supabase.com/docs/guides/database/postgres/row-level-security\#benchmarks)

| Test | Before (ms) | After (ms) | % Improvement | Change |
| --- | --- | --- | --- | --- |
| [test6-To-role](https://github.com/GaryAustin1/RLS-Performance/tree/main/tests/test6-To-role) | 170 | < 0.1 | 99.78% | Before:<br>No `TO` policy<br>After:<br>`TO authenticated` (anon accessing) |

## More resources [\#](https://supabase.com/docs/guides/database/postgres/row-level-security\#more-resources)

- [Testing your database](https://supabase.com/docs/guides/database/testing)
- [Row Level Security and Supabase Auth](https://supabase.com/docs/guides/database/postgres/row-level-security)
- [RLS Guide and Best Practices](https://github.com/orgs/supabase/discussions/14576)
- Community repo on testing RLS using [pgTAP and dbdev](https://github.com/usebasejump/supabase-test-helpers/tree/main)

### Is this helpful?

NoYes

### On this page

[Row Level Security in Supabase](https://supabase.com/docs/guides/database/postgres/row-level-security#row-level-security-in-supabase) [Policies](https://supabase.com/docs/guides/database/postgres/row-level-security#policies) [Enabling Row Level Security](https://supabase.com/docs/guides/database/postgres/row-level-security#enabling-row-level-security) [Authenticated and unauthenticated roles](https://supabase.com/docs/guides/database/postgres/row-level-security#authenticated-and-unauthenticated-roles) [Creating policies](https://supabase.com/docs/guides/database/postgres/row-level-security#creating-policies) [SELECT policies](https://supabase.com/docs/guides/database/postgres/row-level-security#select-policies) [INSERT policies](https://supabase.com/docs/guides/database/postgres/row-level-security#insert-policies) [UPDATE policies](https://supabase.com/docs/guides/database/postgres/row-level-security#update-policies) [DELETE policies](https://supabase.com/docs/guides/database/postgres/row-level-security#delete-policies) [Views](https://supabase.com/docs/guides/database/postgres/row-level-security#views) [Helper functions](https://supabase.com/docs/guides/database/postgres/row-level-security#helper-functions) [auth.uid()](https://supabase.com/docs/guides/database/postgres/row-level-security#authuid) [auth.jwt()](https://supabase.com/docs/guides/database/postgres/row-level-security#authjwt) [MFA](https://supabase.com/docs/guides/database/postgres/row-level-security#mfa) [Bypassing Row Level Security](https://supabase.com/docs/guides/database/postgres/row-level-security#bypassing-row-level-security) [RLS performance recommendations](https://supabase.com/docs/guides/database/postgres/row-level-security#rls-performance-recommendations) [Add indexes](https://supabase.com/docs/guides/database/postgres/row-level-security#add-indexes) [Call functions with select](https://supabase.com/docs/guides/database/postgres/row-level-security#call-functions-with-select) [Add filters to every query](https://supabase.com/docs/guides/database/postgres/row-level-security#add-filters-to-every-query) [Use security definer functions](https://supabase.com/docs/guides/database/postgres/row-level-security#use-security-definer-functions) [Minimize joins](https://supabase.com/docs/guides/database/postgres/row-level-security#minimize-joins) [Specify roles in your policies](https://supabase.com/docs/guides/database/postgres/row-level-security#specify-roles-in-your-policies) [More resources](https://supabase.com/docs/guides/database/postgres/row-level-security#more-resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_postgres_setup_replication_external.md">
Database

# Replicate to another Postgres database using Logical Replication

* * *

For this example, you will need:

- A Supabase project
- A Postgres database (running v10 or newer)

You will be running commands on both of these databases to publish changes from the Supabase database to the external database.

1. Create a `publication` on the **Supabase database**:

`
CREATE PUBLICATION example_pub;
`

2. Also on the **Supabase database**, create a `replication slot`:

`
select pg_create_logical_replication_slot('example_slot', 'pgoutput');
`

3. Now we will connect to our **external database** and subscribe to our `publication` Note: ):

This will need a direct connection to your database and you can find the connection info in the [Dashboard](https://supabase.com/dashboard/project/_/settings/database).

You will also need to ensure that ipv6 is supported by your replication destination.

If you would prefer not to use the `postgres` user, then you can run `CREATE ROLE <user> WITH REPLICATION;` using the `postgres` user.

`
CREATE SUBSCRIPTION example_sub
CONNECTION 'host=db.oaguxblfdassqxvvwtfe.supabase.co user=postgres password=YOUR_PASS dbname=postgres'
PUBLICATION example_pub
WITH (copy_data = true, create_slot=false, slot_name=example_slot);
`

`create_slot` is set to `false` because `slot_name` is provided and the slot was already created in Step 2.
To copy data from before the slot was created, set `copy_data` to `true`.

4. Add all the tables that you want replicated to the publication.

`
ALTER PUBLICATION example_pub ADD TABLE example_table;
`

5. Check the replication status using `pg_stat_replication`

`
select * from pg_stat_replication;
`

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_postgres_timeouts.md">
Database

# Timeouts

## Extend database timeouts to execute longer transactions

* * *

Dashboard and [Client](https://supabase.com/docs/guides/api/rest/client-libs) queries have a max-configurable timeout of 60 seconds. For longer transactions, use [Supavisor or direct connections](https://supabase.com/docs/guides/database/connecting-to-postgres#quick-summary).

## Change Postgres timeout [\#](https://supabase.com/docs/guides/database/postgres/timeouts\#change-postgres-timeout)

You can change the Postgres timeout at the:

1. [Session level](https://supabase.com/docs/guides/database/postgres/timeouts#session-level)
2. [Function level](https://supabase.com/docs/guides/database/postgres/timeouts#function-level)
3. [Global level](https://supabase.com/docs/guides/database/postgres/timeouts#global-level)
4. [Role level](https://supabase.com/docs/guides/database/postgres/timeouts#role-level)

### Session level [\#](https://supabase.com/docs/guides/database/postgres/timeouts\#session-level)

Session level settings persist only for the duration of the connection.

Set the session timeout by running:

`
set statement_timeout = '10min';
`

Because it applies to sessions only, it can only be used with connections through Supavisor in session mode (port 5432) or a direct connection. It cannot be used in the Dashboard, with the Supabase Client API, nor with Supavisor in Transaction mode (port 6543).

This is most often used for single, long running, administrative tasks, such as creating an HSNW index. Once the setting is implemented, you can view it by executing:

`
SHOW statement_timeout;
`

See the full guide on [changing session timeouts](https://github.com/orgs/supabase/discussions/21133).

### Function level [\#](https://supabase.com/docs/guides/database/postgres/timeouts\#function-level)

This works with the Database REST API when called from the Supabase client libraries:

`
create or replace function myfunc()
returns void as $$
select pg_sleep(3); -- simulating some long-running process
$$
language sql
set statement_timeout TO '4s'; -- set custom timeout
`

This is mostly for recurring functions that need a special exemption for runtimes.

### Role level [\#](https://supabase.com/docs/guides/database/postgres/timeouts\#role-level)

This sets the timeout for a specific role.

The default role timeouts are:

- `anon`: 3s
- `authenticated`: 8s
- `service_role`: none (defaults to the `authenticator` role's 8s timeout if unset)
- `postgres`: none (capped by default global timeout to be 2min)

Run the following query to change a role's timeout:

`
alter role example_role set statement_timeout = '10min'; -- could also use seconds '10s'
`

If you are changing the timeout for the Supabase Client API calls, you will need to reload PostgREST to reflect the timeout changes by running the following script:

`
NOTIFY pgrst, 'reload config';
`

Unlike global settings, the result cannot be checked with `SHOW statement_timeout`. Instead, run:

`
select
rolname,
rolconfig
from pg_roles
where
rolname in (
    'anon',
    'authenticated',
    'postgres',
    'service_role'
    -- ,<ANY CUSTOM ROLES>
);
`

### Global level [\#](https://supabase.com/docs/guides/database/postgres/timeouts\#global-level)

This changes the statement timeout for all roles and sessions without an explicit timeout already set.

`
alter database postgres set statement_timeout TO '4s';
`

Check if your changes took effect:

`
show statement_timeout;
`

Although not necessary, if you are uncertain if a timeout has been applied, you can run a quick test:

`
create or replace function myfunc()
returns void as $$
select pg_sleep(601); -- simulating some long-running process
$$
language sql;
`

## Identifying timeouts [\#](https://supabase.com/docs/guides/database/postgres/timeouts\#identifying-timeouts)

The Supabase Dashboard contains tools to help you identify timed-out and long-running queries.

### Using the Logs Explorer [\#](https://supabase.com/docs/guides/database/postgres/timeouts\#using-the-logs-explorer)

Go to the [Logs Explorer](https://supabase.com/dashboard/project/_/logs/explorer), and run the following query to identify timed-out events ( `statement timeout`) and queries that successfully run for longer than 10 seconds ( `duration`).

`
select
cast(postgres_logs.timestamp as datetime) as timestamp,
event_message,
parsed.error_severity,
parsed.user_name,
parsed.query,
parsed.detail,
parsed.hint,
parsed.sql_state_code,
parsed.backend_type
from
postgres_logs
cross join unnest(metadata) as metadata
cross join unnest(metadata.parsed) as parsed
where
regexp_contains(event_message, 'duration|statement timeout')
  -- (OPTIONAL) MODIFY OR REMOVE
and parsed.user_name = 'authenticator' -- <--------CHANGE
order by timestamp desc
limit 100;
`

### Using the Query Performance page [\#](https://supabase.com/docs/guides/database/postgres/timeouts\#using-the-query-performance-page)

Go to the [Query Performance page](https://supabase.com/dashboard/project/_/advisors/query-performance?preset=slowest_execution) and filter by relevant role and query speeds. This only identifies slow-running but successful queries. Unlike the Log Explorer, it does not show you timed-out queries.

### Understanding roles in logs [\#](https://supabase.com/docs/guides/database/postgres/timeouts\#understanding-roles-in-logs)

Each API server uses a designated user for connecting to the database:

| Role | API/Tool |
| --- | --- |
| `supabase_admin` | Used by Supabase to configure projects and for monitoring |
| `authenticator` | PostgREST |
| `supabase_auth_admin` | Auth |
| `supabase_storage_admin` | Storage |
| `supabase_realtime_admin` | Realtime |
| `supabase_replication_admin` | Synchronizes Read Replicas |
| `postgres` | Supabase Dashboard and External Tools (e.g., Prisma, SQLAlchemy, PSQL...) |
| Custom roles | External Tools (e.g., Prisma, SQLAlchemy, PSQL...) |

Filter by the `parsed.user_name` field to only retrieve logs made by specific users:

`
-- find events based on role/server
... query
where
  -- find events from the relevant role
parsed.user_name = '<ROLE>'
`

### Is this helpful?

NoYes

### On this page

[Change Postgres timeout](https://supabase.com/docs/guides/database/postgres/timeouts#change-postgres-timeout) [Session level](https://supabase.com/docs/guides/database/postgres/timeouts#session-level) [Function level](https://supabase.com/docs/guides/database/postgres/timeouts#function-level) [Role level](https://supabase.com/docs/guides/database/postgres/timeouts#role-level) [Global level](https://supabase.com/docs/guides/database/postgres/timeouts#global-level) [Identifying timeouts](https://supabase.com/docs/guides/database/postgres/timeouts#identifying-timeouts) [Using the Logs Explorer](https://supabase.com/docs/guides/database/postgres/timeouts#using-the-logs-explorer) [Using the Query Performance page](https://supabase.com/docs/guides/database/postgres/timeouts#using-the-query-performance-page) [Understanding roles in logs](https://supabase.com/docs/guides/database/postgres/timeouts#understanding-roles-in-logs)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_postgres_triggers.md">
Database

# Postgres Triggers

## Automatically execute SQL on table events.

* * *

In Postgres, a trigger executes a set of actions automatically on table events such as INSERTs, UPDATEs, DELETEs, or TRUNCATE operations.

## Creating a trigger [\#](https://supabase.com/docs/guides/database/postgres/triggers\#creating-a-trigger)

Creating triggers involve 2 parts:

1. A [Function](https://supabase.com/docs/guides/database/functions) which will be executed (called the Trigger Function)
2. The actual Trigger object, with parameters around when the trigger should be run.

An example of a trigger is:

`
create trigger "trigger_name"
after insert on "table_name"
for each row
execute function trigger_function();
`

## Trigger functions [\#](https://supabase.com/docs/guides/database/postgres/triggers\#trigger-functions)

A trigger function is a user-defined [Function](https://supabase.com/docs/guides/database/functions) that Postgres executes when the trigger is fired.

### Example trigger function [\#](https://supabase.com/docs/guides/database/postgres/triggers\#example-trigger-function)

Here is an example that updates `salary_log` whenever an employee's salary is updated:

`
-- Example: Update salary_log when salary is updated
create function update_salary_log()
returns trigger
language plpgsql
as $$
begin
insert into salary_log(employee_id, old_salary, new_salary)
values (new.id, old.salary, new.salary);
return new;
end;
$$;
create trigger salary_update_trigger
after update on employees
for each row
execute function update_salary_log();
`

### Trigger variables [\#](https://supabase.com/docs/guides/database/postgres/triggers\#trigger-variables)

Trigger functions have access to several special variables that provide information about the context of the trigger event and the data being modified. In the example above you can see the values inserted into the salary log are `old.salary` and `new.salary` \- in this case `old` specifies the previous values and `new` specifies the updated values.

Here are some of the key variables and options available within trigger functions:

- `TG_NAME`: The name of the trigger being fired.
- `TG_WHEN`: The timing of the trigger event ( `BEFORE` or `AFTER`).
- `TG_OP`: The operation that triggered the event ( `INSERT`, `UPDATE`, `DELETE`, or `TRUNCATE`).
- `OLD`: A record variable holding the old row's data in `UPDATE` and `DELETE` triggers.
- `NEW`: A record variable holding the new row's data in `UPDATE` and `INSERT` triggers.
- `TG_LEVEL`: The trigger level ( `ROW` or `STATEMENT`), indicating whether the trigger is row-level or statement-level.
- `TG_RELID`: The object ID of the table on which the trigger is being fired.
- `TG_TABLE_NAME`: The name of the table on which the trigger is being fired.
- `TG_TABLE_SCHEMA`: The schema of the table on which the trigger is being fired.
- `TG_ARGV`: An array of string arguments provided when creating the trigger.
- `TG_NARGS`: The number of arguments in the `TG_ARGV` array.

## Types of triggers [\#](https://supabase.com/docs/guides/database/postgres/triggers\#types-of-triggers)

There are two types of trigger, `BEFORE` and `AFTER`:

### Trigger before changes are made [\#](https://supabase.com/docs/guides/database/postgres/triggers\#trigger-before-changes-are-made)

Executes before the triggering event.

`
create trigger before_insert_trigger
before insert on orders
for each row
execute function before_insert_function();
`

### Trigger after changes are made [\#](https://supabase.com/docs/guides/database/postgres/triggers\#trigger-after-changes-are-made)

Executes after the triggering event.

`
create trigger after_delete_trigger
after delete on customers
for each row
execute function after_delete_function();
`

## Execution frequency [\#](https://supabase.com/docs/guides/database/postgres/triggers\#execution-frequency)

There are two options available for executing triggers:

- `for each row`: specifies that the trigger function should be executed once for each affected row.
- `for each statement`: the trigger is executed once for the entire operation (for example, once on insert). This can be more efficient than `for each row` when dealing with multiple rows affected by a single SQL statement, as they allow you to perform calculations or updates on groups of rows at once.

## Dropping a trigger [\#](https://supabase.com/docs/guides/database/postgres/triggers\#dropping-a-trigger)

You can delete a trigger using the `drop trigger` command:

`
drop trigger "trigger_name" on "table_name";
`

## Resources [\#](https://supabase.com/docs/guides/database/postgres/triggers\#resources)

- Official Postgres Docs: [Triggers](https://www.postgresql.org/docs/current/triggers.html)
- Official Postgres Docs: [Overview of Trigger Behavior](https://www.postgresql.org/docs/current/trigger-definition.html)
- Official Postgres Docs: [CREATE TRIGGER](https://www.postgresql.org/docs/current/sql-createtrigger.html)

### Is this helpful?

NoYes

### On this page

[Creating a trigger](https://supabase.com/docs/guides/database/postgres/triggers#creating-a-trigger) [Trigger functions](https://supabase.com/docs/guides/database/postgres/triggers#trigger-functions) [Example trigger function](https://supabase.com/docs/guides/database/postgres/triggers#example-trigger-function) [Trigger variables](https://supabase.com/docs/guides/database/postgres/triggers#trigger-variables) [Types of triggers](https://supabase.com/docs/guides/database/postgres/triggers#types-of-triggers) [Trigger before changes are made](https://supabase.com/docs/guides/database/postgres/triggers#trigger-before-changes-are-made) [Trigger after changes are made](https://supabase.com/docs/guides/database/postgres/triggers#trigger-after-changes-are-made) [Execution frequency](https://supabase.com/docs/guides/database/postgres/triggers#execution-frequency) [Dropping a trigger](https://supabase.com/docs/guides/database/postgres/triggers#dropping-a-trigger) [Resources](https://supabase.com/docs/guides/database/postgres/triggers#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_postgres_which_version_of_postgres.md">
Database

# Print PostgreSQL version

* * *

It's important to know which version of Postgres you are running as each major version has different features and may cause breaking changes. You may also need to update your schema when [upgrading](https://www.postgresql.org/docs/current/pgupgrade.html) or downgrading to a major Postgres version.

Run the following query using the [SQL Editor](https://supabase.com/dashboard/project/_/sql) in the Supabase Dashboard:

`
select
version();
`

Which should return something like:

`
PostgreSQL 15.1 on aarch64-unknown-linux-gnu, compiled by gcc (Ubuntu 10.3.0-1ubuntu1~20.04) 10.3.0, 64-bit
`

This query can also be executed via `psql` or any other query editor if you prefer to [connect directly to the database](https://supabase.com/docs/guides/database/connecting-to-postgres#direct-connections).

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_prisma_prisma_troubleshooting.md">
Database

# Troubleshooting prisma errors

* * *

This guide addresses common Prisma errors that you might encounter while using Supabase.

A full list of errors can be found in [Prisma's official docs](https://www.prisma.io/docs/orm/reference/error-reference).

## Understanding connection string parameters: [\#](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting\#start)

Unlike other libraries, Prisma lets you configure [its settings](https://www.prisma.io/docs/orm/overview/databases/postgresql#arguments) through special options appended to your connection string.

These options, called "query parameters," can be used to address specific errors.

`
# Example of query parameters
connection_string.../postgres?KEY1=VALUE&KEY2=VALUE&KEY3=VALUE
`

# Errors

## ... prepared statement already exists [\#](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting\#-prepared-statement-already-exists)

Supavisor in transaction mode (port 6543) does not support [prepared statements](https://www.postgresql.org/docs/current/sql-prepare.html), which Prisma will try to create in the background.

### Solution: [\#](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting\#solution-prepared-statement-exists)

- Add `pgbouncer=true` to the connection string. This turns off prepared statements in Prisma.

`
.../postgres?pgbouncer=true
`

* * *

## Can't reach database server at: [\#](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting\#cant-reach-database-server-at)

Prisma couldn't establish a connection with Postgres or Supavisor before the timeout

### Possible causes: [\#](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting\#possible-causes-cant-reach-database-server-at)

- **Database overload**: The database server is under heavy load, causing Prisma to struggle to connect.
- **Malformed connection string**: The connection string used by Prisma is incorrect or incomplete.
- **Transient network issues**: Temporary network problems are disrupting the connection.

### Solutions: [\#](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting\#solution-cant-reach-database-server-at)

- **Check database health**: Use the [Reports Dashboard](https://supabase.com/dashboard/project/_/reports/database) to monitor CPU, memory, and I/O usage. If the database is overloaded, consider increasing your [compute size](https://supabase.com/docs/guides/platform/compute-add-ons) or [optimizing your queries](https://supabase.com/docs/guides/database/query-optimization).
- **Verify connection string**: Double-check the connection string in your Prisma configuration to ensure it matches one in your [Database Settings](https://supabase.com/dashboard/project/_/settings/database).
- **Increase connection timeout**: Try increasing the `connect_timeout` parameter in your Prisma configuration to give it more time to establish a connection.

`
.../postgres?connect_timeout=30
`

* * *

## Timed out fetching a new connection from the connection pool: [\#](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting\#timed-out-fetching-a-new-connection-from-the-connection-pool)

Prisma is unable to allocate connections to pending queries fast enough to meet demand.

### Possible causes: [\#](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting\#possible-causes-timed-out-fetching-a-new-connection)

- **Overwhelmed server**: The server hosting Prisma is under heavy load, limiting its ability to manage connections. By default, Prisma will create the default `2 * num_cpus / 2` worth of connections. A common cause for server strain is increasing the `connection_limit` significantly past the default.
- **Insufficient pool size**: The Supavisor pooler does not have enough connections available to quickly satisfy Prisma's requests.
- **Slow queries**: Prisma's queries are taking too long to execute, preventing it from releasing connections for reuse.

### Solutions: [\#](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting\#solution-timed-out-fetching-a-new-connection)

- **Increase the pool timeout**: Increase the `pool_timeout` parameter in your Prisma configuration to give the pooler more time to allocate connections.
- **Reduce the connection limit**: If you've explicitly increased the `connection_limit` parameter in your Prisma configuration, try reducing it to a more reasonable value.
- **Increase pool size**: If you are connecting with Supavisor, try increasing the pool size in the [Database Settings](https://supabase.com/dashboard/project/_/settings/database).
- **Optimize queries**: [Improve the efficiency of your queries](https://supabase.com/docs/guides/database/query-optimization) to reduce execution time.
- **Increase compute size**: Like the preceding option, this is a strategy to reduce query execution time.

* * *

## Server has closed the connection [\#](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting\#server-has-closed-the-connection)

According to this [GitHub Issue for Prisma](https://github.com/prisma/prisma/discussions/7389), this error may be related to large return values for queries. It may also be caused by significant database strain.

### Solutions: [\#](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting\#solution-server-has-closed-the-connection)

- **Limit row return sizes**: Try to limit the total amount of rows returned for particularly large requests.
- **Minimize database strain**:Check the Reports Page for database strain. If there is obvious strain, consider [optimizing](https://supabase.com/docs/guides/database/query-optimization) or increasing compute size

* * *

## Drift detected: Your database schema is not in sync with your migration history [\#](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting\#drift-detected-your-database-schema-is-not-in-sync-with-your-migration-history)

Prisma relies on migration files to ensure your database aligns with Prisma's model. External schema changes are detected as "drift", which Prisma will try to overwrite, potentially causing data loss.

### Possible causes: [\#](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting\#possible-causes-your-database-schema-is-not-in-sync)

- **Supabase Managed Schemas**: Supabase may update managed schemas like auth and storage to introduce new features. Granting Prisma access to these schemas can lead to drift during updates.
- **External Schema Modifications**: Your team or another tool might have modified the database schema outside of Prisma, causing drift.

### Solution: [\#](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting\#solution-your-database-schema-is-not-in-sync)

- **Baselining migrations**: [baselining](https://www.prisma.io/docs/orm/prisma-migrate/workflows/baselining) re-syncs Prisma by capturing the current database schema as the starting point for future migrations.

* * *

## Max client connections reached [\#](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting\#max-client-connections-reached)

Postgres or Supavisor rejected a request for more connections

### Possible causes: [\#](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting\#possible-causes-max-client-connections-reached)

- **When working in transaction mode (port 6543):** The error "Max client connections reached" occurs when clients try to form more connections with the pooler than it can support.
- **When working in session mode (port 5432):** The max amount of clients is restricted to the "Pool Size" value in the [Database Settings](https://supabase.com/dashboard/project/_/settings/database). If the "Pool Size" is set to 15, even if the pooler can handle 200 client connections, it will still be effectively capped at 15 for each unique ["database-role+database" combination](https://github.com/orgs/supabase/discussions/21566).
- **When working with direct connections**: Postgres is already servicing the max amount of connections

### Solutions [\#](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting\#solutions-causes-max-client-connections-reached)

- **Transaction Mode for serverless apps**: If you are using serverless functions (Supabase Edge, Vercel, AWS Lambda), switch to transaction mode (port 6543). It handles more connections than session mode or direct connections.
- **Reduce the number of Prisma connections**: A single client-server can establish multiple connections with a pooler. Typically, serverless setups do not need many connections. Starting with fewer, like five or three, or even just one, is often sufficient. In serverless setups, begin with `connection_limit=1`, increasing cautiously if needed to avoid maxing out connections.
- **Increase pool size**: If you are connecting with Supavisor, try increasing the pool size in the [Database Settings](https://supabase.com/dashboard/project/_/settings/database).
- **Disconnect appropriately**: Close Prisma connections when they are no longer needed.
- **Decrease query time**: Reduce query complexity or add [strategic indexes](https://supabase.com/docs/guides/database/postgres/indexes) to your tables to speed up queries.
- **Increase compute size**: Sometimes the best option is to increase your compute size, which also increases your max client size and query execution speed

* * *

## Cross schema references are only allowed when the target schema is listed in the schemas property of your data-source [\#](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting\#cross-schema-references-are-only-allowed-when-the-target-schema-is-listed-in-the-schemas-property-of-your-data-source)

A Prisma migration is referencing a schema it is not permitted to manage.

### Possible causes: [\#](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting\#possible-causes-cross-schema-references)

- A migration references a schema that Prisma is not permitted to manage

### Solutions: [\#](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting\#solutions-cross-schema-references)

- Multi-Schema support: If the external schema isn't Supabase managed, modify your `prisma.schema` file to enable the multi-Schema preview

prisma.schema

`
generator client {
provider        = "prisma-client-js"
previewFeatures = ["multiSchema"]  //Add line
}
datasource db {
provider  = "postgresql"
url       = env("DATABASE_URL")
directUrl = env("DIRECT_URL")
schemas   = ["public", "other_schema"] //list out relevant schemas
}
`

- Supabase managed schemas: Schemas managed by Supabase, such as `auth` and `storage`, may be changed to support new features. Referencing these schemas directly will cause schema drift in the future. It is best to remove references to these schemas from your migrations.

An alternative strategy to reference these tables is to duplicate values into Prisma managed table with triggers. Below is an example for duplicating values from `auth.users` into a table called `profiles`.

Show/Hide Details

table\_in\_public

`
-- Create the 'profiles' table in the 'public' schema
create table public.profiles (
id uuid primary key,             -- 'id' is a UUID and the primary key for the table
email varchar(256)               -- 'email' is a variable character field with a maximum length of 256 characters
);
`

trigger\_on\_insert

`
-- Function to handle the insertion of a new user into the 'profiles' table
create function public.handle_new_user()
returns trigger
language plpgsql
security definer set search_path = ''
as $$
begin
  -- Insert the new user's data into the 'profiles' table
insert into public.profiles (id, email)
values (new.id, new.email);
return new;     -- Return the new record
end;
$$;
`

trigger\_on\_update

`
-- Function to handle the updating of a user's information in the 'profiles' table
create function public.update_user()
returns trigger
language plpgsql
security definer set search_path = ''
as
$$
begin
  -- Update the user's data in the 'profiles' table
update public.profiles
set email = new.email     -- Update the 'email' field
where id = new.id;        -- Match the 'id' field with the new record
return new;  -- Return the new record
end;
$$;
`

trigger\_on\_delete

`
-- Function to handle the deletion of a user from the 'profiles' table
create function public.delete_user()
returns trigger
language plpgsql
security definer set search_path = ''
as
$$
begin
  -- Delete the user's data from the 'profiles' table
delete from public.profiles
where id = old.id;  -- Match the 'id' field with the old record
return old;  -- Return the old record
end;
$$;
`

triggers\_on\_auth

`
-- Trigger to run 'handle_new_user' function after a new user is inserted into 'auth.users' table
create trigger on_auth_user_created
after insert on auth.users
for each row execute procedure public.handle_new_user();
-- Trigger to run 'update_user' function after a user is updated in the 'auth.users' table
create trigger on_auth_user_updated
after update on auth.users
for each row execute procedure public.update_user();
-- Trigger to run 'delete_user' function after a user is deleted from the 'auth.users' table
create trigger on_auth_user_deleted
after delete on auth.users
for each row execute procedure public.delete_user();
`

### Is this helpful?

NoYes

### On this page

[Understanding connection string parameters:](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting#start) [... prepared statement already exists](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting#-prepared-statement-already-exists) [Solution:](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting#solution-prepared-statement-exists) [Can't reach database server at:](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting#cant-reach-database-server-at) [Possible causes:](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting#possible-causes-cant-reach-database-server-at) [Solutions:](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting#solution-cant-reach-database-server-at) [Timed out fetching a new connection from the connection pool:](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting#timed-out-fetching-a-new-connection-from-the-connection-pool) [Possible causes:](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting#possible-causes-timed-out-fetching-a-new-connection) [Solutions:](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting#solution-timed-out-fetching-a-new-connection) [Server has closed the connection](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting#server-has-closed-the-connection) [Solutions:](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting#solution-server-has-closed-the-connection) [Drift detected: Your database schema is not in sync with your migration history](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting#drift-detected-your-database-schema-is-not-in-sync-with-your-migration-history) [Possible causes:](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting#possible-causes-your-database-schema-is-not-in-sync) [Solution:](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting#solution-your-database-schema-is-not-in-sync) [Max client connections reached](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting#max-client-connections-reached) [Possible causes:](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting#possible-causes-max-client-connections-reached) [Solutions](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting#solutions-causes-max-client-connections-reached) [Cross schema references are only allowed when the target schema is listed in the schemas property of your data-source](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting#cross-schema-references-are-only-allowed-when-the-target-schema-is-listed-in-the-schemas-property-of-your-data-source) [Possible causes:](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting#possible-causes-cross-schema-references) [Solutions:](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting#solutions-cross-schema-references)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_prisma.md">
Database

# Prisma

* * *

This quickly shows how to connect your Prisma application to Supabase Postgres. If you encounter any problems, reference the [Prisma troubleshooting docs](https://supabase.com/docs/guides/database/prisma/prisma-troubleshooting).

If you plan to solely use Prisma instead of the Supabase Data API (PostgREST), turn it off in the [API Settings](https://supabase.com/dashboard/project/_/settings/api).

1

### Create a custom user for Prisma

- In the [SQL Editor](https://supabase.com/dashboard/project/_/sql/new), create a Prisma DB user with full privileges on the public schema.
- This gives you better control over Prisma's access and makes it easier to monitor using Supabase tools like the [Query Performance Dashboard](https://supabase.com/dashboard/project/_/advisors/query-performance) and [Log Explorer](https://supabase.com/dashboard/project/_/logs/explorer).

##### password manager

For security, consider using a [password generator](https://bitwarden.com/password-generator/) for the Prisma role.

`
-- Create custom user
create user "prisma" with password 'custom_password' bypassrls createdb;
-- extend prisma's privileges to postgres (necessary to view changes in Dashboard)
grant "prisma" to "postgres";
-- Grant it necessary permissions over the relevant schemas (public)
grant usage on schema public to prisma;
grant create on schema public to prisma;
grant all on all tables in schema public to prisma;
grant all on all routines in schema public to prisma;
grant all on all sequences in schema public to prisma;
alter default privileges for role postgres in schema public grant all on tables to prisma;
alter default privileges for role postgres in schema public grant all on routines to prisma;
alter default privileges for role postgres in schema public grant all on sequences to prisma;
`

`
-- alter prisma password if needed
alter user "prisma" with password 'new_password';
`

2

### Create a Prisma Project

Create a new Prisma Project on your computer

Create a new directory

Terminal

`
mkdir hello-prisma
cd hello-prisma
`

Initiate a new Prisma project

npmpnpmyarnbun

`
npm init -y
npm install prisma typescript ts-node @types/node --save-dev
npx tsc --init
npx prisma init
`

3

### Add your connection information to your .env file

- Visit the [Database Settings](https://supabase.com/dashboard/project/_/settings/database)
- Find your Supavisor Session Mode string. It should end with 5432. It will be used in your `.env` file.

If you're in an [IPv6 environment](https://github.com/orgs/supabase/discussions/27034) or have the IPv4 Add-On, you can use the direct connection string instead of Supavisor in Session mode.

- If you plan on deploying Prisma to a serverless or auto-scaling environment, you'll also need your Supavisor transaction mode string.
- The string is identical to the session mode string but uses port 6543 at the end.

server-based deploymentsserverless deployments

In your .env file, set the DATABASE\_URL variable to your connection string

.env

`
# Used for Prisma Migrations and within your application
DATABASE_URL="postgres://[DB-USER].[PROJECT-REF]:[PRISMA-PASSWORD]@[DB-REGION].pooler.supabase.com:5432/postgres"
`

Change your string's `[DB-USER]` to `prisma` and add the password you created in step 1

`
postgres://prisma.[PROJECT-REF]...
`

4

### Create your migrations

If you have already modified your Supabase database, synchronize it with your migration file. Otherwise create new tables for your database

New ProjectsPopulated Projects

Create new tables in your prisma.schema file

prisma/schema.prisma

`
model Post {
id        Int     @id @default(autoincrement())
title     String
content   String?
published Boolean @default(false)
author    User?   @relation(fields: [authorId], references: [id])
authorId  Int?
}
model User {
id    Int     @id @default(autoincrement())
email String  @unique
name  String?
posts Post[]
}
`

commit your migration

npmpnpmyarnbun

`
npx prisma migrate dev --name first_prisma_migration
`

5

### Install the prisma client

Install the Prisma client and generate its model

npmpnpmyarnbun

`
npm install @prisma/client
npx prisma generate
`

6

### Test your API

Create a index.ts file and run it to test your connection

index.ts

`
const { PrismaClient } = require('@prisma/client');
const prisma = new PrismaClient();
async function main() {
//change to reference a table in your schema
const val = await prisma.<SOME_TABLE_NAME>.findMany({
    take: 10,
});
console.log(val);
}
main()
.then(async () => {
    await prisma.$disconnect();
})
.catch(async (e) => {
    console.error(e);
    await prisma.$disconnect();
process.exit(1);
});
`

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_psql.md">
Database

# Connecting with PSQL

* * *

[`psql`](https://www.postgresql.org/docs/current/app-psql.html) is a command-line tool that comes with Postgres.

## Connecting with SSL [\#](https://supabase.com/docs/guides/database/psql\#connecting-with-ssl)

You should connect to your database using SSL wherever possible, to prevent snooping and man-in-the-middle attacks.

You can obtain your connection info and Server root certificate from your application's dashboard:

![Connection Info and Certificate.](https://supabase.com/docs/img/database/database-settings-ssl.png)

Download your [SSL certificate](https://supabase.com/docs/guides/database/psql#connecting-with-ssl) to `/path/to/prod-supabase.cer`.

Find your connection settings. Go to your [`Database Settings`](https://supabase.com/dashboard/project/_/settings/database) and make sure `Use connection pooling` is checked. Change the connection mode to `Session`, and copy the parameters into the connection string:

`
psql "sslmode=verify-full sslrootcert=/path/to/prod-supabase.cer host=[CLOUD_PROVIDER]-0-[REGION].pooler.supabase.com dbname=postgres user=postgres.[PROJECT_REF]"
`

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_query_optimization.md">
Database

# Query Optimization

## Choosing indexes to improve your query performance.

* * *

When working with Postgres, or any relational database, indexing is key to improving query performance. Aligning indexes with common query patterns can speed up data retrieval by an order of magnitude.

This guide is intended to:

- help identify parts of a query that have the potential to be improved by indexes
- introduce tooling to help identify useful indexes

This is not a comprehensive resource, but rather a helpful starting point for your optimization journey.

If you're new to query optimization, you may be interested in [`index_advisor`](https://supabase.com/docs/guides/database/extensions/index_advisor), our tool for automatically detecting indexes that improve performance on a given query.

## Example query [\#](https://supabase.com/docs/guides/database/query-optimization\#example-query)

Consider the following example query that retrieves customer names and purchase dates from two tables:

`
select
a.name,
b.date_of_purchase
from
customers as a
join orders as b on a.id = b.customer_id
where a.sign_up_date > '2023-01-01' and b.status = 'shipped'
order by b.date_of_purchase
limit 10;
`

In this query, there are several parts that indexes could likely help in optimizing the performance:

### `where` clause: [\#](https://supabase.com/docs/guides/database/query-optimization\#where-clause)

The `where` clause filters rows based on certain conditions, and indexing the columns involved can improve this process:

- `a.sign_up_date`: If filtering by `sign_up_date` is common, indexing this column can speed up the query.
- `b.status`: Indexing the status may be beneficial if the column has diverse values.

`
create index idx_customers_sign_up_date on customers (sign_up_date);
create index idx_orders_status on orders (status);
`

### `join` columns [\#](https://supabase.com/docs/guides/database/query-optimization\#join-columns)

Indexes on the columns used for joining tables can help Postgres avoid scanning tables in their entirety when connecting tables.

- Indexing `a.id` and `b.customer_id` would likely improve the performance of the join in this query.
- Note that if `a.id` is the primary key of the `customers` table it is already indexed

`
create index idx_orders_customer_id on orders (customer_id);
`

### `order by` clause [\#](https://supabase.com/docs/guides/database/query-optimization\#order-by-clause)

Sorting can also be optimized by indexing:

- An index on `b.date_of_purchase` can improve the sorting process, and is particularly beneficial when a subset of rows is being returned with a `limit` clause.

`
create index idx_orders_date_of_purchase on orders (date_of_purchase);
`

## Key concepts [\#](https://supabase.com/docs/guides/database/query-optimization\#key-concepts)

Here are some concepts and tools to keep in mind to help you identify the best index for the job, and measure the impact that your index had:

### Analyze the query plan [\#](https://supabase.com/docs/guides/database/query-optimization\#analyze-the-query-plan)

Use the `explain` command to understand the query's execution. Look for slow parts, such as Sequential Scans or high cost numbers. If creating an index does not reduce the cost of the query plan, remove it.

For example:

`
explain select * from customers where sign_up_date > 25;
`

### Use appropriate index types [\#](https://supabase.com/docs/guides/database/query-optimization\#use-appropriate-index-types)

Postgres offers various index types like [B-tree, Hash, GIN, etc](https://www.postgresql.org/docs/current/indexes-types.html). Select the type that best suits your data and query pattern. Using the right index type can make a significant difference. For example, using a BRIN index on a field that always increases and lives within a table that updates infrequently - like `created_at` on an `orders` table - routinely results in indexes that are +10x smaller than the equivalent default B-tree index. That translates into better scalability.

`
create index idx_orders_created_at ON customers using brin(created_at);
`

### Partial indexes [\#](https://supabase.com/docs/guides/database/query-optimization\#partial-indexes)

For queries that frequently target a subset of data, a partial index could be faster and smaller than indexing the entire column. A partial index contains a `where` clause to filter the values included in the index. Note that a query's `where` clause must match the index for it to be used.

`
create index idx_orders_status on orders (status)
where status = 'shipped';
`

### Composite indexes [\#](https://supabase.com/docs/guides/database/query-optimization\#composite-indexes)

If filtering or joining on multiple columns, a composite index prevents Postgres from referring to multiple indexes when identifying the relevant rows.

`
create index idx_customers_sign_up_date_priority on customers (sign_up_date, priority);
`

### Over-Indexing [\#](https://supabase.com/docs/guides/database/query-optimization\#over-indexing)

Avoid the urge to index columns you operate on infrequently. While indexes can speed up reads, they also slow down writes, so it's important to balance those factors when making indexing decisions.

### Statistics [\#](https://supabase.com/docs/guides/database/query-optimization\#statistics)

Postgres maintains a set of statistics about the contents of your tables. Those statistics are used by the query planner to decide when it's is more efficient to use an index vs scanning the entire table. If the collected statistics drift too far from reality, the query planner may make poor decisions. To avoid this risk, you can periodically `analyze` tables.

`
analyze customers;
`

* * *

By following this guide, you'll be able to discern where indexes can optimize queries and enhance your Postgres performance. Remember that each database is unique, so always consider the specific context and use case of your queries.

### Is this helpful?

NoYes

### On this page

[Example query](https://supabase.com/docs/guides/database/query-optimization#example-query) [where clause:](https://supabase.com/docs/guides/database/query-optimization#where-clause) [join columns](https://supabase.com/docs/guides/database/query-optimization#join-columns) [order by clause](https://supabase.com/docs/guides/database/query-optimization#order-by-clause) [Key concepts](https://supabase.com/docs/guides/database/query-optimization#key-concepts) [Analyze the query plan](https://supabase.com/docs/guides/database/query-optimization#analyze-the-query-plan) [Use appropriate index types](https://supabase.com/docs/guides/database/query-optimization#use-appropriate-index-types) [Partial indexes](https://supabase.com/docs/guides/database/query-optimization#partial-indexes) [Composite indexes](https://supabase.com/docs/guides/database/query-optimization#composite-indexes) [Over-Indexing](https://supabase.com/docs/guides/database/query-optimization#over-indexing) [Statistics](https://supabase.com/docs/guides/database/query-optimization#statistics)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_replication.md">
Database

# Replication

* * *

Replication is a technique for copying the data from one database to another. Supabase uses replication functionality to provide a real-time API. Replication is useful for:

- Spreading out the "load." For example, if your database has a lot of reads, you might want to split it between two databases.
- Reducing latency. For example, you may want one database in London to serve your European customers, and one in New York to serve the US.

Replication is done through _publications_, a method of choosing which changes to send to other systems (usually another Postgres database). Publications can be managed in the [Dashboard](https://supabase.com/dashboard) or with SQL.

## Manage publications in the dashboard [\#](https://supabase.com/docs/guides/database/replication\#manage-publications-in-the-dashboard)

1. Go to the [Database](https://supabase.com/dashboard/project/_/database/tables) page in the Dashboard.
2. Click on **Publications** in the sidebar.
3. Control which database events are sent by toggling **Insert**, **Update**, and **Delete**.
4. Control which tables broadcast changes by selecting **Source** and toggling each table.

## Create a publication [\#](https://supabase.com/docs/guides/database/replication\#create-a-publication)

This publication contains changes to all tables.

`
create publication publication_name
for all tables;
`

## Create a publication to listen to individual tables [\#](https://supabase.com/docs/guides/database/replication\#create-a-publication-to-listen-to-individual-tables)

`
create publication publication_name
for table table_one, table_two;
`

## Add tables to an existing publication [\#](https://supabase.com/docs/guides/database/replication\#add-tables-to-an-existing-publication)

`
alter publication publication_name
add table table_name;
`

## Listen to `insert` [\#](https://supabase.com/docs/guides/database/replication\#listen-to-insert)

`
create publication publication_name
for all tables
with (publish = 'insert');
`

## Listen to `update` [\#](https://supabase.com/docs/guides/database/replication\#listen-to-update)

`
create publication publication_name
for all tables
with (publish = 'update');
`

## Listen to `delete` [\#](https://supabase.com/docs/guides/database/replication\#listen-to-delete)

`
create publication publication_name
for all tables
with (publish = 'delete');
`

## Remove a publication [\#](https://supabase.com/docs/guides/database/replication\#remove-a-publication)

`
drop publication if exists publication_name;
`

## Recreate a publication [\#](https://supabase.com/docs/guides/database/replication\#recreate-a-publication)

If you're recreating a publication, it's best to do it in a transaction to ensure the operation succeeds.

`
begin;
  -- remove the realtime publication
drop publication if exists publication_name;
  -- re-create the publication but don't enable it for any tables
create publication publication_name;
commit;
`

### Is this helpful?

NoYes

### On this page

[Manage publications in the dashboard](https://supabase.com/docs/guides/database/replication#manage-publications-in-the-dashboard) [Create a publication](https://supabase.com/docs/guides/database/replication#create-a-publication) [Create a publication to listen to individual tables](https://supabase.com/docs/guides/database/replication#create-a-publication-to-listen-to-individual-tables) [Add tables to an existing publication](https://supabase.com/docs/guides/database/replication#add-tables-to-an-existing-publication) [Listen to insert](https://supabase.com/docs/guides/database/replication#listen-to-insert) [Listen to update](https://supabase.com/docs/guides/database/replication#listen-to-update) [Listen to delete](https://supabase.com/docs/guides/database/replication#listen-to-delete) [Remove a publication](https://supabase.com/docs/guides/database/replication#remove-a-publication) [Recreate a publication](https://supabase.com/docs/guides/database/replication#recreate-a-publication)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_secure_data.md">
Database

# Securing your data

* * *

Supabase helps you control access to your data. With access policies, you can protect sensitive data and make sure users only access what they're allowed to see.

## Connecting your app securely [\#](https://supabase.com/docs/guides/database/secure-data\#connecting-your-app-securely)

Supabase allows you to access your database using the auto-generated [Data APIs](https://supabase.com/docs/guides/database/connecting-to-postgres#data-apis). This speeds up the process of building web apps, since you don't need to write your own backend services to pass database queries and results back and forth.

You can keep your data secure while accessing the Data APIs from the frontend, so long as you:

- Turn on [Row Level Security](https://supabase.com/docs/guides/database/postgres/row-level-security) (RLS) for your tables
- Use your Supabase **anon key** when you create a Supabase client

Your anon key is safe to expose with RLS enabled, because row access permission is checked against your access policies and the user's [JSON Web Token (JWT)](https://supabase.com/docs/learn/auth-deep-dive/auth-deep-dive-jwts). The JWT is automatically sent by the Supabase client libraries if the user is logged in using Supabase Auth.

##### Never expose your service role key on the frontend

Unlike your anon key, your **service role key** is **never** safe to expose because it bypasses RLS. Only use your service role key on the backend. Treat it as a secret (for example, import it as a sensitive environment variable instead of hardcoding it).

## More information [\#](https://supabase.com/docs/guides/database/secure-data\#more-information)

Supabase and Postgres provide you with multiple ways to manage security, including but not limited to Row Level Security. See the Access and Security pages for more information:

- [Row Level Security](https://supabase.com/docs/guides/database/postgres/row-level-security)
- [Column Level Security](https://supabase.com/docs/guides/database/postgres/column-level-security)
- [Hardening the Data API](https://supabase.com/docs/guides/database/hardening-data-api)
- [Managing Postgres roles](https://supabase.com/docs/guides/database/postgres/roles)
- [Managing secrets with Vault](https://supabase.com/docs/guides/database/vault)

### Is this helpful?

NoYes

### On this page

[Connecting your app securely](https://supabase.com/docs/guides/database/secure-data#connecting-your-app-securely) [More information](https://supabase.com/docs/guides/database/secure-data#more-information)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_supavisor.md">
Database

# Supavisor

## Troubleshooting Supavisor errors

* * *

Supavisor logs are available under [Pooler Logs](https://supabase.com/dashboard/project/_/logs/pooler-logs) in the Dashboard. The following are common errors and their solutions:

| Error Type | Description | Resolution Link |
| --- | --- | --- |
| Max client connections reached | This error happens when the number of connections to Supavisor is more than [the allowed limit of your compute add-on](https://supabase.com/docs/guides/platform/compute-add-ons). | Follow this [guide](https://github.com/orgs/supabase/discussions/22305) to resolve. |
| Connection failed `{:error, :eaddrnotavail}` to 'db.xxx.supabase.co':5432 | Supavisor cannot connect to the customer database. This is usually caused if the target database is unable to respond. | N/A |
| Connection failed `{:error, :nxdomain}` to 'db.xxx.supabase.co':5432 | Supavisor cannot connect to the customer database. This is usually caused if the target database is unable to respond. | N/A |
| Connection closed when state was authentication | This error happens when either the database doesnt exist or if the user doesn't have the right credentials. | N/A |
| Subscribe error: `{:error, :worker_not_found}` | This log event is emitted when the client tries to connect to the database, but Supavisor does not have the necessary information to route the connection. Try reconnecting to the database as it can take some time for the project information to propagate to Supavisor. | N/A |
| Subscribe error: `{:error, {:badrpc, {:error, {:erpc, :timeout}}}}` | This is a timeout error when the communication between different Supavisor nodes takes longer than expected. Try reconnecting to the database. | N/A |
| Terminating with reason :client\_termination when state was :busy | This error happens when the client terminates the connection before the connection with the database is completed. | N/A |
| Error: received invalid response to GSSAPI negotiation: S | This error happens due to `gssencmode` parameter not set to disabled. | Follow this [guide](https://github.com/orgs/supabase/discussions/30173) to resolve. |

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_tables.md">
Database

# Tables and Data

* * *

Tables are where you store your data.

Tables are similar to excel spreadsheets. They contain columns and rows.
For example, this table has 3 "columns" ( `id`, `name`, `description`) and 4 "rows" of data:

| `id` | `name` | `description` |
| --- | --- | --- |
| 1 | The Phantom Menace | Two Jedi escape a hostile blockade to find allies and come across a young boy who may bring balance to the Force. |
| 2 | Attack of the Clones | Ten years after the invasion of Naboo, the Galactic Republic is facing a Separatist movement. |
| 3 | Revenge of the Sith | As Obi-Wan pursues a new threat, Anakin acts as a double agent between the Jedi Council and Palpatine and is lured into a sinister plan to rule the galaxy. |
| 4 | Star Wars | Luke Skywalker joins forces with a Jedi Knight, a cocky pilot, a Wookiee and two droids to save the galaxy from the Empire's world-destroying battle station. |

There are a few important differences from a spreadsheet, but it's a good starting point if you're new to Relational databases.

## Creating tables [\#](https://supabase.com/docs/guides/database/tables\#creating-tables)

When creating a table, it's best practice to add columns at the same time.

![Tables and columns](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fdatabase%2Fmanaging-tables%2Fcreating-tables--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

You must define the "data type" of each column when it is created. You can add and remove columns at any time after creating a table.

Supabase provides several options for creating tables. You can use the Dashboard or create them directly using SQL.
We provide a SQL editor within the Dashboard, or you can [connect](https://supabase.com/docs/guides/database/connecting-to-postgres) to your database
and run the SQL queries yourself.

DashboardSQL

1. Go to the [Table Editor](https://supabase.com/dashboard/project/_/editor) page in the Dashboard.
2. Click **New Table** and create a table with the name `todos`.
3. Click **Save**.
4. Click **New Column** and create a column with the name `task` and type `text`.
5. Click **Save**.

When naming tables, use lowercase and underscores instead of spaces (e.g., `table_name`, not `Table Name`).

## Columns [\#](https://supabase.com/docs/guides/database/tables\#columns)

You must define the "data type" when you create a column.

### Data types [\#](https://supabase.com/docs/guides/database/tables\#data-types)

Every column is a predefined type. Postgres provides many [default types](https://www.postgresql.org/docs/current/datatype.html), and you can even design your own (or use extensions) if the default types don't fit your needs. You can use any data type that Postgres supports via the SQL editor. We only support a subset of these in the Table Editor in an effort to keep the experience simple for people with less experience with databases.

Show/Hide default data types

| `Name` | `Aliases` | `Description` |
| --- | --- | --- |
| `bigint` | `int8` | signed eight-byte integer |
| `bigserial` | `serial8` | autoincrementing eight-byte integer |
| `bit` |  | fixed-length bit string |
| `bit varying` | `varbit` | variable-length bit string |
| `boolean` | `bool` | logical Boolean (true/false) |
| `box` |  | rectangular box on a plane |
| `bytea` |  | binary data (byte array) |
| `character` | `char` | fixed-length character string |
| `character varying` | `varchar` | variable-length character string |
| `cidr` |  | IPv4 or IPv6 network address |
| `circle` |  | circle on a plane |
| `date` |  | calendar date (year, month, day) |
| `double precision` | `float8` | double precision floating-point number (8 bytes) |
| `inet` |  | IPv4 or IPv6 host address |
| `integer` | `int`, `int4` | signed four-byte integer |
| `interval [ fields ]` |  | time span |
| `json` |  | textual JSON data |
| `jsonb` |  | binary JSON data, decomposed |
| `line` |  | infinite line on a plane |
| `lseg` |  | line segment on a plane |
| `macaddr` |  | MAC (Media Access Control) address |
| `macaddr8` |  | MAC (Media Access Control) address (EUI-64 format) |
| `money` |  | currency amount |
| `numeric` | `decimal` | exact numeric of selectable precision |
| `path` |  | geometric path on a plane |
| `pg_lsn` |  | Postgres Log Sequence Number |
| `pg_snapshot` |  | user-level transaction ID snapshot |
| `point` |  | geometric point on a plane |
| `polygon` |  | closed geometric path on a plane |
| `real` | `float4` | single precision floating-point number (4 bytes) |
| `smallint` | `int2` | signed two-byte integer |
| `smallserial` | `serial2` | autoincrementing two-byte integer |
| `serial` | `serial4` | autoincrementing four-byte integer |
| `text` |  | variable-length character string |
| `time [ without time zone ]` |  | time of day (no time zone) |
| `time with time zone` | `timetz` | time of day, including time zone |
| `timestamp [ without time zone ]` |  | date and time (no time zone) |
| `timestamp with time zone` | `timestamptz` | date and time, including time zone |
| `tsquery` |  | text search query |
| `tsvector` |  | text search document |
| `txid_snapshot` |  | user-level transaction ID snapshot (deprecated; see pg\_snapshot) |
| `uuid` |  | universally unique identifier |
| `xml` |  | XML data |

You can "cast" columns from one type to another, however there can be some incompatibilities between types.
For example, if you cast a `timestamp` to a `date`, you will lose all the time information that was previously saved.

### Primary keys [\#](https://supabase.com/docs/guides/database/tables\#primary-keys)

A table can have a "primary key" - a unique identifier for every row of data. A few tips for Primary Keys:

- It's recommended to create a Primary Key for every table in your database.
- You can use any column as a primary key, as long as it is unique for every row.
- It's common to use a `uuid` type or a numbered `identity` column as your primary key.

`
create table movies (
id bigint generated always as identity primary key
);
`

In the example above, we have:

1. created a column called `id`
2. assigned the data type `bigint`
3. instructed the database that this should be `generated always as identity`, which means that Postgres will automatically assign a unique number to this column.
4. Because it's unique, we can also use it as our `primary key`.

We could also use `generated by default as identity`, which would allow us to insert our own unique values.

`
create table movies (
id bigint generated by default as identity primary key
);
`

## Loading data [\#](https://supabase.com/docs/guides/database/tables\#loading-data)

There are several ways to load data in Supabase. You can load data directly into the database or using the [APIs](https://supabase.com/docs/guides/database/api).
Use the "Bulk Loading" instructions if you are loading large data sets.

### Basic data loading [\#](https://supabase.com/docs/guides/database/tables\#basic-data-loading)

SQLJavaScriptDartSwiftPythonKotlin

`
insert into movies
(name, description)
values
(
    'The Empire Strikes Back',
    'After the Rebels are brutally overpowered by the Empire on the ice planet Hoth, Luke Skywalker begins Jedi training with Yoda.'
),
(
    'Return of the Jedi',
    'After a daring mission to rescue Han Solo from Jabba the Hutt, the Rebels dispatch to Endor to destroy the second Death Star.'
);
`

### Bulk data loading [\#](https://supabase.com/docs/guides/database/tables\#bulk-data-loading)

When inserting large data sets it's best to use PostgreSQL's [COPY](https://www.postgresql.org/docs/current/sql-copy.html) command.
This loads data directly from a file into a table. There are several file formats available for copying data: text, CSV, binary, JSON, etc.

For example, if you wanted to load a CSV file into your movies table:

./movies.csv

`
"The Empire Strikes Back", "After the Rebels are brutally overpowered by the Empire on the ice planet Hoth, Luke Skywalker begins Jedi training with Yoda."
"Return of the Jedi", "After a daring mission to rescue Han Solo from Jabba the Hutt, the Rebels dispatch to Endor to destroy the second Death Star."
`

You would [connect](https://supabase.com/docs/guides/database/connecting-to-postgres#direct-connections) to your database directly and load the file with the COPY command:

`
psql -h DATABASE_URL -p 5432 -d postgres -U postgres \
  -c "\COPY movies FROM './movies.csv';"
`

Additionally use the `DELIMITER`, `HEADER` and `FORMAT` options as defined in the Postgres [COPY](https://www.postgresql.org/docs/current/sql-copy.html) docs.

`
psql -h DATABASE_URL -p 5432 -d postgres -U postgres \
  -c "\COPY movies FROM './movies.csv' WITH DELIMITER ',' CSV HEADER"
`

If you receive an error `FATAL:  password authentication failed for user "postgres"`, reset your database password in the Database Settings and try again.

## Joining tables with foreign keys [\#](https://supabase.com/docs/guides/database/tables\#joining-tables-with-foreign-keys)

Tables can be "joined" together using Foreign Keys.

![Foreign Keys](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fdatabase%2Fmanaging-tables%2Fjoining-tables--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

This is where the "Relational" naming comes from, as data typically forms some sort of relationship.

In our "movies" example above, we might want to add a "category" for each movie (for example, "Action", or "Documentary").
Let's create a new table called `categories` and "link" our `movies` table.

`
create table categories (
id bigint generated always as identity primary key,
name text -- category name
);
alter table movies
add column category_id bigint references categories;
`

You can also create "many-to-many" relationships by creating a "join" table.
For example if you had the following situations:

- You have a list of `movies`.
- A movie can have several `actors`.
- An `actor` can perform in several movies.

DashboardSQL

Supabase Docs: many-to-many joins - YouTube

Supabase

45.5K subscribers

[Supabase Docs: many-to-many joins](https://www.youtube.com/watch?v=TKwF3IGij5c)

Supabase

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=TKwF3IGij5c "Watch on YouTube")

## Schemas [\#](https://supabase.com/docs/guides/database/tables\#schemas)

Tables belong to `schemas`. Schemas are a way of organizing your tables, often for security reasons.

![Schemas and tables](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fdatabase%2Fmanaging-tables%2Fschemas--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

If you don't explicitly pass a schema when creating a table, Postgres will assume that you want to create the table in the `public` schema.

We can create schemas for organizing tables. For example, we might want a private schema which is hidden from our API:

`
create schema private;
`

Now we can create tables inside the `private` schema:

`
create table private.salaries (
id bigint generated by default as identity primary key,
salary bigint not null,
actor_id bigint not null references public.actors
);
`

## Views [\#](https://supabase.com/docs/guides/database/tables\#views)

A View is a convenient shortcut to a query. Creating a view does not involve new tables or data. When run, an underlying query is executed, returning its results to the user.

Say we have the following tables from a database of a university:

**`students`**

| id | name | type |
| --- | --- | --- |
| 1 | Princess Leia | undergraduate |
| 2 | Yoda | graduate |
| 3 | Anakin Skywalker | graduate |

**`courses`**

| id | title | code |
| --- | --- | --- |
| 1 | Introduction to Postgres | PG101 |
| 2 | Authentication Theories | AUTH205 |
| 3 | Fundamentals of Supabase | SUP412 |

**`grades`**

| id | student\_id | course\_id | result |
| --- | --- | --- | --- |
| 1 | 1 | 1 | B+ |
| 2 | 1 | 3 | A+ |
| 3 | 2 | 2 | A |
| 4 | 3 | 1 | A- |
| 5 | 3 | 2 | A |
| 6 | 3 | 3 | B- |

Creating a view consisting of all the three tables will look like this:

`
create view transcripts as
    select
        students.name,
        students.type,
        courses.title,
        courses.code,
        grades.result
    from grades
    left join students on grades.student_id = students.id
    left join courses on grades.course_id = courses.id;
alter view transcripts owner to authenticated;
`

Once done, we can now access the underlying query with:

`
select * from transcripts;
`

### View security [\#](https://supabase.com/docs/guides/database/tables\#view-security)

By default, views are accessed with their creator's permission ("security definer"). If a privileged role creates a view, others accessing it will use that role's elevated permissions. To enforce row level security policies, define the view with the "security invoker" modifier.

`
-- alter a security_definer view to be security_invoker
alter view <view name>
set (security_invoker = true);
-- create a view with the security_invoker modifier
create view <view name> with(security_invoker=true) as (
select * from <some table>
);
`

### When to use views [\#](https://supabase.com/docs/guides/database/tables\#when-to-use-views)

Views provide the several benefits:

- Simplicity
- Consistency
- Logical Organization
- Security

#### Simplicity [\#](https://supabase.com/docs/guides/database/tables\#simplicity)

As a query becomes more complex, it can be a hassle to call it over and over - especially when we run it regularly. In the example above, instead of repeatedly running:

`
select
students.name,
students.type,
courses.title,
courses.code,
grades.result
from
grades
left join students on grades.student_id = students.id
left join courses on grades.course_id = courses.id;
`

We can run this instead:

`
select * from transcripts;
`

Additionally, a view behaves like a typical table. We can safely use it in table `JOIN` s or even create new views using existing views.

#### Consistency [\#](https://supabase.com/docs/guides/database/tables\#consistency)

Views ensure that the likelihood of mistakes decreases when repeatedly executing a query. In our example above, we may decide that we want to exclude the course _Introduction to Postgres_. The query would become:

`
select
students.name,
students.type,
courses.title,
courses.code,
grades.result
from
grades
left join students on grades.student_id = students.id
left join courses on grades.course_id = courses.id
where courses.code != 'PG101';
`

Without a view, we would need to go into every dependent query to add the new rule. This would increase in the likelihood of errors and inconsistencies, as well as introducing a lot of effort for a developer. With views, we can alter just the underlying query in the view **transcripts**. The change will be applied to all applications using this view.

#### Logical organization [\#](https://supabase.com/docs/guides/database/tables\#logical-organization)

With views, we can give our query a name. This is extremely useful for teams working with the same database. Instead of guessing what a query is supposed to do, a well-named view can explain it. For example, by looking at the name of the view **transcripts**, we can infer that the underlying query might involve the **students**, **courses**, and **grades** tables.

#### Security [\#](https://supabase.com/docs/guides/database/tables\#security)

Views can restrict the amount and type of data presented to a user. Instead of allowing a user direct access to a set of tables, we provide them a view instead. We can prevent them from reading sensitive columns by excluding them from the underlying query.

### Materialized views [\#](https://supabase.com/docs/guides/database/tables\#materialized-views)

A [materialized view](https://www.postgresql.org/docs/12/rules-materializedviews.html) is a form of view but it also stores the results to disk. In subsequent reads of a materialized view, the time taken to return its results would be much faster than a conventional view. This is because the data is readily available for a materialized view while the conventional view executes the underlying query each time it is called.

Using our example above, a materialized view can be created like this:

`
create materialized view transcripts as
select
    students.name,
    students.type,
    courses.title,
    courses.code,
    grades.result
from
    grades
    left join students on grades.student_id = students.id
    left join courses on grades.course_id = courses.id;
`

Reading from the materialized view is the same as a conventional view:

`
select * from transcripts;
`

### Refreshing materialized views [\#](https://supabase.com/docs/guides/database/tables\#refreshing-materialized-views)

Unfortunately, there is a trade-off - data in materialized views are not always up to date. We need to refresh it regularly to prevent the data from becoming too stale. To do so:

`
refresh materialized view transcripts;
`

It's up to you how regularly refresh your materialized views, and it's probably different for each view depending on its use-case.

### Materialized views vs conventional views [\#](https://supabase.com/docs/guides/database/tables\#materialized-views-vs-conventional-views)

Materialized views are useful when execution times for queries or views are too slow. These could likely occur in views or queries involving multiple tables and billions of rows. When using such a view, however, there should be tolerance towards data being outdated. Some use-cases for materialized views are internal dashboards and analytics.

Creating a materialized view is not a solution to inefficient queries. You should always seek to optimize a slow running query even if you are implementing a materialized view.

## Resources [\#](https://supabase.com/docs/guides/database/tables\#resources)

- [Official Docs: Create table](https://www.postgresql.org/docs/current/sql-createtable.html)
- [Official Docs: Create view](https://www.postgresql.org/docs/12/sql-createview.html)
- [Postgres Tutorial: Create tables](https://www.postgresqltutorial.com/postgresql-tutorial/postgresql-create-table/)
- [Postgres Tutorial: Add column](https://www.postgresqltutorial.com/postgresql-tutorial/postgresql-add-column/)
- [Postgres Tutorial: Views](https://www.postgresqltutorial.com/postgresql-views/)

### Is this helpful?

NoYes

### On this page

[Creating tables](https://supabase.com/docs/guides/database/tables#creating-tables) [Columns](https://supabase.com/docs/guides/database/tables#columns) [Data types](https://supabase.com/docs/guides/database/tables#data-types) [Primary keys](https://supabase.com/docs/guides/database/tables#primary-keys) [Loading data](https://supabase.com/docs/guides/database/tables#loading-data) [Basic data loading](https://supabase.com/docs/guides/database/tables#basic-data-loading) [Bulk data loading](https://supabase.com/docs/guides/database/tables#bulk-data-loading) [Joining tables with foreign keys](https://supabase.com/docs/guides/database/tables#joining-tables-with-foreign-keys) [Schemas](https://supabase.com/docs/guides/database/tables#schemas) [Views](https://supabase.com/docs/guides/database/tables#views) [View security](https://supabase.com/docs/guides/database/tables#view-security) [When to use views](https://supabase.com/docs/guides/database/tables#when-to-use-views) [Materialized views](https://supabase.com/docs/guides/database/tables#materialized-views) [Refreshing materialized views](https://supabase.com/docs/guides/database/tables#refreshing-materialized-views) [Materialized views vs conventional views](https://supabase.com/docs/guides/database/tables#materialized-views-vs-conventional-views) [Resources](https://supabase.com/docs/guides/database/tables#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings


![Tables and columns](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fdatabase%2Fmanaging-tables%2Fcreating-tables--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![Foreign Keys](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fdatabase%2Fmanaging-tables%2Fjoining-tables--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![Schemas and tables](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fdatabase%2Fmanaging-tables%2Fschemas--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)
</file>

<file path="supabase_com_docs_guides_database_testing.md">
Database

# Testing Your Database

* * *

To ensure that queries return the expected data, RLS policies are correctly applied and etc., we encourage you to write automated tests. There are essentially two approaches to testing:

- Firstly, you can write tests that interface with a Supabase client instance (same way you use Supabase client in your application code) in the programming language(s) you use in your application and using your favorite testing framework.

- Secondly, you can test through the Supabase CLI, which is a more low-level approach where you write tests in SQL.


# Testing using the Supabase CLI

You can use the Supabase CLI to test your database. The minimum required version of the CLI is [v1.11.4](https://github.com/supabase/cli/releases). To get started:

- [Install the Supabase CLI](https://supabase.com/docs/guides/cli) on your local machine

## Creating a test [\#](https://supabase.com/docs/guides/database/testing\#creating-a-test)

Create a tests folder inside the `supabase` folder:

`
mkdir -p ./supabase/tests/database
`

Create a new file with the `.sql` extension which will contain the test.

`
touch ./supabase/tests/database/hello_world.test.sql
`

## Writing tests [\#](https://supabase.com/docs/guides/database/testing\#writing-tests)

All `sql` files use [pgTAP](https://supabase.com/docs/guides/database/extensions/pgtap) as the test runner.

Let's write a simple test to check that our `auth.users` table has an ID column. Open `hello_world.test.sql` and add the following code:

`
begin;
select plan(1); -- only one statement to run
SELECT has_column(
    'auth',
    'users',
    'id',
    'id should exist'
);
select * from finish();
rollback;
`

## Running tests [\#](https://supabase.com/docs/guides/database/testing\#running-tests)

To run the test, you can use:

`
supabase test db
`

This will produce the following output:

`
$ supabase test db
supabase/tests/database/hello_world.test.sql .. ok
All tests successful.
Files=1, Tests=1,  1 wallclock secs ( 0.01 usr  0.00 sys +  0.04 cusr  0.02 csys =  0.07 CPU)
Result: PASS
`

## More resources [\#](https://supabase.com/docs/guides/database/testing\#more-resources)

- [Testing RLS policies](https://supabase.com/docs/guides/database/extensions/pgtap#testing-rls-policies)
- [pgTAP extension](https://supabase.com/docs/guides/database/extensions/pgtap)
- Official [pgTAP documentation](https://pgtap.org/)

### Is this helpful?

NoYes

### On this page

[Creating a test](https://supabase.com/docs/guides/database/testing#creating-a-test) [Writing tests](https://supabase.com/docs/guides/database/testing#writing-tests) [Running tests](https://supabase.com/docs/guides/database/testing#running-tests) [More resources](https://supabase.com/docs/guides/database/testing#more-resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_vault.md">
Database

# Vault

## Managing secrets in Postgres.

* * *

Vault is a Postgres extension and accompanying Supabase UI that makes it safe and easy to store encrypted secrets and other data in your database. This opens up a lot of possibilities to use Postgres in ways that go beyond what is available in a stock distribution.

Under the hood, the Vault is a table of Secrets and Encryption Keys that are stored using [Authenticated Encryption](https://en.wikipedia.org/wiki/Authenticated_encryption) on disk. They are then available in decrypted form through a Postgres view so that the secrets can be used by applications from SQL. Because the secrets are stored on disk encrypted and authenticated, any backups or replication streams also preserve this encryption in a way that can't be decrypted or forged.

Supabase provides a dashboard UI for the Vault that makes storing secrets easy. Click a button, type in your secret, and save. Optionally create your own keys you can use to encrypt your secret. Your secret will then be stored on disk encrypted using the specified key.

There are two main parts to the Vault UI, Secrets and Encryption Keys:

## Secrets [\#](https://supabase.com/docs/guides/database/vault\#secrets)

You can use the Vault to store secrets - everything from Environment Variables to API Keys. You can then use these secrets anywhere in your database: Postgres [Functions](https://supabase.com/docs/guides/database/functions), Triggers, and [Webhooks](https://supabase.com/docs/guides/database/webhooks). From a SQL perspective, accessing secrets is as easy as querying a table (or in this case, a view). The underlying secrets tables will be stored in encrypted form.

## Encryption keys [\#](https://supabase.com/docs/guides/database/vault\#encryption-keys)

These are keys used to encrypt data inside your database. You can create different Encryption Keys for different purposes, for example: one for encrypting user-data, and another for application-data. Each key is encrypted itself using a root encryption key that lives outside of the database. See **[Encryption key location](https://supabase.com/docs/guides/database/vault#encryption-key-location)** for more details.

## Using the Vault [\#](https://supabase.com/docs/guides/database/vault\#using-the-vault)

You can manage secrets and encryption keys from the UI or using SQL.

### Adding secrets [\#](https://supabase.com/docs/guides/database/vault\#adding-secrets)

There is also a handy function for creating secrets called `vault.create_secret()`:

`
select vault.create_secret('my_s3kre3t');
`

The function returns the UUID of the new secret.

Show Result

`
-[ RECORD 1 ]-+-------------------------------------
create_secret | c9b00867-ca8b-44fc-a81d-d20b8169be17
`

Secrets can also have an optional _unique_ name and an optional description. These are also arguments to `vault.create_secret()`:

`
select vault.create_secret('another_s3kre3t', 'unique_name', 'This is the description');
`

Show Result

`
-[ RECORD 1 ]-----------------------------------------------------------------
id          | 7095d222-efe5-4cd5-b5c6-5755b451e223
name        | unique_name
description | This is the description
secret      | 3mMeOcoG84a5F2uOfy2ugWYDp9sdxvCTmi6kTeT97bvA8rCEsG5DWWZtTU8VVeE=
key_id      | c62da7a0-b85d-471d-8ea7-52aae21d7354
nonce       | \x9f2d60954ba5eb566445736e0760b0e3
created_at  | 2022-12-14 02:34:23.85159+00
updated_at  | 2022-12-14 02:34:23.85159+00
`

Alternatively, you can create a secret by inserting data into the `vault.secret` table:

`
insert into vault.secrets (secret)
values ('s3kre3t_k3y') returning *;
`

Show Result

`
-[ RECORD 1 ]-------------------------------------------------------------
id          | d91596b8-1047-446c-b9c0-66d98af6d001
name        |
description |
secret      | S02eXS9BBY+kE3r621IS8beAytEEtj+dDHjs9/0AoMy7HTbog+ylxcS22A==
key_id      | 7f5ad44b-6bd5-4c99-9f68-4b6c7486f927
nonce       | \x3aa2e92f9808e496aa4163a59304b895
created_at  | 2022-12-14 02:29:21.3625+00
updated_at  | 2022-12-14 02:29:21.3625+00
`

### Viewing secrets [\#](https://supabase.com/docs/guides/database/vault\#viewing-secrets)

If you look in the `vault.secrets` table, you will see that your data is stored encrypted. To decrypt the data, there is an automatically created view `vault.decrypted_secrets`. This view will decrypt secret data on the fly:

`
select *
from vault.decrypted_secrets
order by created_at desc
limit 3;
`

Show Result

`
-[ RECORD 1 ]----+-----------------------------------------------------------------
id               | 7095d222-efe5-4cd5-b5c6-5755b451e223
name             | unique_name
description      | This is the description
secret           | 3mMeOcoG84a5F2uOfy2ugWYDp9sdxvCTmi6kTeT97bvA8rCEsG5DWWZtTU8VVeE=
decrypted_secret | another_s3kre3t
key_id           | c62da7a0-b85d-471d-8ea7-52aae21d7354
nonce            | \x9f2d60954ba5eb566445736e0760b0e3
created_at       | 2022-12-14 02:34:23.85159+00
updated_at       | 2022-12-14 02:34:23.85159+00
-[ RECORD 2 ]----+-----------------------------------------------------------------
id               | c9b00867-ca8b-44fc-a81d-d20b8169be17
name             |
description      |
secret           | a1CE4vXwQ53+N9bllJj1D7fasm59ykohjb7K90PPsRFUd9IbBdxIGZNoSQLIXl4=
decrypted_secret | another_s3kre3t
key_id           | 8c72b05e-b931-4372-abf9-a09cfad18489
nonce            | \x1d3b2761548c4efb2d29ca11d44aa22f
created_at       | 2022-12-14 02:32:50.58921+00
updated_at       | 2022-12-14 02:32:50.58921+00
-[ RECORD 3 ]----+-----------------------------------------------------------------
id               | d91596b8-1047-446c-b9c0-66d98af6d001
name             |
description      |
secret           | S02eXS9BBY+kE3r621IS8beAytEEtj+dDHjs9/0AoMy7HTbog+ylxcS22A==
decrypted_secret | s3kre3t_k3y
key_id           | 7f5ad44b-6bd5-4c99-9f68-4b6c7486f927
nonce            | \x3aa2e92f9808e496aa4163a59304b895
created_at       | 2022-12-14 02:29:21.3625+00
updated_at       | 2022-12-14 02:29:21.3625+00
`

Notice how this view has a `decrypted_secret` column that contains the decrypted secrets. Views are not stored on disk, they are only run at query time, so the secret remains encrypted on disk, and in any backup dumps or replication streams.

You should ensure that you protect access to this view with the appropriate SQL privilege settings at all times, as anyone that has access to the view has access to decrypted secrets.

### Updating secrets [\#](https://supabase.com/docs/guides/database/vault\#updating-secrets)

A secret can be updated with the `vault.update_secret()` function, this function makes updating secrets easy, just provide the secret UUID as the first argument, and then an updated secret, updated optional unique name, or updated description:

`
select
vault.update_secret(
    '7095d222-efe5-4cd5-b5c6-5755b451e223',
    'n3w_upd@ted_s3kret',
    'updated_unique_name',
    'This is the updated description'
);
`

Show Result

`
-[ RECORD 1 ]-+-
update_secret |
postgres=> select * from vault.decrypted_secrets where id = '7095d222-efe5-4cd5-b5c6-5755b451e223';
-[ RECORD 1 ]----+---------------------------------------------------------------------
id               | 7095d222-efe5-4cd5-b5c6-5755b451e223
name             | updated_unique_name
description      | This is the updated description
secret           | lhb3HBFxF+qJzp/HHCwhjl4QFb5dYDsIQEm35DaZQOovdkgp2iy6UMufTKJGH4ThMrU=
decrypted_secret | n3w_upd@ted_s3kret
key_id           | c62da7a0-b85d-471d-8ea7-52aae21d7354
nonce            | \x9f2d60954ba5eb566445736e0760b0e3
created_at       | 2022-12-14 02:34:23.85159+00
updated_at       | 2022-12-14 02:51:13.938396+00
`

## Deep dive [\#](https://supabase.com/docs/guides/database/vault\#deep-dive)

Encrypted Columns in PostgreSQL - Secrets Management with Supabase Vault - YouTube

Supabase

45.5K subscribers

[Encrypted Columns in PostgreSQL - Secrets Management with Supabase Vault](https://www.youtube.com/watch?v=QHLPNDrdN2w)

Supabase

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

Full screen is unavailable. [Learn More](https://support.google.com/youtube/answer/6276924)

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=QHLPNDrdN2w "Watch on YouTube")

As we mentioned, the Vault uses `pgsodium`'s Transparent Column Encryption (TCE) to store secrets in an authenticated encrypted form. There are some details around that you may be curious about, what does authenticated mean, and where are encryption keys store? This section explains those details.

### Authenticated encryption with associated data [\#](https://supabase.com/docs/guides/database/vault\#authenticated-encryption-with-associated-data)

The first important feature of TCE is that it uses an [Authenticated Encryption with Associated Data](https://en.wikipedia.org/wiki/Authenticated_encryption#Authenticated_encryption_with_associated_data_(AEAD)) encryption algorithm (based on `libsodium`).

### Encryption key location [\#](https://supabase.com/docs/guides/database/vault\#encryption-key-location)

**Authenticated Encryption** means that in addition to the data being encrypted, it is also signed so that it cannot be forged. You can guarantee that the data was encrypted by someone you trust, which you wouldn't get with encryption alone. The decryption function verifies that the signature is valid _before decrypting the value_.

**Associated Data** means that you can include any other columns from the same row as part of the signature computation. This doesn't encrypt those other columns - rather it ensures that your encrypted value is only associated with columns from that row. If an attacker were to copy an encrypted value from another row to the current one, the signature would be rejected (assuming you used a unique column in the associated data).

Another important feature of `pgsodium` is that the encryption keys are never stored in the database alongside the encrypted data. Instead, only a **Key ID** is stored, which is a reference to the key that is only accessible outside of SQL. Even if an attacker can capture a dump of your entire database, they will see only encrypted data and key IDs, _never the raw key itself_.

This is an important safety precaution - there is little value in storing the encryption key in the database itself as this would be like locking your front door but leaving the key in the lock! Storing the key outside the database fixes this issue.

Where are the keys stored? Supabase creates and manages the root keys (from which all key IDs are derived) in our secured backend systems. We keep this root key safe and separate from your data. You remain in control of your keys - a separate API endpoint is available that you can use to access the key if you want to decrypt your data outside of Supabase.

### Internal details [\#](https://supabase.com/docs/guides/database/vault\#internal-details)

To encrypt data, you need a _key id_. You can use the default key id created automatically for every project, or create your own key ids Using the `pgsodium.create_key()` function. Key ids are used to internally derive the encryption key used to encrypt secrets in the vault. Vault users typically do not have access to the key itself, only the key id.

Both `vault.create_secret()` and `vault.update_secret()` take an optional fourth `new_key_id` argument. This argument can be used to store a different key id for the secret instead of the default value.

`
select vault.create_secret(
'another_s3kre3t_key',
'another_unique_name',
'This is another description',
(pgsodium.create_key()).id
);
`

Result:

`
-[ RECORD 1 ]-+-------------------------------------
create_secret | cec9e005-a44d-4b19-86e1-febf3cd40619
`

Which roles should have access to the `vault.secrets` table should be carefully considered. There are two ways to grant access, the first is that the `postgres` user can explicitly grant access to the vault table itself.

### Resources [\#](https://supabase.com/docs/guides/database/vault\#resources)

- Read more about Supabase Vault in the [blog post](https://supabase.com/blog/vault-now-in-beta)
- [Supabase Vault on GitHub](https://github.com/supabase/vault)
- [Column Encryption](https://supabase.com/docs/guides/database/column-encryption)

### Is this helpful?

NoYes

### On this page

[Secrets](https://supabase.com/docs/guides/database/vault#secrets) [Encryption keys](https://supabase.com/docs/guides/database/vault#encryption-keys) [Using the Vault](https://supabase.com/docs/guides/database/vault#using-the-vault) [Adding secrets](https://supabase.com/docs/guides/database/vault#adding-secrets) [Viewing secrets](https://supabase.com/docs/guides/database/vault#viewing-secrets) [Updating secrets](https://supabase.com/docs/guides/database/vault#updating-secrets) [Deep dive](https://supabase.com/docs/guides/database/vault#deep-dive) [Authenticated encryption with associated data](https://supabase.com/docs/guides/database/vault#authenticated-encryption-with-associated-data) [Encryption key location](https://supabase.com/docs/guides/database/vault#encryption-key-location) [Internal details](https://supabase.com/docs/guides/database/vault#internal-details) [Resources](https://supabase.com/docs/guides/database/vault#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_database_webhooks.md">
Database

# Database Webhooks

## Trigger external payloads on database events.

* * *

Database Webhooks allow you to send real-time data from your database to another system whenever a table event occurs.

You can hook into three table events: `INSERT`, `UPDATE`, and `DELETE`. All events are fired _after_ a database row is changed.

## Webhooks vs triggers [\#](https://supabase.com/docs/guides/database/webhooks\#webhooks-vs-triggers)

Database Webhooks are very similar to triggers, and that's because Database Webhooks are just a convenience wrapper around triggers using the [pg\_net](https://supabase.com/docs/guides/database/extensions/pgnet) extension. This extension is asynchronous, and therefore will not block your database changes for long-running network requests.

This video demonstrates how you can create a new customer in Stripe each time a row is inserted into a `profiles` table:

Automate API requests with Database Webhooks in Supabase - YouTube

Supabase

45.5K subscribers

[Automate API requests with Database Webhooks in Supabase](https://www.youtube.com/watch?v=codAs9-NeHM)

Supabase

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=codAs9-NeHM "Watch on YouTube")

## Creating a webhook [\#](https://supabase.com/docs/guides/database/webhooks\#creating-a-webhook)

1. Create a new [Database Webhook](https://supabase.com/dashboard/project/_/integrations/hooks) in the Dashboard.
2. Give your Webhook a name.
3. Select the table you want to hook into.
4. Select one or more events (table inserts, updates, or deletes) you want to hook into.

Since webhooks are just database triggers, you can also create one from SQL statement directly.

`
create trigger "my_webhook" after insert
on "public"."my_table" for each row
execute function "supabase_functions"."http_request"(
'http://localhost:3000',
'POST',
'{"Content-Type":"application/json"}',
'{}',
'1000'
);
`

We currently support HTTP webhooks. These can be sent as `POST` or `GET` requests with a JSON payload.

## Payload [\#](https://supabase.com/docs/guides/database/webhooks\#payload)

The payload is automatically generated from the underlying table record:

`
type InsertPayload = {
type: 'INSERT'
table: string
schema: string
record: TableRecord<T>
old_record: null
}
type UpdatePayload = {
type: 'UPDATE'
table: string
schema: string
record: TableRecord<T>
old_record: TableRecord<T>
}
type DeletePayload = {
type: 'DELETE'
table: string
schema: string
record: null
old_record: TableRecord<T>
}
`

## Monitoring [\#](https://supabase.com/docs/guides/database/webhooks\#monitoring)

Logging history of webhook calls is available under the `net` schema of your database. For more info, see the [GitHub Repo](https://github.com/supabase/pg_net).

## Resources [\#](https://supabase.com/docs/guides/database/webhooks\#resources)

- [pg\_net](https://supabase.com/docs/guides/database/extensions/pgnet): an async networking extension for Postgres

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2FcodAs9-NeHM%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Webhooks vs triggers](https://supabase.com/docs/guides/database/webhooks#webhooks-vs-triggers) [Creating a webhook](https://supabase.com/docs/guides/database/webhooks#creating-a-webhook) [Payload](https://supabase.com/docs/guides/database/webhooks#payload) [Monitoring](https://supabase.com/docs/guides/database/webhooks#monitoring) [Resources](https://supabase.com/docs/guides/database/webhooks#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_deployment_branching.md">
Home

# Branching

## Use Supabase Branches to test and preview changes

* * *

Use branching to safely experiment with changes to your Supabase project.

Supabase branches work like Git branches. They let you create and test changes like new configurations, database schemas, or features in a separate, temporary instance without affecting your production setup.

When you're ready to ship your changes, merge your branch to update your production instance with the new changes.

If you understand Git, you already understand Supabase Branching.

## How branching works [\#](https://supabase.com/docs/guides/deployment/branching\#how-branching-works)

- **Separate Environments**: Each branch is a separate environment with its own Supabase instance and API credentials.
- **Git Integration**: Branching works with Git, currently supporting GitHub repositories.
- **Preview Branches**: You can create multiple Preview Branches for testing.
- **Migrations and Seeding**: Branches run migrations from your repository and can seed data using a `seed.sql` file.

## Prerequisites [\#](https://supabase.com/docs/guides/deployment/branching\#prerequisites)

- **Supabase Project**: You need an existing Supabase project.
- **GitHub Repository**: Your project must be connected to a GitHub repository containing your Supabase directory.

You can run multiple Preview Branches for every Supabase project. Branches contain all the Supabase features with their own API credentials.

Preview Environments auto-pause after 5 minutes of inactivity. Upon receiving a new request to your database or REST API, the paused branch will automatically resume to serve the request. The implications of this architecture means

- `pg_cron` jobs will not execute in an auto-paused database.
- Larger variance in request latency due to database cold starts.

If you need higher performance guarantees on your Preview Environment, you can switch individual branches to [persistent](https://supabase.com/docs/guides/deployment/branching#persistent-branches) so they are not auto-paused.

![Each branch has a separate Supabase instance.](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fbranching%2Fgithub-workflow-without-branching--light.jpg%3Fv%3D1&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

Each Branch is a separate environment.

### Branching workflow [\#](https://supabase.com/docs/guides/deployment/branching\#branching-workflow)

Preview Branch instances contain no data by default. You must include a seed file to seed your preview instance with sample data when the Preview Branch is created. Future versions of Branching may allow for automated data seeding and cloning after we are confident that we can provide safe data masking.

## Git providers [\#](https://supabase.com/docs/guides/deployment/branching\#git-providers)

To manage code changes, your Supabase project must be connected to a Git repository. At this stage, we only support [GitHub](https://supabase.com/docs/guides/deployment/branching#branching-with-github). If you are interested in other Git providers, join the [discussion](https://github.com/orgs/supabase/discussions/18936) for GitLab, Bitbucket, and non-Git based Branching.

### Branching with GitHub [\#](https://supabase.com/docs/guides/deployment/branching\#branching-with-github)

Supabase Branching uses the Supabase GitHub integration to read files from your GitHub repository. With this integration, Supabase watches all commits, branches, and pull requests of your GitHub repository.

You can create a corresponding Preview Branch for any Git branch in your repository. Each time a new Preview Branch is created and configured based on the [`config.toml`](https://supabase.com/docs/guides/local-development/cli/config) configuration on this branch, the migrations from the corresponding Git branch are run on the Preview Branch.

The Preview Branch is also [seeded](https://supabase.com/docs/guides/local-development/seeding-your-database) with sample data based on `./supabase/seed.sql` by default, if that file exists.

Supabase Branching follows the [Trunk Based Development](https://trunkbaseddevelopment.com/) workflow, with one main Production branch and multiple development branches:

![Each GitHub branch can have its own Supabase preview branch.](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fbranching%2Fgithub-workflow--light.jpg%3Fv%3D1&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

Each GitHub branch can have its own Supabase preview branch.

When you merge your Git branch into the production branch, all new migrations will be applied to your Production environment. If you have declared Storage buckets or Edge Functions in `config.toml`, they will also be deployed automatically. All other configurations, including API, Auth, and seed files, will be ignored by default.

##### Data changes are not merged into production.

### Preparing your Git repository [\#](https://supabase.com/docs/guides/deployment/branching\#preparing-your-git-repository)

You can use the [Supabase CLI](https://supabase.com/docs/guides/cli) to manage changes inside a local `./supabase` directory:

Existing projectNew Project

1

### Initialize Supabase locally

If you don't have a `./supabase` directory, you can create one:

`
supabase init
`

2

### Pull your database migration

Pull your database changes using `supabase db pull`. You can find your database URL in your [database settings](https://supabase.com/dashboard/project/_/settings/database), under the URI tab of the Connection String settings panel. Make sure **Use connection pooling** is checked so you can use the IPv4-enabled connection pooler. (Without connection pooling, your database is only accessible over IPv6, which isn't yet supported by all network providers.)

`
supabase db pull --db-url <db_url>
# Your Database URL looks something like:
# postgres://postgres.xxxx:password@xxxx.pooler.supabase.com:6543/postgres
`

3

### Commit the \`supabase\` directory to Git

Commit the `supabase` directory to Git, and push your changes to your remote repository.

`
git add supabase
git commit -m "Initial migration"
git push
`

### Enable Supabase branching [\#](https://supabase.com/docs/guides/deployment/branching\#enable-supabase-branching)

Once your repository is [correctly prepared](https://supabase.com/docs/guides/deployment/branching#preparing-your-git-repository), you can enable branching from the Supabase dashboard.

##### Prepare your GitHub repository before enabling Branching

If your repository doesn't have all the migration files, your production branch could run an incomplete set of migrations. Make sure your [GitHub repository is prepared](https://supabase.com/docs/guides/deployment/branching#preparing-your-git-repository).

1

### Inside your Supabase project, click \`Enable branching\`

![](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fbranching%2Fenable-supabase-branching-opt-in-popover.jpg%3Fv%3D1&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

2

### Install the GitHub integration

When clicking `Enable branching` you will see the following dialog:

![](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fbranching%2Fenable-supabase-branching-opt-in-install-github.jpg%3Fv%3D1&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

If you don't have the GitHub integration installed, click `Add new project connection`. The integration is required to run migration files and the optional database seed file.

You're taken to the GitHub integration page. Click `Install`.

![](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fbranching%2Fenable-supabase-branching-opt-in-install-github-permissions.jpg%3Fv%3D1&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

Follow the instructions to link your Supabase project to its GitHub repository.

![](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fbranching%2Fenable-supabase-branching-opt-in-install-github-integration-link.jpg%3Fv%3D1&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

Return to your project and re-click `Enable branching`.

3

### You should now see a popover with the GitHub Connection details shown

Type in the branch you want to use for production. The name of the branch will be validated to make sure it exists in your GitHub repository.

##### Your production branch can't be changed while branching is enabled.

To change your production branch, you need to disable branching and re-enable it with a different branch.

![](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fbranching%2Fenable-supabase-branching-opt-in-install-production-branch.jpg%3Fv%3D1&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

4

### Click \`I understand, enable branching\`. Branching is now enabled for your project.

### Open a pull request [\#](https://supabase.com/docs/guides/deployment/branching\#open-a-pull-request)

When you open a pull request on GitHub, the Supabase integration automatically checks for a matching preview branch. If one doesn't exist, it gets created.

A comment is added to your PR with the deployment status of your preview branch. Statuses are shown separately for Database, Services, and APIs.

![GitHub view of the deployment status of your preview branch](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fbranching%2Fdevelop-your-app-open-pull-request-github.jpg%3Fv%3D1&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

Supabase GitHub integration will comment on your PR with the status of your Preview Branch, including whether migrations have successfully run.

Every time a new commit is pushed that changes the migration files in `./supabase/migrations`, the new migrations are run against the preview branch. You can check the status of these runs in the comment's Tasks table.

### Preventing migration failures [\#](https://supabase.com/docs/guides/deployment/branching\#preventing-migration-failures)

We highly recommend turning on a 'required check' for the Supabase integration. You can do this from your GitHub repository settings. This prevents PRs from being merged when migration checks fail, and stops invalid migrations from being merged into your production branch.

![Check the "Require status checks to pass before merging" option.](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fbranching%2Fgithub-required-check.jpg%3Fv%3D1&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

Check the "Require status checks to pass before merging" option.

### Manually create a preview branch [\#](https://supabase.com/docs/guides/deployment/branching\#manually-create-a-preview-branch)

Preview branches are automatically created for each pull request, but you can also manually create one.

1

### Create a new Git branch in your GitHub repository

You need at least one other branch aside from your Supabase production branch.

![](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fbranching%2Fenable-supabase-branching-first-preview-branch-github.jpg%3Fv%3D1&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)You can use the GitHub dashboard or command line to create a new branch. In this example, the new branch is called `feat/add-members`.

2

### Navigate to the Branches page in your Supabase dashboard.

In the Supabase dashboard, look for the branch dropdown on the right-hand side of the top bar. It should be set to your production branch by default. Open the dropdown and click [`Manage branches`](https://supabase.com/dashboard/project/_/branches).

![](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fbranching%2Fenable-supabase-branching-first-preview-branch-branch-dropdown.jpg%3Fv%3D1&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

3

### Create a Supabase preview branch

Click `Create preview branch`.

![](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fbranching%2Fenable-supabase-branching-first-preview-branch-branch-action.jpg%3Fv%3D1&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

Type in the branch name you want to add. Click `Create branch` to confirm.

##### Only branches from the repository can be used to create a Preview Branch

Git branches from external contributors currently can't support a Preview Branch

![](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fbranching%2Fenable-supabase-branching-first-preview-branch-choose-branch.jpg%3Fv%3D1&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

The Git integration watches for changes in the `supabase` directory. This includes:

- All SQL migration files, under the subdirectory `migrations`
- An optional `seed.sql` file, used to seed preview instances with sample data

You can create new migrations either [locally](https://supabase.com/docs/guides/deployment/branching#develop-locally) or [remotely](https://supabase.com/docs/guides/deployment/branching#develop-remotely). Local development is recommended.

Local DevelopmentRemote Development

The Supabase CLI provides two options: [manual migrations](https://supabase.com/docs/guides/deployment/database-migrations) and [generated migrations](https://supabase.com/docs/guides/deployment/database-migrations#diffing-changes) using Supabase's local studio and the `supabase db-diff` command. Let's use the latter and push the change to our Preview Branch:

1

### Make schema changes locally

Start Supabase locally:

`
supabase start
`

Then proceed to [localhost:54323](http://localhost:54323/) to access your local Supabase dashboard.

You can make changes in either the [Table Editor](http://localhost:54323/project/default/editor) or the [SQL Editor](https://supabase.com/docs/guides/deployment/(http://localhost:54323/project/default/sql)).

2

### Generate a migration file

Once you are finished making database changes, run `supabase db diff` to create a new migration file. For example:

`
supabase db diff -f "add_employees_table"
`

This will create a SQL file called `./supabase/migrations/[timestamp]add_employees_table.sql`. This file will reflect the changes that you made in your local dashboard.

If you want to continue making changes, you can manually edit this migration file, then use the `db reset` command to pick up your edits:

`
supabase db reset
`

This will reset the database and run all the migrations again. The local dashboard at [localhost:54323](http://localhost:54323/) will reflect the new changes you made.

3

### Commit your changes and push.

Commit and push your migration file to your remote GitHub repository. For example:

`
git add supabase/migrations
git commit -m "Add employees table"
git push --set-upstream origin new-employee
`

The Supabase integration detects the new migration and runs it on the remote Preview Branch. It can take up to 10 minutes for migrations to be applied. If you have a PR for your branch, errors are reflected in the GitHub check run status and in a PR comment.

If you need to reset your database to a clean state (that is, discard any changes that aren't reflected in the migration files), run `supabase db reset` locally. Then, delete the preview branch and recreate it by closing, and reopening your pull request.

### Disable branching [\#](https://supabase.com/docs/guides/deployment/branching\#disable-branching)

You can disable branching at any time. Navigate to the [Branches](https://supabase.com/dashboard/project/_/branches) page, which can be found via the Branches dropdown menu on the top navigation, then click "Manage Branches" in the menu. Click the 'Disable branching' button at the top of the Overview section.

### Persistent branches [\#](https://supabase.com/docs/guides/deployment/branching\#persistent-branches)

Persistent branches are the type of branches that will remain active even after the underlying PR is closed.
You can change any branch to be persistent on the [Branches](https://supabase.com/dashboard/project/_/branches) page by clicking the triple dots icon next to the branch you want to modify, and selecting "Switch to persistent".
All persistent branches can be toggled back to be an ephemeral branch in the exact same way.

## Migration and seeding behavior [\#](https://supabase.com/docs/guides/deployment/branching\#migration-and-seeding-behavior)

Migrations are run in sequential order. Each migration builds upon the previous one.

The preview branch has a record of which migrations have been applied, and only applies new migrations for each commit. This can create an issue when rolling back migrations.

## Branch configuration with remotes [\#](https://supabase.com/docs/guides/deployment/branching\#branch-configuration-with-remotes)

When Branching is enabled, your `config.toml` settings automatically sync to all ephemeral branches through a one-to-one mapping between your Git and Supabase branches.

### Basic configuration [\#](https://supabase.com/docs/guides/deployment/branching\#basic-configuration)

To update configuration for a Supabase branch, modify `config.toml` and push to git. The Supabase integration will detect the changes and apply them to the corresponding branch.

### Remote-specific configuration [\#](https://supabase.com/docs/guides/deployment/branching\#remote-specific-configuration)

For persistent branches that need specific settings, you can use the `[remotes]` block in your `config.toml`. Each remote configuration must reference an existing project ID.

Here's an example of configuring a separate seed script for a staging environment:

`
[remotes.staging]
project_id = "your-project-ref"
[remotes.staging.db.seed]
sql_paths = ["./seeds/staging.sql"]
`

Since the `project_id` field must reference an existing branch, you need to create the persistent branch before adding its configuration. Use the CLI to create a persistent branch first:

`
supabase --experimental branches create --persistent
# Do you want to create a branch named develop? [Y/n]
`

### Configuration merging [\#](https://supabase.com/docs/guides/deployment/branching\#configuration-merging)

When merging a PR into a persistent branch, the Supabase integration:

1. Checks for configuration changes
2. Logs the changes
3. Applies them to the target remote

If no remote is declared or the project ID is incorrect, the configuration step is skipped.

### Available configuration options [\#](https://supabase.com/docs/guides/deployment/branching\#available-configuration-options)

All standard configuration options are available in the `[remotes]` block. This includes:

- Database settings
- API configurations
- Authentication settings
- Edge Functions configuration
- And more

You can use this to maintain different configurations for different environments while keeping them all in version control.

### Rolling back migrations [\#](https://supabase.com/docs/guides/deployment/branching\#rolling-back-migrations)

You might want to roll back changes you've made in an earlier migration change. For example, you may have pushed a migration file containing schema changes you no longer want.

To fix this, push your latest changes, then delete the preview branch in Supabase and reopen it.

The new preview branch is reseeded from your `./supabase/seed.sql` file by default. Any additional data changes you made on the old preview branch are lost. This is equivalent to running `supabase db reset` locally. All migrations are rerun in sequential order.

### Seeding behavior [\#](https://supabase.com/docs/guides/deployment/branching\#seeding-behavior)

Your Preview Branches are seeded with sample data using the same as [local seeding behavior](https://supabase.com/docs/guides/local-development/seeding-your-database).

The database is only seeded once, when the preview branch is created. To rerun seeding, delete the preview branch and recreate it by closing, and reopening your pull request.

## Branching and hosting providers [\#](https://supabase.com/docs/guides/deployment/branching\#branching-and-hosting-providers)

Branching works with hosting providers that support preview deployments.

With the Supabase branching integration, you can sync the Git branch used by the hosting provider with the corresponding Supabase preview branch. This means that the preview deployment built by your hosting provider is matched to the correct database schema, edge functions, and other Supabase configurations.

### Vercel [\#](https://supabase.com/docs/guides/deployment/branching\#vercel)

Install the Vercel integration:

- From the [Vercel marketplace](https://vercel.com/integrations/supabase) or
- By clicking the blue `Deploy` button in a Supabase example app's `README` file

##### Vercel GitHub integration also required.

For branching to work with Vercel, you also need the [Vercel GitHub integration](https://vercel.com/docs/deployments/git/vercel-for-github).

And make sure you have [connected](https://supabase.com/dashboard/org/_/integrations) your Supabase project to your Vercel project.

Supabase automatically updates your Vercel project with the correct environment variables for the corresponding preview branches. The synchronization happens at the time of Pull Request being opened, not at the time of branch creation.

As branching integration is tied to the Preview Deployments feature in Vercel, there are possible race conditions between Supabase setting correct variables, and Vercel running a deployment process. Because of that, Supabase is always automatically re-deploying the most recent deployment of the given pull request.

## Other Git providers [\#](https://supabase.com/docs/guides/deployment/branching\#other-git-providers)

There are multiple alternative Git providers under consideration. If you're interested in branching for GitLab, Bitbucket, or some other provider, [join the GitHub discussion](https://github.com/orgs/supabase/discussions/18938).

## Alternatives to branching [\#](https://supabase.com/docs/guides/deployment/branching\#alternatives-to-branching)

Under the hood, you can see Supabase branching as a way to programmatically "duplicate" your Supabase project via git flow. This allows spawning a new configured (via [`config.toml`](https://supabase.com/docs/guides/local-development/cli/config)) and seeded instance of the database and the adjacent Supabase services (buckets, edge functions, etc.).

1. A new project is deployed on behalf of the user on the Supabase side as the new "branch" if it doesn't already exist. This includes the database, storage, edge-function, and all Supabase-related services.
2. The branch is cloned and the new project is configured based on the [`config.toml`](https://supabase.com/docs/guides/local-development/cli/config) committed into this project branch.
3. Migrations are applied and seeding scripts are run (the first time) for this branch.

You can make a similar setup with a distinct project for each environment. Or just have two environments, the localhost and the production one.

## Pricing [\#](https://supabase.com/docs/guides/deployment/branching\#pricing)

Branching is available on the Pro Plan and above. The price is:

- Each Preview branch costs $0.32 per day
- Each Preview branch is billed until it is removed

## Troubleshooting [\#](https://supabase.com/docs/guides/deployment/branching\#troubleshooting)

### Rolling back migrations [\#](https://supabase.com/docs/guides/deployment/branching\#rolling-back-migrations)

You might want to roll back changes you've made in an earlier migration change. For example, you may have pushed a migration file containing schema changes you no longer want.

To fix this, push the latest changes, then delete the preview branch in Supabase and reopen it.

The new preview branch is reseeded from the `./supabase/seed.sql` file by default. Any additional data changes made on the old preview branch are lost. This is equivalent to running `supabase db reset` locally. All migrations are rerun in sequential order.

### Deployment failures [\#](https://supabase.com/docs/guides/deployment/branching\#deployment-failures)

A deployment might fail for various reasons, including invalid SQL statements and schema conflicts in migrations, errors within the `config.toml` config, or something else.

To check the error message, see the Supabase workflow run for your branch under the [View logs](https://supabase.com/dashboard/project/_/branches) section.

### Schema drift between preview branches [\#](https://supabase.com/docs/guides/deployment/branching\#schema-drift-between-preview-branches)

If multiple preview branches exist, each preview branch might contain different schema changes. This is similar to Git branches, where each branch might contain different code changes.

When a preview branch is merged into the production branch, it creates a schema drift between the production branch and the preview branches that haven't been merged yet.

These conflicts can be resolved in the same way as normal Git Conflicts: merge or rebase from the production Git branch to the preview Git branch. Since migrations are applied sequentially, ensure that migration files are timestamped correctly after the rebase. Changes that build on top of earlier changes should always have later timestamps.

### Changing production branch [\#](https://supabase.com/docs/guides/deployment/branching\#changing-production-branch)

It's not possible to change the Git branch used as the Production branch for Supabase Branching. The only way to change it is to disable and re-enable branching. See [Disable Branching](https://supabase.com/docs/guides/deployment/branching#disable-branching).

## Feedback [\#](https://supabase.com/docs/guides/deployment/branching\#feedback)

Supabase branching is a new and exciting part of the Supabase development ecosystem. Feedback is welcome.

You can join the [conversation over in GitHub discussions](https://github.com/orgs/supabase/discussions/18937).

### Is this helpful?

NoYes

### On this page

[How branching works](https://supabase.com/docs/guides/deployment/branching#how-branching-works) [Prerequisites](https://supabase.com/docs/guides/deployment/branching#prerequisites) [Branching workflow](https://supabase.com/docs/guides/deployment/branching#branching-workflow) [Git providers](https://supabase.com/docs/guides/deployment/branching#git-providers) [Branching with GitHub](https://supabase.com/docs/guides/deployment/branching#branching-with-github) [Preparing your Git repository](https://supabase.com/docs/guides/deployment/branching#preparing-your-git-repository) [Enable Supabase branching](https://supabase.com/docs/guides/deployment/branching#enable-supabase-branching) [Open a pull request](https://supabase.com/docs/guides/deployment/branching#open-a-pull-request) [Preventing migration failures](https://supabase.com/docs/guides/deployment/branching#preventing-migration-failures) [Manually create a preview branch](https://supabase.com/docs/guides/deployment/branching#manually-create-a-preview-branch) [Disable branching](https://supabase.com/docs/guides/deployment/branching#disable-branching) [Persistent branches](https://supabase.com/docs/guides/deployment/branching#persistent-branches) [Migration and seeding behavior](https://supabase.com/docs/guides/deployment/branching#migration-and-seeding-behavior) [Branch configuration with remotes](https://supabase.com/docs/guides/deployment/branching#branch-configuration-with-remotes) [Basic configuration](https://supabase.com/docs/guides/deployment/branching#basic-configuration) [Remote-specific configuration](https://supabase.com/docs/guides/deployment/branching#remote-specific-configuration) [Configuration merging](https://supabase.com/docs/guides/deployment/branching#configuration-merging) [Available configuration options](https://supabase.com/docs/guides/deployment/branching#available-configuration-options) [Rolling back migrations](https://supabase.com/docs/guides/deployment/branching#rolling-back-migrations) [Seeding behavior](https://supabase.com/docs/guides/deployment/branching#seeding-behavior) [Branching and hosting providers](https://supabase.com/docs/guides/deployment/branching#branching-and-hosting-providers) [Vercel](https://supabase.com/docs/guides/deployment/branching#vercel) [Other Git providers](https://supabase.com/docs/guides/deployment/branching#other-git-providers) [Alternatives to branching](https://supabase.com/docs/guides/deployment/branching#alternatives-to-branching) [Pricing](https://supabase.com/docs/guides/deployment/branching#pricing) [Troubleshooting](https://supabase.com/docs/guides/deployment/branching#troubleshooting) [Rolling back migrations](https://supabase.com/docs/guides/deployment/branching#rolling-back-migrations) [Deployment failures](https://supabase.com/docs/guides/deployment/branching#deployment-failures) [Schema drift between preview branches](https://supabase.com/docs/guides/deployment/branching#schema-drift-between-preview-branches) [Changing production branch](https://supabase.com/docs/guides/deployment/branching#changing-production-branch) [Feedback](https://supabase.com/docs/guides/deployment/branching#feedback)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings


![Each branch has a separate Supabase instance.](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fbranching%2Fgithub-workflow-without-branching--light.jpg%3Fv%3D1&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![Each GitHub branch can have its own Supabase preview branch.](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fbranching%2Fgithub-workflow--light.jpg%3Fv%3D1&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![Check the "Require status checks to pass before merging" option.](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fbranching%2Fgithub-required-check.jpg%3Fv%3D1&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![GitHub view of the deployment status of your preview branch](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fbranching%2Fdevelop-your-app-open-pull-request-github.jpg%3Fv%3D1&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)
</file>

<file path="supabase_com_docs_guides_deployment_database_migrations.md">
Home

# Database Migrations

## How to manage schema migrations for your Supabase project.

* * *

Database migrations are SQL statements that create, update, or delete your existing database schemas. They are a common way of tracking changes to your database over time.

## Schema migrations [\#](https://supabase.com/docs/guides/deployment/database-migrations\#schema-migrations)

For this guide, we'll create a table called `employees` and see how we can make changes to it.

You will need to [install](https://supabase.com/docs/guides/local-development#quickstart) the Supabase CLI and start the local development stack.

1

### Create your first migration file

To get started, generate a [new migration](https://supabase.com/docs/reference/cli/supabase-migration-new) to store the SQL needed to create our `employees` table.

Terminal

`
supabase migration new create_employees_table
`

2

### Add the SQL to your migration file

This creates a new migration file in supabase/migrations directory.

To that file, add the SQL to create this `employees` table.

supabase/migrations/<timestamp>\_create\_employees\_table.sql

`
create table if not exists employees (
id bigint primary key generated always as identity,
name text not null,
email text,
created_at timestamptz default now()
);
`

3

### Apply your first migration

Run this migration to create the `employees` table.

Now you can visit your new `employees` table in the local Dashboard.

Terminal

`
supabase migration up
`

4

### Modify your employees table

Next, modify your `employees` table by adding a column for `department`.

Terminal

`
supabase migration new add_department_column
`

5

### Add a new column to your table

To that new migration file, add the SQL to create a new `department` column.

supabase/migrations/<timestamp>\_add\_department\_column.sql

`
alter table if exists public.employees
add department text default 'Hooli';
`

6

### Apply your second migration

Run this migration to update your existing `employees` table.

Terminal

`
supabase migration up
`

Finally, you should see the `department` column added to your `employees` table in the local Dashboard.

View the [complete code](https://github.com/supabase/supabase/tree/master/examples/database/employees) for this example on GitHub.

### Seeding data [\#](https://supabase.com/docs/guides/deployment/database-migrations\#seeding-data)

Now that you are managing your database with migrations scripts, it would be great have some seed data to use every time you reset the database.

1

### Populate your table

Create a seed script in supabase/seed.sql.

To that file, add the SQL to insert data into your `employees` table.

supabase/seed.sql

`
insert into public.employees
(name)
values
('Erlich Bachman'),
('Richard Hendricks'),
('Monica Hall');
`

2

### Reset your database

Reset your database to reapply migrations and populate with seed data.

Terminal

`
supabase db reset
`

You should now see the `employees` table, along with your seed data in the Dashboard! All of your database changes are captured in code, and you can reset to a known state at any time, complete with seed data.

### Diffing changes [\#](https://supabase.com/docs/guides/deployment/database-migrations\#diffing-changes)

This workflow is great if you know SQL and are comfortable creating tables and columns. If not, you can still use the Dashboard to create tables and columns, and then use the CLI to diff your changes and create migrations.

1

### Create your table from the Dashboard

Create a new table called `cities`, with columns `id`, `name` and `population`.

Then generate a [schema diff](https://supabase.com/docs/reference/cli/supabase-db-diff).

Terminal

`
supabase db diff -f create_cities_table
`

2

### Add schema diff as a migration

A new migration file is created for you.

Alternately, you can copy the table definitions directly from the Table Editor.

supabase/migrations/<timestamp>\_create\_cities\_table.sql

`
create table "public"."cities" (
"id" bigint primary key generated always as identity,
"name" text,
"population" bigint
);
`

3

### Test your migration

Test your new migration file by resetting your local database.

Terminal

`
supabase db reset
`

The last step is deploying these changes to a live Supabase project.

## Deploy your project [\#](https://supabase.com/docs/guides/deployment/database-migrations\#deploy-your-project)

You've been developing your project locally, making changes to your tables via migrations. It's time to deploy your project to the Supabase Platform and start scaling up to millions of users!

Head over to [Supabase](https://supabase.com/dashboard) and create a new project to deploy to.

1

### Log in to the Supabase CLI

[Login](https://supabase.com/docs/reference/cli/supabase-login) to the Supabase CLI using an auto-generated Personal Access Token.

Terminal

`
supabase login
`

2

### Link your project

[Link](https://supabase.com/docs/reference/cli/supabase-link) to your remote project by selecting from the on-screen prompt.

Terminal

`
supabase link
`

3

### Deploy database changes

[Push](https://supabase.com/docs/reference/cli/supabase-db-push) your migrations to the remote database.

Terminal

`
supabase db push
`

Visiting your live project on [Supabase](https://supabase.com/dashboard/project/_), you'll see a new `employees` table, complete with the `department` column you added in the second migration above.

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2FKx5nHBmIxyQ%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Schema migrations](https://supabase.com/docs/guides/deployment/database-migrations#schema-migrations) [Seeding data](https://supabase.com/docs/guides/deployment/database-migrations#seeding-data) [Diffing changes](https://supabase.com/docs/guides/deployment/database-migrations#diffing-changes) [Deploy your project](https://supabase.com/docs/guides/deployment/database-migrations#deploy-your-project)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_deployment_going_into_prod.md">
Home

# Production Checklist

* * *

After developing your project and deciding it's Production Ready, you should run through this checklist to ensure that your project:

- is secure
- won't falter under the expected load
- remains available whilst in production

## Security [\#](https://supabase.com/docs/guides/deployment/going-into-prod\#security)

- Ensure RLS is enabled
  - Tables that do not have RLS enabled with reasonable policies allow any client to access and modify their data. This is unlikely to be what you want in the majority of cases.
  - [Learn more about RLS](https://supabase.com/docs/guides/database/postgres/row-level-security).
- Enable replication on tables containing sensitive data by enabling Row Level Security (RLS) and setting row security policies:
  - Go to the Authentication > Policies page in the Supabase Dashboard to enable RLS and create security policies.
  - Go to the Database > Publications page in the Supabase Dashboard to manage replication tables.
- Turn on [SSL Enforcement](https://supabase.com/docs/guides/platform/ssl-enforcement)
- Enable [Network Restrictions](https://supabase.com/docs/guides/platform/network-restrictions) for your database.
- Ensure that your Supabase Account is protected with multi-factor authentication (MFA).
  - If using a GitHub signin, [enable 2FA on GitHub](https://docs.github.com/en/authentication/securing-your-account-with-two-factor-authentication-2fa/configuring-two-factor-authentication). Since your GitHub account gives you administrative rights to your Supabase org, you should protect it with a strong password and 2FA using a U2F key or a TOTP app.
  - If using email+password signin, set up [MFA for your Supabase account](https://supabase.com/docs/guides/platform/multi-factor-authentication#enable-mfa).
- Consider [adding multiple owners on your Supabase org](https://supabase.com/dashboard/org/_/team). This ensures that if one of the owners is unreachable or loses access to their account, you still have Owner access to your org.
- Ensure email confirmations are [enabled](https://supabase.com/dashboard/project/_/auth/providers) in the `Settings > Auth` page.
- Ensure that you've [set the expiry](https://supabase.com/dashboard/project/_/auth/providers) for one-time passwords (OTPs) to a reasonable value that you are comfortable with. We recommend setting this to 3600 seconds (1 hour) or lower.
- Increase the length of the OTP if you need a higher level of entropy.
- If your application requires a higher level of security, consider setting up [multi-factor authentication](https://supabase.com/docs/guides/auth/auth-mfa) (MFA) for your users.
- Use a custom SMTP server for auth emails so that your users can see that the mails are coming from a trusted domain (preferably the same domain that your app is hosted on). Grab SMTP credentials from any major email provider such as SendGrid, AWS SES, etc.
- Think hard about how _you_ would abuse your service as an attacker, and mitigate.
- Review these [common cybersecurity threats](https://auth0.com/docs/security/prevent-threats).
- Check and review issues in your database using [Security Advisor](https://supabase.com/dashboard/project/_/database/security-advisor).

## Performance [\#](https://supabase.com/docs/guides/deployment/going-into-prod\#performance)

- Ensure that you have suitable indices to cater to your common query patterns
  - [Learn more about indexes in Postgres](https://www.enterprisedb.com/postgres-tutorials/overview-postgresql-indexes).
  - `pg_stat_statements` can help you [identify hot or slow queries](https://www.virtual-dba.com/blog/postgresql-performance-identifying-hot-and-slow-queries/).
- Perform load testing (preferably on a staging env)
  - Tools like [k6](https://k6.io/) can simulate traffic from many different users.
- Upgrade your database if you require more resources. If you need anything beyond what is listed, contact [enterprise@supabase.io](mailto:enterprise@supabase.io).
- If you are expecting a surge in traffic (for a big launch) and are on a Team or Enterprise Plan, [contact support](https://supabase.com/dashboard/support/new) with more details about your launch and we'll help keep an eye on your project.
- If you expect your database size to be > 4 GB, [enable](https://supabase.com/dashboard/project/_/settings/addons?panel=pitr) the Point in Time Recovery (PITR) add-on. Daily backups can take up resources from your database when the backup is in progress. PITR is more resource efficient, since only the changes to the database are backed up.
- Check and review issues in your database using [Performance Advisor](https://supabase.com/dashboard/project/_/database/performance-advisor).

## Availability [\#](https://supabase.com/docs/guides/deployment/going-into-prod\#availability)

- Use your own SMTP credentials so that you have full control over the deliverability of your transactional auth emails (see Settings > Auth)
  - you can grab SMTP credentials from any major email provider such as SendGrid, AWS SES, etc. You can refer to our [SMTP guide](https://supabase.com/docs/guides/auth/auth-smtp) for more details.
  - The default rate limit for auth emails when using a custom SMTP provider is 30 new users per hour, if doing a major public announcement you will likely require more than this.
- If your application is on the Free Plan and is **not** expected to be queried at least once every 7 days, then it may be paused by Supabase to save on server resources.
  - You can restore paused projects from the Supabase dashboard.
  - Upgrade to Pro to guarantee that your project will not be paused for inactivity.
- Database backups are not available for download on the Free Plan.
  - You can set up your own backup systems using tools like [pg\_dump](https://www.postgresqltutorial.com/postgresql-backup-database/) or [wal-g](https://github.com/wal-g/wal-g).
  - Nightly backups for Pro Plan projects are available on the Supabase dashboard for up to 7 days.
  - Point in Time Recovery (PITR) allows a project to be backed up at much shorter intervals. This provides users an option to restore to any chosen point of up to seconds in granularity. In terms of Recovery Point Objective (RPO), Daily Backups would be suitable for projects willing to lose up to 24 hours worth of data. If a lower RPO is required, enable PITR.
- Supabase Projects use disks that offer 99.8-99.9% durability by default.
  - Use Read Replicas if you require availability resilience to a disk failure event
  - Use PITR if you require durability resilience to a disk failure event
- Upgrading to the Supabase Pro Plan will give you [access to our support team](https://supabase.com/dashboard/support/new).

## Rate limiting, resource allocation, & abuse prevention [\#](https://supabase.com/docs/guides/deployment/going-into-prod\#rate-limiting-resource-allocation--abuse-prevention)

- Supabase employs a number of safeguards against bursts of incoming traffic to prevent abuse and help maximize stability across the platform
  - If you're on a Team or Enterprise Plan and expect high load events, such as production launches, heavy load testing, or prolonged high resource usage, open a ticket via the [support form](https://supabase.help/) for help. Provide at least 2 weeks notice.

### Auth rate limits [\#](https://supabase.com/docs/guides/deployment/going-into-prod\#auth-rate-limits)

- The table below shows the rate limit quotas on the following authentication endpoints. You can configure the auth rate limits for your project [here](https://supabase.com/dashboard/project/_/auth/rate-limits).

| Endpoint | Path | Limited By | Rate Limit |
| --- | --- | --- | --- |
| All endpoints that send emails | `/auth/v1/signup` `/auth/v1/recover` `/auth/v1/user`\[^1\] | Sum of combined requests | As of 3 Sep 2024, this has been updated to 2 emails per hour. You can only change this with your own [custom SMTP setup](https://supabase.com/docs/guides/auth/auth-smtp). |
| All endpoints that send One-Time-Passwords (OTP) | `/auth/v1/otp` | Sum of combined requests | Defaults to 360 OTPs per hour. Is customizable. |
| Send OTPs or magic links | `/auth/v1/otp` | Last request | Defaults to 60 seconds window before a new request is allowed. Is customizable. |
| Signup confirmation request | `/auth/v1/signup` | Last request | Defaults to 60 seconds window before a new request is allowed. Is customizable. |
| Password Reset Request | `/auth/v1/recover` | Last request | Defaults to 60 seconds window before a new request is allowed. Is customizable. |
| Verification requests | `/auth/v1/verify` | IP Address | 360 requests per hour (with bursts up to 30 requests) |
| Token refresh requests | `/auth/v1/token` | IP Address | 1800 requests per hour (with bursts up to 30 requests) |
| Create or Verify an MFA challenge | `/auth/v1/factors/:id/challenge` `/auth/v1/factors/:id/verify` | IP Address | 15 requests per minute (with bursts up to 30 requests) |
| Anonymous sign-ins | `/auth/v1/signup`\[^2\] | IP Address | 30 requests per hour (with bursts up to 30 requests) |

### Realtime quotas [\#](https://supabase.com/docs/guides/deployment/going-into-prod\#realtime-quotas)

- Review the [Realtime quotas](https://supabase.com/docs/guides/realtime/quotas).
- If you need quotas increased you can always [contact support](https://supabase.com/dashboard/support/new).

### Abuse prevention [\#](https://supabase.com/docs/guides/deployment/going-into-prod\#abuse-prevention)

- Supabase provides CAPTCHA protection on the signup, sign-in and password reset endpoints. Refer to [our guide](https://supabase.com/docs/guides/auth/auth-captcha) on how to protect against abuse using this method.

### Email link validity [\#](https://supabase.com/docs/guides/deployment/going-into-prod\#email-link-validity)

- When working with enterprise systems, email scanners may scan and make a `GET` request to the reset password link or sign up link in your email. Since links in Supabase Auth are single use, a user who opens an email post-scan to click on a link will receive an error. To get around this problem,
consider altering the email template to replace the original magic link with a link to a domain you control. The domain can present the user with a "Sign-in" button which redirect the user to the original magic link URL when clicked.

- When using a custom SMTP service, some services might have link tracking enabled which may overwrite or disform the email confirmation links sent by Supabase Auth. To prevent this from happening, we recommend that you disable link tracking when using a custom SMTP service.


## Subscribe to Supabase status page [\#](https://supabase.com/docs/guides/deployment/going-into-prod\#subscribe-to-supabase-status-page)

Stay informed about Supabase service status by subscribing to the [Status Page](https://status.supabase.com/). We recommend setting up Slack notifications through an RSS feed to ensure your team receives timely updates about service status changes.

### Setting up Slack notifications [\#](https://supabase.com/docs/guides/deployment/going-into-prod\#setting-up-slack-notifications)

1. Install the RSS app in Slack:
   - Visit the [RSS app page](https://slack.com/marketplace/A0F81R7U7-rss) in the Slack marketplace
   - Click `Add to Slack` if not already installed
   - Otherwise you will get straight to next step, no need to reinstall the app
2. Configure the Supabase status feed:
   - Create a channel (e.g., `#supabase-status-alerts`) for status updates
   - On the [RSS app page](https://slack.com/marketplace/A0F81R7U7-rss) go to _Add a Feed_ section and set Feed URL to `https://status.supabase.com/history.rss`
   - Select your designated channel and click "Subscribe to this feed"

Once configured, your team will receive automatic notifications in Slack whenever the Supabase Status Page is updated.

For detailed setup instructions, see the [Add RSS feeds to Slack](https://slack.com/intl/en-nz/help/articles/218688467-Add-RSS-feeds-to-Slack).

## Next steps [\#](https://supabase.com/docs/guides/deployment/going-into-prod\#next-steps)

This checklist is always growing so be sure to check back frequently, and also feel free to suggest additions and amendments by making a PR on [GitHub](https://github.com/supabase/supabase).

### Is this helpful?

NoYes

### On this page

[Security](https://supabase.com/docs/guides/deployment/going-into-prod#security) [Performance](https://supabase.com/docs/guides/deployment/going-into-prod#performance) [Availability](https://supabase.com/docs/guides/deployment/going-into-prod#availability) [Rate limiting, resource allocation, & abuse prevention](https://supabase.com/docs/guides/deployment/going-into-prod#rate-limiting-resource-allocation--abuse-prevention) [Auth rate limits](https://supabase.com/docs/guides/deployment/going-into-prod#auth-rate-limits) [Realtime quotas](https://supabase.com/docs/guides/deployment/going-into-prod#realtime-quotas) [Abuse prevention](https://supabase.com/docs/guides/deployment/going-into-prod#abuse-prevention) [Email link validity](https://supabase.com/docs/guides/deployment/going-into-prod#email-link-validity) [Subscribe to Supabase status page](https://supabase.com/docs/guides/deployment/going-into-prod#subscribe-to-supabase-status-page) [Setting up Slack notifications](https://supabase.com/docs/guides/deployment/going-into-prod#setting-up-slack-notifications) [Next steps](https://supabase.com/docs/guides/deployment/going-into-prod#next-steps)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_deployment_managing_environments.md">
Home

# Managing Environments

## Manage multiple environments using Database Migrations and GitHub Actions.

* * *

This guide shows you how to set up your local Supabase development environment that integrates with GitHub Actions to automatically test and release schema changes to staging and production Supabase projects.

![Diagram showing a possible environment setup for Supabase development. There are 3 branches and 3 corresponding databases: feature branch and local database, develop branch and staging database, and main branch and production database.](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Flocal-dev-environment--light.svg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

## Set up a local environment [\#](https://supabase.com/docs/guides/deployment/managing-environments\#set-up-a-local-environment)

The first step is to set up your local repository with the Supabase CLI:

`
supabase init
`

You should see a new `supabase` directory. Then you need to link your local repository with your Supabase project:

`
supabase login
supabase link --project-ref $PROJECT_ID
`

You can get your `$PROJECT_ID` from your project's dashboard URL:

`
https://supabase.com/dashboard/project/<project-id>
`

If you're using an existing Supabase project, you might have made schema changes through the Dashboard.
Run the following command to pull these changes before making local schema changes from the CLI:

`
supabase db pull
`

This command creates a new migration in `supabase/migrations/<timestamp>_remote_schema.sql` which reflects the schema changes you have made previously.

Now commit your local changes to Git and run the local development setup:

`
git add .
git commit -m "init supabase"
supabase start
`

You are now ready to develop schema changes locally and create your first migration.

## Create a new migration [\#](https://supabase.com/docs/guides/deployment/managing-environments\#create-a-new-migration)

There are two ways to make schema changes:

1. Manual migration: Write DDL statements manually into a migration file
2. Auto schema diff: Make changes through Studio UI and auto generate a schema diff

### Manual migration [\#](https://supabase.com/docs/guides/deployment/managing-environments\#manual-migration)

Create a new migration script by running:

`
supabase migration new new_employee
`

You should see a new file created: `supabase/migrations/<timestamp>_new_employee.sql`. You can then write SQL statements in this script using a text editor:

`
create table public.employees (
id integer primary key generated always as identity,
name text
);
`

Apply the new migration to your local database:

`
supabase db reset
`

This command recreates your local database from scratch and applies all migration scripts under `supabase/migrations` directory. Now your local database is up to date.

The new migration command also supports stdin as input. This allows you to pipe in an existing script from another file or stdout:

`supabase migration new new_employee < create_employees_table.sql`

### Auto schema diff [\#](https://supabase.com/docs/guides/deployment/managing-environments\#auto-schema-diff)

Unlike manual migrations, auto schema diff creates a new migration script from changes **already** applied to your local database.

Create an `employees` table under the `public` schema using Studio UI, accessible at [localhost:54323](http://localhost:54323/) by default.

Next, generate a schema diff by running the following command:

`
supabase db diff -f new_employee
`

You should see that a new file `supabase/migrations/<timestamp>_new_employee.sql` is created. Open the file and verify that the generated DDL statements are the same as below.

`
-- This script was generated by the Schema Diff utility in pgAdmin 4
-- For the circular dependencies, the order in which Schema Diff writes the objects is not very sophisticated
-- and may require manual changes to the script to ensure changes are applied in the correct order.
-- Please report an issue for any failure with the reproduction steps.
CREATE TABLE IF NOT EXISTS public.employees
(
    id integer NOT NULL GENERATED ALWAYS AS IDENTITY ( INCREMENT 1 START 1 MINVALUE 1 MAXVALUE 2147483647 CACHE 1 ),
    name text COLLATE pg_catalog."default",
    CONSTRAINT employees_pkey PRIMARY KEY (id)
)
TABLESPACE pg_default;
ALTER TABLE IF EXISTS public.employees
    OWNER to postgres;
GRANT ALL ON TABLE public.employees TO anon;
GRANT ALL ON TABLE public.employees TO authenticated;
GRANT ALL ON TABLE public.employees TO postgres;
GRANT ALL ON TABLE public.employees TO service_role;
`

You may notice that the auto-generated migration script is more verbose than the manually written one.
This is because the default schema diff tool does not account for default privileges added by the initial schema.

Commit the new migration script to git and you are ready to deploy.

Alternatively, you may pass in the `--use-migra` experimental flag to generate a more concise migration using [`migra`](https://github.com/djrobstep/migra).

Without the `-f` file flag, the output is written to stdout by default.

`supabase db diff --use-migra`

## Deploy a migration [\#](https://supabase.com/docs/guides/deployment/managing-environments\#deploy-a-migration)

In a production environment, we recommend using a CI/CD pipeline to deploy new migrations with GitHub Actions rather than deploying from your local machine.

![Diagram showing a possible environment setup for Supabase development. There are 3 branches and 3 corresponding databases: feature branch and local database, develop branch and staging database, and main branch and production database.](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Flocal-dev-environment--light.svg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

This example uses two Supabase projects, one for production and one for staging.

Prepare your environments by:

- Creating separate Supabase projects for staging and production
- Pushing your git repository to GitHub and enabling GitHub Actions

You need a _new_ project for staging. A project which has already been modified to reflect the production project's schema can't be used because the CLI would reapply these changes.

### Configure GitHub Actions [\#](https://supabase.com/docs/guides/deployment/managing-environments\#configure-github-actions)

The Supabase CLI requires a few environment variables to run in non-interactive mode.

- `SUPABASE_ACCESS_TOKEN` is your personal access token
- `SUPABASE_DB_PASSWORD` is your project specific database password
- `SUPABASE_PROJECT_ID` is your project specific reference string

We recommend adding these as [encrypted secrets](https://docs.github.com/en/actions/security-guides/encrypted-secrets) to your GitHub Actions runners.

Create the following files inside the `.github/workflows` directory:

ci.yamlstaging.yamlproduction.yaml

.github/workflows/ci.yml

`
name: CI
on:
pull_request:
workflow_dispatch:
jobs:
test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: supabase/setup-cli@v1
        with:
          version: latest
      - name: Start Supabase local development setup
        run: supabase db start
      - name: Verify generated types are checked in
        run: |
          supabase gen types typescript --local > types.gen.ts
          if ! git diff --ignore-space-at-eol --exit-code --quiet types.gen.ts; then
            echo "Detected uncommitted changes after build. See status below:"
            git diff
            exit 1
          fi
`

The full example code is available in the [demo repository](https://github.com/supabase/supabase-action-example).

Commit these files to git and push to your `main` branch on GitHub. Update these environment variables to match your Supabase projects:

- `SUPABASE_ACCESS_TOKEN`
- `PRODUCTION_PROJECT_ID`
- `PRODUCTION_DB_PASSWORD`
- `STAGING_PROJECT_ID`
- `STAGING_DB_PASSWORD`

When configured correctly, your repository will have CI and Release workflows that trigger on new commits pushed to `main` and `develop` branches.

![Correctly configured repo](https://supabase.com/docs/img/guides/cli/ci-main.png)

### Open a PR with new migration [\#](https://supabase.com/docs/guides/deployment/managing-environments\#open-a-pr-with-new-migration)

Follow the [migration steps](https://supabase.com/docs/guides/deployment/managing-environments#create-a-new-migration) to create a `supabase/migrations/<timestamp>_new_employee.sql` file.

Checkout a new branch `feat/employee` from `develop` , commit the migration file, and push to GitHub.

`
git checkout -b feat/employee
git add supabase/migrations/<timestamp>_new_employee.sql
git commit -m "Add employee table"
git push --set-upstream origin feat/employee
`

Open a PR from `feat/employee` to the `develop` branch to see that the CI workflow has been triggered.

Once the test error is resolved, merge this PR and watch the deployment in action.

### Release to production [\#](https://supabase.com/docs/guides/deployment/managing-environments\#release-to-production)

After verifying your staging project has successfully migrated, create another PR from `develop` to `main` and merge it to deploy the migration to the production project.

The `release` job applies all new migration scripts merged in `supabase/migrations` directory to a linked Supabase project. You can control which project the job links to via `PROJECT_ID` environment variable.

## Troubleshooting [\#](https://supabase.com/docs/guides/deployment/managing-environments\#troubleshooting)

### Sync production project to staging [\#](https://supabase.com/docs/guides/deployment/managing-environments\#sync-production-project-to-staging)

When setting up a new staging project, you might need to sync the initial schema with migrations previously applied to the production project.

One way is to leverage the Release workflow:

- Create a new branch `develop` and choose `main` as the branch source
- Push the `develop` branch to GitHub

The GitHub Actions runner will deploy your existing migrations to the staging project.

Alternatively, you can also apply migrations through your local CLI to a linked remote database.

`
supabase db push
`

Once pushed, check that the migration version is up to date for both local and remote databases.

`
supabase migration list
`

### Permission denied on `db pull` [\#](https://supabase.com/docs/guides/deployment/managing-environments\#permission-denied-on-db-pull)

If you have been using Supabase hosted projects for a long time, you might encounter the following permission error when executing `db pull`.

`
Error: Error running pg_dump on remote database: pg_dump: error: query failed: ERROR:  permission denied for table _type
pg_dump: error: query was: LOCK TABLE "graphql"."_type" IN ACCESS SHARE MODE
`

To resolve this error, you need to grant `postgres` role permissions to `graphql` schema. You can do that by running the following query from Supabase dashboard's SQL Editor.

`
grant all on all tables in schema graphql to postgres, anon, authenticated, service_role;
grant all on all functions in schema graphql to postgres, anon, authenticated, service_role;
grant all on all sequences in schema graphql to postgres, anon, authenticated, service_role;
`

### Permission denied on `db push` [\#](https://supabase.com/docs/guides/deployment/managing-environments\#permission-denied-on-db-push)

If you created a table through Supabase dashboard, and your new migration script contains `ALTER TABLE` statements, you might run into permission error when applying them on staging or production databases.

`
ERROR: must be owner of table employees (SQLSTATE 42501); while executing migration <timestamp>
`

This is because tables created through Supabase dashboard are owned by `supabase_admin` role while the migration scripts executed through CLI are under `postgres` role.

One way to solve this is to reassign the owner of those tables to `postgres` role. For example, if your table is named `users` in the public schema, you can run the following command to reassign owner.

`
ALTER TABLE users OWNER TO postgres;
`

Apart from tables, you also need to reassign owner of other entities using their respective commands, including [types](https://www.postgresql.org/docs/current/sql-altertype.html), [functions](https://www.postgresql.org/docs/current/sql-alterroutine.html), and [schemas](https://www.postgresql.org/docs/current/sql-alterschema.html).

### Rebasing new migrations [\#](https://supabase.com/docs/guides/deployment/managing-environments\#rebasing-new-migrations)

Sometimes your teammate may merge a new migration file to git main branch, and now you need to rebase your local schema changes on top.

We can handle this scenario gracefully by renaming your old migration file with a new timestamp.

`
git pull
supabase migration new dev_A
# Assume the new file is: supabase/migrations/<t+2>_dev_A.sql
mv <time>_dev_A.sql <t+2>_dev_A.sql
supabase db reset
`

In case [`reset`](https://supabase.com/docs/reference/cli/usage#supabase-db-reset) fails, you can manually resolve conflicts by editing `<t+2>_dev_A.sql` file.

Once validated locally, commit your changes to Git and push to GitHub.

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2FrOLyOsBR1Uc%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Set up a local environment](https://supabase.com/docs/guides/deployment/managing-environments#set-up-a-local-environment) [Create a new migration](https://supabase.com/docs/guides/deployment/managing-environments#create-a-new-migration) [Manual migration](https://supabase.com/docs/guides/deployment/managing-environments#manual-migration) [Auto schema diff](https://supabase.com/docs/guides/deployment/managing-environments#auto-schema-diff) [Deploy a migration](https://supabase.com/docs/guides/deployment/managing-environments#deploy-a-migration) [Configure GitHub Actions](https://supabase.com/docs/guides/deployment/managing-environments#configure-github-actions) [Open a PR with new migration](https://supabase.com/docs/guides/deployment/managing-environments#open-a-pr-with-new-migration) [Release to production](https://supabase.com/docs/guides/deployment/managing-environments#release-to-production) [Troubleshooting](https://supabase.com/docs/guides/deployment/managing-environments#troubleshooting) [Sync production project to staging](https://supabase.com/docs/guides/deployment/managing-environments#sync-production-project-to-staging) [Permission denied on db pull](https://supabase.com/docs/guides/deployment/managing-environments#permission-denied-on-db-pull) [Permission denied on db push](https://supabase.com/docs/guides/deployment/managing-environments#permission-denied-on-db-push) [Rebasing new migrations](https://supabase.com/docs/guides/deployment/managing-environments#rebasing-new-migrations)

![Diagram showing a possible environment setup for Supabase development. There are 3 branches and 3 corresponding databases: feature branch and local database, develop branch and staging database, and main branch and production database.](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Flocal-dev-environment--light.svg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_deployment_maturity_model.md">
Home

# Maturity Model

* * *

Supabase is great for building something very fast _and_ for scaling up. However, it's important to note that as your application matures and your team expands, the practices you use for managing an application in production should not be the same as the practices you used for prototyping.

## Prototyping [\#](https://supabase.com/docs/guides/deployment/maturity-model\#prototyping)

The Dashboard is a quick and easy tool for building applications while you are prototyping. That said, we strongly recommend using [Migrations](https://supabase.com/docs/guides/deployment/database-migrations) to manage your database changes. You can use our CLI to [capture any changes](https://supabase.com/docs/reference/cli/supabase-db-diff) you have made on the Dashboard so that you can commit them a version control system, like git.

## Collaborating [\#](https://supabase.com/docs/guides/deployment/maturity-model\#collaborating)

As soon as you start collaborating with team members, all project changes should be in version control. At this point we strongly recommend moving away from using the Dashboard for schema changes. Use migrations to manage your database, and check them into your version control system to track every change.

Resources:

- [Database migrations](https://supabase.com/docs/guides/deployment/database-migrations)
- [Managing access on the Dashboard](https://supabase.com/docs/guides/platform/access-control)
- [PGAudit for Postgres](https://supabase.com/docs/guides/database/extensions/pgaudit)

## In production [\#](https://supabase.com/docs/guides/deployment/maturity-model\#in-production)

Once your application is live, you should never change your database using the Dashboard - everything should be done with [Migrations](https://supabase.com/docs/guides/cli/managing-environments#create-a-new-migration). Some other important things to consider at this point include:

- The Dashboard has various [access levels](https://supabase.com/docs/guides/platform/access-control) that can prevent changes being made via the UI.
- Design a [safe workflow](https://supabase.com/docs/guides/platform/shared-responsibility-model#you-decide-your-own-workflow) for managing your database. We strongly recommend running [multiple environments](https://supabase.com/docs/guides/cli/managing-environments) as part of your development workflow ( `local` -\> `staging` -\> `prod`).
- Do not share any production passwords with your team, _especially_ your `postgres` password. All changes should be made via version-controlled migrations which run via a bastion host or a CI platform (like [GitHub Actions](https://supabase.com/docs/guides/cli/managing-environments#configure-github-actions). If you use GitHub Actions, use [approval workflows](https://docs.github.com/en/actions/managing-workflow-runs/reviewing-deployments) to prevent any migrations being run accidentally.
- Restrict production access to your database using [Network Restrictions](https://supabase.com/docs/guides/platform/network-restrictions).
- As your database to grows, we strongly recommend moving to [Point-in-Time Recovery](https://supabase.com/docs/guides/platform/backups#point-in-time-recovery). This is safer and has less impact on your database performance during maintenance windows.
- Read the [Production Checklist](https://supabase.com/docs/guides/platform/going-into-prod) and familiarize your team with the [Shared Responsibilities](https://supabase.com/docs/guides/platform/shared-responsibility-model) between your organization and Supabase.

Resources:

- [Database migrations](https://supabase.com/docs/guides/deployment/database-migrations)
- [Managing access on the Dashboard](https://supabase.com/docs/guides/platform/access-control)
- [PGAudit for Postgres](https://supabase.com/docs/guides/database/extensions/pgaudit)
- [Managing environments](https://supabase.com/docs/guides/cli/managing-environments)

## Enterprise [\#](https://supabase.com/docs/guides/deployment/maturity-model\#enterprise)

For a more secure setup, consider running your workload across several organizations. It's a common pattern to have a Production organization which is restricted to only those team members who are qualified to have direct access to production databases.

Reach out to [growth](https://forms.supabase.com/enterprise) if you need help designing a secure development workflow for your organization.

### Is this helpful?

NoYes

### On this page

[Prototyping](https://supabase.com/docs/guides/deployment/maturity-model#prototyping) [Collaborating](https://supabase.com/docs/guides/deployment/maturity-model#collaborating) [In production](https://supabase.com/docs/guides/deployment/maturity-model#in-production) [Enterprise](https://supabase.com/docs/guides/deployment/maturity-model#enterprise)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_deployment_shared_responsibility_model.md">
Home

# Shared Responsibility Model

* * *

Running databases is a shared responsibility between you and Supabase. There are some things that we can take care of for you, and some things that you are responsible for. This is by design: we want to give you the freedom to use your database however you want. While we _could_ put many more restrictions in place to ensure that you cant do anything wrong, you will eventually find those restrictions prohibitive.

![Diagram showing the shared responsibility model between Supabase and the customer. The customer is responsible for Application architecture and implementation, information and data, the database schema and user management. The responsibility for API rate-limiting, Postgres security controls, upgrades, performance tuning and resource allocation is shared. Supabase is responsible for Postgres backups and observability, operating system maintenance, infrastructure and the monitoring and security thereof.](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fplatform%2Fshared-responsibility-model--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

To summarize, you are always responsible for:

- Your Supabase account
- Access management (Supabase account, database, tables, etc)
- Data
- Applying security controls

Generally, we aim to reduce your burden of managing infrastructure and knowing about Postgres internals, minimizing configuration as much as we can. Here are a few things that you should know:

## You share the security responsibility [\#](https://supabase.com/docs/guides/deployment/shared-responsibility-model\#you-share-the-security-responsibility)

We give you full access to the database. If you share that access with other people (either people on your team, or the public in general) then it is your responsibility to ensure that the access levels you provide are correctly managed.

If you have an inexperienced member on your team, then you probably shouldnt give them access to Production. You should set internal workflows around what they should and should not be able to do, with restricted access to avoid anything that might be deemed dangerous.

You are also responsible for ensuring that tables with sensitive data have the right level of access. You are also responsible for managing your database secrets and API keys, storing them safely in an encrypted store.

Supabase provides controls for [securing your data](https://supabase.com/docs/guides/database/secure-data), and it is recommended that you always apply [Row Level Security](https://supabase.com/docs/guides/database/postgres/row-level-security) (RLS).

We will also provide you with security alerts through [Security Advisor](https://supabase.com/dashboard/project/_/database/security-advisor) and applying the recommendations are your responsibility.

## You decide your own workflow [\#](https://supabase.com/docs/guides/deployment/shared-responsibility-model\#you-decide-your-own-workflow)

There are _many_ ways to work with Supabase.

You can use our Dashboard, our client libraries, external tools like Prisma and Drizzle, or migration tools like our CLI, Flyway, Sqitch, and anything else that is Postgres-compatible. You can develop directly on your database while you're getting started, run migrations from [local to production](https://supabase.com/docs/guides/getting-started/local-development), or you can use [multiple environments](https://supabase.com/docs/guides/cli/managing-environments).

None of these are right or wrong. It depends on the stage of your project. You _definitely_ shouldnt be developing on your database directly when youre in production - but thats absolutely fine when youre prototyping and dont have users.

## You are responsible for your application architecture [\#](https://supabase.com/docs/guides/deployment/shared-responsibility-model\#you-are-responsible-for-your-application-architecture)

Supabase isn't a silver-bullet for bad architectural decisions. A poorly designed database will run poorly, no matter where its hosted.

You can get away with a poorly-designed database for a while by adding compute. After a while, things will start to break. The database schema is the area you want to spend _the most_ time thinking about. Thats the benefit of Supabase - you can spend more time designing a scalable database system and less time thinking about the mundane tasks like implementing CRUD APIs.

If you dont want to implement logic inside your database, that is 100% fine. You can use _any_ tools which work with Postgres.

## You are responsible for third-party services [\#](https://supabase.com/docs/guides/deployment/shared-responsibility-model\#you-are-responsible-for-third-party-services)

Supabase offers a lot of opportunities for flexibly integrating with third-party services, such as:

- OAuth and SAML login providers
- SMTP and SMS sending APIs
- Calls to external APIs within Postgres functions or triggers
- Calls to external APIs within Edge Functions

You are free to use and integrate with any service, but you're also responsible for ensuring that the performance, availability, and security of the services you use match up with your application's requirements. We do not monitor for outages or performance issues within integrations with third-party services. Depending on the implementation, an issue with such an integration could also result in performance degradation or an outage for your Supabase project.

If your application architecture relies on such integrations, you should monitor the relevant logs and metrics to ensure optimal performance.

## You choose your level of comfort with Postgres [\#](https://supabase.com/docs/guides/deployment/shared-responsibility-model\#you-choose-your-level-of-comfort-with-postgres)

Our goal at Supabase is to make _all_ of Postgres easy to use. That doesnt mean you have to use all of it. If youre a Postgres veteran, youll probably love the tools that we offer. If youve never used Postgres before, then start smaller and grow into it. If you just want to treat Postgres like a simple table-store, thats perfectly fine.

## You are in control of your database [\#](https://supabase.com/docs/guides/deployment/shared-responsibility-model\#you-are-in-control-of-your-database)

Supabase places very few guard-rails around your database. That gives you a lot of control, but it also means you can break things. Break is used liberally here. It refers to any situation that affects your application because of the way you're using the database.

You are responsible for using best-practices to optimize and manage your database: adding indexes, adding filters on large queries, using caching strategies, optimizing your database queries, and managing connections to the database.

You are responsible of provisioning enough compute to run the workload that your application requires. The Supabase Dashboard provides [observability tooling](https://supabase.com/dashboard/project/_/reports/database) to help with this.

## Before going to production [\#](https://supabase.com/docs/guides/deployment/shared-responsibility-model\#before-going-to-production)

We recommend reviewing and applying the recommendations offered in our [Production Checklist](https://supabase.com/docs/guides/platform/going-into-prod). This checklist covers the responsibilities discussed here and a few additional general production readiness best practices.

## SOC 2 and compliance [\#](https://supabase.com/docs/guides/deployment/shared-responsibility-model\#soc-2-and-compliance)

Supabase provides a SOC 2 compliant environment for hosting and managing sensitive data. We recommend reviewing the [SOC 2 compliance responsibilities document](https://supabase.com/docs/guides/security/soc-2-compliance) alongside the aforementioned production checklist.

## Managing healthcare data [\#](https://supabase.com/docs/guides/deployment/shared-responsibility-model\#managing-healthcare-data)

You can use Supabase to store and process Protected Health Information (PHI). You are responsible for the following

- Signing a Business Associate Agreement (BAA) with Supabase. Submit a [HIPAA add-on request](https://forms.supabase.com/hipaa2) to get started. You will need to be at least on the [Team Plan](https://supabase.com/pricing) to sign a BAA with us.
- [Marking specific projects as HIPAA projects](https://supabase.com/docs/guides/platform/hipaa-projects) and addressing security issues raised by the advisor.
- Ensuring [MFA is enabled](https://supabase.com/docs/guides/platform/multi-factor-authentication) on all Supabase accounts.
- Enabling [Point in Time Recovery](https://supabase.com/docs/guides/platform/backups#point-in-time-recovery) which requires at least a [small compute add-on](https://supabase.com/docs/guides/platform/compute-add-ons).
- Turning on [SSL Enforcement](https://supabase.com/docs/guides/platform/ssl-enforcement).
- Enabling [Network Restrictions](https://supabase.com/docs/guides/platform/network-restrictions).
- Disabling data sharing for [Supabase AI editor](https://supabase.com/dashboard/org/_/general) in our dashboard.
  - Specifically, " _Opt-in to sending anonymous data to OpenAI_" should be disabled (Opt-out).
- Complying with encryption requirements in the HIPAA Security Rule. Data is encrypted at rest and in transit by Supabase. You can consider encrypting the data at your application layer.
- Not using [Edge functions](https://supabase.com/docs/guides/functions) to process PHI.
- Not storing PHI in [public Storage buckets](https://supabase.com/docs/guides/storage/buckets/fundamentals#public-buckets).
- Not [transferring projects](https://supabase.com/docs/guides/platform/project-transfer) to a non-HIPAA organization.

For more information on the shared responsibilities and rules under HIPAA, review the [HIPAA compliance responsibilities document](https://supabase.com/docs/guides/security/hipaa-compliance).

### Is this helpful?

NoYes

### On this page

[You share the security responsibility](https://supabase.com/docs/guides/deployment/shared-responsibility-model#you-share-the-security-responsibility) [You decide your own workflow](https://supabase.com/docs/guides/deployment/shared-responsibility-model#you-decide-your-own-workflow) [You are responsible for your application architecture](https://supabase.com/docs/guides/deployment/shared-responsibility-model#you-are-responsible-for-your-application-architecture) [You are responsible for third-party services](https://supabase.com/docs/guides/deployment/shared-responsibility-model#you-are-responsible-for-third-party-services) [You choose your level of comfort with Postgres](https://supabase.com/docs/guides/deployment/shared-responsibility-model#you-choose-your-level-of-comfort-with-postgres) [You are in control of your database](https://supabase.com/docs/guides/deployment/shared-responsibility-model#you-are-in-control-of-your-database) [Before going to production](https://supabase.com/docs/guides/deployment/shared-responsibility-model#before-going-to-production) [SOC 2 and compliance](https://supabase.com/docs/guides/deployment/shared-responsibility-model#soc-2-and-compliance) [Managing healthcare data](https://supabase.com/docs/guides/deployment/shared-responsibility-model#managing-healthcare-data)

![Diagram showing the shared responsibility model between Supabase and the customer. The customer is responsible for Application architecture and implementation, information and data, the database schema and user management. The responsibility for API rate-limiting, Postgres security controls, upgrades, performance tuning and resource allocation is shared. Supabase is responsible for Postgres backups and observability, operating system maintenance, infrastructure and the monitoring and security thereof.](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fplatform%2Fshared-responsibility-model--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_deployment.md">
Home

# Deployment

* * *

Deploying your app makes it live and accessible to users. Usually, you will deploy an app to at least two environments: a production environment for users and (one or multiple) staging or preview environments for developers.

Supabase provides several options for environment management and deployment.

## Environment management [\#](https://supabase.com/docs/guides/deployment\#environment-management)

You can maintain separate development, staging, and production environments for Supabase:

- **Development**: Develop with a local Supabase stack using the [Supabase CLI](https://supabase.com/docs/guides/local-development).
- **Staging**: Use [branching](https://supabase.com/docs/guides/deployment/branching) to create staging or preview environments. You can use persistent branches for a long-lived staging setup, or ephemeral branches for short-lived previews (which are often tied to a pull request).
- **Production**: If you have branching enabled, you can use the Supabase GitHub integration to automatically push your migration files when you merge a pull request. Alternatively, you can set up your own continuous deployment pipeline using the Supabase CLI.

##### Self-hosting

See the [self-hosting guides](https://supabase.com/docs/guides/self-hosting) for instructions on hosting your own Supabase stack.

## Deployment [\#](https://supabase.com/docs/guides/deployment\#deployment)

You can automate deployments using:

- The [Supabase GitHub integration](https://supabase.com/dashboard/project/_/settings/integrations) (with branching enabled)
- The [Supabase CLI](https://supabase.com/docs/guides/local-development) in your own continuous deployment pipeline
- The [Supabase Terraform provider](https://supabase.com/docs/guides/deployment/terraform)

### Is this helpful?

NoYes

### On this page

[Environment management](https://supabase.com/docs/guides/deployment#environment-management) [Deployment](https://supabase.com/docs/guides/deployment#deployment)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_ai_models.md">
Edge Functions

# Running AI Models

## How to run AI models in Edge Functions.

* * *

[Supabase Edge Runtime](https://github.com/supabase/edge-runtime) has a built-in API for running AI models. You can use this API to generate embeddings, build conversational workflows, and do other AI related tasks in your Edge Functions.

## Setup [\#](https://supabase.com/docs/guides/functions/ai-models\#setup)

There are no external dependencies or packages to install to enable the API.

You can create a new inference session by doing:

`
const model = new Supabase.ai.Session('model-name')
`

To get type hints and checks for the API you can import types from `functions-js` at the top of your file:

`
import 'jsr:@supabase/functions-js/edge-runtime.d.ts'
`

## Running a model inference [\#](https://supabase.com/docs/guides/functions/ai-models\#running-a-model-inference)

Once the session is instantiated, you can call it with inputs to perform inferences. Depending on the model you run, you may need to provide different options (discussed below).

`
const output = await model.run(input, options)
`

## How to generate text embeddings [\#](https://supabase.com/docs/guides/functions/ai-models\#how-to-generate-text-embeddings)

Now let's see how to write an Edge Function using the `Supabase.ai` API to generate text embeddings. Currently, `Supabase.ai` API only supports the [gte-small](https://huggingface.co/Supabase/gte-small) model.

`gte-small` model exclusively caters to English texts, and any lengthy texts will be truncated to a maximum of 512 tokens. While you can provide inputs longer than 512 tokens, truncation may affect the accuracy.

`
const model = new Supabase.ai.Session('gte-small')
Deno.serve(async (req: Request) => {
const params = new URL(req.url).searchParams
const input = params.get('input')
const output = await model.run(input, { mean_pool: true, normalize: true })
return new Response(JSON.stringify(output), {
    headers: {
      'Content-Type': 'application/json',
      Connection: 'keep-alive',
    },
})
})
`

## Using Large Language Models (LLM) [\#](https://supabase.com/docs/guides/functions/ai-models\#using-large-language-models-llm)

Inference via larger models is supported via [Ollama](https://ollama.com/) and [Mozilla Llamafile](https://github.com/Mozilla-Ocho/llamafile). In the first iteration, you can use it with a self-managed Ollama or [Llamafile server](https://www.docker.com/blog/a-quick-guide-to-containerizing-llamafile-with-docker-for-ai-applications/). We are progressively rolling out support for the hosted solution. To sign up for early access, fill up [this form](https://forms.supabase.com/supabase.ai-llm-early-access).

### Running locally [\#](https://supabase.com/docs/guides/functions/ai-models\#running-locally)

OllamaMozilla Llamafile

[Install Ollama](https://github.com/ollama/ollama?tab=readme-ov-file#ollama) and pull the Mistral model

`
ollama pull mistral
`

Run the Ollama server locally

`
ollama serve
`

Set a function secret called AI\_INFERENCE\_API\_HOST to point to the Ollama server

`
echo "AI_INFERENCE_API_HOST=http://host.docker.internal:11434" >> supabase/functions/.env
`

Create a new function with the following code

`
supabase functions new ollama-test
`

supabase/functions/ollama-test/index.ts

`
import 'jsr:@supabase/functions-js/edge-runtime.d.ts'
const session = new Supabase.ai.Session('mistral')
Deno.serve(async (req: Request) => {
const params = new URL(req.url).searchParams
const prompt = params.get('prompt') ?? ''
// Get the output as a stream
const output = await session.run(prompt, { stream: true })
const headers = new Headers({
    'Content-Type': 'text/event-stream',
    Connection: 'keep-alive',
})
// Create a stream
const stream = new ReadableStream({
    async start(controller) {
      const encoder = new TextEncoder()
      try {
        for await (const chunk of output) {
          controller.enqueue(encoder.encode(chunk.response ?? ''))
        }
      } catch (err) {
        console.error('Stream error:', err)
      } finally {
        controller.close()
      }
    },
})
// Return the stream to the user
return new Response(stream, {
    headers,
})
})
`

Serve the function

`
supabase functions serve --env-file supabase/functions/.env
`

Execute the function

`
curl --get "http://localhost:54321/functions/v1/ollama-test" \
--data-urlencode "prompt=write a short rap song about Supabase, the Postgres Developer platform, as sung by Nicki Minaj" \
-H "Authorization: $ANON_KEY"
`

### Deploying to production [\#](https://supabase.com/docs/guides/functions/ai-models\#deploying-to-production)

Once the function is working locally, it's time to deploy to production.

Deploy an Ollama or Llamafile server and set a function secret called `AI_INFERENCE_API_HOST` to point to the deployed server

`
supabase secrets set AI_INFERENCE_API_HOST=https://path-to-your-llm-server/
`

Deploy the Supabase function

`
supabase functions deploy
`

Execute the function

`
curl --get "https://project-ref.supabase.co/functions/v1/ollama-test" \
 --data-urlencode "prompt=write a short rap song about Supabase, the Postgres Developer platform, as sung by Nicki Minaj" \
 -H "Authorization: $ANON_KEY"
`

As demonstrated in the video above, running Ollama locally is typically slower than running it in on a server with dedicated GPUs. We are collaborating with the Ollama team to improve local performance.

In the future, a hosted LLM API, will be provided as part of the Supabase platform. Supabase will scale and manage the API and GPUs for you. To sign up for early access, fill up [this form](https://forms.supabase.com/supabase.ai-llm-early-access).

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2Fw4Rr_1whU-U%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Setup](https://supabase.com/docs/guides/functions/ai-models#setup) [Running a model inference](https://supabase.com/docs/guides/functions/ai-models#running-a-model-inference) [How to generate text embeddings](https://supabase.com/docs/guides/functions/ai-models#how-to-generate-text-embeddings) [Using Large Language Models (LLM)](https://supabase.com/docs/guides/functions/ai-models#using-large-language-models-llm) [Running locally](https://supabase.com/docs/guides/functions/ai-models#running-locally) [Deploying to production](https://supabase.com/docs/guides/functions/ai-models#deploying-to-production)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_auth.md">
Edge Functions

# Integrating With Supabase Auth

## Supabase Edge Functions and Auth.

* * *

Edge Functions work seamlessly with [Supabase Auth](https://supabase.com/docs/guides/auth).

## Auth context [\#](https://supabase.com/docs/guides/functions/auth\#auth-context)

When a user makes a request to an Edge Function, you can use the Authorization header to set the Auth context in the Supabase client:

`
import { createClient } from 'jsr:@supabase/supabase-js@2'
Deno.serve(async (req: Request) => {
const supabaseClient = createClient(
    Deno.env.get('SUPABASE_URL') ?? '',
    Deno.env.get('SUPABASE_ANON_KEY') ?? '',
);
// Get the session or user object
const authHeader = req.headers.get('Authorization')!;
const token = authHeader.replace('Bearer ', '');
const { data } = await supabaseClient.auth.getUser(token);
})
`

Importantly, this is done _inside_ the `Deno.serve()` callback argument, so that the Authorization header is set for each request.

## Fetching the user [\#](https://supabase.com/docs/guides/functions/auth\#fetching-the-user)

After initializing a Supabase client with the Auth context, you can use `getUser()` to fetch the user object, and run queries in the context of the user with [Row Level Security (RLS)](https://supabase.com/docs/guides/database/postgres/row-level-security) policies enforced.

`
import { createClient } from 'jsr:@supabase/supabase-js@2'
Deno.serve(async (req: Request) => {
const supabaseClient = createClient(
    Deno.env.get('SUPABASE_URL') ?? '',
    Deno.env.get('SUPABASE_ANON_KEY') ?? '',
)
// Get the session or user object
const authHeader = req.headers.get('Authorization')!
const token = authHeader.replace('Bearer ', '')
const { data } = await supabaseClient.auth.getUser(token)
const user = data.user
return new Response(JSON.stringify({ user }), {
    headers: { 'Content-Type': 'application/json' },
    status: 200,
})
})
`

## Row Level Security [\#](https://supabase.com/docs/guides/functions/auth\#row-level-security)

After initializing a Supabase client with the Auth context, all queries will be executed with the context of the user. For database queries, this means [Row Level Security](https://supabase.com/docs/guides/database/postgres/row-level-security) will be enforced.

`
import { createClient } from 'jsr:@supabase/supabase-js@2'
Deno.serve(async (req: Request) => {
const supabaseClient = createClient(
    Deno.env.get('SUPABASE_URL') ?? '',
    Deno.env.get('SUPABASE_ANON_KEY') ?? '',
);
// Get the session or user object
const authHeader = req.headers.get('Authorization')!;
const token = authHeader.replace('Bearer ', '');
const { data: userData } = await supabaseClient.auth.getUser(token);
const { data, error } = await supabaseClient.from('profiles').select('*');
return new Response(JSON.stringify({ data }), {
    headers: { 'Content-Type': 'application/json' },
    status: 200,
})
})
`

## Example code [\#](https://supabase.com/docs/guides/functions/auth\#example-code)

See a full [example on GitHub](https://github.com/supabase/supabase/blob/master/examples/edge-functions/supabase/functions/select-from-table-with-auth-rls/index.ts).

### Is this helpful?

NoYes

### On this page

[Auth context](https://supabase.com/docs/guides/functions/auth#auth-context) [Fetching the user](https://supabase.com/docs/guides/functions/auth#fetching-the-user) [Row Level Security](https://supabase.com/docs/guides/functions/auth#row-level-security) [Example code](https://supabase.com/docs/guides/functions/auth#example-code)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_background_tasks.md">
Edge Functions

# Background Tasks

## How to run background tasks in an Edge Function outside of the request handler

* * *

Edge Function instances can process background tasks outside of the request handler. Background tasks are useful for asynchronous operations like uploading a file to Storage, updating a database, or sending events to a logging service. You can respond to the request immediately and leave the task running in the background.

### How it works [\#](https://supabase.com/docs/guides/functions/background-tasks\#how-it-works)

You can use `EdgeRuntime.waitUntil(promise)` to explicitly mark background tasks. The Function instance continues to run until the promise provided to `waitUntil` completes.

The maximum duration is capped based on the wall-clock, CPU, and memory limits. The Function will shutdown when it reaches one of these [limits](https://supabase.com/docs/guides/functions/limits).

You can listen to the `beforeunload` event handler to be notified when Function invocation is about to be shut down.

### Example [\#](https://supabase.com/docs/guides/functions/background-tasks\#example)

Here's an example of using `EdgeRuntime.waitUntil` to run a background task and using `beforeunload` event to be notified when the instance is about to be shut down.

`
async function longRunningTask() {
// do work here
}
// Mark the longRunningTask's returned promise as a background task.
// note: we are not using await because we don't want it to block.
EdgeRuntime.waitUntil(longRunningTask())
// Use beforeunload event handler to be notified when function is about to shutdown
addEventListener('beforeunload', (ev) => {
console.log('Function will be shutdown due to', ev.detail?.reason)
// save state or log the current progress
})
// Invoke the function using a HTTP request.
// This will start the background task
Deno.serve(async (req) => {
return new Response('ok')
})
`

### Starting a background task in the request handler [\#](https://supabase.com/docs/guides/functions/background-tasks\#starting-a-background-task-in-the-request-handler)

You can call `EdgeRuntime.waitUntil` in the request handler too. This will not block the request.

`
async function fetchAndLog(url: string) {
const response = await fetch(url)
console.log(response)
}
Deno.serve(async (req) => {
// this will not block the request,
// instead it will run in the background
EdgeRuntime.waitUntil(fetchAndLog('https://httpbin.org/json'))
return new Response('ok')
})
`

### Testing background tasks locally [\#](https://supabase.com/docs/guides/functions/background-tasks\#testing-background-tasks-locally)

When testing Edge Functions locally with Supabase CLI, the instances are terminated automatically after a request is completed. This will prevent background tasks from running to completion.

To prevent that, you can update the `supabase/config.toml` with the following settings:

`
[edge_runtime]
policy = "per_worker"
`

When running with `per_worker` policy, Function won't auto-reload on edits. You will need to manually restart it by running `supabase functions serve`.

### Is this helpful?

NoYes

### On this page

[How it works](https://supabase.com/docs/guides/functions/background-tasks#how-it-works) [Example](https://supabase.com/docs/guides/functions/background-tasks#example) [Starting a background task in the request handler](https://supabase.com/docs/guides/functions/background-tasks#starting-a-background-task-in-the-request-handler) [Testing background tasks locally](https://supabase.com/docs/guides/functions/background-tasks#testing-background-tasks-locally)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_cicd_workflow.md">
Edge Functions

# Deploying with CI / CD pipelines

## Use GitHub Actions, Bitbucket, and GitLab CI to deploy your Edge Functions.

* * *

You can use popular CI / CD tools like GitHub Actions, Bitbucket, and GitLab CI to automate Edge Function deployments.

## GitHub Actions [\#](https://supabase.com/docs/guides/functions/cicd-workflow\#github-actions)

You can use the official [`setup-cli` GitHub Action](https://github.com/marketplace/actions/supabase-cli-action) to run Supabase CLI commands in your GitHub Actions.

The following GitHub Action deploys all Edge Functions any time code is merged into the `main` branch:

`
name: Deploy Function
on:
push:
    branches:
      - main
workflow_dispatch:
jobs:
deploy:
    runs-on: ubuntu-latest
    env:
      SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
      PROJECT_ID: your-project-id
    steps:
      - uses: actions/checkout@v3
      - uses: supabase/setup-cli@v1
        with:
          version: latest
      - run: supabase functions deploy --project-ref $PROJECT_ID
`

## GitLab CI [\#](https://supabase.com/docs/guides/functions/cicd-workflow\#gitlab-ci)

Here is the sample pipeline configuration to deploy via GitLab CI.

`
image: node:20
# List of stages for jobs, and their order of execution
stages:
  - setup
  - deploy
# This job runs in the setup stage, which runs first.
setup-npm:
stage: setup
script:
    - npm i supabase
cache:
    paths:
      - node_modules/
artifacts:
    paths:
      - node_modules/
# This job runs in the deploy stage, which only starts when the job in the build stage completes successfully.
deploy-function:
stage: deploy
script:
    - npx supabase init
    - npx supabase functions deploy --debug
services:
    - docker:dind
variables:
    DOCKER_HOST: tcp://docker:2375
`

## Bitbucket Pipelines [\#](https://supabase.com/docs/guides/functions/cicd-workflow\#bitbucket-pipelines)

Here is the sample pipeline configuration to deploy via Bitbucket.

`
image: node:20
pipelines:
default:
    - step:
        name: Setup
        caches:
          - node
        script:
          - npm i supabase
    - parallel:
        - step:
            name: Functions Deploy
            script:
              - npx supabase init
              - npx supabase functions deploy --debug
            services:
              - docker
`

## Declarative configuration [\#](https://supabase.com/docs/guides/functions/cicd-workflow\#declarative-configuration)

Individual function configuration like [JWT verification](https://supabase.com/docs/guides/cli/config#functions.function_name.verify_jwt) and [import map location](https://supabase.com/docs/guides/cli/config#functions.function_name.import_map) can be set via the `config.toml` file.

`
[functions.hello-world]
verify_jwt = false
`

## Resources [\#](https://supabase.com/docs/guides/functions/cicd-workflow\#resources)

- See the [example on GitHub](https://github.com/supabase/supabase/blob/master/examples/edge-functions/.github/workflows/deploy.yaml).

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2F6OMVWiiycLs%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[GitHub Actions](https://supabase.com/docs/guides/functions/cicd-workflow#github-actions) [GitLab CI](https://supabase.com/docs/guides/functions/cicd-workflow#gitlab-ci) [Bitbucket Pipelines](https://supabase.com/docs/guides/functions/cicd-workflow#bitbucket-pipelines) [Declarative configuration](https://supabase.com/docs/guides/functions/cicd-workflow#declarative-configuration) [Resources](https://supabase.com/docs/guides/functions/cicd-workflow#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_compression.md">
Edge Functions

# Handling Compressed Requests

## Handling Gzip compressed requests.

* * *

To decompress Gzip bodies, you can use `gunzipSync` from the `node:zlib` API to decompress and then read the body.

``
import { gunzipSync } from 'node:zlib'
Deno.serve(async (req) => {
try {
    // Check if the request body is gzip compressed
    const contentEncoding = req.headers.get('content-encoding')
    if (contentEncoding !== 'gzip') {
      return new Response('Request body is not gzip compressed', {
        status: 400,
      })
    }
    // Read the compressed body
    const compressedBody = await req.arrayBuffer()
    // Decompress the body
    const decompressedBody = gunzipSync(new Uint8Array(compressedBody))
    // Convert the decompressed body to a string
    const decompressedString = new TextDecoder().decode(decompressedBody)
    const data = JSON.parse(decompressedString)
    // Process the decompressed body as needed
    console.log(`Received: ${JSON.stringify(data)}`)
    return new Response('ok', {
      headers: { 'Content-Type': 'text/plain' },
    })
} catch (error) {
    console.error('Error:', error)
    return new Response('Error processing request', { status: 500 })
}
})
``

Edge functions have a runtime memory limit of 150MB. Overly large compressed payloads may result in an out-of-memory error.

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_connect_to_postgres.md">
Edge Functions

# Connecting directly to Postgres

## Connecting to Postgres from Edge Functions.

* * *

Connect to your Postgres database from an Edge Function by using the `supabase-js` client.
You can also use other Postgres clients like [Deno Postgres](https://deno.land/x/postgres)

## Using supabase-js [\#](https://supabase.com/docs/guides/functions/connect-to-postgres\#using-supabase-js)

The `supabase-js` client is a great option for connecting to your Supabase database since it handles authorization with Row Level Security, and it automatically formats your response as JSON.

index.ts

`
import { createClient } from 'jsr:@supabase/supabase-js@2'
Deno.serve(async (req) => {
try {
    const supabase = createClient(
      Deno.env.get('SUPABASE_URL') ?? '',
      Deno.env.get('SUPABASE_ANON_KEY') ?? '',
      { global: { headers: { Authorization: req.headers.get('Authorization')! } } }
    )
    const { data, error } = await supabase.from('countries').select('*')
    if (error) {
      throw error
    }
    return new Response(JSON.stringify({ data }), {
      headers: { 'Content-Type': 'application/json' },
      status: 200,
    })
} catch (err) {
    return new Response(String(err?.message ?? err), { status: 500 })
}
})
`

## Using a Postgres client [\#](https://supabase.com/docs/guides/functions/connect-to-postgres\#using-a-postgres-client)

Because Edge Functions are a server-side technology, it's safe to connect directly to your database using any popular Postgres client. This means you can run raw SQL from your Edge Functions.

Here is how you can connect to the database using Deno Postgres driver and run raw SQL.

Check out the [full example](https://github.com/supabase/supabase/tree/master/examples/edge-functions/supabase/functions/postgres-on-the-edge).

index.ts

``
import * as postgres from 'https://deno.land/x/postgres@v0.17.0/mod.ts'
// Get the connection string from the environment variable "SUPABASE_DB_URL"
const databaseUrl = Deno.env.get('SUPABASE_DB_URL')!
// Create a database pool with three connections that are lazily established
const pool = new postgres.Pool(databaseUrl, 3, true)
Deno.serve(async (_req) => {
try {
    // Grab a connection from the pool
    const connection = await pool.connect()
    try {
      // Run a query
      const result = await connection.queryObject`SELECT * FROM animals`
      const animals = result.rows // [{ id: 1, name: "Lion" }, ...]
      // Encode the result as pretty printed JSON
      const body = JSON.stringify(
        animals,
        (key, value) => (typeof value === 'bigint' ? value.toString() : value),
        2
      )
      // Return the response with the correct content type header
      return new Response(body, {
        status: 200,
        headers: { 'Content-Type': 'application/json; charset=utf-8' },
      })
    } finally {
      // Release the connection back into the pool
      connection.release()
    }
} catch (err) {
    console.error(err)
    return new Response(String(err?.message ?? err), { status: 500 })
}
})
``

## Using Drizzle [\#](https://supabase.com/docs/guides/functions/connect-to-postgres\#using-drizzle)

You can use Drizzle together with [Postgres.js](https://github.com/porsager/postgres). Both can be loaded directly from npm:

supabase/functions/import\_map.json

`
{
"imports": {
    "drizzle-orm": "npm:drizzle-orm@0.29.1",
    "drizzle-orm/": "npm:/drizzle-orm@0.29.1/",
    "postgres": "npm:postgres@3.4.3"
}
}
`

supabase/functions/drizzle/index.ts

`
import { drizzle } from 'drizzle-orm/postgres-js'
import postgres from 'postgres'
import { countries } from '../_shared/schema.ts'
const connectionString = Deno.env.get('SUPABASE_DB_URL')!
Deno.serve(async (_req) => {
// Disable prefetch as it is not supported for "Transaction" pool mode
const client = postgres(connectionString, { prepare: false })
const db = drizzle(client)
const allCountries = await db.select().from(countries)
return Response.json(allCountries)
})
`

You can find the full example on [GitHub](https://github.com/thorwebdev/edgy-drizzle).

## SSL connections [\#](https://supabase.com/docs/guides/functions/connect-to-postgres\#ssl-connections)

Deployed edge functions are pre-configured to use SSL for connections to the Supabase database. You don't need to add any extra configurations.

If you want to use SSL connections during local development, follow these steps:

- Download the SSL certificate from [Database settings](https://supabase.com/dashboard/project/_/settings/database)

- In your [local .env file](https://supabase.com/docs/guides/functions/secrets), add these two variables:


`
SSL_CERT_FILE=/path/to/cert.crt # set the path to the downloaded cert
DENO_TLS_CA_STORE=mozilla,system
`

Connecting to Postgres from Edge Functions - YouTube

Supabase

45.5K subscribers

[Connecting to Postgres from Edge Functions](https://www.youtube.com/watch?v=cl7EuF1-RsY)

Supabase

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=cl7EuF1-RsY "Watch on YouTube")

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2Fcl7EuF1-RsY%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Using supabase-js](https://supabase.com/docs/guides/functions/connect-to-postgres#using-supabase-js) [Using a Postgres client](https://supabase.com/docs/guides/functions/connect-to-postgres#using-a-postgres-client) [Using Drizzle](https://supabase.com/docs/guides/functions/connect-to-postgres#using-drizzle) [SSL connections](https://supabase.com/docs/guides/functions/connect-to-postgres#ssl-connections)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_cors.md">
Edge Functions

# CORS (Cross-Origin Resource Sharing) support for Invoking from the browser

* * *

To invoke edge functions from the browser, you need to handle [CORS Preflight](https://developer.mozilla.org/en-US/docs/Glossary/Preflight_request) requests.

See the [example on GitHub](https://github.com/supabase/supabase/blob/master/examples/edge-functions/supabase/functions/browser-with-cors/index.ts).

### Recommended setup [\#](https://supabase.com/docs/guides/functions/cors\#recommended-setup)

We recommend adding a `cors.ts` file within a [`_shared` folder](https://supabase.com/docs/guides/functions/quickstart#organizing-your-edge-functions) which makes it easy to reuse the CORS headers across functions:

cors.ts

`
export const corsHeaders = {
'Access-Control-Allow-Origin': '*',
'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
}
`

You can then import and use the CORS headers within your functions:

index.ts

``
import { corsHeaders } from '../_shared/cors.ts'
console.log(`Function "browser-with-cors" up and running!`)
Deno.serve(async (req) => {
// This is needed if you're planning to invoke your function from a browser.
if (req.method === 'OPTIONS') {
    return new Response('ok', { headers: corsHeaders })
}
try {
    const { name } = await req.json()
    const data = {
      message: `Hello ${name}!`,
    }
    return new Response(JSON.stringify(data), {
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      status: 200,
    })
} catch (error) {
    return new Response(JSON.stringify({ error: error.message }), {
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      status: 400,
    })
}
})
``

### Is this helpful?

NoYes

### On this page

[Recommended setup](https://supabase.com/docs/guides/functions/cors#recommended-setup)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_dart_edge.md">
Edge Functions

# Dart Edge

* * *

Be aware that the Dart Edge project is currently not actively maintained due to numerous breaking changes in Dart's development of (WASM) support.

[Dart Edge](https://docs.dartedge.dev/) is an experimental project that enables you to write Supabase Edge Functions using Dart. It's built and maintained by [Invertase](https://invertase.io/).

For detailed information on how to set up and use Dart Edge with Supabase, refer to the [official Dart Edge documentation for Supabase](https://invertase.docs.page/dart_edge/platform/supabase).

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_debugging_tools.md">
Edge Functions

# Local Debugging with DevTools

## How to use Chrome DevTools to debug Edge Functions.

* * *

Since [v1.171.0](https://github.com/supabase/cli/releases/tag/v1.171.0) the Supabase CLI supports debugging Edge Functions via the v8 inspector protocol, allowing for debugging via [Chrome DevTools](https://developer.chrome.com/docs/devtools/) and other Chromium-based browsers.

### Inspect with Chrome Developer Tools [\#](https://supabase.com/docs/guides/functions/debugging-tools\#inspect-with-chrome-developer-tools)

You can use the [Chrome DevTools](https://developer.chrome.com/docs/devtools/) to set breakpoints and inspect the execution of your Edge Functions.

1. Serve your functions in [inspect mode](https://supabase.com/docs/reference/cli/supabase-functions-serve): `supabase functions serve --inspect-mode brk`. This will set a breakpoint at the first line to pause script execution before any code runs.
2. In your Chrome browser navigate to `chrome://inspect`.
3. Click the "Configure..."" button to the right of the Discover network targets checkbox.
4. In the Target discovery settings dialog box that opens, enter `127.0.0.1:8083` in the blank space and click the "Done" button to exit the dialog box.
5. Click "Open dedicated DevTools for Node" to complete the preparation for debugging. The opened DevTools window will now listen to any incoming requests to edge-runtime.
6. Send a request to your function running locally, e.g. via curl or Postman. The DevTools window will now pause script execution at first line.
7. In the "Sources" tab navigate to `file://` \> `home/deno/functions/<your-function-name>/index.ts`.
8. Use the DevTools to set breakpoints and inspect the execution of your Edge Function.

![Debugging in Chrome DevTools.](https://supabase.com/docs/img/guides/functions/debug-chrome-devtools.png)

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2FsOrtcoKg5zQ%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Inspect with Chrome Developer Tools](https://supabase.com/docs/guides/functions/debugging-tools#inspect-with-chrome-developer-tools)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_dependencies.md">
Edge Functions

# Managing dependencies

## Managing packages and dependencies.

* * *

## Importing dependencies [\#](https://supabase.com/docs/guides/functions/dependencies\#importing-dependencies)

Supabase Edge Functions support several ways to import dependencies:

- JavaScript modules from npm ( [https://docs.deno.com/examples/npm/](https://docs.deno.com/examples/npm/))
- Built-in [Node APIs](https://docs.deno.com/runtime/manual/node/compatibility)
- Modules published to [JSR](https://jsr.io/) or [deno.land/x](https://deno.land/x)

### NPM modules [\#](https://supabase.com/docs/guides/functions/dependencies\#npm-modules)

You can import npm modules using the `npm:` specifier:

`
import { createClient } from 'npm:@supabase/supabase-js@2'
`

### Node.js built-ins [\#](https://supabase.com/docs/guides/functions/dependencies\#nodejs-built-ins)

For Node.js built-in APIs, use the `node:` specifier:

`
import process from 'node:process'
`

Learn more about npm specifiers and Node built-in APIs in [Deno's documentation](https://docs.deno.com/runtime/manual/node/npm_specifiers).

### JSR [\#](https://supabase.com/docs/guides/functions/dependencies\#jsr)

You can import JS modules published to [JSR](https://jsr.io/) (e.g.: Deno's standard library), using the `jsr:` specifier:

`
import path from 'jsr:@std/path@1.0.8'
`

## Managing dependencies [\#](https://supabase.com/docs/guides/functions/dependencies\#managing-dependencies)

Developing with Edge Functions is similar to developing with Node.js, but with a few key differences.

In the Deno ecosystem, each function should be treated as an independent project with its own set of dependencies and configurations. This "isolation by design" approach:

- Ensures each function has explicit control over its dependencies
- Prevents unintended side effects between functions
- Makes deployments more predictable and maintainable
- Allows for different versions of the same dependency across functions

For these reasons, we recommend maintaining separate configuration files ( `deno.json`, `.npmrc`, or `import_map.json`) within each function's directory, even if it means duplicating some configurations.

There are two ways to manage your dependencies in Supabase Edge Functions:

### Using deno.json (recommended) [\#](https://supabase.com/docs/guides/functions/dependencies\#using-denojson-recommended)

This feature requires Supabase CLI version 1.215.0 or higher.

Each function should have its own `deno.json` file to manage dependencies and configure Deno-specific settings. This ensures proper isolation between functions and is the recommended approach for deployment. For a complete list of supported options, see the [official Deno configuration documentation](https://docs.deno.com/runtime/manual/getting_started/configuration_file).

supabase/functions/my-function/deno.json

`
{
"imports": {
    "lodash": "https://cdn.skypack.dev/lodash"
}
}
`

The recommended file structure for deployment:

`
 supabase
     functions
        function-one
           index.ts
          - deno.json    # Function-specific Deno configuration
           .npmrc       # Function-specific npm configuration (if needed)
        function-two
            index.ts
           - deno.json    # Function-specific Deno configuration
            .npmrc       # Function-specific npm configuration (if needed)
     config.toml
`

While it's possible to use a global `deno.json` in the `/supabase/functions` directory for local
development, this approach is not recommended for deployment. Each function should maintain its
own configuration to ensure proper isolation and dependency management.

### Using import maps (legacy) [\#](https://supabase.com/docs/guides/functions/dependencies\#using-import-maps-legacy)

Import Maps are a legacy way to manage dependencies, similar to a `package.json` file. While still supported, we recommend using `deno.json`. If both exist, `deno.json` takes precedence.

Each function should have its own `import_map.json` file for proper isolation:

supabase/functions/my-function/import\_map.json

`
{
"imports": {
    "lodash": "https://cdn.skypack.dev/lodash"
}
}
`

The recommended file structure:

`
 supabase
     functions
        function-one
           index.ts
           import_map.json    # Function-specific import map
        function-two
            index.ts
            import_map.json    # Function-specific import map
     config.toml
`

While it's possible to use a global `import_map.json` in the `/supabase/functions` directory for
local development, this approach is not recommended for deployment. Each function should maintain
its own import map to ensure proper isolation.

If using import maps with VSCode, update your `.vscode/settings.json` to point to your function-specific import map:

settings.json

`
{
"deno.enable": true,
"deno.unstable": [\
    "bare-node-builtins",\
    "byonm"\
    // ... other flags ...\
],
"deno.importMap": "./supabase/functions/my-function/import_map.json"
}
`

You can override the default import map location using the `--import-map <string>` flag with `serve` and `deploy` commands, or by setting the `import_map` property in your `config.toml` file:

supabase/config.toml

`
[functions.my-function]
import_map = "./supabase/functions/my-function/import_map.json"
`

### Importing from private registries [\#](https://supabase.com/docs/guides/functions/dependencies\#importing-from-private-registries)

This feature requires Supabase CLI version 1.207.9 or higher.

To use private npm packages, create a `.npmrc` file within your function directory. This ensures proper isolation and dependency management for each function.

`
 supabase
     functions
         my-function
             index.ts
             deno.json
             .npmrc       # Function-specific npm configuration
`

Add your registry details in the `.npmrc` file. Follow [this guide](https://docs.npmjs.com/cli/v10/configuring-npm/npmrc) to learn more about the syntax of npmrc files.

`
@myorg:registry=https://npm.registryhost.com
//npm.registryhost.com/:_authToken=VALID_AUTH_TOKEN
`

While it's possible to use a global `.npmrc` in the `/supabase/functions` directory for local
development, we recommend using function-specific `.npmrc` files for deployment to maintain proper
isolation.

After configuring your `.npmrc`, you can import the private package in your function code:

`
import MyPackage from 'npm:@myorg/private-package@v1.0.1'
// use MyPackage
`

### Using a custom NPM registry [\#](https://supabase.com/docs/guides/functions/dependencies\#using-a-custom-npm-registry)

This feature requires Supabase CLI version 2.2.8 or higher.

Some organizations require a custom NPM registry for security and compliance purposes. In such instances, you can specify the custom NPM registry to use via `NPM_CONFIG_REGISTRY` environment variable.

You can define it in the project's `.env` file or directly specify it when running the deploy command:

`
NPM_CONFIG_REGISTRY=https://custom-registry/ supabase functions deploy my-function
`

## Importing types [\#](https://supabase.com/docs/guides/functions/dependencies\#importing-types)

If your [environment is set up properly](https://supabase.com/docs/guides/functions/local-development) and the module you're importing is exporting types, the import will have types and autocompletion support.

Some npm packages may not ship out of the box types and you may need to import them from a separate package. You can specify their types with a `@deno-types` directive:

`
// @deno-types="npm:@types/express@^4.17"
import express from 'npm:express@^4.17'
`

To include types for built-in Node APIs, add the following line to the top of your imports:

`
/// <reference types="npm:@types/node" />
`

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2FILr3cneZuFk%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Importing dependencies](https://supabase.com/docs/guides/functions/dependencies#importing-dependencies) [NPM modules](https://supabase.com/docs/guides/functions/dependencies#npm-modules) [Node.js built-ins](https://supabase.com/docs/guides/functions/dependencies#nodejs-built-ins) [JSR](https://supabase.com/docs/guides/functions/dependencies#jsr) [Managing dependencies](https://supabase.com/docs/guides/functions/dependencies#managing-dependencies) [Using deno.json (recommended)](https://supabase.com/docs/guides/functions/dependencies#using-denojson-recommended) [Using import maps (legacy)](https://supabase.com/docs/guides/functions/dependencies#using-import-maps-legacy) [Importing from private registries](https://supabase.com/docs/guides/functions/dependencies#importing-from-private-registries) [Using a custom NPM registry](https://supabase.com/docs/guides/functions/dependencies#using-a-custom-npm-registry) [Importing types](https://supabase.com/docs/guides/functions/dependencies#importing-types)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_deploy.md">
Edge Functions

# Deploy to Production

## Deploy your Edge Functions to your remote Supabase Project.

* * *

Once you have developed your Edge Functions locally, you can deploy them to your Supabase project.

## Login to the CLI [\#](https://supabase.com/docs/guides/functions/deploy\#login-to-the-cli)

Log in to the Supabase CLI if necessary:

`
supabase login
`

##### CLI not installed?

See the [CLI Docs](https://supabase.com/docs/guides/cli) to learn how to install the Supabase CLI on your local machine.

## Get your project ID [\#](https://supabase.com/docs/guides/functions/deploy\#get-your-project-id)

Get the project ID associated with your function by running:

`
supabase projects list
`

##### Need a new project?

If you haven't yet created a Supabase project, you can do so by visiting [database.new](https://database.new/).

## Link your local project [\#](https://supabase.com/docs/guides/functions/deploy\#link-your-local-project)

[Link](https://supabase.com/docs/reference/cli/usage#supabase-link) your local project to your remote Supabase project using the ID you just retrieved:

`
supabase link --project-ref your-project-id
`

## Deploy your Edge Functions [\#](https://supabase.com/docs/guides/functions/deploy\#deploy-your-edge-functions)

##### Docker required

Since Supabase CLI version 1.123.4, you must have [Docker Desktop](https://docs.docker.com/desktop/) installed to deploy Edge Functions.

You can deploy all of your Edge Functions with a single command:

`
supabase functions deploy
`

You can deploy individual Edge Functions by specifying the name of the function in the deploy command:

`
supabase functions deploy hello-world
`

By default, Edge Functions require a valid JWT in the authorization header. If you want to use Edge Functions without Authorization checks (commonly used for Stripe webhooks), you can pass the `--no-verify-jwt` flag when deploying your Edge Functions.

`
supabase functions deploy hello-world --no-verify-jwt
`

Be careful when using this flag, as it will allow anyone to invoke your Edge Function without a valid JWT. The Supabase client libraries automatically handle authorization.

## Invoking remote functions [\#](https://supabase.com/docs/guides/functions/deploy\#invoking-remote-functions)

You can now invoke your Edge Function using the project's `ANON_KEY`, which can be found in the [API settings](https://supabase.com/dashboard/project/_/settings/api) of the Supabase Dashboard.

cURL

JavaScript

`
curl --request POST 'https://<project_id>.supabase.co/functions/v1/hello-world' \
  --header 'Authorization: Bearer ANON_KEY' \
  --header 'Content-Type: application/json' \
  --data '{ "name":"Functions" }'
`

You should receive the response `{ "message":"Hello Functions!" }`.

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2F5OWH9c4u68M%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Login to the CLI](https://supabase.com/docs/guides/functions/deploy#login-to-the-cli) [Get your project ID](https://supabase.com/docs/guides/functions/deploy#get-your-project-id) [Link your local project](https://supabase.com/docs/guides/functions/deploy#link-your-local-project) [Deploy your Edge Functions](https://supabase.com/docs/guides/functions/deploy#deploy-your-edge-functions) [Invoking remote functions](https://supabase.com/docs/guides/functions/deploy#invoking-remote-functions)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_ephemeral_storage.md">
Edge Functions

# Ephemeral Storage

## Read and write from temporary directory

* * *

Edge Functions provides ephemeral file storage. You can read and write files to the `/tmp` directory.

Ephemeral storage will reset on each function invocation. This means the files you write during an invocation can only be read within the same invocation.

### Use cases [\#](https://supabase.com/docs/guides/functions/ephemeral-storage\#use-cases)

Here are some use cases where ephemeral storage can be useful:

- Unzip an archive of CSVs and then add them as records to the DB
- Custom image manipulation workflows (using [`magick-wasm`](https://supabase.com/docs/guides/functions/examples/image-manipulation))

You can use [Background Tasks](https://supabase.com/docs/guides/functions/background-tasks) to handle slow file processing outside of a request.

### How to use [\#](https://supabase.com/docs/guides/functions/ephemeral-storage\#how-to-use)

You can use [Deno File System APIs](https://docs.deno.com/api/deno/file-system) or the [`node:fs` module](https://docs.deno.com/api/node/fs/) to access the `/tmp` path.

### Example [\#](https://supabase.com/docs/guides/functions/ephemeral-storage\#example)

Here is an example of how to write a user-uploaded zip file into temporary storage for further processing.

`
Deno.serve(async (req) => {
if (req.headers.get('content-type') !== 'application/zip') {
    return new Response('file must be a zip file', {
      status: 400,
    })
}
const uploadId = crypto.randomUUID()
await Deno.writeFile('/tmp/' + uploadId, req.body)
// do something with the written zip file
return new Response('ok')
})
`

### Unavailable APIs [\#](https://supabase.com/docs/guides/functions/ephemeral-storage\#unavailable-apis)

Currently, the synchronous APIs (e.g. `Deno.writeFileSync` or `Deno.mkdirSync`) for creating or writing files are not supported.

You can use sync variations of read APIs (e.g. `Deno.readFileSync`).

### Limits [\#](https://supabase.com/docs/guides/functions/ephemeral-storage\#limits)

In the hosted platform, a free project can write up to 256MB of data to ephemeral storage. A paid project can write up to 512MB.

### Is this helpful?

NoYes

### On this page

[Use cases](https://supabase.com/docs/guides/functions/ephemeral-storage#use-cases) [How to use](https://supabase.com/docs/guides/functions/ephemeral-storage#how-to-use) [Example](https://supabase.com/docs/guides/functions/ephemeral-storage#example) [Unavailable APIs](https://supabase.com/docs/guides/functions/ephemeral-storage#unavailable-apis) [Limits](https://supabase.com/docs/guides/functions/ephemeral-storage#limits)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_examples_amazon_bedrock_image_generator.md">
Edge Functions

# Generate Images with Amazon Bedrock

* * *

[Amazon Bedrock](https://aws.amazon.com/bedrock) is a fully managed service that offers a choice of high-performing foundation models (FMs) from leading AI companies like AI21 Labs, Anthropic, Cohere, Meta, Mistral AI, Stability AI, and Amazon. Each model is accessible through a common API which implements a broad set of features to help build generative AI applications with security, privacy, and responsible AI in mind.

This guide will walk you through an example using the Amazon Bedrock JavaScript SDK in Supabase Edge Functions to generate images using the [Amazon Titan Image Generator G1](https://aws.amazon.com/blogs/machine-learning/use-amazon-titan-models-for-image-generation-editing-and-searching/) model.

## Setup [\#](https://supabase.com/docs/guides/functions/examples/amazon-bedrock-image-generator\#setup)

- In your AWS console, navigate to Amazon Bedrock and under "Request model access", select the Amazon Titan Image Generator G1 model.
- In your Supabase project, create a `.env` file in the `supabase` directory with the following contents:

`
AWS_DEFAULT_REGION="<your_region>"
AWS_ACCESS_KEY_ID="<replace_your_own_credentials>"
AWS_SECRET_ACCESS_KEY="<replace_your_own_credentials>"
AWS_SESSION_TOKEN="<replace_your_own_credentials>"
# Mocked config files
AWS_SHARED_CREDENTIALS_FILE="./aws/credentials"
AWS_CONFIG_FILE="./aws/config"
`

### Configure Storage [\#](https://supabase.com/docs/guides/functions/examples/amazon-bedrock-image-generator\#configure-storage)

- \[locally\] Run `supabase start`
- Open Studio URL: [locally](http://127.0.0.1:54323/project/default/storage/buckets) \| [hosted](https://app.supabase.com/project/_/storage/buckets)
- Navigate to Storage
- Click "New bucket"
- Create a new public bucket called "images"

## Code [\#](https://supabase.com/docs/guides/functions/examples/amazon-bedrock-image-generator\#code)

Create a new function in your project:

`
supabase functions new amazon-bedrock
`

And add the code to the `index.ts` file:

index.ts

``
// We need to mock the file system for the AWS SDK to work.
import { prepareVirtualFile } from 'https://deno.land/x/mock_file@v1.1.2/mod.ts'
import { BedrockRuntimeClient, InvokeModelCommand } from 'npm:@aws-sdk/client-bedrock-runtime'
import { createClient } from 'npm:@supabase/supabase-js'
import { decode } from 'npm:base64-arraybuffer'
console.log('Hello from Amazon Bedrock!')
Deno.serve(async (req) => {
prepareVirtualFile('./aws/config')
prepareVirtualFile('./aws/credentials')
const client = new BedrockRuntimeClient({
    region: Deno.env.get('AWS_DEFAULT_REGION') ?? 'us-west-2',
    credentials: {
      accessKeyId: Deno.env.get('AWS_ACCESS_KEY_ID') ?? '',
      secretAccessKey: Deno.env.get('AWS_SECRET_ACCESS_KEY') ?? '',
      sessionToken: Deno.env.get('AWS_SESSION_TOKEN') ?? '',
    },
})
const { prompt, seed } = await req.json()
console.log(prompt)
const input = {
    contentType: 'application/json',
    accept: '*/*',
    modelId: 'amazon.titan-image-generator-v1',
    body: JSON.stringify({
      taskType: 'TEXT_IMAGE',
      textToImageParams: { text: prompt },
      imageGenerationConfig: {
        numberOfImages: 1,
        quality: 'standard',
        cfgScale: 8.0,
        height: 512,
        width: 512,
        seed: seed ?? 0,
      },
    }),
}
const command = new InvokeModelCommand(input)
const response = await client.send(command)
console.log(response)
if (response.$metadata.httpStatusCode === 200) {
    const { body, $metadata } = response
    const textDecoder = new TextDecoder('utf-8')
    const jsonString = textDecoder.decode(body.buffer)
    const parsedData = JSON.parse(jsonString)
    console.log(parsedData)
    const image = parsedData.images[0]
    const supabaseClient = createClient(
      // Supabase API URL - env var exported by default.
      Deno.env.get('SUPABASE_URL')!,
      // Supabase API ANON KEY - env var exported by default.
      Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!
    )
    const { data: upload, error: uploadError } = await supabaseClient.storage
      .from('images')
      .upload(`${$metadata.requestId ?? ''}.png`, decode(image), {
        contentType: 'image/png',
        cacheControl: '3600',
        upsert: false,
      })
    if (!upload) {
      return Response.json(uploadError)
    }
    const { data } = supabaseClient.storage.from('images').getPublicUrl(upload.path!)
    return Response.json(data)
}
return Response.json(response)
})
``

## Run the function locally [\#](https://supabase.com/docs/guides/functions/examples/amazon-bedrock-image-generator\#run-the-function-locally)

1. Run `supabase start` (see: [https://supabase.com/docs/reference/cli/supabase-start](https://supabase.com/docs/reference/cli/supabase-start))
2. Start with env: `supabase functions serve --env-file supabase/.env`
3. Make an HTTP request:

`
curl -i --location --request POST 'http://127.0.0.1:54321/functions/v1/amazon-bedrock' \
    --header 'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZS1kZW1vIiwicm9sZSI6ImFub24iLCJleHAiOjE5ODM4MTI5OTZ9.CRXP1A7WOeoJeXxjNni43kdQwgnWNReilDMblYTn_I0' \
    --header 'Content-Type: application/json' \
    --data '{"prompt":"A beautiful picture of a bird"}'
`

4. Navigate back to your storage bucket. You might have to hit the refresh button to see the uploaded image.

## Deploy to your hosted project [\#](https://supabase.com/docs/guides/functions/examples/amazon-bedrock-image-generator\#deploy-to-your-hosted-project)

`
supabase link
supabase functions deploy amazon-bedrock
supabase secrets set --env-file supabase/.env
`

You've now deployed a serverless function that uses AI to generate and upload images to your Supabase storage bucket.

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2FKIwN2TmkTlg%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Setup](https://supabase.com/docs/guides/functions/examples/amazon-bedrock-image-generator#setup) [Configure Storage](https://supabase.com/docs/guides/functions/examples/amazon-bedrock-image-generator#configure-storage) [Code](https://supabase.com/docs/guides/functions/examples/amazon-bedrock-image-generator#code) [Run the function locally](https://supabase.com/docs/guides/functions/examples/amazon-bedrock-image-generator#run-the-function-locally) [Deploy to your hosted project](https://supabase.com/docs/guides/functions/examples/amazon-bedrock-image-generator#deploy-to-your-hosted-project)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_examples_auth_send_email_hook_react_email_resend.md">
Edge Functions

# Custom Auth Emails with React Email and Resend

* * *

Use the [send email hook](https://supabase.com/docs/guides/auth/auth-hooks/send-email-hook?queryGroups=language&language=http) to send custom auth emails with [React Email](https://react.email/) and [Resend](https://resend.com/) in Supabase Edge Functions.

Prefer to jump straight to the code? [Check out the example on GitHub](https://github.com/supabase/supabase/tree/master/examples/edge-functions/supabase/functions/auth-hook-react-email-resend).

### Prerequisites [\#](https://supabase.com/docs/guides/functions/examples/auth-send-email-hook-react-email-resend\#prerequisites)

To get the most out of this guide, youll need to:

- [Create a Resend API key](https://resend.com/api-keys)
- [Verify your domain](https://resend.com/domains)

Make sure you have the latest version of the[Supabase CLI](https://supabase.com/docs/guides/cli#installation)installed.

### 1\. Create Supabase function [\#](https://supabase.com/docs/guides/functions/examples/auth-send-email-hook-react-email-resend\#1-create-supabase-function)

Create a new function locally:

`
supabase functions new send-email
`

### 2\. Edit the handler function [\#](https://supabase.com/docs/guides/functions/examples/auth-send-email-hook-react-email-resend\#2-edit-the-handler-function)

Paste the following code into the`index.ts`file:

supabase/functions/send-email/index.ts

`
import React from 'npm:react@18.3.1'
import { Webhook } from 'https://esm.sh/standardwebhooks@1.0.0'
import { Resend } from 'npm:resend@4.0.0'
import { renderAsync } from 'npm:@react-email/components@0.0.22'
import { MagicLinkEmail } from './_templates/magic-link.tsx'
const resend = new Resend(Deno.env.get('RESEND_API_KEY') as string)
const hookSecret = Deno.env.get('SEND_EMAIL_HOOK_SECRET') as string
Deno.serve(async (req) => {
if (req.method !== 'POST') {
    return new Response('not allowed', { status: 400 })
}
const payload = await req.text()
const headers = Object.fromEntries(req.headers)
const wh = new Webhook(hookSecret)
try {
    const {
      user,
      email_data: { token, token_hash, redirect_to, email_action_type },
    } = wh.verify(payload, headers) as {
      user: {
        email: string
      }
      email_data: {
        token: string
        token_hash: string
        redirect_to: string
        email_action_type: string
        site_url: string
        token_new: string
        token_hash_new: string
      }
    }
    const html = await renderAsync(
      React.createElement(MagicLinkEmail, {
        supabase_url: Deno.env.get('SUPABASE_URL') ?? '',
        token,
        token_hash,
        redirect_to,
        email_action_type,
      })
    )
    const { error } = await resend.emails.send({
      from: 'welcome <onboarding@resend.dev>',
      to: [user.email],
      subject: 'Supa Custom MagicLink!',
      html,
    })
    if (error) {
      throw error
    }
} catch (error) {
    console.log(error)
    return new Response(
      JSON.stringify({
        error: {
          http_code: error.code,
          message: error.message,
        },
      }),
      {
        status: 401,
        headers: { 'Content-Type': 'application/json' },
      }
    )
}
const responseHeaders = new Headers()
responseHeaders.set('Content-Type', 'application/json')
return new Response(JSON.stringify({}), {
    status: 200,
    headers: responseHeaders,
})
})
`

### 3\. Create React Email templates [\#](https://supabase.com/docs/guides/functions/examples/auth-send-email-hook-react-email-resend\#3-create-react-email-templates)

Create a new folder `_templates` and create a new file `magic-link.tsx` with the following code:

supabase/functions/send-email/\_templates/magic-link.tsx

``
import {
Body,
Container,
Head,
Heading,
Html,
Link,
Preview,
Text,
} from 'npm:@react-email/components@0.0.22'
import * as React from 'npm:react@18.3.1'
interface MagicLinkEmailProps {
supabase_url: string
email_action_type: string
redirect_to: string
token_hash: string
token: string
}
export const MagicLinkEmail = ({
token,
supabase_url,
email_action_type,
redirect_to,
token_hash,
}: MagicLinkEmailProps) => (
<Html>
    <Head />
    <Preview>Log in with this magic link</Preview>
    <Body style={main}>
      <Container style={container}>
        <Heading style={h1}>Login</Heading>
        <Link
          href={`${supabase_url}/auth/v1/verify?token=${token_hash}&type=${email_action_type}&redirect_to=${redirect_to}`}
          target="_blank"
          style={{
            ...link,
            display: 'block',
            marginBottom: '16px',
          }}
        >
          Click here to log in with this magic link
        </Link>
        <Text style={{ ...text, marginBottom: '14px' }}>
          Or, copy and paste this temporary login code:
        </Text>
        <code style={code}>{token}</code>
        <Text
          style={{
            ...text,
            color: '#ababab',
            marginTop: '14px',
            marginBottom: '16px',
          }}
        >
          If you didn&apos;t try to login, you can safely ignore this email.
        </Text>
        <Text style={footer}>
          <Link
            href="https://demo.vercel.store/"
            target="_blank"
            style={{ ...link, color: '#898989' }}
          >
            ACME Corp
          </Link>
          , the famouse demo corp.
        </Text>
      </Container>
    </Body>
</Html>
)
export default MagicLinkEmail
const main = {
backgroundColor: '#ffffff',
}
const container = {
paddingLeft: '12px',
paddingRight: '12px',
margin: '0 auto',
}
const h1 = {
color: '#333',
fontFamily:
    "-apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', 'Oxygen', 'Ubuntu', 'Cantarell', 'Fira Sans', 'Droid Sans', 'Helvetica Neue', sans-serif",
fontSize: '24px',
fontWeight: 'bold',
margin: '40px 0',
padding: '0',
}
const link = {
color: '#2754C5',
fontFamily:
    "-apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', 'Oxygen', 'Ubuntu', 'Cantarell', 'Fira Sans', 'Droid Sans', 'Helvetica Neue', sans-serif",
fontSize: '14px',
textDecoration: 'underline',
}
const text = {
color: '#333',
fontFamily:
    "-apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', 'Oxygen', 'Ubuntu', 'Cantarell', 'Fira Sans', 'Droid Sans', 'Helvetica Neue', sans-serif",
fontSize: '14px',
margin: '24px 0',
}
const footer = {
color: '#898989',
fontFamily:
    "-apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', 'Oxygen', 'Ubuntu', 'Cantarell', 'Fira Sans', 'Droid Sans', 'Helvetica Neue', sans-serif",
fontSize: '12px',
lineHeight: '22px',
marginTop: '12px',
marginBottom: '24px',
}
const code = {
display: 'inline-block',
padding: '16px 4.5%',
width: '90.5%',
backgroundColor: '#f4f4f4',
borderRadius: '5px',
border: '1px solid #eee',
color: '#333',
}
``

You can find a selection of React Email templates in the [React Email Examples](https://react.email/examples).

### 4\. Deploy the Function [\#](https://supabase.com/docs/guides/functions/examples/auth-send-email-hook-react-email-resend\#4-deploy-the-function)

Deploy function to Supabase:

`
supabase functions deploy send-email --no-verify-jwt
`

Note down the function URL, you will need it in the next step!

### 5\. Configure the Send Email Hook [\#](https://supabase.com/docs/guides/functions/examples/auth-send-email-hook-react-email-resend\#5-configure-the-send-email-hook)

- Go to the [Auth Hooks](https://supabase.com/dashboard/project/_/auth/hooks) section of the Supabase dashboard and create a new "Send Email hook".
- Select HTTPS as the hook type.
- Paste the function URL in the "URL" field.
- Click "Generate Secret" to generate your webhook secret and note it down.
- Click "Create" to save the hook configuration.

Store these secrets in your `.env` file.

supabase/functions/.env

`
RESEND_API_KEY=your_resend_api_key
SEND_EMAIL_HOOK_SECRET=<base64_secret>
`

You can generate the secret in the [Auth Hooks](https://supabase.com/dashboard/project/_/auth/hooks) section of the Supabase dashboard. Make sure to remove the `v1,whsec_` prefix!

Set the secrets from the `.env` file:

`
supabase secrets set --env-file supabase/functions/.env
`

Now your Supabase Edge Function will be triggered anytime an Auth Email needs to be send to the user!

## More resources [\#](https://supabase.com/docs/guides/functions/examples/auth-send-email-hook-react-email-resend\#more-resources)

- [Send Email Hooks](https://supabase.com/docs/guides/auth/auth-hooks/send-email-hook)
- [Auth Hooks](https://supabase.com/docs/guides/auth/auth-hooks)

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2FtlA7BomSCgU%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Prerequisites](https://supabase.com/docs/guides/functions/examples/auth-send-email-hook-react-email-resend#prerequisites) [1\. Create Supabase function](https://supabase.com/docs/guides/functions/examples/auth-send-email-hook-react-email-resend#1-create-supabase-function) [2\. Edit the handler function](https://supabase.com/docs/guides/functions/examples/auth-send-email-hook-react-email-resend#2-edit-the-handler-function) [3\. Create React Email templates](https://supabase.com/docs/guides/functions/examples/auth-send-email-hook-react-email-resend#3-create-react-email-templates) [4\. Deploy the Function](https://supabase.com/docs/guides/functions/examples/auth-send-email-hook-react-email-resend#4-deploy-the-function) [5\. Configure the Send Email Hook](https://supabase.com/docs/guides/functions/examples/auth-send-email-hook-react-email-resend#5-configure-the-send-email-hook) [More resources](https://supabase.com/docs/guides/functions/examples/auth-send-email-hook-react-email-resend#more-resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_examples_cloudflare_turnstile.md">
Edge Functions

# CAPTCHA support with Cloudflare Turnstile

* * *

[Cloudflare Turnstile](https://www.cloudflare.com/products/turnstile/) is a friendly, free CAPTCHA replacement, and it works seamlessly with Supabase Edge Functions to protect your forms. [View on GitHub](https://github.com/supabase/supabase/tree/master/examples/edge-functions/supabase/functions/cloudflare-turnstile).

## Setup [\#](https://supabase.com/docs/guides/functions/examples/cloudflare-turnstile\#setup)

- Follow these steps to set up a new site: [https://developers.cloudflare.com/turnstile/get-started/](https://developers.cloudflare.com/turnstile/get-started/)
- Add the Cloudflare Turnstile widget to your site: [https://developers.cloudflare.com/turnstile/get-started/client-side-rendering/](https://developers.cloudflare.com/turnstile/get-started/client-side-rendering/)

## Code [\#](https://supabase.com/docs/guides/functions/examples/cloudflare-turnstile\#code)

Create a new function in your project:

`
supabase functions new cloudflare-turnstile
`

And add the code to the `index.ts` file:

index.ts

`
import { corsHeaders } from '../_shared/cors.ts'
console.log('Hello from Cloudflare Trunstile!')
function ips(req: Request) {
return req.headers.get('x-forwarded-for')?.split(/\s*,\s*/)
}
Deno.serve(async (req) => {
// This is needed if you're planning to invoke your function from a browser.
if (req.method === 'OPTIONS') {
    return new Response('ok', { headers: corsHeaders })
}
const { token } = await req.json()
const clientIps = ips(req) || ['']
const ip = clientIps[0]
// Validate the token by calling the
// "/siteverify" API endpoint.
let formData = new FormData()
formData.append('secret', Deno.env.get('CLOUDFLARE_SECRET_KEY') ?? '')
formData.append('response', token)
formData.append('remoteip', ip)
const url = 'https://challenges.cloudflare.com/turnstile/v0/siteverify'
const result = await fetch(url, {
    body: formData,
    method: 'POST',
})
const outcome = await result.json()
console.log(outcome)
if (outcome.success) {
    return new Response('success', { headers: corsHeaders })
}
return new Response('failure', { headers: corsHeaders })
})
`

## Deploy the server-side validation Edge Functions [\#](https://supabase.com/docs/guides/functions/examples/cloudflare-turnstile\#deploy-the-server-side-validation-edge-functions)

- [https://developers.cloudflare.com/turnstile/get-started/server-side-validation/](https://developers.cloudflare.com/turnstile/get-started/server-side-validation/)

`
supabase functions deploy cloudflare-turnstile
supabase secrets set CLOUDFLARE_SECRET_KEY=your_secret_key
`

## Invoke the function from your site [\#](https://supabase.com/docs/guides/functions/examples/cloudflare-turnstile\#invoke-the-function-from-your-site)

`
const { data, error } = await supabase.functions.invoke('cloudflare-turnstile', {
body: { token },
})
`

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2FOwW0znboh60%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Setup](https://supabase.com/docs/guides/functions/examples/cloudflare-turnstile#setup) [Code](https://supabase.com/docs/guides/functions/examples/cloudflare-turnstile#code) [Deploy the server-side validation Edge Functions](https://supabase.com/docs/guides/functions/examples/cloudflare-turnstile#deploy-the-server-side-validation-edge-functions) [Invoke the function from your site](https://supabase.com/docs/guides/functions/examples/cloudflare-turnstile#invoke-the-function-from-your-site)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_examples_discord_bot.md">
Edge Functions

# Building a Discord Bot

* * *

Discord Bots with Edge Functions - YouTube

Supabase

45.5K subscribers

[Discord Bots with Edge Functions](https://www.youtube.com/watch?v=J24Bvo_m7DM)

Supabase

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=J24Bvo_m7DM "Watch on YouTube")

## Create an application on Discord Developer portal [\#](https://supabase.com/docs/guides/functions/examples/discord-bot\#create-an-application-on-discord-developer-portal)

1. Go to [https://discord.com/developers/applications](https://discord.com/developers/applications) (login using your discord account if required).
2. Click on **New Application** button available at left side of your profile picture.
3. Name your application and click on **Create**.
4. Go to **Bot** section, click on **Add Bot**, and finally on **Yes, do it!** to confirm.

A new application is created which will hold our Slash Command. Don't close the tab as we need information from this application page throughout our development.

Before we can write some code, we need to curl a discord endpoint to register a Slash Command in our app.

Fill `DISCORD_BOT_TOKEN` with the token available in the **Bot** section and `CLIENT_ID` with the ID available on the **General Information** section of the page and run the command on your terminal.

`
BOT_TOKEN='replace_me_with_bot_token'
CLIENT_ID='replace_me_with_client_id'
curl -X POST \
-H 'Content-Type: application/json' \
-H "Authorization: Bot $BOT_TOKEN" \
-d '{"name":"hello","description":"Greet a person","options":[{"name":"name","description":"The name of the person","type":3,"required":true}]}' \
"https://discord.com/api/v8/applications/$CLIENT_ID/commands"
`

This will register a Slash Command named `hello` that accepts a parameter named `name` of type string.

## Code [\#](https://supabase.com/docs/guides/functions/examples/discord-bot\#code)

index.ts

``
// Sift is a small routing library that abstracts away details like starting a
// listener on a port, and provides a simple function (serve) that has an API
// to invoke a function for a specific path.
import { json, serve, validateRequest } from 'https://deno.land/x/sift@0.6.0/mod.ts'
// TweetNaCl is a cryptography library that we use to verify requests
// from Discord.
import nacl from 'https://cdn.skypack.dev/tweetnacl@v1.0.3?dts'
enum DiscordCommandType {
Ping = 1,
ApplicationCommand = 2,
}
// For all requests to "/" endpoint, we want to invoke home() handler.
serve({
'/discord-bot': home,
})
// The main logic of the Discord Slash Command is defined in this function.
async function home(request: Request) {
// validateRequest() ensures that a request is of POST method and
// has the following headers.
const { error } = await validateRequest(request, {
    POST: {
      headers: ['X-Signature-Ed25519', 'X-Signature-Timestamp'],
    },
})
if (error) {
    return json({ error: error.message }, { status: error.status })
}
// verifySignature() verifies if the request is coming from Discord.
// When the request's signature is not valid, we return a 401 and this is
// important as Discord sends invalid requests to test our verification.
const { valid, body } = await verifySignature(request)
if (!valid) {
    return json(
      { error: 'Invalid request' },
      {
        status: 401,
      }
    )
}
const { type = 0, data = { options: [] } } = JSON.parse(body)
// Discord performs Ping interactions to test our application.
// Type 1 in a request implies a Ping interaction.
if (type === DiscordCommandType.Ping) {
    return json({
      type: 1, // Type 1 in a response is a Pong interaction response type.
    })
}
// Type 2 in a request is an ApplicationCommand interaction.
// It implies that a user has issued a command.
if (type === DiscordCommandType.ApplicationCommand) {
    const { value } = data.options.find(
      (option: { name: string; value: string }) => option.name === 'name'
    )
    return json({
      // Type 4 responds with the below message retaining the user's
      // input at the top.
      type: 4,
      data: {
        content: `Hello, ${value}!`,
      },
    })
}
// We will return a bad request error as a valid Discord request
// shouldn't reach here.
return json({ error: 'bad request' }, { status: 400 })
}
/** Verify whether the request is coming from Discord. */
async function verifySignature(request: Request): Promise<{ valid: boolean; body: string }> {
const PUBLIC_KEY = Deno.env.get('DISCORD_PUBLIC_KEY')!
// Discord sends these headers with every request.
const signature = request.headers.get('X-Signature-Ed25519')!
const timestamp = request.headers.get('X-Signature-Timestamp')!
const body = await request.text()
const valid = nacl.sign.detached.verify(
    new TextEncoder().encode(timestamp + body),
    hexToUint8Array(signature),
    hexToUint8Array(PUBLIC_KEY)
)
return { valid, body }
}
/** Converts a hexadecimal string to Uint8Array. */
function hexToUint8Array(hex: string) {
return new Uint8Array(hex.match(/.{1,2}/g)!.map((val) => parseInt(val, 16)))
}
``

## Deploy the slash command handler [\#](https://supabase.com/docs/guides/functions/examples/discord-bot\#deploy-the-slash-command-handler)

`
supabase functions deploy discord-bot --no-verify-jwt
supabase secrets set DISCORD_PUBLIC_KEY=your_public_key
`

Navigate to your Function details in the Supabase Dashboard to get your Endpoint URL.

### Configure Discord application to use our URL as interactions endpoint URL [\#](https://supabase.com/docs/guides/functions/examples/discord-bot\#configure-discord-application-to-use-our-url-as-interactions-endpoint-url)

1. Go back to your application (Greeter) page on Discord Developer Portal
2. Fill **INTERACTIONS ENDPOINT URL** field with the URL and click on **Save Changes**.

The application is now ready. Let's proceed to the next section to install it.

## Install the slash command on your Discord server [\#](https://supabase.com/docs/guides/functions/examples/discord-bot\#install-the-slash-command-on-your-discord-server)

So to use the `hello` Slash Command, we need to install our Greeter application on our Discord server. Here are the steps:

1. Go to **OAuth2** section of the Discord application page on Discord Developer Portal
2. Select `applications.commands` scope and click on the **Copy** button below.
3. Now paste and visit the URL on your browser. Select your server and click on **Authorize**.

Open Discord, type `/Promise` and press **Enter**.

## Run locally [\#](https://supabase.com/docs/guides/functions/examples/discord-bot\#run-locally)

`
supabase functions serve discord-bot --no-verify-jwt --env-file ./supabase/.env.local
ngrok http 54321
`

### Is this helpful?

NoYes

### On this page

[Create an application on Discord Developer portal](https://supabase.com/docs/guides/functions/examples/discord-bot#create-an-application-on-discord-developer-portal) [Code](https://supabase.com/docs/guides/functions/examples/discord-bot#code) [Deploy the slash command handler](https://supabase.com/docs/guides/functions/examples/discord-bot#deploy-the-slash-command-handler) [Configure Discord application to use our URL as interactions endpoint URL](https://supabase.com/docs/guides/functions/examples/discord-bot#configure-discord-application-to-use-our-url-as-interactions-endpoint-url) [Install the slash command on your Discord server](https://supabase.com/docs/guides/functions/examples/discord-bot#install-the-slash-command-on-your-discord-server) [Run locally](https://supabase.com/docs/guides/functions/examples/discord-bot#run-locally)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_examples_elevenlabs_generate_speech_stream.md">
Edge Functions

# Streaming Speech with ElevenLabs

## Generate and stream speech through Supabase Edge Functions. Store speech in Supabase Storage and cache responses via built-in CDN.

* * *

## Introduction [\#](https://supabase.com/docs/guides/functions/examples/elevenlabs-generate-speech-stream\#introduction)

In this tutorial you will learn how to build an edge API to generate, stream, store, and cache speech using Supabase Edge Functions, Supabase Storage, and [ElevenLabs text to speech API](https://elevenlabs.io/text-to-speech).

Find the [example project on\\
GitHub](https://github.com/elevenlabs/elevenlabs-examples/tree/main/examples/text-to-speech/supabase/stream-and-cache-storage).

## Requirements [\#](https://supabase.com/docs/guides/functions/examples/elevenlabs-generate-speech-stream\#requirements)

- An ElevenLabs account with an [API key](https://supabase.com/app/settings/api-keys).
- A [Supabase](https://supabase.com/) account (you can sign up for a free account via [database.new](https://database.new/)).
- The [Supabase CLI](https://supabase.com/docs/guides/local-development) installed on your machine.
- The [Deno runtime](https://docs.deno.com/runtime/getting_started/installation/) installed on your machine and optionally [setup in your favourite IDE](https://docs.deno.com/runtime/getting_started/setup_your_environment).

## Setup [\#](https://supabase.com/docs/guides/functions/examples/elevenlabs-generate-speech-stream\#setup)

### Create a Supabase project locally [\#](https://supabase.com/docs/guides/functions/examples/elevenlabs-generate-speech-stream\#create-a-supabase-project-locally)

After installing the [Supabase CLI](https://supabase.com/docs/guides/local-development), run the following command to create a new Supabase project locally:

`
supabase init
`

### Configure the storage bucket [\#](https://supabase.com/docs/guides/functions/examples/elevenlabs-generate-speech-stream\#configure-the-storage-bucket)

You can configure the Supabase CLI to automatically generate a storage bucket by adding this configuration in the `config.toml` file:

./supabase/config.toml

`
[storage.buckets.audio]
public = false
file_size_limit = "50MiB"
allowed_mime_types = ["audio/mp3"]
objects_path = "./audio"
`

Upon running `supabase start` this will create a new storage bucket in your local Supabase
project. Should you want to push this to your hosted Supabase project, you can run `supabase seed     buckets --linked`.

### Configure background tasks for Supabase Edge Functions [\#](https://supabase.com/docs/guides/functions/examples/elevenlabs-generate-speech-stream\#configure-background-tasks-for-supabase-edge-functions)

To use background tasks in Supabase Edge Functions when developing locally, you need to add the following configuration in the `config.toml` file:

./supabase/config.toml

`
[edge_runtime]
policy = "per_worker"
`

When running with `per_worker` policy, Function won't auto-reload on edits. You will need to
manually restart it by running `supabase functions serve`.

### Create a Supabase Edge Function for speech generation [\#](https://supabase.com/docs/guides/functions/examples/elevenlabs-generate-speech-stream\#create-a-supabase-edge-function-for-speech-generation)

Create a new Edge Function by running the following command:

`
supabase functions new text-to-speech
`

If you're using VS Code or Cursor, select `y` when the CLI prompts "Generate VS Code settings for Deno? \[y/N\]"!

### Set up the environment variables [\#](https://supabase.com/docs/guides/functions/examples/elevenlabs-generate-speech-stream\#set-up-the-environment-variables)

Within the `supabase/functions` directory, create a new `.env` file and add the following variables:

supabase/functions/.env

`
# Find / create an API key at https://elevenlabs.io/app/settings/api-keys
ELEVENLABS_API_KEY=your_api_key
`

### Dependencies [\#](https://supabase.com/docs/guides/functions/examples/elevenlabs-generate-speech-stream\#dependencies)

The project uses a couple of dependencies:

- The [@supabase/supabase-js](https://supabase.com/docs/reference/javascript) library to interact with the Supabase database.
- The ElevenLabs [JavaScript SDK](https://supabase.com/docs/quickstart) to interact with the text-to-speech API.
- The open-source [object-hash](https://www.npmjs.com/package/object-hash) to generate a hash from the request parameters.

Since Supabase Edge Function uses the [Deno runtime](https://deno.land/), you don't need to install the dependencies, rather you can [import](https://docs.deno.com/examples/npm/) them via the `npm:` prefix.

## Code the Supabase Edge Function [\#](https://supabase.com/docs/guides/functions/examples/elevenlabs-generate-speech-stream\#code-the-supabase-edge-function)

In your newly created `supabase/functions/text-to-speech/index.ts` file, add the following code:

supabase/functions/text-to-speech/index.ts

``
// Setup type definitions for built-in Supabase Runtime APIs
import 'jsr:@supabase/functions-js/edge-runtime.d.ts'
import { createClient } from 'jsr:@supabase/supabase-js@2'
import { ElevenLabsClient } from 'npm:elevenlabs@1.52.0'
import * as hash from 'npm:object-hash'
const supabase = createClient(
Deno.env.get('SUPABASE_URL')!,
Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!
)
const client = new ElevenLabsClient({
apiKey: Deno.env.get('ELEVENLABS_API_KEY'),
})
// Upload audio to Supabase Storage in a background task
async function uploadAudioToStorage(stream: ReadableStream, requestHash: string) {
const { data, error } = await supabase.storage
    .from('audio')
    .upload(`${requestHash}.mp3`, stream, {
      contentType: 'audio/mp3',
    })
console.log('Storage upload result', { data, error })
}
Deno.serve(async (req) => {
// To secure your function for production, you can for example validate the request origin,
// or append a user access token and validate it with Supabase Auth.
console.log('Request origin', req.headers.get('host'))
const url = new URL(req.url)
const params = new URLSearchParams(url.search)
const text = params.get('text')
const voiceId = params.get('voiceId') ?? 'JBFqnCBsd6RMkjVDRZzb'
const requestHash = hash.MD5({ text, voiceId })
console.log('Request hash', requestHash)
// Check storage for existing audio file
const { data } = await supabase.storage.from('audio').createSignedUrl(`${requestHash}.mp3`, 60)
if (data) {
    console.log('Audio file found in storage', data)
    const storageRes = await fetch(data.signedUrl)
    if (storageRes.ok) return storageRes
}
if (!text) {
    return new Response(JSON.stringify({ error: 'Text parameter is required' }), {
      status: 400,
      headers: { 'Content-Type': 'application/json' },
    })
}
try {
    console.log('ElevenLabs API call')
    const response = await client.textToSpeech.convertAsStream(voiceId, {
      output_format: 'mp3_44100_128',
      model_id: 'eleven_multilingual_v2',
      text,
    })
    const stream = new ReadableStream({
      async start(controller) {
        for await (const chunk of response) {
          controller.enqueue(chunk)
        }
        controller.close()
      },
    })
    // Branch stream to Supabase Storage
    const [browserStream, storageStream] = stream.tee()
    // Upload to Supabase Storage in the background
    EdgeRuntime.waitUntil(uploadAudioToStorage(storageStream, requestHash))
    // Return the streaming response immediately
    return new Response(browserStream, {
      headers: {
        'Content-Type': 'audio/mpeg',
      },
    })
} catch (error) {
    console.log('error', { error })
    return new Response(JSON.stringify({ error: error.message }), {
      status: 500,
      headers: { 'Content-Type': 'application/json' },
    })
}
})
``

## Run locally [\#](https://supabase.com/docs/guides/functions/examples/elevenlabs-generate-speech-stream\#run-locally)

To run the function locally, run the following commands:

`
supabase start
`

Once the local Supabase stack is up and running, run the following command to start the function and observe the logs:

`
supabase functions serve
`

### Try it out [\#](https://supabase.com/docs/guides/functions/examples/elevenlabs-generate-speech-stream\#try-it-out)

Navigate to `http://127.0.0.1:54321/functions/v1/text-to-speech?text=hello%20world` to hear the function in action.

Afterwards, navigate to `http://127.0.0.1:54323/project/default/storage/buckets/audio` to see the audio file in your local Supabase Storage bucket.

## Deploy to Supabase [\#](https://supabase.com/docs/guides/functions/examples/elevenlabs-generate-speech-stream\#deploy-to-supabase)

If you haven't already, create a new Supabase account at [database.new](https://database.new/) and link the local project to your Supabase account:

`
supabase link
`

Once done, run the following command to deploy the function:

`
supabase functions deploy
`

### Set the function secrets [\#](https://supabase.com/docs/guides/functions/examples/elevenlabs-generate-speech-stream\#set-the-function-secrets)

Now that you have all your secrets set locally, you can run the following command to set the secrets in your Supabase project:

`
supabase secrets set --env-file supabase/functions/.env
`

## Test the function [\#](https://supabase.com/docs/guides/functions/examples/elevenlabs-generate-speech-stream\#test-the-function)

The function is designed in a way that it can be used directly as a source for an `<audio>` element.

`
<audio
src="https://${SUPABASE_PROJECT_REF}.supabase.co/functions/v1/text-to-speech?text=Hello%2C%20world!&voiceId=JBFqnCBsd6RMkjVDRZzb"
controls
/>
`

You can find an example frontend implementation in the complete code example on [GitHub](https://github.com/elevenlabs/elevenlabs-examples/tree/main/examples/text-to-speech/supabase/stream-and-cache-storage/src/pages/Index.tsx).

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2F4Roog4PAmZ8%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Introduction](https://supabase.com/docs/guides/functions/examples/elevenlabs-generate-speech-stream#introduction) [Requirements](https://supabase.com/docs/guides/functions/examples/elevenlabs-generate-speech-stream#requirements) [Setup](https://supabase.com/docs/guides/functions/examples/elevenlabs-generate-speech-stream#setup) [Create a Supabase project locally](https://supabase.com/docs/guides/functions/examples/elevenlabs-generate-speech-stream#create-a-supabase-project-locally) [Configure the storage bucket](https://supabase.com/docs/guides/functions/examples/elevenlabs-generate-speech-stream#configure-the-storage-bucket) [Configure background tasks for Supabase Edge Functions](https://supabase.com/docs/guides/functions/examples/elevenlabs-generate-speech-stream#configure-background-tasks-for-supabase-edge-functions) [Create a Supabase Edge Function for speech generation](https://supabase.com/docs/guides/functions/examples/elevenlabs-generate-speech-stream#create-a-supabase-edge-function-for-speech-generation) [Set up the environment variables](https://supabase.com/docs/guides/functions/examples/elevenlabs-generate-speech-stream#set-up-the-environment-variables) [Dependencies](https://supabase.com/docs/guides/functions/examples/elevenlabs-generate-speech-stream#dependencies) [Code the Supabase Edge Function](https://supabase.com/docs/guides/functions/examples/elevenlabs-generate-speech-stream#code-the-supabase-edge-function) [Run locally](https://supabase.com/docs/guides/functions/examples/elevenlabs-generate-speech-stream#run-locally) [Try it out](https://supabase.com/docs/guides/functions/examples/elevenlabs-generate-speech-stream#try-it-out) [Deploy to Supabase](https://supabase.com/docs/guides/functions/examples/elevenlabs-generate-speech-stream#deploy-to-supabase) [Set the function secrets](https://supabase.com/docs/guides/functions/examples/elevenlabs-generate-speech-stream#set-the-function-secrets) [Test the function](https://supabase.com/docs/guides/functions/examples/elevenlabs-generate-speech-stream#test-the-function)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_examples_elevenlabs_transcribe_speech.md">
Edge Functions

# Transcription Telegram Bot

## Build a Telegram bot that transcribes audio and video messages in 99 languages using TypeScript with Deno in Supabase Edge Functions.

* * *

## Introduction [\#](https://supabase.com/docs/guides/functions/examples/elevenlabs-transcribe-speech\#introduction)

In this tutorial you will learn how to build a Telegram bot that transcribes audio and video messages in 99 languages using TypeScript and the ElevenLabs Scribe model via the [speech to text API](https://elevenlabs.io/speech-to-text).

To check out what the end result will look like, you can test out the [t.me/ElevenLabsScribeBot](https://t.me/ElevenLabsScribeBot)

Find the [example project on\\
GitHub](https://github.com/elevenlabs/elevenlabs-examples/tree/main/examples/speech-to-text/telegram-transcription-bot).

## Requirements [\#](https://supabase.com/docs/guides/functions/examples/elevenlabs-transcribe-speech\#requirements)

- An ElevenLabs account with an [API key](https://supabase.com/app/settings/api-keys).
- A [Supabase](https://supabase.com/) account (you can sign up for a free account via [database.new](https://database.new/)).
- The [Supabase CLI](https://supabase.com/docs/guides/local-development) installed on your machine.
- The [Deno runtime](https://docs.deno.com/runtime/getting_started/installation/) installed on your machine and optionally [setup in your favourite IDE](https://docs.deno.com/runtime/getting_started/setup_your_environment).
- A [Telegram](https://telegram.org/) account.

## Setup [\#](https://supabase.com/docs/guides/functions/examples/elevenlabs-transcribe-speech\#setup)

### Register a Telegram bot [\#](https://supabase.com/docs/guides/functions/examples/elevenlabs-transcribe-speech\#register-a-telegram-bot)

Use the [BotFather](https://t.me/BotFather) to create a new Telegram bot. Run the `/newbot` command and follow the instructions to create a new bot. At the end, you will receive your secret bot token. Note it down securely for the next step.

![BotFather](https://supabase.com/docs/img/guides/functions/elevenlabs/bot-father.png)

### Create a Supabase project locally [\#](https://supabase.com/docs/guides/functions/examples/elevenlabs-transcribe-speech\#create-a-supabase-project-locally)

After installing the [Supabase CLI](https://supabase.com/docs/guides/local-development), run the following command to create a new Supabase project locally:

`
supabase init
`

### Create a database table to log the transcription results [\#](https://supabase.com/docs/guides/functions/examples/elevenlabs-transcribe-speech\#create-a-database-table-to-log-the-transcription-results)

Next, create a new database table to log the transcription results:

`
supabase migrations new init
`

This will create a new migration file in the `supabase/migrations` directory. Open the file and add the following SQL:

supabase/migrations/init.sql

`
CREATE TABLE IF NOT EXISTS transcription_logs (
id BIGSERIAL PRIMARY KEY,
file_type VARCHAR NOT NULL,
duration INTEGER NOT NULL,
chat_id BIGINT NOT NULL,
message_id BIGINT NOT NULL,
username VARCHAR,
transcript TEXT,
language_code VARCHAR,
created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
error TEXT
);
ALTER TABLE transcription_logs ENABLE ROW LEVEL SECURITY;
`

### Create a Supabase Edge Function to handle Telegram webhook requests [\#](https://supabase.com/docs/guides/functions/examples/elevenlabs-transcribe-speech\#create-a-supabase-edge-function-to-handle-telegram-webhook-requests)

Next, create a new Edge Function to handle Telegram webhook requests:

`
supabase functions new scribe-bot
`

If you're using VS Code or Cursor, select `y` when the CLI prompts "Generate VS Code settings for Deno? \[y/N\]"!

### Set up the environment variables [\#](https://supabase.com/docs/guides/functions/examples/elevenlabs-transcribe-speech\#set-up-the-environment-variables)

Within the `supabase/functions` directory, create a new `.env` file and add the following variables:

supabase/functions/.env

`
# Find / create an API key at https://elevenlabs.io/app/settings/api-keys
ELEVENLABS_API_KEY=your_api_key
# The bot token you received from the BotFather.
TELEGRAM_BOT_TOKEN=your_bot_token
# A random secret chosen by you to secure the function.
FUNCTION_SECRET=random_secret
`

### Dependencies [\#](https://supabase.com/docs/guides/functions/examples/elevenlabs-transcribe-speech\#dependencies)

The project uses a couple of dependencies:

- The open-source [grammY Framework](https://grammy.dev/) to handle the Telegram webhook requests.
- The [@supabase/supabase-js](https://supabase.com/docs/reference/javascript) library to interact with the Supabase database.
- The ElevenLabs [JavaScript SDK](https://supabase.com/docs/quickstart) to interact with the speech-to-text API.

Since Supabase Edge Function uses the [Deno runtime](https://deno.land/), you don't need to install the dependencies, rather you can [import](https://docs.deno.com/examples/npm/) them via the `npm:` prefix.

## Code the Telegram bot [\#](https://supabase.com/docs/guides/functions/examples/elevenlabs-transcribe-speech\#code-the-telegram-bot)

In your newly created `scribe-bot/index.ts` file, add the following code:

supabase/functions/scribe-bot/index.ts

``
import { Bot, webhookCallback } from 'https://deno.land/x/grammy@v1.34.0/mod.ts'
import 'jsr:@supabase/functions-js/edge-runtime.d.ts'
import { createClient } from 'jsr:@supabase/supabase-js@2'
import { ElevenLabsClient } from 'npm:elevenlabs@1.50.5'
console.log(`Function "elevenlabs-scribe-bot" up and running!`)
const elevenLabsClient = new ElevenLabsClient({
apiKey: Deno.env.get('ELEVENLABS_API_KEY') || '',
})
const supabase = createClient(
Deno.env.get('SUPABASE_URL') || '',
Deno.env.get('SUPABASE_SERVICE_ROLE_KEY') || ''
)
async function scribe({
fileURL,
fileType,
duration,
chatId,
messageId,
username,
}: {
fileURL: string
fileType: string
duration: number
chatId: number
messageId: number
username: string
}) {
let transcript: string | null = null
let languageCode: string | null = null
let errorMsg: string | null = null
try {
    const sourceFileArrayBuffer = await fetch(fileURL).then((res) => res.arrayBuffer())
    const sourceBlob = new Blob([sourceFileArrayBuffer], {
      type: fileType,
    })
    const scribeResult = await elevenLabsClient.speechToText.convert({
      file: sourceBlob,
      model_id: 'scribe_v1',
      tag_audio_events: false,
    })
    transcript = scribeResult.text
    languageCode = scribeResult.language_code
    // Reply to the user with the transcript
    await bot.api.sendMessage(chatId, transcript, {
      reply_parameters: { message_id: messageId },
    })
} catch (error) {
    errorMsg = error.message
    console.log(errorMsg)
    await bot.api.sendMessage(chatId, 'Sorry, there was an error. Please try again.', {
      reply_parameters: { message_id: messageId },
    })
}
// Write log to Supabase.
const logLine = {
    file_type: fileType,
    duration,
    chat_id: chatId,
    message_id: messageId,
    username,
    language_code: languageCode,
    error: errorMsg,
}
console.log({ logLine })
await supabase.from('transcription_logs').insert({ ...logLine, transcript })
}
const telegramBotToken = Deno.env.get('TELEGRAM_BOT_TOKEN')
const bot = new Bot(telegramBotToken || '')
const startMessage = `Welcome to the ElevenLabs Scribe Bot\\! I can transcribe speech in 99 languages with super high accuracy\\!
    \nTry it out by sending or forwarding me a voice message, video, or audio file\\!
    \n[Learn more about Scribe](https://elevenlabs.io/speech-to-text) or [build your own bot](https://elevenlabs.io/docs/cookbooks/speech-to-text/telegram-bot)\\!
`
bot.command('start', (ctx) => ctx.reply(startMessage.trim(), { parse_mode: 'MarkdownV2' }))
bot.on([':voice', ':audio', ':video'], async (ctx) => {
try {
    const file = await ctx.getFile()
    const fileURL = `https://api.telegram.org/file/bot${telegramBotToken}/${file.file_path}`
    const fileMeta = ctx.message?.video ?? ctx.message?.voice ?? ctx.message?.audio
    if (!fileMeta) {
      return ctx.reply('No video|audio|voice metadata found. Please try again.')
    }
    // Run the transcription in the background.
    EdgeRuntime.waitUntil(
      scribe({
        fileURL,
        fileType: fileMeta.mime_type!,
        duration: fileMeta.duration,
        chatId: ctx.chat.id,
        messageId: ctx.message?.message_id!,
        username: ctx.from?.username || '',
      })
    )
    // Reply to the user immediately to let them know we received their file.
    return ctx.reply('Received. Scribing...')
} catch (error) {
    console.error(error)
    return ctx.reply(
      'Sorry, there was an error getting the file. Please try again with a smaller file!'
    )
}
})
const handleUpdate = webhookCallback(bot, 'std/http')
Deno.serve(async (req) => {
try {
    const url = new URL(req.url)
    if (url.searchParams.get('secret') !== Deno.env.get('FUNCTION_SECRET')) {
      return new Response('not allowed', { status: 405 })
    }
    return await handleUpdate(req)
} catch (err) {
    console.error(err)
}
})
``

## Deploy to Supabase [\#](https://supabase.com/docs/guides/functions/examples/elevenlabs-transcribe-speech\#deploy-to-supabase)

If you haven't already, create a new Supabase account at [database.new](https://database.new/) and link the local project to your Supabase account:

`
supabase link
`

### Apply the database migrations [\#](https://supabase.com/docs/guides/functions/examples/elevenlabs-transcribe-speech\#apply-the-database-migrations)

Run the following command to apply the database migrations from the `supabase/migrations` directory:

`
supabase db push
`

Navigate to the [table editor](https://supabase.com/dashboard/project/_/editor) in your Supabase dashboard and you should see and empty `transcription_logs` table.

![Empty table](https://supabase.com/docs/img/guides/functions/elevenlabs/supa-empty-table.png)

Lastly, run the following command to deploy the Edge Function:

`
supabase functions deploy --no-verify-jwt scribe-bot
`

Navigate to the [Edge Functions view](https://supabase.com/dashboard/project/_/functions) in your Supabase dashboard and you should see the `scribe-bot` function deployed. Make a note of the function URL as you'll need it later, it should look something like `https://<project-ref>.functions.supabase.co/scribe-bot`.

![Edge Function deployed](https://supabase.com/docs/img/guides/functions/elevenlabs/supa-edge-function-deployed.png)

### Set up the webhook [\#](https://supabase.com/docs/guides/functions/examples/elevenlabs-transcribe-speech\#set-up-the-webhook)

Set your bot's webhook URL to `https://<PROJECT_REFERENCE>.functions.supabase.co/telegram-bot` (Replacing `<...>` with respective values). In order to do that, run a GET request to the following URL (in your browser, for example):

`
https://api.telegram.org/bot<TELEGRAM_BOT_TOKEN>/setWebhook?url=https://<PROJECT_REFERENCE>.supabase.co/functions/v1/scribe-bot?secret=<FUNCTION_SECRET>
`

Note that the `FUNCTION_SECRET` is the secret you set in your `.env` file.

![Set webhook](https://supabase.com/docs/img/guides/functions/elevenlabs/set-webhook.png)

### Set the function secrets [\#](https://supabase.com/docs/guides/functions/examples/elevenlabs-transcribe-speech\#set-the-function-secrets)

Now that you have all your secrets set locally, you can run the following command to set the secrets in your Supabase project:

`
supabase secrets set --env-file supabase/functions/.env
`

## Test the bot [\#](https://supabase.com/docs/guides/functions/examples/elevenlabs-transcribe-speech\#test-the-bot)

Finally you can test the bot by sending it a voice message, audio or video file.

![Test the bot](https://supabase.com/docs/img/guides/functions/elevenlabs/test-bot.png)

After you see the transcript as a reply, navigate back to your table editor in the Supabase dashboard and you should see a new row in your `transcription_logs` table.

![New row in table](https://supabase.com/docs/img/guides/functions/elevenlabs/supa-new-row.png)

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2FCE4iPp7kd7Q%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Introduction](https://supabase.com/docs/guides/functions/examples/elevenlabs-transcribe-speech#introduction) [Requirements](https://supabase.com/docs/guides/functions/examples/elevenlabs-transcribe-speech#requirements) [Setup](https://supabase.com/docs/guides/functions/examples/elevenlabs-transcribe-speech#setup) [Register a Telegram bot](https://supabase.com/docs/guides/functions/examples/elevenlabs-transcribe-speech#register-a-telegram-bot) [Create a Supabase project locally](https://supabase.com/docs/guides/functions/examples/elevenlabs-transcribe-speech#create-a-supabase-project-locally) [Create a database table to log the transcription results](https://supabase.com/docs/guides/functions/examples/elevenlabs-transcribe-speech#create-a-database-table-to-log-the-transcription-results) [Create a Supabase Edge Function to handle Telegram webhook requests](https://supabase.com/docs/guides/functions/examples/elevenlabs-transcribe-speech#create-a-supabase-edge-function-to-handle-telegram-webhook-requests) [Set up the environment variables](https://supabase.com/docs/guides/functions/examples/elevenlabs-transcribe-speech#set-up-the-environment-variables) [Dependencies](https://supabase.com/docs/guides/functions/examples/elevenlabs-transcribe-speech#dependencies) [Code the Telegram bot](https://supabase.com/docs/guides/functions/examples/elevenlabs-transcribe-speech#code-the-telegram-bot) [Deploy to Supabase](https://supabase.com/docs/guides/functions/examples/elevenlabs-transcribe-speech#deploy-to-supabase) [Apply the database migrations](https://supabase.com/docs/guides/functions/examples/elevenlabs-transcribe-speech#apply-the-database-migrations) [Set up the webhook](https://supabase.com/docs/guides/functions/examples/elevenlabs-transcribe-speech#set-up-the-webhook) [Set the function secrets](https://supabase.com/docs/guides/functions/examples/elevenlabs-transcribe-speech#set-the-function-secrets) [Test the bot](https://supabase.com/docs/guides/functions/examples/elevenlabs-transcribe-speech#test-the-bot)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_examples_github_actions.md">
Edge Functions

# GitHub Actions

* * *

Deploying Edge Functions with GitHub Actions - YouTube

Supabase

45.5K subscribers

[Deploying Edge Functions with GitHub Actions](https://www.youtube.com/watch?v=l2KlzGrhB6w)

Supabase

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=l2KlzGrhB6w "Watch on YouTube")

Use the Supabase CLI together with GitHub Actions to automatically deploy our Supabase Edge Functions. [View on GitHub](https://github.com/supabase/supabase/tree/master/examples/edge-functions/supabase/functions/github-action-deploy).

deploy.yaml

`
name: Deploy Function
on:
push:
    branches:
      - main
workflow_dispatch:
jobs:
deploy:
    runs-on: ubuntu-latest
    env:
      SUPABASE_ACCESS_TOKEN: YOUR_SUPABASE_ACCESS_TOKEN
      PROJECT_ID: YOUR_SUPABASE_PROJECT_ID
    steps:
      - uses: actions/checkout@v4
      - uses: supabase/setup-cli@v1
        with:
          version: latest
      - run: supabase functions deploy --project-ref $PROJECT_ID
`

Since Supabase CLI [v1.62.0](https://github.com/supabase/cli/releases/tag/v1.62.0) you can deploy all functions with a single command.

Individual function configuration like [JWT verification](https://supabase.com/docs/guides/cli/config#functions.function_name.verify_jwt) and [import map location](https://supabase.com/docs/guides/cli/config#functions.function_name.import_map) can be set via the `config.toml` file.

`
[functions.hello-world]
verify_jwt = false
`

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_examples_image_manipulation.md">
Edge Functions

# Image Manipulation

* * *

Supabase Storage has [out-of-the-box support](https://supabase.com/docs/guides/storage/serving/image-transformations?queryGroups=language&language=js) for the most common image transformations and optimizations you need.
If you need to do anything custom beyond what Supabase Storage provides, you can use Edge Functions to write custom image manipulation scripts.

In this example, we will use [`magick-wasm`](https://github.com/dlemstra/magick-wasm) to perform image manipulations. `magick-wasm` is the WebAssembly port of the popular ImageMagick library and supports processing over 100 file formats.

Edge Functions currently doesn't support image processing libraries such as `Sharp`, which depend on native libraries. Only WASM-based libraries are supported.

### Prerequisites [\#](https://supabase.com/docs/guides/functions/examples/image-manipulation\#prerequisites)

Make sure you have the latest version of the[Supabase CLI](https://supabase.com/docs/guides/cli#installation)installed.

### Create the Edge Function [\#](https://supabase.com/docs/guides/functions/examples/image-manipulation\#create-the-edge-function)

Create a new function locally:

`
supabase functions new image-blur
`

### Write the function [\#](https://supabase.com/docs/guides/functions/examples/image-manipulation\#write-the-function)

In this example, we are implementing a function allowing users to upload an image and get a blurred thumbnail.

Here's theimplementation in `index.ts`file:

`
// This is an example showing how to use Magick WASM to do image manipulations in Edge Functions.
//
import {
ImageMagick,
initializeImageMagick,
MagickFormat,
} from "npm:@imagemagick/magick-wasm@0.0.30";
const wasmBytes = await Deno.readFile(
new URL(
    "magick.wasm",
    import.meta.resolve("npm:@imagemagick/magick-wasm@0.0.30"),
),
);
await initializeImageMagick(
wasmBytes,
);
Deno.serve(async (req) => {
const formData = await req.formData();
const content = await formData.get("file").bytes();
let result = ImageMagick.read(
    content,
    (img): Uint8Array => {
      // resize the image
      img.resize(500, 300);
      // add a blur of 60x5
      img.blur(60, 5);
      return img.write(
        (data) => data,
      );
    },
);
return new Response(
    result,
    { headers: { "Content-Type": "image/png" } },
);
});
`

[View source](https://github.com/supabase/supabase/blob/9b9cf69c7e6cf3b275a7f324e7556b2960368e3f/examples/edge-functions/supabase/functions/image-manipulation/index.ts)

### Test it locally [\#](https://supabase.com/docs/guides/functions/examples/image-manipulation\#test-it-locally)

You can test the function locally by running:

`
supabase start
supabase functions serve --no-verify-jwt
`

Then, make a request using `curl` or your favorite API testing tool.

`
curl --location '<http://localhost:54321/functions/v1/image-blur>' \\
--form 'file=@"/path/to/image.png"'
--output '/path/to/output.png'
`

If you open the `output.png` file you will find a transformed version of your original image.

### Deploy to your hosted project [\#](https://supabase.com/docs/guides/functions/examples/image-manipulation\#deploy-to-your-hosted-project)

Now, let's deploy the function to your Supabase project.

`
supabase link
supabase functions deploy image-blur
`

Hosted Edge Functions have [limits](https://supabase.com/docs/guides/functions/limits) on memory and CPU usage.

If you try to perform complex image processing or handle large images (> 5MB) your function may return a resource limit exceeded error.

### Is this helpful?

NoYes

### On this page

[Prerequisites](https://supabase.com/docs/guides/functions/examples/image-manipulation#prerequisites) [Create the Edge Function](https://supabase.com/docs/guides/functions/examples/image-manipulation#create-the-edge-function) [Write the function](https://supabase.com/docs/guides/functions/examples/image-manipulation#write-the-function) [Test it locally](https://supabase.com/docs/guides/functions/examples/image-manipulation#test-it-locally) [Deploy to your hosted project](https://supabase.com/docs/guides/functions/examples/image-manipulation#deploy-to-your-hosted-project)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_examples_og_image.md">
Edge Functions

# Generating OG Images

* * *

Generating OG Images with Edge Functions - YouTube

Supabase

45.5K subscribers

[Generating OG Images with Edge Functions](https://www.youtube.com/watch?v=jZgyOJGWayQ)

Supabase

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=jZgyOJGWayQ "Watch on YouTube")

Generate Open Graph images with Deno and Supabase Edge Functions. [View on GitHub](https://github.com/supabase/supabase/tree/master/examples/edge-functions/supabase/functions/opengraph).

## Code [\#](https://supabase.com/docs/guides/functions/examples/og-image\#code)

Create a `handler.tsx` file to construct the OG image in React:

handler.tsx

`
import React from 'https://esm.sh/react@18.2.0'
import { ImageResponse } from 'https://deno.land/x/og_edge@0.0.4/mod.ts'
export default function handler(req: Request) {
return new ImageResponse(
    (
      <div
        style={{
          width: '100%',
          height: '100%',
          display: 'flex',
          alignItems: 'center',
          justifyContent: 'center',
          fontSize: 128,
          background: 'lavender',
        }}
      >
        Hello OG Image!
      </div>
    )
)
}
`

Create an `index.ts` file to execute the handler on incoming requests:

index.ts

`
import handler from './handler.tsx'
console.log('Hello from og-image Function!')
Deno.serve(handler)
`

### Is this helpful?

NoYes

### On this page

[Code](https://supabase.com/docs/guides/functions/examples/og-image#code)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_examples_push_notifications.md">
Edge Functions

# Sending Push Notifications

* * *

Push notifications are an important part of any mobile app. They allow you to send notifications to your users even when they are not using your app. This guide will show you how to send push notifications to different mobile app frameworks from your Supabase edge functions.

Expo Push NotificationsFirebase Cloud Messaging

[Expo](https://docs.expo.dev/push-notifications/overview/) makes implementing push notifications easy. All the hassle with device information and communicating with Firebase Cloud Messaging (FCM) or Apple Push Notification Service (APNs) is done behind the scenes. This allows you to treat Android and iOS notifications in the same way and save time both on the frontend and backend.

Find the example code on [GitHub](https://github.com/supabase/supabase/blob/master/examples/user-management/expo-push-notifications/).

## Supabase setup [\#](https://supabase.com/docs/guides/functions/examples/push-notifications\#supabase-setup)

- [Create a new Supabase project](https://database.new/).
- Link your project: `supabase link --project-ref your-supabase-project-ref`
- Start Supabase locally: `supabase start`
- Push up the schema: `supabase db push` (schema is defined in [supabase/migrations](https://github.com/supabase/supabase/blob/master/examples/user-management/expo-push-notifications/supabase/migrations/))

## Expo setup [\#](https://supabase.com/docs/guides/functions/examples/push-notifications\#expo-setup)

To utilize Expo's push notification service, you must configure your app by installing a set of libraries, implementing functions to handle notifications, and setting up credentials for Android and iOS. Follow the official [Expo Push Notifications Setup Guide](https://docs.expo.dev/push-notifications/push-notifications-setup/) to get the credentials for Android and iOS. This project uses [Expo's EAS build](https://docs.expo.dev/build/introduction/) service to simplify this part.

1. Install the dependencies: `npm i`
2. Create a [new Expo project](https://expo.dev/accounts/_/projects)
3. Link this app to your project: `npm install --global eas-cli && eas init --id your-expo-project-id`
4. [Create a build for your physical device](https://docs.expo.dev/develop/development-builds/create-a-build/#create-a-build-for-the-device)
5. Start the development server for your project: `npx expo start --dev-client`
6. Scan the QR code shown in the terminal with your physical device.
7. Sign up/in to create a user in Supabase Auth.

## Enhanced security for push notifications [\#](https://supabase.com/docs/guides/functions/examples/push-notifications\#enhanced-security-for-push-notifications)

1. Navigate to your [Expo Access Token Settings](https://expo.dev/accounts/_/settings/access-tokens).
2. Create a new token for usage in Supabase Edge Functions.
3. Toggle on "Enhanced Security for Push Notifications".
4. Create the local `.env` file: `cp .env.local.example .env.local`
5. In the newly created `.env.local` file, set your `EXPO_ACCESS_TOKEN` value.

## Deploy the Supabase Edge Function [\#](https://supabase.com/docs/guides/functions/examples/push-notifications\#deploy-the-supabase-edge-function)

The database webhook handler to send push notifications is located in [supabase/functions/push/index.ts](https://github.com/supabase/supabase/blob/master/examples/user-management/expo-push-notifications/supabase/functions/push/index.ts). Deploy the function to your linked project and set the `EXPO_ACCESS_TOKEN` secret.

1. `supabase functions deploy push`
2. `supabase secrets set --env-file .env.local`

supabase/functions/push/index.ts

``
import { createClient } from 'jsr:@supabase/supabase-js@2'
console.log('Hello from Functions!')
interface Notification {
id: string
user_id: string
body: string
}
interface WebhookPayload {
type: 'INSERT' | 'UPDATE' | 'DELETE'
table: string
record: Notification
schema: 'public'
old_record: null | Notification
}
const supabase = createClient(
Deno.env.get('SUPABASE_URL')!,
Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!
)
Deno.serve(async (req) => {
const payload: WebhookPayload = await req.json()
const { data } = await supabase
    .from('profiles')
    .select('expo_push_token')
    .eq('id', payload.record.user_id)
    .single()
const res = await fetch('https://exp.host/--/api/v2/push/send', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      Authorization: `Bearer ${Deno.env.get('EXPO_ACCESS_TOKEN')}`,
    },
    body: JSON.stringify({
      to: data?.expo_push_token,
      sound: 'default',
      body: payload.record.body,
    }),
}).then((res) => res.json())
return new Response(JSON.stringify(res), {
    headers: { 'Content-Type': 'application/json' },
})
})
``

## Create the database webhook [\#](https://supabase.com/docs/guides/functions/examples/push-notifications\#create-the-database-webhook)

Navigate to the [Database Webhooks settings](https://supabase.com/dashboard/project/_/database/hooks) in your Supabase Dashboard.

1. Enable and create a new hook.
2. Conditions to fire webhook: Select the `notifications` table and tick the `Insert` event.
3. Webhook configuration: Supabase Edge Functions.
4. Edge Function: Select the `push` edge function and leave the method as `POST` and timeout as `1000`.
5. HTTP Headers: Click "Add new header" > "Add auth header with service key" and leave Content-type: `application/json`.
6. Click "Create webhook".

## Send push notification [\#](https://supabase.com/docs/guides/functions/examples/push-notifications\#send-push-notification)

1. Navigate to the [table editor](https://supabase.com/dashboard/project/_/editor) in your Supabase Dashboard.
2. In your `notifications` table, insert a new row.
3. Watch the magic happen 

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2FxYRbYG77M_o%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Supabase setup](https://supabase.com/docs/guides/functions/examples/push-notifications#supabase-setup) [Expo setup](https://supabase.com/docs/guides/functions/examples/push-notifications#expo-setup) [Enhanced security for push notifications](https://supabase.com/docs/guides/functions/examples/push-notifications#enhanced-security-for-push-notifications) [Deploy the Supabase Edge Function](https://supabase.com/docs/guides/functions/examples/push-notifications#deploy-the-supabase-edge-function) [Create the database webhook](https://supabase.com/docs/guides/functions/examples/push-notifications#create-the-database-webhook) [Send push notification](https://supabase.com/docs/guides/functions/examples/push-notifications#send-push-notification)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_examples_rate_limiting.md">
Edge Functions

# Rate Limiting Edge Functions

* * *

Rate Limiting Edge Functions - YouTube

Supabase

45.5K subscribers

[Rate Limiting Edge Functions](https://www.youtube.com/watch?v=o4ooiE-SdUg)

Supabase

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=o4ooiE-SdUg "Watch on YouTube")

[Redis](https://redis.io/docs/about/) is an open source (BSD licensed), in-memory data structure store used as a database, cache, message broker, and streaming engine. It is optimized for atomic operations like incrementing a value, for example for a view counter or rate limiting. We can even rate limit based on the user ID from Supabase Auth!

[Upstash](https://upstash.com/) provides an HTTP/REST based Redis client which is ideal for serverless use-cases and therefore works well with Supabase Edge Functions.

Find the code on [GitHub](https://github.com/supabase/supabase/tree/master/examples/edge-functions/supabase/functions/upstash-redis-ratelimit).

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_examples_screenshots.md">
Edge Functions

# Taking Screenshots with Puppeteer

* * *

Screenshots in Edge Functions - YouTube

Supabase

45.5K subscribers

[Screenshots in Edge Functions](https://www.youtube.com/watch?v=Q1nfnQggR4c)

Supabase

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=Q1nfnQggR4c "Watch on YouTube")

[Puppeteer](https://pptr.dev/) is a handy tool to programmatically take screenshots and generate PDFs. However, trying to do so in Edge Functions can be challenging due to the size restrictions. Luckily there is a [serverless browser offering available](https://www.browserless.io/) that we can connect to via WebSockets.

Find the code on [GitHub](https://github.com/supabase/supabase/tree/master/examples/edge-functions/supabase/functions/puppeteer).

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_examples_semantic_search.md">
Edge Functions

# Semantic Search

## Semantic Search with pgvector and Supabase Edge Functions

* * *

[Semantic search](https://supabase.com/docs/guides/ai/semantic-search) interprets the meaning behind user queries rather than exact [keywords](https://supabase.com/docs/guides/ai/keyword-search). It uses machine learning to capture the intent and context behind the query, handling language nuances like synonyms, phrasing variations, and word relationships.

Since Supabase Edge Runtime [v1.36.0](https://github.com/supabase/edge-runtime/releases/tag/v1.36.0) you can run the [`gte-small` model](https://huggingface.co/Supabase/gte-small) natively within Supabase Edge Functions without any external dependencies! This allows you to generate text embeddings without calling any external APIs!

In this tutorial you're implementing three parts:

1. A [`generate-embedding`](https://github.com/supabase/supabase/tree/master/examples/ai/edge-functions/supabase/functions/generate-embedding/index.ts) database webhook edge function which generates embeddings when a content row is added (or updated) in the [`public.embeddings`](https://github.com/supabase/supabase/tree/master/examples/ai/edge-functions/supabase/migrations/20240408072601_embeddings.sql) table.
2. A [`query_embeddings` Postgres function](https://github.com/supabase/supabase/tree/master/examples/ai/edge-functions/supabase/migrations/20240410031515_vector-search.sql) which allows us to perform similarity search from an Edge Function via [Remote Procedure Call (RPC)](https://supabase.com/docs/guides/database/functions?language=js).
3. A [`search` edge function](https://github.com/supabase/supabase/tree/master/examples/ai/edge-functions/supabase/functions/search/index.ts) which generates the embedding for the search term, performs the similarity search via RPC function call, and returns the result.

You can find the complete example code on [GitHub](https://github.com/supabase/supabase/tree/master/examples/ai/edge-functions)

### Create the database table and webhook [\#](https://supabase.com/docs/guides/functions/examples/semantic-search\#create-the-database-table-and-webhook)

Given the [following table definition](https://github.com/supabase/supabase/blob/master/examples/ai/edge-functions/supabase/migrations/20240408072601_embeddings.sql):

`
create extension if not exists vector with schema extensions;
create table embeddings (
id bigint primary key generated always as identity,
content text not null,
embedding vector (384)
);
alter table embeddings enable row level security;
create index on embeddings using hnsw (embedding vector_ip_ops);
`

You can deploy the [following edge function](https://github.com/supabase/supabase/blob/master/examples/ai/edge-functions/supabase/functions/generate-embedding/index.ts) as a [database webhook](https://supabase.com/docs/guides/database/webhooks) to generate the embeddings for any text content inserted into the table:

`
const model = new Supabase.ai.Session('gte-small')
Deno.serve(async (req) => {
const payload: WebhookPayload = await req.json()
const { content, id } = payload.record
// Generate embedding.
const embedding = await model.run(content, {
    mean_pool: true,
    normalize: true,
})
// Store in database.
const { error } = await supabase
    .from('embeddings')
    .update({ embedding: JSON.stringify(embedding) })
    .eq('id', id)
if (error) console.warn(error.message)
return new Response('ok')
})
`

## Create a Database Function and RPC [\#](https://supabase.com/docs/guides/functions/examples/semantic-search\#create-a-database-function-and-rpc)

With the embeddings now stored in your Postgres database table, you can query them from Supabase Edge Functions by utilizing [Remote Procedure Calls (RPC)](https://supabase.com/docs/guides/database/functions?language=js).

Given the [following Postgres Function](https://github.com/supabase/supabase/blob/master/examples/ai/edge-functions/supabase/migrations/20240410031515_vector-search.sql):

`
-- Matches document sections using vector similarity search on embeddings
--
-- Returns a setof embeddings so that we can use PostgREST resource embeddings (joins with other tables)
-- Additional filtering like limits can be chained to this function call
create or replace function query_embeddings(embedding vector(384), match_threshold float)
returns setof embeddings
language plpgsql
as $$
begin
return query
select *
from embeddings
  -- The inner product is negative, so we negate match_threshold
where embeddings.embedding <#> embedding < -match_threshold
  -- Our embeddings are normalized to length 1, so cosine similarity
  -- and inner product will produce the same query results.
  -- Using inner product which can be computed faster.
  --
  -- For the different distance functions, see https://github.com/pgvector/pgvector
order by embeddings.embedding <#> embedding;
end;
$$;
`

## Query vectors in Supabase Edge Functions [\#](https://supabase.com/docs/guides/functions/examples/semantic-search\#query-vectors-in-supabase-edge-functions)

You can use `supabase-js` to first generate the embedding for the search term and then invoke the Postgres function to find the relevant results from your stored embeddings, right from your [Supabase Edge Function](https://github.com/supabase/supabase/blob/master/examples/ai/edge-functions/supabase/functions/search/index.ts):

`
const model = new Supabase.ai.Session('gte-small')
Deno.serve(async (req) => {
const { search } = await req.json()
if (!search) return new Response('Please provide a search param!')
// Generate embedding for search term.
const embedding = await model.run(search, {
    mean_pool: true,
    normalize: true,
})
// Query embeddings.
const { data: result, error } = await supabase
    .rpc('query_embeddings', {
      embedding,
      match_threshold: 0.8,
    })
    .select('content')
    .limit(3)
if (error) {
    return Response.json(error)
}
return Response.json({ search, result })
})
`

You now have AI powered semantic search set up without any external dependencies! Just you, pgvector, and Supabase Edge Functions!

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2Fw4Rr_1whU-U%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Create the database table and webhook](https://supabase.com/docs/guides/functions/examples/semantic-search#create-the-database-table-and-webhook) [Create a Database Function and RPC](https://supabase.com/docs/guides/functions/examples/semantic-search#create-a-database-function-and-rpc) [Query vectors in Supabase Edge Functions](https://supabase.com/docs/guides/functions/examples/semantic-search#query-vectors-in-supabase-edge-functions)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_examples_send_emails.md">
Edge Functions

# Sending Emails

* * *

Sending emails from Edge Functions using the [Resend API](https://resend.com/).

### Prerequisites [\#](https://supabase.com/docs/guides/functions/examples/send-emails\#prerequisites)

To get the most out of this guide, youll need to:

- [Create an API key](https://resend.com/api-keys)
- [Verify your domain](https://resend.com/domains)

Make sure you have the latest version of the[Supabase CLI](https://supabase.com/docs/guides/cli#installation)installed.

### 1\. Create Supabase function [\#](https://supabase.com/docs/guides/functions/examples/send-emails\#1-create-supabase-function)

Create a new function locally:

`
supabase functions new resend
`

Store the `RESEND_API_KEY` in your `.env` file.

### 2\. Edit the handler function [\#](https://supabase.com/docs/guides/functions/examples/send-emails\#2-edit-the-handler-function)

Paste the following code into the`index.ts`file:

``
const RESEND_API_KEY = Deno.env.get('RESEND_API_KEY')
const handler = async (_request: Request): Promise<Response> => {
const res = await fetch('https://api.resend.com/emails', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      Authorization: `Bearer ${RESEND_API_KEY}`,
    },
    body: JSON.stringify({
      from: 'onboarding@resend.dev',
      to: 'delivered@resend.dev',
      subject: 'hello world',
      html: '<strong>it works!</strong>',
    }),
})
const data = await res.json()
return new Response(JSON.stringify(data), {
    status: 200,
    headers: {
      'Content-Type': 'application/json',
    },
})
}
Deno.serve(handler)
``

### 3\. Deploy and send email [\#](https://supabase.com/docs/guides/functions/examples/send-emails\#3-deploy-and-send-email)

Run function locally:

`
supabase start
supabase functions serve --no-verify-jwt --env-file .env
`

Test it: [http://localhost:54321/functions/v1/resend](http://localhost:54321/functions/v1/resend)

Deploy function to Supabase:

`
supabase functions deploy resend --no-verify-jwt
`

When you deploy to Supabase, make sure that your `RESEND_API_KEY` is set in [Edge Function Secrets Management](https://supabase.com/dashboard/project/_/settings/functions)

Open the endpoint URL to send an email:

### 4\. Try it yourself [\#](https://supabase.com/docs/guides/functions/examples/send-emails\#4-try-it-yourself)

Find the complete example on [GitHub](https://github.com/resendlabs/resend-supabase-edge-functions-example).

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2FQf7XvL1fjvo%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Prerequisites](https://supabase.com/docs/guides/functions/examples/send-emails#prerequisites) [1\. Create Supabase function](https://supabase.com/docs/guides/functions/examples/send-emails#1-create-supabase-function) [2\. Edit the handler function](https://supabase.com/docs/guides/functions/examples/send-emails#2-edit-the-handler-function) [3\. Deploy and send email](https://supabase.com/docs/guides/functions/examples/send-emails#3-deploy-and-send-email) [4\. Try it yourself](https://supabase.com/docs/guides/functions/examples/send-emails#4-try-it-yourself)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_examples_sentry_monitoring.md">
Edge Functions

# Monitoring with Sentry

* * *

Add the [Sentry Deno SDK](https://docs.sentry.io/platforms/javascript/guides/deno/) to your Supabase Edge Functions to track exceptions and get notified of errors or performance issues.

### Prerequisites [\#](https://supabase.com/docs/guides/functions/examples/sentry-monitoring\#prerequisites)

- [Create a Sentry account](https://sentry.io/signup/).
- Make sure you have the latest version of the[Supabase CLI](https://supabase.com/docs/guides/cli#installation)installed.

### 1\. Create Supabase function [\#](https://supabase.com/docs/guides/functions/examples/sentry-monitoring\#1-create-supabase-function)

Create a new function locally:

`
supabase functions new sentryfied
`

### 2\. Add the Sentry Deno SDK [\#](https://supabase.com/docs/guides/functions/examples/sentry-monitoring\#2-add-the-sentry-deno-sdk)

Handle exceptions within your function and send them to Sentry.

``
import * as Sentry from 'https://deno.land/x/sentry/index.mjs'
Sentry.init({
// https://docs.sentry.io/product/sentry-basics/concepts/dsn-explainer/#where-to-find-your-dsn
dsn: SENTRY_DSN,
defaultIntegrations: false,
// Performance Monitoring
tracesSampleRate: 1.0,
// Set sampling rate for profiling - this is relative to tracesSampleRate
profilesSampleRate: 1.0,
})
// Set region and execution_id as custom tags
Sentry.setTag('region', Deno.env.get('SB_REGION'))
Sentry.setTag('execution_id', Deno.env.get('SB_EXECUTION_ID'))
Deno.serve(async (req) => {
try {
    const { name } = await req.json()
    // This will throw, as `name` in our example call will be `undefined`
    const data = {
      message: `Hello ${name}!`,
    }
    return new Response(JSON.stringify(data), { headers: { 'Content-Type': 'application/json' } })
} catch (e) {
    Sentry.captureException(e)
    return new Response(JSON.stringify({ msg: 'error' }), {
      status: 500,
      headers: { 'Content-Type': 'application/json' },
    })
}
})
``

### 3\. Deploy and test [\#](https://supabase.com/docs/guides/functions/examples/sentry-monitoring\#3-deploy-and-test)

Run function locally:

`
supabase start
supabase functions serve --no-verify-jwt
`

Test it: [http://localhost:54321/functions/v1/sentryfied](http://localhost:54321/functions/v1/sentryfied)

Deploy function to Supabase:

`
supabase functions deploy sentryfied --no-verify-jwt
`

### 4\. Try it yourself [\#](https://supabase.com/docs/guides/functions/examples/sentry-monitoring\#4-try-it-yourself)

Find the complete example on [GitHub](https://github.com/supabase/supabase/tree/master/examples/edge-functions/supabase/functions/sentryfied/index.ts).

## Working with scopes [\#](https://supabase.com/docs/guides/functions/examples/sentry-monitoring\#working-with-scopes)

Sentry Deno SDK currently do not support `Deno.serve` instrumentation, which means that there is no scope separation between requests.
Because of that, when the Edge Functions runtime is reused between multiple requests, all globally captured breadcrumbs and contextual data
will be shared, which is not the desired behavior. To work around this, all default integrations in the example code above are disabled,
and you should be relying on [`withScope`](https://docs.sentry.io/platforms/javascript/enriching-events/scopes/#using-withscope) to encapsulate
all Sentry SDK API calls, or [pass context directly](https://docs.sentry.io/platforms/javascript/enriching-events/context/#passing-context-directly)
to the `captureException` or `captureMessage` calls.

### Is this helpful?

NoYes

### On this page

[Prerequisites](https://supabase.com/docs/guides/functions/examples/sentry-monitoring#prerequisites) [1\. Create Supabase function](https://supabase.com/docs/guides/functions/examples/sentry-monitoring#1-create-supabase-function) [2\. Add the Sentry Deno SDK](https://supabase.com/docs/guides/functions/examples/sentry-monitoring#2-add-the-sentry-deno-sdk) [3\. Deploy and test](https://supabase.com/docs/guides/functions/examples/sentry-monitoring#3-deploy-and-test) [4\. Try it yourself](https://supabase.com/docs/guides/functions/examples/sentry-monitoring#4-try-it-yourself) [Working with scopes](https://supabase.com/docs/guides/functions/examples/sentry-monitoring#working-with-scopes)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_examples_slack_bot_mention.md">
Edge Functions

# Slack Bot Mention Edge Function

* * *

The Slack Bot Mention Edge Function allows you to process mentions in Slack and respond accordingly.

## Configuring Slack apps [\#](https://supabase.com/docs/guides/functions/examples/slack-bot-mention\#configuring-slack-apps)

For your bot to seamlessly interact with Slack, you'll need to configure Slack Apps:

1. Navigate to the Slack Apps page.
2. Under "Event Subscriptions," add the URL of the `slack-bot-mention` function and click to verify the URL.
3. The Edge function will respond, confirming that everything is set up correctly.
4. Add `app-mention` in the events the bot will subscribe to.

## Creating the Edge Function [\#](https://supabase.com/docs/guides/functions/examples/slack-bot-mention\#creating-the-edge-function)

Deploy the following code as an Edge function using the CLI:

`
supabase --project-ref nacho_slacker secrets \
set SLACK_TOKEN=<xoxb-0000000000-0000000000-01010101010nacho101010>
`

Here's the code of the Edge Function, you can change the response to handle the text received:

index.ts

``
import { WebClient } from 'https://deno.land/x/slack_web_api@6.7.2/mod.js'
const slackBotToken = Deno.env.get('SLACK_TOKEN') ?? ''
const botClient = new WebClient(slackBotToken)
console.log(`Slack URL verification function up and running!`)
Deno.serve(async (req) => {
try {
    const reqBody = await req.json()
    console.log(JSON.stringify(reqBody, null, 2))
    const { token, challenge, type, event } = reqBody
    if (type == 'url_verification') {
      return new Response(JSON.stringify({ challenge }), {
        headers: { 'Content-Type': 'application/json' },
        status: 200,
      })
    } else if (event.type == 'app_mention') {
      const { user, text, channel, ts } = event
      // Here you should process the text received and return a response:
      const response = await botClient.chat.postMessage({
        channel: channel,
        text: `Hello <@${user}>!`,
        thread_ts: ts,
      })
      return new Response('ok', { status: 200 })
    }
} catch (error) {
    return new Response(JSON.stringify({ error: error.message }), {
      headers: { 'Content-Type': 'application/json' },
      status: 500,
    })
}
})
``

### Is this helpful?

NoYes

### On this page

[Configuring Slack apps](https://supabase.com/docs/guides/functions/examples/slack-bot-mention#configuring-slack-apps) [Creating the Edge Function](https://supabase.com/docs/guides/functions/examples/slack-bot-mention#creating-the-edge-function)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_examples_stripe_webhooks.md">
Edge Functions

# Handling Stripe Webhooks

* * *

Handling signed Stripe Webhooks with Edge Functions - YouTube

Supabase

45.5K subscribers

[Handling signed Stripe Webhooks with Edge Functions](https://www.youtube.com/watch?v=6OMVWiiycLs)

Supabase

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=6OMVWiiycLs "Watch on YouTube")

Handling signed Stripe Webhooks with Edge Functions. [View on GitHub](https://github.com/supabase/supabase/blob/master/examples/edge-functions/supabase/functions/stripe-webhooks/index.ts).

index.ts

``
// Follow this setup guide to integrate the Deno language server with your editor:
// https://deno.land/manual/getting_started/setup_your_environment
// This enables autocomplete, go to definition, etc.
// Import via bare specifier thanks to the import_map.json file.
import Stripe from 'https://esm.sh/stripe@14?target=denonext'
const stripe = new Stripe(Deno.env.get('STRIPE_API_KEY') as string, {
// This is needed to use the Fetch API rather than relying on the Node http
// package.
apiVersion: '2024-11-20'
})
// This is needed in order to use the Web Crypto API in Deno.
const cryptoProvider = Stripe.createSubtleCryptoProvider()
console.log('Hello from Stripe Webhook!')
Deno.serve(async (request) => {
const signature = request.headers.get('Stripe-Signature')
// First step is to verify the event. The .text() method must be used as the
// verification relies on the raw request body rather than the parsed JSON.
const body = await request.text()
let receivedEvent
try {
    receivedEvent = await stripe.webhooks.constructEventAsync(
      body,
      signature!,
      Deno.env.get('STRIPE_WEBHOOK_SIGNING_SECRET')!,
      undefined,
      cryptoProvider
    )
} catch (err) {
    return new Response(err.message, { status: 400 })
}
console.log(` Event received: ${receivedEvent.id}`)
return new Response(JSON.stringify({ ok: true }), { status: 200 })
});
``

[View source](https://github.com/supabase/supabase/blob/9b9cf69c7e6cf3b275a7f324e7556b2960368e3f/examples/edge-functions/supabase/functions/stripe-webhooks/index.ts)

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_examples_telegram_bot.md">
Edge Functions

# Building a Telegram Bot

* * *

Building a Telegram Bot with Edge Functions - YouTube

Supabase

45.5K subscribers

[Building a Telegram Bot with Edge Functions](https://www.youtube.com/watch?v=AWfE3a9J_uo)

Supabase

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=AWfE3a9J_uo "Watch on YouTube")

Handle Telegram Bot Webhooks with the [grammY framework](https://grammy.dev/). grammY is an open source Telegram Bot Framework which makes it easy to handle and respond to incoming messages. [View on GitHub](https://github.com/supabase/supabase/tree/master/examples/edge-functions/supabase/functions/telegram-bot).

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_examples_upstash_redis.md">
Edge Functions

# Upstash Redis

* * *

Increment Redis Counter in Edge Functions - YouTube

Supabase

45.5K subscribers

[Increment Redis Counter in Edge Functions](https://www.youtube.com/watch?v=OPg3_oPZCh0)

Supabase

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=OPg3_oPZCh0 "Watch on YouTube")

A Redis counter example that stores a [hash](https://redis.io/commands/hincrby/) of function invocation count per region. Find the code on [GitHub](https://github.com/supabase/supabase/tree/master/examples/edge-functions/supabase/functions/upstash-redis-counter).

## Redis database setup [\#](https://supabase.com/docs/guides/functions/examples/upstash-redis\#redis-database-setup)

Create a Redis database using the [Upstash Console](https://console.upstash.com/) or [Upstash CLI](https://github.com/upstash/cli).

Select the `Global` type to minimize the latency from all edge locations. Copy the `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` to your .env file.

You'll find them under **Details > REST API > .env**.

`
cp supabase/functions/upstash-redis-counter/.env.example supabase/functions/upstash-redis-counter/.env
`

## Code [\#](https://supabase.com/docs/guides/functions/examples/upstash-redis\#code)

Make sure you have the latest version of the [Supabase CLI installed](https://supabase.com/docs/guides/cli#installation).

Create a new function in your project:

`
supabase functions new upstash-redis-counter
`

And add the code to the `index.ts` file:

index.ts

``
import { Redis } from 'https://deno.land/x/upstash_redis@v1.19.3/mod.ts'
console.log(`Function "upstash-redis-counter" up and running!`)
Deno.serve(async (_req) => {
try {
    const redis = new Redis({
      url: Deno.env.get('UPSTASH_REDIS_REST_URL')!,
      token: Deno.env.get('UPSTASH_REDIS_REST_TOKEN')!,
    })
    const deno_region = Deno.env.get('DENO_REGION')
    if (deno_region) {
      // Increment region counter
      await redis.hincrby('supa-edge-counter', deno_region, 1)
    } else {
      // Increment localhost counter
      await redis.hincrby('supa-edge-counter', 'localhost', 1)
    }
    // Get all values
    const counterHash: Record<string, number> | null = await redis.hgetall('supa-edge-counter')
    const counters = Object.entries(counterHash!)
      .sort(([, a], [, b]) => b - a) // sort desc
      .reduce((r, [k, v]) => ({ total: r.total + v, regions: { ...r.regions, [k]: v } }), {
        total: 0,
        regions: {},
      })
    return new Response(JSON.stringify({ counters }), { status: 200 })
} catch (error) {
    return new Response(JSON.stringify({ error: error.message }), { status: 200 })
}
})
``

## Run locally [\#](https://supabase.com/docs/guides/functions/examples/upstash-redis\#run-locally)

`
supabase start
supabase functions serve --no-verify-jwt --env-file supabase/functions/upstash-redis-counter/.env
`

Navigate to [http://localhost:54321/functions/v1/upstash-redis-counter](http://localhost:54321/functions/v1/upstash-redis-counter).

## Deploy [\#](https://supabase.com/docs/guides/functions/examples/upstash-redis\#deploy)

`
supabase functions deploy upstash-redis-counter --no-verify-jwt
supabase secrets set --env-file supabase/functions/upstash-redis-counter/.env
`

### Is this helpful?

NoYes

### On this page

[Redis database setup](https://supabase.com/docs/guides/functions/examples/upstash-redis#redis-database-setup) [Code](https://supabase.com/docs/guides/functions/examples/upstash-redis#code) [Run locally](https://supabase.com/docs/guides/functions/examples/upstash-redis#run-locally) [Deploy](https://supabase.com/docs/guides/functions/examples/upstash-redis#deploy)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_kysely_postgres.md">
Edge Functions

# Type-Safe SQL with Kysely

* * *

Type-Safe SQL on the Edge with Kysely - YouTube

Supabase

45.5K subscribers

[Type-Safe SQL on the Edge with Kysely](https://www.youtube.com/watch?v=zd9a_Lk3jAc)

Supabase

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=zd9a_Lk3jAc "Watch on YouTube")

Supabase Edge Functions can [connect directly to your Postgres database](https://supabase.com/docs/guides/functions/connect-to-postgres) to execute SQL queries. [Kysely](https://github.com/kysely-org/kysely#kysely) is a type-safe and autocompletion-friendly typescript SQL query builder.

Combining Kysely with Deno Postgres gives you a convenient developer experience for interacting directly with your Postgres database.

## Code [\#](https://supabase.com/docs/guides/functions/kysely-postgres\#code)

Find the example on [GitHub](https://github.com/supabase/supabase/tree/master/examples/edge-functions/supabase/functions/kysely-postgres)

Get your database connection credentials from your [Supabase Dashboard](https://supabase.com/dashboard/project/_/settings/database) and store them in an `.env` file:

.env

`
DB_HOSTNAME=
DB_PASSWORD=
DB_SSL_CERT="-----BEGIN CERTIFICATE-----
GET YOUR CERT FROM YOUR PROJECT DASHBOARD
-----END CERTIFICATE-----"
`

Create a `DenoPostgresDriver.ts` file to manage the connection to Postgres via [deno-postgres](https://deno-postgres.com/):

DenoPostgresDriver.ts

``
import {
CompiledQuery,
DatabaseConnection,
Driver,
PostgresCursorConstructor,
QueryResult,
TransactionSettings,
} from 'https://esm.sh/kysely@0.23.4'
import { freeze, isFunction } from 'https://esm.sh/kysely@0.23.4/dist/esm/util/object-utils.js'
import { extendStackTrace } from 'https://esm.sh/kysely@0.23.4/dist/esm/util/stack-trace-utils.js'
import { Pool, PoolClient } from 'https://deno.land/x/postgres@v0.17.0/mod.ts'
export interface PostgresDialectConfig {
pool: Pool | (() => Promise<Pool>)
cursor?: PostgresCursorConstructor
onCreateConnection?: (connection: DatabaseConnection) => Promise<void>
}
const PRIVATE_RELEASE_METHOD = Symbol()
export class PostgresDriver implements Driver {
readonly #config: PostgresDialectConfig
readonly #connections = new WeakMap<PoolClient, DatabaseConnection>()
#pool?: Pool
constructor(config: PostgresDialectConfig) {
    this.#config = freeze({ ...config })
}
async init(): Promise<void> {
    this.#pool = isFunction(this.#config.pool) ? await this.#config.pool() : this.#config.pool
}
async acquireConnection(): Promise<DatabaseConnection> {
    const client = await this.#pool!.connect()
    let connection = this.#connections.get(client)
    if (!connection) {
      connection = new PostgresConnection(client, {
        cursor: this.#config.cursor ?? null,
      })
      this.#connections.set(client, connection)
      // The driver must take care of calling `onCreateConnection` when a new
      // connection is created. The `pg` module doesn't provide an async hook
      // for the connection creation. We need to call the method explicitly.
      if (this.#config?.onCreateConnection) {
        await this.#config.onCreateConnection(connection)
      }
    }
    return connection
}
async beginTransaction(
    connection: DatabaseConnection,
    settings: TransactionSettings
): Promise<void> {
    if (settings.isolationLevel) {
      await connection.executeQuery(
        CompiledQuery.raw(`start transaction isolation level ${settings.isolationLevel}`)
      )
    } else {
      await connection.executeQuery(CompiledQuery.raw('begin'))
    }
}
async commitTransaction(connection: DatabaseConnection): Promise<void> {
    await connection.executeQuery(CompiledQuery.raw('commit'))
}
async rollbackTransaction(connection: DatabaseConnection): Promise<void> {
    await connection.executeQuery(CompiledQuery.raw('rollback'))
}
async releaseConnection(connection: PostgresConnection): Promise<void> {
    connection[PRIVATE_RELEASE_METHOD]()
}
async destroy(): Promise<void> {
    if (this.#pool) {
      const pool = this.#pool
      this.#pool = undefined
      await pool.end()
    }
}
}
interface PostgresConnectionOptions {
cursor: PostgresCursorConstructor | null
}
class PostgresConnection implements DatabaseConnection {
#client: PoolClient
#options: PostgresConnectionOptions
constructor(client: PoolClient, options: PostgresConnectionOptions) {
    this.#client = client
    this.#options = options
}
async executeQuery<O>(compiledQuery: CompiledQuery): Promise<QueryResult<O>> {
    try {
      const result = await this.#client.queryObject<O>(compiledQuery.sql, [\
        ...compiledQuery.parameters,\
      ])
      if (
        result.command === 'INSERT' ||
        result.command === 'UPDATE' ||
        result.command === 'DELETE'
      ) {
        const numAffectedRows = BigInt(result.rowCount || 0)
        return {
          numUpdatedOrDeletedRows: numAffectedRows,
          numAffectedRows,
          rows: result.rows ?? [],
        } as any
      }
      return {
        rows: result.rows ?? [],
      }
    } catch (err) {
      throw extendStackTrace(err, new Error())
    }
}
async *streamQuery<O>(
    _compiledQuery: CompiledQuery,
    chunkSize: number
): AsyncIterableIterator<QueryResult<O>> {
    if (!this.#options.cursor) {
      throw new Error(
        "'cursor' is not present in your postgres dialect config. It's required to make streaming work in postgres."
      )
    }
    if (!Number.isInteger(chunkSize) || chunkSize <= 0) {
      throw new Error('chunkSize must be a positive integer')
    }
    // stream not available
    return null
}
[PRIVATE_RELEASE_METHOD](): void {
    this.#client.release()
}
}
``

Create an `index.ts` file to execute a query on incoming requests:

index.ts

``
import { serve } from 'https://deno.land/std@0.175.0/http/server.ts'
import { Pool } from 'https://deno.land/x/postgres@v0.17.0/mod.ts'
import {
Kysely,
Generated,
PostgresAdapter,
PostgresIntrospector,
PostgresQueryCompiler,
} from 'https://esm.sh/kysely@0.23.4'
import { PostgresDriver } from './DenoPostgresDriver.ts'
console.log(`Function "kysely-postgres" up and running!`)
interface AnimalTable {
id: Generated<bigint>
animal: string
created_at: Date
}
// Keys of this interface are table names.
interface Database {
animals: AnimalTable
}
// Create a database pool with one connection.
const pool = new Pool(
{
    tls: { caCertificates: [Deno.env.get('DB_SSL_CERT')!] },
    database: 'postgres',
    hostname: Deno.env.get('DB_HOSTNAME'),
    user: 'postgres',
    port: 5432,
    password: Deno.env.get('DB_PASSWORD'),
},
1
)
// You'd create one of these when you start your app.
const db = new Kysely<Database>({
dialect: {
    createAdapter() {
      return new PostgresAdapter()
    },
    createDriver() {
      return new PostgresDriver({ pool })
    },
    createIntrospector(db: Kysely<unknown>) {
      return new PostgresIntrospector(db)
    },
    createQueryCompiler() {
      return new PostgresQueryCompiler()
    },
},
})
serve(async (_req) => {
try {
    // Run a query
    const animals = await db.selectFrom('animals').select(['id', 'animal', 'created_at']).execute()
    // Neat, it's properly typed \o/
    console.log(animals[0].created_at.getFullYear())
    // Encode the result as pretty printed JSON
    const body = JSON.stringify(
      animals,
      (key, value) => (typeof value === 'bigint' ? value.toString() : value),
      2
    )
    // Return the response with the correct content type header
    return new Response(body, {
      status: 200,
      headers: {
        'Content-Type': 'application/json; charset=utf-8',
      },
    })
} catch (err) {
    console.error(err)
    return new Response(String(err?.message ?? err), { status: 500 })
}
})
``

### Is this helpful?

NoYes

### On this page

[Code](https://supabase.com/docs/guides/functions/kysely-postgres#code)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_limits.md">
Edge Functions

# Limits

## Limits applied Edge Functions in Supabase's hosted platform.

* * *

## Runtime limits [\#](https://supabase.com/docs/guides/functions/limits\#runtime-limits)

- Maximum Memory: 256MB
- Maximum Duration (Wall clock limit):
This is the duration an Edge Function worker will stay active. During this period, a worker can serve multiple requests or process background tasks.
  - Free plan: 150s
  - Paid plans: 400s
- Maximum CPU Time: 2s (Amount of actual time spent on the CPU per request - does not include async I/O.)
- Request idle timeout: 150s (If an Edge Function doesn't send a response before the timeout, 504 Gateway Timeout will be returned)
- Maximum Function Size: 20MB (After bundling using CLI)
- Maximum log message length: 10,000 characters
- Log event threshold: 100 events per 10 seconds

## Other limits & restrictions [\#](https://supabase.com/docs/guides/functions/limits\#other-limits--restrictions)

- Outgoing connections to ports`25` and`587`are not allowed.
- Serving of HTML content is only supported with [custom domains](https://supabase.com/docs/reference/cli/supabase-domains) (Otherwise `GET`requests that return`text/html`will be rewritten to`text/plain`).
- Web Worker API (or Node `vm` API) are not available.
- Node Libraries that require multithreading are not supported. Examples: [`libvips`](https://github.com/libvips/libvips), [sharp](https://github.com/lovell/sharp).

### Is this helpful?

NoYes

### On this page

[Runtime limits](https://supabase.com/docs/guides/functions/limits#runtime-limits) [Other limits & restrictions](https://supabase.com/docs/guides/functions/limits#other-limits--restrictions)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_local_development.md">
Edge Functions

# Local development

## Setup local development environment for Edge Functions.

* * *

We recommend installing the Deno CLI and related tools for local development.

## Deno support [\#](https://supabase.com/docs/guides/functions/local-development\#deno-support)

You can follow the [Deno guide](https://deno.com/manual@v1.32.5/getting_started/setup_your_environment) for setting up your development environment with your favorite editor/IDE.

## Deno with Visual Studio Code [\#](https://supabase.com/docs/guides/functions/local-development\#deno-with-visual-studio-code)

When using VSCode, you should install both the Deno CLI and the the Deno language server [via this link](vscode:extension/denoland.vscode-deno) or by browsing the extensions in VSCode and choosing to install the _Deno_ extension.

The Supabase CLI can automatically create helpful Deno settings when running `supabase init`. Select `y` when prompted "Generate VS Code settings for Deno? \[y/N\]"!

## Deno support in subfolders [\#](https://supabase.com/docs/guides/functions/local-development\#deno-support-in-subfolders)

You can enable the Deno language server for specific sub-paths in a workspace, while using VSCode's built-in JavaScript/TypeScript language server for all other files.

For example if you have a project like this:

`
project
 app
 supabase
 functions
`

To enable the Deno language server only for the `supabase/functions` folder, add `./supabase/functions` to the list of _Deno: Enable Paths_ in the configuration. In your `.vscode/settings.json` file add:

`
{
"deno.enablePaths": ["./supabase/functions"],
"deno.importMap": "./supabase/functions/import_map.json"
}
`

## Multi-root workspaces in VSCode [\#](https://supabase.com/docs/guides/functions/local-development\#multi-root-workspaces-in-vscode)

We recommend using `deno.enablePaths` mentioned above as it's easier to manage, however if you like [multi-root workspaces](https://code.visualstudio.com/docs/editor/workspaces#_multiroot-workspaces) you can use these as an alternative.

VS Code Workspace Configuration for Edge Functions - YouTube

Supabase

45.5K subscribers

[VS Code Workspace Configuration for Edge Functions](https://www.youtube.com/watch?v=lFhU3L8VoSQ)

Supabase

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=lFhU3L8VoSQ "Watch on YouTube")

For example, see this `edge-functions.code-workspace` configuration for a CRA (create react app) client with Supabase Edge Functions. You can find the complete example on [GitHub](https://github.com/supabase/supabase/tree/master/examples/edge-functions).

`
{
"folders": [\
    {\
      "name": "project-root",\
      "path": "./"\
    },\
    {\
      "name": "client",\
      "path": "app"\
    },\
    {\
      "name": "supabase-functions",\
      "path": "supabase/functions"\
    }\
],
"settings": {
    "files.exclude": {
      "node_modules/": true,
      "app/": true,
      "supabase/functions/": true
    },
    "deno.importMap": "./supabase/functions/import_map.json"
}
}
`

### Is this helpful?

NoYes

### On this page

[Deno support](https://supabase.com/docs/guides/functions/local-development#deno-support) [Deno with Visual Studio Code](https://supabase.com/docs/guides/functions/local-development#deno-with-visual-studio-code) [Deno support in subfolders](https://supabase.com/docs/guides/functions/local-development#deno-support-in-subfolders) [Multi-root workspaces in VSCode](https://supabase.com/docs/guides/functions/local-development#multi-root-workspaces-in-vscode)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_logging.md">
Edge Functions

# Logging

## How to access logs for your Edge Functions.

* * *

Logs are provided for each function invocation, locally and in hosted environments.

## How to access logs [\#](https://supabase.com/docs/guides/functions/logging\#how-to-access-logs)

### Hosted [\#](https://supabase.com/docs/guides/functions/logging\#hosted)

You can access both tools from the [Functions section](https://supabase.com/dashboard/project/_/functions) of the Dashboard. Select your function from the list, and click `Invocations` or `Logs`:

- **Invocations**: shows the Request and Response for each execution. You can see the headers, body, status code, and duration of each invocation. You can also filter the invocations by date, time, or status code.
- **Logs**: shows any platform events, uncaught exceptions, and custom log events. You can see the timestamp, level, and message of each log event. You can also filter the log events by date, time, or level.

![Function invocations.](https://supabase.com/docs/img/guides/functions/function-logs.png)

### Local [\#](https://supabase.com/docs/guides/functions/logging\#local)

When [developing locally](https://supabase.com/docs/guides/functions/local-development) you will see error messages and console log statements printed to your local terminal window.

## Events that get logged [\#](https://supabase.com/docs/guides/functions/logging\#events-that-get-logged)

- **Uncaught exceptions**: Uncaught exceptions thrown by a function during execution are automatically logged. You can see the error message and stack trace in the Logs tool.
- **Custom log events**: You can use `console.log`, `console.error`, and `console.warn` in your code to emit custom log events. These events also appear in the Logs tool.
- **Boot and Shutdown Logs**: The Logs tool extends its coverage to include logs for the boot and shutdown of functions.

A custom log message can contain up to 10,000 characters. A function can log up to 100 events
within a 10 second period.

Here is an example of how to use custom logs events in your function:

``
Deno.serve(async (req) => {
try {
    const { name } = await req.json()
    if (!name) {
      console.warn('Empty name provided')
    }
    const data = {
      message: `Hello ${name || 'Guest'}!`, // Provide a default value if name is empty
    }
    console.log(`Name: ${name}`)
    return new Response(JSON.stringify(data), { headers: { 'Content-Type': 'application/json' } })
} catch (error) {
    console.error(`Error processing request: ${error.message}`)
    return new Response(JSON.stringify({ error: 'Internal Server Error' }), {
      status: 500,
      headers: { 'Content-Type': 'application/json' },
    })
}
})
``

## Logging tips [\#](https://supabase.com/docs/guides/functions/logging\#logging-tips)

### Logging request headers [\#](https://supabase.com/docs/guides/functions/logging\#logging-request-headers)

When debugging Edge Functions, a common mistake is to try to log headers to the developer console via code like this:

index.ts

``
Deno.serve(async (req) => {
const headers = JSON.stringify(req.headers)
console.log(`Request headers: ${headers}`)
// OR
console.log(`Request headers: ${JSON.stringify(req.headers)}`)
return new Response('ok', {
    headers: {
      'Content-Type': 'application/json',
    },
    status: 200,
})
})
``

Both attempts will give as output the string `"{}"`, even though retrieving the value using `request.headers.get("Your-Header-Name")` will indeed give you the correct value. This behavior mirrors that of browsers.

The reason behind this behavior is that [Headers](https://developer.mozilla.org/en-US/docs/Web/API/Headers) objects don't store headers in JavaScript properties that can be enumerated. As a result, neither the developer console nor the JSON stringifier can properly interpret the names and values of the headers. Essentially, it's not an empty object, but rather an opaque one.

However, `Headers` objects are iterable. You can utilize this feature to craft a couple of succinct one-liners for debugging and printing headers.

### Convert headers into an object with `Object.fromEntries`: [\#](https://supabase.com/docs/guides/functions/logging\#convert-headers-into-an-object-with-objectfromentries-)

You can use `Object.fromEntries` which is a call to convert the headers into an object:

index.ts

``
Deno.serve(async (req) => {
let headersObject = Object.fromEntries(req.headers)
let requestHeaders = JSON.stringify(headersObject, null, 2)
console.log(`Request headers: ${requestHeaders}`)
return new Response('ok', {
    headers: {
      'Content-Type': 'application/json',
    },
    status: 200,
})
})
``

This results in something like:

index.ts

`
Request headers: {
    "accept": "*/*",
    "accept-encoding": "gzip",
    "authorization": "Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InN1cGFuYWNobyIsInJvbGUiOiJhbm9uIiwieW91IjoidmVyeSBzbmVha3ksIGh1aD8iLCJpYXQiOjE2NTQ1NDA5MTYsImV4cCI6MTk3MDExNjkxNn0.cwBbk2tq-fUcKF1S0jVKkOAG2FIQSID7Jjvff5Do99Y",
    "cdn-loop": "cloudflare; subreqs=1",
    "cf-ew-via": "15",
    "cf-ray": "8597a2fcc558a5d7-GRU",
    "cf-visitor": "{\"scheme\":\"https\"}",
    "cf-worker": "supabase.co",
    "content-length": "20",
    "content-type": "application/x-www-form-urlencoded",
    "host": "edge-runtime.supabase.com",
    "my-custom-header": "abcd",
    "user-agent": "curl/8.4.0",
    "x-deno-subhost": "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiIsImtpZCI6InN1cGFiYXNlIn0.eyJkZXBsb3ltZW50X2lkIjoic3VwYW5hY2hvX2M1ZGQxMWFiLTFjYmUtNDA3NS1iNDAxLTY3ZTRlZGYxMjVjNV8wMDciLCJycGNfcm9vdCI6Imh0dHBzOi8vc3VwYWJhc2Utb3JpZ2luLmRlbm8uZGV2L3YwLyIsImV4cCI6MTcwODYxMDA4MiwiaWF0IjoxNzA4NjA5MTgyfQ.-fPid2kEeEM42QHxWeMxxv2lJHZRSkPL-EhSH0r_iV4",
    "x-forwarded-host": "edge-runtime.supabase.com",
    "x-forwarded-port": "443",
    "x-forwarded-proto": "https"
}
`

### Is this helpful?

NoYes

### On this page

[How to access logs](https://supabase.com/docs/guides/functions/logging#how-to-access-logs) [Hosted](https://supabase.com/docs/guides/functions/logging#hosted) [Local](https://supabase.com/docs/guides/functions/logging#local) [Events that get logged](https://supabase.com/docs/guides/functions/logging#events-that-get-logged) [Logging tips](https://supabase.com/docs/guides/functions/logging#logging-tips) [Logging request headers](https://supabase.com/docs/guides/functions/logging#logging-request-headers) [Convert headers into an object with Object.fromEntries:](https://supabase.com/docs/guides/functions/logging#convert-headers-into-an-object-with-objectfromentries-)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_pricing.md">
Edge Functions

# Pricing

* * *

$2 per 1 million invocations. You are only charged for usage exceeding your subscription plan's quota.

| Plan | Quota | Over-Usage |
| --- | --- | --- |
| Free | 500,000 | - |
| Pro | 2 million | $2 per 1 million invocations |
| Team | 2 million | $2 per 1 million invocations |
| Enterprise | Custom | Custom |

For a detailed explanation of how charges are calculated, refer to [Manage Edge Function Invocations usage](https://supabase.com/docs/guides/platform/manage-your-usage/edge-function-invocations).

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_quickstart.md">
Edge Functions

# Developing Edge Functions locally

## Get started with Edge Functions on your local machine.

* * *

Let's create a basic Edge Function on your local machine and then invoke it using the Supabase CLI.

## Initialize a project [\#](https://supabase.com/docs/guides/functions/quickstart\#initialize-a-project)

Create a new Supabase project in a folder on your local machine:

`
supabase init
`

##### CLI not installed?

Check out the [CLI Docs](https://supabase.com/docs/guides/cli) to learn how to install the Supabase CLI on your local machine.

If you're using VS code you can have the CLI automatically create helpful Deno settings when running `supabase init`. Select `y` when prompted "Generate VS Code settings for Deno? \[y/N\]"!

If you're using an IntelliJ IDEA editor such as WebStorm, you can use the `--with-intellij-settings` flag with `supabase init` to create an auto generated Deno config.

## Create an Edge Function [\#](https://supabase.com/docs/guides/functions/quickstart\#create-an-edge-function)

Let's create a new Edge Function called `hello-world` inside your project:

`
supabase functions new hello-world
`

This creates a function stub in your `supabase` folder:

`
 supabase
     functions
        hello-world
           index.ts ## Your function code
     config.toml
`

## How to write the code [\#](https://supabase.com/docs/guides/functions/quickstart\#how-to-write-the-code)

The generated function uses native [Deno.serve](https://docs.deno.com/runtime/manual/runtime/http_server_apis) to handle requests. It gives you access to `Request` and `Response` objects.

Here's the generated Hello World Edge Function, that accepts a name in the `Request` and responds with a greeting:

``
Deno.serve(async (req) => {
const { name } = await req.json()
const data = {
    message: `Hello ${name}!`,
}
return new Response(JSON.stringify(data), { headers: { 'Content-Type': 'application/json' } })
})
``

## Running Edge Functions locally [\#](https://supabase.com/docs/guides/functions/quickstart\#running-edge-functions-locally)

You can run your Edge Function locally using [`supabase functions serve`](https://supabase.com/docs/reference/cli/usage#supabase-functions-serve):

`
supabase start # start the supabase stack
supabase functions serve # start the Functions watcher
`

The `functions serve` command has hot-reloading capabilities. It will watch for any changes to your files and restart the Deno server.

## Invoking Edge Functions locally [\#](https://supabase.com/docs/guides/functions/quickstart\#invoking-edge-functions-locally)

While serving your local Edge Function, you can invoke it using curl or one of the client libraries.
To call the function from a browser you need to handle CORS requests. See [CORS](https://supabase.com/docs/guides/functions/cors).

cURL

JavaScript

`
curl --request POST 'http://localhost:54321/functions/v1/hello-world' \
  --header 'Authorization: Bearer SUPABASE_ANON_KEY' \
  --header 'Content-Type: application/json' \
  --data '{ "name":"Functions" }'
`

##### Where is my SUPABASE\_ANON\_KEY?

Run `supabase status` to see your local credentials.

You should see the response `{ "message":"Hello Functions!" }`.

If you execute the function with a different payload, the response will change.

Modify the `--data '{"name":"Functions"}'` line to `--data '{"name":"World"}'` and try invoking the command again.

## Next steps [\#](https://supabase.com/docs/guides/functions/quickstart\#next-steps)

Check out the [Deploy to Production](https://supabase.com/docs/guides/functions/deploy) guide to make your Edge Function available to the world.

Read on for some common development tips.

## Development tips [\#](https://supabase.com/docs/guides/functions/quickstart\#development-tips)

Here are a few recommendations when developing Edge Functions.

### Skipping authorization checks [\#](https://supabase.com/docs/guides/functions/quickstart\#skipping-authorization-checks)

By default, Edge Functions require a valid JWT in the authorization header. If you want to use Edge Functions without Authorization checks (commonly used for Stripe webhooks), you can pass the `--no-verify-jwt` flag when serving your Edge Functions locally.

`
supabase functions serve hello-world --no-verify-jwt
`

Be careful when using this flag, as it will allow anyone to invoke your Edge Function without a valid JWT. The Supabase client libraries automatically handle authorization.

### Using HTTP methods [\#](https://supabase.com/docs/guides/functions/quickstart\#using-http-methods)

Edge Functions support `GET`, `POST`, `PUT`, `PATCH`, `DELETE`, and `OPTIONS`. A Function can be designed to perform different actions based on a request's HTTP method. See the [example on building a RESTful service](https://github.com/supabase/supabase/tree/master/examples/edge-functions/supabase/functions/restful-tasks) to learn how to handle different HTTP methods in your Function.

##### HTML not supported

HTML content is not supported. `GET` requests that return `text/html` will be rewritten to `text/plain`.

### Naming Edge Functions [\#](https://supabase.com/docs/guides/functions/quickstart\#naming-edge-functions)

We recommend using hyphens to name functions because hyphens are the most URL-friendly of all the naming conventions (snake\_case, camelCase, PascalCase).

### Organizing your Edge Functions [\#](https://supabase.com/docs/guides/functions/quickstart\#organizing-your-edge-functions)

We recommend developing fat functions. This means that you should develop few large functions, rather than many small functions. One common pattern when developing Functions is that you need to share code between two or more Functions. To do this, you can store any shared code in a folder prefixed with an underscore ( `_`). We also recommend a separate folder for [Unit Tests](https://supabase.com/docs/guides/functions/unit-test) including the name of the function followed by a `-test` suffix.
We recommend this folder structure:

`
 supabase
     functions
        import_map.json # A top-level import map to use across functions.
        _shared
           supabaseAdmin.ts # Supabase client with SERVICE_ROLE key.
           supabaseClient.ts # Supabase client with ANON key.
           cors.ts # Reusable CORS headers.
        function-one # Use hyphens to name functions.
           index.ts
        function-two
           index.ts
        tests
            function-one-test.ts
            function-two-test.ts
     migrations
     config.toml
`

### Using config.toml [\#](https://supabase.com/docs/guides/functions/quickstart\#using-configtoml)

Individual function configuration like [JWT verification](https://supabase.com/docs/guides/cli/config#functions.function_name.verify_jwt) and [import map location](https://supabase.com/docs/guides/cli/config#functions.function_name.import_map) can be set via the `config.toml` file.

supabase/config.toml

`
[functions.hello-world]
verify_jwt = false
import_map = './import_map.json'
`

### Not using TypeScript [\#](https://supabase.com/docs/guides/functions/quickstart\#not-using-typescript)

When you create a new Edge Function, it will use TypeScript by default. However, it is possible to write and deploy Edge Functions using pure JavaScript.

Save your Function as a JavaScript file (e.g. `index.js`) and then update the `supabase/config.toml` as follows:

`entrypoint` is available only in Supabase CLI version 1.215.0 or higher.

supabase/config.toml

`
[functions.hello-world]
# other entries
entrypoint = './functions/hello-world/index.js' # path must be relative to config.toml
`

You can use any `.ts`, `.js`, `.tsx`, `.jsx` or `.mjs` file as the `entrypoint` for a Function.

### Error handling [\#](https://supabase.com/docs/guides/functions/quickstart\#error-handling)

The `supabase-js` library provides several error types that you can use to handle errors that might occur when invoking Edge Functions:

`
import { FunctionsHttpError, FunctionsRelayError, FunctionsFetchError } from '@supabase/supabase-js'
const { data, error } = await supabase.functions.invoke('hello', {
headers: { 'my-custom-header': 'my-custom-header-value' },
body: { foo: 'bar' },
})
if (error instanceof FunctionsHttpError) {
const errorMessage = await error.context.json()
console.log('Function returned an error', errorMessage)
} else if (error instanceof FunctionsRelayError) {
console.log('Relay error:', error.message)
} else if (error instanceof FunctionsFetchError) {
console.log('Fetch error:', error.message)
}
`

### Database Functions vs Edge Functions [\#](https://supabase.com/docs/guides/functions/quickstart\#database-functions-vs-edge-functions)

For data-intensive operations we recommend using [Database Functions](https://supabase.com/docs/guides/database/functions), which are executed within your database and can be called remotely using the [REST and GraphQL API](https://supabase.com/docs/guides/api).

For use-cases which require low-latency we recommend [Edge Functions](https://supabase.com/docs/guides/functions), which are globally-distributed and can be written in TypeScript.

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2F5OWH9c4u68M%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Initialize a project](https://supabase.com/docs/guides/functions/quickstart#initialize-a-project) [Create an Edge Function](https://supabase.com/docs/guides/functions/quickstart#create-an-edge-function) [How to write the code](https://supabase.com/docs/guides/functions/quickstart#how-to-write-the-code) [Running Edge Functions locally](https://supabase.com/docs/guides/functions/quickstart#running-edge-functions-locally) [Invoking Edge Functions locally](https://supabase.com/docs/guides/functions/quickstart#invoking-edge-functions-locally) [Next steps](https://supabase.com/docs/guides/functions/quickstart#next-steps) [Development tips](https://supabase.com/docs/guides/functions/quickstart#development-tips) [Skipping authorization checks](https://supabase.com/docs/guides/functions/quickstart#skipping-authorization-checks) [Using HTTP methods](https://supabase.com/docs/guides/functions/quickstart#using-http-methods) [Naming Edge Functions](https://supabase.com/docs/guides/functions/quickstart#naming-edge-functions) [Organizing your Edge Functions](https://supabase.com/docs/guides/functions/quickstart#organizing-your-edge-functions) [Using config.toml](https://supabase.com/docs/guides/functions/quickstart#using-configtoml) [Not using TypeScript](https://supabase.com/docs/guides/functions/quickstart#not-using-typescript) [Error handling](https://supabase.com/docs/guides/functions/quickstart#error-handling) [Database Functions vs Edge Functions](https://supabase.com/docs/guides/functions/quickstart#database-functions-vs-edge-functions)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_regional_invocation.md">
Edge Functions

# Regional Invocations

## How to execute an Edge Function in a particular region.

* * *

Edge Functions are executed in the region closest to the user making the request. This helps to reduce network latency and provide faster responses to the user.

However, if your Function performs lots of database or storage operations, invoking the Function in the same region as your database may provide better performance. Some situations where this might be helpful include:

- Bulk adding and editing records in your database
- Uploading files

Supabase provides an option to specify the region when invoking the Function.

## Using the `x-region` header [\#](https://supabase.com/docs/guides/functions/regional-invocation\#using-the-x-region-header)

Use the `x-region` HTTP header when calling an Edge Function to determine where the Function should be executed:

cURL

JavaScript

`
# https://supabase.com/docs/guides/functions/deploy#invoking-remote-functions
curl --request POST 'https://<project_ref>.supabase.co/functions/v1/hello-world' \
  --header 'Authorization: Bearer ANON_KEY' \
  --header 'Content-Type: application/json' \
  --header 'x-region: eu-west-3' \
  --data '{ "name":"Functions" }'
`

You can verify the execution region by looking at the `x-sb-edge-region` HTTP header in the response. You can also find it as metadata in [Edge Function Logs](https://supabase.com/docs/guides/functions/logging).

## Available regions [\#](https://supabase.com/docs/guides/functions/regional-invocation\#available-regions)

These are the currently supported region values you can provide for `x-region` header.

- `ap-northeast-1`
- `ap-northeast-2`
- `ap-south-1`
- `ap-southeast-1`
- `ap-southeast-2`
- `ca-central-1`
- `eu-central-1`
- `eu-west-1`
- `eu-west-2`
- `eu-west-3`
- `sa-east-1`
- `us-east-1`
- `us-west-1`
- `us-west-2`

## Using the client library [\#](https://supabase.com/docs/guides/functions/regional-invocation\#using-the-client-library)

You can also specify the region when invoking a Function using the Supabase client library:

`
const { createClient, FunctionRegion } = require('@supabase/supabase-js')
const { data: ret, error } = await supabase.functions.invoke('my-function-name', {
headers: { 'Content-Type': 'application/json' },
method: 'GET',
body: {},
region: FunctionRegion.UsEast1,
})
`

## Handling regional outages [\#](https://supabase.com/docs/guides/functions/regional-invocation\#handling-regional-outages)

If you explicitly specify the region via `x-region` header, requests **will NOT** be automatically re-routed to another region and you should consider temporarily changing regions during the outage.

### Is this helpful?

NoYes

### On this page

[Using the x-region header](https://supabase.com/docs/guides/functions/regional-invocation#using-the-x-region-header) [Available regions](https://supabase.com/docs/guides/functions/regional-invocation#available-regions) [Using the client library](https://supabase.com/docs/guides/functions/regional-invocation#using-the-client-library) [Handling regional outages](https://supabase.com/docs/guides/functions/regional-invocation#handling-regional-outages)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_routing.md">
Edge Functions

# Handling Routing in Functions

## How to handle custom routing within Edge Functions.

* * *

Usually, an Edge Function is written to perform a single action (e.g. write a record to the database). However, if your app's logic is split into multiple Edge Functions requests to each action may seem slower.
This is because each Edge Function needs to be booted before serving a request (known as cold starts). If an action is performed less frequently (e.g. deleting a record), there is a high-chance of that function experiencing a cold-start.

One way to reduce the cold starts and increase performance of your app is to combine multiple actions into a single Edge Function. This way only one instance of the Edge Function needs to be booted and it can handle multiple requests to different actions.
For example, we can use a single Edge Function to create a typical CRUD API (create, read, update, delete records).

To combine multiple endpoints into a single Edge Function, you can use web application frameworks such as [Express](https://expressjs.com/), [Oak](https://oakserver.github.io/oak/), or [Hono](https://hono.dev/).

Let's dive into some examples.

## Routing with frameworks [\#](https://supabase.com/docs/guides/functions/routing\#routing-with-frameworks)

Here's a simple hello world example using some popular web frameworks.

Create a new function called `hello-world` using Supabase CLI:

`
supabase functions new hello-world
`

Copy and paste the following code:

ExpressOakHonoDeno

``
import { Hono } from 'jsr:@hono/hono';
const app = new Hono();
app.post('/hello-world', async (c) => {
const { name } = await c.req.json();
return new Response(`Hello ${name}!`)
});
app.get('/hello-world', (c) => {
return new Response('Hello World!')
});
Deno.serve(app.fetch);
``

You will notice in the above example, we created two routes - `GET` and `POST`. The path for both routes are defined as `/hello-world`.
If you run a server outside of Edge Functions, you'd usually set the root path as `/` .
However, within Edge Functions, paths should always be prefixed with the function name (in this case `hello-world`).

You can deploy the function to Supabase via:

`
supabase functions deploy hello-world
`

Once the function is deployed, you can try to call the two endpoints using cURL (or Postman).

`
# https://supabase.com/docs/guides/functions/deploy#invoking-remote-functions
curl --request GET 'https://<project_ref>.supabase.co/functions/v1/hello-world' \
  --header 'Authorization: Bearer ANON_KEY' \
`

This should print the response as `Hello World!`, meaning it was handled by the `GET` route.

Similarly, we can make a request to the `POST` route.

cURL

`
# https://supabase.com/docs/guides/functions/deploy#invoking-remote-functions
curl --request POST 'https://<project_ref>.supabase.co/functions/v1/hello-world' \
  --header 'Authorization: Bearer ANON_KEY' \
  --header 'Content-Type: application/json' \
  --data '{ "name":"Foo" }'
`

We should see a response printing `Hello Foo!`.

## Using route parameters [\#](https://supabase.com/docs/guides/functions/routing\#using-route-parameters)

We can use route parameters to capture values at specific URL segments (e.g. `/tasks/:taskId/notes/:noteId`).

Here's an example Edge Function implemented using the Framework for managing tasks using route parameters.
Keep in mind paths must be prefixed by function name (i.e. `tasks` in this example). Route parameters can only be used after the function name prefix.

ExpressOakHonoDeno

## URL patterns API [\#](https://supabase.com/docs/guides/functions/routing\#url-patterns-api)

If you prefer not to use a web framework, you can directly use [URL Pattern API](https://developer.mozilla.org/en-US/docs/Web/API/URL_Pattern_API) within your Edge Functions to implement routing.
This is ideal for small apps with only couple of routes and you want to have a custom matching algorithm.

Here is an example Edge Function using URL Patterns API: [https://github.com/supabase/supabase/blob/master/examples/edge-functions/supabase/functions/restful-tasks/index.ts](https://github.com/supabase/supabase/blob/master/examples/edge-functions/supabase/functions/restful-tasks/index.ts)

### Is this helpful?

NoYes

### On this page

[Routing with frameworks](https://supabase.com/docs/guides/functions/routing#routing-with-frameworks) [Using route parameters](https://supabase.com/docs/guides/functions/routing#using-route-parameters) [URL patterns API](https://supabase.com/docs/guides/functions/routing#url-patterns-api)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_schedule_functions.md">
Edge Functions

# Scheduling Edge Functions

* * *

Scheduling Edge Functions - YouTube

Supabase

45.5K subscribers

[Scheduling Edge Functions](https://www.youtube.com/watch?v=-U6DJcjVvGo)

Supabase

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=-U6DJcjVvGo "Watch on YouTube")

The hosted Supabase Platform supports the [`pg_cron` extension](https://supabase.com/docs/guides/database/extensions/pgcron), a recurring job scheduler in Postgres.

In combination with the [`pg_net` extension](https://supabase.com/docs/guides/database/extensions/pgnet), this allows us to invoke Edge Functions periodically on a set schedule.

To access the auth token securely for your Edge Function call, we recommend storing them in [Supabase Vault](https://supabase.com/docs/guides/database/vault).

## Examples [\#](https://supabase.com/docs/guides/functions/schedule-functions\#examples)

### Invoke an Edge Function every minute [\#](https://supabase.com/docs/guides/functions/schedule-functions\#invoke-an-edge-function-every-minute)

Store `project_url` and `anon_key` in Supabase Vault:

`
select vault.create_secret('https://project-ref.supabase.co', 'project_url');
select vault.create_secret('YOUR_SUPABASE_ANON_KEY', 'anon_key');
`

Make a POST request to a Supabase Edge Function every minute:

`
select
cron.schedule(
    'invoke-function-every-minute',
    '* * * * *', -- every minute
    $$
    select
      net.http_post(
          url:= (select decrypted_secret from vault.decrypted_secrets where name = 'project_url') || '/functions/v1/function-name',
          headers:=jsonb_build_object(
            'Content-type', 'application/json',
            'Authorization', 'Bearer ' || (select decrypted_secret from vault.decrypted_secrets where name = 'anon_key')
          ),
          body:=concat('{"time": "', now(), '"}')::jsonb
      ) as request_id;
    $$
);
`

## Resources [\#](https://supabase.com/docs/guides/functions/schedule-functions\#resources)

- [`pg_net` extension](https://supabase.com/docs/guides/database/extensions/pgnet)
- [`pg_cron` extension](https://supabase.com/docs/guides/database/extensions/pgcron)

### Is this helpful?

NoYes

### On this page

[Examples](https://supabase.com/docs/guides/functions/schedule-functions#examples) [Invoke an Edge Function every minute](https://supabase.com/docs/guides/functions/schedule-functions#invoke-an-edge-function-every-minute) [Resources](https://supabase.com/docs/guides/functions/schedule-functions#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_secrets.md">
Edge Functions

# Managing Secrets (Environment Variables)

## Managing secrets and environment variables.

* * *

It's common that you will need to use environment variables or other sensitive information Edge Functions. You can manage secrets using the CLI or the Dashboard.

You can access these using Deno's built-in handler

`
Deno.env.get('MY_SECRET_NAME')
`

## Default secrets [\#](https://supabase.com/docs/guides/functions/secrets\#default-secrets)

Edge Functions have access to these secrets by default:

- `SUPABASE_URL`: The API gateway for your Supabase project.
- `SUPABASE_ANON_KEY`: The `anon` key for your Supabase API. This is safe to use in a browser when you have [Row Level Security](https://supabase.com/docs/guides/database/postgres/row-level-security) enabled.
- `SUPABASE_SERVICE_ROLE_KEY`: The `service_role` key for your Supabase API. This is safe to use in Edge Functions, but it should NEVER be used in a browser. This key will bypass [Row Level Security](https://supabase.com/docs/guides/database/postgres/row-level-security).
- `SUPABASE_DB_URL`: The URL for your [Postgres database](https://supabase.com/docs/guides/database). You can use this to connect directly to your database.

## Local secrets [\#](https://supabase.com/docs/guides/functions/secrets\#local-secrets)

You can load environment variables in two ways:

1. Through an `.env` file placed at `supabase/functions/.env`, which is automatically loaded on `supabase start`
2. Through the `--env-file` option for `supabase functions serve`, for example: `supabase functions serve --env-file ./path/to/.env-file`

Let's create a local file for storing our secrets, and inside it we can store a secret `MY_NAME`:

`
echo "MY_NAME=Yoda" >> ./supabase/.env.local
`

This creates a new file `./supabase/.env.local` for storing your local development secrets.

Never check your .env files into Git!

Now let's access this environment variable `MY_NAME` inside our Function. Anywhere in your function, add this line:

`
console.log(Deno.env.get('MY_NAME'))
`

Now we can invoke our function locally, by serving it with our new `.env.local` file:

`
supabase functions serve --env-file ./supabase/.env.local
`

When the function starts you should see the name Yoda output to the terminal.

## Production secrets [\#](https://supabase.com/docs/guides/functions/secrets\#production-secrets)

You will also need to set secrets for your production Edge Functions. You can do this via the Dashboard or using the CLI.

### Using the Dashboard [\#](https://supabase.com/docs/guides/functions/secrets\#using-the-dashboard)

1. Visit [Edge Function Secrets Management](https://supabase.com/dashboard/project/_/settings/functions) page in your Dashboard.
2. Add the Key and Value for your secret and press Save.
3. Note that you can paste multiple secrets at a time.

![Edge Functions Secrets Management](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fedge-functions-secrets--light.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Using the CLI [\#](https://supabase.com/docs/guides/functions/secrets\#using-the-cli)

Let's create a `.env` to help us deploy our secrets to production. In this case we'll just use the same as our local secrets:

`
cp ./supabase/.env.local ./supabase/.env
`

This creates a new file `./supabase/.env` for storing your production secrets.

Never check your `.env` files into Git! You only use the `.env` file to help deploy your secrets to production. Don't commit it to your repository.

Let's push all the secrets from the `.env` file to our remote project using [`supabase secrets set`](https://supabase.com/docs/reference/cli/usage#supabase-secrets-set):

`
supabase secrets set --env-file ./supabase/.env
# You can also set secrets individually using:
supabase secrets set MY_NAME=Chewbacca
`

You don't need to re-deploy after setting your secrets.

To see all the secrets which you have set remotely, use [`supabase secrets list`](https://supabase.com/docs/reference/cli/usage#supabase-secrets-list):

`
supabase secrets list
`

### Is this helpful?

NoYes

### On this page

[Default secrets](https://supabase.com/docs/guides/functions/secrets#default-secrets) [Local secrets](https://supabase.com/docs/guides/functions/secrets#local-secrets) [Production secrets](https://supabase.com/docs/guides/functions/secrets#production-secrets) [Using the Dashboard](https://supabase.com/docs/guides/functions/secrets#using-the-dashboard) [Using the CLI](https://supabase.com/docs/guides/functions/secrets#using-the-cli)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_status_codes.md">
Edge Functions

# Status codes

## Edge Functions can return following status codes.

* * *

## 2XX Success [\#](https://supabase.com/docs/guides/functions/status-codes\#2xx-success)

A successful Edge Function Response

## 3XX Redirect [\#](https://supabase.com/docs/guides/functions/status-codes\#3xx-redirect)

The Edge Function has responded with a `Response.redirect` [API docs](https://developer.mozilla.org/en-US/docs/Web/API/Response/redirect_static)

## 4XX Client Errors [\#](https://supabase.com/docs/guides/functions/status-codes\#4xx-client-errors)

### 401 Unauthorized [\#](https://supabase.com/docs/guides/functions/status-codes\#401-unauthorized)

If the Edge Function has `Verify JWT` option enabled, but the request was made with an invalid JWT.

### 404 Not Found [\#](https://supabase.com/docs/guides/functions/status-codes\#404-not-found)

Requested Edge Function was not found.

### 405 Method Not Allowed [\#](https://supabase.com/docs/guides/functions/status-codes\#405-method-not-allowed)

Edge Functions only support these HTTP methods: 'POST', 'GET', 'PUT', 'PATCH', 'DELETE', 'OPTIONS'

## 5XX Server Errors [\#](https://supabase.com/docs/guides/functions/status-codes\#5xx-server-errors)

### 500 Internal Server Error [\#](https://supabase.com/docs/guides/functions/status-codes\#500-internal-server-error)

Edge Function threw an uncaught exception ( `WORKER_ERROR`). Check Edge Function logs to find the cause.

### 503 Service Unavailable [\#](https://supabase.com/docs/guides/functions/status-codes\#503-service-unavailable)

Edge Function failed to start ( `BOOT_ERROR`). Check Edge Function logs to find the cause.

### 504 Gateway Timeout [\#](https://supabase.com/docs/guides/functions/status-codes\#504-gateway-timeout)

Edge Function didn't respond before the [request idle timeout](https://supabase.com/docs/guides/functions/limits).

### 546 Resource Limit (Custom Error Code) [\#](https://supabase.com/docs/guides/functions/status-codes\#546-resource-limit-custom-error-code)

Edge Function execution was stopped due to a resource limit ( `WORKER_LIMIT`). Edge Function logs should provide which [resource limit](https://supabase.com/docs/guides/functions/limits) was exceeded.

### Is this helpful?

NoYes

### On this page

[2XX Success](https://supabase.com/docs/guides/functions/status-codes#2xx-success) [3XX Redirect](https://supabase.com/docs/guides/functions/status-codes#3xx-redirect) [4XX Client Errors](https://supabase.com/docs/guides/functions/status-codes#4xx-client-errors) [401 Unauthorized](https://supabase.com/docs/guides/functions/status-codes#401-unauthorized) [404 Not Found](https://supabase.com/docs/guides/functions/status-codes#404-not-found) [405 Method Not Allowed](https://supabase.com/docs/guides/functions/status-codes#405-method-not-allowed) [5XX Server Errors](https://supabase.com/docs/guides/functions/status-codes#5xx-server-errors) [500 Internal Server Error](https://supabase.com/docs/guides/functions/status-codes#500-internal-server-error) [503 Service Unavailable](https://supabase.com/docs/guides/functions/status-codes#503-service-unavailable) [504 Gateway Timeout](https://supabase.com/docs/guides/functions/status-codes#504-gateway-timeout) [546 Resource Limit (Custom Error Code)](https://supabase.com/docs/guides/functions/status-codes#546-resource-limit-custom-error-code)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_storage_caching.md">
Edge Functions

# Integrating with Supabase Storage

* * *

Caching OG Images with Supabase Storage CDN - YouTube

Supabase

45.5K subscribers

[Caching OG Images with Supabase Storage CDN](https://www.youtube.com/watch?v=wW6L52v9Ldo)

Supabase

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=wW6L52v9Ldo "Watch on YouTube")

Integrate Edge Functions with Supabase Storage to cache images on the Edge (CDN). [View on GitHub](https://github.com/supabase/supabase/tree/master/examples/edge-functions/supabase/functions/og-image-with-storage-cdn).

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_troubleshooting.md">
Edge Functions

# Troubleshooting Common Issues

## How to solve common problems and issues related to Edge Functions.

* * *

If you encounter any problems or issues with your Edge Functions, here are some tips and steps to help you resolve them.

### Unable to deploy Edge Function [\#](https://supabase.com/docs/guides/functions/troubleshooting\#unable-to-deploy-edge-function)

- Make sure you're on the latest version of the [Supabase CLI](https://supabase.com/docs/guides/cli#updates).
- If the output from the commands above does not help you to resolve the issue, open a support ticket via the Supabase Dashboard (by clicking the "Help" button at the top right) and include all output from the commands mentioned above.

### Unable to call Edge Function [\#](https://supabase.com/docs/guides/functions/troubleshooting\#unable-to-call-edge-function)

If youre unable to call your Edge Function or are experiencing any CORS issues:

- Make sure you followed the [CORS guide](https://supabase.com/docs/guides/functions/cors). This guide explains how to enable and configure CORS for your Edge Functions, and how to avoid common pitfalls and errors.
- Check your function logs. Navigate to the [Functions section](https://supabase.com/dashboard/project/_/functions) in your dashboard, select your function from the list, and click `Logs`. Check for any errors or warnings that may indicate the cause of the problem.

There are two debugging tools available: Invocations and Logs. Invocations shows the Request and Response for each execution, while Logs shows any platform events, including deployments and errors.

### Edge Function takes too long to respond [\#](https://supabase.com/docs/guides/functions/troubleshooting\#edge-function-takes-too-long-to-respond)

If your Edge Function takes too long to respond or times out:

- Navigate to the [Functions section](https://supabase.com/dashboard/project/_/functions) in your dashboard, select your function from the list, and click `Logs`.
- In the logs, look for the `booted` event and check if they have consistent boot times.
  - If the boot times are similar, its likely an issue with your functions code, such as a large dependency, a slow API call, or a complex computation. You can try to optimize your code, reduce the size of your dependencies, or use caching techniques to improve the performance of your function.
  - If only some of the `booted` events are slow, find the affected `region` in the metadata and submit a support request via the "Help" button at the top.

### Receiving 546 Error Response [\#](https://supabase.com/docs/guides/functions/troubleshooting\#receiving-546-error-response)

The 546 error response might occur because:

- **Memory or CPU Limits**: The function might have exhausted its memory or encountered CPU limits enforced during execution.
- **Event Loop Completion**: If you observe "Event loop completed" in your error logs, it's likely your function is not implemented correctly. You should check your function code for any syntax errors, infinite loops, or unresolved promises that might cause this error. Or you can try running the function locally (using Supabase CLI **`functions serve`**) to see if you can debug the error. The local console should give a full stack trace on the error with line numbers of the source code. You can also refer to [Edge Functions examples](https://github.com/supabase/supabase/tree/master/examples/edge-functions) for guidance.

### Issues serving Edge Functions locally with the Supabase CLI [\#](https://supabase.com/docs/guides/functions/troubleshooting\#issues-serving-edge-functions-locally-with-the-supabase-cli)

- Make sure you're on the latest version of the [Supabase CLI](https://supabase.com/docs/guides/cli#updates).
- Run the serve command with the `-debug` flag.
- Support engineers can then try to run the provided sample code locally and see if they can reproduce the issue.
- Search the [Edge Runtime](https://github.com/supabase/edge-runtime) and [CLI](https://github.com/supabase/cli) repos for the error message, to see if it has been reported before.
- If the output from the commands above does not help you to resolve the issue, open a support ticket via the Supabase Dashboard (by clicking the "Help" button at the top right) and include all output and details about your commands.

## Advanced techniques [\#](https://supabase.com/docs/guides/functions/troubleshooting\#advanced-techniques)

### Monitoring Edge Function resource usage [\#](https://supabase.com/docs/guides/functions/troubleshooting\#monitoring-edge-function-resource-usage)

To determine how much memory and CPU your Edge Function consumes, follow these steps:

- Navigate to the Supabase Dashboard.
- Go to **Edge Functions**.
- Select the specific function by clicking on its name.
- View the resource usage **Metrics** on the charts provided.

Edge Functions have limited resources (CPU, memory, and execution time) compared to traditional
servers. Make sure your functions are optimized for performance and don't exceed the allocated
resources.

### Understanding CPU soft and hard limits [\#](https://supabase.com/docs/guides/functions/troubleshooting\#understanding-cpu-soft-and-hard-limits)

An isolate is like a worker that can handle multiple requests for a function. It works until a time limit of 400 seconds is reached. Now, there are two types of limits for the CPU.

1. **Soft Limit**: When the isolate hits the soft limit, it retires. This means it won't take on any new requests, but it will finish processing the ones it's already working on. It keeps going until it either hits the hard limit for CPU time or reaches the 400-second time limit, whichever comes first.
2. **Hard Limit**: If there are new requests after the soft limit is reached, a new isolate is created to handle them. The original isolate continues until it hits the hard limit or the time limit. This ensures that existing requests are completed, and new ones will be managed by a newly created isolate.

### Checking function boot time [\#](https://supabase.com/docs/guides/functions/troubleshooting\#checking-function-boot-time)

Check the logs for the function. In the logs, look for a "Booted" event and note the reported boot time. If available, click on the event to access more details, including the regions from where the function was served. Investigate if the boot time is excessively high (longer than 1 second) and note any patterns or regions where it occurs. You can refer to this guide for troubleshooting [regional invocations](https://supabase.com/docs/guides/functions/regional-invocation).

### Finding bundle size [\#](https://supabase.com/docs/guides/functions/troubleshooting\#finding-bundle-size)

To find the bundle size of a function, run the following command locally:

`deno info /path/to/function/index.ts`

Look for the "size" field in the output which represents the approximate bundle size of the function. You can find the accurate bundle size when you deploy your function via Supabase CLI. If the function is part of a larger application, consider examining the bundle size of the specific function independently.

The source code of a function is subject to 10MB site limit.

### Analyze dependencies [\#](https://supabase.com/docs/guides/functions/troubleshooting\#analyze-dependencies)

When analyzing dependencies for your Supabase Edge Functions, it's essential to review both Deno and NPM dependencies to ensure optimal performance and resource utilization.
By selectively importing only the required submodules, you can effectively reduce the size of your function's dependencies and optimize its performance.
Before finalizing your imports, ensure to review both Deno and NPM dependencies, checking for any unnecessary or redundant dependencies that can be removed. Additionally, check for outdated dependencies and update to the latest versions if possible.

#### Deno dependencies [\#](https://supabase.com/docs/guides/functions/troubleshooting\#deno-dependencies)

Run `deno info`, providing the path to your input map if you use one.
Review the dependencies listed in the output. Pay attention to any significantly large dependencies, as they can contribute to increased bundle size and potential boot time issues.
Examine if there are any unnecessary or redundant dependencies that can be removed. Check for outdated dependencies and update to the latest versions if possible.

`
deno info --import-map=/path/to/import_map.json /path/to/function/index.ts
`

#### NPM dependencies [\#](https://supabase.com/docs/guides/functions/troubleshooting\#npm-dependencies)

Additionally, if you utilize NPM modules in your Edge Functions, it's crucial to be mindful of their size and impact on the overall bundle size. While importing NPM modules, consider using the notation `import { submodule } from 'npm:package/submodule'` to selectively import specific submodules rather than importing the entire package. This approach can help minimize unnecessary overhead and streamline the execution of your function.

For example, if you only need the `Sheets` submodule from the `googleapis` package, you can import it like this:

`
import { Sheets } from 'npm:@googleapis/sheets'
`

### Is this helpful?

NoYes

### On this page

[Unable to deploy Edge Function](https://supabase.com/docs/guides/functions/troubleshooting#unable-to-deploy-edge-function) [Unable to call Edge Function](https://supabase.com/docs/guides/functions/troubleshooting#unable-to-call-edge-function) [Edge Function takes too long to respond](https://supabase.com/docs/guides/functions/troubleshooting#edge-function-takes-too-long-to-respond) [Receiving 546 Error Response](https://supabase.com/docs/guides/functions/troubleshooting#receiving-546-error-response) [Issues serving Edge Functions locally with the Supabase CLI](https://supabase.com/docs/guides/functions/troubleshooting#issues-serving-edge-functions-locally-with-the-supabase-cli) [Advanced techniques](https://supabase.com/docs/guides/functions/troubleshooting#advanced-techniques) [Monitoring Edge Function resource usage](https://supabase.com/docs/guides/functions/troubleshooting#monitoring-edge-function-resource-usage) [Understanding CPU soft and hard limits](https://supabase.com/docs/guides/functions/troubleshooting#understanding-cpu-soft-and-hard-limits) [Checking function boot time](https://supabase.com/docs/guides/functions/troubleshooting#checking-function-boot-time) [Finding bundle size](https://supabase.com/docs/guides/functions/troubleshooting#finding-bundle-size) [Analyze dependencies](https://supabase.com/docs/guides/functions/troubleshooting#analyze-dependencies)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_unit_test.md">
Edge Functions

# Testing your Edge Functions

## Writing Unit Tests for Edge Functions using Deno Test

* * *

Testing is an essential step in the development process to ensure the correctness and performance of your Edge Functions.

## Testing in Deno [\#](https://supabase.com/docs/guides/functions/unit-test\#testing-in-deno)

Deno has a built-in test runner that you can use for testing JavaScript or TypeScript code. You can read the [official documentation](https://docs.deno.com/runtime/manual/basics/testing/) for more information and details about the available testing functions.

## Folder structure [\#](https://supabase.com/docs/guides/functions/unit-test\#folder-structure)

We recommend creating your testing in a `supabase/functions/tests` directory, using the same name as the Function followed by `-test.ts`:

`
 supabase
     functions
        function-one
           index.ts
        function-two
           index.ts
        tests
            function-one-test.ts  # Tests for function-one
            function-two-test.ts  # Tests for function-two
     config.toml
`

## Example script [\#](https://supabase.com/docs/guides/functions/unit-test\#example-script)

The following script is a good example to get started with testing your Edge Functions:

function-one-test.ts

`
// Import required libraries and modules
import { assert, assertEquals } from 'https://deno.land/std@0.192.0/testing/asserts.ts'
import { createClient, SupabaseClient } from 'jsr:@supabase/supabase-js@2'
// Will load the .env file to Deno.env
import 'https://deno.land/x/dotenv@v3.2.2/load.ts'
// Set up the configuration for the Supabase client
const supabaseUrl = Deno.env.get('SUPABASE_URL') ?? ''
const supabaseKey = Deno.env.get('SUPABASE_ANON_KEY') ?? ''
const options = {
auth: {
    autoRefreshToken: false,
    persistSession: false,
    detectSessionInUrl: false,
},
}
// Test the creation and functionality of the Supabase client
const testClientCreation = async () => {
var client: SupabaseClient = createClient(supabaseUrl, supabaseKey, options)
// Verify if the Supabase URL and key are provided
if (!supabaseUrl) throw new Error('supabaseUrl is required.')
if (!supabaseKey) throw new Error('supabaseKey is required.')
// Test a simple query to the database
const { data: table_data, error: table_error } = await client
    .from('my_table')
    .select('*')
    .limit(1)
if (table_error) {
    throw new Error('Invalid Supabase client: ' + table_error.message)
}
assert(table_data, 'Data should be returned from the query.')
}
// Test the 'hello-world' function
const testHelloWorld = async () => {
var client: SupabaseClient = createClient(supabaseUrl, supabaseKey, options)
// Invoke the 'hello-world' function with a parameter
const { data: func_data, error: func_error } = await client.functions.invoke('hello-world', {
    body: { name: 'bar' },
})
// Check for errors from the function invocation
if (func_error) {
    throw new Error('Invalid response: ' + func_error.message)
}
// Log the response from the function
console.log(JSON.stringify(func_data, null, 2))
// Assert that the function returned the expected result
assertEquals(func_data.message, 'Hello bar!')
}
// Register and run the tests
Deno.test('Client Creation Test', testClientCreation)
Deno.test('Hello-world Function Test', testHelloWorld)
`

This test case consists of two parts. The first part tests the client library and verifies that the database can be connected to and returns values from a table ( `my_table`). The second part tests the edge function and checks if the received value matches the expected value. Here's a brief overview of the code:

- We import various testing functions from the Deno standard library, including `assert`, `assertExists`, and `assertEquals`.
- We import the `createClient` and `SupabaseClient` classes from the `@supabase/supabase-js` library to interact with the Supabase client.
- We define the necessary configuration for the Supabase client, including the Supabase URL, API key, and authentication options.
- The `testClientCreation` function tests the creation of a Supabase client instance and queries the database for data from a table. It verifies that data is returned from the query.
- The `testHelloWorld` function tests the "Hello-world" Edge Function by invoking it using the Supabase client's `functions.invoke` method. It checks if the response message matches the expected greeting.
- We run the tests using the `Deno.test` function, providing a descriptive name for each test case and the corresponding test function.

Make sure to replace the placeholders ( `supabaseUrl`, `supabaseKey`, `my_table`) with the actual values relevant to your Supabase setup.

## Running Edge Functions locally [\#](https://supabase.com/docs/guides/functions/unit-test\#running-edge-functions-locally)

To locally test and debug Edge Functions, you can utilize the Supabase CLI. Let's explore how to run Edge Functions locally using the Supabase CLI:

1. Ensure that the Supabase server is running by executing the following command:



`
supabase start
`

2. In your terminal, use the following command to serve the Edge Functions locally:



`
supabase functions serve
`



This command starts a local server that runs your Edge Functions, enabling you to test and debug them in a development environment.

3. Create the environment variables file:



`
# creates the file
touch .env
# adds the SUPABASE_URL secret
echo "SUPABASE_URL=http://localhost:54321" >> .env
# adds the SUPABASE_ANON_KEY secret
echo "SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZS1kZW1vIiwicm9sZSI6ImFub24iLCJleHAiOjE5ODM4MTI5OTZ9.CRXP1A7WOeoJeXxjNni43kdQwgnWNReilDMblYTn_I0" >> .env
# Alternatively, you can open it in your editor:
open .env
`

4. To run the tests, use the following command in your terminal:



`
deno test --allow-all supabase/functions/tests/function-one-test.ts
`


## Resources [\#](https://supabase.com/docs/guides/functions/unit-test\#resources)

- Full guide on Testing Supabase Edge Functions on [Mansueli's tips](https://blog.mansueli.com/testing-supabase-edge-functions-with-deno-test)

### Is this helpful?

NoYes

### On this page

[Testing in Deno](https://supabase.com/docs/guides/functions/unit-test#testing-in-deno) [Folder structure](https://supabase.com/docs/guides/functions/unit-test#folder-structure) [Example script](https://supabase.com/docs/guides/functions/unit-test#example-script) [Running Edge Functions locally](https://supabase.com/docs/guides/functions/unit-test#running-edge-functions-locally) [Resources](https://supabase.com/docs/guides/functions/unit-test#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_wasm.md">
Edge Functions

# Using Wasm modules

## How to use WebAssembly in Edge Functions.

* * *

Edge Functions supports running [WebAssembly (Wasm)](https://developer.mozilla.org/en-US/docs/WebAssembly) modules. WebAssembly is useful if you want to optimize code that's slower to run in JavaScript or require low-level manipulation.

It also gives you the option to port existing libraries written in other languages to be used with JavaScript. For example, [magick-wasm](https://supabase.com/docs/guides/functions/examples/image-manipulation), which does image manipulation and transforms, is a port of an existing C library to WebAssembly.

### Writing a Wasm module [\#](https://supabase.com/docs/guides/functions/wasm\#writing-a-wasm-module)

You can use different languages and SDKs to write Wasm modules. For this tutorial, we will write a simple Wasm module in Rust that adds two numbers.

Follow this [guide on writing Wasm modules in Rust](https://developer.mozilla.org/en-US/docs/WebAssembly/Rust_to_Wasm) to setup your dev environment.

Create a new Edge Function called `wasm-add`.

`
supabase functions new wasm-add
`

Create a new Cargo project for the Wasm module inside the function's directory:

`
cd supabase/functions/wasm-add
cargo new --lib add-wasm
`

Add the following code to `add-wasm/src/lib.rs`.

`
use wasm_bindgen::prelude::*;
#[wasm_bindgen]
pub fn add(a: u32, b: u32) -> u32 {
    a + b
}
`

[View source](https://github.com/supabase/supabase/blob/9b9cf69c7e6cf3b275a7f324e7556b2960368e3f/examples/edge-functions/supabase/functions/wasm-modules/add-wasm/src/lib.rs)

Update the `add-wasm/Cargo.toml` to include the `wasm-bindgen` dependency.

`
[package]
name = "add-wasm"
version = "0.1.0"
description = "A simple wasm module that adds two numbers"
license = "MIT/Apache-2.0"
edition = "2021"
[lib]
crate-type = ["cdylib"]
[dependencies]
wasm-bindgen = "0.2"
`

[View source](https://github.com/supabase/supabase/blob/9b9cf69c7e6cf3b275a7f324e7556b2960368e3f/examples/edge-functions/supabase/functions/wasm-modules/add-wasm/Cargo.toml)

After that we can build the package, by running:

`
wasm-pack build --target deno
`

This will produce a Wasm binary file inside `add-wasm/pkg` directory.

### Calling the Wasm module from the Edge Function [\#](https://supabase.com/docs/guides/functions/wasm\#calling-the-wasm-module-from-the-edge-function)

Now let's update the Edge Function to call `add` from the Wasm module.

index.ts

`
import { add } from "./add-wasm/pkg/add_wasm.js";
Deno.serve(async (req) => {
const { a, b } = await req.json();
return new Response(
    JSON.stringify({ result: add(a, b) }),
    { headers: { "Content-Type": "application/json" } },
);
});
`

[View source](https://github.com/supabase/supabase/blob/9b9cf69c7e6cf3b275a7f324e7556b2960368e3f/examples/edge-functions/supabase/functions/wasm-modules/index.ts)

Supabase Edge Functions currently use Deno 1.46. From [Deno 2.1, importing Wasm\\
modules](https://deno.com/blog/v2.1) will require even less boilerplate code.

### Bundle and deploy the Edge Function [\#](https://supabase.com/docs/guides/functions/wasm\#bundle-and-deploy-the-edge-function)

Before deploying the Edge Function, we need to ensure it bundles the Wasm module with it. We can do this by defining it in the `static_files` for the function in `superbase/config.toml`.

You will need update Supabase CLI to 2.7.0 or higher for the `static_files` support.

`
[functions.wasm-add]
static_files = [ "./functions/wasm-add/add-wasm/pkg/*"]
`

Deploy the function by running:

`
supabase functions deploy wasm-add
`

### Is this helpful?

NoYes

### On this page

[Writing a Wasm module](https://supabase.com/docs/guides/functions/wasm#writing-a-wasm-module) [Calling the Wasm module from the Edge Function](https://supabase.com/docs/guides/functions/wasm#calling-the-wasm-module-from-the-edge-function) [Bundle and deploy the Edge Function](https://supabase.com/docs/guides/functions/wasm#bundle-and-deploy-the-edge-function)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions_websockets.md">
Edge Functions

# Handling WebSockets

## How to handle WebSocket connections in Edge Functions

* * *

Edge Functions supports hosting WebSocket servers that can facilitate bi-directional communications with browser clients.

You can also establish outgoing WebSocket client connections to another server from Edge Functions (e.g., [OpenAI Realtime API](https://platform.openai.com/docs/guides/realtime/overview)). You can find an example OpenAI Realtime Relay Server implementation on the [supabase-community GitHub account](https://github.com/supabase-community/openai-realtime-console?tab=readme-ov-file#using-supabase-edge-functions-as-a-relay-server).

### Writing a WebSocket server [\#](https://supabase.com/docs/guides/functions/websockets\#writing-a-websocket-server)

Here are some basic examples of setting up WebSocket servers using Deno and Node.js APIs.

DenoNode.js

`
Deno.serve(req => {
    const upgrade = req.headers.get("upgrade") || "";
    if (upgrade.toLowerCase() != "WebSocket") {
        return new Response("request isn't trying to upgrade to WebSocket.", { status: 400 });
    }
    const { socket, response } = Deno.upgradeWebSocket(req);
    socket.onopen = () => console.log("socket opened");
    socket.onmessage = (e) => {
        console.log("socket message:", e.data);
        socket.send(new Date().toString());
    };
    socket.onerror = e => console.log("socket errored:", e.message);
    socket.onclose = () => console.log("socket closed");
    return response;
});
`

### Outbound WebSockets [\#](https://supabase.com/docs/guides/functions/websockets\#outbound-websockets)

You can also establish an outbound WebSocket connection to another server from an Edge Function.

Combining it with incoming WebSocket servers, it's possible to use Edge Functions as a WebSocket proxy, for example as a [relay server](https://github.com/supabase-community/openai-realtime-console?tab=readme-ov-file#using-supabase-edge-functions-as-a-relay-server) for the [OpenAI Realtime API](https://platform.openai.com/docs/guides/realtime/overview).

supabase/functions/relay/index.ts

``
import { createServer } from "node:http";
import { WebSocketServer } from "npm:ws";
import { RealtimeClient } from "https://raw.githubusercontent.com/openai/openai-realtime-api-beta/refs/heads/main/lib/client.js";
// ...
const OPENAI_API_KEY = Deno.env.get("OPENAI_API_KEY");
const server = createServer();
// Since we manually created the HTTP server,
// turn on the noServer mode.
const wss = new WebSocketServer({ noServer: true });
wss.on("connection", async (ws) => {
console.log("socket opened");
if (!OPENAI_API_KEY) {
    throw new Error("OPENAI_API_KEY is not set");
}
// Instantiate new client
console.log(`Connecting with key "${OPENAI_API_KEY.slice(0, 3)}..."`);
const client = new RealtimeClient({ apiKey: OPENAI_API_KEY });
// Relay: OpenAI Realtime API Event -> Browser Event
client.realtime.on("server.*", (event) => {
    console.log(`Relaying "${event.type}" to Client`);
    ws.send(JSON.stringify(event));
});
client.realtime.on("close", () => ws.close());
// Relay: Browser Event -> OpenAI Realtime API Event
// We need to queue data waiting for the OpenAI connection
const messageQueue = [];
const messageHandler = (data) => {
    try {
      const event = JSON.parse(data);
      console.log(`Relaying "${event.type}" to OpenAI`);
      client.realtime.send(event.type, event);
    } catch (e) {
      console.error(e.message);
      console.log(`Error parsing event from client: ${data}`);
    }
};
ws.on("message", (data) => {
    if (!client.isConnected()) {
      messageQueue.push(data);
    } else {
      messageHandler(data);
    }
});
ws.on("close", () => client.disconnect());
// Connect to OpenAI Realtime API
try {
    console.log(`Connecting to OpenAI...`);
    await client.connect();
} catch (e) {
    console.log(`Error connecting to OpenAI: ${e.message}`);
    ws.close();
    return;
}
console.log(`Connected to OpenAI successfully!`);
while (messageQueue.length) {
    messageHandler(messageQueue.shift());
}
});
server.on("upgrade", (req, socket, head) => {
wss.handleUpgrade(req, socket, head, (ws) => {
    wss.emit("connection", ws, req);
});
});
server.listen(8080);
``

[View source](https://github.com/supabase-community/openai-realtime-console/blob/0f93657a71670704fbf77c48cf54d6c9eb956698/supabase/functions/relay/index.ts)

### Authentication [\#](https://supabase.com/docs/guides/functions/websockets\#authentication)

WebSocket browser clients don't have the option to send custom headers. Because of this, Edge Functions won't be able to perform the usual authorization header check to verify the JWT.

You can skip the default authorization header checks by explicitly providing `--no-verify-jwt` when serving and deploying functions.

To authenticate the user making WebSocket requests, you can pass the JWT in URL query params or via a custom protocol.

Using query paramsUsing custom protocol

`
import { createClient } from "jsr:@supabase/supabase-js@2";
const supabase = createClient(
Deno.env.get("SUPABASE_URL"),
Deno.env.get("SUPABASE_SERVICE_ROLE_KEY"),
);
Deno.serve(req => {
const upgrade = req.headers.get("upgrade") || "";
    if (upgrade.toLowerCase() != "WebSocket") {
        return new Response("request isn't trying to upgrade to WebSocket.", { status: 400 });
    }
// Please be aware query params may be logged in some logging systems.
const url = new URL(req.url);
const jwt = url.searchParams.get("jwt");
if (!jwt) {
console.error("Auth token not provided");
return new Response("Auth token not provided", { status: 403 });
}
const { error, data } = await supabase.auth.getUser(jwt);
if (error) {
console.error(error);
return new Response("Invalid token provided", { status: 403 });
}
if (!data.user) {
console.error("user is not authenticated");
return new Response("User is not authenticated", { status: 403 });
}
    const { socket, response } = Deno.upgradeWebSocket(req);
    socket.onopen = () => console.log("socket opened");
    socket.onmessage = (e) => {
        console.log("socket message:", e.data);
        socket.send(new Date().toString());
    };
    socket.onerror = e => console.log("socket errored:", e.message);
    socket.onclose = () => console.log("socket closed");
    return response;
});
`

### Limits [\#](https://supabase.com/docs/guides/functions/websockets\#limits)

The maximum duration is capped based on the wall-clock, CPU, and memory limits. The Function will shutdown when it reaches one of these [limits](https://supabase.com/docs/guides/functions/limits).

### Testing WebSockets locally [\#](https://supabase.com/docs/guides/functions/websockets\#testing-websockets-locally)

When testing Edge Functions locally with Supabase CLI, the instances are terminated automatically after a request is completed. This will prevent keeping WebSocket connections open.

To prevent that, you can update the `supabase/config.toml` with the following settings:

`
[edge_runtime]
policy = "per_worker"
`

When running with `per_worker` policy, Function won't auto-reload on edits. You will need to manually restart it by running `supabase functions serve`.

### Is this helpful?

NoYes

### On this page

[Writing a WebSocket server](https://supabase.com/docs/guides/functions/websockets#writing-a-websocket-server) [Outbound WebSockets](https://supabase.com/docs/guides/functions/websockets#outbound-websockets) [Authentication](https://supabase.com/docs/guides/functions/websockets#authentication) [Limits](https://supabase.com/docs/guides/functions/websockets#limits) [Testing WebSockets locally](https://supabase.com/docs/guides/functions/websockets#testing-websockets-locally)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_functions.md">
Edge Functions

# Edge Functions

## Globally distributed TypeScript functions.

* * *

Edge Functions are server-side TypeScript functions, distributed globally at the edgeclose to your users. They can be used for listening to webhooks or integrating your Supabase project with third-parties [like Stripe](https://github.com/supabase/supabase/tree/master/examples/edge-functions/supabase/functions/stripe-webhooks). Edge Functions are developed using [Deno](https://deno.com/), which offers a few benefits to you as a developer:

- It is open source.
- It is portable. Supabase Edge Functions run locally, and on any other Deno-compatible platform (including self-hosted infrastructure).
- It is TypeScript first and supports WASM.
- Edge Functions are globally distributed for low-latency.

[Get started](https://supabase.com/docs/guides/functions/quickstart)

## Examples [\#](https://supabase.com/docs/guides/functions\#examples)

Check out the [Edge Function Examples](https://github.com/supabase/supabase/tree/master/examples/edge-functions) in our GitHub repository.

[![With supabase-js](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
With supabase-js\\
\\
Use the Supabase client inside your Edge Function.](https://supabase.com/docs/guides/functions/auth)

[![Type-Safe SQL with Kysely](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
Type-Safe SQL with Kysely\\
\\
Combining Kysely with Deno Postgres gives you a convenient developer experience for interacting directly with your Postgres database.](https://supabase.com/docs/guides/functions/kysely-postgres)

[![Monitoring with Sentry](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
Monitoring with Sentry\\
\\
Monitor Edge Functions with the Sentry Deno SDK.](https://supabase.com/docs/guides/functions/examples/sentry-monitoring)

[![With CORS headers](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
With CORS headers\\
\\
Send CORS headers for invoking from the browser.](https://supabase.com/docs/guides/functions/cors)

[![React Native with Stripe](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
React Native with Stripe\\
\\
Full example for using Supabase and Stripe, with Expo.](https://github.com/supabase-community/expo-stripe-payments-with-supabase-functions)

[![Flutter with Stripe](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
Flutter with Stripe\\
\\
Full example for using Supabase and Stripe, with Flutter.](https://github.com/supabase-community/flutter-stripe-payments-with-supabase-functions)

[![Building a RESTful Service API](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
Building a RESTful Service API\\
\\
Learn how to use HTTP methods and paths to build a RESTful service for managing tasks.](https://github.com/supabase/supabase/blob/master/examples/edge-functions/supabase/functions/restful-tasks/index.ts)

[![Working with Supabase Storage](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
Working with Supabase Storage\\
\\
An example on reading a file from Supabase Storage.](https://github.com/supabase/supabase/blob/master/examples/edge-functions/supabase/functions/read-storage/index.ts)

[![Open Graph Image Generation](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
Open Graph Image Generation\\
\\
Generate Open Graph images with Deno and Supabase Edge Functions.](https://supabase.com/docs/guides/functions/examples/og-image)

[![OG Image Generation & Storage CDN Caching](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
OG Image Generation & Storage CDN Caching\\
\\
Cache generated images with Supabase Storage CDN.](https://github.com/supabase/supabase/tree/master/examples/edge-functions/supabase/functions/og-image-with-storage-cdn)

[![Get User Location](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
Get User Location\\
\\
Get user location data from user's IP address.](https://github.com/supabase/supabase/tree/master/examples/edge-functions/supabase/functions/location)

[![Cloudflare Turnstile](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
Cloudflare Turnstile\\
\\
Protecting Forms with Cloudflare Turnstile.](https://supabase.com/docs/guides/functions/examples/cloudflare-turnstile)

[![Connect to Postgres](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
Connect to Postgres\\
\\
Connecting to Postgres from Edge Functions.](https://supabase.com/docs/guides/functions/connect-to-postgres)

[![Github Actions](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
Github Actions\\
\\
Deploying Edge Functions with GitHub Actions.](https://supabase.com/docs/guides/functions/examples/github-actions)

[![Oak Server Middleware](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
Oak Server Middleware\\
\\
Request Routing with Oak server middleware.](https://github.com/supabase/supabase/tree/master/examples/edge-functions/supabase/functions/oak-server)

[![Hugging Face](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
Hugging Face\\
\\
Access 100,000+ Machine Learning models.](https://supabase.com/docs/guides/ai/examples/huggingface-image-captioning)

[![Amazon Bedrock](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
Amazon Bedrock\\
\\
Amazon Bedrock Image Generator](https://supabase.com/docs/guides/functions/examples/amazon-bedrock-image-generator)

[![OpenAI](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
OpenAI\\
\\
Using OpenAI in Edge Functions.](https://supabase.com/docs/guides/ai/examples/openai)

[![Stripe Webhooks](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
Stripe Webhooks\\
\\
Handling signed Stripe Webhooks with Edge Functions.](https://supabase.com/docs/guides/functions/examples/stripe-webhooks)

[![Send emails](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
Send emails\\
\\
Send emails in Edge Functions with Resend.](https://supabase.com/docs/guides/functions/examples/send-emails)

[![Web Stream](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
Web Stream\\
\\
Server-Sent Events in Edge Functions.](https://github.com/supabase/supabase/tree/master/examples/edge-functions/supabase/functions/streams)

[![Puppeteer](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
Puppeteer\\
\\
Generate screenshots with Puppeteer.](https://supabase.com/docs/guides/functions/examples/screenshots)

[![Discord Bot](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
Discord Bot\\
\\
Building a Slash Command Discord Bot with Edge Functions.](https://supabase.com/docs/guides/functions/examples/discord-bot)

[![Telegram Bot](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
Telegram Bot\\
\\
Building a Telegram Bot with Edge Functions.](https://supabase.com/docs/guides/functions/examples/telegram-bot)

[![Upload File](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
Upload File\\
\\
Process multipart/form-data.](https://github.com/supabase/supabase/tree/master/examples/edge-functions/supabase/functions/file-upload-storage)

[![Upstash Redis](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
Upstash Redis\\
\\
Build an Edge Functions Counter with Upstash Redis.](https://supabase.com/docs/guides/functions/examples/upstash-redis)

[![Rate Limiting](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
Rate Limiting\\
\\
Rate Limiting Edge Functions with Upstash Redis.](https://supabase.com/docs/guides/functions/examples/rate-limiting)

[![Slack Bot Mention Edge Function](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
Slack Bot Mention Edge Function\\
\\
Slack Bot handling Slack mentions in Edge Function](https://supabase.com/docs/guides/functions/examples/slack-bot-mention)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_ai_prompts.md">
Getting Started

# AI Prompts

## Prompts for working with Supabase using AI-powered IDE tools

* * *

We've curated a selection of prompts to help you work with Supabase using your favorite AI-powered IDE tools, such as Cursor or GitHub Copilot.

## How to use [\#](https://supabase.com/docs/guides/getting-started/ai-prompts\#how-to-use)

Copy the prompt to a file in your repo.

Use the "include file" feature from your AI tool to include the prompt when chatting with your AI assistant. For example, in Cursor, add them as [project rules](https://docs.cursor.com/context/rules-for-ai#project-rules-recommended), with GitHub Copilot, use `#<filename>`, and in Zed, use `/file`.

## Prompts [\#](https://supabase.com/docs/guides/getting-started/ai-prompts\#prompts)

[Bootstrap Next.js app with Supabase Auth](https://supabase.com/docs/guides/getting-started/ai-prompts/nextjs-supabase-auth) [Writing Supabase Edge Functions](https://supabase.com/docs/guides/getting-started/ai-prompts/edge-functions) [Database: Create RLS policies](https://supabase.com/docs/guides/getting-started/ai-prompts/database-rls-policies) [Database: Create functions](https://supabase.com/docs/guides/getting-started/ai-prompts/database-functions) [Database: Create migration](https://supabase.com/docs/guides/getting-started/ai-prompts/database-create-migration) [Postgres SQL Style Guide](https://supabase.com/docs/guides/getting-started/ai-prompts/code-format-sql)

### Is this helpful?

NoYes

### On this page

[How to use](https://supabase.com/docs/guides/getting-started/ai-prompts#how-to-use) [Prompts](https://supabase.com/docs/guides/getting-started/ai-prompts#prompts)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_architecture.md">
Getting Started

# Architecture

* * *

Supabase is open source. We choose open source tools which are scalable and make them simple to use.

Supabase is not a 1-to-1 mapping of Firebase. While we are building many of the features that Firebase offers, we are not going about it the same way:
our technological choices are quite different; everything we use is open source; and wherever possible, we use and support existing tools rather than developing from scratch.

Most notably, we use Postgres rather than a NoSQL store. This choice was deliberate. We believe that no other database offers the functionality required to compete with Firebase, while maintaining the scalability required to go beyond it.

## Choose your comfort level [\#](https://supabase.com/docs/guides/getting-started/architecture\#choose-your-comfort-level)

Our goal at Supabase is to make _all_ of Postgres easy to use. That doesnt mean you have to use all of it. If youre a Postgres veteran, youll probably love the tools that we offer. If youve never used Postgres before, then start smaller and grow into it. If you just want to treat Postgres like a simple table-store, thats perfectly fine.

## Architecture [\#](https://supabase.com/docs/guides/getting-started/architecture\#architecture)

Each Supabase project consists of several tools:

![Diagram showing the architecture of Supabase. The Kong API gateway sits in front of 7 services: GoTrue, PostgREST, Realtime, Storage, pg_meta, Functions, and pg_graphql. All the services talk to a single Postgres instance.](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fsupabase-architecture--light.svg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Postgres (database) [\#](https://supabase.com/docs/guides/getting-started/architecture\#postgres-database)

Postgres is the core of Supabase. We do not abstract the Postgres databaseyou can access it and use it with full privileges. We provide tools which makes Postgres as easy to use as Firebase.

- Official Docs: [postgresql.org/docs](https://www.postgresql.org/docs/current/index.html)
- Source code: [github.com/postgres/postgres](https://github.com/postgres/postgres) (mirror)
- License: [PostgreSQL License](https://www.postgresql.org/about/licence/)\- Language: C

### Studio (dashboard) [\#](https://supabase.com/docs/guides/getting-started/architecture\#studio-dashboard)

An open source Dashboard for managing your database and services.

- Official Docs: [Supabase docs](https://supabase.com/docs)
- Source code: [github.com/supabase/supabase](https://github.com/supabase/supabase/tree/master/apps/studio)
- License: [Apache 2](https://github.com/supabase/supabase/blob/master/LICENSE)
- Language: TypeScript

### GoTrue (Auth) [\#](https://supabase.com/docs/guides/getting-started/architecture\#gotrue-auth)

A JWT-based API for managing users and issuing access tokens. This integrates with PostgreSQL's Row Level Security and the API servers.

- Official Docs: [Supabase Auth reference docs](https://supabase.com/docs/reference/auth)
- Source code: [github.com/supabase/gotrue](https://github.com/supabase/gotrue)
- License: [MIT](https://github.com/supabase/gotrue/blob/master/LICENSE)
- Language: Go

### PostgREST (API) [\#](https://supabase.com/docs/guides/getting-started/architecture\#postgrest-api)

A standalone web server that turns your Postgres database directly into a RESTful API.
We use this with our [`pg_graphql`](https://github.com/supabase/pg_graphql) extension to provide a GraphQL API.

- Official Docs: [postgrest.org](https://postgrest.org/)
- Source code: [github.com/PostgREST/postgrest](https://github.com/PostgREST/postgrest)
- License: [MIT](https://github.com/PostgREST/postgrest/blob/main/LICENSE)
- Language: Haskell

### Realtime (API & multiplayer) [\#](https://supabase.com/docs/guides/getting-started/architecture\#realtime-api--multiplayer)

A scalable WebSocket engine for managing user Presence, broadcasting messages, and streaming database changes.

- Official Docs: [Supabase Realtime docs](https://supabase.com/docs/guides/realtime)
- Source code: [github.com/supabase/realtime](https://github.com/supabase/realtime)
- License: [Apache 2](https://github.com/supabase/realtime/blob/main/LICENSE)
- Language: Elixir

### Storage API (large file storage) [\#](https://supabase.com/docs/guides/getting-started/architecture\#storage-api-large-file-storage)

An S3-compatible object storage service that stores metadata in Postgres.

- Official Docs: [Supabase Storage reference docs](https://supabase.com/docs/reference/storage)
- Source code: [github.com/supabase/storage-api](https://github.com/supabase/storage-api)
- License: [Apache 2.0](https://github.com/supabase/storage-api/blob/master/LICENSE)
- Language: Node.js / TypeScript

### Deno (Edge Functions) [\#](https://supabase.com/docs/guides/getting-started/architecture\#deno-edge-functions)

A modern runtime for JavaScript and TypeScript.

- Official Docs: [Deno documentation](https://deno.land/)
- Source code: [Deno source code](https://github.com/denoland/deno)
- License: [MIT](https://github.com/denoland/deno/blob/main/LICENSE.md)
- Language: TypeScript / Rust

### `postgres-meta` (database management) [\#](https://supabase.com/docs/guides/getting-started/architecture\#postgres-meta-database-management)

A RESTful API for managing your Postgres. Fetch tables, add roles, and run queries.

- Official Docs: [supabase.github.io/postgres-meta](https://supabase.github.io/postgres-meta/)
- Source code: [github.com/supabase/postgres-meta](https://github.com/supabase/postgres-meta)
- License: [Apache 2.0](https://github.com/supabase/postgres-meta/blob/master/LICENSE)
- Language: Node.js / TypeScript

### Supavisor [\#](https://supabase.com/docs/guides/getting-started/architecture\#supavisor)

A cloud-native, multi-tenant Postgres connection pooler.

- Official Docs: [Supavisor GitHub Pages](https://supabase.github.io/supavisor/)
- Source code: [`supabase/supavisor`](https://github.com/supabase/supavisor)
- License: [Apache 2.0](https://github.com/supabase/supavisor/blob/main/LICENSE)
- Language: Elixir

### Kong (API gateway) [\#](https://supabase.com/docs/guides/getting-started/architecture\#kong-api-gateway)

A cloud-native API gateway, built on top of NGINX.

- Official Docs: [docs.konghq.com](https://docs.konghq.com/)
- Source code: [github.com/kong/kong](https://github.com/kong/kong)
- License: [Apache 2.0](https://github.com/Kong/kong/blob/master/LICENSE)
- Language: Lua

## Product principles [\#](https://supabase.com/docs/guides/getting-started/architecture\#product-principles)

It is our goal to provide an architecture that any large-scale company would design for themselves,
and then provide tooling around that architecture that is easy-to-use for indie-developers and small teams.

We use a series of principles to ensure that scalability and usability are never mutually exclusive:

### Everything works in isolation [\#](https://supabase.com/docs/guides/getting-started/architecture\#everything-works-in-isolation)

Each system must work as a standalone tool with as few moving parts as possible.
The litmus test for this is: "Can a user run this product with nothing but a Postgres database?"

### Everything is integrated [\#](https://supabase.com/docs/guides/getting-started/architecture\#everything-is-integrated)

Supabase is composable. Even though every product works in isolation, each product on the platform needs to 10x the other products.
For integration, each tool should expose an API and Webhooks.

### Everything is extensible [\#](https://supabase.com/docs/guides/getting-started/architecture\#everything-is-extensible)

We're deliberate about adding a new tool, and prefer instead to extend an existing one.
This is the opposite of many cloud providers whose product offering expands into niche use-cases. We provide _primitives_ for developers, which allow them to achieve any goal.
Less, but better.

### Everything is portable [\#](https://supabase.com/docs/guides/getting-started/architecture\#everything-is-portable)

To avoid lock-in, we make it easy to migrate in and out. Our cloud offering is compatible with our self-hosted product.
We use existing standards to increase portability (like `pg_dump` and CSV files). If a new standard emerges which competes with a "Supabase" approach, we will deprecate the approach in favor of the standard.
This forces us to compete on user experience. We aim to be the best Postgres hosting service.

### Play the long game [\#](https://supabase.com/docs/guides/getting-started/architecture\#play-the-long-game)

We sacrifice short-term wins for long-term gains. For example, it is tempting to run a fork of Postgres with additional functionality which only our customers need.
Instead, we prefer to support efforts to upstream missing functionality so that the entire community benefits. This has the additional benefit of ensuring portability and longevity.

### Build for developers [\#](https://supabase.com/docs/guides/getting-started/architecture\#build-for-developers)

"Developers" are a specific profile of user: they are _builders_.
When assessing impact as a function of effort, developers have a large efficiency due to the type of products and systems they can build.
As the profile of a developer changes over time, Supabase will continue to evolve the product to fit this evolving profile.

### Support existing tools [\#](https://supabase.com/docs/guides/getting-started/architecture\#support-existing-tools)

Supabase supports existing tools and communities wherever possible. Supabase is more like a "community of communities" - each tool typically has its own community which we work with.
Open source is something we approach [collaboratively](https://supabase.com/blog/supabase-series-b#giving-back): we employ maintainers, sponsor projects, invest in businesses, and develop our own open source tools.

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2FT-qAtAKjqwc%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Choose your comfort level](https://supabase.com/docs/guides/getting-started/architecture#choose-your-comfort-level) [Architecture](https://supabase.com/docs/guides/getting-started/architecture#architecture) [Postgres (database)](https://supabase.com/docs/guides/getting-started/architecture#postgres-database) [Studio (dashboard)](https://supabase.com/docs/guides/getting-started/architecture#studio-dashboard) [GoTrue (Auth)](https://supabase.com/docs/guides/getting-started/architecture#gotrue-auth) [PostgREST (API)](https://supabase.com/docs/guides/getting-started/architecture#postgrest-api) [Realtime (API & multiplayer)](https://supabase.com/docs/guides/getting-started/architecture#realtime-api--multiplayer) [Storage API (large file storage)](https://supabase.com/docs/guides/getting-started/architecture#storage-api-large-file-storage) [Deno (Edge Functions)](https://supabase.com/docs/guides/getting-started/architecture#deno-edge-functions) [postgres-meta (database management)](https://supabase.com/docs/guides/getting-started/architecture#postgres-meta-database-management) [Supavisor](https://supabase.com/docs/guides/getting-started/architecture#supavisor) [Kong (API gateway)](https://supabase.com/docs/guides/getting-started/architecture#kong-api-gateway) [Product principles](https://supabase.com/docs/guides/getting-started/architecture#product-principles) [Everything works in isolation](https://supabase.com/docs/guides/getting-started/architecture#everything-works-in-isolation) [Everything is integrated](https://supabase.com/docs/guides/getting-started/architecture#everything-is-integrated) [Everything is extensible](https://supabase.com/docs/guides/getting-started/architecture#everything-is-extensible) [Everything is portable](https://supabase.com/docs/guides/getting-started/architecture#everything-is-portable) [Play the long game](https://supabase.com/docs/guides/getting-started/architecture#play-the-long-game) [Build for developers](https://supabase.com/docs/guides/getting-started/architecture#build-for-developers) [Support existing tools](https://supabase.com/docs/guides/getting-started/architecture#support-existing-tools)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_features.md">
Getting Started

# Features

* * *

This is a non-exhaustive list of features that Supabase provides for every project.

## Database [\#](https://supabase.com/docs/guides/getting-started/features\#database)

### Postgres database [\#](https://supabase.com/docs/guides/getting-started/features\#postgres-database)

Every project is a full Postgres database. [Docs](https://supabase.com/docs/guides/database).

### Vector database [\#](https://supabase.com/docs/guides/getting-started/features\#vector-database)

Store vector embeddings right next to the rest of your data. [Docs](https://supabase.com/docs/guides/ai).

### Auto-generated REST API via PostgREST [\#](https://supabase.com/docs/guides/getting-started/features\#auto-generated-rest-api-via-postgrest)

RESTful APIs are auto-generated from your database, without a single line of code. [Docs](https://supabase.com/docs/guides/api#rest-api-overview).

### Auto-generated GraphQL API via pg\_graphql [\#](https://supabase.com/docs/guides/getting-started/features\#auto-generated-graphql-api-via-pggraphql)

Fast GraphQL APIs using our custom Postgres GraphQL extension. [Docs](https://supabase.com/docs/guides/graphql/api).

### Database webhooks [\#](https://supabase.com/docs/guides/getting-started/features\#database-webhooks)

Send database changes to any external service using Webhooks. [Docs](https://supabase.com/docs/guides/database/webhooks).

### Secrets and encryption [\#](https://supabase.com/docs/guides/getting-started/features\#secrets-and-encryption)

Encrypt sensitive data and store secrets using our Postgres extension, Supabase Vault. [Docs](https://supabase.com/docs/guides/database/vault).

## Platform [\#](https://supabase.com/docs/guides/getting-started/features\#platform)

### Database backups [\#](https://supabase.com/docs/guides/getting-started/features\#database-backups)

Projects are backed up daily with the option to upgrade to Point in Time recovery. [Docs](https://supabase.com/docs/guides/platform/backups).

### Custom domains [\#](https://supabase.com/docs/guides/getting-started/features\#custom-domains)

White-label the Supabase APIs to create a branded experience for your users. [Docs](https://supabase.com/docs/guides/platform/custom-domains).

### Network restrictions [\#](https://supabase.com/docs/guides/getting-started/features\#network-restrictions)

Restrict IP ranges that can connect to your database. [Docs](https://supabase.com/docs/guides/platform/network-restrictions).

### SSL enforcement [\#](https://supabase.com/docs/guides/getting-started/features\#ssl-enforcement)

Enforce Postgres clients to connect via SSL. [Docs](https://supabase.com/docs/guides/platform/ssl-enforcement).

### Branching [\#](https://supabase.com/docs/guides/getting-started/features\#branching)

Use Supabase Branches to test and preview changes. [Docs](https://supabase.com/docs/guides/platform/branching).

### Terraform provider [\#](https://supabase.com/docs/guides/getting-started/features\#terraform-provider)

Manage Supabase infrastructure via Terraform, an Infrastructure as Code tool. [Docs](https://supabase.com/docs/guides/platform/terraform).

### Read replicas [\#](https://supabase.com/docs/guides/getting-started/features\#read-replicas)

Deploy read-only databases across multiple regions, for lower latency and better resource management. [Docs](https://supabase.com/docs/guides/platform/read-replicas).

### Log drains [\#](https://supabase.com/docs/guides/getting-started/features\#log-drains)

Export Supabase logs at to 3rd party providers and external tooling. [Docs](https://supabase.com/docs/guides/platform/log-drains).

## Studio [\#](https://supabase.com/docs/guides/getting-started/features\#studio)

### Studio Single Sign-On [\#](https://supabase.com/docs/guides/getting-started/features\#studio-single-sign-on)

Login to the Supabase dashboard via SSO. [Docs](https://supabase.com/docs/guides/platform/sso).

## Realtime [\#](https://supabase.com/docs/guides/getting-started/features\#realtime)

### Postgres changes [\#](https://supabase.com/docs/guides/getting-started/features\#postgres-changes)

Receive your database changes through WebSockets. [Docs](https://supabase.com/docs/guides/realtime/postgres-changes).

### Broadcast [\#](https://supabase.com/docs/guides/getting-started/features\#broadcast)

Send messages between connected users through WebSockets. [Docs](https://supabase.com/docs/guides/realtime/broadcast).

### Presence [\#](https://supabase.com/docs/guides/getting-started/features\#presence)

Synchronize shared state across your users, including online status and typing indicators. [Docs](https://supabase.com/docs/guides/realtime/presence).

## Auth [\#](https://supabase.com/docs/guides/getting-started/features\#auth)

### Email login [\#](https://supabase.com/docs/guides/getting-started/features\#email-login)

Build email logins for your application or website. [Docs](https://supabase.com/docs/guides/auth/auth-email).

### Social login [\#](https://supabase.com/docs/guides/getting-started/features\#social-login)

Provide social logins - everything from Apple, to GitHub, to Slack. [Docs](https://supabase.com/docs/guides/auth/social-login).

### Phone logins [\#](https://supabase.com/docs/guides/getting-started/features\#phone-logins)

Provide phone logins using a third-party SMS provider. [Docs](https://supabase.com/docs/guides/auth/phone-login).

### Passwordless login [\#](https://supabase.com/docs/guides/getting-started/features\#passwordless-login)

Build passwordless logins via magic links for your application or website. [Docs](https://supabase.com/docs/guides/auth/auth-magic-link).

### Authorization via Row Level Security [\#](https://supabase.com/docs/guides/getting-started/features\#authorization-via-row-level-security)

Control the data each user can access with Postgres Policies. [Docs](https://supabase.com/docs/guides/database/postgres/row-level-security).

### CAPTCHA protection [\#](https://supabase.com/docs/guides/getting-started/features\#captcha-protection)

Add CAPTCHA to your sign-in, sign-up, and password reset forms. [Docs](https://supabase.com/docs/guides/auth/auth-captcha).

### Server-Side Auth [\#](https://supabase.com/docs/guides/getting-started/features\#server-side-auth)

Helpers for implementing user authentication in popular server-side languages and frameworks like Next.js, SvelteKit and Remix. [Docs](https://supabase.com/docs/guides/auth/server-side).

## Storage [\#](https://supabase.com/docs/guides/getting-started/features\#storage)

### File storage [\#](https://supabase.com/docs/guides/getting-started/features\#file-storage)

Supabase Storage makes it simple to store and serve files. [Docs](https://supabase.com/docs/guides/storage).

### Content Delivery Network [\#](https://supabase.com/docs/guides/getting-started/features\#content-delivery-network)

Cache large files using the Supabase CDN. [Docs](https://supabase.com/docs/guides/storage/cdn/fundamentals).

### Smart Content Delivery Network [\#](https://supabase.com/docs/guides/getting-started/features\#smart-content-delivery-network)

Automatically revalidate assets at the edge via the Smart CDN. [Docs](https://supabase.com/docs/guides/storage/cdn/smart-cdn).

### Image transformations [\#](https://supabase.com/docs/guides/getting-started/features\#image-transformations)

Transform images on the fly. [Docs](https://supabase.com/docs/guides/storage/serving/image-transformations).

### Resumable uploads [\#](https://supabase.com/docs/guides/getting-started/features\#resumable-uploads)

Upload large files using resumable uploads. [Docs](https://supabase.com/docs/guides/storage/uploads/resumable-uploads).

### S3 compatibility [\#](https://supabase.com/docs/guides/getting-started/features\#s3-compatibility)

Interact with Storage from tool which supports the S3 protocol. [Docs](https://supabase.com/docs/guides/storage/s3/compatibility).

## Edge Functions [\#](https://supabase.com/docs/guides/getting-started/features\#edge-functions)

### Deno Edge Functions [\#](https://supabase.com/docs/guides/getting-started/features\#deno-edge-functions)

Globally distributed TypeScript functions to execute custom business logic. [Docs](https://supabase.com/docs/guides/functions).

### Regional invocations [\#](https://supabase.com/docs/guides/getting-started/features\#regional-invocations)

Execute an Edge Function in a region close to your database. [Docs](https://supabase.com/docs/guides/functions/regional-invocation).

### NPM compatibility [\#](https://supabase.com/docs/guides/getting-started/features\#npm-compatibility)

Edge functions natively support NPM modules and Node built-in APIs. [Link](https://supabase.com/blog/edge-functions-node-npm).

## Project management [\#](https://supabase.com/docs/guides/getting-started/features\#project-management)

### CLI [\#](https://supabase.com/docs/guides/getting-started/features\#cli)

Use our CLI to develop your project locally and deploy to the Supabase Platform. [Docs](https://supabase.com/docs/reference/cli).

### Management API [\#](https://supabase.com/docs/guides/getting-started/features\#management-api)

Manage your projects programmatically. [Docs](https://supabase.com/docs/reference/api).

## Client libraries [\#](https://supabase.com/docs/guides/getting-started/features\#client-libraries)

Official client libraries for [JavaScript](https://supabase.com/docs/reference/javascript/start), [Flutter](https://supabase.com/docs/reference/dart/initializing) and [Swift](https://supabase.com/docs/reference/swift/introduction).
Unofficial libraries are supported by the community.

## Feature status [\#](https://supabase.com/docs/guides/getting-started/features\#feature-status)

Supabase Features are in 4 different states - Private Alpha, Public Alpha, Beta and Generally Available.

### Private alpha [\#](https://supabase.com/docs/guides/getting-started/features\#private-alpha)

Features are initially launched as a private alpha to gather feedback from the community. To join our early access program, send an email to [product-ops@supabase.io](mailto:product-ops@supabase.io).

### Public alpha [\#](https://supabase.com/docs/guides/getting-started/features\#public-alpha)

The alpha stage indicates that the API might change in the future, not that the service isnt stable. Even though the [uptime Service Level Agreement](https://supabase.com/sla) does not cover products in Alpha, we do our best to have the service as stable as possible.

### Beta [\#](https://supabase.com/docs/guides/getting-started/features\#beta)

Features in Beta are tested by an external penetration tester for security issues. The API is guaranteed to be stable and there is a strict communication process for breaking changes.

### Generally available [\#](https://supabase.com/docs/guides/getting-started/features\#generally-available)

In addition to the Beta requirements, features in GA are covered by the [uptime SLA](https://supabase.com/sla).

| Product | Feature | Stage | Available on self-hosted |
| --- | --- | --- | --- |
| Database | Postgres | `GA` |  |
| Database | Vector Database | `GA` |  |
| Database | Auto-generated Rest API | `GA` |  |
| Database | Auto-generated GraphQL API | `GA` |  |
| Database | Webhooks | `beta` |  |
| Database | Vault | `public alpha` |  |
| Platform |  | `GA` |  |
| Platform | Point-in-Time Recovery | `GA` | [wal-g](https://github.com/wal-g/wal-g) |
| Platform | Custom Domains | `GA` | N/A |
| Platform | Network Restrictions | `beta` | N/A |
| Platform | SSL enforcement | `GA` | N/A |
| Platform | Branching | `public alpha` | N/A |
| Platform | Terraform Provider | `public alpha` | N/A |
| Platform | Read Replicas | `private alpha` | N/A |
| Platform | Log Drains | `public alpha` |  |
| Studio |  | `GA` |  |
| Studio | SSO | `GA` |  |
| Realtime | Postgres Changes | `GA` |  |
| Realtime | Broadcast | `GA` |  |
| Realtime | Presence | `GA` |  |
| Realtime | Broadcast Authorization | `public beta` |  |
| Realtime | Presence Authorization | `public beta` |  |
| Storage |  | `GA` |  |
| Storage | CDN | `GA` |  [Cloudflare](https://www.cloudflare.com/) |
| Storage | Smart CDN | `GA` |  [Cloudflare](https://www.cloudflare.com/) |
| Storage | Image Transformations | `GA` |  |
| Storage | Resumable Uploads | `GA` |  |
| Storage | S3 compatibility | `public alpha` |  |
| Edge Functions |  | `beta` |  |
| Edge Functions | Regional Invocations | `beta` |  |
| Edge Functions | NPM compatibility | `beta` |  |
| Auth |  | `GA` |  |
| Auth | Email login | `GA` |  |
| Auth | Social login | `GA` |  |
| Auth | Phone login | `GA` |  |
| Auth | Passwordless login | `GA` |  |
| Auth | SSO with SAML | `GA` |  |
| Auth | Authorization via RLS | `GA` |  |
| Auth | CAPTCHA protection | `GA` |  |
| Auth | Server-side Auth | `beta` |  |
| CLI |  | `GA` |  Works with self-hosted |
| Management API |  | `GA` | N/A |
| Client Library | JavaScript | `GA` | N/A |
| Client Library | Flutter | `beta` | N/A |
| Client Library | Swift | `beta` | N/A |

-  = Fully Available
-  = Available, but requires external tools or configuration

### Is this helpful?

NoYes

### On this page

[Database](https://supabase.com/docs/guides/getting-started/features#database) [Postgres database](https://supabase.com/docs/guides/getting-started/features#postgres-database) [Vector database](https://supabase.com/docs/guides/getting-started/features#vector-database) [Auto-generated REST API via PostgREST](https://supabase.com/docs/guides/getting-started/features#auto-generated-rest-api-via-postgrest) [Auto-generated GraphQL API via pg\_graphql](https://supabase.com/docs/guides/getting-started/features#auto-generated-graphql-api-via-pggraphql) [Database webhooks](https://supabase.com/docs/guides/getting-started/features#database-webhooks) [Secrets and encryption](https://supabase.com/docs/guides/getting-started/features#secrets-and-encryption) [Platform](https://supabase.com/docs/guides/getting-started/features#platform) [Database backups](https://supabase.com/docs/guides/getting-started/features#database-backups) [Custom domains](https://supabase.com/docs/guides/getting-started/features#custom-domains) [Network restrictions](https://supabase.com/docs/guides/getting-started/features#network-restrictions) [SSL enforcement](https://supabase.com/docs/guides/getting-started/features#ssl-enforcement) [Branching](https://supabase.com/docs/guides/getting-started/features#branching) [Terraform provider](https://supabase.com/docs/guides/getting-started/features#terraform-provider) [Read replicas](https://supabase.com/docs/guides/getting-started/features#read-replicas) [Log drains](https://supabase.com/docs/guides/getting-started/features#log-drains) [Studio](https://supabase.com/docs/guides/getting-started/features#studio) [Studio Single Sign-On](https://supabase.com/docs/guides/getting-started/features#studio-single-sign-on) [Realtime](https://supabase.com/docs/guides/getting-started/features#realtime) [Postgres changes](https://supabase.com/docs/guides/getting-started/features#postgres-changes) [Broadcast](https://supabase.com/docs/guides/getting-started/features#broadcast) [Presence](https://supabase.com/docs/guides/getting-started/features#presence) [Auth](https://supabase.com/docs/guides/getting-started/features#auth) [Email login](https://supabase.com/docs/guides/getting-started/features#email-login) [Social login](https://supabase.com/docs/guides/getting-started/features#social-login) [Phone logins](https://supabase.com/docs/guides/getting-started/features#phone-logins) [Passwordless login](https://supabase.com/docs/guides/getting-started/features#passwordless-login) [Authorization via Row Level Security](https://supabase.com/docs/guides/getting-started/features#authorization-via-row-level-security) [CAPTCHA protection](https://supabase.com/docs/guides/getting-started/features#captcha-protection) [Server-Side Auth](https://supabase.com/docs/guides/getting-started/features#server-side-auth) [Storage](https://supabase.com/docs/guides/getting-started/features#storage) [File storage](https://supabase.com/docs/guides/getting-started/features#file-storage) [Content Delivery Network](https://supabase.com/docs/guides/getting-started/features#content-delivery-network) [Smart Content Delivery Network](https://supabase.com/docs/guides/getting-started/features#smart-content-delivery-network) [Image transformations](https://supabase.com/docs/guides/getting-started/features#image-transformations) [Resumable uploads](https://supabase.com/docs/guides/getting-started/features#resumable-uploads) [S3 compatibility](https://supabase.com/docs/guides/getting-started/features#s3-compatibility) [Edge Functions](https://supabase.com/docs/guides/getting-started/features#edge-functions) [Deno Edge Functions](https://supabase.com/docs/guides/getting-started/features#deno-edge-functions) [Regional invocations](https://supabase.com/docs/guides/getting-started/features#regional-invocations) [NPM compatibility](https://supabase.com/docs/guides/getting-started/features#npm-compatibility) [Project management](https://supabase.com/docs/guides/getting-started/features#project-management) [CLI](https://supabase.com/docs/guides/getting-started/features#cli) [Management API](https://supabase.com/docs/guides/getting-started/features#management-api) [Client libraries](https://supabase.com/docs/guides/getting-started/features#client-libraries) [Feature status](https://supabase.com/docs/guides/getting-started/features#feature-status) [Private alpha](https://supabase.com/docs/guides/getting-started/features#private-alpha) [Public alpha](https://supabase.com/docs/guides/getting-started/features#public-alpha) [Beta](https://supabase.com/docs/guides/getting-started/features#beta) [Generally available](https://supabase.com/docs/guides/getting-started/features#generally-available)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_mcp.md">
Getting Started

# Model context protocol (MCP)

* * *

The [Model Context Protocol](https://modelcontextprotocol.io/introduction) (MCP) is a standard for connecting Large Language Models (LLMs) to external services. This guide will walk you through how to connect AI tools to Supabase using MCP.

There are a number of popular AI tools that support MCP, including:

- [Cursor](https://www.cursor.com/)
- [Claude desktop](https://claude.ai/download)
- [Cline](https://github.com/cline/cline) (VS Code extension)
- [Windsurf](https://docs.codeium.com/windsurf) (Codium)

Connecting these tools to Supabase will allow you to query your database and perform other SQL operations using natural language commands.

## Connect to Supabase using MCP [\#](https://supabase.com/docs/guides/getting-started/mcp\#connect-to-supabase-using-mcp)

We will use the [Postgres MCP server](https://github.com/modelcontextprotocol/servers/tree/main/src/postgres) to connect AI tools to Supabase.

### Step 1: Find your database connection string [\#](https://supabase.com/docs/guides/getting-started/mcp\#step-1-find-your-database-connection-string)

To get started, you will need to retrieve your database connection string. These will differ depending on whether you are using a local or hosted instance of Supabase.

#### For a local Supabase instance [\#](https://supabase.com/docs/guides/getting-started/mcp\#for-a-local-supabase-instance)

When running a local instance of Supabase via the [CLI](https://supabase.com/docs/reference/cli/introduction), you can find your connection string by running:

`
supabase status
`

or if you are using `npx`:

`
npx supabase status
`

This will output a list of details about your local Supabase instance. Copy the `DB URL` field in the output.

#### For a hosted Supabase instance [\#](https://supabase.com/docs/guides/getting-started/mcp\#for-a-hosted-supabase-instance)

When running a hosted instance of Supabase, you can find your connection string by:

1. Navigating to your project's [Connection settings](https://supabase.com/dashboard/project/_/settings/database?showConnect=true)
2. Copying the connection string found under **Session pooler**.

### Step 2: Configure in your AI tool [\#](https://supabase.com/docs/guides/getting-started/mcp\#step-2-configure-in-your-ai-tool)

All MCP compatible tools can connect to Supabase using the [Postgres MCP server](https://github.com/modelcontextprotocol/servers/tree/main/src/postgres). Pass the following CLI command to your tool:

`
npx -y @modelcontextprotocol/server-postgres <connection-string>
`

Replace `<connection-string>` with the connection string you retrieved in Step 1.

This assumes you have Node.js and npx installed. If you don't have Node.js or prefer to connect to the server using Docker, you can follow the instructions in the [Postgres MCP server README](https://github.com/modelcontextprotocol/servers/tree/main/src/postgres#docker).

Below are some ways to connect to the Postgres MCP server using popular AI tools:

#### Cursor [\#](https://supabase.com/docs/guides/getting-started/mcp\#cursor)

1. Open Cursor and open `.cursor/mcp.json` file. Create the file if it doesn't exist.

2. Add the following configuration:



`
{
"mcpServers": {
       "supabase": {
         "command": "npx",
         "args": ["-y", "@modelcontextprotocol/server-postgres", "<connection-string>"]
       }
}
}
`



Replace `<connection-string>` with your connection string.

3. Save the configuration file.

4. Open Cursor and navigate to **Settings/MCP**. You should see a green active status after the server is successfully connected.


#### Claude desktop [\#](https://supabase.com/docs/guides/getting-started/mcp\#claude-desktop)

1. Open Claude desktop and navigate to **Settings**.

2. Under the **Developer** tab, tap **Edit Config** to open the configuration file.

3. Add the following configuration:



`
{
"mcpServers": {
       "supabase": {
         "command": "npx",
         "args": ["-y", "@modelcontextprotocol/server-postgres", "<connection-string>"]
       }
}
}
`



Replace `<connection-string>` with your connection string.

4. Save the configuration file and restart Claude desktop.

5. From the new chat screen, you should see a hammer (MCP) icon appear with the new MCP server available.


#### Cline [\#](https://supabase.com/docs/guides/getting-started/mcp\#cline)

1. Open the Cline extension in VS Code and tap the **MCP Servers** icon.

2. Tap **Configure MCP Servers** to open the configuration file.

3. Add the following configuration:



`
{
"mcpServers": {
       "supabase": {
         "command": "npx",
         "args": ["-y", "@modelcontextprotocol/server-postgres", "<connection-string>"]
       }
}
}
`



Replace `<connection-string>` with your connection string.

4. Save the configuration file. Cline should automatically reload the configuration.

5. You should see a green active status after the server is successfully connected.


#### Windsurf [\#](https://supabase.com/docs/guides/getting-started/mcp\#windsurf)

1. Open Windsurf and navigate to the Cascade assistant.

2. Tap on the hammer (MCP) icon, then **Configure** to open the configuration file.

3. Add the following configuration:



`
{
"mcpServers": {
       "supabase": {
         "command": "npx",
         "args": ["-y", "@modelcontextprotocol/server-postgres", "<connection-string>"]
       }
}
}
`



Replace `<connection-string>` with your connection string.

4. Save the configuration file and reload by tapping **Refresh** in the Cascade assistant.

5. You should see a green active status after the server is successfully connected.


## Next steps [\#](https://supabase.com/docs/guides/getting-started/mcp\#next-steps)

You are now connected to Supabase using MCP! You can now interact with your database using natural language commands. Try asking your AI tool to query your database, create a new table, or perform other SQL operations.

### Is this helpful?

NoYes

### On this page

[Connect to Supabase using MCP](https://supabase.com/docs/guides/getting-started/mcp#connect-to-supabase-using-mcp) [Step 1: Find your database connection string](https://supabase.com/docs/guides/getting-started/mcp#step-1-find-your-database-connection-string) [Step 2: Configure in your AI tool](https://supabase.com/docs/guides/getting-started/mcp#step-2-configure-in-your-ai-tool) [Next steps](https://supabase.com/docs/guides/getting-started/mcp#next-steps)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_quickstarts_flutter.md">
Getting Started

# Use Supabase with Flutter

## Learn how to create a Supabase project, add some sample data to your database, and query the data from a Flutter app.

* * *

1

### Create a Supabase project

Go to [database.new](https://database.new/) and create a new Supabase project.

When your project is up and running, go to the [Table Editor](https://supabase.com/dashboard/project/_/editor), create a new table and insert some data.

Alternatively, you can run the following snippet in your project's [SQL Editor](https://supabase.com/dashboard/project/_/sql/new). This will create a `instruments` table with some sample data.

SQL\_EDITOR

`
-- Create the table
create table instruments (
id bigint primary key generated always as identity,
name text not null
);
-- Insert some sample data into the table
insert into instruments (name)
values
('violin'),
('viola'),
('cello');
alter table instruments enable row level security;
`

Make the data in your table publicly readable by adding an RLS policy:

SQL\_EDITOR

`
create policy "public can read instruments"
on public.instruments
for select to anon
using (true);
`

2

### Create a Flutter app

Create a Flutter app using the `flutter create` command. You can skip this step if you already have a working app.

Terminal

`
flutter create my_app
`

3

### Install the Supabase client library

The fastest way to get started is to use the [`supabase_flutter`](https://pub.dev/packages/supabase_flutter) client library which provides a convenient interface for working with Supabase from a Flutter app.

Open the `pubspec.yaml` file inside your Flutter app and add `supabase_flutter` as a dependency.

pubspec.yaml

`
supabase_flutter: ^2.0.0
`

4

### Initialize the Supabase client

Open `lib/main.dart` and edit the main function to initialize Supabase using your project URL and public API (anon) key:

###### Project URL

No project found

To get your Project URL, [log in](https://supabase.com/dashboard).

###### Anon key

No project found

To get your Anon key, [log in](https://supabase.com/dashboard).

lib/main.dart

`
import 'package:supabase_flutter/supabase_flutter.dart';
Future<void> main() async {
WidgetsFlutterBinding.ensureInitialized();
await Supabase.initialize(
    url: 'YOUR_SUPABASE_URL',
    anonKey: 'YOUR_SUPABASE_ANON_KEY',
);
runApp(MyApp());
}
`

5

### Query data from the app

Use a `FutureBuilder` to fetch the data when the home page loads and display the query result in a `ListView`.

Replace the default `MyApp` and `MyHomePage` classes with the following code.

lib/main.dart

`
class MyApp extends StatelessWidget {
const MyApp({super.key});
@override
Widget build(BuildContext context) {
    return const MaterialApp(
      title: 'Instruments',
      home: HomePage(),
    );
}
}
class HomePage extends StatefulWidget {
const HomePage({super.key});
@override
State<HomePage> createState() => _HomePageState();
}
class _HomePageState extends State<HomePage> {
final _future = Supabase.instance.client
      .from('instruments')
      .select();
@override
Widget build(BuildContext context) {
    return Scaffold(
      body: FutureBuilder(
        future: _future,
        builder: (context, snapshot) {
          if (!snapshot.hasData) {
            return const Center(child: CircularProgressIndicator());
          }
          final instruments = snapshot.data!;
          return ListView.builder(
            itemCount: instruments.length,
            itemBuilder: ((context, index) {
              final instrument = instruments[index];
              return ListTile(
                title: Text(instrument['name']),
              );
            }),
          );
        },
      ),
    );
}
}
`

6

### Start the app

Run your app on a platform of your choosing! By default an app should launch in your web browser.

Note that `supabase_flutter` is compatible with web, iOS, Android, macOS, and Windows apps.
Running the app on macOS requires additional configuration to [set the entitlements](https://docs.flutter.dev/development/platform-integration/macos/building#setting-up-entitlements).

Terminal

`
flutter run
`

## Going to production [\#](https://supabase.com/docs/guides/getting-started/quickstarts/flutter\#going-to-production)

### Android [\#](https://supabase.com/docs/guides/getting-started/quickstarts/flutter\#android)

In production, your Android app needs explicit permission to use the internet connection on the user's device which is required to communicate with Supabase APIs.
To do this, add the following line to the `android/app/src/main/AndroidManifest.xml` file.

`
<manifest xmlns:android="http://schemas.android.com/apk/res/android">
<!-- Required to fetch data from the internet. -->
<uses-permission android:name="android.permission.INTERNET" />
<!-- ... -->
</manifest>
`

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_quickstarts_hono.md">
Getting Started

# Use Supabase with Hono

## Learn how to create a Supabase project, add some sample data to your database, secure it with auth, and query the data from a Hono app.

* * *

1

### Create a Hono app

Bootstrap the Hono example app from the Supabase Samples using the CLI.

Terminal

`
npx supabase@latest bootstrap hono
`

2

### Install the Supabase client library

The `package.json` file in the project includes the necessary dependencies, including `@supabase/supabase-js` and `@supabase/ssr` to help with server-side auth.

Terminal

`
npm install
`

3

### Set up the required environment variables

Copy the `.env.example` file to `.env` and update the values with your Supabase project URL and anon key.

Lastly, [enable anonymous sign-ins](https://supabase.com/dashboard/project/_/settings/auth) in the Auth settings.

###### Project URL

No project found

To get your Project URL, [log in](https://supabase.com/dashboard).

###### Anon key

No project found

To get your Anon key, [log in](https://supabase.com/dashboard).

Terminal

`
cp .env.example .env
`

4

### Start the app

Start the app, go to [http://localhost:5173](http://localhost:5173/).

Learn how [server side auth](https://supabase.com/docs/guides/auth/server-side/creating-a-client?queryGroups=framework&framework=hono) works with Hono.

Terminal

`
npm run dev
`

## Next steps [\#](https://supabase.com/docs/guides/getting-started/quickstarts/hono\#next-steps)

- Learn how [server side auth](https://supabase.com/docs/guides/auth/server-side/creating-a-client?queryGroups=framework&framework=hono) works with Hono.
- [Insert more data](https://supabase.com/docs/guides/database/import-data) into your database
- Upload and serve static files using [Storage](https://supabase.com/docs/guides/storage)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_quickstarts_ios_swiftui.md">
Getting Started

# Use Supabase with iOS and SwiftUI

## Learn how to create a Supabase project, add some sample data to your database, and query the data from an iOS app.

* * *

1

### Create a Supabase project

Go to [database.new](https://database.new/) and create a new Supabase project.

When your project is up and running, go to the [Table Editor](https://supabase.com/dashboard/project/_/editor), create a new table and insert some data.

Alternatively, you can run the following snippet in your project's [SQL Editor](https://supabase.com/dashboard/project/_/sql/new). This will create a `instruments` table with some sample data.

SQL\_EDITOR

`
-- Create the table
create table instruments (
id bigint primary key generated always as identity,
name text not null
);
-- Insert some sample data into the table
insert into instruments (name)
values
('violin'),
('viola'),
('cello');
alter table instruments enable row level security;
`

Make the data in your table publicly readable by adding an RLS policy:

SQL\_EDITOR

`
create policy "public can read instruments"
on public.instruments
for select to anon
using (true);
`

2

### Create an iOS SwiftUI app with Xcode

Open Xcode > New Project > iOS > App. You can skip this step if you already have a working app.

3

### Install the Supabase client library

Install Supabase package dependency using Xcode by following Apple's [tutorial](https://developer.apple.com/documentation/xcode/adding-package-dependencies-to-your-app).

Make sure to add `Supabase` product package as dependency to the application.

4

### Initialize the Supabase client

Create a new `Supabase.swift` file add a new Supabase instance using your project URL and public API (anon) key:

###### Project URL

No project found

To get your Project URL, [log in](https://supabase.com/dashboard).

###### Anon key

No project found

To get your Anon key, [log in](https://supabase.com/dashboard).

Supabase.swift

`
import Supabase
let supabase = SupabaseClient(
supabaseURL: URL(string: "YOUR_SUPABASE_URL")!,
supabaseKey: "YOUR_SUPABASE_ANON_KEY"
)
`

5

### Create a data model for instruments

Create a decodable struct to deserialize the data from the database.

Add the following code to a new file named `Instrument.swift`.

Supabase.swift

`
struct Instrument: Decodable, Identifiable {
let id: Int
let name: String
}
`

6

### Query data from the app

Use a `task` to fetch the data from the database and display it using a `List`.

Replace the default `ContentView` with the following code.

ContentView.swift

`
struct ContentView: View {
@State var instruments: [Instrument] = []
var body: some View {
    List(instruments) { instrument in
      Text(instrument.name)
    }
    .overlay {
      if instruments.isEmpty {
        ProgressView()
      }
    }
    .task {
      do {
        instruments = try await supabase.from("instruments").select().execute().value
      } catch {
        dump(error)
      }
    }
}
}
`

7

### Start the app

Run the app on a simulator or a physical device by hitting `Cmd + R` on Xcode.

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_quickstarts_kotlin.md">
Getting Started

# Use Supabase with Android Kotlin

## Learn how to create a Supabase project, add some sample data to your database, and query the data from an Android Kotlin app.

* * *

1

### Create a Supabase project

Go to [database.new](https://database.new/) and create a new Supabase project.

When your project is up and running, go to the [Table Editor](https://supabase.com/dashboard/project/_/editor), create a new table and insert some data.

Alternatively, you can run the following snippet in your project's [SQL Editor](https://supabase.com/dashboard/project/_/sql/new). This will create a `instruments` table with some sample data.

SQL\_EDITOR

`
-- Create the table
create table instruments (
id bigint primary key generated always as identity,
name text not null
);
-- Insert some sample data into the table
insert into instruments (name)
values
('violin'),
('viola'),
('cello');
alter table instruments enable row level security;
`

Make the data in your table publicly readable by adding an RLS policy:

SQL\_EDITOR

`
create policy "public can read instruments"
on public.instruments
for select to anon
using (true);
`

2

### Create an Android app with Android Studio

Open Android Studio > New > New Android Project.

3

### Install the Dependencies

Open `build.gradle.kts` (app) file and add the serialization plug, Ktor client, and Supabase client.

Replace the version placeholders `$kotlin_version` with the Kotlin version of the project, and `$supabase_version` and `$ktor_version` with the respective latest versions.

The latest supabase-kt version can be found [here](https://github.com/supabase-community/supabase-kt/releases) and Ktor version can be found [here](https://ktor.io/docs/welcome.html).

`
plugins {
...
kotlin("plugin.serialization") version "$kotlin_version"
}
...
dependencies {
...
implementation(platform("io.github.jan-tennert.supabase:bom:$supabase_version"))
implementation("io.github.jan-tennert.supabase:postgrest-kt")
implementation("io.ktor:ktor-client-android:$ktor_version")
}
`

4

### Add internet access permission

Add the following line to the `AndroidManifest.xml` file under the `manifest` tag and outside the `application` tag.

`
...
<uses-permission android:name="android.permission.INTERNET" />
...
`

5

### Initialize the Supabase client

You can create a Supabase client whenever you need to perform an API call.

For the sake of simplicity, we will create a client in the `MainActivity.kt` file at the top just below the imports.

Replace the `supabaseUrl` and `supabaseKey` with your own:

###### Project URL

No project found

To get your Project URL, [log in](https://supabase.com/dashboard).

###### Anon key

No project found

To get your Anon key, [log in](https://supabase.com/dashboard).

`
import ...
val supabase = createSupabaseClient(
    supabaseUrl = "https://xyzcompany.supabase.co",
    supabaseKey = "your_public_anon_key"
) {
    install(Postgrest)
}
...
`

6

### Create a data model for instruments

Create a serializable data class to represent the data from the database.

Add the following below the `createSupabaseClient` function in the `MainActivity.kt` file.

`
@Serializable
data class Instrument(
    val id: Int,
    val name: String,
)
`

7

### Query data from the app

Use `LaunchedEffect` to fetch data from the database and display it in a `LazyColumn`.

Replace the default `MainActivity` class with the following code.

Note that we are making a network request from our UI code. In production, you should probably use a `ViewModel` to separate the UI and data fetching logic.

`
class MainActivity : ComponentActivity() {
    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        setContent {
            SupabaseTutorialTheme {
                // A surface container using the 'background' color from the theme
                Surface(
                    modifier = Modifier.fillMaxSize(),
                    color = MaterialTheme.colorScheme.background
                ) {
                    InstrumentsList()
                }
            }
        }
    }
}
@Composable
fun InstrumentsList() {
    var instruments by remember { mutableStateOf<List<Instrument>>(listOf()) }
    LaunchedEffect(Unit) {
        withContext(Dispatchers.IO) {
            instruments = supabase.from("instruments")
                              .select().decodeList<Instrument>()
        }
    }
    LazyColumn {
        items(
            instruments,
            key = { instrument -> instrument.id },
        ) { instrument ->
            Text(
                instrument.name,
                modifier = Modifier.padding(8.dp),
            )
        }
    }
}
`

8

### Start the app

Run the app on an emulator or a physical device by clicking the `Run app` button in Android Studio.

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_quickstarts_laravel.md">
Getting Started

# Use Supabase with Laravel

## Learn how to create a PHP Laravel project, connect it to your Supabase Postgres database, and configure user authentication.

* * *

1

### Create a Laravel Project

Make sure your PHP and Composer versions are up to date, then use `composer create-project` to scaffold a new Laravel project.

See the [Laravel docs](https://laravel.com/docs/10.x/installation#creating-a-laravel-project) for more details.

Terminal

`
composer create-project laravel/laravel example-app
`

2

### Install the Authentication template

Install [Laravel Breeze](https://laravel.com/docs/10.x/starter-kits#laravel-breeze), a simple implementation of all of Laravel's [authentication features](https://laravel.com/docs/10.x/authentication).

Terminal

`
composer require laravel/breeze --dev
php artisan breeze:install
`

3

### Set up the Postgres connection details

Go to [database.new](https://database.new/) and create a new Supabase project. Save your database password securely.

When your project is up and running, navigate to the [database settings](https://supabase.com/dashboard/project/_/settings/database) to find the URI connection string. Make sure **Use connection pooling** is checked and **Session mode** is selected. Then copy the URI. Replace the password placeholder with your saved database password.

If your network supports IPv6 connections, you can also use the direct connection string. Uncheck **Use connection pooling** and copy the new URI.

.env

`
DB_CONNECTION=pgsql
DB_URL=postgres://postgres.xxxx:password@xxxx.pooler.supabase.com:5432/postgres
`

4

### Change the default schema

By default Laravel uses the `public` schema. We recommend changing this as Supabase exposes the `public` schema as a [data API](https://supabase.com/docs/guides/api).

You can change the schema of your Laravel application by modifying the `search_path` variable `app/config/database.php`.

The schema you specify in `search_path` has to exist on Supabase. You can create a new schema from the [Table Editor](https://supabase.com/dashboard/project/_/editor).

app/config/database.php

`
'pgsql' => [\
    'driver' => 'pgsql',\
    'url' => env('DB_URL'),\
    'host' => env('DB_HOST', '127.0.0.1'),\
    'port' => env('DB_PORT', '5432'),\
    'database' => env('DB_DATABASE', 'laravel'),\
    'username' => env('DB_USERNAME', 'root'),\
    'password' => env('DB_PASSWORD', ''),\
    'charset' => env('DB_CHARSET', 'utf8'),\
    'prefix' => '',\
    'prefix_indexes' => true,\
    'search_path' => 'laravel',\
    'sslmode' => 'prefer',\
],
`

5

### Run the database migrations

Laravel ships with database migration files that set up the required tables for Laravel Authentication and User Management.

Note: Laravel does not use Supabase Auth but rather implements its own authentication system!

Terminal

`
php artisan migrate
`

6

### Start the app

Run the development server. Go to [http://127.0.0.1:8000](http://127.0.0.1:8000/) in a browser to see your application. You can also navigate to [http://127.0.0.1:8000/register](http://127.0.0.1:8000/register) and [http://127.0.0.1:8000/login](http://127.0.0.1:8000/login) to register and log in users.

Terminal

`
php artisan serve
`

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_quickstarts_nextjs.md">
Getting Started

# Use Supabase with Next.js

## Learn how to create a Supabase project, add some sample data, and query from a Next.js app.

* * *

1

### Create a Supabase project

Go to [database.new](https://database.new/) and create a new Supabase project.

When your project is up and running, go to the [Table Editor](https://supabase.com/dashboard/project/_/editor), create a new table and insert some data.

Alternatively, you can run the following snippet in your project's [SQL Editor](https://supabase.com/dashboard/project/_/sql/new). This will create a `instruments` table with some sample data.

SQL\_EDITOR

`
-- Create the table
create table instruments (
id bigint primary key generated always as identity,
name text not null
);
-- Insert some sample data into the table
insert into instruments (name)
values
('violin'),
('viola'),
('cello');
alter table instruments enable row level security;
`

Make the data in your table publicly readable by adding an RLS policy:

SQL\_EDITOR

`
create policy "public can read instruments"
on public.instruments
for select to anon
using (true);
`

2

### Create a Next.js app

Use the `create-next-app` command and the `with-supabase` template, to create a Next.js app pre-configured with:

- [Cookie-based Auth](https://supabase.com/docs/guides/auth/auth-helpers/nextjs)
- [TypeScript](https://www.typescriptlang.org/)
- [Tailwind CSS](https://tailwindcss.com/)

Terminal

`
npx create-next-app -e with-supabase
`

3

### Declare Supabase Environment Variables

Rename `.env.example` to `.env.local` and populate with your Supabase connection variables:

###### Project URL

No project found

To get your Project URL, [log in](https://supabase.com/dashboard).

###### Anon key

No project found

To get your Anon key, [log in](https://supabase.com/dashboard).

.env.local

`
NEXT_PUBLIC_SUPABASE_URL=<SUBSTITUTE_SUPABASE_URL>
NEXT_PUBLIC_SUPABASE_ANON_KEY=<SUBSTITUTE_SUPABASE_ANON_KEY>
`

4

### Query Supabase data from Next.js

Create a new file at `app/instruments/page.tsx` and populate with the following.

This will select all the rows from the `instruments` table in Supabase and render them on the page.

app/instruments/page.tsx

utils/supabase/server.ts

`
import { createClient } from '@/utils/supabase/server';
export default async function Instruments() {
    const supabase = await createClient();
    const { data: instruments } = await supabase.from("instruments").select();
    return <pre>{JSON.stringify(instruments, null, 2)}</pre>
}
`

5

### Start the app

Run the development server, go to [http://localhost:3000/instruments](http://localhost:3000/instruments) in a browser and you should see the list of instruments.

Terminal

`
npm run dev
`

## Next steps [\#](https://supabase.com/docs/guides/getting-started/quickstarts/nextjs\#next-steps)

- Set up [Auth](https://supabase.com/docs/guides/auth) for your app
- [Insert more data](https://supabase.com/docs/guides/database/import-data) into your database
- Upload and serve static files using [Storage](https://supabase.com/docs/guides/storage)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_quickstarts_nuxtjs.md">
Getting Started

# Use Supabase with Nuxt

## Learn how to create a Supabase project, add some sample data to your database, and query the data from a Nuxt app.

* * *

1

### Create a Supabase project

Go to [database.new](https://database.new/) and create a new Supabase project.

When your project is up and running, go to the [Table Editor](https://supabase.com/dashboard/project/_/editor), create a new table and insert some data.

Alternatively, you can run the following snippet in your project's [SQL Editor](https://supabase.com/dashboard/project/_/sql/new). This will create a `instruments` table with some sample data.

SQL\_EDITOR

`
-- Create the table
create table instruments (
id bigint primary key generated always as identity,
name text not null
);
-- Insert some sample data into the table
insert into instruments (name)
values
('violin'),
('viola'),
('cello');
alter table instruments enable row level security;
`

Make the data in your table publicly readable by adding an RLS policy:

SQL\_EDITOR

`
create policy "public can read instruments"
on public.instruments
for select to anon
using (true);
`

2

### Create a Nuxt app

Create a Nuxt app using the `npx nuxi` command.

Terminal

`
npx nuxi@latest init my-app
`

3

### Install the Supabase client library

The fastest way to get started is to use the `supabase-js` client library which provides a convenient interface for working with Supabase from a Nuxt app.

Navigate to the Nuxt app and install `supabase-js`.

Terminal

`
cd my-app && npm install @supabase/supabase-js
`

4

### Query data from the app

In `app.vue`, create a Supabase client using your project URL and public API (anon) key:

###### Project URL

No project found

To get your Project URL, [log in](https://supabase.com/dashboard).

###### Anon key

No project found

To get your Anon key, [log in](https://supabase.com/dashboard).

Replace the existing content in your `app.vue` file with the following code.

app.vue

`
<script setup>
import { createClient } from '@supabase/supabase-js'
const supabase = createClient('https://<project>.supabase.co', '<your-anon-key>')
const instruments = ref([])
async function getInstruments() {
const { data } = await supabase.from('instruments').select()
instruments.value = data
}
onMounted(() => {
getInstruments()
})
</script>
<template>
<ul>
    <li v-for="instrument in instruments" :key="instrument.id">{{ instrument.name }}</li>
</ul>
</template>
`

5

### Start the app

Start the app, navigate to [http://localhost:3000](http://localhost:3000/) in the browser, open the browser console, and you should see the list of instruments.

Terminal

`
npm run dev
`

The community-maintained [@nuxtjs/supabase](https://supabase.nuxtjs.org/) module provides an alternate DX for working with Supabase in Nuxt.

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_quickstarts_reactjs.md">
Getting Started

# Use Supabase with React

## Learn how to create a Supabase project, add some sample data to your database, and query the data from a React app.

* * *

1

### Create a Supabase project

Go to [database.new](https://database.new/) and create a new Supabase project.

When your project is up and running, go to the [Table Editor](https://supabase.com/dashboard/project/_/editor), create a new table and insert some data.

Alternatively, you can run the following snippet in your project's [SQL Editor](https://supabase.com/dashboard/project/_/sql/new). This will create a `instruments` table with some sample data.

SQL\_EDITOR

`
-- Create the table
create table instruments (
id bigint primary key generated always as identity,
name text not null
);
-- Insert some sample data into the table
insert into instruments (name)
values
('violin'),
('viola'),
('cello');
alter table instruments enable row level security;
`

Make the data in your table publicly readable by adding an RLS policy:

SQL\_EDITOR

`
create policy "public can read instruments"
on public.instruments
for select to anon
using (true);
`

2

### Create a React app

Create a React app using a [Vite](https://vitejs.dev/guide/) template.

Terminal

`
npm create vite@latest my-app -- --template react
`

3

### Install the Supabase client library

The fastest way to get started is to use the `supabase-js` client library which provides a convenient interface for working with Supabase from a React app.

Navigate to the React app and install `supabase-js`.

Terminal

`
cd my-app && npm install @supabase/supabase-js
`

4

### Query data from the app

In `App.jsx`, create a Supabase client using your project URL and public API (anon) key:

###### Project URL

No project found

To get your Project URL, [log in](https://supabase.com/dashboard).

###### Anon key

No project found

To get your Anon key, [log in](https://supabase.com/dashboard).

Add a `getInstruments` function to fetch the data and display the query result to the page.

src/App.jsx

`
import { useEffect, useState } from "react";
import { createClient } from "@supabase/supabase-js";
const supabase = createClient("https://<project>.supabase.co", "<your-anon-key>");
function App() {
    const [instruments, setInstruments] = useState([]);
    useEffect(() => {
      getInstruments();
    }, []);
    async function getInstruments() {
      const { data } = await supabase.from("instruments").select();
      setInstruments(data);
    }
    return (
      <ul>
        {instruments.map((instrument) => (
          <li key={instrument.name}>{instrument.name}</li>
        ))}
      </ul>
    );
}
export default App;
`

5

### Start the app

Start the app, go to [http://localhost:5173](http://localhost:5173/) in a browser, and open the browser console and you should see the list of instruments.

Terminal

`
npm run dev
`

## Next steps [\#](https://supabase.com/docs/guides/getting-started/quickstarts/reactjs\#next-steps)

- Set up [Auth](https://supabase.com/docs/guides/auth) for your app
- [Insert more data](https://supabase.com/docs/guides/database/import-data) into your database
- Upload and serve static files using [Storage](https://supabase.com/docs/guides/storage)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_quickstarts_redwoodjs.md">
Getting Started

# Use Supabase with RedwoodJS

## Learn how to create a Supabase project, add some sample data to your database using Prisma migration and seeds, and query the data from a RedwoodJS app.

* * *

1

### Setup your new Supabase Project

[Create a new project](https://supabase.com/dashboard) in the Supabase Dashboard.

Be sure to make note of the Database Password you used as you will need this later to connect to your database.

![New project for redwoodjs](https://supabase.com/docs/img/guides/getting-started/quickstarts/redwoodjs/new-project.png)

2

### Gather Database Connection Strings

Go to the [database settings page](https://supabase.com/dashboard/project/_/settings/database). In this quickstart, we are going to connect via the connection pooler. If your network supports IPv6, you can connect to the database directly without using the connection pooler.

We will use the pooler both in `Transaction` and `Session` mode. `Transaction` mode is used for application queries and `Session` mode is used for running migrations with Prisma.

To do this, set the connection mode to `Transaction` in the [database settings page](https://supabase.com/dashboard/project/_/settings/database) and copy the connection string and append `?pgbouncer=true&&connection_limit=1`. `pgbouncer=true` disables Prisma from generating prepared statements. This is required since our connection pooler does not support prepared statements in transaction mode yet. The `connection_limit=1` parameter is only required if you are using Prisma from a serverless environment. This is the Transaction mode connection string.

To get the Session mode connection pooler string, change the port of the connection string from the dashboard to 5432.

You will need the Transaction mode connection string and the Session mode connection string to setup environment variables in Step 5.

You can copy and paste these connection strings from the Supabase Dashboard when needed in later steps.

![pooled connection for redwoodjs](https://supabase.com/docs/img/guides/getting-started/quickstarts/redwoodjs/pooled-connection-strings.png)

3

### Create a RedwoodJS app

Create a RedwoodJS app with TypeScript.

The [`yarn` package manager](https://yarnpkg.com/) is required to create a RedwoodJS app. You will use it to run RedwoodJS commands later.

While TypeScript is recommended, If you want a JavaScript app, omit the `--ts` flag.

Terminal

`
yarn create redwood-app my-app --ts
`

4

### Open your RedwoodJS app in VS Code

You'll develop your app, manage database migrations, and run your app in VS Code.

Terminal

`
cd my-app
code .
`

5

### Configure Environment Variables

In your `.env` file, add the following environment variables for your database connection:

- The `DATABASE_URL` should use the Transaction mode connection string you copied in Step 1.

- The `DIRECT_URL` should use the Session mode connection string you copied in Step 1.


.env

`
# Transaction mode connection string used for migrations
DATABASE_URL="postgres://postgres.[project-ref]:[db-password]@xxx.pooler.supabase.com:6543/postgres?pgbouncer=true&connection_limit=1"
# Session mode connection string  used by Prisma Client
DIRECT_URL="postgres://postgres.[project-ref]:[db-password]@xxx.pooler.supabase.com:5432/postgres"
`

6

### Update your Prisma Schema

By default, RedwoodJS ships with a SQLite database, but we want to use Postgres.

Update your Prisma schema file `api/db/schema.prisma` to use your Supabase Postgres database connection environment variables you setup in Step 5.

api/db/schema.prisma

`
datasource db {
provider  = "postgresql"
url       = env("DATABASE_URL")
directUrl = env("DIRECT_URL")
}
`

7

### Create the Instrument model and apply a schema migration

Create the Instrument model in `api/db/schema.prisma` and then run `yarn rw prisma migrate dev` from your terminal to apply the migration.

api/db/schema.prisma

`
model Instrument {
id   Int    @id @default(autoincrement())
name String @unique
}
`

8

### Update seed script

Let's seed the database with a few instruments.

Update the file `scripts/seeds.ts` to contain the following code:

scripts/seed.ts

`
import type { Prisma } from '@prisma/client'
import { db } from 'api/src/lib/db'
export default async () => {
try {
    const data: Prisma.InstrumentCreateArgs['data'][] = [\
      { name: 'dulcimer' },\
      { name: 'harp' },\
      { name: 'guitar' },\
    ]
    console.log('Seeding instruments ...')
    const instruments = await db.instrument.createMany({ data })
    console.log('Done.', instruments)
} catch (error) {
    console.error(error)
}
}
`

9

### Seed your database

Run the seed database command to populate the `Instrument` table with the instruments you just created.

The reset database command `yarn rw prisma db reset` will recreate the tables and will also run the seed script.

Terminal

`
yarn rw prisma db seed
`

10

### Scaffold the Instrument UI

Now, we'll use RedwoodJS generators to scaffold a CRUD UI for the `Instrument` model.

Terminal

`
yarn rw g scaffold instrument
`

11

### Start the app

Start the app via `yarn rw dev`. A browser will open to the RedwoodJS Splash page.

![RedwoodJS Splash Page](https://supabase.com/docs/img/redwoodjs-qs-splash.png)

12

### View Books UI

Click on `/instruments` to visit [http://localhost:8910/instruments](http://localhost:8910/instruments) where should see the list of instruments.

You may now edit, delete, and add new books using the scaffolded UI.

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_quickstarts_refine.md">
Getting Started

# Use Supabase with refine

## Learn how to create a Supabase project, add some sample data to your database, and query the data from a refine app.

* * *

1

### Create a Supabase project

Go to [database.new](https://database.new/) and create a new Supabase project.

When your project is up and running, go to the [Table Editor](https://supabase.com/dashboard/project/_/editor), create a new table and insert some data.

Alternatively, you can run the following snippet in your project's [SQL Editor](https://supabase.com/dashboard/project/_/sql/new). This will create a `instruments` table with some sample data.

SQL\_EDITOR

`
-- Create the table
create table instruments (
id bigint primary key generated always as identity,
name text not null
);
-- Insert some sample data into the table
insert into instruments (name)
values
('violin'),
('viola'),
('cello');
alter table instruments enable row level security;
`

Make the data in your table publicly readable by adding an RLS policy:

SQL\_EDITOR

`
create policy "public can read instruments"
on public.instruments
for select to anon
using (true);
`

2

### Create a refine app

Create a [refine](https://github.com/refinedev/refine) app using the [create refine-app](https://refine.dev/docs/getting-started/quickstart/).

The `refine-supabase` preset adds `@refinedev/supabase` supplementary package that supports Supabase in a refine app. `@refinedev/supabase` out-of-the-box includes the Supabase dependency: [supabase-js](https://github.com/supabase/supabase-js).

Terminal

`
npm create refine-app@latest -- --preset refine-supabase my-app
`

3

### Open your refine app in VS Code

You will develop your app, connect to the Supabase backend and run the refine app in VS Code.

Terminal

`
cd my-app
code .
`

4

### Start the app

Start the app, go to [http://localhost:5173](http://localhost:5173/) in a browser, and you should be greeted with the refine Welcome page.

Terminal

`
npm run dev
`

![refine welcome page](https://supabase.com/docs/img/refine-qs-welcome-page.png)

5

### Update \`supabaseClient\`

You now have to update the `supabaseClient` with the `SUPABASE_URL` and `SUPABASE_KEY` of your Supabase API. The `supabaseClient` is used in auth provider and data provider methods that allow the refine app to connect to your Supabase backend.

###### Project URL

No project found

To get your Project URL, [log in](https://supabase.com/dashboard).

###### Anon key

No project found

To get your Anon key, [log in](https://supabase.com/dashboard).

src/utility/supabaseClient.ts

`
import { createClient } from "@refinedev/supabase";
const SUPABASE_URL = YOUR_SUPABASE_URL;
const SUPABASE_KEY = YOUR_SUPABASE_KEY
export const supabaseClient = createClient(SUPABASE_URL, SUPABASE_KEY, {
db: {
    schema: "public",
},
auth: {
    persistSession: true,
},
});
`

6

### Add instruments resource and pages

You have to then configure resources and define pages for `instruments` resource.

Use the following command to automatically add resources and generate code for pages for `instruments` using refine Inferencer.

This defines pages for `list`, `create`, `show` and `edit` actions inside the `src/pages/instruments/` directory with `<HeadlessInferencer />` component.

The `<HeadlessInferencer />` component depends on `@refinedev/react-table` and `@refinedev/react-hook-form` packages. In order to avoid errors, you should install them as dependencies with `npm install @refinedev/react-table @refinedev/react-hook-form`.

The `<HeadlessInferencer />` is a refine Inferencer component that automatically generates necessary code for the `list`, `create`, `show` and `edit` pages.

More on [how the Inferencer works is available in the docs here](https://refine.dev/docs/packages/documentation/inferencer/).

Terminal

`
npm run refine create-resource instruments
`

7

### Add routes for instruments pages

Add routes for the `list`, `create`, `show`, and `edit` pages.

You should remove the `index` route for the Welcome page presented with the `<Welcome />` component.

src/App.tsx

`
import { Refine, WelcomePage } from "@refinedev/core";
import { RefineKbar, RefineKbarProvider } from "@refinedev/kbar";
import routerBindings, {
DocumentTitleHandler,
NavigateToResource,
UnsavedChangesNotifier,
} from "@refinedev/react-router-v6";
import { dataProvider, liveProvider } from "@refinedev/supabase";
import { BrowserRouter, Route, Routes } from "react-router-dom";
import "./App.css";
import authProvider from "./authProvider";
import { supabaseClient } from "./utility";
import { InstrumentsCreate, InstrumentsEdit, InstrumentsList, InstrumentsShow } from "./pages/instruments";
function App() {
return (
    <BrowserRouter>
      <RefineKbarProvider>
        <Refine
          dataProvider={dataProvider(supabaseClient)}
          liveProvider={liveProvider(supabaseClient)}
          authProvider={authProvider}
          routerProvider={routerBindings}
          options={{
            syncWithLocation: true,
            warnWhenUnsavedChanges: true,
          }}
          resources={[{\
            name: "instruments",\
            list: "/instruments",\
            create: "/instruments/create",\
            edit: "/instruments/edit/:id",\
            show: "/instruments/show/:id"\
          }]}>
          <Routes>
            <Route index
              element={<NavigateToResource resource="instruments" />}
            />
            <Route path="/instruments">
              <Route index element={<InstrumentsList />} />
              <Route path="create" element={<InstrumentsCreate />} />
              <Route path="edit/:id" element={<InstrumentsEdit />} />
              <Route path="show/:id" element={<InstrumentsShow />} />
            </Route>
          </Routes>
          <RefineKbar />
          <UnsavedChangesNotifier />
          <DocumentTitleHandler />
        </Refine>
      </RefineKbarProvider>
    </BrowserRouter>
);
}
export default App;
`

8

### View instruments pages

Now you should be able to see the instruments pages along the `/instruments` routes. You may now edit and add new instruments using the Inferencer generated UI.

The Inferencer auto-generated code gives you a good starting point on which to keep building your `list`, `create`, `show` and `edit` pages. They can be obtained by clicking the `Show the auto-generated code` buttons in their respective pages.

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_quickstarts_ruby_on_rails.md">
Getting Started

# Use Supabase with Ruby on Rails

## Learn how to create a Rails project and connect it to your Supabase Postgres database.

* * *

1

### Create a Rails Project

Make sure your Ruby and Rails versions are up to date, then use `rails new` to scaffold a new Rails project. Use the `-d=postgresql` flag to set it up for Postgres.

Go to the [Rails docs](https://guides.rubyonrails.org/getting_started.html) for more details.

Terminal

`
rails new blog -d=postgresql
`

2

### Set up the Postgres connection details

Go to [database.new](https://database.new/) and create a new Supabase project. Save your database password securely.

When your project is up and running, navigate to the [database settings](https://supabase.com/dashboard/project/_/settings/database) to find the URI connection string. Make sure **Use connection pooling** is checked and **Session mode** is selected. Then copy the URI. Replace the password placeholder with your saved database password.

If your network supports IPv6 connections, you can also use the direct connection string. Uncheck **Use connection pooling** and copy the new URI.

Terminal

`
export DATABASE_URL=postgres://postgres.xxxx:password@xxxx.pooler.supabase.com:5432/postgres
`

3

### Create and run a database migration

Rails includes Active Record as the ORM as well as database migration tooling which generates the SQL migration files for you.

Create an example `Article` model and generate the migration files.

Terminal

`
bin/rails generate model Article title:string body:text
bin/rails db:migrate
`

4

### Use the Model to interact with the database

You can use the included Rails console to interact with the database. For example, you can create new entries or list all entries in a Model's table.

Terminal

`
bin/rails console
`

irb

`
article = Article.new(title: "Hello Rails", body: "I am on Rails!")
article.save # Saves the entry to the database
Article.all
`

5

### Start the app

Run the development server. Go to [http://127.0.0.1:3000](http://127.0.0.1:3000/) in a browser to see your application running.

Terminal

`
bin/rails server
`

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_quickstarts_solidjs.md">
Getting Started

# Use Supabase with SolidJS

## Learn how to create a Supabase project, add some sample data to your database, and query the data from a SolidJS app.

* * *

1

### Create a Supabase project

Go to [database.new](https://database.new/) and create a new Supabase project.

When your project is up and running, go to the [Table Editor](https://supabase.com/dashboard/project/_/editor), create a new table and insert some data.

Alternatively, you can run the following snippet in your project's [SQL Editor](https://supabase.com/dashboard/project/_/sql/new). This will create a `instruments` table with some sample data.

SQL\_EDITOR

`
-- Create the table
create table instruments (
id bigint primary key generated always as identity,
name text not null
);
-- Insert some sample data into the table
insert into instruments (name)
values
('violin'),
('viola'),
('cello');
alter table instruments enable row level security;
`

Make the data in your table publicly readable by adding an RLS policy:

SQL\_EDITOR

`
create policy "public can read instruments"
on public.instruments
for select to anon
using (true);
`

2

### Create a SolidJS app

Create a SolidJS app using the `degit` command.

Terminal

`
npx degit solidjs/templates/js my-app
`

3

### Install the Supabase client library

The fastest way to get started is to use the `supabase-js` client library which provides a convenient interface for working with Supabase from a SolidJS app.

Navigate to the SolidJS app and install `supabase-js`.

Terminal

`
cd my-app && npm install @supabase/supabase-js
`

4

### Query data from the app

In `App.jsx`, create a Supabase client using your project URL and public API (anon) key:

###### Project URL

No project found

To get your Project URL, [log in](https://supabase.com/dashboard).

###### Anon key

No project found

To get your Anon key, [log in](https://supabase.com/dashboard).

Add a `getInstruments` function to fetch the data and display the query result to the page.

src/App.jsx

`
import { createClient } from "@supabase/supabase-js";
import { createResource, For } from "solid-js";
const supabase = createClient('https://<project>.supabase.co', '<your-anon-key>');
async function getInstruments() {
    const { data } = await supabase.from("instruments").select();
    return data;
}
function App() {
    const [instruments] = createResource(getInstruments);
    return (
      <ul>
        <For each={instruments()}>{(instrument) => <li>{instrument.name}</li>}</For>
      </ul>
    );
}
export default App;
`

5

### Start the app

Start the app and go to [http://localhost:3000](http://localhost:3000/) in a browser and you should see the list of instruments.

Terminal

`
npm run dev
`

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_quickstarts_sveltekit.md">
Getting Started

# Use Supabase with SvelteKit

## Learn how to create a Supabase project, add some sample data to your database, and query the data from a SvelteKit app.

* * *

1

### Create a Supabase project

Go to [database.new](https://database.new/) and create a new Supabase project.

When your project is up and running, go to the [Table Editor](https://supabase.com/dashboard/project/_/editor), create a new table and insert some data.

Alternatively, you can run the following snippet in your project's [SQL Editor](https://supabase.com/dashboard/project/_/sql/new). This will create a `instruments` table with some sample data.

SQL\_EDITOR

`
-- Create the table
create table instruments (
id bigint primary key generated always as identity,
name text not null
);
-- Insert some sample data into the table
insert into instruments (name)
values
('violin'),
('viola'),
('cello');
alter table instruments enable row level security;
`

Make the data in your table publicly readable by adding an RLS policy:

SQL\_EDITOR

`
create policy "public can read instruments"
on public.instruments
for select to anon
using (true);
`

2

### Create a SvelteKit app

Create a SvelteKit app using the `npm create` command.

Terminal

`
npx sv create my-app
`

3

### Install the Supabase client library

The fastest way to get started is to use the `supabase-js` client library which provides a convenient interface for working with Supabase from a SvelteKit app.

Navigate to the SvelteKit app and install `supabase-js`.

Terminal

`
cd my-app && npm install @supabase/supabase-js
`

4

### Create the Supabase client

Create a `src/lib` directory in your SvelteKit app, create a file called `supabaseClient.js` and add the following code to initialize the Supabase client with your project URL and public API (anon) key:

###### Project URL

No project found

To get your Project URL, [log in](https://supabase.com/dashboard).

###### Anon key

No project found

To get your Anon key, [log in](https://supabase.com/dashboard).

src/lib/supabaseClient.js

`
import { createClient } from '@supabase/supabase-js'
export const supabase = createClient('https://<project>.supabase.co', '<your-anon-key>')
`

5

### Query data from the app

Use `load` method to fetch the data server-side and display the query results as a simple list.

Create `+page.server.js` file in the `src/routes` directory with the following code.

src/routes/+page.server.js

`
import { supabase } from "$lib/supabaseClient";
export async function load() {
    const { data } = await supabase.from("instruments").select();
    return {
      instruments: data ?? [],
    };
}
`

Replace the existing content in your `+page.svelte` file in the `src/routes` directory with the following code.

src/routes/+page.svelte

`
<script>
    let { data } = $props();
</script>
<ul>
    {#each data.instruments as instrument}
      <li>{instrument.name}</li>
    {/each}
</ul>
`

6

### Start the app

Start the app and go to [http://localhost:5173](http://localhost:5173/) in a browser and you should see the list of instruments.

Terminal

`
npm run dev
`

## Next steps [\#](https://supabase.com/docs/guides/getting-started/quickstarts/sveltekit\#next-steps)

- Set up [Auth](https://supabase.com/docs/guides/auth) for your app
- [Insert more data](https://supabase.com/docs/guides/database/import-data) into your database
- Upload and serve static files using [Storage](https://supabase.com/docs/guides/storage)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_quickstarts_vue.md">
Getting Started

# Use Supabase with Vue

## Learn how to create a Supabase project, add some sample data to your database, and query the data from a Vue app.

* * *

1

### Create a Supabase project

Go to [database.new](https://database.new/) and create a new Supabase project.

When your project is up and running, go to the [Table Editor](https://supabase.com/dashboard/project/_/editor), create a new table and insert some data.

Alternatively, you can run the following snippet in your project's [SQL Editor](https://supabase.com/dashboard/project/_/sql/new). This will create a `instruments` table with some sample data.

SQL\_EDITOR

`
-- Create the table
create table instruments (
id bigint primary key generated always as identity,
name text not null
);
-- Insert some sample data into the table
insert into instruments (name)
values
('violin'),
('viola'),
('cello');
alter table instruments enable row level security;
`

Make the data in your table publicly readable by adding an RLS policy:

SQL\_EDITOR

`
create policy "public can read instruments"
on public.instruments
for select to anon
using (true);
`

2

### Create a Vue app

Create a Vue app using the `npm init` command.

Terminal

`
npm init vue@latest my-app
`

3

### Install the Supabase client library

The fastest way to get started is to use the `supabase-js` client library which provides a convenient interface for working with Supabase from a Vue app.

Navigate to the Vue app and install `supabase-js`.

Terminal

`
cd my-app && npm install @supabase/supabase-js
`

4

### Create the Supabase client

Create a `/src/lib` directory in your Vue app, create a file called `supabaseClient.js` and add the following code to initialize the Supabase client with your project URL and public API (anon) key:

###### Project URL

No project found

To get your Project URL, [log in](https://supabase.com/dashboard).

###### Anon key

No project found

To get your Anon key, [log in](https://supabase.com/dashboard).

src/lib/supabaseClient.js

`
import { createClient } from '@supabase/supabase-js'
export const supabase = createClient('https://<project>.supabase.co', '<your-anon-key>')
`

5

### Query data from the app

Replace the existing content in your `App.vue` file with the following code.

src/App.vue

`
<script setup>
import { ref, onMounted } from 'vue'
import { supabase } from './lib/supabaseClient'
const instruments = ref([])
async function getInstruments() {
    const { data } = await supabase.from('instruments').select()
    instruments.value = data
}
onMounted(() => {
    getInstruments()
})
</script>
<template>
    <ul>
      <li v-for="instrument in instruments" :key="instrument.id">{{ instrument.name }}</li>
    </ul>
</template>
`

6

### Start the app

Start the app and go to [http://localhost:5173](http://localhost:5173/) in a browser and you should see the list of instruments.

Terminal

`
npm run dev
`

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_tutorials_with_angular.md">
Getting Started

# Build a User Management App with Angular

* * *

This tutorial demonstrates how to build a basic user management app. The app authenticates and identifies the user, stores their profile information in the database, and allows the user to log in, update their profile details, and upload a profile photo. The app uses:

- [Supabase Database](https://supabase.com/docs/guides/database) \- a Postgres database for storing your user data and [Row Level Security](https://supabase.com/docs/guides/auth#row-level-security) so data is protected and users can only access their own information.
- [Supabase Auth](https://supabase.com/docs/guides/auth) \- allow users to sign up and log in.
- [Supabase Storage](https://supabase.com/docs/guides/storage) \- users can upload a profile photo.

![Supabase User Management example](https://supabase.com/docs/img/user-management-demo.png)

If you get stuck while working through this guide, refer to the [full example on GitHub](https://github.com/supabase/supabase/tree/master/examples/user-management/angular-user-management).

## Project setup [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-angular\#project-setup)

Before we start building we're going to set up our Database and API. This is as simple as starting a new Project in Supabase and then creating a "schema" inside the database.

### Create a project [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-angular\#create-a-project)

1. [Create a new project](https://supabase.com/dashboard) in the Supabase Dashboard.
2. Enter your project details.
3. Wait for the new database to launch.

### Set up the database schema [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-angular\#set-up-the-database-schema)

Now we are going to set up the database schema. We can use the "User Management Starter" quickstart in the SQL Editor, or you can just copy/paste the SQL from below and run it yourself.

DashboardSQL

1. Go to the [SQL Editor](https://supabase.com/dashboard/project/_/sql) page in the Dashboard.
2. Click **User Management Starter**.
3. Click **Run**.

You can easily pull the database schema down to your local project by running the `db pull` command. Read the [local development docs](https://supabase.com/docs/guides/cli/local-development#link-your-project) for detailed instructions.

`
supabase link --project-ref <project-id>
# You can get <project-id> from your project's dashboard URL: https://supabase.com/dashboard/project/<project-id>
supabase db pull
`

### Get the API Keys [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-angular\#get-the-api-keys)

Now that you've created some database tables, you are ready to insert data using the auto-generated API.
We just need to get the Project URL and `anon` key from the API settings.

1. Go to the [API Settings](https://supabase.com/dashboard/project/_/settings/api) page in the Dashboard.
2. Find your Project `URL`, `anon`, and `service_role` keys on this page.

## Building the app [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-angular\#building-the-app)

Let's start building the Angular app from scratch.

### Initialize an Angular app [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-angular\#initialize-an-angular-app)

We can use the [Angular CLI](https://angular.io/cli) to initialize
an app called `supabase-angular`:

`
npx ng new supabase-angular --routing false --style css --standalone false
cd supabase-angular
`

Then let's install the only additional dependency: [supabase-js](https://github.com/supabase/supabase-js)

`
npm install @supabase/supabase-js
`

And finally we want to save the environment variables in the `src/environments/environment.ts` file.
All we need are the API URL and the `anon` key that you copied [earlier](https://supabase.com/docs/guides/getting-started/tutorials/with-angular#get-the-api-keys).
These variables will be exposed on the browser, and that's completely fine since we have [Row Level Security](https://supabase.com/docs/guides/auth#row-level-security) enabled on our Database.

src/environments/environment.ts

`
export const environment = {
production: false,
supabaseUrl: 'YOUR_SUPABASE_URL',
supabaseKey: 'YOUR_SUPABASE_KEY',
}
`

Now that we have the API credentials in place, let's create a `SupabaseService` with `ng g s supabase` to initialize the Supabase client and implement functions to communicate with the Supabase API.

src/app/supabase.service.ts

``
import { Injectable } from '@angular/core'
import {
AuthChangeEvent,
AuthSession,
createClient,
Session,
SupabaseClient,
User,
} from '@supabase/supabase-js'
import { environment } from '../environments/environment'
export interface Profile {
id?: string
username: string
website: string
avatar_url: string
}
@Injectable({
providedIn: 'root',
})
export class SupabaseService {
private supabase: SupabaseClient
_session: AuthSession | null = null
constructor() {
    this.supabase = createClient(environment.supabaseUrl, environment.supabaseKey)
}
get session() {
    this.supabase.auth.getSession().then(({ data }) => {
      this._session = data.session
    })
    return this._session
}
profile(user: User) {
    return this.supabase
      .from('profiles')
      .select(`username, website, avatar_url`)
      .eq('id', user.id)
      .single()
}
authChanges(callback: (event: AuthChangeEvent, session: Session | null) => void) {
    return this.supabase.auth.onAuthStateChange(callback)
}
signIn(email: string) {
    return this.supabase.auth.signInWithOtp({ email })
}
signOut() {
    return this.supabase.auth.signOut()
}
updateProfile(profile: Profile) {
    const update = {
      ...profile,
      updated_at: new Date(),
    }
    return this.supabase.from('profiles').upsert(update)
}
downLoadImage(path: string) {
    return this.supabase.storage.from('avatars').download(path)
}
uploadAvatar(filePath: string, file: File) {
    return this.supabase.storage.from('avatars').upload(filePath, file)
}
}
``

Optionally, update [src/styles.css](https://raw.githubusercontent.com/supabase/supabase/master/examples/user-management/angular-user-management/src/styles.css) to style the app.

### Set up a login component [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-angular\#set-up-a-login-component)

Let's set up an Angular component to manage logins and sign ups. We'll use Magic Links, so users can sign in with their email without using passwords.
Create an `AuthComponent` with `ng g c auth` Angular CLI command.

src/app/auth/auth.component.ts

`
import { Component } from '@angular/core'
import { FormBuilder } from '@angular/forms'
import { SupabaseService } from '../supabase.service'
@Component({
selector: 'app-auth',
templateUrl: './auth.component.html',
styleUrls: ['./auth.component.css'],
})
export class AuthComponent {
loading = false
signInForm = this.formBuilder.group({
    email: '',
})
constructor(
    private readonly supabase: SupabaseService,
    private readonly formBuilder: FormBuilder
) {}
async onSubmit(): Promise<void> {
    try {
      this.loading = true
      const email = this.signInForm.value.email as string
      const { error } = await this.supabase.signIn(email)
      if (error) throw error
      alert('Check your email for the login link!')
    } catch (error) {
      if (error instanceof Error) {
        alert(error.message)
      }
    } finally {
      this.signInForm.reset()
      this.loading = false
    }
}
}
`

src/app/auth/auth.component.html

`
<div class="row flex-center flex">
<div class="col-6 form-widget" aria-live="polite">
    <h1 class="header">Supabase + Angular</h1>
    <p class="description">Sign in via magic link with your email below</p>
    <form [formGroup]="signInForm" (ngSubmit)="onSubmit()" class="form-widget">
      <div>
        <label for="email">Email</label>
        <input
          id="email"
          formControlName="email"
          class="inputField"
          type="email"
          placeholder="Your email"
        />
      </div>
      <div>
        <button type="submit" class="button block" [disabled]="loading">
          {{ loading ? 'Loading' : 'Send magic link' }}
        </button>
      </div>
    </form>
</div>
</div>
`

### Account page [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-angular\#account-page)

Users also need a way to edit their profile details and manage their accounts after signing in.
Create an `AccountComponent` with the `ng g c account` Angular CLI command.

src/app/account/account.component.ts

`
import { Component, Input, OnInit } from '@angular/core'
import { FormBuilder } from '@angular/forms'
import { AuthSession } from '@supabase/supabase-js'
import { Profile, SupabaseService } from '../supabase.service'
@Component({
selector: 'app-account',
templateUrl: './account.component.html',
styleUrls: ['./account.component.css'],
})
export class AccountComponent implements OnInit {
loading = false
profile!: Profile
@Input()
session!: AuthSession
updateProfileForm = this.formBuilder.group({
    username: '',
    website: '',
    avatar_url: '',
})
constructor(
    private readonly supabase: SupabaseService,
    private formBuilder: FormBuilder
) {}
async ngOnInit(): Promise<void> {
    await this.getProfile()
    const { username, website, avatar_url } = this.profile
    this.updateProfileForm.patchValue({
      username,
      website,
      avatar_url,
    })
}
async getProfile() {
    try {
      this.loading = true
      const { user } = this.session
      const { data: profile, error, status } = await this.supabase.profile(user)
      if (error && status !== 406) {
        throw error
      }
      if (profile) {
        this.profile = profile
      }
    } catch (error) {
      if (error instanceof Error) {
        alert(error.message)
      }
    } finally {
      this.loading = false
    }
}
async updateProfile(): Promise<void> {
    try {
      this.loading = true
      const { user } = this.session
      const username = this.updateProfileForm.value.username as string
      const website = this.updateProfileForm.value.website as string
      const avatar_url = this.updateProfileForm.value.avatar_url as string
      const { error } = await this.supabase.updateProfile({
        id: user.id,
        username,
        website,
        avatar_url,
      })
      if (error) throw error
    } catch (error) {
      if (error instanceof Error) {
        alert(error.message)
      }
    } finally {
      this.loading = false
    }
}
async signOut() {
    await this.supabase.signOut()
}
}
`

src/app/account/account.component.html

`
<form [formGroup]="updateProfileForm" (ngSubmit)="updateProfile()" class="form-widget">
<div>
    <label for="email">Email</label>
    <input id="email" type="text" [value]="session.user.email" disabled />
</div>
<div>
    <label for="username">Name</label>
    <input formControlName="username" id="username" type="text" />
</div>
<div>
    <label for="website">Website</label>
    <input formControlName="website" id="website" type="url" />
</div>
<div>
    <button type="submit" class="button primary block" [disabled]="loading">
      {{ loading ? 'Loading ...' : 'Update' }}
    </button>
</div>
<div>
    <button class="button block" (click)="signOut()">Sign Out</button>
</div>
</form>
`

### Launch! [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-angular\#launch)

Now that we have all the components in place, let's update `AppComponent`:

src/app/app.component.ts

`
import { Component, OnInit } from '@angular/core'
import { SupabaseService } from './supabase.service'
@Component({
selector: 'app-root',
templateUrl: './app.component.html',
styleUrls: ['./app.component.css'],
})
export class AppComponent implements OnInit {
title = 'angular-user-management'
session = this.supabase.session
constructor(private readonly supabase: SupabaseService) {}
ngOnInit() {
    this.supabase.authChanges((_, session) => (this.session = session))
}
}
`

src/app/app.component.html

`
<div class="container" style="padding: 50px 0 100px 0">
<app-account *ngIf="session; else auth" [session]="session"></app-account>
<ng-template #auth>
    <app-auth></app-auth>
</ng-template>
</div>
`

`app.module.ts` also needs to be modified to include the `ReactiveFormsModule` from the `@angular/forms` package.

src/app/app.module.ts

`
import { NgModule } from '@angular/core'
import { BrowserModule } from '@angular/platform-browser'
import { AppComponent } from './app.component'
import { AuthComponent } from './auth/auth.component'
import { AccountComponent } from './account/account.component'
import { ReactiveFormsModule } from '@angular/forms'
import { AvatarComponent } from './avatar/avatar.component'
@NgModule({
declarations: [AppComponent, AuthComponent, AccountComponent, AvatarComponent],
imports: [BrowserModule, ReactiveFormsModule],
providers: [],
bootstrap: [AppComponent],
})
export class AppModule {}
`

Once that's done, run this in a terminal window:

`
npm run start
`

And then open the browser to [localhost:4200](http://localhost:4200/) and you should see the completed app.

![Supabase Angular](https://supabase.com/docs/img/supabase-angular-demo.png)

## Bonus: Profile photos [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-angular\#bonus-profile-photos)

Every Supabase project is configured with [Storage](https://supabase.com/docs/guides/storage) for managing large files like photos and videos.

### Create an upload widget [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-angular\#create-an-upload-widget)

Let's create an avatar for the user so that they can upload a profile photo.
Create an `AvatarComponent` with `ng g c avatar` Angular CLI command.

src/app/avatar/avatar.component.ts

``
import { Component, EventEmitter, Input, Output } from '@angular/core'
import { SafeResourceUrl, DomSanitizer } from '@angular/platform-browser'
import { SupabaseService } from '../supabase.service'
@Component({
selector: 'app-avatar',
templateUrl: './avatar.component.html',
styleUrls: ['./avatar.component.css'],
})
export class AvatarComponent {
_avatarUrl: SafeResourceUrl | undefined
uploading = false
@Input()
set avatarUrl(url: string | null) {
    if (url) {
      this.downloadImage(url)
    }
}
@Output() upload = new EventEmitter<string>()
constructor(
    private readonly supabase: SupabaseService,
    private readonly dom: DomSanitizer
) {}
async downloadImage(path: string) {
    try {
      const { data } = await this.supabase.downLoadImage(path)
      if (data instanceof Blob) {
        this._avatarUrl = this.dom.bypassSecurityTrustResourceUrl(URL.createObjectURL(data))
      }
    } catch (error) {
      if (error instanceof Error) {
        console.error('Error downloading image: ', error.message)
      }
    }
}
async uploadAvatar(event: any) {
    try {
      this.uploading = true
      if (!event.target.files || event.target.files.length === 0) {
        throw new Error('You must select an image to upload.')
      }
      const file = event.target.files[0]
      const fileExt = file.name.split('.').pop()
      const filePath = `${Math.random()}.${fileExt}`
      await this.supabase.uploadAvatar(filePath, file)
      this.upload.emit(filePath)
    } catch (error) {
      if (error instanceof Error) {
        alert(error.message)
      }
    } finally {
      this.uploading = false
    }
}
}
``

src/app/avatar/avatar.component.html

`
<div>
<img
    *ngIf="_avatarUrl"
    [src]="_avatarUrl"
    alt="Avatar"
    class="avatar image"
    style="height: 150px; width: 150px"
/>
</div>
<div *ngIf="!_avatarUrl" class="avatar no-image" style="height: 150px; width: 150px"></div>
<div style="width: 150px">
<label class="button primary block" for="single">
    {{ uploading ? 'Uploading ...' : 'Upload' }}
</label>
<input
    style="visibility: hidden;position: absolute"
    type="file"
    id="single"
    accept="image/*"
    (change)="uploadAvatar($event)"
    [disabled]="uploading"
/>
</div>
`

### Add the new widget [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-angular\#add-the-new-widget)

And then we can add the widget on top of the `AccountComponent` HTML template:

src/app/account.component.html

`
<form [formGroup]="updateProfileForm" (ngSubmit)="updateProfile()" class="form-widget">
<app-avatar [avatarUrl]="this.avatarUrl" (upload)="updateAvatar($event)"> </app-avatar>
<!-- input fields -->
</form>
`

And add an `updateAvatar` function along with an `avatarUrl` getter to the `AccountComponent` typescript file:

src/app/account.component.ts

`
@Component({
selector: 'app-account',
templateUrl: './account.component.html',
styleUrls: ['./account.component.css'],
})
export class AccountComponent implements OnInit {
// ...
get avatarUrl() {
    return this.updateProfileForm.value.avatar_url as string
}
async updateAvatar(event: string): Promise<void> {
    this.updateProfileForm.patchValue({
      avatar_url: event,
    })
    await this.updateProfile()
}
// ...
}
`

At this stage you have a fully functional application!

### Is this helpful?

NoYes

### On this page

[Project setup](https://supabase.com/docs/guides/getting-started/tutorials/with-angular#project-setup) [Create a project](https://supabase.com/docs/guides/getting-started/tutorials/with-angular#create-a-project) [Set up the database schema](https://supabase.com/docs/guides/getting-started/tutorials/with-angular#set-up-the-database-schema) [Get the API Keys](https://supabase.com/docs/guides/getting-started/tutorials/with-angular#get-the-api-keys) [Building the app](https://supabase.com/docs/guides/getting-started/tutorials/with-angular#building-the-app) [Initialize an Angular app](https://supabase.com/docs/guides/getting-started/tutorials/with-angular#initialize-an-angular-app) [Set up a login component](https://supabase.com/docs/guides/getting-started/tutorials/with-angular#set-up-a-login-component) [Account page](https://supabase.com/docs/guides/getting-started/tutorials/with-angular#account-page) [Launch!](https://supabase.com/docs/guides/getting-started/tutorials/with-angular#launch) [Bonus: Profile photos](https://supabase.com/docs/guides/getting-started/tutorials/with-angular#bonus-profile-photos) [Create an upload widget](https://supabase.com/docs/guides/getting-started/tutorials/with-angular#create-an-upload-widget) [Add the new widget](https://supabase.com/docs/guides/getting-started/tutorials/with-angular#add-the-new-widget)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_tutorials_with_expo_react_native.md">
Getting Started

# Build a User Management App with Expo React Native

* * *

This tutorial demonstrates how to build a basic user management app. The app authenticates and identifies the user, stores their profile information in the database, and allows the user to log in, update their profile details, and upload a profile photo. The app uses:

- [Supabase Database](https://supabase.com/docs/guides/database) \- a Postgres database for storing your user data and [Row Level Security](https://supabase.com/docs/guides/auth#row-level-security) so data is protected and users can only access their own information.
- [Supabase Auth](https://supabase.com/docs/guides/auth) \- allow users to sign up and log in.
- [Supabase Storage](https://supabase.com/docs/guides/storage) \- users can upload a profile photo.

![Supabase User Management example](https://supabase.com/docs/img/supabase-flutter-demo.png)

If you get stuck while working through this guide, refer to the [full example on GitHub](https://github.com/supabase/supabase/tree/master/examples/user-management/expo-user-management).

## Project setup [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-expo-react-native\#project-setup)

Before we start building we're going to set up our Database and API. This is as simple as starting a new Project in Supabase and then creating a "schema" inside the database.

### Create a project [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-expo-react-native\#create-a-project)

1. [Create a new project](https://supabase.com/dashboard) in the Supabase Dashboard.
2. Enter your project details.
3. Wait for the new database to launch.

### Set up the database schema [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-expo-react-native\#set-up-the-database-schema)

Now we are going to set up the database schema. We can use the "User Management Starter" quickstart in the SQL Editor, or you can just copy/paste the SQL from below and run it yourself.

DashboardSQL

1. Go to the [SQL Editor](https://supabase.com/dashboard/project/_/sql) page in the Dashboard.
2. Click **User Management Starter**.
3. Click **Run**.

You can easily pull the database schema down to your local project by running the `db pull` command. Read the [local development docs](https://supabase.com/docs/guides/cli/local-development#link-your-project) for detailed instructions.

`
supabase link --project-ref <project-id>
# You can get <project-id> from your project's dashboard URL: https://supabase.com/dashboard/project/<project-id>
supabase db pull
`

### Get the API Keys [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-expo-react-native\#get-the-api-keys)

Now that you've created some database tables, you are ready to insert data using the auto-generated API.
We just need to get the Project URL and `anon` key from the API settings.

1. Go to the [API Settings](https://supabase.com/dashboard/project/_/settings/api) page in the Dashboard.
2. Find your Project `URL`, `anon`, and `service_role` keys on this page.

## Building the app [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-expo-react-native\#building-the-app)

Let's start building the React Native app from scratch.

### Initialize a React Native app [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-expo-react-native\#initialize-a-react-native-app)

We can use [`expo`](https://docs.expo.dev/get-started/create-a-new-app/) to initialize
an app called `expo-user-management`:

`
npx create-expo-app -t expo-template-blank-typescript expo-user-management
cd expo-user-management
`

Then let's install the additional dependencies: [supabase-js](https://github.com/supabase/supabase-js)

`
npx expo install @supabase/supabase-js @react-native-async-storage/async-storage @rneui/themed
`

Now let's create a helper file to initialize the Supabase client.
We need the API URL and the `anon` key that you copied [earlier](https://supabase.com/docs/guides/getting-started/tutorials/with-expo-react-native#get-the-api-keys).
These variables are safe to expose in your Expo app since Supabase has
[Row Level Security](https://supabase.com/docs/guides/database/postgres/row-level-security) enabled on your Database.

AsyncStorageSecureStore

lib/supabase.ts

`
import AsyncStorage from '@react-native-async-storage/async-storage'
import { createClient } from '@supabase/supabase-js'
const supabaseUrl = YOUR_REACT_NATIVE_SUPABASE_URL
const supabaseAnonKey = YOUR_REACT_NATIVE_SUPABASE_ANON_KEY
export const supabase = createClient(supabaseUrl, supabaseAnonKey, {
auth: {
    storage: AsyncStorage,
    autoRefreshToken: true,
    persistSession: true,
    detectSessionInUrl: false,
},
})
`

### Set up a login component [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-expo-react-native\#set-up-a-login-component)

Let's set up a React Native component to manage logins and sign ups.
Users would be able to sign in with their email and password.

components/Auth.tsx

``
import React, { useState } from 'react'
import { Alert, StyleSheet, View, AppState } from 'react-native'
import { supabase } from '../lib/supabase'
import { Button, Input } from '@rneui/themed'
// Tells Supabase Auth to continuously refresh the session automatically if
// the app is in the foreground. When this is added, you will continue to receive
// `onAuthStateChange` events with the `TOKEN_REFRESHED` or `SIGNED_OUT` event
// if the user's session is terminated. This should only be registered once.
AppState.addEventListener('change', (state) => {
if (state === 'active') {
    supabase.auth.startAutoRefresh()
} else {
    supabase.auth.stopAutoRefresh()
}
})
export default function Auth() {
const [email, setEmail] = useState('')
const [password, setPassword] = useState('')
const [loading, setLoading] = useState(false)
async function signInWithEmail() {
    setLoading(true)
    const { error } = await supabase.auth.signInWithPassword({
      email: email,
      password: password,
    })
    if (error) Alert.alert(error.message)
    setLoading(false)
}
async function signUpWithEmail() {
    setLoading(true)
    const {
      data: { session },
      error,
    } = await supabase.auth.signUp({
      email: email,
      password: password,
    })
    if (error) Alert.alert(error.message)
    if (!session) Alert.alert('Please check your inbox for email verification!')
    setLoading(false)
}
return (
    <View style={styles.container}>
      <View style={[styles.verticallySpaced, styles.mt20]}>
        <Input
          label="Email"
          leftIcon={{ type: 'font-awesome', name: 'envelope' }}
          onChangeText={(text) => setEmail(text)}
          value={email}
          placeholder="email@address.com"
          autoCapitalize={'none'}
        />
      </View>
      <View style={styles.verticallySpaced}>
        <Input
          label="Password"
          leftIcon={{ type: 'font-awesome', name: 'lock' }}
          onChangeText={(text) => setPassword(text)}
          value={password}
          secureTextEntry={true}
          placeholder="Password"
          autoCapitalize={'none'}
        />
      </View>
      <View style={[styles.verticallySpaced, styles.mt20]}>
        <Button title="Sign in" disabled={loading} onPress={() => signInWithEmail()} />
      </View>
      <View style={styles.verticallySpaced}>
        <Button title="Sign up" disabled={loading} onPress={() => signUpWithEmail()} />
      </View>
    </View>
)
}
const styles = StyleSheet.create({
container: {
    marginTop: 40,
    padding: 12,
},
verticallySpaced: {
    paddingTop: 4,
    paddingBottom: 4,
    alignSelf: 'stretch',
},
mt20: {
    marginTop: 20,
},
})
``

By default Supabase Auth requires email verification before a session is created for the users. To support email verification you need to [implement deep link handling](https://supabase.com/docs/guides/auth/native-mobile-deep-linking?platform=react-native)!

While testing, you can disable email confirmation in your [project's email auth provider settings](https://supabase.com/dashboard/project/_/auth/providers).

### Account page [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-expo-react-native\#account-page)

After a user is signed in we can allow them to edit their profile details and manage their account.

Let's create a new component for that called `Account.tsx`.

components/Account.tsx

``
import { useState, useEffect } from 'react'
import { supabase } from '../lib/supabase'
import { StyleSheet, View, Alert } from 'react-native'
import { Button, Input } from '@rneui/themed'
import { Session } from '@supabase/supabase-js'
export default function Account({ session }: { session: Session }) {
const [loading, setLoading] = useState(true)
const [username, setUsername] = useState('')
const [website, setWebsite] = useState('')
const [avatarUrl, setAvatarUrl] = useState('')
useEffect(() => {
    if (session) getProfile()
}, [session])
async function getProfile() {
    try {
      setLoading(true)
      if (!session?.user) throw new Error('No user on the session!')
      const { data, error, status } = await supabase
        .from('profiles')
        .select(`username, website, avatar_url`)
        .eq('id', session?.user.id)
        .single()
      if (error && status !== 406) {
        throw error
      }
      if (data) {
        setUsername(data.username)
        setWebsite(data.website)
        setAvatarUrl(data.avatar_url)
      }
    } catch (error) {
      if (error instanceof Error) {
        Alert.alert(error.message)
      }
    } finally {
      setLoading(false)
    }
}
async function updateProfile({
    username,
    website,
    avatar_url,
}: {
    username: string
    website: string
    avatar_url: string
}) {
    try {
      setLoading(true)
      if (!session?.user) throw new Error('No user on the session!')
      const updates = {
        id: session?.user.id,
        username,
        website,
        avatar_url,
        updated_at: new Date(),
      }
      const { error } = await supabase.from('profiles').upsert(updates)
      if (error) {
        throw error
      }
    } catch (error) {
      if (error instanceof Error) {
        Alert.alert(error.message)
      }
    } finally {
      setLoading(false)
    }
}
return (
    <View style={styles.container}>
      <View style={[styles.verticallySpaced, styles.mt20]}>
        <Input label="Email" value={session?.user?.email} disabled />
      </View>
      <View style={styles.verticallySpaced}>
        <Input label="Username" value={username || ''} onChangeText={(text) => setUsername(text)} />
      </View>
      <View style={styles.verticallySpaced}>
        <Input label="Website" value={website || ''} onChangeText={(text) => setWebsite(text)} />
      </View>
      <View style={[styles.verticallySpaced, styles.mt20]}>
        <Button
          title={loading ? 'Loading ...' : 'Update'}
          onPress={() => updateProfile({ username, website, avatar_url: avatarUrl })}
          disabled={loading}
        />
      </View>
      <View style={styles.verticallySpaced}>
        <Button title="Sign Out" onPress={() => supabase.auth.signOut()} />
      </View>
    </View>
)
}
const styles = StyleSheet.create({
container: {
    marginTop: 40,
    padding: 12,
},
verticallySpaced: {
    paddingTop: 4,
    paddingBottom: 4,
    alignSelf: 'stretch',
},
mt20: {
    marginTop: 20,
},
})
``

### Launch! [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-expo-react-native\#launch)

Now that we have all the components in place, let's update `App.tsx`:

App.tsx

`
import { useState, useEffect } from 'react'
import { supabase } from './lib/supabase'
import Auth from './components/Auth'
import Account from './components/Account'
import { View } from 'react-native'
import { Session } from '@supabase/supabase-js'
export default function App() {
const [session, setSession] = useState<Session | null>(null)
useEffect(() => {
    supabase.auth.getSession().then(({ data: { session } }) => {
      setSession(session)
    })
    supabase.auth.onAuthStateChange((_event, session) => {
      setSession(session)
    })
}, [])
return (
    <View>
      {session && session.user ? <Account key={session.user.id} session={session} /> : <Auth />}
    </View>
)
}
`

Once that's done, run this in a terminal window:

`
npm start
`

And then press the appropriate key for the environment you want to test the app in and you should see the completed app.

## Bonus: Profile photos [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-expo-react-native\#bonus-profile-photos)

Every Supabase project is configured with [Storage](https://supabase.com/docs/guides/storage) for managing large files like
photos and videos.

### Additional dependency installation [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-expo-react-native\#additional-dependency-installation)

You will need an image picker that works on the environment you will build the project for, we will use `expo-image-picker` in this example.

`
npx expo install expo-image-picker
`

### Create an upload widget [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-expo-react-native\#create-an-upload-widget)

Let's create an avatar for the user so that they can upload a profile photo.
We can start by creating a new component:

components/Avatar.tsx

``
import { useState, useEffect } from 'react'
import { supabase } from '../lib/supabase'
import { StyleSheet, View, Alert, Image, Button } from 'react-native'
import * as ImagePicker from 'expo-image-picker'
interface Props {
size: number
url: string | null
onUpload: (filePath: string) => void
}
export default function Avatar({ url, size = 150, onUpload }: Props) {
const [uploading, setUploading] = useState(false)
const [avatarUrl, setAvatarUrl] = useState<string | null>(null)
const avatarSize = { height: size, width: size }
useEffect(() => {
    if (url) downloadImage(url)
}, [url])
async function downloadImage(path: string) {
    try {
      const { data, error } = await supabase.storage.from('avatars').download(path)
      if (error) {
        throw error
      }
      const fr = new FileReader()
      fr.readAsDataURL(data)
      fr.onload = () => {
        setAvatarUrl(fr.result as string)
      }
    } catch (error) {
      if (error instanceof Error) {
        console.log('Error downloading image: ', error.message)
      }
    }
}
async function uploadAvatar() {
    try {
      setUploading(true)
      const result = await ImagePicker.launchImageLibraryAsync({
        mediaTypes: ImagePicker.MediaTypeOptions.Images, // Restrict to only images
        allowsMultipleSelection: false, // Can only select one image
        allowsEditing: true, // Allows the user to crop / rotate their photo before uploading it
        quality: 1,
        exif: false, // We don't want nor need that data.
      })
      if (result.canceled || !result.assets || result.assets.length === 0) {
        console.log('User cancelled image picker.')
        return
      }
      const image = result.assets[0]
      console.log('Got image', image)
      if (!image.uri) {
        throw new Error('No image uri!') // Realistically, this should never happen, but just in case...
      }
      const arraybuffer = await fetch(image.uri).then((res) => res.arrayBuffer())
      const fileExt = image.uri?.split('.').pop()?.toLowerCase() ?? 'jpeg'
      const path = `${Date.now()}.${fileExt}`
      const { data, error: uploadError } = await supabase.storage
        .from('avatars')
        .upload(path, arraybuffer, {
          contentType: image.mimeType ?? 'image/jpeg',
        })
      if (uploadError) {
        throw uploadError
      }
      onUpload(data.path)
    } catch (error) {
      if (error instanceof Error) {
        Alert.alert(error.message)
      } else {
        throw error
      }
    } finally {
      setUploading(false)
    }
}
return (
    <View>
      {avatarUrl ? (
        <Image
          source={{ uri: avatarUrl }}
          accessibilityLabel="Avatar"
          style={[avatarSize, styles.avatar, styles.image]}
        />
      ) : (
        <View style={[avatarSize, styles.avatar, styles.noImage]} />
      )}
      <View>
        <Button
          title={uploading ? 'Uploading ...' : 'Upload'}
          onPress={uploadAvatar}
          disabled={uploading}
        />
      </View>
    </View>
)
}
const styles = StyleSheet.create({
avatar: {
    borderRadius: 5,
    overflow: 'hidden',
    maxWidth: '100%',
},
image: {
    objectFit: 'cover',
    paddingTop: 0,
},
noImage: {
    backgroundColor: '#333',
    borderWidth: 1,
    borderStyle: 'solid',
    borderColor: 'rgb(200, 200, 200)',
    borderRadius: 5,
},
})
``

### Add the new widget [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-expo-react-native\#add-the-new-widget)

And then we can add the widget to the Account page:

components/Account.tsx

`
// Import the new component
import Avatar from './Avatar'
// ...
return (
<View>
    {/* Add to the body */}
    <View>
      <Avatar
        size={200}
        url={avatarUrl}
        onUpload={(url: string) => {
          setAvatarUrl(url)
          updateProfile({ username, website, avatar_url: url })
        }}
      />
    </View>
    {/* ... */}
</View>
)
// ...
`

Now you will need to run the prebuild command to get the application working on your chosen platform.

`
npx expo prebuild
`

At this stage you have a fully functional application!

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2FAE7dKIKMJy4%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Project setup](https://supabase.com/docs/guides/getting-started/tutorials/with-expo-react-native#project-setup) [Create a project](https://supabase.com/docs/guides/getting-started/tutorials/with-expo-react-native#create-a-project) [Set up the database schema](https://supabase.com/docs/guides/getting-started/tutorials/with-expo-react-native#set-up-the-database-schema) [Get the API Keys](https://supabase.com/docs/guides/getting-started/tutorials/with-expo-react-native#get-the-api-keys) [Building the app](https://supabase.com/docs/guides/getting-started/tutorials/with-expo-react-native#building-the-app) [Initialize a React Native app](https://supabase.com/docs/guides/getting-started/tutorials/with-expo-react-native#initialize-a-react-native-app) [Set up a login component](https://supabase.com/docs/guides/getting-started/tutorials/with-expo-react-native#set-up-a-login-component) [Account page](https://supabase.com/docs/guides/getting-started/tutorials/with-expo-react-native#account-page) [Launch!](https://supabase.com/docs/guides/getting-started/tutorials/with-expo-react-native#launch) [Bonus: Profile photos](https://supabase.com/docs/guides/getting-started/tutorials/with-expo-react-native#bonus-profile-photos) [Additional dependency installation](https://supabase.com/docs/guides/getting-started/tutorials/with-expo-react-native#additional-dependency-installation) [Create an upload widget](https://supabase.com/docs/guides/getting-started/tutorials/with-expo-react-native#create-an-upload-widget) [Add the new widget](https://supabase.com/docs/guides/getting-started/tutorials/with-expo-react-native#add-the-new-widget)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_tutorials_with_flutter.md">
Getting Started

# Build a User Management App with Flutter

* * *

This tutorial demonstrates how to build a basic user management app. The app authenticates and identifies the user, stores their profile information in the database, and allows the user to log in, update their profile details, and upload a profile photo. The app uses:

- [Supabase Database](https://supabase.com/docs/guides/database) \- a Postgres database for storing your user data and [Row Level Security](https://supabase.com/docs/guides/auth#row-level-security) so data is protected and users can only access their own information.
- [Supabase Auth](https://supabase.com/docs/guides/auth) \- allow users to sign up and log in.
- [Supabase Storage](https://supabase.com/docs/guides/storage) \- users can upload a profile photo.

![Supabase User Management example](https://supabase.com/docs/img/supabase-flutter-demo.png)

If you get stuck while working through this guide, refer to the [full example on GitHub](https://github.com/supabase/supabase/tree/master/examples/user-management/flutter-user-management).

## Project setup [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter\#project-setup)

Before we start building we're going to set up our Database and API. This is as simple as starting a new Project in Supabase and then creating a "schema" inside the database.

### Create a project [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter\#create-a-project)

1. [Create a new project](https://supabase.com/dashboard) in the Supabase Dashboard.
2. Enter your project details.
3. Wait for the new database to launch.

### Set up the database schema [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter\#set-up-the-database-schema)

Now we are going to set up the database schema. We can use the "User Management Starter" quickstart in the SQL Editor, or you can just copy/paste the SQL from below and run it yourself.

DashboardSQL

1. Go to the [SQL Editor](https://supabase.com/dashboard/project/_/sql) page in the Dashboard.
2. Click **User Management Starter**.
3. Click **Run**.

You can easily pull the database schema down to your local project by running the `db pull` command. Read the [local development docs](https://supabase.com/docs/guides/cli/local-development#link-your-project) for detailed instructions.

`
supabase link --project-ref <project-id>
# You can get <project-id> from your project's dashboard URL: https://supabase.com/dashboard/project/<project-id>
supabase db pull
`

### Get the API Keys [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter\#get-the-api-keys)

Now that you've created some database tables, you are ready to insert data using the auto-generated API.
We just need to get the Project URL and `anon` key from the API settings.

1. Go to the [API Settings](https://supabase.com/dashboard/project/_/settings/api) page in the Dashboard.
2. Find your Project `URL`, `anon`, and `service_role` keys on this page.

## Building the app [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter\#building-the-app)

Let's start building the Flutter app from scratch.

### Initialize a Flutter app [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter\#initialize-a-flutter-app)

We can use [`flutter create`](https://flutter.dev/docs/get-started/test-drive) to initialize
an app called `supabase_quickstart`:

`
flutter create supabase_quickstart
`

Then let's install the only additional dependency: [`supabase_flutter`](https://pub.dev/packages/supabase_flutter)

Copy and paste the following line in your pubspec.yaml to install the package:

`
supabase_flutter: ^2.0.0
`

Run `flutter pub get` to install the dependencies.

### Setup deep links [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter\#setup-deep-links)

Now that we have the dependencies installed let's setup deep links.
Setting up deep links is required to bring back the user to the app when they click on the magic link to sign in.
We can setup deep links with just a minor tweak on our Flutter application.

We have to use `io.supabase.flutterquickstart` as the scheme. In this example, we will use `login-callback` as the host for our deep link, but you can change it to whatever you would like.

First, add `io.supabase.flutterquickstart://login-callback/` as a new [redirect URL](https://supabase.com/dashboard/project/_/auth/url-configuration) in the Dashboard.

![Supabase console deep link setting](https://supabase.com/docs/img/deeplink-setting.png)

That is it on Supabase's end and the rest are platform specific settings:

iOSAndroidWeb

Edit the `ios/Runner/Info.plist` file.

Add `CFBundleURLTypes` to enable deep linking:

ios/Runner/Info.plist"

`
<!-- ... other tags -->
<plist>
<dict>
<!-- ... other tags -->
<!-- Add this array for Deep Links -->
<key>CFBundleURLTypes</key>
<array>
    <dict>
      <key>CFBundleTypeRole</key>
      <string>Editor</string>
      <key>CFBundleURLSchemes</key>
      <array>
        <string>io.supabase.flutterquickstart</string>
      </array>
    </dict>
</array>
<!-- ... other tags -->
</dict>
</plist>
`

### Main function [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter\#main-function)

Now that we have deep links ready let's initialize the Supabase client inside our `main` function with the API credentials that you copied [earlier](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter#get-the-api-keys). These variables will be exposed on the app, and that's completely fine since we have [Row Level Security](https://supabase.com/docs/guides/auth#row-level-security) enabled on our Database.

lib/main.dart

`
import 'package:flutter/material.dart';
import 'package:supabase_flutter/supabase_flutter.dart';
Future<void> main() async {
await Supabase.initialize(
    url: 'YOUR_SUPABASE_URL',
    anonKey: 'YOUR_SUPABASE_ANON_KEY',
);
runApp(const MyApp());
}
final supabase = Supabase.instance.client;
class MyApp extends StatelessWidget {
const MyApp({super.key});
@override
Widget build(BuildContext context) {
    return const MaterialApp(title: 'Supabase Flutter');
}
}
extension ContextExtension on BuildContext {
void showSnackBar(String message, {bool isError = false}) {
    ScaffoldMessenger.of(this).showSnackBar(
      SnackBar(
        content: Text(message),
        backgroundColor: isError
            ? Theme.of(this).colorScheme.error
            : Theme.of(this).snackBarTheme.backgroundColor,
      ),
    );
}
}
`

Notice that we have a `showSnackBar` extension method that we will use to show snack bars in the app. You could define this method in a separate file and import it where needed, but for simplicity, we will define it here.

### Set up a login page [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter\#set-up-a-login-page)

Let's create a Flutter widget to manage logins and sign ups. We will use Magic Links, so users can sign in with their email without using passwords.

Notice that this page sets up a listener on the user's auth state using `onAuthStateChange`. A new event will fire when the user comes back to the app by clicking their magic link, which this page can catch and redirect the user accordingly.

lib/pages/login\_page.dart

`
import 'dart:async';
import 'package:flutter/foundation.dart';
import 'package:flutter/material.dart';
import 'package:supabase_flutter/supabase_flutter.dart';
import 'package:supabase_quickstart/main.dart';
import 'package:supabase_quickstart/pages/account_page.dart';
class LoginPage extends StatefulWidget {
const LoginPage({super.key});
@override
State<LoginPage> createState() => _LoginPageState();
}
class _LoginPageState extends State<LoginPage> {
bool _isLoading = false;
bool _redirecting = false;
late final TextEditingController _emailController = TextEditingController();
late final StreamSubscription<AuthState> _authStateSubscription;
Future<void> _signIn() async {
    try {
      setState(() {
        _isLoading = true;
      });
      await supabase.auth.signInWithOtp(
        email: _emailController.text.trim(),
        emailRedirectTo:
            kIsWeb ? null : 'io.supabase.flutterquickstart://login-callback/',
      );
      if (mounted) {
        context.showSnackBar('Check your email for a login link!');
        _emailController.clear();
      }
    } on AuthException catch (error) {
      if (mounted) context.showSnackBar(error.message, isError: true);
    } catch (error) {
      if (mounted) {
        context.showSnackBar('Unexpected error occurred', isError: true);
      }
    } finally {
      if (mounted) {
        setState(() {
          _isLoading = false;
        });
      }
    }
}
@override
void initState() {
    _authStateSubscription = supabase.auth.onAuthStateChange.listen(
      (data) {
        if (_redirecting) return;
        final session = data.session;
        if (session != null) {
          _redirecting = true;
          Navigator.of(context).pushReplacement(
            MaterialPageRoute(builder: (context) => const AccountPage()),
          );
        }
      },
      onError: (error) {
        if (error is AuthException) {
          context.showSnackBar(error.message, isError: true);
        } else {
          context.showSnackBar('Unexpected error occurred', isError: true);
        }
      },
    );
    super.initState();
}
@override
void dispose() {
    _emailController.dispose();
    _authStateSubscription.cancel();
    super.dispose();
}
@override
Widget build(BuildContext context) {
    return Scaffold(
      appBar: AppBar(title: const Text('Sign In')),
      body: ListView(
        padding: const EdgeInsets.symmetric(vertical: 18, horizontal: 12),
        children: [\
          const Text('Sign in via the magic link with your email below'),\
          const SizedBox(height: 18),\
          TextFormField(\
            controller: _emailController,\
            decoration: const InputDecoration(labelText: 'Email'),\
          ),\
          const SizedBox(height: 18),\
          ElevatedButton(\
            onPressed: _isLoading ? null : _signIn,\
            child: Text(_isLoading ? 'Sending...' : 'Send Magic Link'),\
          ),\
        ],
      ),
    );
}
}
`

### Set up account page [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter\#set-up-account-page)

After a user is signed in we can allow them to edit their profile details and manage their account.
Let's create a new widget called `account_page.dart` for that.

lib/pages/account\_page.dart"

``
import 'package:flutter/material.dart';
import 'package:supabase_flutter/supabase_flutter.dart';
import 'package:supabase_quickstart/main.dart';
import 'package:supabase_quickstart/pages/login_page.dart';
class AccountPage extends StatefulWidget {
const AccountPage({super.key});
@override
State<AccountPage> createState() => _AccountPageState();
}
class _AccountPageState extends State<AccountPage> {
final _usernameController = TextEditingController();
final _websiteController = TextEditingController();
String? _avatarUrl;
var _loading = true;
/// Called once a user id is received within `onAuthenticated()`
Future<void> _getProfile() async {
    setState(() {
      _loading = true;
    });
    try {
      final userId = supabase.auth.currentSession!.user.id;
      final data =
          await supabase.from('profiles').select().eq('id', userId).single();
      _usernameController.text = (data['username'] ?? '') as String;
      _websiteController.text = (data['website'] ?? '') as String;
      _avatarUrl = (data['avatar_url'] ?? '') as String;
    } on PostgrestException catch (error) {
      if (mounted) context.showSnackBar(error.message, isError: true);
    } catch (error) {
      if (mounted) {
        context.showSnackBar('Unexpected error occurred', isError: true);
      }
    } finally {
      if (mounted) {
        setState(() {
          _loading = false;
        });
      }
    }
}
/// Called when user taps `Update` button
Future<void> _updateProfile() async {
    setState(() {
      _loading = true;
    });
    final userName = _usernameController.text.trim();
    final website = _websiteController.text.trim();
    final user = supabase.auth.currentUser;
    final updates = {
      'id': user!.id,
      'username': userName,
      'website': website,
      'updated_at': DateTime.now().toIso8601String(),
    };
    try {
      await supabase.from('profiles').upsert(updates);
      if (mounted) context.showSnackBar('Successfully updated profile!');
    } on PostgrestException catch (error) {
      if (mounted) context.showSnackBar(error.message, isError: true);
    } catch (error) {
      if (mounted) {
        context.showSnackBar('Unexpected error occurred', isError: true);
      }
    } finally {
      if (mounted) {
        setState(() {
          _loading = false;
        });
      }
    }
}
Future<void> _signOut() async {
    try {
      await supabase.auth.signOut();
    } on AuthException catch (error) {
      if (mounted) context.showSnackBar(error.message, isError: true);
    } catch (error) {
      if (mounted) {
        context.showSnackBar('Unexpected error occurred', isError: true);
      }
    } finally {
      if (mounted) {
        Navigator.of(context).pushReplacement(
          MaterialPageRoute(builder: (_) => const LoginPage()),
        );
      }
    }
}
@override
void initState() {
    super.initState();
    _getProfile();
}
@override
void dispose() {
    _usernameController.dispose();
    _websiteController.dispose();
    super.dispose();
}
@override
Widget build(BuildContext context) {
    return Scaffold(
      appBar: AppBar(title: const Text('Profile')),
      body: ListView(
        padding: const EdgeInsets.symmetric(vertical: 18, horizontal: 12),
        children: [\
          TextFormField(\
            controller: _usernameController,\
            decoration: const InputDecoration(labelText: 'User Name'),\
          ),\
          const SizedBox(height: 18),\
          TextFormField(\
            controller: _websiteController,\
            decoration: const InputDecoration(labelText: 'Website'),\
          ),\
          const SizedBox(height: 18),\
          ElevatedButton(\
            onPressed: _loading ? null : _updateProfile,\
            child: Text(_loading ? 'Saving...' : 'Update'),\
          ),\
          const SizedBox(height: 18),\
          TextButton(onPressed: _signOut, child: const Text('Sign Out')),\
        ],
      ),
    );
}
}
``

### Launch! [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter\#launch)

Now that we have all the components in place, let's update `lib/main.dart`.
The `home` of the `MaterialApp`, meaning the initial page shown to the user, will be the `LoginPage` if the user is not authenticated, and the `AccountPage` if the user is authenticated.
We also included some theming to make the app look a bit nicer.

lib/main.dart

`
import 'package:flutter/material.dart';
import 'package:supabase_flutter/supabase_flutter.dart';
import 'package:supabase_quickstart/pages/account_page.dart';
import 'package:supabase_quickstart/pages/login_page.dart';
Future<void> main() async {
await Supabase.initialize(
    url: 'YOUR_SUPABASE_URL',
    anonKey: 'YOUR_SUPABASE_ANON_KEY',
);
runApp(const MyApp());
}
final supabase = Supabase.instance.client;
class MyApp extends StatelessWidget {
const MyApp({super.key});
@override
Widget build(BuildContext context) {
    return MaterialApp(
      title: 'Supabase Flutter',
      theme: ThemeData.dark().copyWith(
        primaryColor: Colors.green,
        textButtonTheme: TextButtonThemeData(
          style: TextButton.styleFrom(
            foregroundColor: Colors.green,
          ),
        ),
        elevatedButtonTheme: ElevatedButtonThemeData(
          style: ElevatedButton.styleFrom(
            foregroundColor: Colors.white,
            backgroundColor: Colors.green,
          ),
        ),
      ),
      home: supabase.auth.currentSession == null
          ? const LoginPage()
          : const AccountPage(),
    );
}
}
extension ContextExtension on BuildContext {
void showSnackBar(String message, {bool isError = false}) {
    ScaffoldMessenger.of(this).showSnackBar(
      SnackBar(
        content: Text(message),
        backgroundColor: isError
            ? Theme.of(this).colorScheme.error
            : Theme.of(this).snackBarTheme.backgroundColor,
      ),
    );
}
}
`

Once that's done, run this in a terminal window to launch on Android or iOS:

`
flutter run
`

Or for web, run the following command to launch it on `localhost:3000`

`
flutter run -d web-server --web-hostname localhost --web-port 3000
`

And then open the browser to [localhost:3000](http://localhost:3000/) and you should see the completed app.

![Supabase User Management example](https://supabase.com/docs/img/supabase-flutter-account-page.png)

## Bonus: Profile photos [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter\#bonus-profile-photos)

Every Supabase project is configured with [Storage](https://supabase.com/docs/guides/storage) for managing large files like
photos and videos.

### Making sure we have a public bucket [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter\#making-sure-we-have-a-public-bucket)

We will be storing the image as a publicly sharable image.
Make sure your `avatars` bucket is set to public, and if it is not, change the publicity by clicking the dot menu that appears when you hover over the bucket name.
You should see an orange `Public` badge next to your bucket name if your bucket is set to public.

### Adding image uploading feature to account page [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter\#adding-image-uploading-feature-to-account-page)

We will use [`image_picker`](https://pub.dev/packages/image_picker) plugin to select an image from the device.

Add the following line in your pubspec.yaml file to install `image_picker`:

`
image_picker: ^1.0.5
`

Using [`image_picker`](https://pub.dev/packages/image_picker) requires some additional preparation depending on the platform.
Follow the instruction on README.md of [`image_picker`](https://pub.dev/packages/image_picker) on how to set it up for the platform you are using.

Once you are done with all of the above, it is time to dive into coding.

### Create an upload widget [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter\#create-an-upload-widget)

Let's create an avatar for the user so that they can upload a profile photo.
We can start by creating a new component:

lib/components/avatar.dart

`
import 'package:flutter/material.dart';
import 'package:image_picker/image_picker.dart';
import 'package:supabase_flutter/supabase_flutter.dart';
import 'package:supabase_quickstart/main.dart';
class Avatar extends StatefulWidget {
const Avatar({
    super.key,
    required this.imageUrl,
    required this.onUpload,
});
final String? imageUrl;
final void Function(String) onUpload;
@override
State<Avatar> createState() => _AvatarState();
}
class _AvatarState extends State<Avatar> {
bool _isLoading = false;
@override
Widget build(BuildContext context) {
    return Column(
      children: [\
        if (widget.imageUrl == null || widget.imageUrl!.isEmpty)\
          Container(\
            width: 150,\
            height: 150,\
            color: Colors.grey,\
            child: const Center(\
              child: Text('No Image'),\
            ),\
          )\
        else\
          Image.network(\
            widget.imageUrl!,\
            width: 150,\
            height: 150,\
            fit: BoxFit.cover,\
          ),\
        ElevatedButton(\
          onPressed: _isLoading ? null : _upload,\
          child: const Text('Upload'),\
        ),\
      ],
    );
}
Future<void> _upload() async {
    final picker = ImagePicker();
    final imageFile = await picker.pickImage(
      source: ImageSource.gallery,
      maxWidth: 300,
      maxHeight: 300,
    );
    if (imageFile == null) {
      return;
    }
    setState(() => _isLoading = true);
    try {
      final bytes = await imageFile.readAsBytes();
      final fileExt = imageFile.path.split('.').last;
      final fileName = '${DateTime.now().toIso8601String()}.$fileExt';
      final filePath = fileName;
      await supabase.storage.from('avatars').uploadBinary(
            filePath,
            bytes,
            fileOptions: FileOptions(contentType: imageFile.mimeType),
          );
      final imageUrlResponse = await supabase.storage
          .from('avatars')
          .createSignedUrl(filePath, 60 * 60 * 24 * 365 * 10);
      widget.onUpload(imageUrlResponse);
    } on StorageException catch (error) {
      if (mounted) {
        context.showSnackBar(error.message, isError: true);
      }
    } catch (error) {
      if (mounted) {
        context.showSnackBar('Unexpected error occurred', isError: true);
      }
    }
    setState(() => _isLoading = false);
}
}
`

### Add the new widget [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter\#add-the-new-widget)

And then we can add the widget to the Account page as well as some logic to update the `avatar_url` whenever the user uploads a new avatar.

lib/pages/account\_page.dart

``
import 'package:flutter/material.dart';
import 'package:supabase_flutter/supabase_flutter.dart';
import 'package:supabase_quickstart/components/avatar.dart';
import 'package:supabase_quickstart/main.dart';
import 'package:supabase_quickstart/pages/login_page.dart';
class AccountPage extends StatefulWidget {
const AccountPage({super.key});
@override
State<AccountPage> createState() => _AccountPageState();
}
class _AccountPageState extends State<AccountPage> {
final _usernameController = TextEditingController();
final _websiteController = TextEditingController();
String? _avatarUrl;
var _loading = true;
/// Called once a user id is received within `onAuthenticated()`
Future<void> _getProfile() async {
    setState(() {
      _loading = true;
    });
    try {
      final userId = supabase.auth.currentSession!.user.id;
      final data =
          await supabase.from('profiles').select().eq('id', userId).single();
      _usernameController.text = (data['username'] ?? '') as String;
      _websiteController.text = (data['website'] ?? '') as String;
      _avatarUrl = (data['avatar_url'] ?? '') as String;
    } on PostgrestException catch (error) {
      if (mounted) context.showSnackBar(error.message, isError: true);
    } catch (error) {
      if (mounted) {
        context.showSnackBar('Unexpected error occurred', isError: true);
      }
    } finally {
      if (mounted) {
        setState(() {
          _loading = false;
        });
      }
    }
}
/// Called when user taps `Update` button
Future<void> _updateProfile() async {
    setState(() {
      _loading = true;
    });
    final userName = _usernameController.text.trim();
    final website = _websiteController.text.trim();
    final user = supabase.auth.currentUser;
    final updates = {
      'id': user!.id,
      'username': userName,
      'website': website,
      'updated_at': DateTime.now().toIso8601String(),
    };
    try {
      await supabase.from('profiles').upsert(updates);
      if (mounted) context.showSnackBar('Successfully updated profile!');
    } on PostgrestException catch (error) {
      if (mounted) context.showSnackBar(error.message, isError: true);
    } catch (error) {
      if (mounted) {
        context.showSnackBar('Unexpected error occurred', isError: true);
      }
    } finally {
      if (mounted) {
        setState(() {
          _loading = false;
        });
      }
    }
}
Future<void> _signOut() async {
    try {
      await supabase.auth.signOut();
    } on AuthException catch (error) {
      if (mounted) context.showSnackBar(error.message, isError: true);
    } catch (error) {
      if (mounted) {
        context.showSnackBar('Unexpected error occurred', isError: true);
      }
    } finally {
      if (mounted) {
        Navigator.of(context).pushReplacement(
          MaterialPageRoute(builder: (_) => const LoginPage()),
        );
      }
    }
}
/// Called when image has been uploaded to Supabase storage from within Avatar widget
Future<void> _onUpload(String imageUrl) async {
    try {
      final userId = supabase.auth.currentUser!.id;
      await supabase.from('profiles').upsert({
        'id': userId,
        'avatar_url': imageUrl,
      });
      if (mounted) {
        const SnackBar(
          content: Text('Updated your profile image!'),
        );
      }
    } on PostgrestException catch (error) {
      if (mounted) context.showSnackBar(error.message, isError: true);
    } catch (error) {
      if (mounted) {
        context.showSnackBar('Unexpected error occurred', isError: true);
      }
    }
    if (!mounted) {
      return;
    }
    setState(() {
      _avatarUrl = imageUrl;
    });
}
@override
void initState() {
    super.initState();
    _getProfile();
}
@override
void dispose() {
    _usernameController.dispose();
    _websiteController.dispose();
    super.dispose();
}
@override
Widget build(BuildContext context) {
    return Scaffold(
      appBar: AppBar(title: const Text('Profile')),
      body: ListView(
        padding: const EdgeInsets.symmetric(vertical: 18, horizontal: 12),
        children: [\
          Avatar(\
            imageUrl: _avatarUrl,\
            onUpload: _onUpload,\
          ),\
          const SizedBox(height: 18),\
          TextFormField(\
            controller: _usernameController,\
            decoration: const InputDecoration(labelText: 'User Name'),\
          ),\
          const SizedBox(height: 18),\
          TextFormField(\
            controller: _websiteController,\
            decoration: const InputDecoration(labelText: 'Website'),\
          ),\
          const SizedBox(height: 18),\
          ElevatedButton(\
            onPressed: _loading ? null : _updateProfile,\
            child: Text(_loading ? 'Saving...' : 'Update'),\
          ),\
          const SizedBox(height: 18),\
          TextButton(onPressed: _signOut, child: const Text('Sign Out')),\
        ],
      ),
    );
}
}
``

Congratulations, you've built a fully functional user management app using Flutter and Supabase!

## See also [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter\#see-also)

- [Flutter Tutorial: building a Flutter chat app](https://supabase.com/blog/flutter-tutorial-building-a-chat-app)
- [Flutter Tutorial - Part 2: Authentication and Authorization with RLS](https://supabase.com/blog/flutter-authentication-and-authorization-with-rls)

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2Fr7ysVtZ5Row%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Project setup](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter#project-setup) [Create a project](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter#create-a-project) [Set up the database schema](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter#set-up-the-database-schema) [Get the API Keys](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter#get-the-api-keys) [Building the app](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter#building-the-app) [Initialize a Flutter app](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter#initialize-a-flutter-app) [Setup deep links](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter#setup-deep-links) [Main function](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter#main-function) [Set up a login page](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter#set-up-a-login-page) [Set up account page](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter#set-up-account-page) [Launch!](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter#launch) [Bonus: Profile photos](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter#bonus-profile-photos) [Making sure we have a public bucket](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter#making-sure-we-have-a-public-bucket) [Adding image uploading feature to account page](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter#adding-image-uploading-feature-to-account-page) [Create an upload widget](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter#create-an-upload-widget) [Add the new widget](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter#add-the-new-widget) [See also](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter#see-also)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_tutorials_with_ionic_angular.md">
Getting Started

# Build a User Management App with Ionic Angular

* * *

This tutorial demonstrates how to build a basic user management app. The app authenticates and identifies the user, stores their profile information in the database, and allows the user to log in, update their profile details, and upload a profile photo. The app uses:

- [Supabase Database](https://supabase.com/docs/guides/database) \- a Postgres database for storing your user data and [Row Level Security](https://supabase.com/docs/guides/auth#row-level-security) so data is protected and users can only access their own information.
- [Supabase Auth](https://supabase.com/docs/guides/auth) \- allow users to sign up and log in.
- [Supabase Storage](https://supabase.com/docs/guides/storage) \- users can upload a profile photo.

![Supabase User Management example](https://supabase.com/docs/img/ionic-demos/ionic-angular-account.png)

If you get stuck while working through this guide, refer to the [full example on GitHub](https://github.com/mhartington/supabase-ionic-angular).

## Project setup [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-angular\#project-setup)

Before we start building we're going to set up our Database and API. This is as simple as starting a new Project in Supabase and then creating a "schema" inside the database.

### Create a project [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-angular\#create-a-project)

1. [Create a new project](https://supabase.com/dashboard) in the Supabase Dashboard.
2. Enter your project details.
3. Wait for the new database to launch.

### Set up the database schema [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-angular\#set-up-the-database-schema)

Now we are going to set up the database schema. We can use the "User Management Starter" quickstart in the SQL Editor, or you can just copy/paste the SQL from below and run it yourself.

DashboardSQL

1. Go to the [SQL Editor](https://supabase.com/dashboard/project/_/sql) page in the Dashboard.
2. Click **User Management Starter**.
3. Click **Run**.

You can easily pull the database schema down to your local project by running the `db pull` command. Read the [local development docs](https://supabase.com/docs/guides/cli/local-development#link-your-project) for detailed instructions.

`
supabase link --project-ref <project-id>
# You can get <project-id> from your project's dashboard URL: https://supabase.com/dashboard/project/<project-id>
supabase db pull
`

### Get the API Keys [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-angular\#get-the-api-keys)

Now that you've created some database tables, you are ready to insert data using the auto-generated API.
We just need to get the Project URL and `anon` key from the API settings.

1. Go to the [API Settings](https://supabase.com/dashboard/project/_/settings/api) page in the Dashboard.
2. Find your Project `URL`, `anon`, and `service_role` keys on this page.

## Building the app [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-angular\#building-the-app)

Let's start building the Angular app from scratch.

### Initialize an Ionic Angular app [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-angular\#initialize-an-ionic-angular-app)

We can use the [Ionic CLI](https://ionicframework.com/docs/cli) to initialize
an app called `supabase-ionic-angular`:

`
npm install -g @ionic/cli
ionic start supabase-ionic-angular blank --type angular
cd supabase-ionic-angular
`

Then let's install the only additional dependency: [supabase-js](https://github.com/supabase/supabase-js)

`
npm install @supabase/supabase-js
`

And finally, we want to save the environment variables in the `src/environments/environment.ts` file.
All we need are the API URL and the `anon` key that you copied [earlier](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-angular#get-the-api-keys).
These variables will be exposed on the browser, and that's completely fine since we have [Row Level Security](https://supabase.com/docs/guides/auth#row-level-security) enabled on our Database.

environment.ts

`
export const environment = {
production: false,
supabaseUrl: 'YOUR_SUPABASE_URL',
supabaseKey: 'YOUR_SUPABASE_KEY',
}
`

Now that we have the API credentials in place, let's create a `SupabaseService` with `ionic g s supabase` to initialize the Supabase client and implement functions to communicate with the Supabase API.

src/app/supabase.service.ts

``
import { Injectable } from '@angular/core'
import { LoadingController, ToastController } from '@ionic/angular'
import { AuthChangeEvent, createClient, Session, SupabaseClient } from '@supabase/supabase-js'
import { environment } from '../environments/environment'
export interface Profile {
username: string
website: string
avatar_url: string
}
@Injectable({
providedIn: 'root',
})
export class SupabaseService {
private supabase: SupabaseClient
constructor(
    private loadingCtrl: LoadingController,
    private toastCtrl: ToastController
) {
    this.supabase = createClient(environment.supabaseUrl, environment.supabaseKey)
}
get user() {
    return this.supabase.auth.getUser().then(({ data }) => data?.user)
}
get session() {
    return this.supabase.auth.getSession().then(({ data }) => data?.session)
}
get profile() {
    return this.user
      .then((user) => user?.id)
      .then((id) =>
        this.supabase.from('profiles').select(`username, website, avatar_url`).eq('id', id).single()
      )
}
authChanges(callback: (event: AuthChangeEvent, session: Session | null) => void) {
    return this.supabase.auth.onAuthStateChange(callback)
}
signIn(email: string) {
    return this.supabase.auth.signInWithOtp({ email })
}
signOut() {
    return this.supabase.auth.signOut()
}
async updateProfile(profile: Profile) {
    const user = await this.user
    const update = {
      ...profile,
      id: user?.id,
      updated_at: new Date(),
    }
    return this.supabase.from('profiles').upsert(update)
}
downLoadImage(path: string) {
    return this.supabase.storage.from('avatars').download(path)
}
uploadAvatar(filePath: string, file: File) {
    return this.supabase.storage.from('avatars').upload(filePath, file)
}
async createNotice(message: string) {
    const toast = await this.toastCtrl.create({ message, duration: 5000 })
    await toast.present()
}
createLoader() {
    return this.loadingCtrl.create()
}
}
``

### Set up a login route [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-angular\#set-up-a-login-route)

Let's set up a route to manage logins and signups. We'll use Magic Links so users can sign in with their email without using passwords.
Create a `LoginPage` with the `ionic g page login` Ionic CLI command.

This guide will show the template inline, but the example app will have `templateUrl` s

src/app/login/login.page.ts

``
import { Component, OnInit } from '@angular/core'
import { SupabaseService } from '../supabase.service'
@Component({
selector: 'app-login',
template: `
    <ion-header>
      <ion-toolbar>
        <ion-title>Login</ion-title>
      </ion-toolbar>
    </ion-header>
    <ion-content>
      <div class="ion-padding">
        <h1>Supabase + Ionic Angular</h1>
        <p>Sign in via magic link with your email below</p>
      </div>
      <ion-list inset="true">
        <form (ngSubmit)="handleLogin($event)">
          <ion-item>
            <ion-label position="stacked">Email</ion-label>
            <ion-input [(ngModel)]="email" name="email" autocomplete type="email"></ion-input>
          </ion-item>
          <div class="ion-text-center">
            <ion-button type="submit" fill="clear">Login</ion-button>
          </div>
        </form>
      </ion-list>
    </ion-content>
`,
styleUrls: ['./login.page.scss'],
})
export class LoginPage {
email = ''
constructor(private readonly supabase: SupabaseService) {}
async handleLogin(event: any) {
    event.preventDefault()
    const loader = await this.supabase.createLoader()
    await loader.present()
    try {
      const { error } = await this.supabase.signIn(this.email)
      if (error) {
        throw error
      }
      await loader.dismiss()
      await this.supabase.createNotice('Check your email for the login link!')
    } catch (error: any) {
      await loader.dismiss()
      await this.supabase.createNotice(error.error_description || error.message)
    }
}
}
``

### Account page [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-angular\#account-page)

After a user is signed in, we can allow them to edit their profile details and manage their account.
Create an `AccountComponent` with `ionic g page account` Ionic CLI command.

src/app/account.page.ts

``
import { Component, OnInit } from '@angular/core'
import { Router } from '@angular/router'
import { Profile, SupabaseService } from '../supabase.service'
@Component({
selector: 'app-account',
template: `
    <ion-header>
      <ion-toolbar>
        <ion-title>Account</ion-title>
      </ion-toolbar>
    </ion-header>
    <ion-content>
      <form>
        <ion-item>
          <ion-label position="stacked">Email</ion-label>
          <ion-input type="email" name="email" [(ngModel)]="email" readonly></ion-input>
        </ion-item>
        <ion-item>
          <ion-label position="stacked">Name</ion-label>
          <ion-input type="text" name="username" [(ngModel)]="profile.username"></ion-input>
        </ion-item>
        <ion-item>
          <ion-label position="stacked">Website</ion-label>
          <ion-input type="url" name="website" [(ngModel)]="profile.website"></ion-input>
        </ion-item>
        <div class="ion-text-center">
          <ion-button fill="clear" (click)="updateProfile()">Update Profile</ion-button>
        </div>
      </form>
      <div class="ion-text-center">
        <ion-button fill="clear" (click)="signOut()">Log Out</ion-button>
      </div>
    </ion-content>
`,
styleUrls: ['./account.page.scss'],
})
export class AccountPage implements OnInit {
profile: Profile = {
    username: '',
    avatar_url: '',
    website: '',
}
email = ''
constructor(
    private readonly supabase: SupabaseService,
    private router: Router
) {}
ngOnInit() {
    this.getEmail()
    this.getProfile()
}
async getEmail() {
    this.email = await this.supabase.user.then((user) => user?.email || '')
}
async getProfile() {
    try {
      const { data: profile, error, status } = await this.supabase.profile
      if (error && status !== 406) {
        throw error
      }
      if (profile) {
        this.profile = profile
      }
    } catch (error: any) {
      alert(error.message)
    }
}
async updateProfile(avatar_url: string = '') {
    const loader = await this.supabase.createLoader()
    await loader.present()
    try {
      const { error } = await this.supabase.updateProfile({ ...this.profile, avatar_url })
      if (error) {
        throw error
      }
      await loader.dismiss()
      await this.supabase.createNotice('Profile updated!')
    } catch (error: any) {
      await loader.dismiss()
      await this.supabase.createNotice(error.message)
    }
}
async signOut() {
    console.log('testing?')
    await this.supabase.signOut()
    this.router.navigate(['/'], { replaceUrl: true })
}
}
``

### Launch! [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-angular\#launch)

Now that we have all the components in place, let's update `AppComponent`:

src/app/app.component.ts

``
import { Component } from '@angular/core'
import { Router } from '@angular/router'
import { SupabaseService } from './supabase.service'
@Component({
selector: 'app-root',
template: `
    <ion-app>
      <ion-router-outlet></ion-router-outlet>
    </ion-app>
`,
styleUrls: ['app.component.scss'],
})
export class AppComponent {
constructor(
    private supabase: SupabaseService,
    private router: Router
) {
    this.supabase.authChanges((_, session) => {
      console.log(session)
      if (session?.user) {
        this.router.navigate(['/account'])
      }
    })
}
}
``

Then update the `AppRoutingModule`

src/app/app-routing.module.ts"

`
import { NgModule } from '@angular/core'
import { PreloadAllModules, RouterModule, Routes } from '@angular/router'
const routes: Routes = [\
{\
    path: '',\
    loadChildren: () => import('./login/login.module').then((m) => m.LoginPageModule),\
},\
{\
    path: 'account',\
    loadChildren: () => import('./account/account.module').then((m) => m.AccountPageModule),\
},\
]
@NgModule({
imports: [\
    RouterModule.forRoot(routes, {\
      preloadingStrategy: PreloadAllModules,\
    }),\
],
exports: [RouterModule],
})
export class AppRoutingModule {}
`

Once that's done, run this in a terminal window:

`
ionic serve
`

And the browser will automatically open to show the app.

![Supabase Angular](https://supabase.com/docs/img/ionic-demos/ionic-angular.png)

## Bonus: Profile photos [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-angular\#bonus-profile-photos)

Every Supabase project is configured with [Storage](https://supabase.com/docs/guides/storage) for managing large files like photos and videos.

### Create an upload widget [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-angular\#create-an-upload-widget)

Let's create an avatar for the user so that they can upload a profile photo.

First, install two packages in order to interact with the user's camera.

`
npm install @ionic/pwa-elements @capacitor/camera
`

[Capacitor](https://capacitorjs.com/) is a cross-platform native runtime from Ionic that enables web apps to be deployed through the app store and provides access to native device API.

Ionic PWA elements is a companion package that will polyfill certain browser APIs that provide no user interface with custom Ionic UI.

With those packages installed, we can update our `main.ts` to include an additional bootstrapping call for the Ionic PWA Elements.

src/main.ts

`
import { enableProdMode } from '@angular/core'
import { platformBrowserDynamic } from '@angular/platform-browser-dynamic'
import { AppModule } from './app/app.module'
import { environment } from './environments/environment'
import { defineCustomElements } from '@ionic/pwa-elements/loader'
defineCustomElements(window)
if (environment.production) {
enableProdMode()
}
platformBrowserDynamic()
.bootstrapModule(AppModule)
.catch((err) => console.log(err))
`

Then create an `AvatarComponent` with this Ionic CLI command:

`
ionic g component avatar --module=/src/app/account/account.module.ts --create-module
`

src/app/avatar.component.ts

``
import { Component, EventEmitter, Input, OnInit, Output } from '@angular/core'
import { DomSanitizer, SafeResourceUrl } from '@angular/platform-browser'
import { SupabaseService } from '../supabase.service'
import { Camera, CameraResultType } from '@capacitor/camera'
import { addIcons } from 'ionicons'
import { person } from 'ionicons/icons'
@Component({
selector: 'app-avatar',
template: `
    <div class="avatar_wrapper" (click)="uploadAvatar()">
      <img *ngIf="_avatarUrl; else noAvatar" [src]="_avatarUrl" />
      <ng-template #noAvatar>
        <ion-icon name="person" class="no-avatar"></ion-icon>
      </ng-template>
    </div>
`,
style: [\
    `\
    :host {\
       display: block;\
       margin: auto;\
       min-height: 150px;\
    }\
     :host .avatar_wrapper {\
       margin: 16px auto 16px;\
       border-radius: 50%;\
       overflow: hidden;\
       height: 150px;\
       aspect-ratio: 1;\
       background: var(--ion-color-step-50);\
       border: thick solid var(--ion-color-step-200);\
    }\
     :host .avatar_wrapper:hover {\
       cursor: pointer;\
    }\
     :host .avatar_wrapper ion-icon.no-avatar {\
       width: 100%;\
       height: 115%;\
    }\
     :host img {\
       display: block;\
       object-fit: cover;\
       width: 100%;\
       height: 100%;\
    }\
`,\
],
})
export class AvatarComponent {
_avatarUrl: SafeResourceUrl | undefined
uploading = false
@Input()
set avatarUrl(url: string | undefined) {
    if (url) {
      this.downloadImage(url)
    }
}
@Output() upload = new EventEmitter<string>()
constructor(
    private readonly supabase: SupabaseService,
    private readonly dom: DomSanitizer
) {
    addIcons({ person })
}
async downloadImage(path: string) {
    try {
      const { data, error } = await this.supabase.downLoadImage(path)
      if (error) {
        throw error
      }
      this._avatarUrl = this.dom.bypassSecurityTrustResourceUrl(URL.createObjectURL(data!))
    } catch (error: any) {
      console.error('Error downloading image: ', error.message)
    }
}
async uploadAvatar() {
    const loader = await this.supabase.createLoader()
    try {
      const photo = await Camera.getPhoto({
        resultType: CameraResultType.DataUrl,
      })
      const file = await fetch(photo.dataUrl!)
        .then((res) => res.blob())
        .then((blob) => new File([blob], 'my-file', { type: `image/${photo.format}` }))
      const fileName = `${Math.random()}-${new Date().getTime()}.${photo.format}`
      await loader.present()
      const { error } = await this.supabase.uploadAvatar(fileName, file)
      if (error) {
        throw error
      }
      this.upload.emit(fileName)
    } catch (error: any) {
      this.supabase.createNotice(error.message)
    } finally {
      loader.dismiss()
    }
}
}
``

### Add the new widget [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-angular\#add-the-new-widget)

And then, we can add the widget on top of the `AccountComponent` HTML template:

src/app/account.component.ts

``
template: `
<ion-header>
<ion-toolbar>
    <ion-title>Account</ion-title>
</ion-toolbar>
</ion-header>
<ion-content>
<app-avatar
    [avatarUrl]="this.profile?.avatar_url"
    (upload)="updateProfile($event)"
></app-avatar>
<!-- input fields -->
`
``

At this stage, you have a fully functional application!

## See also [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-angular\#see-also)

- [Authentication in Ionic Angular with Supabase](https://supabase.com/blog/authentication-in-ionic-angular)

### Is this helpful?

NoYes

### On this page

[Project setup](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-angular#project-setup) [Create a project](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-angular#create-a-project) [Set up the database schema](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-angular#set-up-the-database-schema) [Get the API Keys](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-angular#get-the-api-keys) [Building the app](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-angular#building-the-app) [Initialize an Ionic Angular app](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-angular#initialize-an-ionic-angular-app) [Set up a login route](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-angular#set-up-a-login-route) [Account page](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-angular#account-page) [Launch!](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-angular#launch) [Bonus: Profile photos](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-angular#bonus-profile-photos) [Create an upload widget](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-angular#create-an-upload-widget) [Add the new widget](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-angular#add-the-new-widget) [See also](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-angular#see-also)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_tutorials_with_ionic_react.md">
Getting Started

# Build a User Management App with Ionic React

* * *

This tutorial demonstrates how to build a basic user management app. The app authenticates and identifies the user, stores their profile information in the database, and allows the user to log in, update their profile details, and upload a profile photo. The app uses:

- [Supabase Database](https://supabase.com/docs/guides/database) \- a Postgres database for storing your user data and [Row Level Security](https://supabase.com/docs/guides/auth#row-level-security) so data is protected and users can only access their own information.
- [Supabase Auth](https://supabase.com/docs/guides/auth) \- allow users to sign up and log in.
- [Supabase Storage](https://supabase.com/docs/guides/storage) \- users can upload a profile photo.

![Supabase User Management example](https://supabase.com/docs/img/ionic-demos/ionic-angular-account.png)

If you get stuck while working through this guide, refer to the [full example on GitHub](https://github.com/mhartington/supabase-ionic-react).

## Project setup [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-react\#project-setup)

Before we start building we're going to set up our Database and API. This is as simple as starting a new Project in Supabase and then creating a "schema" inside the database.

### Create a project [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-react\#create-a-project)

1. [Create a new project](https://supabase.com/dashboard) in the Supabase Dashboard.
2. Enter your project details.
3. Wait for the new database to launch.

### Set up the database schema [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-react\#set-up-the-database-schema)

Now we are going to set up the database schema. We can use the "User Management Starter" quickstart in the SQL Editor, or you can just copy/paste the SQL from below and run it yourself.

DashboardSQL

1. Go to the [SQL Editor](https://supabase.com/dashboard/project/_/sql) page in the Dashboard.
2. Click **User Management Starter**.
3. Click **Run**.

You can easily pull the database schema down to your local project by running the `db pull` command. Read the [local development docs](https://supabase.com/docs/guides/cli/local-development#link-your-project) for detailed instructions.

`
supabase link --project-ref <project-id>
# You can get <project-id> from your project's dashboard URL: https://supabase.com/dashboard/project/<project-id>
supabase db pull
`

### Get the API Keys [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-react\#get-the-api-keys)

Now that you've created some database tables, you are ready to insert data using the auto-generated API.
We just need to get the Project URL and `anon` key from the API settings.

1. Go to the [API Settings](https://supabase.com/dashboard/project/_/settings/api) page in the Dashboard.
2. Find your Project `URL`, `anon`, and `service_role` keys on this page.

## Building the app [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-react\#building-the-app)

Let's start building the React app from scratch.

### Initialize an Ionic React app [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-react\#initialize-an-ionic-react-app)

We can use the [Ionic CLI](https://ionicframework.com/docs/cli) to initialize
an app called `supabase-ionic-react`:

`
npm install -g @ionic/cli
ionic start supabase-ionic-react blank --type react
cd supabase-ionic-react
`

Then let's install the only additional dependency: [supabase-js](https://github.com/supabase/supabase-js)

`
npm install @supabase/supabase-js
`

And finally we want to save the environment variables in a `.env`.
All we need are the API URL and the `anon` key that you copied [earlier](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-react#get-the-api-keys).

.env

`
REACT_APP_SUPABASE_URL=YOUR_SUPABASE_URL
REACT_APP_SUPABASE_ANON_KEY=YOUR_SUPABASE_ANON_KEY
`

Now that we have the API credentials in place, let's create a helper file to initialize the Supabase client. These variables will be exposed
on the browser, and that's completely fine since we have [Row Level Security](https://supabase.com/docs/guides/auth#row-level-security) enabled on our Database.

src/supabaseClient.js

`
import { createClient } from '@supabase/supabase-js'
const supabaseUrl = process.env.REACT_APP_SUPABASE_URL
const supabaseAnonKey = process.env.REACT_APP_SUPABASE_ANON_KEY
export const supabase = createClient(supabaseUrl, supabaseAnonKey)
`

### Set up a login route [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-react\#set-up-a-login-route)

Let's set up a React component to manage logins and sign ups. We'll use Magic Links, so users can sign in with their email without using passwords.

/src/pages/Login.tsx

`
import { useState } from 'react';
import {
IonButton,
IonContent,
IonHeader,
IonInput,
IonItem,
IonLabel,
IonList,
IonPage,
IonTitle,
IonToolbar,
useIonToast,
useIonLoading,
} from '@ionic/react';
import { supabase } from '../supabaseClient';
export function LoginPage() {
const [email, setEmail] = useState('');
const [showLoading, hideLoading] = useIonLoading();
const [showToast ] = useIonToast();
const handleLogin = async (e: React.FormEvent<HTMLFormElement>) => {
    console.log()
    e.preventDefault();
    await showLoading();
    try {
      await supabase.auth.signIn({ email });
      await showToast({ message: 'Check your email for the login link!' });
    } catch (e: any) {
      await showToast({ message: e.error_description || e.message , duration: 5000});
    } finally {
      await hideLoading();
    }
};
return (
    <IonPage>
      <IonHeader>
        <IonToolbar>
          <IonTitle>Login</IonTitle>
        </IonToolbar>
      </IonHeader>
      <IonContent>
        <div className="ion-padding">
          <h1>Supabase + Ionic React</h1>
          <p>Sign in via magic link with your email below</p>
        </div>
        <IonList inset={true}>
          <form onSubmit={handleLogin}>
            <IonItem>
              <IonLabel position="stacked">Email</IonLabel>
              <IonInput
                value={email}
                name="email"
                onIonChange={(e) => setEmail(e.detail.value ?? '')}
                type="email"
              ></IonInput>
            </IonItem>
            <div className="ion-text-center">
              <IonButton type="submit" fill="clear">
                Login
              </IonButton>
            </div>
          </form>
        </IonList>
      </IonContent>
    </IonPage>
);
}
`

### Account page [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-react\#account-page)

After a user is signed in we can allow them to edit their profile details and manage their account.

Let's create a new component for that called `Account.tsx`.

src/pages/Account.tsx

``
import {
IonButton,
IonContent,
IonHeader,
IonInput,
IonItem,
IonLabel,
IonPage,
IonTitle,
IonToolbar,
useIonLoading,
useIonToast,
useIonRouter
} from '@ionic/react';
import { useEffect, useState } from 'react';
import { supabase } from '../supabaseClient';
export function AccountPage() {
const [showLoading, hideLoading] = useIonLoading();
const [showToast] = useIonToast();
const [session] = useState(() => supabase.auth.session());
const router = useIonRouter();
const [profile, setProfile] = useState({
    username: '',
    website: '',
    avatar_url: '',
});
useEffect(() => {
    getProfile();
}, [session]);
const getProfile = async () => {
    console.log('get');
    await showLoading();
    try {
      const user = supabase.auth.user();
      const { data, error, status } = await supabase
        .from('profiles')
        .select(`username, website, avatar_url`)
        .eq('id', user!.id)
        .single();
      if (error && status !== 406) {
        throw error;
      }
      if (data) {
        setProfile({
          username: data.username,
          website: data.website,
          avatar_url: data.avatar_url,
        });
      }
    } catch (error: any) {
      showToast({ message: error.message, duration: 5000 });
    } finally {
      await hideLoading();
    }
};
const signOut = async () => {
    await supabase.auth.signOut();
    router.push('/', 'forward', 'replace');
}
const updateProfile = async (e?: any, avatar_url: string = '') => {
    e?.preventDefault();
    console.log('update ');
    await showLoading();
    try {
      const user = supabase.auth.user();
      const updates = {
        id: user!.id,
        ...profile,
        avatar_url: avatar_url,
        updated_at: new Date(),
      };
      const { error } = await supabase.from('profiles').upsert(updates, {
        returning: 'minimal', // Don't return the value after inserting
      });
      if (error) {
        throw error;
      }
    } catch (error: any) {
      showToast({ message: error.message, duration: 5000 });
    } finally {
      await hideLoading();
    }
};
return (
    <IonPage>
      <IonHeader>
        <IonToolbar>
          <IonTitle>Account</IonTitle>
        </IonToolbar>
      </IonHeader>
      <IonContent>
        <form onSubmit={updateProfile}>
          <IonItem>
            <IonLabel>
              <p>Email</p>
              <p>{session?.user?.email}</p>
            </IonLabel>
          </IonItem>
          <IonItem>
            <IonLabel position="stacked">Name</IonLabel>
            <IonInput
              type="text"
              name="username"
              value={profile.username}
              onIonChange={(e) =>
                setProfile({ ...profile, username: e.detail.value ?? '' })
              }
            ></IonInput>
          </IonItem>
          <IonItem>
            <IonLabel position="stacked">Website</IonLabel>
            <IonInput
              type="url"
              name="website"
              value={profile.website}
              onIonChange={(e) =>
                setProfile({ ...profile, website: e.detail.value ?? '' })
              }
            ></IonInput>
          </IonItem>
          <div className="ion-text-center">
            <IonButton fill="clear" type="submit">
              Update Profile
            </IonButton>
          </div>
        </form>
        <div className="ion-text-center">
          <IonButton fill="clear" onClick={signOut}>
            Log Out
          </IonButton>
        </div>
      </IonContent>
    </IonPage>
);
}
``

### Launch! [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-react\#launch)

Now that we have all the components in place, let's update `App.tsx`:

src/App.tsx

`
import { Redirect, Route } from 'react-router-dom'
import { IonApp, IonRouterOutlet, setupIonicReact } from '@ionic/react'
import { IonReactRouter } from '@ionic/react-router'
import { supabase } from './supabaseClient'
import '@ionic/react/css/ionic.bundle.css'
/* Theme variables */
import './theme/variables.css'
import { LoginPage } from './pages/Login'
import { AccountPage } from './pages/Account'
import { useEffect, useState } from 'react'
import { Session } from '@supabase/supabase-js'
setupIonicReact()
const App: React.FC = () => {
const [session, setSession] = useState < Session > null
useEffect(() => {
    setSession(supabase.auth.session())
    supabase.auth.onAuthStateChange((_event, session) => {
      setSession(session)
    })
}, [])
return (
    <IonApp>
      <IonReactRouter>
        <IonRouterOutlet>
          <Route
            exact
            path="/"
            render={() => {
              return session ? <Redirect to="/account" /> : <LoginPage />
            }}
          />
          <Route exact path="/account">
            <AccountPage />
          </Route>
        </IonRouterOutlet>
      </IonReactRouter>
    </IonApp>
)
}
export default App
`

Once that's done, run this in a terminal window:

`
ionic serve
`

And then open the browser to [localhost:3000](http://localhost:3000/) and you should see the completed app.

![Supabase Ionic React](https://supabase.com/docs/img/ionic-demos/ionic-react.png)

## Bonus: Profile photos [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-react\#bonus-profile-photos)

Every Supabase project is configured with [Storage](https://supabase.com/docs/guides/storage) for managing large files like photos and videos.

### Create an upload widget [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-react\#create-an-upload-widget)

First install two packages in order to interact with the user's camera.

`
npm install @ionic/pwa-elements @capacitor/camera
`

[Capacitor](https://capacitorjs.com/) is a cross platform native runtime from Ionic that enables web apps to be deployed through the app store and provides access to native device API.

Ionic PWA elements is a companion package that will polyfill certain browser APIs that provide no user interface with custom Ionic UI.

With those packages installed we can update our `index.tsx` to include an additional bootstrapping call for the Ionic PWA Elements.

src/index.tsx

`
import React from 'react'
import ReactDOM from 'react-dom'
import App from './App'
import * as serviceWorkerRegistration from './serviceWorkerRegistration'
import reportWebVitals from './reportWebVitals'
import { defineCustomElements } from '@ionic/pwa-elements/loader'
defineCustomElements(window)
ReactDOM.render(
<React.StrictMode>
    <App />
</React.StrictMode>,
document.getElementById('root')
)
serviceWorkerRegistration.unregister()
reportWebVitals()
`

Then create an `AvatarComponent`.

src/components/Avatar.tsx

``
import { IonIcon } from '@ionic/react';
import { person } from 'ionicons/icons';
import { Camera, CameraResultType } from '@capacitor/camera';
import { useEffect, useState } from 'react';
import { supabase } from '../supabaseClient';
import './Avatar.css'
export function Avatar({
url,
onUpload,
}: {
url: string;
onUpload: (e: any, file: string) => Promise<void>;
}) {
const [avatarUrl, setAvatarUrl] = useState<string | undefined>();
useEffect(() => {
    if (url) {
      downloadImage(url);
    }
}, [url]);
const uploadAvatar = async () => {
    try {
      const photo = await Camera.getPhoto({
        resultType: CameraResultType.DataUrl,
      });
      const file = await fetch(photo.dataUrl!)
        .then((res) => res.blob())
        .then(
          (blob) =>
            new File([blob], 'my-file', { type: `image/${photo.format}` })
        );
      const fileName = `${Math.random()}-${new Date().getTime()}.${
        photo.format
      }`;
      const { error: uploadError } = await supabase.storage
        .from('avatars')
        .upload(fileName, file);
      if (uploadError) {
        throw uploadError;
      }
      onUpload(null, fileName);
    } catch (error) {
      console.log(error);
    }
};
const downloadImage = async (path: string) => {
    try {
      const { data, error } = await supabase.storage
        .from('avatars')
        .download(path);
      if (error) {
        throw error;
      }
      const url = URL.createObjectURL(data!);
      setAvatarUrl(url);
    } catch (error: any) {
      console.log('Error downloading image: ', error.message);
    }
};
return (
    <div className="avatar">
    <div className="avatar_wrapper" onClick={uploadAvatar}>
      {avatarUrl ? (
        <img src={avatarUrl} />
      ) : (
        <IonIcon icon={person} className="no-avatar" />
      )}
    </div>
    </div>
);
}
``

### Add the new widget [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-react\#add-the-new-widget)

And then we can add the widget to the Account page:

src/pages/Account.tsx

`
// Import the new component
import { Avatar } from '../components/Avatar';
// ...
return (
<IonPage>
    <IonHeader>
      <IonToolbar>
        <IonTitle>Account</IonTitle>
      </IonToolbar>
    </IonHeader>
    <IonContent>
      <Avatar url={profile.avatar_url} onUpload={updateProfile}></Avatar>
`

At this stage you have a fully functional application!

### Is this helpful?

NoYes

### On this page

[Project setup](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-react#project-setup) [Create a project](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-react#create-a-project) [Set up the database schema](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-react#set-up-the-database-schema) [Get the API Keys](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-react#get-the-api-keys) [Building the app](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-react#building-the-app) [Initialize an Ionic React app](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-react#initialize-an-ionic-react-app) [Set up a login route](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-react#set-up-a-login-route) [Account page](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-react#account-page) [Launch!](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-react#launch) [Bonus: Profile photos](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-react#bonus-profile-photos) [Create an upload widget](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-react#create-an-upload-widget) [Add the new widget](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-react#add-the-new-widget)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_tutorials_with_ionic_vue.md">
Getting Started

# Build a User Management App with Ionic Vue

* * *

This tutorial demonstrates how to build a basic user management app. The app authenticates and identifies the user, stores their profile information in the database, and allows the user to log in, update their profile details, and upload a profile photo. The app uses:

- [Supabase Database](https://supabase.com/docs/guides/database) \- a Postgres database for storing your user data and [Row Level Security](https://supabase.com/docs/guides/auth#row-level-security) so data is protected and users can only access their own information.
- [Supabase Auth](https://supabase.com/docs/guides/auth) \- allow users to sign up and log in.
- [Supabase Storage](https://supabase.com/docs/guides/storage) \- users can upload a profile photo.

![Supabase User Management example](https://supabase.com/docs/img/ionic-demos/ionic-angular-account.png)

If you get stuck while working through this guide, refer to the [full example on GitHub](https://github.com/mhartington/supabase-ionic-vue).

## Project setup [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-vue\#project-setup)

Before we start building we're going to set up our Database and API. This is as simple as starting a new Project in Supabase and then creating a "schema" inside the database.

### Create a project [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-vue\#create-a-project)

1. [Create a new project](https://supabase.com/dashboard) in the Supabase Dashboard.
2. Enter your project details.
3. Wait for the new database to launch.

### Set up the database schema [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-vue\#set-up-the-database-schema)

Now we are going to set up the database schema. We can use the "User Management Starter" quickstart in the SQL Editor, or you can just copy/paste the SQL from below and run it yourself.

DashboardSQL

1. Go to the [SQL Editor](https://supabase.com/dashboard/project/_/sql) page in the Dashboard.
2. Click **User Management Starter**.
3. Click **Run**.

You can easily pull the database schema down to your local project by running the `db pull` command. Read the [local development docs](https://supabase.com/docs/guides/cli/local-development#link-your-project) for detailed instructions.

`
supabase link --project-ref <project-id>
# You can get <project-id> from your project's dashboard URL: https://supabase.com/dashboard/project/<project-id>
supabase db pull
`

### Get the API Keys [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-vue\#get-the-api-keys)

Now that you've created some database tables, you are ready to insert data using the auto-generated API.
We just need to get the Project URL and `anon` key from the API settings.

1. Go to the [API Settings](https://supabase.com/dashboard/project/_/settings/api) page in the Dashboard.
2. Find your Project `URL`, `anon`, and `service_role` keys on this page.

## Building the app [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-vue\#building-the-app)

Let's start building the Vue app from scratch.

### Initialize an Ionic Vue app [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-vue\#initialize-an-ionic-vue-app)

We can use the [Ionic CLI](https://ionicframework.com/docs/cli) to initialize
an app called `supabase-ionic-vue`:

`
npm install -g @ionic/cli
ionic start supabase-ionic-vue blank --type vue
cd supabase-ionic-vue
`

Then let's install the only additional dependency: [supabase-js](https://github.com/supabase/supabase-js)

`
npm install @supabase/supabase-js
`

And finally we want to save the environment variables in a `.env`.
All we need are the API URL and the `anon` key that you copied [earlier](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-vue#get-the-api-keys).

.env

`
VUE_APP_SUPABASE_URL=YOUR_SUPABASE_URL
VUE_APP_SUPABASE_ANON_KEY=YOUR_SUPABASE_ANON_KEY
`

Now that we have the API credentials in place, let's create a helper file to initialize the Supabase client. These variables will be exposed
on the browser, and that's completely fine since we have [Row Level Security](https://supabase.com/docs/guides/auth#row-level-security) enabled on our Database.

src/supabase.ts"

`
import { createClient } from '@supabase/supabase-js';
const supabaseUrl = process.env.VUE_APP_SUPABASE_URL as string;
const supabaseAnonKey = process.env.VUE_APP_SUPABASE_ANON_KEY as string;
export const supabase = createClient(supabaseUrl, supabaseAnonKey);
`

### Set up a login route [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-vue\#set-up-a-login-route)

Let's set up a Vue component to manage logins and sign ups. We'll use Magic Links, so users can sign in with their email without using passwords.

/src/views/Login.vue

`
<template>
<ion-page>
    <ion-header>
      <ion-toolbar>
        <ion-title>Login</ion-title>
      </ion-toolbar>
    </ion-header>
    <ion-content>
      <div class="ion-padding">
        <h1>Supabase + Ionic Vue</h1>
        <p>Sign in via magic link with your email below</p>
      </div>
      <ion-list inset="true">
        <form @submit.prevent="handleLogin">
          <ion-item>
            <ion-label position="stacked">Email</ion-label>
            <ion-input v-model="email" name="email" autocomplete type="email"></ion-input>
          </ion-item>
          <div class="ion-text-center">
            <ion-button type="submit" fill="clear">Login</ion-button>
          </div>
        </form>
      </ion-list>
      <p>{{email}}</p>
    </ion-content>
</ion-page>
</template>
<script lang="ts">
import { supabase } from '../supabase'
import {
    IonContent,
    IonHeader,
    IonPage,
    IonTitle,
    IonToolbar,
    IonList,
    IonItem,
    IonLabel,
    IonInput,
    IonButton,
    toastController,
    loadingController,
} from '@ionic/vue'
import { defineComponent, ref } from 'vue'
export default defineComponent({
    name: 'LoginPage',
    components: {
      IonContent,
      IonHeader,
      IonPage,
      IonTitle,
      IonToolbar,
      IonList,
      IonItem,
      IonLabel,
      IonInput,
      IonButton,
    },
    setup() {
      const email = ref('')
      const handleLogin = async () => {
        const loader = await loadingController.create({})
        const toast = await toastController.create({ duration: 5000 })
        try {
          await loader.present()
          const { error } = await supabase.auth.signIn({ email: email.value })
          if (error) throw error
          toast.message = 'Check your email for the login link!'
          await toast.present()
        } catch (error: any) {
          toast.message = error.error_description || error.message
          await toast.present()
        } finally {
          await loader.dismiss()
        }
      }
      return { handleLogin, email }
    },
})
</script>
`

### Account page [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-vue\#account-page)

After a user is signed in we can allow them to edit their profile details and manage their account.

Let's create a new component for that called `Account.vue`.

src/views/Account.vue

``
<template>
<ion-page>
    <ion-header>
      <ion-toolbar>
        <ion-title>Account</ion-title>
      </ion-toolbar>
    </ion-header>
    <ion-content>
      <form @submit.prevent="updateProfile">
        <ion-item>
          <ion-label>
            <p>Email</p>
            <p>{{ session?.user?.email }}</p>
          </ion-label>
        </ion-item>
        <ion-item>
          <ion-label position="stacked">Name</ion-label>
          <ion-input type="text" name="username" v-model="profile.username"></ion-input>
        </ion-item>
        <ion-item>
          <ion-label position="stacked">Website</ion-label>
          <ion-input type="url" name="website" v-model="profile.website"></ion-input>
        </ion-item>
        <div class="ion-text-center">
          <ion-button fill="clear" type="submit">Update Profile</ion-button>
        </div>
      </form>
      <div class="ion-text-center">
        <ion-button fill="clear" @click="signOut">Log Out</ion-button>
      </div>
    </ion-content>
</ion-page>
</template>
<script lang="ts">
import { store } from '@/store'
import { supabase } from '@/supabase'
import {
    IonContent,
    IonHeader,
    IonPage,
    IonTitle,
    IonToolbar,
    toastController,
    loadingController,
    IonInput,
    IonItem,
    IonButton,
    IonLabel,
} from '@ionic/vue'
import { User } from '@supabase/supabase-js'
import { defineComponent, onMounted, ref } from 'vue'
export default defineComponent({
    name: 'AccountPage',
    components: {
      IonContent,
      IonHeader,
      IonPage,
      IonTitle,
      IonToolbar,
      IonInput,
      IonItem,
      IonButton,
      IonLabel,
    },
    setup() {
      const session = ref(supabase.auth.session())
      const profile = ref({
        username: '',
        website: '',
        avatar_url: '',
      })
      const user = store.user as User
      async function getProfile() {
        const loader = await loadingController.create({})
        const toast = await toastController.create({ duration: 5000 })
        await loader.present()
        try {
          const { data, error, status } = await supabase
            .from('profiles')
            .select(`username, website, avatar_url`)
            .eq('id', user.id)
            .single()
          if (error && status !== 406) throw error
          if (data) {
            console.log(data)
            profile.value = {
              username: data.username,
              website: data.website,
              avatar_url: data.avatar_url,
            }
          }
        } catch (error: any) {
          toast.message = error.message
          await toast.present()
        } finally {
          await loader.dismiss()
        }
      }
      const updateProfile = async () => {
        const loader = await loadingController.create({})
        const toast = await toastController.create({ duration: 5000 })
        try {
          await loader.present()
          const updates = {
            id: user.id,
            ...profile.value,
            updated_at: new Date(),
          }
          //
          const { error } = await supabase.from('profiles').upsert(updates, {
            returning: 'minimal', // Don't return the value after inserting
          })
          //
          if (error) throw error
        } catch (error: any) {
          toast.message = error.message
          await toast.present()
        } finally {
          await loader.dismiss()
        }
      }
      async function signOut() {
        const loader = await loadingController.create({})
        const toast = await toastController.create({ duration: 5000 })
        await loader.present()
        try {
          const { error } = await supabase.auth.signOut()
          if (error) throw error
        } catch (error: any) {
          toast.message = error.message
          await toast.present()
        } finally {
          await loader.dismiss()
        }
      }
      onMounted(() => {
        getProfile()
      })
      return { signOut, profile, session, updateProfile }
    },
})
</script>
``

### Launch! [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-vue\#launch)

Now that we have all the components in place, let's update `App.vue` and our routes:

src/router.index.ts

`
import { createRouter, createWebHistory } from '@ionic/vue-router'
import { RouteRecordRaw } from 'vue-router'
import LoginPage from '../views/Login.vue'
import AccountPage from '../views/Account.vue'
const routes: Array<RouteRecordRaw> = [\
{\
    path: '/',\
    name: 'Login',\
    component: LoginPage,\
},\
{\
    path: '/account',\
    name: 'Account',\
    component: AccountPage,\
},\
]
const router = createRouter({
history: createWebHistory(process.env.BASE_URL),
routes,
})
export default router
`

src/App.vue

`
<template>
<ion-app>
    <ion-router-outlet />
</ion-app>
</template>
<script lang="ts">
import { IonApp, IonRouterOutlet, useIonRouter } from '@ionic/vue'
import { defineComponent } from 'vue'
import { store } from './store'
import { supabase } from './supabase'
export default defineComponent({
    name: 'App',
    components: {
      IonApp,
      IonRouterOutlet,
    },
    setup() {
      const router = useIonRouter()
      store.user = supabase.auth.user() ?? {}
      supabase.auth.onAuthStateChange((_, session) => {
        store.user = session?.user ?? {}
        if (session?.user) {
          router.replace('/account')
        }
      })
    },
})
</script>
`

Once that's done, run this in a terminal window:

`
ionic serve
`

And then open the browser to [localhost:3000](http://localhost:3000/) and you should see the completed app.

![Supabase Ionic Vue](https://supabase.com/docs/img/ionic-demos/ionic-vue.png)

## Bonus: Profile photos [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-vue\#bonus-profile-photos)

Every Supabase project is configured with [Storage](https://supabase.com/docs/guides/storage) for managing large files like photos and videos.

### Create an upload widget [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-vue\#create-an-upload-widget)

First install two packages in order to interact with the user's camera.

`
npm install @ionic/pwa-elements @capacitor/camera
`

[Capacitor](https://capacitorjs.com/) is a cross-platform native runtime from Ionic that enables web apps to be deployed through the app store and provides access to native device API.

Ionic PWA elements is a companion package that will polyfill certain browser APIs that provide no user interface with custom Ionic UI.

With those packages installed we can update our `main.ts` to include an additional bootstrapping call for the Ionic PWA Elements.

src/main.tsx"

`
import { createApp } from 'vue'
import App from './App.vue'
import router from './router'
import { IonicVue } from '@ionic/vue'
/* Core CSS required for Ionic components to work properly */
import '@ionic/vue/css/ionic.bundle.css'
/* Theme variables */
import './theme/variables.css'
import { defineCustomElements } from '@ionic/pwa-elements/loader'
defineCustomElements(window)
const app = createApp(App).use(IonicVue).use(router)
router.isReady().then(() => {
app.mount('#app')
})
`

Then create an `AvatarComponent`.

src/components/Avatar.vue

``
<template>
<div class="avatar">
    <div class="avatar_wrapper" @click="uploadAvatar">
      <img v-if="avatarUrl" :src="avatarUrl" />
      <ion-icon v-else name="person" class="no-avatar"></ion-icon>
    </div>
</div>
</template>
<script lang="ts">
import { ref, toRefs, watch, defineComponent } from 'vue'
import { supabase } from '../supabase'
import { Camera, CameraResultType } from '@capacitor/camera'
import { IonIcon } from '@ionic/vue'
import { person } from 'ionicons/icons'
export default defineComponent({
    name: 'AppAvatar',
    props: { path: String },
    emits: ['upload', 'update:path'],
    components: { IonIcon },
    setup(prop, { emit }) {
      const { path } = toRefs(prop)
      const avatarUrl = ref('')
      const downloadImage = async () => {
        try {
          const { data, error } = await supabase.storage.from('avatars').download(path.value)
          if (error) throw error
          avatarUrl.value = URL.createObjectURL(data!)
        } catch (error: any) {
          console.error('Error downloading image: ', error.message)
        }
      }
      const uploadAvatar = async () => {
        try {
          const photo = await Camera.getPhoto({
            resultType: CameraResultType.DataUrl,
          })
          if (photo.dataUrl) {
            const file = await fetch(photo.dataUrl)
              .then((res) => res.blob())
              .then((blob) => new File([blob], 'my-file', { type: `image/${photo.format}` }))
            const fileName = `${Math.random()}-${new Date().getTime()}.${photo.format}`
            const { error: uploadError } = await supabase.storage
              .from('avatars')
              .upload(fileName, file)
            if (uploadError) {
              throw uploadError
            }
            emit('update:path', fileName)
            emit('upload')
          }
        } catch (error) {
          console.log(error)
        }
      }
      watch(path, () => {
        if (path.value) downloadImage()
      })
      return { avatarUrl, uploadAvatar, person }
    },
})
</script>
<style>
.avatar {
    display: block;
    margin: auto;
    min-height: 150px;
}
.avatar .avatar_wrapper {
    margin: 16px auto 16px;
    border-radius: 50%;
    overflow: hidden;
    height: 150px;
    aspect-ratio: 1;
    background: var(--ion-color-step-50);
    border: thick solid var(--ion-color-step-200);
}
.avatar .avatar_wrapper:hover {
    cursor: pointer;
}
.avatar .avatar_wrapper ion-icon.no-avatar {
    width: 100%;
    height: 115%;
}
.avatar img {
    display: block;
    object-fit: cover;
    width: 100%;
    height: 100%;
}
</style>
``

### Add the new widget [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-vue\#add-the-new-widget)

And then we can add the widget to the Account page:

src/views/Account.vue

`
<template>
<ion-page>
    <ion-header>
      <ion-toolbar>
        <ion-title>Account</ion-title>
      </ion-toolbar>
    </ion-header>
    <ion-content>
      <avatar v-model:path="profile.avatar_url" @upload="updateProfile"></avatar>
...
</template>
<script lang="ts">
import Avatar from '../components/Avatar.vue';
export default defineComponent({
name: 'AccountPage',
components: {
    Avatar,
    ....
}
</script>
`

At this stage you have a fully functional application!

### Is this helpful?

NoYes

### On this page

[Project setup](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-vue#project-setup) [Create a project](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-vue#create-a-project) [Set up the database schema](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-vue#set-up-the-database-schema) [Get the API Keys](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-vue#get-the-api-keys) [Building the app](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-vue#building-the-app) [Initialize an Ionic Vue app](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-vue#initialize-an-ionic-vue-app) [Set up a login route](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-vue#set-up-a-login-route) [Account page](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-vue#account-page) [Launch!](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-vue#launch) [Bonus: Profile photos](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-vue#bonus-profile-photos) [Create an upload widget](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-vue#create-an-upload-widget) [Add the new widget](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-vue#add-the-new-widget)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_tutorials_with_kotlin.md">
Getting Started

# Build a Product Management Android App with Jetpack Compose

* * *

This tutorial demonstrates how to build a basic product management app. The app demonstrates management operations, photo upload, account creation and authentication using:

- [Supabase Database](https://supabase.com/docs/guides/database) \- a Postgres database for storing your user data and [Row Level Security](https://supabase.com/docs/guides/auth#row-level-security) so data is protected and users can only access their own information.
- [Supabase Auth](https://supabase.com/docs/guides/auth) \- users log in through magic links sent to their email (without having to set up a password).
- [Supabase Storage](https://supabase.com/docs/guides/storage) \- users can upload a profile photo.

![manage-product-cover](https://supabase.com/docs/img/guides/kotlin/manage-product-cover.png)

If you get stuck while working through this guide, refer to the [full example on GitHub](https://github.com/hieuwu/product-sample-supabase-kt).

## Project setup [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin\#project-setup)

Before we start building we're going to set up our Database and API. This is as simple as starting a new Project in Supabase and then creating a "schema" inside the database.

### Create a project [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin\#create-a-project)

1. [Create a new project](https://app.supabase.com/) in the Supabase Dashboard.
2. Enter your project details.
3. Wait for the new database to launch.

### Set up the database schema [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin\#set-up-the-database-schema)

Now we are going to set up the database schema. You can just copy/paste the SQL from below and run it yourself.

SQL

`
-- Create a table for public profiles
create table
public.products (
    id uuid not null default gen_random_uuid (),
    name text not null,
    price real not null,
    image text null,
    constraint products_pkey primary key (id)
) tablespace pg_default;
-- Set up Storage!
insert into storage.buckets (id, name)
values ('Product Image', 'Product Image');
-- Set up access controls for storage.
-- See https://supabase.com/docs/guides/storage/security/access-control#policy-examples for more details.
CREATE POLICY "Enable read access for all users" ON "storage"."objects"
AS PERMISSIVE FOR SELECT
TO public
USING (true)
CREATE POLICY "Enable insert for all users" ON "storage"."objects"
AS PERMISSIVE FOR INSERT
TO authenticated, anon
WITH CHECK (true)
CREATE POLICY "Enable update for all users" ON "storage"."objects"
AS PERMISSIVE FOR UPDATE
TO public
USING (true)
WITH CHECK (true)
`

### Get the API Keys [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin\#get-the-api-keys)

Now that you've created some database tables, you are ready to insert data using the auto-generated API.
We just need to get the Project URL and `anon` key from the API settings.

1. Go to the [API Settings](https://app.supabase.com/project/_/settings/api) page in the Dashboard.
2. Find your Project `URL`, `anon`, and `service_role` keys on this page.

### Set up Google Authentication [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin\#set-up-google-authentication)

From the [Google Console](https://console.developers.google.com/apis/library), create a new project and add OAuth2 credentials.

![Create Google OAuth credentials](https://supabase.com/docs/img/guides/kotlin/google-cloud-oauth-credentials-create.png)

In your [Supabase Auth settings](https://app.supabase.com/project/_/auth/providers) enable Google as a provider and set the required credentials as outlined in the [auth docs](https://supabase.com/docs/guides/auth/social-login/auth-google).

## Building the app [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin\#building-the-app)

### Create new Android project [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin\#create-new-android-project)

Open Android Studio > New Project > Base Activity (Jetpack Compose).

![Android Studio new project](https://supabase.com/docs/img/guides/kotlin/android-studio-new-project.png)

### Set up API key and secret securely [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin\#set-up-api-key-and-secret-securely)

#### Create local environment secret [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin\#create-local-environment-secret)

Create or edit the `local.properties` file at the root (same level as `build.gradle`) of your project.

> **Note**: Do not commit this file to your source control, for example, by adding it to your `.gitignore` file!

`
SUPABASE_ANON_KEY=YOUR_SUPABASE_ANON_KEY
SUPABASE_URL=YOUR_SUPABASE_URL
`

#### Read and set value to `BuildConfig` [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin\#read-and-set-value-to-buildconfig)

In your `build.gradle` (app) file, create a `Properties` object and read the values from your `local.properties` file by calling the `buildConfigField` method:

`
defaultConfig {
applicationId "com.example.manageproducts"
minSdkVersion 22
targetSdkVersion 33
versionCode 5
versionName "1.0"
testInstrumentationRunner "androidx.test.runner.AndroidJUnitRunner"
// Set value part
Properties properties = new Properties()
properties.load(project.rootProject.file("local.properties").newDataInputStream())
buildConfigField("String", "SUPABASE_ANON_KEY", "\"${properties.getProperty("SUPABASE_ANON_KEY")}\"")
buildConfigField("String", "SECRET", "\"${properties.getProperty("SECRET")}\"")
buildConfigField("String", "SUPABASE_URL", "\"${properties.getProperty("SUPABASE_URL")}\"")
}
`

#### Use value from `BuildConfig` [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin\#use-value-from-buildconfig)

Read the value from `BuildConfig`:

`
val url = BuildConfig.SUPABASE_URL
val apiKey = BuildConfig.SUPABASE_ANON_KEY
`

### Set up Supabase dependencies [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin\#set-up-supabase-dependencies)

![Gradle dependencies](https://supabase.com/docs/img/guides/kotlin/gradle-dependencies.png)

In the `build.gradle` (app) file, add these dependencies then press "Sync now." Replace the dependency version placeholders `$supabase_version` and `$ktor_version` with their respective latest versions.

`
implementation "io.github.jan-tennert.supabase:postgrest-kt:$supabase_version"
implementation "io.github.jan-tennert.supabase:storage-kt:$supabase_version"
implementation "io.github.jan-tennert.supabase:auth-kt:$supabase_version"
implementation "io.ktor:ktor-client-android:$ktor_version"
implementation "io.ktor:ktor-client-core:$ktor_version"
implementation "io.ktor:ktor-utils:$ktor_version"
`

Also in the `build.gradle` (app) file, add the plugin for serialization. The version of this plugin should be the same as your Kotlin version.

`
plugins {
    ...
    id 'org.jetbrains.kotlin.plugin.serialization' version '$kotlin_version'
    ...
}
`

### Set up Hilt for dependency injection [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin\#set-up-hilt-for-dependency-injection)

In the `build.gradle` (app) file, add the following:

`
implementation "com.google.dagger:hilt-android:$hilt_version"
annotationProcessor "com.google.dagger:hilt-compiler:$hilt_version"
implementation("androidx.hilt:hilt-navigation-compose:1.0.0")
`

Create a new `ManageProductApplication.kt` class extending Application with `@HiltAndroidApp` annotation:

`
// ManageProductApplication.kt
@HiltAndroidApp
class ManageProductApplication: Application()
`

Open the `AndroidManifest.xml` file, update name property of Application tag:

`
<application
...
    android:name=".ManageProductApplication"
...
</application>
`

Create the `MainActivity`:

`
@AndroidEntryPoint
class MainActivity : ComponentActivity() {
    //This will come later
}
`

### Provide Supabase instances with Hilt [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin\#provide-supabase-instances-with-hilt)

To make the app easier to test, create a `SupabaseModule.kt` file as follows:

`
@InstallIn(SingletonComponent::class)
@Module
object SupabaseModule {
    @Provides
    @Singleton
    fun provideSupabaseClient(): SupabaseClient {
        return createSupabaseClient(
            supabaseUrl = BuildConfig.SUPABASE_URL,
            supabaseKey = BuildConfig.SUPABASE_ANON_KEY
        ) {
            install(Postgrest)
            install(Auth) {
                flowType = FlowType.PKCE
                scheme = "app"
                host = "supabase.com"
            }
            install(Storage)
        }
    }
    @Provides
    @Singleton
    fun provideSupabaseDatabase(client: SupabaseClient): Postgrest {
        return client.postgrest
    }
    @Provides
    @Singleton
    fun provideSupabaseAuth(client: SupabaseClient): Auth {
        return client.auth
    }
    @Provides
    @Singleton
    fun provideSupabaseStorage(client: SupabaseClient): Storage {
        return client.storage
    }
}
`

### Create a data transfer object [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin\#create-a-data-transfer-object)

Create a `ProductDto.kt` class and use annotations to parse data from Supabase:

`
@Serializable
data class ProductDto(
    @SerialName("name")
    val name: String,
    @SerialName("price")
    val price: Double,
    @SerialName("image")
    val image: String?,
    @SerialName("id")
    val id: String,
)
`

Create a Domain object in `Product.kt` expose the data in your view:

`
data class Product(
    val id: String,
    val name: String,
    val price: Double,
    val image: String?
)
`

### Implement repositories [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin\#implement-repositories)

Create a `ProductRepository` interface and its implementation named `ProductRepositoryImpl`. This holds the logic to interact with data sources from Supabase. Do the same with the `AuthenticationRepository`.

Create the Product Repository:

`
interface ProductRepository {
    suspend fun createProduct(product: Product): Boolean
    suspend fun getProducts(): List<ProductDto>?
    suspend fun getProduct(id: String): ProductDto
    suspend fun deleteProduct(id: String)
    suspend fun updateProduct(
        id: String, name: String, price: Double, imageName: String, imageFile: ByteArray
    )
}
`

`
class ProductRepositoryImpl @Inject constructor(
    private val postgrest: Postgrest,
    private val storage: Storage,
) : ProductRepository {
    override suspend fun createProduct(product: Product): Boolean {
        return try {
            withContext(Dispatchers.IO) {
                val productDto = ProductDto(
                    name = product.name,
                    price = product.price,
                )
                postgrest.from("products").insert(productDto)
                true
            }
            true
        } catch (e: java.lang.Exception) {
            throw e
        }
    }
    override suspend fun getProducts(): List<ProductDto>? {
        return withContext(Dispatchers.IO) {
            val result = postgrest.from("products")
                .select().decodeList<ProductDto>()
            result
        }
    }
    override suspend fun getProduct(id: String): ProductDto {
        return withContext(Dispatchers.IO) {
            postgrest.from("products").select {
                filter {
                    eq("id", id)
                }
            }.decodeSingle<ProductDto>()
        }
    }
    override suspend fun deleteProduct(id: String) {
        return withContext(Dispatchers.IO) {
            postgrest.from("products").delete {
                filter {
                    eq("id", id)
                }
            }
        }
    }
    override suspend fun updateProduct(
        id: String,
        name: String,
        price: Double,
        imageName: String,
        imageFile: ByteArray
    ) {
        withContext(Dispatchers.IO) {
            if (imageFile.isNotEmpty()) {
                val imageUrl =
                    storage.from("Product%20Image").upload(
                        path = "$imageName.png",
                        data = imageFile,
                        upsert = true
                    )
                postgrest.from("products").update({
                    set("name", name)
                    set("price", price)
                    set("image", buildImageUrl(imageFileName = imageUrl))
                }) {
                    filter {
                        eq("id", id)
                    }
                }
            } else {
                postgrest.from("products").update({
                    set("name", name)
                    set("price", price)
                }) {
                    filter {
                        eq("id", id)
                    }
                }
            }
        }
    }
    // Because I named the bucket as "Product Image" so when it turns to an url, it is "%20"
    // For better approach, you should create your bucket name without space symbol
    private fun buildImageUrl(imageFileName: String) =
        "${BuildConfig.SUPABASE_URL}/storage/v1/object/public/${imageFileName}".replace(" ", "%20")
}
`

Create the Authentication Repository:

`
interface AuthenticationRepository {
    suspend fun signIn(email: String, password: String): Boolean
    suspend fun signUp(email: String, password: String): Boolean
    suspend fun signInWithGoogle(): Boolean
}
`

`
class AuthenticationRepositoryImpl @Inject constructor(
    private val auth: Auth
) : AuthenticationRepository {
    override suspend fun signIn(email: String, password: String): Boolean {
        return try {
            auth.signInWith(Email) {
                this.email = email
                this.password = password
            }
            true
        } catch (e: Exception) {
            false
        }
    }
    override suspend fun signUp(email: String, password: String): Boolean {
        return try {
            auth.signUpWith(Email) {
                this.email = email
                this.password = password
            }
            true
        } catch (e: Exception) {
            false
        }
    }
    override suspend fun signInWithGoogle(): Boolean {
        return try {
            auth.signInWith(Google)
            true
        } catch (e: Exception) {
            false
        }
    }
}
`

### Implement screens [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin\#implement-screens)

To navigate screens, use the AndroidX navigation library. For routes, implement a `Destination` interface:

`
interface Destination {
    val route: String
    val title: String
}
object ProductListDestination : Destination {
    override val route = "product_list"
    override val title = "Product List"
}
object ProductDetailsDestination : Destination {
    override val route = "product_details"
    override val title = "Product Details"
    const val productId = "product_id"
    val arguments = listOf(navArgument(name = productId) {
        type = NavType.StringType
    })
    fun createRouteWithParam(productId: String) = "$route/${productId}"
}
object AddProductDestination : Destination {
    override val route = "add_product"
    override val title = "Add Product"
}
object AuthenticationDestination: Destination {
    override val route = "authentication"
    override val title = "Authentication"
}
object SignUpDestination: Destination {
    override val route = "signup"
    override val title = "Sign Up"
}
`

This will help later for navigating between screens.

Create a `ProductListViewModel`:

`
@HiltViewModel
class ProductListViewModel @Inject constructor(
private val productRepository: ProductRepository,
) : ViewModel() {
    private val _productList = MutableStateFlow<List<Product>?>(listOf())
    val productList: Flow<List<Product>?> = _productList
    private val _isLoading = MutableStateFlow(false)
    val isLoading: Flow<Boolean> = _isLoading
    init {
        getProducts()
    }
    fun getProducts() {
        viewModelScope.launch {
            val products = productRepository.getProducts()
            _productList.emit(products?.map { it -> it.asDomainModel() })
        }
    }
    fun removeItem(product: Product) {
        viewModelScope.launch {
            val newList = mutableListOf<Product>().apply { _productList.value?.let { addAll(it) } }
            newList.remove(product)
            _productList.emit(newList.toList())
            // Call api to remove
            productRepository.deleteProduct(id = product.id)
            // Then fetch again
            getProducts()
        }
    }
    private fun ProductDto.asDomainModel(): Product {
        return Product(
            id = this.id,
            name = this.name,
            price = this.price,
            image = this.image
        )
    }
}
`

Create the `ProductListScreen.kt`:

`
@OptIn(ExperimentalMaterial3Api::class, ExperimentalMaterialApi::class)
@Composable
fun ProductListScreen(
    modifier: Modifier = Modifier,
    navController: NavController,
    viewModel: ProductListViewModel = hiltViewModel(),
) {
    val isLoading by viewModel.isLoading.collectAsState(initial = false)
    val swipeRefreshState = rememberSwipeRefreshState(isRefreshing = isLoading)
    SwipeRefresh(state = swipeRefreshState, onRefresh = { viewModel.getProducts() }) {
        Scaffold(
            topBar = {
                TopAppBar(
                    backgroundColor = MaterialTheme.colorScheme.primary,
                    title = {
                        Text(
                            text = stringResource(R.string.product_list_text_screen_title),
                            color = MaterialTheme.colorScheme.onPrimary,
                        )
                    },
                )
            },
            floatingActionButton = {
                AddProductButton(onClick = { navController.navigate(AddProductDestination.route) })
            }
        ) { padding ->
            val productList = viewModel.productList.collectAsState(initial = listOf()).value
            if (!productList.isNullOrEmpty()) {
                LazyColumn(
                    modifier = modifier.padding(padding),
                    contentPadding = PaddingValues(5.dp)
                ) {
                    itemsIndexed(
                        items = productList,
                        key = { _, product -> product.name }) { _, item ->
                        val state = rememberDismissState(
                            confirmStateChange = {
                                if (it == DismissValue.DismissedToStart) {
                                    // Handle item removed
                                    viewModel.removeItem(item)
                                }
                                true
                            }
                        )
                        SwipeToDismiss(
                            state = state,
                            background = {
                                val color by animateColorAsState(
                                    targetValue = when (state.dismissDirection) {
                                        DismissDirection.StartToEnd -> MaterialTheme.colorScheme.primary
                                        DismissDirection.EndToStart -> MaterialTheme.colorScheme.primary.copy(
                                            alpha = 0.2f
                                        )
                                        null -> Color.Transparent
                                    }
                                )
                                Box(
                                    modifier = modifier
                                        .fillMaxSize()
                                        .background(color = color)
                                        .padding(16.dp),
                                ) {
                                    Icon(
                                        imageVector = Icons.Filled.Delete,
                                        contentDescription = null,
                                        tint = MaterialTheme.colorScheme.primary,
                                        modifier = modifier.align(Alignment.CenterEnd)
                                    )
                                }
                            },
                            dismissContent = {
                                ProductListItem(
                                    product = item,
                                    modifier = modifier,
                                    onClick = {
                                        navController.navigate(
                                            ProductDetailsDestination.createRouteWithParam(
                                                item.id
                                            )
                                        )
                                    },
                                )
                            },
                            directions = setOf(DismissDirection.EndToStart),
                        )
                    }
                }
            } else {
                Text("Product list is empty!")
            }
        }
    }
}
@Composable
private fun AddProductButton(
    modifier: Modifier = Modifier,
    onClick: () -> Unit,
) {
    FloatingActionButton(
        modifier = modifier,
        onClick = onClick,
        containerColor = MaterialTheme.colorScheme.primary,
        contentColor = MaterialTheme.colorScheme.onPrimary
    ) {
        Icon(
            imageVector = Icons.Filled.Add,
            contentDescription = null,
        )
    }
}
`

Create the `ProductDetailsViewModel.kt`:

`
@HiltViewModel
class ProductDetailsViewModel @Inject constructor(
    private val productRepository: ProductRepository,
    savedStateHandle: SavedStateHandle,
    ) : ViewModel() {
    private val _product = MutableStateFlow<Product?>(null)
    val product: Flow<Product?> = _product
    private val _name = MutableStateFlow("")
    val name: Flow<String> = _name
    private val _price = MutableStateFlow(0.0)
    val price: Flow<Double> = _price
    private val _imageUrl = MutableStateFlow("")
    val imageUrl: Flow<String> = _imageUrl
    init {
        val productId = savedStateHandle.get<String>(ProductDetailsDestination.productId)
        productId?.let {
            getProduct(productId = it)
        }
    }
    private fun getProduct(productId: String) {
        viewModelScope.launch {
           val result = productRepository.getProduct(productId).asDomainModel()
            _product.emit(result)
            _name.emit(result.name)
            _price.emit(result.price)
        }
    }
    fun onNameChange(name: String) {
        _name.value = name
    }
    fun onPriceChange(price: Double) {
        _price.value = price
    }
    fun onSaveProduct(image: ByteArray) {
        viewModelScope.launch {
            productRepository.updateProduct(
                id = _product.value?.id,
                price = _price.value,
                name = _name.value,
                imageFile = image,
                imageName = "image_${_product.value.id}",
            )
        }
    }
    fun onImageChange(url: String) {
        _imageUrl.value = url
    }
    private fun ProductDto.asDomainModel(): Product {
        return Product(
            id = this.id,
            name = this.name,
            price = this.price,
            image = this.image
        )
    }
}
`

Create the `ProductDetailsScreen.kt`:

`
@OptIn(ExperimentalCoilApi::class)
@SuppressLint("UnusedMaterialScaffoldPaddingParameter")
@Composable
fun ProductDetailsScreen(
    modifier: Modifier = Modifier,
    viewModel: ProductDetailsViewModel = hiltViewModel(),
    navController: NavController,
    productId: String?,
) {
    val snackBarHostState = remember { SnackbarHostState() }
    val coroutineScope = rememberCoroutineScope()
    Scaffold(
        snackbarHost = { SnackbarHost(snackBarHostState) },
        topBar = {
            TopAppBar(
                navigationIcon = {
                    IconButton(onClick = {
                        navController.navigateUp()
                    }) {
                        Icon(
                            imageVector = Icons.Filled.ArrowBack,
                            contentDescription = null,
                            tint = MaterialTheme.colorScheme.onPrimary
                        )
                    }
                },
                backgroundColor = MaterialTheme.colorScheme.primary,
                title = {
                    Text(
                        text = stringResource(R.string.product_details_text_screen_title),
                        color = MaterialTheme.colorScheme.onPrimary,
                    )
                },
            )
        }
    ) {
        val name = viewModel.name.collectAsState(initial = "")
        val price = viewModel.price.collectAsState(initial = 0.0)
        var imageUrl = Uri.parse(viewModel.imageUrl.collectAsState(initial = null).value)
        val contentResolver = LocalContext.current.contentResolver
        Column(
            modifier = modifier
                .padding(16.dp)
                .fillMaxSize()
        ) {
            val galleryLauncher =
                rememberLauncherForActivityResult(ActivityResultContracts.GetContent())
                { uri ->
                    uri?.let {
                        if (it.toString() != imageUrl.toString()) {
                            viewModel.onImageChange(it.toString())
                        }
                    }
                }
            Image(
                painter = rememberImagePainter(imageUrl),
                contentScale = ContentScale.Fit,
                contentDescription = null,
                modifier = Modifier
                    .padding(16.dp, 8.dp)
                    .size(100.dp)
                    .align(Alignment.CenterHorizontally)
            )
            IconButton(modifier = modifier.align(alignment = Alignment.CenterHorizontally),
                onClick = {
                    galleryLauncher.launch("image/*")
                }) {
                Icon(
                    imageVector = Icons.Filled.Edit,
                    contentDescription = null,
                    tint = MaterialTheme.colorScheme.primary
                )
            }
            OutlinedTextField(
                label = {
                    Text(
                        text = "Product name",
                        color = MaterialTheme.colorScheme.primary,
                        style = MaterialTheme.typography.titleMedium
                    )
                },
                maxLines = 2,
                shape = RoundedCornerShape(32),
                modifier = modifier.fillMaxWidth(),
                value = name.value,
                onValueChange = {
                    viewModel.onNameChange(it)
                },
            )
            Spacer(modifier = modifier.height(12.dp))
            OutlinedTextField(
                label = {
                    Text(
                        text = "Product price",
                        color = MaterialTheme.colorScheme.primary,
                        style = MaterialTheme.typography.titleMedium
                    )
                },
                maxLines = 2,
                shape = RoundedCornerShape(32),
                modifier = modifier.fillMaxWidth(),
                value = price.value.toString(),
                keyboardOptions = KeyboardOptions(keyboardType = KeyboardType.Number),
                onValueChange = {
                    viewModel.onPriceChange(it.toDouble())
                },
            )
            Spacer(modifier = modifier.weight(1f))
            Button(
                modifier = modifier.fillMaxWidth(),
                onClick = {
                    if (imageUrl.host?.contains("supabase") == true) {
                        viewModel.onSaveProduct(image = byteArrayOf())
                    } else {
                        val image = uriToByteArray(contentResolver, imageUrl)
                        viewModel.onSaveProduct(image = image)
                    }
                    coroutineScope.launch {
                        snackBarHostState.showSnackbar(
                            message = "Product updated successfully !",
                            duration = SnackbarDuration.Short
                        )
                    }
                }) {
                Text(text = "Save changes")
            }
            Spacer(modifier = modifier.height(12.dp))
            OutlinedButton(
                modifier = modifier
                    .fillMaxWidth(),
                onClick = {
                    navController.navigateUp()
                }) {
                Text(text = "Cancel")
            }
        }
    }
}
private fun getBytes(inputStream: InputStream): ByteArray {
    val byteBuffer = ByteArrayOutputStream()
    val bufferSize = 1024
    val buffer = ByteArray(bufferSize)
    var len = 0
    while (inputStream.read(buffer).also { len = it } != -1) {
        byteBuffer.write(buffer, 0, len)
    }
    return byteBuffer.toByteArray()
}
private fun uriToByteArray(contentResolver: ContentResolver, uri: Uri): ByteArray {
    if (uri == Uri.EMPTY) {
        return byteArrayOf()
    }
    val inputStream = contentResolver.openInputStream(uri)
    if (inputStream != null) {
        return getBytes(inputStream)
    }
    return byteArrayOf()
}
`

Create a `AddProductScreen`:

`
@SuppressLint("UnusedMaterial3ScaffoldPaddingParameter")
@OptIn(ExperimentalMaterial3Api::class)
@Composable
fun AddProductScreen(
    modifier: Modifier = Modifier,
    navController: NavController,
    viewModel: AddProductViewModel = hiltViewModel(),
) {
    Scaffold(
        topBar = {
            TopAppBar(
                navigationIcon = {
                    IconButton(onClick = {
                        navController.navigateUp()
                    }) {
                        Icon(
                            imageVector = Icons.Filled.ArrowBack,
                            contentDescription = null,
                            tint = MaterialTheme.colorScheme.onPrimary
                        )
                    }
                },
                backgroundColor = MaterialTheme.colorScheme.primary,
                title = {
                    Text(
                        text = stringResource(R.string.add_product_text_screen_title),
                        color = MaterialTheme.colorScheme.onPrimary,
                    )
                },
            )
        }
    ) { padding ->
        val navigateAddProductSuccess =
            viewModel.navigateAddProductSuccess.collectAsState(initial = null).value
        val isLoading =
            viewModel.isLoading.collectAsState(initial = null).value
        if (isLoading == true) {
            LoadingScreen(message = "Adding Product",
                onCancelSelected = {
                    navController.navigateUp()
                })
        } else {
            SuccessScreen(
                message = "Product added",
                onMoreAction = {
                    viewModel.onAddMoreProductSelected()
                },
                onNavigateBack = {
                    navController.navigateUp()
                })
        }
    }
}
`

Create the `AddProductViewModel.kt`:

`
@HiltViewModel
class AddProductViewModel @Inject constructor(
    private val productRepository: ProductRepository,
) : ViewModel() {
    private val _isLoading = MutableStateFlow(false)
    val isLoading: Flow<Boolean> = _isLoading
    private val _showSuccessMessage = MutableStateFlow(false)
    val showSuccessMessage: Flow<Boolean> = _showSuccessMessage
    fun onCreateProduct(name: String, price: Double) {
        if (name.isEmpty() || price <= 0) return
        viewModelScope.launch {
            _isLoading.value = true
            val product = Product(
                id = UUID.randomUUID().toString(),
                name = name,
                price = price,
            )
            productRepository.createProduct(product = product)
            _isLoading.value = false
            _showSuccessMessage.emit(true)
        }
    }
}
`

Create a `SignUpViewModel`:

`
@HiltViewModel
class SignUpViewModel @Inject constructor(
    private val authenticationRepository: AuthenticationRepository
) : ViewModel() {
    private val _email = MutableStateFlow("")
    val email: Flow<String> = _email
    private val _password = MutableStateFlow("")
    val password = _password
    fun onEmailChange(email: String) {
        _email.value = email
    }
    fun onPasswordChange(password: String) {
        _password.value = password
    }
    fun onSignUp() {
        viewModelScope.launch {
            authenticationRepository.signUp(
                email = _email.value,
                password = _password.value
            )
        }
    }
}
`

Create the `SignUpScreen.kt`:

`
@Composable
fun SignUpScreen(
    modifier: Modifier = Modifier,
    navController: NavController,
    viewModel: SignUpViewModel = hiltViewModel()
) {
    val snackBarHostState = remember { SnackbarHostState() }
    val coroutineScope = rememberCoroutineScope()
    Scaffold(
        snackbarHost = { androidx.compose.material.SnackbarHost(snackBarHostState) },
        topBar = {
            TopAppBar(
                navigationIcon = {
                    IconButton(onClick = {
                        navController.navigateUp()
                    }) {
                        Icon(
                            imageVector = Icons.Filled.ArrowBack,
                            contentDescription = null,
                            tint = MaterialTheme.colorScheme.onPrimary
                        )
                    }
                },
                backgroundColor = MaterialTheme.colorScheme.primary,
                title = {
                    Text(
                        text = "Sign Up",
                        color = MaterialTheme.colorScheme.onPrimary,
                    )
                },
            )
        }
    ) { paddingValues ->
        Column(
            modifier = modifier
                .padding(paddingValues)
                .padding(20.dp)
        ) {
            val email = viewModel.email.collectAsState(initial = "")
            val password = viewModel.password.collectAsState()
            OutlinedTextField(
                label = {
                    Text(
                        text = "Email",
                        color = MaterialTheme.colorScheme.primary,
                        style = MaterialTheme.typography.titleMedium
                    )
                },
                maxLines = 1,
                shape = RoundedCornerShape(32),
                modifier = modifier.fillMaxWidth(),
                value = email.value,
                onValueChange = {
                    viewModel.onEmailChange(it)
                },
            )
            OutlinedTextField(
                label = {
                    Text(
                        text = "Password",
                        color = MaterialTheme.colorScheme.primary,
                        style = MaterialTheme.typography.titleMedium
                    )
                },
                maxLines = 1,
                shape = RoundedCornerShape(32),
                modifier = modifier
                    .fillMaxWidth()
                    .padding(top = 12.dp),
                value = password.value,
                onValueChange = {
                    viewModel.onPasswordChange(it)
                },
            )
            val localSoftwareKeyboardController = LocalSoftwareKeyboardController.current
            Button(modifier = modifier
                .fillMaxWidth()
                .padding(top = 12.dp),
                onClick = {
                    localSoftwareKeyboardController?.hide()
                    viewModel.onSignUp()
                    coroutineScope.launch {
                        snackBarHostState.showSnackbar(
                            message = "Create account successfully. Sign in now!",
                            duration = SnackbarDuration.Long
                        )
                    }
                }) {
                Text("Sign up")
            }
        }
    }
}
`

Create a `SignInViewModel`:

`
@HiltViewModel
class SignInViewModel @Inject constructor(
    private val authenticationRepository: AuthenticationRepository
) : ViewModel() {
    private val _email = MutableStateFlow("")
    val email: Flow<String> = _email
    private val _password = MutableStateFlow("")
    val password = _password
    fun onEmailChange(email: String) {
        _email.value = email
    }
    fun onPasswordChange(password: String) {
        _password.value = password
    }
    fun onSignIn() {
        viewModelScope.launch {
            authenticationRepository.signIn(
                email = _email.value,
                password = _password.value
            )
        }
    }
    fun onGoogleSignIn() {
        viewModelScope.launch {
            authenticationRepository.signInWithGoogle()
        }
    }
}
`

Create the `SignInScreen.kt`:

`
@OptIn(ExperimentalMaterial3Api::class, ExperimentalComposeUiApi::class)
@Composable
fun SignInScreen(
    modifier: Modifier = Modifier,
    navController: NavController,
    viewModel: SignInViewModel = hiltViewModel()
) {
    val snackBarHostState = remember { SnackbarHostState() }
    val coroutineScope = rememberCoroutineScope()
    Scaffold(
        snackbarHost = { androidx.compose.material.SnackbarHost(snackBarHostState) },
        topBar = {
            TopAppBar(
                navigationIcon = {
                    IconButton(onClick = {
                        navController.navigateUp()
                    }) {
                        Icon(
                            imageVector = Icons.Filled.ArrowBack,
                            contentDescription = null,
                            tint = MaterialTheme.colorScheme.onPrimary
                        )
                    }
                },
                backgroundColor = MaterialTheme.colorScheme.primary,
                title = {
                    Text(
                        text = "Login",
                        color = MaterialTheme.colorScheme.onPrimary,
                    )
                },
            )
        }
    ) { paddingValues ->
        Column(
            modifier = modifier
                .padding(paddingValues)
                .padding(20.dp)
        ) {
            val email = viewModel.email.collectAsState(initial = "")
            val password = viewModel.password.collectAsState()
            androidx.compose.material.OutlinedTextField(
                label = {
                    Text(
                        text = "Email",
                        color = MaterialTheme.colorScheme.primary,
                        style = MaterialTheme.typography.titleMedium
                    )
                },
                maxLines = 1,
                shape = RoundedCornerShape(32),
                modifier = modifier.fillMaxWidth(),
                value = email.value,
                onValueChange = {
                    viewModel.onEmailChange(it)
                },
            )
            androidx.compose.material.OutlinedTextField(
                label = {
                    Text(
                        text = "Password",
                        color = MaterialTheme.colorScheme.primary,
                        style = MaterialTheme.typography.titleMedium
                    )
                },
                maxLines = 1,
                shape = RoundedCornerShape(32),
                modifier = modifier
                    .fillMaxWidth()
                    .padding(top = 12.dp),
                value = password.value,
                onValueChange = {
                    viewModel.onPasswordChange(it)
                },
            )
            val localSoftwareKeyboardController = LocalSoftwareKeyboardController.current
            Button(modifier = modifier
                .fillMaxWidth()
                .padding(top = 12.dp),
                onClick = {
                    localSoftwareKeyboardController?.hide()
                    viewModel.onGoogleSignIn()
                }) {
                Text("Sign in with Google")
            }
            Button(modifier = modifier
                .fillMaxWidth()
                .padding(top = 12.dp),
                onClick = {
                    localSoftwareKeyboardController?.hide()
                    viewModel.onSignIn()
                    coroutineScope.launch {
                        snackBarHostState.showSnackbar(
                            message = "Sign in successfully !",
                            duration = SnackbarDuration.Long
                        )
                    }
                }) {
                Text("Sign in")
            }
            OutlinedButton(modifier = modifier
                .fillMaxWidth()
                .padding(top = 12.dp), onClick = {
                navController.navigate(SignUpDestination.route)
            }) {
                Text("Sign up")
            }
        }
    }
}
`

### Implement the `MainActivity` [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin\#implement-the-mainactivity)

In the `MainActivity` you created earlier, show your newly created screens:

`
@AndroidEntryPoint
class MainActivity : ComponentActivity() {
    @Inject
    lateinit var supabaseClient: SupabaseClient
    @OptIn(ExperimentalMaterial3Api::class)
    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        setContent {
            ManageProductsTheme {
                // A surface container using the 'background' color from the theme
                val navController = rememberNavController()
                val currentBackStack by navController.currentBackStackEntryAsState()
                val currentDestination = currentBackStack?.destination
                Scaffold { innerPadding ->
                    NavHost(
                        navController,
                        startDestination = ProductListDestination.route,
                        Modifier.padding(innerPadding)
                    ) {
                        composable(ProductListDestination.route) {
                            ProductListScreen(
                                navController = navController
                            )
                        }
                        composable(AuthenticationDestination.route) {
                            SignInScreen(
                                navController = navController
                            )
                        }
                        composable(SignUpDestination.route) {
                            SignUpScreen(
                                navController = navController
                            )
                        }
                        composable(AddProductDestination.route) {
                            AddProductScreen(
                                navController = navController
                            )
                        }
                        composable(
                            route = "${ProductDetailsDestination.route}/{${ProductDetailsDestination.productId}}",
                            arguments = ProductDetailsDestination.arguments
                        ) { navBackStackEntry ->
                            val productId =
                                navBackStackEntry.arguments?.getString(ProductDetailsDestination.productId)
                            ProductDetailsScreen(
                                productId = productId,
                                navController = navController,
                            )
                        }
                    }
                }
            }
        }
    }
}
`

### Create the success screen [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin\#create-the-success-screen)

To handle OAuth and OTP signins, create a new activity to handle the deep link you set in `AndroidManifest.xml`:

`
<?xml version="1.0" encoding="utf-8"?>
<manifest xmlns:android="http://schemas.android.com/apk/res/android"
    xmlns:tools="http://schemas.android.com/tools">
    <uses-permission android:name="android.permission.INTERNET" />
    <application
        android:name=".ManageProductApplication"
        android:allowBackup="true"
        android:dataExtractionRules="@xml/data_extraction_rules"
        android:enableOnBackInvokedCallback="true"
        android:fullBackupContent="@xml/backup_rules"
        android:icon="@mipmap/ic_launcher"
        android:label="@string/app_name"
        android:supportsRtl="true"
        android:theme="@style/Theme.ManageProducts"
        tools:targetApi="31">
        <activity
            android:name=".DeepLinkHandlerActivity"
            android:exported="true"
            android:theme="@style/Theme.ManageProducts" >
            <intent-filter android:autoVerify="true">
                <action android:name="android.intent.action.VIEW" />
                <category android:name="android.intent.category.DEFAULT" />
                <category android:name="android.intent.category.BROWSABLE" />
                <data
                    android:host="supabase.com"
                    android:scheme="app" />
            </intent-filter>
        </activity>
        <activity
            android:name=".MainActivity"
            android:exported="true"
            android:label="@string/app_name"
            android:theme="@style/Theme.ManageProducts">
            <intent-filter>
                <action android:name="android.intent.action.MAIN" />
                <category android:name="android.intent.category.LAUNCHER" />
            </intent-filter>
        </activity>
    </application>
</manifest>
`

Then create the `DeepLinkHandlerActivity`:

`
@AndroidEntryPoint
class DeepLinkHandlerActivity : ComponentActivity() {
    @Inject
    lateinit var supabaseClient: SupabaseClient
    private lateinit var callback: (String, String) -> Unit
    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        supabaseClient.handleDeeplinks(intent = intent,
            onSessionSuccess = { userSession ->
                Log.d("LOGIN", "Log in successfully with user info: ${userSession.user}")
                userSession.user?.apply {
                    callback(email ?: "", createdAt.toString())
                }
            })
        setContent {
            val navController = rememberNavController()
            val emailState = remember { mutableStateOf("") }
            val createdAtState = remember { mutableStateOf("") }
            LaunchedEffect(Unit) {
                callback = { email, created ->
                    emailState.value = email
                    createdAtState.value = created
                }
            }
            ManageProductsTheme {
                Surface(
                    modifier = Modifier.fillMaxSize(),
                    color = MaterialTheme.colorScheme.background
                ) {
                    SignInSuccessScreen(
                        modifier = Modifier.padding(20.dp),
                        navController = navController,
                        email = emailState.value,
                        createdAt = createdAtState.value,
                        onClick = { navigateToMainApp() }
                    )
                }
            }
        }
    }
    private fun navigateToMainApp() {
        val intent = Intent(this, MainActivity::class.java).apply {
            flags = Intent.FLAG_ACTIVITY_CLEAR_TOP
        }
        startActivity(intent)
    }
}
`

### Is this helpful?

NoYes

### On this page

[Project setup](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin#project-setup) [Create a project](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin#create-a-project) [Set up the database schema](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin#set-up-the-database-schema) [Get the API Keys](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin#get-the-api-keys) [Set up Google Authentication](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin#set-up-google-authentication) [Building the app](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin#building-the-app) [Create new Android project](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin#create-new-android-project) [Set up API key and secret securely](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin#set-up-api-key-and-secret-securely) [Set up Supabase dependencies](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin#set-up-supabase-dependencies) [Set up Hilt for dependency injection](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin#set-up-hilt-for-dependency-injection) [Provide Supabase instances with Hilt](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin#provide-supabase-instances-with-hilt) [Create a data transfer object](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin#create-a-data-transfer-object) [Implement repositories](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin#implement-repositories) [Implement screens](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin#implement-screens) [Implement the MainActivity](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin#implement-the-mainactivity) [Create the success screen](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin#create-the-success-screen)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_tutorials_with_nextjs.md">
Getting Started

# Build a User Management App with Next.js

* * *

This tutorial demonstrates how to build a basic user management app. The app authenticates and identifies the user, stores their profile information in the database, and allows the user to log in, update their profile details, and upload a profile photo. The app uses:

- [Supabase Database](https://supabase.com/docs/guides/database) \- a Postgres database for storing your user data and [Row Level Security](https://supabase.com/docs/guides/auth#row-level-security) so data is protected and users can only access their own information.
- [Supabase Auth](https://supabase.com/docs/guides/auth) \- allow users to sign up and log in.
- [Supabase Storage](https://supabase.com/docs/guides/storage) \- users can upload a profile photo.

![Supabase User Management example](https://supabase.com/docs/img/user-management-demo.png)

If you get stuck while working through this guide, refer to the [full example on GitHub](https://github.com/supabase/supabase/tree/master/examples/user-management/nextjs-user-management).

## Project setup [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs\#project-setup)

Before we start building we're going to set up our Database and API. This is as simple as starting a new Project in Supabase and then creating a "schema" inside the database.

### Create a project [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs\#create-a-project)

1. [Create a new project](https://supabase.com/dashboard) in the Supabase Dashboard.
2. Enter your project details.
3. Wait for the new database to launch.

### Set up the database schema [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs\#set-up-the-database-schema)

Now we are going to set up the database schema. We can use the "User Management Starter" quickstart in the SQL Editor, or you can just copy/paste the SQL from below and run it yourself.

DashboardSQL

1. Go to the [SQL Editor](https://supabase.com/dashboard/project/_/sql) page in the Dashboard.
2. Click **User Management Starter**.
3. Click **Run**.

You can easily pull the database schema down to your local project by running the `db pull` command. Read the [local development docs](https://supabase.com/docs/guides/cli/local-development#link-your-project) for detailed instructions.

`
supabase link --project-ref <project-id>
# You can get <project-id> from your project's dashboard URL: https://supabase.com/dashboard/project/<project-id>
supabase db pull
`

### Get the API Keys [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs\#get-the-api-keys)

Now that you've created some database tables, you are ready to insert data using the auto-generated API.
We just need to get the Project URL and `anon` key from the API settings.

1. Go to the [API Settings](https://supabase.com/dashboard/project/_/settings/api) page in the Dashboard.
2. Find your Project `URL`, `anon`, and `service_role` keys on this page.

## Building the app [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs\#building-the-app)

Let's start building the Next.js app from scratch.

### Initialize a Next.js app [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs\#initialize-a-nextjs-app)

We can use [`create-next-app`](https://nextjs.org/docs/getting-started) to initialize an app called `supabase-nextjs`:

JavaScriptTypeScript

`
npx create-next-app@latest --use-npm supabase-nextjs
cd supabase-nextjs
`

Then install the Supabase client library: [supabase-js](https://github.com/supabase/supabase-js)

`
npm install @supabase/supabase-js
`

And finally we want to save the environment variables in a `.env.local`.
Create a `.env.local` file at the root of the project, and paste the API URL and the `anon` key that you copied [earlier](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs#get-the-api-keys).

.env.local

`
NEXT_PUBLIC_SUPABASE_URL=YOUR_SUPABASE_URL
NEXT_PUBLIC_SUPABASE_ANON_KEY=YOUR_SUPABASE_ANON_KEY
`

### App styling (optional) [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs\#app-styling-optional)

An optional step is to update the CSS file `app/globals.css` to make the app look nice.
You can find the full contents of this file [here](https://raw.githubusercontent.com/supabase/supabase/master/examples/user-management/nextjs-user-management/app/globals.css).

### Supabase Server-Side Auth [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs\#supabase-server-side-auth)

Next.js is a highly versatile framework offering pre-rendering at build time (SSG), server-side rendering at request time (SSR), API routes, and middleware edge-functions.

To better integrate with the framework, we've created the `@supabase/ssr` package for Server-Side Auth. It has all the functionalities to quickly configure your Supabase project to use cookies for storing user sessions. See the [Next.js Server-Side Auth guide](https://supabase.com/docs/guides/auth/server-side/nextjs) for more information.

Install the package for Next.js.

`
npm install @supabase/ssr
`

### Supabase utilities [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs\#supabase-utilities)

There are two different types of clients in Supabase:

1. **Client Component client** \- To access Supabase from Client Components, which run in the browser.
2. **Server Component client** \- To access Supabase from Server Components, Server Actions, and Route Handlers, which run only on the server.

It is recommended to create the following essential utilities files for creating clients, and organize them within `utils/supabase` at the root of the project.

JavaScriptTypeScript

Create a `client.js` and a `server.js` with the following functionalities for client-side Supabase and server-side Supabase, respectively.

utils/supabase/client.js

utils/supabase/server.js

`
import { createBrowserClient } from '@supabase/ssr'
export function createClient() {
// Create a supabase client on the browser with project's credentials
return createBrowserClient(
    process.env.NEXT_PUBLIC_SUPABASE_URL,
    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY
)
}
`

### Next.js middleware [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs\#nextjs-middleware)

Since Server Components can't write cookies, you need middleware to refresh expired Auth tokens and store them. This is accomplished by:

- Refreshing the Auth token with the call to `supabase.auth.getUser`.
- Passing the refreshed Auth token to Server Components through `request.cookies.set`, so they don't attempt to refresh the same token themselves.
- Passing the refreshed Auth token to the browser, so it replaces the old token. This is done with `response.cookies.set`.

You could also add a matcher, so that the middleware only runs on route that access Supabase. For more information, check out this [documentation](https://nextjs.org/docs/app/building-your-application/routing/middleware#matching-paths).

Be careful when protecting pages. The server gets the user session from the cookies, which can be spoofed by anyone.

Always use `supabase.auth.getUser()` to protect pages and user data.

_Never_ trust `supabase.auth.getSession()` inside server code such as middleware. It isn't guaranteed to revalidate the Auth token.

It's safe to trust `getUser()` because it sends a request to the Supabase Auth server every time to revalidate the Auth token.

JavaScriptTypeScript

Create a `middleware.js` file at the project root and another one within the `utils/supabase` folder. The `utils/supabase` file contains the logic for updating the session. This is used by the `middleware.js` file, which is a Next.js convention.

middleware.js

utils/supabase/middleware.js

`
import { updateSession } from '@/utils/supabase/middleware'
export async function middleware(request) {
// update user's auth session
return await updateSession(request)
}
export const config = {
matcher: [\
    /*\
     * Match all request paths except for the ones starting with:\
     * - _next/static (static files)\
     * - _next/image (image optimization files)\
     * - favicon.ico (favicon file)\
     * Feel free to modify this pattern to include more paths.\
     */\
    '/((?!_next/static|_next/image|favicon.ico|.*\\.(?:svg|png|jpg|jpeg|gif|webp)$).*)',\
],
}
`

## Set up a login page [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs\#set-up-a-login-page)

### Login and signup form [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs\#login-and-signup-form)

Create a login/signup page for your application:

JavaScriptTypeScript

Create a new folder named `login`, containing a `page.jsx` file with a login/signup form.

app/login/page.jsx

`
import { login, signup } from './actions'
export default function LoginPage() {
return (
    <form>
      <label htmlFor="email">Email:</label>
      <input id="email" name="email" type="email" required />
      <label htmlFor="password">Password:</label>
      <input id="password" name="password" type="password" required />
      <button formAction={login}>Log in</button>
      <button formAction={signup}>Sign up</button>
    </form>
)
}
`

Navigate to `http://localhost:3000/login`. You should see your login form, but it's not yet hooked up to the actual login function. Next, you need to create the login/signup actions. They will:

- Retrieve the user's information.
- Send that information to Supabase as a signup request, which in turns will send a confirmation email.
- Handle any error that arises.

Note that cookies is called before any calls to Supabase, which opts fetch calls out of Next.js's caching. This is important for authenticated data fetches, to ensure that users get access only to their own data.

See the Next.js docs to learn more about [opting out of data caching](https://nextjs.org/docs/app/building-your-application/data-fetching/fetching-caching-and-revalidating#opting-out-of-data-caching).

JavaScriptTypeScript

app/login/actions.js

app/error/page.jsx

`
'use server'
import { revalidatePath } from 'next/cache'
import { redirect } from 'next/navigation'
import { createClient } from '@/utils/supabase/server'
export async function login(formData) {
const supabase = await createClient()
// type-casting here for convenience
// in practice, you should validate your inputs
const data = {
    email: formData.get('email'),
    password: formData.get('password'),
}
const { error } = await supabase.auth.signInWithPassword(data)
if (error) {
    redirect('/error')
}
revalidatePath('/', 'layout')
redirect('/account')
}
export async function signup(formData) {
const supabase = await createClient()
const data = {
    email: formData.get('email'),
    password: formData.get('password'),
}
const { error } = await supabase.auth.signUp(data)
if (error) {
    redirect('/error')
}
revalidatePath('/', 'layout')
redirect('/account')
}
`

When you enter your email and password, you will receive an email with the title **Confirm Your Signup**. Congrats !!!

### Email template [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs\#email-template)

Change the email template to support a server-side authentication flow.

Before we proceed, let's change the email template to support sending a token hash:

- Go to the [Auth templates](https://supabase.com/dashboard/project/_/auth/templates) page in your dashboard.
- Select `Confirm signup` template.
- Change `{{ .ConfirmationURL }}` to `{{ .SiteURL }}/auth/confirm?token_hash={{ .TokenHash }}&type=email`.

Did you know? You could also customize emails sent out to new users, including the email's looks, content, and query parameters. Check out the [settings of your project](https://supabase.com/dashboard/project/_/auth/templates).

### Confirmation endpoint [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs\#confirmation-endpoint)

As we are working in a server-side rendering (SSR) environment, it is necessary to create a server endpoint responsible for exchanging the `token_hash` for a session.

In the following code snippet, we perform the following steps:

- Retrieve the code sent back from the Supabase Auth server using the `token_hash` query parameter.
- Exchange this code for a session, which we store in our chosen storage mechanism (in this case, cookies).
- Finally, we redirect the user to the `account` page.

JavaScriptTypeScript

app/auth/confirm/route.js

`
import { type NextRequest, NextResponse } from 'next/server'
import { createClient } from '@/utils/supabase/server'
// Creating a handler to a GET request to route /auth/confirm
export async function GET(request) {
const { searchParams } = new URL(request.url)
const token_hash = searchParams.get('token_hash')
const type = searchParams.get('type')
const next = '/account'
// Create redirect link without the secret token
const redirectTo = request.nextUrl.clone()
redirectTo.pathname = next
redirectTo.searchParams.delete('token_hash')
redirectTo.searchParams.delete('type')
if (token_hash && type) {
    const supabase = await createClient()
    const { error } = await supabase.auth.verifyOtp({
      type,
      token_hash,
    })
    if (!error) {
      redirectTo.searchParams.delete('next')
      return NextResponse.redirect(redirectTo)
    }
}
// return the user to an error page with some instructions
redirectTo.pathname = '/error'
return NextResponse.redirect(redirectTo)
}
`

### Account page [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs\#account-page)

After a user is signed in we can allow them to edit their profile details and manage their account.

Let's create a new component for that called `AccountForm` within the `app/account` folder.

JavaScriptTypeScript

app/account/account-form.jsx

``
'use client'
import { useCallback, useEffect, useState } from 'react'
import { createClient } from '@/utils/supabase/client'
export default function AccountForm({ user }) {
const supabase = createClient()
const [loading, setLoading] = useState(true)
const [fullname, setFullname] = useState(null)
const [username, setUsername] = useState(null)
const [website, setWebsite] = useState(null)
const [avatar_url, setAvatarUrl] = useState(null)
const getProfile = useCallback(async () => {
    try {
      setLoading(true)
      const { data, error, status } = await supabase
        .from('profiles')
        .select(`full_name, username, website, avatar_url`)
        .eq('id', user?.id)
        .single()
      if (error && status !== 406) {
        throw error
      }
      if (data) {
        setFullname(data.full_name)
        setUsername(data.username)
        setWebsite(data.website)
        setAvatarUrl(data.avatar_url)
      }
    } catch (error) {
      alert('Error loading user data!')
    } finally {
      setLoading(false)
    }
}, [user, supabase])
useEffect(() => {
    getProfile()
}, [user, getProfile])
async function updateProfile({ username, website, avatar_url }) {
    try {
      setLoading(true)
      const { error } = await supabase.from('profiles').upsert({
        id: user?.id,
        full_name: fullname,
        username,
        website,
        avatar_url,
        updated_at: new Date().toISOString(),
      })
      if (error) throw error
      alert('Profile updated!')
    } catch (error) {
      alert('Error updating the data!')
    } finally {
      setLoading(false)
    }
}
return (
    <div className="form-widget">
      <div>
        <label htmlFor="email">Email</label>
        <input id="email" type="text" value={user?.email} disabled />
      </div>
      <div>
        <label htmlFor="fullName">Full Name</label>
        <input
          id="fullName"
          type="text"
          value={fullname || ''}
          onChange={(e) => setFullname(e.target.value)}
        />
      </div>
      <div>
        <label htmlFor="username">Username</label>
        <input
          id="username"
          type="text"
          value={username || ''}
          onChange={(e) => setUsername(e.target.value)}
        />
      </div>
      <div>
        <label htmlFor="website">Website</label>
        <input
          id="website"
          type="url"
          value={website || ''}
          onChange={(e) => setWebsite(e.target.value)}
        />
      </div>
      <div>
        <button
          className="button primary block"
          onClick={() => updateProfile({ fullname, username, website, avatar_url })}
          disabled={loading}
        >
          {loading ? 'Loading ...' : 'Update'}
        </button>
      </div>
      <div>
        <form action="/auth/signout" method="post">
          <button className="button block" type="submit">
            Sign out
          </button>
        </form>
      </div>
    </div>
)
}
``

Create an account page for the `AccountForm` component we just created

JavaScriptTypeScript

app/account/page.jsx

`
import AccountForm from './account-form'
import { createClient } from '@/utils/supabase/server'
export default async function Account() {
const supabase = await createClient()
const {
    data: { user },
} = await supabase.auth.getUser()
return <AccountForm user={user} />
}
`

### Sign out [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs\#sign-out)

Let's create a route handler to handle the signout from the server side. Make sure to check if the user is logged in first!

JavaScriptTypeScript

app/auth/signout/route.js

`
import { createClient } from '@/utils/supabase/server'
import { revalidatePath } from 'next/cache'
import { NextResponse } from 'next/server'
export async function POST(req) {
const supabase = await createClient()
// Check if a user's logged in
const {
    data: { user },
} = await supabase.auth.getUser()
if (user) {
    await supabase.auth.signOut()
}
revalidatePath('/', 'layout')
return NextResponse.redirect(new URL('/login', req.url), {
    status: 302,
})
}
`

### Launch! [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs\#launch)

Now that we have all the pages, route handlers and components in place, let's run this in a terminal window:

`
npm run dev
`

And then open the browser to [localhost:3000](http://localhost:3000/) and you should see the completed app.

## Bonus: Profile photos [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs\#bonus-profile-photos)

Every Supabase project is configured with [Storage](https://supabase.com/docs/guides/storage) for managing large files like
photos and videos.

### Create an upload widget [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs\#create-an-upload-widget)

Let's create an avatar widget for the user so that they can upload a profile photo. We can start by creating a new component:

JavaScriptTypeScript

app/account/avatar.jsx

``
'use client'
import React, { useEffect, useState } from 'react'
import { createClient } from '@/utils/supabase/client'
import Image from 'next/image'
export default function Avatar({ uid, url, size, onUpload }) {
const supabase = createClient()
const [avatarUrl, setAvatarUrl] = useState(url)
const [uploading, setUploading] = useState(false)
useEffect(() => {
    async function downloadImage(path) {
      try {
        const { data, error } = await supabase.storage.from('avatars').download(path)
        if (error) {
          throw error
        }
        const url = URL.createObjectURL(data)
        setAvatarUrl(url)
      } catch (error) {
        console.log('Error downloading image: ', error)
      }
    }
    if (url) downloadImage(url)
}, [url, supabase])
const uploadAvatar = async (event) => {
    try {
      setUploading(true)
      if (!event.target.files || event.target.files.length === 0) {
        throw new Error('You must select an image to upload.')
      }
      const file = event.target.files[0]
      const fileExt = file.name.split('.').pop()
      const filePath = `${uid}-${Math.random()}.${fileExt}`
      const { error: uploadError } = await supabase.storage.from('avatars').upload(filePath, file)
      if (uploadError) {
        throw uploadError
      }
      onUpload(filePath)
    } catch (error) {
      alert('Error uploading avatar!')
    } finally {
      setUploading(false)
    }
}
return (
    <div>
      {avatarUrl ? (
        <Image
          width={size}
          height={size}
          src={avatarUrl}
          alt="Avatar"
          className="avatar image"
          style={{ height: size, width: size }}
        />
      ) : (
        <div className="avatar no-image" style={{ height: size, width: size }} />
      )}
      <div style={{ width: size }}>
        <label className="button primary block" htmlFor="single">
          {uploading ? 'Uploading ...' : 'Upload'}
        </label>
        <input
          style={{
            visibility: 'hidden',
            position: 'absolute',
          }}
          type="file"
          id="single"
          accept="image/*"
          onChange={uploadAvatar}
          disabled={uploading}
        />
      </div>
    </div>
)
}
``

### Add the new widget [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs\#add-the-new-widget)

And then we can add the widget to the `AccountForm` component:

JavaScriptTypeScript

app/account/account-form.jsx

`
// Import the new component
import Avatar from './avatar'
// ...
return (
<div className="form-widget">
    {/* Add to the body */}
    <Avatar
      uid={user?.id}
      url={avatar_url}
      size={150}
      onUpload={(url) => {
        setAvatarUrl(url)
        updateProfile({ fullname, username, website, avatar_url: url })
      }}
    />
    {/* ... */}
</div>
)
`

At this stage you have a fully functional application!

## See also [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs\#see-also)

- See the complete [example on GitHub](https://github.com/supabase/supabase/tree/master/examples/user-management/nextjs-user-management) and deploy it to Vercel
- [Build a Twitter Clone with the Next.js App Router and Supabase - free egghead course](https://egghead.io/courses/build-a-twitter-clone-with-the-next-js-app-router-and-supabase-19bebadb)
- Explore the [pre-built Auth UI for React](https://supabase.com/docs/guides/auth/auth-helpers/auth-ui)
- Explore the [Auth Helpers for Next.js](https://supabase.com/docs/guides/auth/auth-helpers/nextjs)
- Explore the [Supabase Cache Helpers](https://github.com/psteinroe/supabase-cache-helpers)
- See the [Next.js Subscription Payments Starter](https://github.com/vercel/nextjs-subscription-payments) template on GitHub

### Is this helpful?

NoYes

### On this page

[Project setup](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs#project-setup) [Create a project](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs#create-a-project) [Set up the database schema](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs#set-up-the-database-schema) [Get the API Keys](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs#get-the-api-keys) [Building the app](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs#building-the-app) [Initialize a Next.js app](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs#initialize-a-nextjs-app) [App styling (optional)](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs#app-styling-optional) [Supabase Server-Side Auth](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs#supabase-server-side-auth) [Supabase utilities](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs#supabase-utilities) [Next.js middleware](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs#nextjs-middleware) [Set up a login page](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs#set-up-a-login-page) [Login and signup form](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs#login-and-signup-form) [Email template](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs#email-template) [Confirmation endpoint](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs#confirmation-endpoint) [Account page](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs#account-page) [Sign out](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs#sign-out) [Launch!](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs#launch) [Bonus: Profile photos](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs#bonus-profile-photos) [Create an upload widget](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs#create-an-upload-widget) [Add the new widget](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs#add-the-new-widget) [See also](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs#see-also)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_tutorials_with_nuxt_3.md">
Getting Started

# Build a User Management App with Nuxt 3

* * *

This tutorial demonstrates how to build a basic user management app. The app authenticates and identifies the user, stores their profile information in the database, and allows the user to log in, update their profile details, and upload a profile photo. The app uses:

- [Supabase Database](https://supabase.com/docs/guides/database) \- a Postgres database for storing your user data and [Row Level Security](https://supabase.com/docs/guides/auth#row-level-security) so data is protected and users can only access their own information.
- [Supabase Auth](https://supabase.com/docs/guides/auth) \- allow users to sign up and log in.
- [Supabase Storage](https://supabase.com/docs/guides/storage) \- users can upload a profile photo.

![Supabase User Management example](https://supabase.com/docs/img/user-management-demo.png)

If you get stuck while working through this guide, refer to the [full example on GitHub](https://github.com/supabase/supabase/tree/master/examples/user-management/nuxt3-user-management).

## Project setup [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nuxt-3\#project-setup)

Before we start building we're going to set up our Database and API. This is as simple as starting a new Project in Supabase and then creating a "schema" inside the database.

### Create a project [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nuxt-3\#create-a-project)

1. [Create a new project](https://supabase.com/dashboard) in the Supabase Dashboard.
2. Enter your project details.
3. Wait for the new database to launch.

### Set up the database schema [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nuxt-3\#set-up-the-database-schema)

Now we are going to set up the database schema. We can use the "User Management Starter" quickstart in the SQL Editor, or you can just copy/paste the SQL from below and run it yourself.

DashboardSQL

1. Go to the [SQL Editor](https://supabase.com/dashboard/project/_/sql) page in the Dashboard.
2. Click **User Management Starter**.
3. Click **Run**.

You can easily pull the database schema down to your local project by running the `db pull` command. Read the [local development docs](https://supabase.com/docs/guides/cli/local-development#link-your-project) for detailed instructions.

`
supabase link --project-ref <project-id>
# You can get <project-id> from your project's dashboard URL: https://supabase.com/dashboard/project/<project-id>
supabase db pull
`

### Get the API Keys [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nuxt-3\#get-the-api-keys)

Now that you've created some database tables, you are ready to insert data using the auto-generated API.
We just need to get the Project URL and `anon` key from the API settings.

1. Go to the [API Settings](https://supabase.com/dashboard/project/_/settings/api) page in the Dashboard.
2. Find your Project `URL`, `anon`, and `service_role` keys on this page.

## Building the app [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nuxt-3\#building-the-app)

Let's start building the Vue 3 app from scratch.

### Initialize a Nuxt 3 app [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nuxt-3\#initialize-a-nuxt-3-app)

We can use [`nuxi init`](https://nuxt.com/docs/getting-started/installation) to create an app called `nuxt-user-management`:

`
npx nuxi init nuxt-user-management
cd nuxt-user-management
`

Then let's install the only additional dependency: [Nuxt Supabase](https://supabase.nuxtjs.org/). We only need to import Nuxt Supabase as a dev dependency.

`
npm install @nuxtjs/supabase --save-dev
`

And finally we want to save the environment variables in a `.env`.
All we need are the API URL and the `anon` key that you copied [earlier](https://supabase.com/docs/guides/getting-started/tutorials/with-nuxt-3#get-the-api-keys).

.env

`
SUPABASE_URL="YOUR_SUPABASE_URL"
SUPABASE_KEY="YOUR_SUPABASE_ANON_KEY"
`

These variables will be exposed on the browser, and that's completely fine since we have [Row Level Security](https://supabase.com/docs/guides/auth#row-level-security) enabled on our Database.
Amazing thing about [Nuxt Supabase](https://supabase.nuxtjs.org/) is that setting environment variables is all we need to do in order to start using Supabase.
No need to initialize Supabase. The library will take care of it automatically.

### App styling (optional) [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nuxt-3\#app-styling-optional)

An optional step is to update the CSS file `assets/main.css` to make the app look nice.
You can find the full contents of this file [here](https://github.com/supabase-community/nuxt3-quickstarter/blob/main/assets/main.css).

nuxt.config.ts

`
import { defineNuxtConfig } from 'nuxt'
// https://v3.nuxtjs.org/api/configuration/nuxt.config
export default defineNuxtConfig({
modules: ['@nuxtjs/supabase'],
css: ['@/assets/main.css'],
})
`

### Set up Auth component [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nuxt-3\#set-up-auth-component)

Let's set up a Vue component to manage logins and sign ups. We'll use Magic Links, so users can sign in with their email without using passwords.

/components/Auth.vue

`
<script setup>
const supabase = useSupabaseClient()
const loading = ref(false)
const email = ref('')
const handleLogin = async () => {
try {
    loading.value = true
    const { error } = await supabase.auth.signInWithOtp({ email: email.value })
    if (error) throw error
    alert('Check your email for the login link!')
} catch (error) {
    alert(error.error_description || error.message)
} finally {
    loading.value = false
}
}
</script>
<template>
<form class="row flex-center flex" @submit.prevent="handleLogin">
    <div class="col-6 form-widget">
      <h1 class="header">Supabase + Nuxt 3</h1>
      <p class="description">Sign in via magic link with your email below</p>
      <div>
        <input class="inputField" type="email" placeholder="Your email" v-model="email" />
      </div>
      <div>
        <input
          type="submit"
          class="button block"
          :value="loading ? 'Loading' : 'Send magic link'"
          :disabled="loading"
        />
      </div>
    </div>
</form>
</template>
`

### User state [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nuxt-3\#user-state)

To access the user information, use the composable [`useSupabaseUser`](https://supabase.nuxtjs.org/usage/composables/usesupabaseuser) provided by the Supabase Nuxt module.

### Account component [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nuxt-3\#account-component)

After a user is signed in we can allow them to edit their profile details and manage their account.
Let's create a new component for that called `Account.vue`.

components/Account.vue

``
<script setup>
const supabase = useSupabaseClient()
const loading = ref(true)
const username = ref('')
const website = ref('')
const avatar_path = ref('')
loading.value = true
const user = useSupabaseUser()
const { data } = await supabase
.from('profiles')
.select(`username, website, avatar_url`)
.eq('id', user.value.id)
.single()
if (data) {
username.value = data.username
website.value = data.website
avatar_path.value = data.avatar_url
}
loading.value = false
async function updateProfile() {
try {
    loading.value = true
    const user = useSupabaseUser()
    const updates = {
      id: user.value.id,
      username: username.value,
      website: website.value,
      avatar_url: avatar_path.value,
      updated_at: new Date(),
    }
    const { error } = await supabase.from('profiles').upsert(updates, {
      returning: 'minimal', // Don't return the value after inserting
    })
    if (error) throw error
} catch (error) {
    alert(error.message)
} finally {
    loading.value = false
}
}
async function signOut() {
try {
    loading.value = true
    const { error } = await supabase.auth.signOut()
    if (error) throw error
    user.value = null
} catch (error) {
    alert(error.message)
} finally {
    loading.value = false
}
}
</script>
<template>
<form class="form-widget" @submit.prevent="updateProfile">
    <div>
      <label for="email">Email</label>
      <input id="email" type="text" :value="user.email" disabled />
    </div>
    <div>
      <label for="username">Username</label>
      <input id="username" type="text" v-model="username" />
    </div>
    <div>
      <label for="website">Website</label>
      <input id="website" type="url" v-model="website" />
    </div>
    <div>
      <input
        type="submit"
        class="button primary block"
        :value="loading ? 'Loading ...' : 'Update'"
        :disabled="loading"
      />
    </div>
    <div>
      <button class="button block" @click="signOut" :disabled="loading">Sign Out</button>
    </div>
</form>
</template>
``

### Launch! [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nuxt-3\#launch)

Now that we have all the components in place, let's update `app.vue`:

app.vue

`
<script setup>
const user = useSupabaseUser()
</script>
<template>
<div class="container" style="padding: 50px 0 100px 0">
    <Account v-if="user" />
    <Auth v-else />
</div>
</template>
`

Once that's done, run this in a terminal window:

`
npm run dev
`

And then open the browser to [localhost:3000](http://localhost:3000/) and you should see the completed app.

![Supabase Nuxt 3](https://supabase.com/docs/img/supabase-vue-3-demo.png)

## Bonus: Profile photos [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nuxt-3\#bonus-profile-photos)

Every Supabase project is configured with [Storage](https://supabase.com/docs/guides/storage) for managing large files like photos and videos.

### Create an upload widget [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nuxt-3\#create-an-upload-widget)

Let's create an avatar for the user so that they can upload a profile photo. We can start by creating a new component:

components/Avatar.vue

``
<script setup>
const props = defineProps(['path'])
const { path } = toRefs(props)
const emit = defineEmits(['update:path', 'upload'])
const supabase = useSupabaseClient()
const uploading = ref(false)
const src = ref('')
const files = ref()
const downloadImage = async () => {
try {
    const { data, error } = await supabase.storage.from('avatars').download(path.value)
    if (error) throw error
    src.value = URL.createObjectURL(data)
} catch (error) {
    console.error('Error downloading image: ', error.message)
}
}
const uploadAvatar = async (evt) => {
files.value = evt.target.files
try {
    uploading.value = true
    if (!files.value || files.value.length === 0) {
      throw new Error('You must select an image to upload.')
    }
    const file = files.value[0]
    const fileExt = file.name.split('.').pop()
    const fileName = `${Math.random()}.${fileExt}`
    const filePath = `${fileName}`
    const { error: uploadError } = await supabase.storage.from('avatars').upload(filePath, file)
    if (uploadError) throw uploadError
    emit('update:path', filePath)
    emit('upload')
} catch (error) {
    alert(error.message)
} finally {
    uploading.value = false
}
}
downloadImage()
watch(path, () => {
if (path.value) {
    downloadImage()
}
})
</script>
<template>
<div>
    <img
      v-if="src"
      :src="src"
      alt="Avatar"
      class="avatar image"
      style="width: 10em; height: 10em;"
    />
    <div v-else class="avatar no-image" :style="{ height: size, width: size }" />
    <div style="width: 10em; position: relative;">
      <label class="button primary block" for="single">
        {{ uploading ? 'Uploading ...' : 'Upload' }}
      </label>
      <input
        style="position: absolute; visibility: hidden;"
        type="file"
        id="single"
        accept="image/*"
        @change="uploadAvatar"
        :disabled="uploading"
      />
    </div>
</div>
</template>
``

### Add the new widget [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-nuxt-3\#add-the-new-widget)

And then we can add the widget to the Account page:

components/Account.vue

``
<script setup>
const supabase = useSupabaseClient()
const loading = ref(true)
const username = ref('')
const website = ref('')
const avatar_path = ref('')
loading.value = true
const user = useSupabaseUser()
const { data } = await supabase
.from('profiles')
.select(`username, website, avatar_url`)
.eq('id', user.value.id)
.single()
if (data) {
username.value = data.username
website.value = data.website
avatar_path.value = data.avatar_url
}
loading.value = false
async function updateProfile() {
try {
    loading.value = true
    const user = useSupabaseUser()
    const updates = {
      id: user.value.id,
      username: username.value,
      website: website.value,
      avatar_url: avatar_path.value,
      updated_at: new Date(),
    }
    const { error } = await supabase.from('profiles').upsert(updates, {
      returning: 'minimal', // Don't return the value after inserting
    })
    if (error) throw error
} catch (error) {
    alert(error.message)
} finally {
    loading.value = false
}
}
async function signOut() {
try {
    loading.value = true
    const { error } = await supabase.auth.signOut()
    if (error) throw error
} catch (error) {
    alert(error.message)
} finally {
    loading.value = false
}
}
</script>
<template>
<form class="form-widget" @submit.prevent="updateProfile">
    <Avatar v-model:path="avatar_path" @upload="updateProfile" />
    <div>
      <label for="email">Email</label>
      <input id="email" type="text" :value="user.email" disabled />
    </div>
    <div>
      <label for="username">Name</label>
      <input id="username" type="text" v-model="username" />
    </div>
    <div>
      <label for="website">Website</label>
      <input id="website" type="url" v-model="website" />
    </div>
    <div>
      <input
        type="submit"
        class="button primary block"
        :value="loading ? 'Loading ...' : 'Update'"
        :disabled="loading"
      />
    </div>
    <div>
      <button class="button block" @click="signOut" :disabled="loading">Sign Out</button>
    </div>
</form>
</template>
``

That is it! You should now be able to upload a profile photo to Supabase Storage and you have a fully functional application.

### Is this helpful?

NoYes

### On this page

[Project setup](https://supabase.com/docs/guides/getting-started/tutorials/with-nuxt-3#project-setup) [Create a project](https://supabase.com/docs/guides/getting-started/tutorials/with-nuxt-3#create-a-project) [Set up the database schema](https://supabase.com/docs/guides/getting-started/tutorials/with-nuxt-3#set-up-the-database-schema) [Get the API Keys](https://supabase.com/docs/guides/getting-started/tutorials/with-nuxt-3#get-the-api-keys) [Building the app](https://supabase.com/docs/guides/getting-started/tutorials/with-nuxt-3#building-the-app) [Initialize a Nuxt 3 app](https://supabase.com/docs/guides/getting-started/tutorials/with-nuxt-3#initialize-a-nuxt-3-app) [App styling (optional)](https://supabase.com/docs/guides/getting-started/tutorials/with-nuxt-3#app-styling-optional) [Set up Auth component](https://supabase.com/docs/guides/getting-started/tutorials/with-nuxt-3#set-up-auth-component) [User state](https://supabase.com/docs/guides/getting-started/tutorials/with-nuxt-3#user-state) [Account component](https://supabase.com/docs/guides/getting-started/tutorials/with-nuxt-3#account-component) [Launch!](https://supabase.com/docs/guides/getting-started/tutorials/with-nuxt-3#launch) [Bonus: Profile photos](https://supabase.com/docs/guides/getting-started/tutorials/with-nuxt-3#bonus-profile-photos) [Create an upload widget](https://supabase.com/docs/guides/getting-started/tutorials/with-nuxt-3#create-an-upload-widget) [Add the new widget](https://supabase.com/docs/guides/getting-started/tutorials/with-nuxt-3#add-the-new-widget)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_tutorials_with_react.md">
Getting Started

# Build a User Management App with React

* * *

This tutorial demonstrates how to build a basic user management app. The app authenticates and identifies the user, stores their profile information in the database, and allows the user to log in, update their profile details, and upload a profile photo. The app uses:

- [Supabase Database](https://supabase.com/docs/guides/database) \- a Postgres database for storing your user data and [Row Level Security](https://supabase.com/docs/guides/auth#row-level-security) so data is protected and users can only access their own information.
- [Supabase Auth](https://supabase.com/docs/guides/auth) \- allow users to sign up and log in.
- [Supabase Storage](https://supabase.com/docs/guides/storage) \- users can upload a profile photo.

![Supabase User Management example](https://supabase.com/docs/img/user-management-demo.png)

If you get stuck while working through this guide, refer to the [full example on GitHub](https://github.com/supabase/supabase/tree/master/examples/user-management/react-user-management).

## Project setup [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-react\#project-setup)

Before we start building we're going to set up our Database and API. This is as simple as starting a new Project in Supabase and then creating a "schema" inside the database.

### Create a project [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-react\#create-a-project)

1. [Create a new project](https://supabase.com/dashboard) in the Supabase Dashboard.
2. Enter your project details.
3. Wait for the new database to launch.

### Set up the database schema [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-react\#set-up-the-database-schema)

Now we are going to set up the database schema. We can use the "User Management Starter" quickstart in the SQL Editor, or you can just copy/paste the SQL from below and run it yourself.

DashboardSQL

1. Go to the [SQL Editor](https://supabase.com/dashboard/project/_/sql) page in the Dashboard.
2. Click **User Management Starter**.
3. Click **Run**.

You can easily pull the database schema down to your local project by running the `db pull` command. Read the [local development docs](https://supabase.com/docs/guides/cli/local-development#link-your-project) for detailed instructions.

`
supabase link --project-ref <project-id>
# You can get <project-id> from your project's dashboard URL: https://supabase.com/dashboard/project/<project-id>
supabase db pull
`

### Get the API Keys [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-react\#get-the-api-keys)

Now that you've created some database tables, you are ready to insert data using the auto-generated API.
We just need to get the Project URL and `anon` key from the API settings.

1. Go to the [API Settings](https://supabase.com/dashboard/project/_/settings/api) page in the Dashboard.
2. Find your Project `URL`, `anon`, and `service_role` keys on this page.

## Building the app [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-react\#building-the-app)

Let's start building the React app from scratch.

### Initialize a React app [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-react\#initialize-a-react-app)

We can use [Vite](https://vitejs.dev/guide/) to initialize
an app called `supabase-react`:

`
npm create vite@latest supabase-react -- --template react
cd supabase-react
`

Then let's install the only additional dependency: [supabase-js](https://github.com/supabase/supabase-js).

`
npm install @supabase/supabase-js
`

And finally we want to save the environment variables in a `.env.local` file.
All we need are the API URL and the `anon` key that you copied [earlier](https://supabase.com/docs/guides/getting-started/tutorials/with-react#get-the-api-keys).

.env

`
VITE_SUPABASE_URL=YOUR_SUPABASE_URL
VITE_SUPABASE_ANON_KEY=YOUR_SUPABASE_ANON_KEY
`

Now that we have the API credentials in place, let's create a helper file to initialize the Supabase client. These variables will be exposed
on the browser, and that's completely fine since we have [Row Level Security](https://supabase.com/docs/guides/auth#row-level-security) enabled on our Database.

Create and edit `src/supabaseClient.js`:

src/supabaseClient.js

`
import { createClient } from '@supabase/supabase-js'
const supabaseUrl = import.meta.env.VITE_SUPABASE_URL
const supabaseAnonKey = import.meta.env.VITE_SUPABASE_ANON_KEY
export const supabase = createClient(supabaseUrl, supabaseAnonKey)
`

### App styling (optional) [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-react\#app-styling-optional)

An optional step is to update the CSS file `src/index.css` to make the app look nice.
You can find the full contents of this file [here](https://raw.githubusercontent.com/supabase/supabase/master/examples/user-management/react-user-management/src/index.css).

### Set up a login component [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-react\#set-up-a-login-component)

Let's set up a React component to manage logins and sign ups. We'll use Magic Links, so users can sign in with their email without using passwords.

Create and edit `src/Auth.jsx`:

src/Auth.jsx

`
import { useState } from 'react'
import { supabase } from './supabaseClient'
export default function Auth() {
const [loading, setLoading] = useState(false)
const [email, setEmail] = useState('')
const handleLogin = async (event) => {
    event.preventDefault()
    setLoading(true)
    const { error } = await supabase.auth.signInWithOtp({ email })
    if (error) {
      alert(error.error_description || error.message)
    } else {
      alert('Check your email for the login link!')
    }
    setLoading(false)
}
return (
    <div className="row flex flex-center">
      <div className="col-6 form-widget">
        <h1 className="header">Supabase + React</h1>
        <p className="description">Sign in via magic link with your email below</p>
        <form className="form-widget" onSubmit={handleLogin}>
          <div>
            <input
              className="inputField"
              type="email"
              placeholder="Your email"
              value={email}
              required={true}
              onChange={(e) => setEmail(e.target.value)}
            />
          </div>
          <div>
            <button className={'button block'} disabled={loading}>
              {loading ? <span>Loading</span> : <span>Send magic link</span>}
            </button>
          </div>
        </form>
      </div>
    </div>
)
}
`

### Account page [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-react\#account-page)

After a user is signed in we can allow them to edit their profile details and manage their account.

Let's create a new component for that called `src/Account.jsx`.

src/Account.jsx

``
import { useState, useEffect } from 'react'
import { supabase } from './supabaseClient'
export default function Account({ session }) {
const [loading, setLoading] = useState(true)
const [username, setUsername] = useState(null)
const [website, setWebsite] = useState(null)
const [avatar_url, setAvatarUrl] = useState(null)
useEffect(() => {
    let ignore = false
    async function getProfile() {
      setLoading(true)
      const { user } = session
      const { data, error } = await supabase
        .from('profiles')
        .select(`username, website, avatar_url`)
        .eq('id', user.id)
        .single()
      if (!ignore) {
        if (error) {
          console.warn(error)
        } else if (data) {
          setUsername(data.username)
          setWebsite(data.website)
          setAvatarUrl(data.avatar_url)
        }
      }
      setLoading(false)
    }
    getProfile()
    return () => {
      ignore = true
    }
}, [session])
async function updateProfile(event, avatarUrl) {
    event.preventDefault()
    setLoading(true)
    const { user } = session
    const updates = {
      id: user.id,
      username,
      website,
      avatar_url: avatarUrl,
      updated_at: new Date(),
    }
    const { error } = await supabase.from('profiles').upsert(updates)
    if (error) {
      alert(error.message)
    } else {
      setAvatarUrl(avatarUrl)
    }
    setLoading(false)
}
return (
    <form onSubmit={updateProfile} className="form-widget">
      <div>
        <label htmlFor="email">Email</label>
        <input id="email" type="text" value={session.user.email} disabled />
      </div>
      <div>
        <label htmlFor="username">Name</label>
        <input
          id="username"
          type="text"
          required
          value={username || ''}
          onChange={(e) => setUsername(e.target.value)}
        />
      </div>
      <div>
        <label htmlFor="website">Website</label>
        <input
          id="website"
          type="url"
          value={website || ''}
          onChange={(e) => setWebsite(e.target.value)}
        />
      </div>
      <div>
        <button className="button block primary" type="submit" disabled={loading}>
          {loading ? 'Loading ...' : 'Update'}
        </button>
      </div>
      <div>
        <button className="button block" type="button" onClick={() => supabase.auth.signOut()}>
          Sign Out
        </button>
      </div>
    </form>
)
}
``

### Launch! [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-react\#launch)

Now that we have all the components in place, let's update `src/App.jsx`:

src/App.jsx

`
import './App.css'
import { useState, useEffect } from 'react'
import { supabase } from './supabaseClient'
import Auth from './Auth'
import Account from './Account'
function App() {
const [session, setSession] = useState(null)
useEffect(() => {
    supabase.auth.getSession().then(({ data: { session } }) => {
      setSession(session)
    })
    supabase.auth.onAuthStateChange((_event, session) => {
      setSession(session)
    })
}, [])
return (
    <div className="container" style={{ padding: '50px 0 100px 0' }}>
      {!session ? <Auth /> : <Account key={session.user.id} session={session} />}
    </div>
)
}
export default App
`

Once that's done, run this in a terminal window:

`
npm run dev
`

And then open the browser to [localhost:5173](http://localhost:5173/) and you should see the completed app.

![Supabase React](https://supabase.com/docs/img/supabase-react-demo.png)

## Bonus: Profile photos [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-react\#bonus-profile-photos)

Every Supabase project is configured with [Storage](https://supabase.com/docs/guides/storage) for managing large files like photos and videos.

### Create an upload widget [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-react\#create-an-upload-widget)

Let's create an avatar for the user so that they can upload a profile photo. We can start by creating a new component:

Create and edit `src/Avatar.jsx`:

src/Avatar.jsx

``
import { useEffect, useState } from 'react'
import { supabase } from './supabaseClient'
export default function Avatar({ url, size, onUpload }) {
const [avatarUrl, setAvatarUrl] = useState(null)
const [uploading, setUploading] = useState(false)
useEffect(() => {
    if (url) downloadImage(url)
}, [url])
async function downloadImage(path) {
    try {
      const { data, error } = await supabase.storage.from('avatars').download(path)
      if (error) {
        throw error
      }
      const url = URL.createObjectURL(data)
      setAvatarUrl(url)
    } catch (error) {
      console.log('Error downloading image: ', error.message)
    }
}
async function uploadAvatar(event) {
    try {
      setUploading(true)
      if (!event.target.files || event.target.files.length === 0) {
        throw new Error('You must select an image to upload.')
      }
      const file = event.target.files[0]
      const fileExt = file.name.split('.').pop()
      const fileName = `${Math.random()}.${fileExt}`
      const filePath = `${fileName}`
      const { error: uploadError } = await supabase.storage.from('avatars').upload(filePath, file)
      if (uploadError) {
        throw uploadError
      }
      onUpload(event, filePath)
    } catch (error) {
      alert(error.message)
    } finally {
      setUploading(false)
    }
}
return (
    <div>
      {avatarUrl ? (
        <img
          src={avatarUrl}
          alt="Avatar"
          className="avatar image"
          style={{ height: size, width: size }}
        />
      ) : (
        <div className="avatar no-image" style={{ height: size, width: size }} />
      )}
      <div style={{ width: size }}>
        <label className="button primary block" htmlFor="single">
          {uploading ? 'Uploading ...' : 'Upload'}
        </label>
        <input
          style={{
            visibility: 'hidden',
            position: 'absolute',
          }}
          type="file"
          id="single"
          accept="image/*"
          onChange={uploadAvatar}
          disabled={uploading}
        />
      </div>
    </div>
)
}
``

### Add the new widget [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-react\#add-the-new-widget)

And then we can add the widget to the Account page at `src/Account.jsx`:

src/Account.jsx

`
// Import the new component
import Avatar from './Avatar'
// ...
return (
<form onSubmit={updateProfile} className="form-widget">
    {/* Add to the body */}
    <Avatar
      url={avatar_url}
      size={150}
      onUpload={(event, url) => {
        updateProfile(event, url)
      }}
    />
    {/* ... */}
</form>
)
`

At this stage you have a fully functional application!

### Is this helpful?

NoYes

### On this page

[Project setup](https://supabase.com/docs/guides/getting-started/tutorials/with-react#project-setup) [Create a project](https://supabase.com/docs/guides/getting-started/tutorials/with-react#create-a-project) [Set up the database schema](https://supabase.com/docs/guides/getting-started/tutorials/with-react#set-up-the-database-schema) [Get the API Keys](https://supabase.com/docs/guides/getting-started/tutorials/with-react#get-the-api-keys) [Building the app](https://supabase.com/docs/guides/getting-started/tutorials/with-react#building-the-app) [Initialize a React app](https://supabase.com/docs/guides/getting-started/tutorials/with-react#initialize-a-react-app) [App styling (optional)](https://supabase.com/docs/guides/getting-started/tutorials/with-react#app-styling-optional) [Set up a login component](https://supabase.com/docs/guides/getting-started/tutorials/with-react#set-up-a-login-component) [Account page](https://supabase.com/docs/guides/getting-started/tutorials/with-react#account-page) [Launch!](https://supabase.com/docs/guides/getting-started/tutorials/with-react#launch) [Bonus: Profile photos](https://supabase.com/docs/guides/getting-started/tutorials/with-react#bonus-profile-photos) [Create an upload widget](https://supabase.com/docs/guides/getting-started/tutorials/with-react#create-an-upload-widget) [Add the new widget](https://supabase.com/docs/guides/getting-started/tutorials/with-react#add-the-new-widget)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_tutorials_with_redwoodjs.md">
Getting Started

# Build a User Management App with RedwoodJS

* * *

This tutorial demonstrates how to build a basic user management app. The app authenticates and identifies the user, stores their profile information in the database, and allows the user to log in, update their profile details, and upload a profile photo. The app uses:

- [Supabase Database](https://supabase.com/docs/guides/database) \- a Postgres database for storing your user data and [Row Level Security](https://supabase.com/docs/guides/auth#row-level-security) so data is protected and users can only access their own information.
- [Supabase Auth](https://supabase.com/docs/guides/auth) \- allow users to sign up and log in.
- [Supabase Storage](https://supabase.com/docs/guides/storage) \- users can upload a profile photo.

![Supabase User Management example](https://supabase.com/docs/img/user-management-demo.png)

If you get stuck while working through this guide, refer to the [full example on GitHub](https://github.com/redwoodjs/redwoodjs-supabase-quickstart).

## About RedwoodJS [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs\#about-redwoodjs)

A Redwood application is split into two parts: a frontend and a backend. This is represented as two node projects within a single monorepo.

The frontend project is called **`web`** and the backend project is called **`api`**. For clarity, we will refer to these in prose as **"sides,"** that is, the `web side` and the `api side`.
They are separate projects because code on the `web side` will end up running in the user's browser while code on the `api side` will run on a server somewhere.

Important: When this guide refers to "API," that means the Supabase API and when it refers to `api side`, that means the RedwoodJS `api side`.

The **`api side`** is an implementation of a GraphQL API. The business logic is organized into "services" that represent their own internal API and can be called both from external GraphQL requests and other internal services.

The **`web side`** is built with React. Redwood's router makes it simple to map URL paths to React "Page" components (and automatically code-split your app on each route).
Pages may contain a "Layout" component to wrap content. They also contain "Cells" and regular React components.
Cells allow you to declaratively manage the lifecycle of a component that fetches and displays data.

For the sake of consistency with the other framework tutorials, we'll build this app a little differently than normal.
We _**won't use**_ Prisma to connect to the Supabase Postgres database or [Prisma migrations](https://redwoodjs.com/docs/cli-commands#prisma-migrate) as one typically might in a Redwood app.
Instead, we'll rely on the Supabase client to do some of the work on the **`web`** side and use the client again on the **`api`** side to do data fetching as well.

That means you will want to refrain from running any `yarn rw prisma migrate` commands and also double check your build commands on deployment to ensure Prisma won't reset your database. Prisma currently doesn't support cross-schema foreign keys, so introspecting the schema fails due
to how your Supabase `public` schema references the `auth.users`.

## Project setup [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs\#project-setup)

Before we start building we're going to set up our Database and API. This is as simple as starting a new Project in Supabase and then creating a "schema" inside the database.

### Create a project [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs\#create-a-project)

1. [Create a new project](https://supabase.com/dashboard) in the Supabase Dashboard.
2. Enter your project details.
3. Wait for the new database to launch.

### Set up the database schema [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs\#set-up-the-database-schema)

Now we are going to set up the database schema. We can use the "User Management Starter" quickstart in the SQL Editor, or you can just copy/paste the SQL from below and run it yourself.

DashboardSQL

1. Go to the [SQL Editor](https://supabase.com/dashboard/project/_/sql) page in the Dashboard.
2. Click **User Management Starter**.
3. Click **Run**.

You can easily pull the database schema down to your local project by running the `db pull` command. Read the [local development docs](https://supabase.com/docs/guides/cli/local-development#link-your-project) for detailed instructions.

`
supabase link --project-ref <project-id>
# You can get <project-id> from your project's dashboard URL: https://supabase.com/dashboard/project/<project-id>
supabase db pull
`

### Get the API Keys [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs\#get-the-api-keys)

Now that you've created some database tables, you are ready to insert data using the auto-generated API.
We just need to get the Project URL and `anon` key from the API settings.

1. Go to the [API Settings](https://supabase.com/dashboard/project/_/settings/api) page in the Dashboard.
2. Find your Project `URL`, `anon`, and `service_role` keys on this page.

## Building the app [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs\#building-the-app)

Let's start building the RedwoodJS app from scratch.

RedwoodJS requires Node.js `>= 14.x <= 16.x` and Yarn `>= 1.15`.

Make sure you have installed yarn since RedwoodJS relies on it to [manage its packages in workspaces](https://classic.yarnpkg.com/lang/en/docs/workspaces/) for its `web` and `api` "sides."

### Initialize a RedwoodJS app [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs\#initialize-a-redwoodjs-app)

We can use [Create Redwood App](https://redwoodjs.com/docs/quick-start) command to initialize
an app called `supabase-redwoodjs`:

`
yarn create redwood-app supabase-redwoodjs
cd supabase-redwoodjs
`

While the app is installing, you should see:

`
 Creating Redwood app
 Checking node and yarn compatibility
 Creating directory 'supabase-redwoodjs'
 Installing packages
 Running 'yarn install'... (This could take a while)
 Convert TypeScript files to JavaScript
 Generating types
Thanks for trying out Redwood!
`

Then let's install the only additional dependency [supabase-js](https://github.com/supabase/supabase-js) by running the `setup auth` command:

`
yarn redwood setup auth supabase
`

When prompted:

> Overwrite existing /api/src/lib/auth.\[jt\]s?

Say, **yes** and it will setup the Supabase client in your app and also provide hooks used with Supabase authentication.

``
 Generating auth lib...
 Successfully wrote file `./api/src/lib/auth.js`
 Adding auth config to web...
 Adding auth config to GraphQL API...
 Adding required web packages...
 Installing packages...
 One more thing...
You will need to add your Supabase URL (SUPABASE_URL), public API KEY,
and JWT SECRET (SUPABASE_KEY, and SUPABASE_JWT_SECRET) to your .env file.
``

Next, we want to save the environment variables in a `.env`.
We need the `API URL` as well as the `anon` and `jwt_secret` keys that you copied [earlier](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs#get-the-api-keys).

.env

`
SUPABASE_URL=YOUR_SUPABASE_URL
SUPABASE_KEY=YOUR_SUPABASE_ANON_KEY
SUPABASE_JWT_SECRET=YOUR_SUPABASE_JWT_SECRET
`

And finally, you will also need to save **just** the `web side` environment variables to the `redwood.toml`.

redwood.toml

`
[web]
title = "Supabase Redwood Tutorial"
port = 8910
apiProxyPath = "/.redwood/functions"
includeEnvironmentVariables = ["SUPABASE_URL", "SUPABASE_KEY"]
[api]
port = 8911
[browser]
open = true
`

These variables will be exposed on the browser, and that's completely fine.
They allow your web app to initialize the Supabase client with your public anon key
since we have [Row Level Security](https://supabase.com/docs/guides/auth#row-level-security) enabled on our Database.

You'll see these being used to configure your Supabase client in `web/src/App.js`:

web/src/App.js

`
// ... Redwood imports
import { AuthProvider } from '@redwoodjs/auth'
import { createClient } from '@supabase/supabase-js'
// ...
const supabase = createClient(process.env.SUPABASE_URL, process.env.SUPABASE_KEY)
const App = () => (
<FatalErrorBoundary page={FatalErrorPage}>
    <RedwoodProvider titleTemplate="%PageTitle | %AppTitle">
      <AuthProvider client={supabase} type="supabase">
        <RedwoodApolloProvider>
          <Routes />
        </RedwoodApolloProvider>
      </AuthProvider>
    </RedwoodProvider>
</FatalErrorBoundary>
)
export default App
`

### App styling (optional) [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs\#app-styling-optional)

An optional step is to update the CSS file `web/src/index.css` to make the app look nice.
You can find the full contents of this file [here](https://raw.githubusercontent.com/supabase/supabase/master/examples/user-management/react-user-management/src/index.css).

### Start RedwoodJS and your first page [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs\#start-redwoodjs-and-your-first-page)

Let's test our setup at the moment by starting up the app:

`
yarn rw dev
`

`rw` is an alias for `redwood`, as in `yarn rw` to run Redwood CLI commands.

You should see a "Welcome to RedwoodJS" page and a message about not having any pages yet.

So, let's create a "home" page:

``
yarn rw generate page home /
 Generating page files...
 Successfully wrote file `./web/src/pages/HomePage/HomePage.stories.js`
 Successfully wrote file `./web/src/pages/HomePage/HomePage.test.js`
 Successfully wrote file `./web/src/pages/HomePage/HomePage.js`
 Updating routes file...
 Generating types ...
``

The `/` is important here as it creates a root level route.

You can stop the `dev` server if you want; to see your changes, just be sure to run `yarn rw dev` again.

You should see the `Home` page route in `web/src/Routes.js`:

web/src/Routes.js

`
import { Router, Route } from '@redwoodjs/router'
const Routes = () => {
return (
    <Router>
      <Route path="/" page={HomePage} name="home" />
      <Route notfound page={NotFoundPage} />
    </Router>
)
}
export default Routes
`

### Set up a login component [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs\#set-up-a-login-component)

Let's set up a Redwood component to manage logins and sign ups. We'll use Magic Links, so users can sign in with their email without using passwords.

``
yarn rw g component auth
 Generating component files...
     Successfully wrote file `./web/src/components/Auth/Auth.test.js`
     Successfully wrote file `./web/src/components/Auth/Auth.stories.js`
     Successfully wrote file `./web/src/components/Auth/Auth.js`
``

Now, update the `Auth.js` component to contain:

/web/src/components/Auth/Auth.js

`
import { useState } from 'react'
import { useAuth } from '@redwoodjs/auth'
const Auth = () => {
const { logIn } = useAuth()
const [loading, setLoading] = useState(false)
const [email, setEmail] = useState('')
const handleLogin = async (email) => {
    try {
      setLoading(true)
      const { error } = await logIn({ email })
      if (error) throw error
      alert('Check your email for the login link!')
    } catch (error) {
      alert(error.error_description || error.message)
    } finally {
      setLoading(false)
    }
}
return (
    <div className="row flex-center flex">
      <div className="col-6 form-widget">
        <h1 className="header">Supabase + RedwoodJS</h1>
        <p className="description">Sign in via magic link with your email below</p>
        <div>
          <input
            className="inputField"
            type="email"
            placeholder="Your email"
            value={email}
            onChange={(e) => setEmail(e.target.value)}
          />
        </div>
        <div>
          <button
            onClick={(e) => {
              e.preventDefault()
              handleLogin(email)
            }}
            className={'button block'}
            disabled={loading}
          >
            {loading ? <span>Loading</span> : <span>Send magic link</span>}
          </button>
        </div>
      </div>
    </div>
)
}
export default Auth
`

### Set up an account component [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs\#set-up-an-account-component)

After a user is signed in we can allow them to edit their profile details and manage their account.

Let's create a new component for that called `Account.js`.

``
yarn rw g component account
 Generating component files...
     Successfully wrote file `./web/src/components/Account/Account.test.js`
     Successfully wrote file `./web/src/components/Account/Account.stories.js`
     Successfully wrote file `./web/src/components/Account/Account.js`
``

And then update the file to contain:

web/src/components/Account/Account.js

``
import { useState, useEffect } from 'react'
import { useAuth } from '@redwoodjs/auth'
const Account = () => {
const { client: supabase, currentUser, logOut } = useAuth()
const [loading, setLoading] = useState(true)
const [username, setUsername] = useState(null)
const [website, setWebsite] = useState(null)
const [avatar_url, setAvatarUrl] = useState(null)
useEffect(() => {
    getProfile()
}, [supabase.auth.session])
async function getProfile() {
    try {
      setLoading(true)
      const user = supabase.auth.user()
      const { data, error, status } = await supabase
        .from('profiles')
        .select(`username, website, avatar_url`)
        .eq('id', user.id)
        .single()
      if (error && status !== 406) {
        throw error
      }
      if (data) {
        setUsername(data.username)
        setWebsite(data.website)
        setAvatarUrl(data.avatar_url)
      }
    } catch (error) {
      alert(error.message)
    } finally {
      setLoading(false)
    }
}
async function updateProfile({ username, website, avatar_url }) {
    try {
      setLoading(true)
      const user = supabase.auth.user()
      const updates = {
        id: user.id,
        username,
        website,
        avatar_url,
        updated_at: new Date(),
      }
      const { error } = await supabase.from('profiles').upsert(updates, {
        returning: 'minimal', // Don't return the value after inserting
      })
      if (error) {
        throw error
      }
      alert('Updated profile!')
    } catch (error) {
      alert(error.message)
    } finally {
      setLoading(false)
    }
}
return (
    <div className="row flex-center flex">
      <div className="col-6 form-widget">
        <h1 className="header">Supabase + RedwoodJS</h1>
        <p className="description">Your profile</p>
        <div className="form-widget">
          <div>
            <label htmlFor="email">Email</label>
            <input id="email" type="text" value={currentUser.email} disabled />
          </div>
          <div>
            <label htmlFor="username">Name</label>
            <input
              id="username"
              type="text"
              value={username || ''}
              onChange={(e) => setUsername(e.target.value)}
            />
          </div>
          <div>
            <label htmlFor="website">Website</label>
            <input
              id="website"
              type="url"
              value={website || ''}
              onChange={(e) => setWebsite(e.target.value)}
            />
          </div>
          <div>
            <button
              className="button primary block"
              onClick={() => updateProfile({ username, website, avatar_url })}
              disabled={loading}
            >
              {loading ? 'Loading ...' : 'Update'}
            </button>
          </div>
          <div>
            <button className="button block" onClick={() => logOut()}>
              Sign Out
            </button>
          </div>
        </div>
      </div>
    </div>
)
}
export default Account
``

You'll see the use of `useAuth()` several times. Redwood's `useAuth` hook provides convenient ways to access
`logIn`, `logOut`, `currentUser`, and access the `supabase` authenticate client. We'll use it to get an instance
of the Supabase client to interact with your API.

### Update home page [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs\#update-home-page)

Now that we have all the components in place, let's update your `HomePage` page to use them:

web/src/pages/HomePage/HomePage.js

`
import { useAuth } from '@redwoodjs/auth'
import { MetaTags } from '@redwoodjs/web'
import Account from 'src/components/Account'
import Auth from 'src/components/Auth'
const HomePage = () => {
const { isAuthenticated } = useAuth()
return (
    <>
      <MetaTags title="Welcome" />
      {!isAuthenticated ? <Auth /> : <Account />}
    </>
)
}
export default HomePage
`

What we're doing here is showing the sign in form if you aren't logged in and your account profile if you are.

### Launch! [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs\#launch)

Once that's done, run this in a terminal window to launch the `dev` server:

`
yarn rw dev
`

And then open the browser to [localhost:8910](http://localhost:8910/) and you should see the completed app.

![Supabase RedwoodJS](https://supabase.com/docs/img/supabase-redwoodjs-demo.png)

## Bonus: Profile photos [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs\#bonus-profile-photos)

Every Supabase project is configured with [Storage](https://supabase.com/docs/guides/storage) for managing large files like photos and videos.

### Create an upload widget [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs\#create-an-upload-widget)

Let's create an avatar for the user so that they can upload a profile photo. We can start by creating a new component:

``
yarn rw g component avatar
 Generating component files...
     Successfully wrote file `./web/src/components/Avatar/Avatar.test.js`
     Successfully wrote file `./web/src/components/Avatar/Avatar.stories.js`
     Successfully wrote file `./web/src/components/Avatar/Avatar.js`
``

Now, update your Avatar component to contain the following widget:

web/src/components/Avatar/Avatar.js

``
import { useEffect, useState } from 'react'
import { useAuth } from '@redwoodjs/auth'
const Avatar = ({ url, size, onUpload }) => {
const { client: supabase } = useAuth()
const [avatarUrl, setAvatarUrl] = useState(null)
const [uploading, setUploading] = useState(false)
useEffect(() => {
    if (url) downloadImage(url)
}, [url])
async function downloadImage(path) {
    try {
      const { data, error } = await supabase.storage.from('avatars').download(path)
      if (error) {
        throw error
      }
      const url = URL.createObjectURL(data)
      setAvatarUrl(url)
    } catch (error) {
      console.log('Error downloading image: ', error.message)
    }
}
async function uploadAvatar(event) {
    try {
      setUploading(true)
      if (!event.target.files || event.target.files.length === 0) {
        throw new Error('You must select an image to upload.')
      }
      const file = event.target.files[0]
      const fileExt = file.name.split('.').pop()
      const fileName = `${Math.random()}.${fileExt}`
      const filePath = `${fileName}`
      const { error: uploadError } = await supabase.storage.from('avatars').upload(filePath, file)
      if (uploadError) {
        throw uploadError
      }
      onUpload(filePath)
    } catch (error) {
      alert(error.message)
    } finally {
      setUploading(false)
    }
}
return (
    <div>
      {avatarUrl ? (
        <img
          src={avatarUrl}
          alt="Avatar"
          className="avatar image"
          style={{ height: size, width: size }}
        />
      ) : (
        <div className="avatar no-image" style={{ height: size, width: size }} />
      )}
      <div style={{ width: size }}>
        <label className="button primary block" htmlFor="single">
          {uploading ? 'Uploading ...' : 'Upload'}
        </label>
        <input
          style={{
            visibility: 'hidden',
            position: 'absolute',
          }}
          type="file"
          id="single"
          accept="image/*"
          onChange={uploadAvatar}
          disabled={uploading}
        />
      </div>
    </div>
)
}
export default Avatar
``

### Add the new widget [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs\#add-the-new-widget)

And then we can add the widget to the Account component:

web/src/components/Account/Account.js

`
// Import the new component
import Avatar from 'src/components/Avatar'
// ...
return (
<div className="form-widget">
    {/* Add to the body */}
    <Avatar
      url={avatar_url}
      size={150}
      onUpload={(url) => {
        setAvatarUrl(url)
        updateProfile({ username, website, avatar_url: url })
      }}
    />
    {/* ... */}
</div>
)
`

At this stage you have a fully functional application!

## See also [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs\#see-also)

- Learn more about [RedwoodJS](https://redwoodjs.com/)
- Visit the [RedwoodJS Discourse Community](https://community.redwoodjs.com/)

### Is this helpful?

NoYes

### On this page

[About RedwoodJS](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs#about-redwoodjs) [Project setup](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs#project-setup) [Create a project](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs#create-a-project) [Set up the database schema](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs#set-up-the-database-schema) [Get the API Keys](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs#get-the-api-keys) [Building the app](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs#building-the-app) [Initialize a RedwoodJS app](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs#initialize-a-redwoodjs-app) [App styling (optional)](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs#app-styling-optional) [Start RedwoodJS and your first page](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs#start-redwoodjs-and-your-first-page) [Set up a login component](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs#set-up-a-login-component) [Set up an account component](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs#set-up-an-account-component) [Update home page](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs#update-home-page) [Launch!](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs#launch) [Bonus: Profile photos](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs#bonus-profile-photos) [Create an upload widget](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs#create-an-upload-widget) [Add the new widget](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs#add-the-new-widget) [See also](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs#see-also)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_tutorials_with_refine.md">
Getting Started

# Build a User Management App with refine

* * *

This tutorial demonstrates how to build a basic user management app. The app authenticates and identifies the user, stores their profile information in the database, and allows the user to log in, update their profile details, and upload a profile photo. The app uses:

- [Supabase Database](https://supabase.com/docs/guides/database) \- a Postgres database for storing your user data and [Row Level Security](https://supabase.com/docs/guides/auth#row-level-security) so data is protected and users can only access their own information.
- [Supabase Auth](https://supabase.com/docs/guides/auth) \- allow users to sign up and log in.
- [Supabase Storage](https://supabase.com/docs/guides/storage) \- users can upload a profile photo.

![Supabase User Management example](https://supabase.com/docs/img/user-management-demo.png)

If you get stuck while working through this guide, refer to the [full example on GitHub](https://github.com/supabase/supabase/tree/master/examples/user-management/refine-user-management).

## About refine [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-refine\#about-refine)

[refine](https://github.com/refinedev/refine) is a React-based framework used to rapidly build data-heavy applications like admin panels, dashboards, storefronts and any type of CRUD apps. It separates app concerns into individual layers, each backed by a React context and respective provider object. For example, the auth layer represents a context served by a specific set of [`authProvider`](https://refine.dev/docs/tutorial/understanding-authprovider/index/) methods that carry out authentication and authorization actions such as logging in, logging out, getting roles data, etc. Similarly, the data layer offers another level of abstraction that is equipped with [`dataProvider`](https://refine.dev/docs/tutorial/understanding-dataprovider/index/) methods to handle CRUD operations at appropriate backend API endpoints.

refine provides hassle-free integration with Supabase backend with its supplementary [`@refinedev/supabase`](https://github.com/refinedev/refine/tree/master/packages/supabase) package. It generates `authProvider` and `dataProvider` methods at project initialization, so we don't need to expend much effort to define them ourselves. We just need to choose Supabase as our backend service while creating the app with `create refine-app`.

It is possible to customize the `authProvider` for Supabase and as we'll see below, it can be tweaked from `src/authProvider.ts` file. In contrast, the Supabase `dataProvider` is part of `node_modules` and therefore is not subject to modification.

## Project setup [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-refine\#project-setup)

Before we start building we're going to set up our Database and API. This is as simple as starting a new Project in Supabase and then creating a "schema" inside the database.

### Create a project [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-refine\#create-a-project)

1. [Create a new project](https://supabase.com/dashboard) in the Supabase Dashboard.
2. Enter your project details.
3. Wait for the new database to launch.

### Set up the database schema [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-refine\#set-up-the-database-schema)

Now we are going to set up the database schema. We can use the "User Management Starter" quickstart in the SQL Editor, or you can just copy/paste the SQL from below and run it yourself.

DashboardSQL

1. Go to the [SQL Editor](https://supabase.com/dashboard/project/_/sql) page in the Dashboard.
2. Click **User Management Starter**.
3. Click **Run**.

You can easily pull the database schema down to your local project by running the `db pull` command. Read the [local development docs](https://supabase.com/docs/guides/cli/local-development#link-your-project) for detailed instructions.

`
supabase link --project-ref <project-id>
# You can get <project-id> from your project's dashboard URL: https://supabase.com/dashboard/project/<project-id>
supabase db pull
`

### Get the API Keys [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-refine\#get-the-api-keys)

Now that you've created some database tables, you are ready to insert data using the auto-generated API.
We just need to get the Project URL and `anon` key from the API settings.

1. Go to the [API Settings](https://supabase.com/dashboard/project/_/settings/api) page in the Dashboard.
2. Find your Project `URL`, `anon`, and `service_role` keys on this page.

## Building the app [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-refine\#building-the-app)

Let's start building the refine app from scratch.

### Initialize a refine app [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-refine\#initialize-a-refine-app)

We can use [create refine-app](https://refine.dev/docs/tutorial/getting-started/headless/create-project/#launch-the-refine-cli-setup) command to initialize
an app. Run the following in the terminal:

`
npm create refine-app@latest -- --preset refine-supabase
`

In the above command, we are using the `refine-supabase` preset which chooses the Supabase supplementary package for our app. We are not using any UI framework, so we'll have a headless UI with plain React and CSS styling.

The `refine-supabase` preset installs the `@refinedev/supabase` package which out-of-the-box includes the Supabase dependency: [supabase-js](https://github.com/supabase/supabase-js).

We also need to install `@refinedev/react-hook-form` and `react-hook-form` packages that allow us to use [React Hook Form](https://react-hook-form.com/) inside refine apps. Run:

`
npm install @refinedev/react-hook-form react-hook-form
`

With the app initialized and packages installed, at this point before we begin discussing refine concepts, let's try running the app:

`
cd app-name
npm run dev
`

We should have a running instance of the app with a Welcome page at `http://localhost:5173`.

Let's move ahead to understand the generated code now.

### Refine `supabaseClient` [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-refine\#refine-supabaseclient)

The `create refine-app` generated a Supabase client for us in the `src/utility/supabaseClient.ts` file. It has two constants: `SUPABASE_URL` and `SUPABASE_KEY`. We want to replace them as `supabaseUrl` and `supabaseAnonKey` respectively and assign them our own Supabase server's values.

We'll update it with environment variables managed by Vite:

src/utility/supabaseClient.ts

`
import { createClient } from '@refinedev/supabase'
const supabaseUrl = import.meta.env.VITE_SUPABASE_URL
const supabaseAnonKey = import.meta.env.VITE_SUPABASE_ANON_KEY
export const supabaseClient = createClient(supabaseUrl, supabaseAnonKey, {
db: {
    schema: 'public',
},
auth: {
    persistSession: true,
},
})
`

And then, we want to save the environment variables in a `.env.local` file. All you need are the API URL and the `anon` key that you copied [earlier](https://supabase.com/docs/guides/getting-started/tutorials/with-refine#get-the-api-keys).

.env.local

`
VITE_SUPABASE_URL=YOUR_SUPABASE_URL
VITE_SUPABASE_ANON_KEY=YOUR_SUPABASE_ANON_KEY
`

The `supabaseClient` will be used in fetch calls to Supabase endpoints from our app. As we'll see below, the client is instrumental in implementing authentication using Refine's auth provider methods and CRUD actions with appropriate data provider methods.

One optional step is to update the CSS file `src/App.css` to make the app look nice.
You can find the full contents of this file [here](https://raw.githubusercontent.com/supabase/supabase/master/examples/user-management/refine-user-management/src/App.css).

In order for us to add login and user profile pages in this App, we have to tweak the `<Refine />` component inside `App.tsx`.

### The `<Refine />` component [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-refine\#the-refine--component)

The `App.tsx` file initially looks like this:

src/App.tsx

`
import { Refine, WelcomePage } from '@refinedev/core'
import { RefineKbar, RefineKbarProvider } from '@refinedev/kbar'
import routerBindings, {
DocumentTitleHandler,
UnsavedChangesNotifier,
} from '@refinedev/react-router-v6'
import { dataProvider, liveProvider } from '@refinedev/supabase'
import { BrowserRouter, Route, Routes } from 'react-router-dom'
import './App.css'
import authProvider from './authProvider'
import { supabaseClient } from './utility'
function App() {
return (
    <BrowserRouter>
      <RefineKbarProvider>
        <Refine
          dataProvider={dataProvider(supabaseClient)}
          liveProvider={liveProvider(supabaseClient)}
          authProvider={authProvider}
          routerProvider={routerBindings}
          options={{
            syncWithLocation: true,
            warnWhenUnsavedChanges: true,
          }}
        >
          <Routes>
            <Route index element={<WelcomePage />} />
          </Routes>
          <RefineKbar />
          <UnsavedChangesNotifier />
          <DocumentTitleHandler />
        </Refine>
      </RefineKbarProvider>
    </BrowserRouter>
)
}
export default App
`

We'd like to focus on the [`<Refine />`](https://refine.dev/docs/api-reference/core/components/refine-config/) component, which comes with several props passed to it. Notice the `dataProvider` prop. It uses a `dataProvider()` function with `supabaseClient` passed as argument to generate the data provider object. The `authProvider` object also uses `supabaseClient` in implementing its methods. You can look it up in `src/authProvider.ts` file.

## Customize `authProvider` [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-refine\#customize-authprovider)

If you examine the `authProvider` object you can notice that it has a `login` method that implements a OAuth and Email / Password strategy for authentication. We'll, however, remove them and use Magic Links to allow users sign in with their email without using passwords.

We want to use `supabaseClient` auth's `signInWithOtp` method inside `authProvider.login` method:

`
login: async ({ email }) => {
try {
    const { error } = await supabaseClient.auth.signInWithOtp({ email });
    if (!error) {
      alert("Check your email for the login link!");
      return {
        success: true,
      };
    };
    throw error;
} catch (e: any) {
    alert(e.message);
    return {
      success: false,
      e,
    };
}
},
`

We also want to remove `register`, `updatePassword`, `forgotPassword` and `getPermissions` properties, which are optional type members and also not necessary for our app. The final `authProvider` object looks like this:

src/authProvider.ts

`
import { AuthBindings } from '@refinedev/core'
import { supabaseClient } from './utility'
const authProvider: AuthBindings = {
login: async ({ email }) => {
    try {
      const { error } = await supabaseClient.auth.signInWithOtp({ email })
      if (!error) {
        alert('Check your email for the login link!')
        return {
          success: true,
        }
      }
      throw error
    } catch (e: any) {
      alert(e.message)
      return {
        success: false,
        e,
      }
    }
},
logout: async () => {
    const { error } = await supabaseClient.auth.signOut()
    if (error) {
      return {
        success: false,
        error,
      }
    }
    return {
      success: true,
      redirectTo: '/',
    }
},
onError: async (error) => {
    console.error(error)
    return { error }
},
check: async () => {
    try {
      const { data } = await supabaseClient.auth.getSession()
      const { session } = data
      if (!session) {
        return {
          authenticated: false,
          error: {
            message: 'Check failed',
            name: 'Session not found',
          },
          logout: true,
          redirectTo: '/login',
        }
      }
    } catch (error: any) {
      return {
        authenticated: false,
        error: error || {
          message: 'Check failed',
          name: 'Not authenticated',
        },
        logout: true,
        redirectTo: '/login',
      }
    }
    return {
      authenticated: true,
    }
},
getIdentity: async () => {
    const { data } = await supabaseClient.auth.getUser()
    if (data?.user) {
      return {
        ...data.user,
        name: data.user.email,
      }
    }
    return null
},
}
export default authProvider
`

### Set up a login component [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-refine\#set-up-a-login-component)

We have chosen to use the headless refine core package that comes with no supported UI framework. So, let's set up a plain React component to manage logins and sign ups.

Create and edit `src/components/auth.tsx`:

src/components/auth.tsx

`
import { useState } from 'react'
import { useLogin } from '@refinedev/core'
export default function Auth() {
const [email, setEmail] = useState('')
const { isLoading, mutate: login } = useLogin()
const handleLogin = async (event: { preventDefault: () => void }) => {
    event.preventDefault()
    login({ email })
}
return (
    <div className="row flex flex-center container">
      <div className="col-6 form-widget">
        <h1 className="header">Supabase + refine</h1>
        <p className="description">Sign in via magic link with your email below</p>
        <form className="form-widget" onSubmit={handleLogin}>
          <div>
            <input
              className="inputField"
              type="email"
              placeholder="Your email"
              value={email}
              required={true}
              onChange={(e) => setEmail(e.target.value)}
            />
          </div>
          <div>
            <button className={'button block'} disabled={isLoading}>
              {isLoading ? <span>Loading</span> : <span>Send magic link</span>}
            </button>
          </div>
        </form>
      </div>
    </div>
)
}
`

Notice we are using the [`useLogin()`](https://refine.dev/docs/api-reference/core/hooks/authentication/useLogin/) refine auth hook to grab the `mutate: login` method to use inside `handleLogin()` function and `isLoading` state for our form submission. The `useLogin()` hook conveniently offers us access to `authProvider.login` method for authenticating the user with OTP.

### Account page [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-refine\#account-page)

After a user is signed in we can allow them to edit their profile details and manage their account.

Let's create a new component for that in `src/components/account.tsx`.

src/components/account.tsx

`
import { BaseKey, useGetIdentity, useLogout } from '@refinedev/core'
import { useForm } from '@refinedev/react-hook-form'
interface IUserIdentity {
id?: BaseKey
username: string
name: string
}
export interface IProfile {
id?: string
username?: string
website?: string
avatar_url?: string
}
export default function Account() {
const { data: userIdentity } = useGetIdentity<IUserIdentity>()
const { mutate: logOut } = useLogout()
const {
    refineCore: { formLoading, queryResult, onFinish },
    register,
    control,
    handleSubmit,
} = useForm<IProfile>({
    refineCoreProps: {
      resource: 'profiles',
      action: 'edit',
      id: userIdentity?.id,
      redirect: false,
      onMutationError: (data) => alert(data?.message),
    },
})
return (
    <div className="container" style={{ padding: '50px 0 100px 0' }}>
      <form onSubmit={handleSubmit(onFinish)} className="form-widget">
        <div>
          <label htmlFor="email">Email</label>
          <input id="email" name="email" type="text" value={userIdentity?.name} disabled />
        </div>
        <div>
          <label htmlFor="username">Name</label>
          <input id="username" type="text" {...register('username')} />
        </div>
        <div>
          <label htmlFor="website">Website</label>
          <input id="website" type="url" {...register('website')} />
        </div>
        <div>
          <button className="button block primary" type="submit" disabled={formLoading}>
            {formLoading ? 'Loading ...' : 'Update'}
          </button>
        </div>
        <div>
          <button className="button block" type="button" onClick={() => logOut()}>
            Sign Out
          </button>
        </div>
      </form>
    </div>
)
}
`

Notice above that, we are using three refine hooks, namely the [`useGetIdentity()`](https://refine.dev/docs/api-reference/core/hooks/authentication/useGetIdentity/), [`useLogOut()`](https://refine.dev/docs/api-reference/core/hooks/authentication/useLogout/) and [`useForm()`](https://refine.dev/docs/packages/documentation/react-hook-form/useForm/) hooks.

`useGetIdentity()` is a auth hook that gets the identity of the authenticated user. It grabs the current user by invoking the `authProvider.getIdentity` method under the hood.

`useLogOut()` is also an auth hook. It calls the `authProvider.logout` method to end the session.

`useForm()`, in contrast, is a data hook that exposes a series of useful objects that serve the edit form. For example, we are grabbing the `onFinish` function to submit the form with the `handleSubmit` event handler. We are also using `formLoading` property to present state changes of the submitted form.

The `useForm()` hook is a higher-level hook built on top of Refine's `useForm()` core hook. It fully supports form state management, field validation and submission using React Hook Form. Behind the scenes, it invokes the `dataProvider.getOne` method to get the user profile data from our Supabase `/profiles` endpoint and also invokes `dataProvider.update` method when `onFinish()` is called.

### Launch! [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-refine\#launch)

Now that we have all the components in place, let's define the routes for the pages in which they should be rendered.

Add the routes for `/login` with the `<Auth />` component and the routes for `index` path with the `<Account />` component. So, the final `App.tsx`:

src/App.tsx

`
import { Authenticated, Refine } from '@refinedev/core'
import { RefineKbar, RefineKbarProvider } from '@refinedev/kbar'
import routerBindings, {
CatchAllNavigate,
DocumentTitleHandler,
UnsavedChangesNotifier,
} from '@refinedev/react-router-v6'
import { dataProvider, liveProvider } from '@refinedev/supabase'
import { BrowserRouter, Outlet, Route, Routes } from 'react-router-dom'
import './App.css'
import authProvider from './authProvider'
import { supabaseClient } from './utility'
import Account from './components/account'
import Auth from './components/auth'
function App() {
return (
    <BrowserRouter>
      <RefineKbarProvider>
        <Refine
          dataProvider={dataProvider(supabaseClient)}
          liveProvider={liveProvider(supabaseClient)}
          authProvider={authProvider}
          routerProvider={routerBindings}
          options={{
            syncWithLocation: true,
            warnWhenUnsavedChanges: true,
          }}
        >
          <Routes>
            <Route
              element={
                <Authenticated fallback={<CatchAllNavigate to="/login" />}>
                  <Outlet />
                </Authenticated>
              }
            >
              <Route index element={<Account />} />
            </Route>
            <Route element={<Authenticated fallback={<Outlet />} />}>
              <Route path="/login" element={<Auth />} />
            </Route>
          </Routes>
          <RefineKbar />
          <UnsavedChangesNotifier />
          <DocumentTitleHandler />
        </Refine>
      </RefineKbarProvider>
    </BrowserRouter>
)
}
export default App
`

Let's test the App by running the server again:

`
npm run dev
`

And then open the browser to [localhost:5173](http://localhost:5173/) and you should see the completed app.

![Supabase refine](https://supabase.com/docs/img/supabase-refine-demo.png)

## Bonus: Profile photos [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-refine\#bonus-profile-photos)

Every Supabase project is configured with [Storage](https://supabase.com/docs/guides/storage) for managing large files like photos and videos.

### Create an upload widget [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-refine\#create-an-upload-widget)

Let's create an avatar for the user so that they can upload a profile photo. We can start by creating a new component:

Create and edit `src/components/avatar.tsx`:

src/components/avatar.tsx

``
import { useEffect, useState } from 'react'
import { supabaseClient } from '../utility/supabaseClient'
type TAvatarProps = {
url?: string
size: number
onUpload: (filePath: string) => void
}
export default function Avatar({ url, size, onUpload }: TAvatarProps) {
const [avatarUrl, setAvatarUrl] = useState('')
const [uploading, setUploading] = useState(false)
useEffect(() => {
    if (url) downloadImage(url)
}, [url])
async function downloadImage(path: string) {
    try {
      const { data, error } = await supabaseClient.storage.from('avatars').download(path)
      if (error) {
        throw error
      }
      const url = URL.createObjectURL(data)
      setAvatarUrl(url)
    } catch (error: any) {
      console.log('Error downloading image: ', error?.message)
    }
}
async function uploadAvatar(event: React.ChangeEvent<HTMLInputElement>) {
    try {
      setUploading(true)
      if (!event.target.files || event.target.files.length === 0) {
        throw new Error('You must select an image to upload.')
      }
      const file = event.target.files[0]
      const fileExt = file.name.split('.').pop()
      const fileName = `${Math.random()}.${fileExt}`
      const filePath = `${fileName}`
      const { error: uploadError } = await supabaseClient.storage
        .from('avatars')
        .upload(filePath, file)
      if (uploadError) {
        throw uploadError
      }
      onUpload(filePath)
    } catch (error: any) {
      alert(error.message)
    } finally {
      setUploading(false)
    }
}
return (
    <div>
      {avatarUrl ? (
        <img
          src={avatarUrl}
          alt="Avatar"
          className="avatar image"
          style={{ height: size, width: size }}
        />
      ) : (
        <div className="avatar no-image" style={{ height: size, width: size }} />
      )}
      <div style={{ width: size }}>
        <label className="button primary block" htmlFor="single">
          {uploading ? 'Uploading ...' : 'Upload'}
        </label>
        <input
          style={{
            visibility: 'hidden',
            position: 'absolute',
          }}
          type="file"
          id="single"
          name="avatar_url"
          accept="image/*"
          onChange={uploadAvatar}
          disabled={uploading}
        />
      </div>
    </div>
)
}
``

### Add the new widget [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-refine\#add-the-new-widget)

And then we can add the widget to the Account page at `src/components/account.tsx`:

src/components/account.tsx

`
// Import the new components
import { Controller } from 'react-hook-form'
import Avatar from './avatar'
// ...
return (
<div className="container" style={{ padding: '50px 0 100px 0' }}>
    <form onSubmit={handleSubmit} className="form-widget">
      <Controller
        control={control}
        name="avatar_url"
        render={({ field }) => {
          return (
            <Avatar
              url={field.value}
              size={150}
              onUpload={(filePath) => {
                onFinish({
                  ...queryResult?.data?.data,
                  avatar_url: filePath,
                  onMutationError: (data: { message: string }) => alert(data?.message),
                })
                field.onChange({
                  target: {
                    value: filePath,
                  },
                })
              }}
            />
          )
        }}
      />
      {/* ... */}
    </form>
</div>
)
`

At this stage, you have a fully functional application!

### Is this helpful?

NoYes

### On this page

[About refine](https://supabase.com/docs/guides/getting-started/tutorials/with-refine#about-refine) [Project setup](https://supabase.com/docs/guides/getting-started/tutorials/with-refine#project-setup) [Create a project](https://supabase.com/docs/guides/getting-started/tutorials/with-refine#create-a-project) [Set up the database schema](https://supabase.com/docs/guides/getting-started/tutorials/with-refine#set-up-the-database-schema) [Get the API Keys](https://supabase.com/docs/guides/getting-started/tutorials/with-refine#get-the-api-keys) [Building the app](https://supabase.com/docs/guides/getting-started/tutorials/with-refine#building-the-app) [Initialize a refine app](https://supabase.com/docs/guides/getting-started/tutorials/with-refine#initialize-a-refine-app) [Refine supabaseClient](https://supabase.com/docs/guides/getting-started/tutorials/with-refine#refine-supabaseclient) [The <Refine /> component](https://supabase.com/docs/guides/getting-started/tutorials/with-refine#the-refine--component) [Customize authProvider](https://supabase.com/docs/guides/getting-started/tutorials/with-refine#customize-authprovider) [Set up a login component](https://supabase.com/docs/guides/getting-started/tutorials/with-refine#set-up-a-login-component) [Account page](https://supabase.com/docs/guides/getting-started/tutorials/with-refine#account-page) [Launch!](https://supabase.com/docs/guides/getting-started/tutorials/with-refine#launch) [Bonus: Profile photos](https://supabase.com/docs/guides/getting-started/tutorials/with-refine#bonus-profile-photos) [Create an upload widget](https://supabase.com/docs/guides/getting-started/tutorials/with-refine#create-an-upload-widget) [Add the new widget](https://supabase.com/docs/guides/getting-started/tutorials/with-refine#add-the-new-widget)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_tutorials_with_solidjs.md">
Getting Started

# Build a User Management App with SolidJS

* * *

This tutorial demonstrates how to build a basic user management app. The app authenticates and identifies the user, stores their profile information in the database, and allows the user to log in, update their profile details, and upload a profile photo. The app uses:

- [Supabase Database](https://supabase.com/docs/guides/database) \- a Postgres database for storing your user data and [Row Level Security](https://supabase.com/docs/guides/auth#row-level-security) so data is protected and users can only access their own information.
- [Supabase Auth](https://supabase.com/docs/guides/auth) \- allow users to sign up and log in.
- [Supabase Storage](https://supabase.com/docs/guides/storage) \- users can upload a profile photo.

![Supabase User Management example](https://supabase.com/docs/img/user-management-demo.png)

If you get stuck while working through this guide, refer to the [full example on GitHub](https://github.com/supabase/supabase/tree/master/examples/user-management/solid-user-management).

## Project setup [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-solidjs\#project-setup)

Before we start building we're going to set up our Database and API. This is as simple as starting a new Project in Supabase and then creating a "schema" inside the database.

### Create a project [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-solidjs\#create-a-project)

1. [Create a new project](https://supabase.com/dashboard) in the Supabase Dashboard.
2. Enter your project details.
3. Wait for the new database to launch.

### Set up the database schema [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-solidjs\#set-up-the-database-schema)

Now we are going to set up the database schema. We can use the "User Management Starter" quickstart in the SQL Editor, or you can just copy/paste the SQL from below and run it yourself.

DashboardSQL

1. Go to the [SQL Editor](https://supabase.com/dashboard/project/_/sql) page in the Dashboard.
2. Click **User Management Starter**.
3. Click **Run**.

You can easily pull the database schema down to your local project by running the `db pull` command. Read the [local development docs](https://supabase.com/docs/guides/cli/local-development#link-your-project) for detailed instructions.

`
supabase link --project-ref <project-id>
# You can get <project-id> from your project's dashboard URL: https://supabase.com/dashboard/project/<project-id>
supabase db pull
`

### Get the API Keys [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-solidjs\#get-the-api-keys)

Now that you've created some database tables, you are ready to insert data using the auto-generated API.
We just need to get the Project URL and `anon` key from the API settings.

1. Go to the [API Settings](https://supabase.com/dashboard/project/_/settings/api) page in the Dashboard.
2. Find your Project `URL`, `anon`, and `service_role` keys on this page.

## Building the app [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-solidjs\#building-the-app)

Let's start building the SolidJS app from scratch.

### Initialize a SolidJS app [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-solidjs\#initialize-a-solidjs-app)

We can use [degit](https://github.com/Rich-Harris/degit) to initialize an app called `supabase-solid`:

`
npx degit solidjs/templates/ts supabase-solid
cd supabase-solid
`

Then let's install the only additional dependency: [supabase-js](https://github.com/supabase/supabase-js)

`
npm install @supabase/supabase-js
`

And finally we want to save the environment variables in a `.env`.
All we need are the API URL and the `anon` key that you copied [earlier](https://supabase.com/docs/guides/getting-started/tutorials/with-solidjs#get-the-api-keys).

.env

`
VITE_SUPABASE_URL=YOUR_SUPABASE_URL
VITE_SUPABASE_ANON_KEY=YOUR_SUPABASE_ANON_KEY
`

Now that we have the API credentials in place, let's create a helper file to initialize the Supabase client. These variables will be exposed
on the browser, and that's completely fine since we have [Row Level Security](https://supabase.com/docs/guides/auth#row-level-security) enabled on our Database.

src/supabaseClient.tsx

`
import { createClient } from '@supabase/supabase-js'
const supabaseUrl = import.meta.env.VITE_SUPABASE_URL
const supabaseAnonKey = import.meta.env.VITE_SUPABASE_ANON_KEY
export const supabase = createClient(supabaseUrl, supabaseAnonKey)
`

### App styling (optional) [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-solidjs\#app-styling-optional)

An optional step is to update the CSS file `src/index.css` to make the app look nice.
You can find the full contents of this file [here](https://raw.githubusercontent.com/supabase/supabase/master/examples/user-management/solid-user-management/src/index.css).

### Set up a login component [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-solidjs\#set-up-a-login-component)

Let's set up a SolidJS component to manage logins and sign ups. We'll use Magic Links, so users can sign in with their email without using passwords.

src/Auth.tsx

`
import { createSignal } from 'solid-js'
import { supabase } from './supabaseClient'
export default function Auth() {
const [loading, setLoading] = createSignal(false)
const [email, setEmail] = createSignal('')
const handleLogin = async (e: SubmitEvent) => {
    e.preventDefault()
    try {
      setLoading(true)
      const { error } = await supabase.auth.signInWithOtp({ email: email() })
      if (error) throw error
      alert('Check your email for the login link!')
    } catch (error) {
      if (error instanceof Error) {
        alert(error.message)
      }
    } finally {
      setLoading(false)
    }
}
return (
    <div class="row flex-center flex">
      <div class="col-6 form-widget" aria-live="polite">
        <h1 class="header">Supabase + SolidJS</h1>
        <p class="description">Sign in via magic link with your email below</p>
        <form class="form-widget" onSubmit={handleLogin}>
          <div>
            <label for="email">Email</label>
            <input
              id="email"
              class="inputField"
              type="email"
              placeholder="Your email"
              value={email()}
              onChange={(e) => setEmail(e.currentTarget.value)}
            />
          </div>
          <div>
            <button type="submit" class="button block" aria-live="polite">
              {loading() ? <span>Loading</span> : <span>Send magic link</span>}
            </button>
          </div>
        </form>
      </div>
    </div>
)
}
`

### Account page [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-solidjs\#account-page)

After a user is signed in we can allow them to edit their profile details and manage their account.

Let's create a new component for that called `Account.tsx`.

src/Account.tsx

``
import { AuthSession } from '@supabase/supabase-js'
import { Component, createEffect, createSignal } from 'solid-js'
import { supabase } from './supabaseClient'
interface Props {
session: AuthSession
}
const Account: Component<Props> = ({ session }) => {
const [loading, setLoading] = createSignal(true)
const [username, setUsername] = createSignal<string | null>(null)
const [website, setWebsite] = createSignal<string | null>(null)
const [avatarUrl, setAvatarUrl] = createSignal<string | null>(null)
createEffect(() => {
    getProfile()
})
const getProfile = async () => {
    try {
      setLoading(true)
      const { user } = session
      const { data, error, status } = await supabase
        .from('profiles')
        .select(`username, website, avatar_url`)
        .eq('id', user.id)
        .single()
      if (error && status !== 406) {
        throw error
      }
      if (data) {
        setUsername(data.username)
        setWebsite(data.website)
        setAvatarUrl(data.avatar_url)
      }
    } catch (error) {
      if (error instanceof Error) {
        alert(error.message)
      }
    } finally {
      setLoading(false)
    }
}
const updateProfile = async (e: Event) => {
    e.preventDefault()
    try {
      setLoading(true)
      const { user } = session
      const updates = {
        id: user.id,
        username: username(),
        website: website(),
        avatar_url: avatarUrl(),
        updated_at: new Date().toISOString(),
      }
      const { error } = await supabase.from('profiles').upsert(updates)
      if (error) {
        throw error
      }
    } catch (error) {
      if (error instanceof Error) {
        alert(error.message)
      }
    } finally {
      setLoading(false)
    }
}
return (
    <div aria-live="polite">
      <form onSubmit={updateProfile} class="form-widget">
        <div>Email: {session.user.email}</div>
        <div>
          <label for="username">Name</label>
          <input
            id="username"
            type="text"
            value={username() || ''}
            onChange={(e) => setUsername(e.currentTarget.value)}
          />
        </div>
        <div>
          <label for="website">Website</label>
          <input
            id="website"
            type="text"
            value={website() || ''}
            onChange={(e) => setWebsite(e.currentTarget.value)}
          />
        </div>
        <div>
          <button type="submit" class="button primary block" disabled={loading()}>
            {loading() ? 'Saving ...' : 'Update profile'}
          </button>
        </div>
        <button type="button" class="button block" onClick={() => supabase.auth.signOut()}>
          Sign Out
        </button>
      </form>
    </div>
)
}
export default Account
``

### Launch! [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-solidjs\#launch)

Now that we have all the components in place, let's update `App.tsx`:

src/App.tsx

`
import { Component, createEffect, createSignal } from 'solid-js'
import { supabase } from './supabaseClient'
import { AuthSession } from '@supabase/supabase-js'
import Account from './Account'
import Auth from './Auth'
const App: Component = () => {
const [session, setSession] = createSignal<AuthSession | null>(null)
createEffect(() => {
    supabase.auth.getSession().then(({ data: { session } }) => {
      setSession(session)
    })
    supabase.auth.onAuthStateChange((_event, session) => {
      setSession(session)
    })
})
return (
    <div class="container" style={{ padding: '50px 0 100px 0' }}>
      {!session() ? <Auth /> : <Account session={session()!} />}
    </div>
)
}
export default App
`

Once that's done, run this in a terminal window:

`
npm start
`

And then open the browser to [localhost:3000](http://localhost:3000/) and you should see the completed app.

![Supabase SolidJS](https://supabase.com/docs/img/supabase-solidjs-demo.png)

## Bonus: Profile photos [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-solidjs\#bonus-profile-photos)

Every Supabase project is configured with [Storage](https://supabase.com/docs/guides/storage) for managing large files like photos and videos.

### Create an upload widget [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-solidjs\#create-an-upload-widget)

Let's create an avatar for the user so that they can upload a profile photo. We can start by creating a new component:

src/Avatar.tsx

``
import { Component, createEffect, createSignal, JSX } from 'solid-js'
import { supabase } from './supabaseClient'
interface Props {
size: number
url: string | null
onUpload: (event: Event, filePath: string) => void
}
const Avatar: Component<Props> = (props) => {
const [avatarUrl, setAvatarUrl] = createSignal<string | null>(null)
const [uploading, setUploading] = createSignal(false)
createEffect(() => {
    if (props.url) downloadImage(props.url)
})
const downloadImage = async (path: string) => {
    try {
      const { data, error } = await supabase.storage.from('avatars').download(path)
      if (error) {
        throw error
      }
      const url = URL.createObjectURL(data)
      setAvatarUrl(url)
    } catch (error) {
      if (error instanceof Error) {
        console.log('Error downloading image: ', error.message)
      }
    }
}
const uploadAvatar: JSX.EventHandler<HTMLInputElement, Event> = async (event) => {
    try {
      setUploading(true)
      const target = event.currentTarget
      if (!target?.files || target.files.length === 0) {
        throw new Error('You must select an image to upload.')
      }
      const file = target.files[0]
      const fileExt = file.name.split('.').pop()
      const fileName = `${Math.random()}.${fileExt}`
      const filePath = `${fileName}`
      const { error: uploadError } = await supabase.storage.from('avatars').upload(filePath, file)
      if (uploadError) {
        throw uploadError
      }
      props.onUpload(event, filePath)
    } catch (error) {
      if (error instanceof Error) {
        alert(error.message)
      }
    } finally {
      setUploading(false)
    }
}
return (
    <div style={{ width: `${props.size}px` }} aria-live="polite">
      {avatarUrl() ? (
        <img
          src={avatarUrl()!}
          alt={avatarUrl() ? 'Avatar' : 'No image'}
          class="avatar image"
          style={{ height: `${props.size}px`, width: `${props.size}px` }}
        />
      ) : (
        <div
          class="avatar no-image"
          style={{ height: `${props.size}px`, width: `${props.size}px` }}
        />
      )}
      <div style={{ width: `${props.size}px` }}>
        <label class="button primary block" for="single">
          {uploading() ? 'Uploading ...' : 'Upload avatar'}
        </label>
        <span style="display:none">
          <input
            type="file"
            id="single"
            accept="image/*"
            onChange={uploadAvatar}
            disabled={uploading()}
          />
        </span>
      </div>
    </div>
)
}
export default Avatar
``

### Add the new widget [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-solidjs\#add-the-new-widget)

And then we can add the widget to the Account page:

src/Account.tsx

`
// Import the new component
import Avatar from './Avatar'
// ...
return (
<form onSubmit={updateProfile} class="form-widget">
    {/* Add to the body */}
    <Avatar
      url={avatarUrl()}
      size={150}
      onUpload={(e: Event, url: string) => {
        setAvatarUrl(url)
        updateProfile(e)
      }}
    />
    {/* ... */}
</div>
)
`

At this stage you have a fully functional application!

### Is this helpful?

NoYes

### On this page

[Project setup](https://supabase.com/docs/guides/getting-started/tutorials/with-solidjs#project-setup) [Create a project](https://supabase.com/docs/guides/getting-started/tutorials/with-solidjs#create-a-project) [Set up the database schema](https://supabase.com/docs/guides/getting-started/tutorials/with-solidjs#set-up-the-database-schema) [Get the API Keys](https://supabase.com/docs/guides/getting-started/tutorials/with-solidjs#get-the-api-keys) [Building the app](https://supabase.com/docs/guides/getting-started/tutorials/with-solidjs#building-the-app) [Initialize a SolidJS app](https://supabase.com/docs/guides/getting-started/tutorials/with-solidjs#initialize-a-solidjs-app) [App styling (optional)](https://supabase.com/docs/guides/getting-started/tutorials/with-solidjs#app-styling-optional) [Set up a login component](https://supabase.com/docs/guides/getting-started/tutorials/with-solidjs#set-up-a-login-component) [Account page](https://supabase.com/docs/guides/getting-started/tutorials/with-solidjs#account-page) [Launch!](https://supabase.com/docs/guides/getting-started/tutorials/with-solidjs#launch) [Bonus: Profile photos](https://supabase.com/docs/guides/getting-started/tutorials/with-solidjs#bonus-profile-photos) [Create an upload widget](https://supabase.com/docs/guides/getting-started/tutorials/with-solidjs#create-an-upload-widget) [Add the new widget](https://supabase.com/docs/guides/getting-started/tutorials/with-solidjs#add-the-new-widget)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_tutorials_with_svelte.md">
Getting Started

# Build a User Management App with Svelte

* * *

This tutorial demonstrates how to build a basic user management app. The app authenticates and identifies the user, stores their profile information in the database, and allows the user to log in, update their profile details, and upload a profile photo. The app uses:

- [Supabase Database](https://supabase.com/docs/guides/database) \- a Postgres database for storing your user data and [Row Level Security](https://supabase.com/docs/guides/auth#row-level-security) so data is protected and users can only access their own information.
- [Supabase Auth](https://supabase.com/docs/guides/auth) \- allow users to sign up and log in.
- [Supabase Storage](https://supabase.com/docs/guides/storage) \- users can upload a profile photo.

![Supabase User Management example](https://supabase.com/docs/img/user-management-demo.png)

If you get stuck while working through this guide, refer to the [full example on GitHub](https://github.com/supabase/supabase/tree/master/examples/user-management/svelte-user-management).

## Project setup [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-svelte\#project-setup)

Before we start building we're going to set up our Database and API. This is as simple as starting a new Project in Supabase and then creating a "schema" inside the database.

### Create a project [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-svelte\#create-a-project)

1. [Create a new project](https://supabase.com/dashboard) in the Supabase Dashboard.
2. Enter your project details.
3. Wait for the new database to launch.

### Set up the database schema [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-svelte\#set-up-the-database-schema)

Now we are going to set up the database schema. We can use the "User Management Starter" quickstart in the SQL Editor, or you can just copy/paste the SQL from below and run it yourself.

DashboardSQL

1. Go to the [SQL Editor](https://supabase.com/dashboard/project/_/sql) page in the Dashboard.
2. Click **User Management Starter**.
3. Click **Run**.

You can easily pull the database schema down to your local project by running the `db pull` command. Read the [local development docs](https://supabase.com/docs/guides/cli/local-development#link-your-project) for detailed instructions.

`
supabase link --project-ref <project-id>
# You can get <project-id> from your project's dashboard URL: https://supabase.com/dashboard/project/<project-id>
supabase db pull
`

### Get the API Keys [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-svelte\#get-the-api-keys)

Now that you've created some database tables, you are ready to insert data using the auto-generated API.
We just need to get the Project URL and `anon` key from the API settings.

1. Go to the [API Settings](https://supabase.com/dashboard/project/_/settings/api) page in the Dashboard.
2. Find your Project `URL`, `anon`, and `service_role` keys on this page.

## Building the app [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-svelte\#building-the-app)

Let's start building the Svelte app from scratch.

### Initialize a Svelte app [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-svelte\#initialize-a-svelte-app)

We can use the Vite Svelte TypeScript Template to initialize an app called `supabase-svelte`:

`
npm create vite@latest supabase-svelte -- --template svelte-ts
cd supabase-svelte
npm install
`

Then let's install the only additional dependency: [supabase-js](https://github.com/supabase/supabase-js)

`
npm install @supabase/supabase-js
`

And finally we want to save the environment variables in a `.env`.
All we need are the API URL and the `anon` key that you copied [earlier](https://supabase.com/docs/guides/getting-started/tutorials/with-svelte#get-the-api-keys).

.env

`
VITE_SUPABASE_URL=YOUR_SUPABASE_URL
VITE_SUPABASE_ANON_KEY=YOUR_SUPABASE_ANON_KEY
`

Now that we have the API credentials in place, let's create a helper file to initialize the Supabase client. These variables will be exposed
on the browser, and that's completely fine since we have [Row Level Security](https://supabase.com/docs/guides/auth#row-level-security) enabled on our Database.

src/supabaseClient.ts

`
import { createClient } from '@supabase/supabase-js'
const supabaseUrl = import.meta.env.VITE_SUPABASE_URL
const supabaseAnonKey = import.meta.env.VITE_SUPABASE_ANON_KEY
export const supabase = createClient(supabaseUrl, supabaseAnonKey)
`

### App styling (optional) [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-svelte\#app-styling-optional)

An optional step is to update the CSS file `src/app.css` to make the app look nice.
You can find the full contents of this file [here](https://raw.githubusercontent.com/supabase/supabase/master/examples/user-management/svelte-user-management/src/app.css).

### Set up a login component [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-svelte\#set-up-a-login-component)

Let's set up a Svelte component to manage logins and sign ups. We'll use Magic Links, so users can sign in with their email without using passwords.

src/lib/Auth.svelte

`
<script lang="ts">
import { supabase } from '../supabaseClient'
let loading = false
let email = ''
const handleLogin = async () => {
    try {
      loading = true
      const { error } = await supabase.auth.signInWithOtp({ email })
      if (error) throw error
      alert('Check your email for login link!')
    } catch (error) {
      if (error instanceof Error) {
        alert(error.message)
      }
    } finally {
      loading = false
    }
}
</script>
<div class="row flex-center flex">
<div class="col-6 form-widget" aria-live="polite">
    <h1 class="header">Supabase + Svelte</h1>
    <p class="description">Sign in via magic link with your email below</p>
    <form class="form-widget" on:submit|preventDefault="{handleLogin}">
      <div>
        <label for="email">Email</label>
        <input
          id="email"
          class="inputField"
          type="email"
          placeholder="Your email"
          bind:value="{email}"
        />
      </div>
      <div>
        <button type="submit" class="button block" aria-live="polite" disabled="{loading}">
          <span>{loading ? 'Loading' : 'Send magic link'}</span>
        </button>
      </div>
    </form>
</div>
</div>
`

### Account page [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-svelte\#account-page)

After a user is signed in we can allow them to edit their profile details and manage their account.
Let's create a new component for that called `Account.svelte`.

src/lib/Account.svelte

`
<script lang="ts">
import { onMount } from 'svelte'
import type { AuthSession } from '@supabase/supabase-js'
import { supabase } from '../supabaseClient'
export let session: AuthSession
let loading = false
let username: string | null = null
let website: string | null = null
let avatarUrl: string | null = null
onMount(() => {
    getProfile()
})
const getProfile = async () => {
    try {
      loading = true
      const { user } = session
      const { data, error, status } = await supabase
        .from('profiles')
        .select('username, website, avatar_url')
        .eq('id', user.id)
        .single()
      if (error && status !== 406) throw error
      if (data) {
        username = data.username
        website = data.website
        avatarUrl = data.avatar_url
      }
    } catch (error) {
      if (error instanceof Error) {
        alert(error.message)
      }
    } finally {
      loading = false
    }
}
const updateProfile = async () => {
    try {
      loading = true
      const { user } = session
      const updates = {
        id: user.id,
        username,
        website,
        avatar_url: avatarUrl,
        updated_at: new Date().toISOString(),
      }
      const { error } = await supabase.from('profiles').upsert(updates)
      if (error) {
        throw error
      }
    } catch (error) {
      if (error instanceof Error) {
        alert(error.message)
      }
    } finally {
      loading = false
    }
}
</script>
<form on:submit|preventDefault="{updateProfile}" class="form-widget">
<div>Email: {session.user.email}</div>
<div>
    <label for="username">Name</label>
    <input id="username" type="text" bind:value="{username}" />
</div>
<div>
    <label for="website">Website</label>
    <input id="website" type="text" bind:value="{website}" />
</div>
<div>
    <button type="submit" class="button primary block" disabled="{loading}">
      {loading ? 'Saving ...' : 'Update profile'}
    </button>
</div>
<button type="button" class="button block" on:click={() => supabase.auth.signOut()}> Sign Out
</button>
</form>
`

### Launch! [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-svelte\#launch)

Now that we have all the components in place, let's update `App.svelte`:

src/App.svelte

`
<script lang="ts">
import { onMount } from 'svelte'
import { supabase } from './supabaseClient'
import type { AuthSession } from '@supabase/supabase-js'
import Account from './lib/Account.svelte'
import Auth from './lib/Auth.svelte'
let session: AuthSession | null
onMount(() => {
    supabase.auth.getSession().then(({ data }) => {
      session = data.session
    })
    supabase.auth.onAuthStateChange((_event, _session) => {
      session = _session
    })
})
</script>
<div class="container" style="padding: 50px 0 100px 0">
{#if !session}
<Auth />
{:else}
<Account {session} />
{/if}
</div>
`

Once that's done, run this in a terminal window:

`
npm run dev
`

And then open the browser to [localhost:5173](http://localhost:5173/) and you should see the completed app.

Svelte uses Vite and the default port is `5173`, Supabase uses `port 3000`. To change the redirection port for Supabase go to: `Authentication > Settings` and change the `Site Url` to `http://localhost:5173/`

![Supabase Svelte](https://supabase.com/docs/img/supabase-svelte-demo.png)

## Bonus: Profile photos [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-svelte\#bonus-profile-photos)

Every Supabase project is configured with [Storage](https://supabase.com/docs/guides/storage) for managing large files like photos and videos.

### Create an upload widget [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-svelte\#create-an-upload-widget)

Let's create an avatar for the user so that they can upload a profile photo. We can start by creating a new component:

src/lib/Avatar.svelte

``
<script lang="ts">
import { createEventDispatcher } from 'svelte'
import { supabase } from '../supabaseClient'
export let size: number
export let url: string | null = null
let avatarUrl: string | null = null
let uploading = false
let files: FileList
const dispatch = createEventDispatcher()
const downloadImage = async (path: string) => {
    try {
      const { data, error } = await supabase.storage.from('avatars').download(path)
      if (error) {
        throw error
      }
      const url = URL.createObjectURL(data)
      avatarUrl = url
    } catch (error) {
      if (error instanceof Error) {
        console.log('Error downloading image: ', error.message)
      }
    }
}
const uploadAvatar = async () => {
    try {
      uploading = true
      if (!files || files.length === 0) {
        throw new Error('You must select an image to upload.')
      }
      const file = files[0]
      const fileExt = file.name.split('.').pop()
      const filePath = `${Math.random()}.${fileExt}`
      const { error } = await supabase.storage.from('avatars').upload(filePath, file)
      if (error) {
        throw error
      }
      url = filePath
      dispatch('upload')
    } catch (error) {
      if (error instanceof Error) {
        alert(error.message)
      }
    } finally {
      uploading = false
    }
}
$: if (url) downloadImage(url)
</script>
<div style="width: {size}px" aria-live="polite">
{#if avatarUrl} <img src={avatarUrl} alt={avatarUrl ? 'Avatar' : 'No image'} class="avatar image"
style="height: {size}px, width: {size}px" /> {:else}
<div class="avatar no-image" style="height: {size}px, width: {size}px" />
{/if}
<div style="width: {size}px">
    <label class="button primary block" for="single">
      {uploading ? 'Uploading ...' : 'Upload avatar'}
    </label>
    <span style="display:none">
      <input
        type="file"
        id="single"
        accept="image/*"
        bind:files
        on:change={uploadAvatar}
        disabled={uploading}
      />
    </span>
</div>
</div>
``

### Add the new widget [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-svelte\#add-the-new-widget)

And then we can add the widget to the Account page:

src/lib/Account.svelte

`
<script lang="ts">
// Import the new component
import Avatar from './Avatar.svelte'
</script>
<form on:submit|preventDefault="{updateProfile}" class="form-widget">
<!-- Add to body -->
<Avatar bind:url="{avatarUrl}" size="{150}" on:upload="{updateProfile}" />
<!-- Other form elements -->
</form>
`

At this stage you have a fully functional application!

### Is this helpful?

NoYes

### On this page

[Project setup](https://supabase.com/docs/guides/getting-started/tutorials/with-svelte#project-setup) [Create a project](https://supabase.com/docs/guides/getting-started/tutorials/with-svelte#create-a-project) [Set up the database schema](https://supabase.com/docs/guides/getting-started/tutorials/with-svelte#set-up-the-database-schema) [Get the API Keys](https://supabase.com/docs/guides/getting-started/tutorials/with-svelte#get-the-api-keys) [Building the app](https://supabase.com/docs/guides/getting-started/tutorials/with-svelte#building-the-app) [Initialize a Svelte app](https://supabase.com/docs/guides/getting-started/tutorials/with-svelte#initialize-a-svelte-app) [App styling (optional)](https://supabase.com/docs/guides/getting-started/tutorials/with-svelte#app-styling-optional) [Set up a login component](https://supabase.com/docs/guides/getting-started/tutorials/with-svelte#set-up-a-login-component) [Account page](https://supabase.com/docs/guides/getting-started/tutorials/with-svelte#account-page) [Launch!](https://supabase.com/docs/guides/getting-started/tutorials/with-svelte#launch) [Bonus: Profile photos](https://supabase.com/docs/guides/getting-started/tutorials/with-svelte#bonus-profile-photos) [Create an upload widget](https://supabase.com/docs/guides/getting-started/tutorials/with-svelte#create-an-upload-widget) [Add the new widget](https://supabase.com/docs/guides/getting-started/tutorials/with-svelte#add-the-new-widget)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_tutorials_with_sveltekit.md">
Getting Started

# Build a User Management App with SvelteKit

* * *

This tutorial demonstrates how to build a basic user management app. The app authenticates and identifies the user, stores their profile information in the database, and allows the user to log in, update their profile details, and upload a profile photo. The app uses:

- [Supabase Database](https://supabase.com/docs/guides/database) \- a Postgres database for storing your user data and [Row Level Security](https://supabase.com/docs/guides/auth#row-level-security) so data is protected and users can only access their own information.
- [Supabase Auth](https://supabase.com/docs/guides/auth) \- allow users to sign up and log in.
- [Supabase Storage](https://supabase.com/docs/guides/storage) \- users can upload a profile photo.

![Supabase User Management example](https://supabase.com/docs/img/user-management-demo.png)

If you get stuck while working through this guide, refer to the [full example on GitHub](https://github.com/supabase/supabase/tree/master/examples/user-management/sveltekit-user-management).

## Project setup [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit\#project-setup)

Before we start building we're going to set up our Database and API. This is as simple as starting a new Project in Supabase and then creating a "schema" inside the database.

### Create a project [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit\#create-a-project)

1. [Create a new project](https://supabase.com/dashboard) in the Supabase Dashboard.
2. Enter your project details.
3. Wait for the new database to launch.

### Set up the database schema [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit\#set-up-the-database-schema)

Now we are going to set up the database schema. We can use the "User Management Starter" quickstart in the SQL Editor, or you can just copy/paste the SQL from below and run it yourself.

DashboardSQL

1. Go to the [SQL Editor](https://supabase.com/dashboard/project/_/sql) page in the Dashboard.
2. Click **User Management Starter**.
3. Click **Run**.

You can easily pull the database schema down to your local project by running the `db pull` command. Read the [local development docs](https://supabase.com/docs/guides/cli/local-development#link-your-project) for detailed instructions.

`
supabase link --project-ref <project-id>
# You can get <project-id> from your project's dashboard URL: https://supabase.com/dashboard/project/<project-id>
supabase db pull
`

### Get the API Keys [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit\#get-the-api-keys)

Now that you've created some database tables, you are ready to insert data using the auto-generated API.
We just need to get the Project URL and `anon` key from the API settings.

1. Go to the [API Settings](https://supabase.com/dashboard/project/_/settings/api) page in the Dashboard.
2. Find your Project `URL`, `anon`, and `service_role` keys on this page.

## Building the app [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit\#building-the-app)

Let's start building the Svelte app from scratch.

### Initialize a Svelte app [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit\#initialize-a-svelte-app)

We can use the [SvelteKit Skeleton Project](https://kit.svelte.dev/docs) to initialize an app called `supabase-sveltekit` (for this tutorial we will be using TypeScript):

`
npm create svelte@latest supabase-sveltekit
cd supabase-sveltekit
npm install
`

Then install the Supabase client library: [supabase-js](https://github.com/supabase/supabase-js)

`
npm install @supabase/supabase-js
`

And finally we want to save the environment variables in a `.env`.
All we need are the `SUPABASE_URL` and the `SUPABASE_KEY` key that you copied [earlier](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit#get-the-api-keys).

.env

`
PUBLIC_SUPABASE_URL="YOUR_SUPABASE_URL"
PUBLIC_SUPABASE_ANON_KEY="YOUR_SUPABASE_KEY"
`

Optionally, add `src/styles.css` with the [CSS from the example](https://raw.githubusercontent.com/supabase/supabase/master/examples/user-management/sveltekit-user-management/src/styles.css).

### Creating a Supabase client for SSR [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit\#creating-a-supabase-client-for-ssr)

The `ssr` package configures Supabase to use Cookies, which is required for server-side languages and frameworks.

Install the Supabase packages:

`
npm install @supabase/ssr @supabase/supabase-js
`

Creating a Supabase client with the `ssr` package automatically configures it to use Cookies. This means your user's session is available throughout the entire SvelteKit stack - page, layout, server, hooks.

Add the code below to your `src/hooks.server.ts` to initialize the client on the server:

src/hooks.server.ts

``
// src/hooks.server.ts
import { PUBLIC_SUPABASE_URL, PUBLIC_SUPABASE_ANON_KEY } from '$env/static/public'
import { createServerClient } from '@supabase/ssr'
import type { Handle } from '@sveltejs/kit'
export const handle: Handle = async ({ event, resolve }) => {
event.locals.supabase = createServerClient(PUBLIC_SUPABASE_URL, PUBLIC_SUPABASE_ANON_KEY, {
    cookies: {
      getAll: () => event.cookies.getAll(),
      /**
       * SvelteKit's cookies API requires `path` to be explicitly set in
       * the cookie options. Setting `path` to `/` replicates previous/
       * standard behavior.
       */
      setAll: (cookiesToSet) => {
        cookiesToSet.forEach(({ name, value, options }) => {
          event.cookies.set(name, value, { ...options, path: '/' })
        })
      },
    },
})
/**
* Unlike `supabase.auth.getSession()`, which returns the session _without_
* validating the JWT, this function also calls `getUser()` to validate the
* JWT before returning the session.
*/
event.locals.safeGetSession = async () => {
    const {
      data: { session },
    } = await event.locals.supabase.auth.getSession()
    if (!session) {
      return { session: null, user: null }
    }
    const {
      data: { user },
      error,
    } = await event.locals.supabase.auth.getUser()
    if (error) {
      // JWT validation has failed
      return { session: null, user: null }
    }
    return { session, user }
}
return resolve(event, {
    filterSerializedResponseHeaders(name) {
      return name === 'content-range' || name === 'x-supabase-api-version'
    },
})
}
``

Note that `auth.getSession` reads the auth token and the unencoded session data from the local storage medium. It _doesn't_ send a request back to the Supabase Auth server unless the local session is expired.

You should **never** trust the unencoded session data if you're writing server code, since it could be tampered with by the sender. If you need verified, trustworthy user data, call `auth.getUser` instead, which always makes a request to the Auth server to fetch trusted data.

If you are using TypeScript the compiler might complain about `event.locals.supabase` and `event.locals.safeGetSession`, this can be fixed by updating your `src/app.d.ts` with the content below:

src/app.d.ts

`
// src/app.d.ts
import { SupabaseClient, Session } from '@supabase/supabase-js'
declare global {
namespace App {
    interface Locals {
      supabase: SupabaseClient
      safeGetSession(): Promise<{ session: Session | null; user: User | null }>
    }
    interface PageData {
      session: Session | null
      user: User | null
    }
    // interface Error {}
    // interface Platform {}
}
}
`

Create a new `src/routes/+layout.server.ts` file to handle the session on the server-side.

src/routes/+layout.server.ts

`
// src/routes/+layout.server.ts
import type { LayoutServerLoad } from './$types'
export const load: LayoutServerLoad = async ({ locals: { safeGetSession }, cookies }) => {
const { session, user } = await safeGetSession()
return {
    session,
    user,
    cookies: cookies.getAll(),
}
}
`

Start your dev server ( `npm run dev`) in order to generate the `./$types` files we are referencing in our project.

Create a new `src/routes/+layout.ts` file to handle the session and the `supabase` object on the client-side.

src/routes/+layout.ts

``
// src/routes/+layout.ts
import { createBrowserClient, createServerClient, isBrowser } from '@supabase/ssr'
import { PUBLIC_SUPABASE_ANON_KEY, PUBLIC_SUPABASE_URL } from '$env/static/public'
import type { LayoutLoad } from './$types'
export const load: LayoutLoad = async ({ fetch, data, depends }) => {
depends('supabase:auth')
const supabase = isBrowser()
    ? createBrowserClient(PUBLIC_SUPABASE_URL, PUBLIC_SUPABASE_ANON_KEY, {
        global: {
          fetch,
        },
      })
    : createServerClient(PUBLIC_SUPABASE_URL, PUBLIC_SUPABASE_ANON_KEY, {
        global: {
          fetch,
        },
        cookies: {
          getAll() {
            return data.cookies
          },
        },
      })
/**
* It's fine to use `getSession` here, because on the client, `getSession` is
* safe, and on the server, it reads `session` from the `LayoutData`, which
* safely checked the session using `safeGetSession`.
*/
const {
    data: { session },
} = await supabase.auth.getSession()
return { supabase, session }
}
``

Update your `src/routes/+layout.svelte`:

src/routes/+layout.svelte

`
<!-- src/routes/+layout.svelte -->
<script lang="ts">
	import '../styles.css'
	import { invalidate } from '$app/navigation'
	import { onMount } from 'svelte'
	export let data
	let { supabase, session } = data
	$: ({ supabase, session } = data)
	onMount(() => {
		const { data } = supabase.auth.onAuthStateChange((event, newSession) => {
			if (newSession?.expires_at !== session?.expires_at) {
				invalidate('supabase:auth')
			}
		})
		return () => data.subscription.unsubscribe()
	})
</script>
<svelte:head>
	<title>User Management</title>
</svelte:head>
<div class="container" style="padding: 50px 0 100px 0">
	<slot />
</div>
`

## Set up a login page [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit\#set-up-a-login-page)

Create a magic link login/signup page for your application:

src/routes/+page.svelte

`
<!-- src/routes/+page.svelte -->
<script lang="ts">
	import { enhance } from '$app/forms'
	import type { ActionData, SubmitFunction } from './$types.js'
	export let form: ActionData;
	let loading = false
	const handleSubmit: SubmitFunction = () => {
		loading = true
		return async ({ update }) => {
			update()
			loading = false
		}
	}
</script>
<svelte:head>
	<title>User Management</title>
</svelte:head>
<form class="row flex flex-center" method="POST" use:enhance={handleSubmit}>
	<div class="col-6 form-widget">
		<h1 class="header">Supabase + SvelteKit</h1>
		<p class="description">Sign in via magic link with your email below</p>
		{#if form?.message !== undefined}
		<div class="success {form?.success ? '' : 'fail'}">
			{form?.message}
		</div>
		{/if}
		<div>
			<label for="email">Email address</label>
			<input
				id="email"
				name="email"
				class="inputField"
				type="email"
				placeholder="Your email"
				value={form?.email ?? ''}
			/>
		</div>
		{#if form?.errors?.email}
		<span class="flex items-center text-sm error">
			{form?.errors?.email}
		</span>
		{/if}
		<div>
			<button class="button primary block">
				{ loading ? 'Loading' : 'Send magic link' }
			</button>
		</div>
	</div>
</form>
`

Create a `src/routes/+page.server.ts` file that will handle our magic link form when submitted.

src/routes/+page.server.ts

``
// src/routes/+page.server.ts
import { fail, redirect } from '@sveltejs/kit'
import type { Actions, PageServerLoad } from './$types'
export const load: PageServerLoad = async ({ url, locals: { safeGetSession } }) => {
const { session } = await safeGetSession()
// if the user is already logged in return them to the account page
if (session) {
    redirect(303, '/account')
}
return { url: url.origin }
}
export const actions: Actions = {
default: async (event) => {
    const {
      url,
      request,
      locals: { supabase },
    } = event
    const formData = await request.formData()
    const email = formData.get('email') as string
    const validEmail = /^[\w-\.+]+@([\w-]+\.)+[\w-]{2,8}$/.test(email)
    if (!validEmail) {
      return fail(400, { errors: { email: 'Please enter a valid email address' }, email })
    }
    const { error } = await supabase.auth.signInWithOtp({ email })
    if (error) {
      return fail(400, {
        success: false,
        email,
        message: `There was an issue, Please contact support.`,
      })
    }
    return {
      success: true,
      message: 'Please check your email for a magic link to log into the website.',
    }
},
}
``

### Email template [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit\#email-template)

Change the email template to support a server-side authentication flow.

Before we proceed, let's change the email template to support sending a token hash:

- Go to the [Auth templates](https://supabase.com/dashboard/project/_/auth/templates) page in your dashboard.
- Select `Confirm signup` template.
- Change `{{ .ConfirmationURL }}` to `{{ .SiteURL }}/auth/confirm?token_hash={{ .TokenHash }}&type=email`.
- Repeat the previous step for `Magic link` template.

Did you know? You could also customize emails sent out to new users, including the email's looks, content, and query parameters. Check out the [settings of your project](https://supabase.com/dashboard/project/_/auth/templates).

### Confirmation endpoint [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit\#confirmation-endpoint)

As we are working in a server-side rendering (SSR) environment, it is necessary to create a server endpoint responsible for exchanging the `token_hash` for a session.

In the following code snippet, we perform the following steps:

- Retrieve the `token_hash` sent back from the Supabase Auth server using the `token_hash` query parameter.
- Exchange this `token_hash` for a session, which we store in storage (in this case, cookies).
- Finally, the user is redirected to the `account` page or the `error` page.

src/routes/auth/confirm/+server.ts

``
// src/routes/auth/confirm/+server.ts
import type { EmailOtpType } from '@supabase/supabase-js'
import { redirect } from '@sveltejs/kit'
import type { RequestHandler } from './$types'
export const GET: RequestHandler = async ({ url, locals: { supabase } }) => {
const token_hash = url.searchParams.get('token_hash')
const type = url.searchParams.get('type') as EmailOtpType | null
const next = url.searchParams.get('next') ?? '/account'
/**
* Clean up the redirect URL by deleting the Auth flow parameters.
*
* `next` is preserved for now, because it's needed in the error case.
*/
const redirectTo = new URL(url)
redirectTo.pathname = next
redirectTo.searchParams.delete('token_hash')
redirectTo.searchParams.delete('type')
if (token_hash && type) {
    const { error } = await supabase.auth.verifyOtp({ type, token_hash })
    if (!error) {
      redirectTo.searchParams.delete('next')
      redirect(303, redirectTo)
    }
}
redirectTo.pathname = '/auth/error'
redirect(303, redirectTo)
}
``

### Authentication error page [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit\#authentication-error-page)

If there is an error with confirming the token you will be redirect to this error page.

src/routes/auth/error/+page.svelte

`
<p>Login error</p>
`

### Account page [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit\#account-page)

After a user is signed in, they need to be able to edit their profile details and manage their account.
Create a new `src/routes/account/+page.svelte` file with the content below.

src/routes/account/+page.svelte

`
<!-- src/routes/account/+page.svelte -->
<script lang="ts">
	import { enhance } from '$app/forms';
	import type { SubmitFunction } from '@sveltejs/kit';
	export let data
	export let form
	let { session, supabase, profile } = data
	$: ({ session, supabase, profile } = data)
	let profileForm: HTMLFormElement
	let loading = false
	let fullName: string = profile?.full_name ?? ''
	let username: string = profile?.username ?? ''
	let website: string = profile?.website ?? ''
	let avatarUrl: string = profile?.avatar_url ?? ''
	const handleSubmit: SubmitFunction = () => {
		loading = true
		return async () => {
			loading = false
		}
	}
	const handleSignOut: SubmitFunction = () => {
		loading = true
		return async ({ update }) => {
			loading = false
			update()
		}
	}
</script>
<div class="form-widget">
	<form
		class="form-widget"
		method="post"
		action="?/update"
		use:enhance={handleSubmit}
		bind:this={profileForm}
	>
		<div>
			<label for="email">Email</label>
			<input id="email" type="text" value={session.user.email} disabled />
		</div>
		<div>
			<label for="fullName">Full Name</label>
			<input id="fullName" name="fullName" type="text" value={form?.fullName ?? fullName} />
		</div>
		<div>
			<label for="username">Username</label>
			<input id="username" name="username" type="text" value={form?.username ?? username} />
		</div>
		<div>
			<label for="website">Website</label>
			<input id="website" name="website" type="url" value={form?.website ?? website} />
		</div>
		<div>
			<input
				type="submit"
				class="button block primary"
				value={loading ? 'Loading...' : 'Update'}
				disabled={loading}
			/>
		</div>
	</form>
	<form method="post" action="?/signout" use:enhance={handleSignOut}>
		<div>
			<button class="button block" disabled={loading}>Sign Out</button>
		</div>
	</form>
</div>
`

Now create the associated `src/routes/account/+page.server.ts` file that will handle loading our data from the server through the `load` function
and handle all our form actions through the `actions` object.

``
import { fail, redirect } from '@sveltejs/kit'
import type { Actions, PageServerLoad } from './$types'
export const load: PageServerLoad = async ({ locals: { supabase, safeGetSession } }) => {
const { session } = await safeGetSession()
if (!session) {
    redirect(303, '/')
}
const { data: profile } = await supabase
    .from('profiles')
    .select(`username, full_name, website, avatar_url`)
    .eq('id', session.user.id)
    .single()
return { session, profile }
}
export const actions: Actions = {
update: async ({ request, locals: { supabase, safeGetSession } }) => {
    const formData = await request.formData()
    const fullName = formData.get('fullName') as string
    const username = formData.get('username') as string
    const website = formData.get('website') as string
    const avatarUrl = formData.get('avatarUrl') as string
    const { session } = await safeGetSession()
    const { error } = await supabase.from('profiles').upsert({
      id: session?.user.id,
      full_name: fullName,
      username,
      website,
      avatar_url: avatarUrl,
      updated_at: new Date(),
    })
    if (error) {
      return fail(500, {
        fullName,
        username,
        website,
        avatarUrl,
      })
    }
    return {
      fullName,
      username,
      website,
      avatarUrl,
    }
},
signout: async ({ locals: { supabase, safeGetSession } }) => {
    const { session } = await safeGetSession()
    if (session) {
      await supabase.auth.signOut()
      redirect(303, '/')
    }
},
}
``

### Launch! [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit\#launch)

Now that we have all the pages in place, run this in a terminal window:

`
npm run dev
`

And then open the browser to [localhost:5173](http://localhost:5173/) and you should see the completed app.

![Supabase Svelte](https://supabase.com/docs/img/supabase-svelte-demo.png)

## Bonus: Profile photos [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit\#bonus-profile-photos)

Every Supabase project is configured with [Storage](https://supabase.com/docs/guides/storage) for managing large files like photos and videos.

### Create an upload widget [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit\#create-an-upload-widget)

Let's create an avatar for the user so that they can upload a profile photo. We can start by creating a new component called `Avatar.svelte` in the `src/routes/account` directory:

src/routes/account/Avatar.svelte

``
<!-- src/routes/account/Avatar.svelte -->
<script lang="ts">
	import type { SupabaseClient } from '@supabase/supabase-js'
	import { createEventDispatcher } from 'svelte'
	export let size = 10
	export let url: string
	export let supabase: SupabaseClient
	let avatarUrl: string | null = null
	let uploading = false
	let files: FileList
	const dispatch = createEventDispatcher()
	const downloadImage = async (path: string) => {
		try {
			const { data, error } = await supabase.storage.from('avatars').download(path)
			if (error) {
				throw error
			}
			const url = URL.createObjectURL(data)
			avatarUrl = url
		} catch (error) {
			if (error instanceof Error) {
				console.log('Error downloading image: ', error.message)
			}
		}
	}
	const uploadAvatar = async () => {
		try {
			uploading = true
			if (!files || files.length === 0) {
				throw new Error('You must select an image to upload.')
			}
			const file = files[0]
			const fileExt = file.name.split('.').pop()
			const filePath = `${Math.random()}.${fileExt}`
			const { error } = await supabase.storage.from('avatars').upload(filePath, file)
			if (error) {
				throw error
			}
			url = filePath
			setTimeout(() => {
				dispatch('upload')
			}, 100)
		} catch (error) {
			if (error instanceof Error) {
				alert(error.message)
			}
		} finally {
			uploading = false
		}
	}
	$: if (url) downloadImage(url)
</script>
<div>
	{#if avatarUrl}
		<img
			src={avatarUrl}
			alt={avatarUrl ? 'Avatar' : 'No image'}
			class="avatar image"
			style="height: {size}em; width: {size}em;"
		/>
	{:else}
		<div class="avatar no-image" style="height: {size}em; width: {size}em;" />
	{/if}
	<input type="hidden" name="avatarUrl" value={url} />
	<div style="width: {size}em;">
		<label class="button primary block" for="single">
			{uploading ? 'Uploading ...' : 'Upload'}
		</label>
		<input
			style="visibility: hidden; position:absolute;"
			type="file"
			id="single"
			accept="image/*"
			bind:files
			on:change={uploadAvatar}
			disabled={uploading}
		/>
	</div>
</div>
``

### Add the new widget [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit\#add-the-new-widget)

And then we can add the widget to the Account page:

src/routes/account/+page.svelte

`
<!-- src/routes/account/+page.svelte -->
<script lang="ts">
// Import the new component
import Avatar from './Avatar.svelte'
</script>
<div class="form-widget">
<form
    class="form-widget"
    method="post"
    action="?/update"
    use:enhance={handleSubmit}
    bind:this={profileForm}
>
    <!-- Add to body -->
    <Avatar
        {supabase}
        bind:url={avatarUrl}
        size={10}
        on:upload={() => {
          profileForm.requestSubmit();
        }}
      />
    <!-- Other form elements -->
</form>
</div>
`

At this stage you have a fully functional application!

### Is this helpful?

NoYes

### On this page

[Project setup](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit#project-setup) [Create a project](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit#create-a-project) [Set up the database schema](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit#set-up-the-database-schema) [Get the API Keys](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit#get-the-api-keys) [Building the app](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit#building-the-app) [Initialize a Svelte app](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit#initialize-a-svelte-app) [Creating a Supabase client for SSR](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit#creating-a-supabase-client-for-ssr) [Set up a login page](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit#set-up-a-login-page) [Email template](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit#email-template) [Confirmation endpoint](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit#confirmation-endpoint) [Authentication error page](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit#authentication-error-page) [Account page](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit#account-page) [Launch!](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit#launch) [Bonus: Profile photos](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit#bonus-profile-photos) [Create an upload widget](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit#create-an-upload-widget) [Add the new widget](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit#add-the-new-widget)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_tutorials_with_swift.md">
Getting Started

# Build a User Management App with Swift and SwiftUI

* * *

This tutorial demonstrates how to build a basic user management app. The app authenticates and identifies the user, stores their profile information in the database, and allows the user to log in, update their profile details, and upload a profile photo. The app uses:

- [Supabase Database](https://supabase.com/docs/guides/database) \- a Postgres database for storing your user data and [Row Level Security](https://supabase.com/docs/guides/auth#row-level-security) so data is protected and users can only access their own information.
- [Supabase Auth](https://supabase.com/docs/guides/auth) \- allow users to sign up and log in.
- [Supabase Storage](https://supabase.com/docs/guides/storage) \- users can upload a profile photo.

![Supabase User Management example](https://supabase.com/docs/img/supabase-swift-demo.png)

If you get stuck while working through this guide, refer to the [full example on GitHub](https://github.com/supabase/supabase/tree/master/examples/user-management/swift-user-management).

## Project setup [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-swift\#project-setup)

Before we start building we're going to set up our Database and API. This is as simple as starting a new Project in Supabase and then creating a "schema" inside the database.

### Create a project [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-swift\#create-a-project)

1. [Create a new project](https://supabase.com/dashboard) in the Supabase Dashboard.
2. Enter your project details.
3. Wait for the new database to launch.

### Set up the database schema [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-swift\#set-up-the-database-schema)

Now we are going to set up the database schema. We can use the "User Management Starter" quickstart in the SQL Editor, or you can just copy/paste the SQL from below and run it yourself.

DashboardSQL

1. Go to the [SQL Editor](https://supabase.com/dashboard/project/_/sql) page in the Dashboard.
2. Click **User Management Starter**.
3. Click **Run**.

You can easily pull the database schema down to your local project by running the `db pull` command. Read the [local development docs](https://supabase.com/docs/guides/cli/local-development#link-your-project) for detailed instructions.

`
supabase link --project-ref <project-id>
# You can get <project-id> from your project's dashboard URL: https://supabase.com/dashboard/project/<project-id>
supabase db pull
`

### Get the API Keys [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-swift\#get-the-api-keys)

Now that you've created some database tables, you are ready to insert data using the auto-generated API.
We just need to get the Project URL and `anon` key from the API settings.

1. Go to the [API Settings](https://supabase.com/dashboard/project/_/settings/api) page in the Dashboard.
2. Find your Project `URL`, `anon`, and `service_role` keys on this page.

## Building the app [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-swift\#building-the-app)

Let's start building the SwiftUI app from scratch.

### Create a SwiftUI app in Xcode [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-swift\#create-a-swiftui-app-in-xcode)

Open Xcode and create a new SwiftUI project.

Add the [supabase-swift](https://github.com/supabase/supabase-swift) dependency.

Add the `https://github.com/supabase/supabase-swift` package to your app. For instructions, see the [Apple tutorial on adding package dependencies](https://developer.apple.com/documentation/xcode/adding-package-dependencies-to-your-app).

Create a helper file to initialize the Supabase client.
You need the API URL and the `anon` key that you copied [earlier](https://supabase.com/docs/guides/getting-started/tutorials/with-swift#get-the-api-keys).
These variables will be exposed on the application, and that's completely fine since you have
[Row Level Security](https://supabase.com/docs/guides/auth#row-level-security) enabled on your database.

Supabase.swift

`
import Foundation
import Supabase
let supabase = SupabaseClient(
supabaseURL: URL(string: "YOUR_SUPABASE_URL")!,
supabaseKey: "YOUR_SUPABASE_ANON_KEY"
)
`

### Set up a login view [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-swift\#set-up-a-login-view)

Set up a SwiftUI view to manage logins and sign ups.
Users should be able to sign in using a magic link.

AuthView.swift

`
import SwiftUI
import Supabase
struct AuthView: View {
@State var email = ""
@State var isLoading = false
@State var result: Result<Void, Error>?
var body: some View {
    Form {
      Section {
        TextField("Email", text: $email)
          .textContentType(.emailAddress)
          .textInputAutocapitalization(.never)
          .autocorrectionDisabled()
      }
      Section {
        Button("Sign in") {
          signInButtonTapped()
        }
        if isLoading {
          ProgressView()
        }
      }
      if let result {
        Section {
          switch result {
          case .success:
            Text("Check your inbox.")
          case .failure(let error):
            Text(error.localizedDescription).foregroundStyle(.red)
          }
        }
      }
    }
    .onOpenURL(perform: { url in
      Task {
        do {
          try await supabase.auth.session(from: url)
        } catch {
          self.result = .failure(error)
        }
      }
    })
}
func signInButtonTapped() {
    Task {
      isLoading = true
      defer { isLoading = false }
      do {
        try await supabase.auth.signInWithOTP(
            email: email,
            redirectTo: URL(string: "io.supabase.user-management://login-callback")
        )
        result = .success(())
      } catch {
        result = .failure(error)
      }
    }
}
}
`

The example uses a custom `redirectTo` URL. For this to work, add a custom redirect URL to Supabase and a custom URL scheme to your SwiftUI application. Follow the guide on [implementing deep link handling](https://supabase.com/docs/guides/auth/native-mobile-deep-linking?platform=swift).

### Account view [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-swift\#account-view)

After a user is signed in, you can allow them to edit their profile details and manage their account.

Create a new view for that called `ProfileView.swift`.

ProfileView.swift

`
import SwiftUI
struct ProfileView: View {
@State var username = ""
@State var fullName = ""
@State var website = ""
@State var isLoading = false
var body: some View {
    NavigationStack {
      Form {
        Section {
          TextField("Username", text: $username)
            .textContentType(.username)
            .textInputAutocapitalization(.never)
          TextField("Full name", text: $fullName)
            .textContentType(.name)
          TextField("Website", text: $website)
            .textContentType(.URL)
            .textInputAutocapitalization(.never)
        }
        Section {
          Button("Update profile") {
            updateProfileButtonTapped()
          }
          .bold()
          if isLoading {
            ProgressView()
          }
        }
      }
      .navigationTitle("Profile")
      .toolbar(content: {
        ToolbarItem(placement: .topBarLeading){
          Button("Sign out", role: .destructive) {
            Task {
              try? await supabase.auth.signOut()
            }
          }
        }
      })
    }
    .task {
      await getInitialProfile()
    }
}
func getInitialProfile() async {
    do {
      let currentUser = try await supabase.auth.session.user
      let profile: Profile =
      try await supabase
        .from("profiles")
        .select()
        .eq("id", value: currentUser.id)
        .single()
        .execute()
        .value
      self.username = profile.username ?? ""
      self.fullName = profile.fullName ?? ""
      self.website = profile.website ?? ""
    } catch {
      debugPrint(error)
    }
}
func updateProfileButtonTapped() {
    Task {
      isLoading = true
      defer { isLoading = false }
      do {
        let currentUser = try await supabase.auth.session.user
        try await supabase
          .from("profiles")
          .update(
            UpdateProfileParams(
              username: username,
              fullName: fullName,
              website: website
            )
          )
          .eq("id", value: currentUser.id)
          .execute()
      } catch {
        debugPrint(error)
      }
    }
}
}
`

### Models [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-swift\#models)

In `ProfileView.swift`, you used 2 model types for deserializing the response and serializing the request to Supabase. Add those in a new `Models.swift` file.

Models.swift

`
struct Profile: Decodable {
let username: String?
let fullName: String?
let website: String?
enum CodingKeys: String, CodingKey {
    case username
    case fullName = "full_name"
    case website
}
}
struct UpdateProfileParams: Encodable {
let username: String
let fullName: String
let website: String
enum CodingKeys: String, CodingKey {
    case username
    case fullName = "full_name"
    case website
}
}
`

### Launch! [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-swift\#launch)

Now that you've created all the views, add an entry point for the application. This will verify if the user has a valid session and route them to the authenticated or non-authenticated state.

Add a new `AppView.swift` file.

AppView.swift

`
import SwiftUI
struct AppView: View {
@State var isAuthenticated = false
var body: some View {
    Group {
      if isAuthenticated {
        ProfileView()
      } else {
        AuthView()
      }
    }
    .task {
      for await state in supabase.auth.authStateChanges {
        if [.initialSession, .signedIn, .signedOut].contains(state.event) {
          isAuthenticated = state.session != nil
        }
      }
    }
}
}
`

Update the entry point to the newly created `AppView`. Run in Xcode to launch your application in the simulator.

## Bonus: Profile photos [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-swift\#bonus-profile-photos)

Every Supabase project is configured with [Storage](https://supabase.com/docs/guides/storage) for managing large files like
photos and videos.

### Add `PhotosPicker` [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-swift\#add-photospicker)

Let's add support for the user to pick an image from the library and upload it.
Start by creating a new type to hold the picked avatar image:

AvatarImage.swift

`
import SwiftUI
struct AvatarImage: Transferable, Equatable {
let image: Image
let data: Data
static var transferRepresentation: some TransferRepresentation {
    DataRepresentation(importedContentType: .image) { data in
      guard let image = AvatarImage(data: data) else {
        throw TransferError.importFailed
      }
      return image
    }
}
}
extension AvatarImage {
init?(data: Data) {
    guard let uiImage = UIImage(data: data) else {
      return nil
    }
    let image = Image(uiImage: uiImage)
    self.init(image: image, data: data)
}
}
enum TransferError: Error {
case importFailed
}
`

#### Add `PhotosPicker` to profile page [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-swift\#add-photospicker-to-profile-page)

ProfileView.swift

`
+ import PhotosUI
+ import Storage
+ import Supabase
import SwiftUI
struct ProfileView: View {
@State var username = ""
@State var fullName = ""
@State var website = ""
@State var isLoading = false
+ @State var imageSelection: PhotosPickerItem?
+ @State var avatarImage: AvatarImage?
var body: some View {
    NavigationStack {
      Form {
+        Section {
+          HStack {
+            Group {
+              if let avatarImage {
+                avatarImage.image.resizable()
+              } else {
+                Color.clear
+              }
+            }
+            .scaledToFit()
+            .frame(width: 80, height: 80)
+
+            Spacer()
+
+            PhotosPicker(selection: $imageSelection, matching: .images) {
+              Image(systemName: "pencil.circle.fill")
+                .symbolRenderingMode(.multicolor)
+                .font(.system(size: 30))
+                .foregroundColor(.accentColor)
+            }
+          }
+        }
        Section {
          TextField("Username", text: $username)
            .textContentType(.username)
            .textInputAutocapitalization(.never)
          TextField("Full name", text: $fullName)
            .textContentType(.name)
          TextField("Website", text: $website)
            .textContentType(.URL)
            .textInputAutocapitalization(.never)
        }
        Section {
          Button("Update profile") {
            updateProfileButtonTapped()
          }
          .bold()
          if isLoading {
            ProgressView()
          }
        }
      }
      .navigationTitle("Profile")
      .toolbar(content: {
        ToolbarItem {
          Button("Sign out", role: .destructive) {
            Task {
              try? await supabase.auth.signOut()
            }
          }
        }
      })
+      .onChange(of: imageSelection) { _, newValue in
+        guard let newValue else { return }
+        loadTransferable(from: newValue)
+      }
    }
    .task {
      await getInitialProfile()
    }
}
func getInitialProfile() async {
    do {
      let currentUser = try await supabase.auth.session.user
      let profile: Profile =
      try await supabase
        .from("profiles")
        .select()
        .eq("id", value: currentUser.id)
        .single()
        .execute()
        .value
      username = profile.username ?? ""
      fullName = profile.fullName ?? ""
      website = profile.website ?? ""
+      if let avatarURL = profile.avatarURL, !avatarURL.isEmpty {
+        try await downloadImage(path: avatarURL)
+      }
    } catch {
      debugPrint(error)
    }
}
func updateProfileButtonTapped() {
    Task {
      isLoading = true
      defer { isLoading = false }
      do {
+        let imageURL = try await uploadImage()
        let currentUser = try await supabase.auth.session.user
        let updatedProfile = Profile(
          username: username,
          fullName: fullName,
          website: website,
+          avatarURL: imageURL
        )
        try await supabase
          .from("profiles")
          .update(updatedProfile)
          .eq("id", value: currentUser.id)
          .execute()
      } catch {
        debugPrint(error)
      }
    }
}
+  private func loadTransferable(from imageSelection: PhotosPickerItem) {
+    Task {
+      do {
+        avatarImage = try await imageSelection.loadTransferable(type: AvatarImage.self)
+      } catch {
+        debugPrint(error)
+      }
+    }
+  }
+
+  private func downloadImage(path: String) async throws {
+    let data = try await supabase.storage.from("avatars").download(path: path)
+    avatarImage = AvatarImage(data: data)
+  }
+
+  private func uploadImage() async throws -> String? {
+    guard let data = avatarImage?.data else { return nil }
+
+    let filePath = "\(UUID().uuidString).jpeg"
+
+    try await supabase.storage
+      .from("avatars")
+      .upload(
+        filePath,
+        data: data,
+        options: FileOptions(contentType: "image/jpeg")
+      )
+
+    return filePath
+  }
}
`

Finally, update your Models.

Models.swift

`
struct Profile: Codable {
let username: String?
let fullName: String?
let website: String?
let avatarURL: String?
enum CodingKeys: String, CodingKey {
    case username
    case fullName = "full_name"
    case website
    case avatarURL = "avatar_url"
}
}
`

You no longer need the `UpdateProfileParams` struct, as you can now reuse the `Profile` struct for both request and response calls.

At this stage you have a fully functional application!

### Is this helpful?

NoYes

### On this page

[Project setup](https://supabase.com/docs/guides/getting-started/tutorials/with-swift#project-setup) [Create a project](https://supabase.com/docs/guides/getting-started/tutorials/with-swift#create-a-project) [Set up the database schema](https://supabase.com/docs/guides/getting-started/tutorials/with-swift#set-up-the-database-schema) [Get the API Keys](https://supabase.com/docs/guides/getting-started/tutorials/with-swift#get-the-api-keys) [Building the app](https://supabase.com/docs/guides/getting-started/tutorials/with-swift#building-the-app) [Create a SwiftUI app in Xcode](https://supabase.com/docs/guides/getting-started/tutorials/with-swift#create-a-swiftui-app-in-xcode) [Set up a login view](https://supabase.com/docs/guides/getting-started/tutorials/with-swift#set-up-a-login-view) [Account view](https://supabase.com/docs/guides/getting-started/tutorials/with-swift#account-view) [Models](https://supabase.com/docs/guides/getting-started/tutorials/with-swift#models) [Launch!](https://supabase.com/docs/guides/getting-started/tutorials/with-swift#launch) [Bonus: Profile photos](https://supabase.com/docs/guides/getting-started/tutorials/with-swift#bonus-profile-photos) [Add PhotosPicker](https://supabase.com/docs/guides/getting-started/tutorials/with-swift#add-photospicker)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started_tutorials_with_vue_3.md">
Getting Started

# Build a User Management App with Vue 3

* * *

This tutorial demonstrates how to build a basic user management app. The app authenticates and identifies the user, stores their profile information in the database, and allows the user to log in, update their profile details, and upload a profile photo. The app uses:

- [Supabase Database](https://supabase.com/docs/guides/database) \- a Postgres database for storing your user data and [Row Level Security](https://supabase.com/docs/guides/auth#row-level-security) so data is protected and users can only access their own information.
- [Supabase Auth](https://supabase.com/docs/guides/auth) \- allow users to sign up and log in.
- [Supabase Storage](https://supabase.com/docs/guides/storage) \- users can upload a profile photo.

![Supabase User Management example](https://supabase.com/docs/img/user-management-demo.png)

If you get stuck while working through this guide, refer to the [full example on GitHub](https://github.com/supabase/supabase/tree/master/examples/user-management/vue3-user-management).

## Project setup [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-vue-3\#project-setup)

Before we start building we're going to set up our Database and API. This is as simple as starting a new Project in Supabase and then creating a "schema" inside the database.

### Create a project [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-vue-3\#create-a-project)

1. [Create a new project](https://supabase.com/dashboard) in the Supabase Dashboard.
2. Enter your project details.
3. Wait for the new database to launch.

### Set up the database schema [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-vue-3\#set-up-the-database-schema)

Now we are going to set up the database schema. We can use the "User Management Starter" quickstart in the SQL Editor, or you can just copy/paste the SQL from below and run it yourself.

DashboardSQL

1. Go to the [SQL Editor](https://supabase.com/dashboard/project/_/sql) page in the Dashboard.
2. Click **User Management Starter**.
3. Click **Run**.

You can easily pull the database schema down to your local project by running the `db pull` command. Read the [local development docs](https://supabase.com/docs/guides/cli/local-development#link-your-project) for detailed instructions.

`
supabase link --project-ref <project-id>
# You can get <project-id> from your project's dashboard URL: https://supabase.com/dashboard/project/<project-id>
supabase db pull
`

### Get the API Keys [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-vue-3\#get-the-api-keys)

Now that you've created some database tables, you are ready to insert data using the auto-generated API.
We just need to get the Project URL and `anon` key from the API settings.

1. Go to the [API Settings](https://supabase.com/dashboard/project/_/settings/api) page in the Dashboard.
2. Find your Project `URL`, `anon`, and `service_role` keys on this page.

## Building the app [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-vue-3\#building-the-app)

Let's start building the Vue 3 app from scratch.

### Initialize a Vue 3 app [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-vue-3\#initialize-a-vue-3-app)

We can quickly use [Vite with Vue 3 Template](https://vitejs.dev/guide/#scaffolding-your-first-vite-project) to initialize
an app called `supabase-vue-3`:

`
# npm 6.x
npm create vite@latest supabase-vue-3 --template vue
# npm 7+, extra double-dash is needed:
npm create vite@latest supabase-vue-3 -- --template vue
cd supabase-vue-3
`

Then let's install the only additional dependency: [supabase-js](https://github.com/supabase/supabase-js)

`
npm install @supabase/supabase-js
`

And finally we want to save the environment variables in a `.env`.
All we need are the API URL and the `anon` key that you copied [earlier](https://supabase.com/docs/guides/getting-started/tutorials/with-vue-3#get-the-api-keys).

.env

`
VITE_SUPABASE_URL=YOUR_SUPABASE_URL
VITE_SUPABASE_ANON_KEY=YOUR_SUPABASE_ANON_KEY
`

With the API credentials in place, create an `src/supabase.js` helper file to initialize the Supabase client. These variables are exposed
on the browser, and that's completely fine since we have [Row Level Security](https://supabase.com/docs/guides/auth#row-level-security) enabled on our Database.

src/supabase.js

`
import { createClient } from '@supabase/supabase-js'
const supabaseUrl = import.meta.env.VITE_SUPABASE_URL
const supabaseAnonKey = import.meta.env.VITE_SUPABASE_ANON_KEY
export const supabase = createClient(supabaseUrl, supabaseAnonKey)
`

Optionally, update [src/style.css](https://raw.githubusercontent.com/supabase/supabase/master/examples/user-management/vue3-user-management/src/style.css) to style the app.

### Set up a login component [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-vue-3\#set-up-a-login-component)

Set up an `src/components/Auth.vue` component to manage logins and sign ups. We'll use Magic Links, so users can sign in with their email without using passwords.

/src/components/Auth.vue

`
<script setup>
import { ref } from 'vue'
import { supabase } from '../supabase'
const loading = ref(false)
const email = ref('')
const handleLogin = async () => {
try {
    loading.value = true
    const { error } = await supabase.auth.signInWithOtp({
      email: email.value,
    })
    if (error) throw error
    alert('Check your email for the login link!')
} catch (error) {
    if (error instanceof Error) {
      alert(error.message)
    }
} finally {
    loading.value = false
}
}
</script>
<template>
<form class="row flex-center flex" @submit.prevent="handleLogin">
    <div class="col-6 form-widget">
      <h1 class="header">Supabase + Vue 3</h1>
      <p class="description">Sign in via magic link with your email below</p>
      <div>
        <input class="inputField" required type="email" placeholder="Your email" v-model="email" />
      </div>
      <div>
        <input
          type="submit"
          class="button block"
          :value="loading ? 'Loading' : 'Send magic link'"
          :disabled="loading"
        />
      </div>
    </div>
</form>
</template>
`

### Account page [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-vue-3\#account-page)

After a user is signed in we can allow them to edit their profile details and manage their account.
Create a new `src/components/Account.vue` component to handle this.

src/components/Account.vue

``
<script setup>
import { supabase } from '../supabase'
import { onMounted, ref, toRefs } from 'vue'
const props = defineProps(['session'])
const { session } = toRefs(props)
const loading = ref(true)
const username = ref('')
const website = ref('')
const avatar_url = ref('')
onMounted(() => {
getProfile()
})
async function getProfile() {
try {
    loading.value = true
    const { user } = session.value
    const { data, error, status } = await supabase
      .from('profiles')
      .select(`username, website, avatar_url`)
      .eq('id', user.id)
      .single()
    if (error && status !== 406) throw error
    if (data) {
      username.value = data.username
      website.value = data.website
      avatar_url.value = data.avatar_url
    }
} catch (error) {
    alert(error.message)
} finally {
    loading.value = false
}
}
async function updateProfile() {
try {
    loading.value = true
    const { user } = session.value
    const updates = {
      id: user.id,
      username: username.value,
      website: website.value,
      avatar_url: avatar_url.value,
      updated_at: new Date(),
    }
    const { error } = await supabase.from('profiles').upsert(updates)
    if (error) throw error
} catch (error) {
    alert(error.message)
} finally {
    loading.value = false
}
}
async function signOut() {
try {
    loading.value = true
    const { error } = await supabase.auth.signOut()
    if (error) throw error
} catch (error) {
    alert(error.message)
} finally {
    loading.value = false
}
}
</script>
<template>
<form class="form-widget" @submit.prevent="updateProfile">
    <div>
      <label for="email">Email</label>
      <input id="email" type="text" :value="session.user.email" disabled />
    </div>
    <div>
      <label for="username">Name</label>
      <input id="username" type="text" v-model="username" />
    </div>
    <div>
      <label for="website">Website</label>
      <input id="website" type="url" v-model="website" />
    </div>
    <div>
      <input
        type="submit"
        class="button primary block"
        :value="loading ? 'Loading ...' : 'Update'"
        :disabled="loading"
      />
    </div>
    <div>
      <button class="button block" @click="signOut" :disabled="loading">Sign Out</button>
    </div>
</form>
</template>
``

### Launch! [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-vue-3\#launch)

Now that we have all the components in place, let's update `App.vue`:

src/App.vue

`
<script setup>
import { onMounted, ref } from 'vue'
import Account from './components/Account.vue'
import Auth from './components/Auth.vue'
import { supabase } from './supabase'
const session = ref()
onMounted(() => {
supabase.auth.getSession().then(({ data }) => {
    session.value = data.session
})
supabase.auth.onAuthStateChange((_, _session) => {
    session.value = _session
})
})
</script>
<template>
<div class="container" style="padding: 50px 0 100px 0">
    <Account v-if="session" :session="session" />
    <Auth v-else />
</div>
</template>
`

Once that's done, run this in a terminal window:

`
npm run dev
`

And then open the browser to [localhost:5173](http://localhost:5173/) and you should see the completed app.

![Supabase Vue 3](https://supabase.com/docs/img/supabase-vue-3-demo.png)

## Bonus: Profile photos [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-vue-3\#bonus-profile-photos)

Every Supabase project is configured with [Storage](https://supabase.com/docs/guides/storage) for managing large files like photos and videos.

### Create an upload widget [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-vue-3\#create-an-upload-widget)

Create a new `src/components/Avatar.vue` component that allows users to upload profile photos:

src/components/Avatar.vue

``
<script setup>
import { ref, toRefs, watchEffect } from 'vue'
import { supabase } from '../supabase'
const prop = defineProps(['path', 'size'])
const { path, size } = toRefs(prop)
const emit = defineEmits(['upload', 'update:path'])
const uploading = ref(false)
const src = ref('')
const files = ref()
const downloadImage = async () => {
try {
    const { data, error } = await supabase.storage.from('avatars').download(path.value)
    if (error) throw error
    src.value = URL.createObjectURL(data)
} catch (error) {
    console.error('Error downloading image: ', error.message)
}
}
const uploadAvatar = async (evt) => {
files.value = evt.target.files
try {
    uploading.value = true
    if (!files.value || files.value.length === 0) {
      throw new Error('You must select an image to upload.')
    }
    const file = files.value[0]
    const fileExt = file.name.split('.').pop()
    const filePath = `${Math.random()}.${fileExt}`
    const { error: uploadError } = await supabase.storage.from('avatars').upload(filePath, file)
    if (uploadError) throw uploadError
    emit('update:path', filePath)
    emit('upload')
} catch (error) {
    alert(error.message)
} finally {
    uploading.value = false
}
}
watchEffect(() => {
if (path.value) downloadImage()
})
</script>
<template>
<div>
    <img
      v-if="src"
      :src="src"
      alt="Avatar"
      class="avatar image"
      :style="{ height: size + 'em', width: size + 'em' }"
    />
    <div v-else class="avatar no-image" :style="{ height: size + 'em', width: size + 'em' }" />
    <div :style="{ width: size + 'em' }">
      <label class="button primary block" for="single">
        {{ uploading ? 'Uploading ...' : 'Upload' }}
      </label>
      <input
        style="visibility: hidden; position: absolute"
        type="file"
        id="single"
        accept="image/*"
        @change="uploadAvatar"
        :disabled="uploading"
      />
    </div>
</div>
</template>
``

### Add the new widget [\#](https://supabase.com/docs/guides/getting-started/tutorials/with-vue-3\#add-the-new-widget)

And then we can add the widget to the Account page in `src/components/Account.vue`:

src/components/Account.vue

`
<script>
// Import the new component
import Avatar from './Avatar.vue'
//...
const avatar_url = ref('')
//...
</script>
<template>
<form class="form-widget" @submit.prevent="updateProfile">
    <!-- Add to body -->
    <Avatar v-model:path="avatar_url" @upload="updateProfile" size="10" />
    <!-- Other form elements -->
</form>
</template>
`

At this stage you have a fully functional application!

### Is this helpful?

NoYes

### On this page

[Project setup](https://supabase.com/docs/guides/getting-started/tutorials/with-vue-3#project-setup) [Create a project](https://supabase.com/docs/guides/getting-started/tutorials/with-vue-3#create-a-project) [Set up the database schema](https://supabase.com/docs/guides/getting-started/tutorials/with-vue-3#set-up-the-database-schema) [Get the API Keys](https://supabase.com/docs/guides/getting-started/tutorials/with-vue-3#get-the-api-keys) [Building the app](https://supabase.com/docs/guides/getting-started/tutorials/with-vue-3#building-the-app) [Initialize a Vue 3 app](https://supabase.com/docs/guides/getting-started/tutorials/with-vue-3#initialize-a-vue-3-app) [Set up a login component](https://supabase.com/docs/guides/getting-started/tutorials/with-vue-3#set-up-a-login-component) [Account page](https://supabase.com/docs/guides/getting-started/tutorials/with-vue-3#account-page) [Launch!](https://supabase.com/docs/guides/getting-started/tutorials/with-vue-3#launch) [Bonus: Profile photos](https://supabase.com/docs/guides/getting-started/tutorials/with-vue-3#bonus-profile-photos) [Create an upload widget](https://supabase.com/docs/guides/getting-started/tutorials/with-vue-3#create-an-upload-widget) [Add the new widget](https://supabase.com/docs/guides/getting-started/tutorials/with-vue-3#add-the-new-widget)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_getting_started.md">
Getting Started

# Getting Started

* * *

[Features\\
\\
A non-exhaustive list of features that Supabase provides for every project.](https://supabase.com/docs/guides/getting-started/features) [Architecture\\
\\
An overview of Supabase's architecture and product principles.](https://supabase.com/docs/guides/getting-started/architecture) [Local Development\\
\\
Use the Supabase CLI to develop locally and collaborate between teams.](https://supabase.com/docs/guides/cli/getting-started)

### Use cases [\#](https://supabase.com/docs/guides/getting-started\#use-cases)

[![AI, Vectors, and embeddings](https://supabase.com/docs/img/icons/openai_logo-light.svg)\\
\\
AI, Vectors, and embeddings\\
\\
Build AI-enabled applications using our Vector toolkit.](https://supabase.com/docs/guides/ai#examples) [![Subscription Payments (SaaS)](https://supabase.com/docs/img/icons/nextjs-icon.svg)\\
\\
Subscription Payments (SaaS)\\
\\
Clone, deploy, and fully customize a SaaS subscription application with Next.js.](https://github.com/vercel/nextjs-subscription-payments#nextjs-subscription-payments-starter) [![Partner Gallery](https://supabase.com/docs/img/icons/nextjs-icon.svg)\\
\\
Partner Gallery\\
\\
Postgres full-text search, image storage, and more.](https://github.com/supabase-community/partner-gallery-example#supabase-partner-gallery-example)

### Framework quickstarts [\#](https://supabase.com/docs/guides/getting-started\#framework-quickstarts)

[![React](https://supabase.com/docs/img/icons/react-icon.svg)\\
\\
React\\
\\
Learn how to create a Supabase project, add some sample data to your database, and query the data from a React app.](https://supabase.com/docs/guides/getting-started/quickstarts/reactjs) [![Next.js](https://supabase.com/docs/img/icons/nextjs-icon-light.svg)\\
\\
Next.js\\
\\
Learn how to create a Supabase project, add some sample data to your database, and query the data from a Next.js app.](https://supabase.com/docs/guides/getting-started/quickstarts/nextjs) [![Nuxt](https://supabase.com/docs/img/icons/nuxt-icon.svg)\\
\\
Nuxt\\
\\
Learn how to create a Supabase project, add some sample data to your database, and query the data from a Nuxt app.](https://supabase.com/docs/guides/getting-started/quickstarts/nuxtjs) [![Hono](https://supabase.com/docs/img/icons/hono-icon.svg)\\
\\
Hono\\
\\
Learn how to create a Supabase project, add some sample data to your database, secure it with auth, and query the data from a Hono app.](https://supabase.com/docs/guides/getting-started/quickstarts/hono) [![RedwoodJS](https://supabase.com/docs/img/icons/redwood-icon.svg)\\
\\
RedwoodJS\\
\\
Learn how to create a Supabase project, add some sample data to your database using Prisma migration and seeds, and query the data from a RedwoodJS app.](https://supabase.com/docs/guides/getting-started/quickstarts/redwoodjs) [![Flutter](https://supabase.com/docs/img/icons/flutter-icon.svg)\\
\\
Flutter\\
\\
Learn how to create a Supabase project, add some sample data to your database, and query the data from a Flutter app.](https://supabase.com/docs/guides/getting-started/quickstarts/flutter) [![iOS SwiftUI](https://supabase.com/docs/img/icons/swift-icon.svg)\\
\\
iOS SwiftUI\\
\\
Learn how to create a Supabase project, add some sample data to your database, and query the data from an iOS app.](https://supabase.com/docs/guides/getting-started/quickstarts/ios-swiftui) [![Android Kotlin](https://supabase.com/docs/img/icons/kotlin-icon.svg)\\
\\
Android Kotlin\\
\\
Learn how to create a Supabase project, add some sample data to your database, and query the data from an Android Kotlin app.](https://supabase.com/docs/guides/getting-started/quickstarts/kotlin) [![SvelteKit](https://supabase.com/docs/img/icons/svelte-icon.svg)\\
\\
SvelteKit\\
\\
Learn how to create a Supabase project, add some sample data to your database, and query the data from a SvelteKit app.](https://supabase.com/docs/guides/getting-started/quickstarts/sveltekit) [![SolidJS](https://supabase.com/docs/img/icons/solidjs-icon.svg)\\
\\
SolidJS\\
\\
Learn how to create a Supabase project, add some sample data to your database, and query the data from a SolidJS app.](https://supabase.com/docs/guides/getting-started/quickstarts/solidjs) [![Vue](https://supabase.com/docs/img/icons/vuejs-icon.svg)\\
\\
Vue\\
\\
Learn how to create a Supabase project, add some sample data to your database, and query the data from a Vue app.](https://supabase.com/docs/guides/getting-started/quickstarts/vue) [![refine](https://supabase.com/docs/img/icons/refine-icon.svg)\\
\\
refine\\
\\
Learn how to create a Supabase project, add some sample data to your database, and query the data from a refine app.](https://supabase.com/docs/guides/getting-started/quickstarts/refine)

### Web app demos [\#](https://supabase.com/docs/guides/getting-started\#web-app-demos)

[![Next.js](https://supabase.com/docs/img/icons/nextjs-icon-light.svg)\\
\\
Next.js\\
\\
Learn how to build a user management app with Next.js and Supabase Database, Auth, and Storage functionality.](https://supabase.com/docs/guides/getting-started/tutorials/with-nextjs) [![React](https://supabase.com/docs/img/icons/react-icon.svg)\\
\\
React\\
\\
Learn how to build a user management app with React and Supabase Database, Auth, and Storage functionality.](https://supabase.com/docs/guides/getting-started/tutorials/with-react) [![Vue 3](https://supabase.com/docs/img/icons/vuejs-icon.svg)\\
\\
Vue 3\\
\\
Learn how to build a user management app with Vue 3 and Supabase Database, Auth, and Storage functionality.](https://supabase.com/docs/guides/getting-started/tutorials/with-vue-3) [![Nuxt 3](https://supabase.com/docs/img/icons/nuxt-icon.svg)\\
\\
Nuxt 3\\
\\
Learn how to build a user management app with Nuxt 3 and Supabase Database, Auth, and Storage functionality.](https://supabase.com/docs/guides/getting-started/tutorials/with-nuxt-3) [![Angular](https://supabase.com/docs/img/icons/angular-icon.svg)\\
\\
Angular\\
\\
Learn how to build a user management app with Angular and Supabase Database, Auth, and Storage functionality.](https://supabase.com/docs/guides/getting-started/tutorials/with-angular) [![RedwoodJS](https://supabase.com/docs/img/icons/redwood-icon.svg)\\
\\
RedwoodJS\\
\\
Learn how to build a user management app with RedwoodJS and Supabase Database, Auth, and Storage functionality.](https://supabase.com/docs/guides/getting-started/tutorials/with-redwoodjs) [![Svelte](https://supabase.com/docs/img/icons/svelte-icon.svg)\\
\\
Svelte\\
\\
Learn how to build a user management app with Svelte and Supabase Database, Auth, and Storage functionality.](https://supabase.com/docs/guides/getting-started/tutorials/with-svelte) [![SvelteKit](https://supabase.com/docs/img/icons/svelte-icon.svg)\\
\\
SvelteKit\\
\\
Learn how to build a user management app with SvelteKit and Supabase Database, Auth, and Storage functionality.](https://supabase.com/docs/guides/getting-started/tutorials/with-sveltekit) [![refine](https://supabase.com/docs/img/icons/refine-icon.svg)\\
\\
refine\\
\\
Learn how to build a user management app with refine and Supabase Database, Auth, and Storage functionality.](https://supabase.com/docs/guides/getting-started/tutorials/with-refine)

### Mobile tutorials [\#](https://supabase.com/docs/guides/getting-started\#mobile-tutorials)

[![Flutter](https://supabase.com/docs/img/icons/flutter-icon.svg)\\
\\
Flutter\\
\\
Learn how to build a user management app with Flutter and Supabase Database, Auth, and Storage functionality.](https://supabase.com/docs/guides/getting-started/tutorials/with-flutter) [![Expo React Native](https://supabase.com/docs/img/icons/expo-icon-light.svg)\\
\\
Expo React Native\\
\\
Learn how to build a user management app with Expo React Native and Supabase Database, Auth, and Storage functionality.](https://supabase.com/docs/guides/getting-started/tutorials/with-expo-react-native) [![Android Kotlin](https://supabase.com/docs/img/icons/kotlin-icon.svg)\\
\\
Android Kotlin\\
\\
Learn how to build a product management app with Android and Supabase Database, Auth, and Storage functionality.](https://supabase.com/docs/guides/getting-started/tutorials/with-kotlin) [![iOS Swift](https://supabase.com/docs/img/icons/swift-icon.svg)\\
\\
iOS Swift\\
\\
Learn how to build a user management app with iOS and Supabase Database, Auth, and Storage functionality.](https://supabase.com/docs/guides/getting-started/tutorials/with-swift) [![Ionic React](https://supabase.com/docs/img/icons/ionic-icon.svg)\\
\\
Ionic React\\
\\
Learn how to build a user management app with Ionic React and Supabase Database, Auth, and Storage functionality.](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-react) [![Ionic Vue](https://supabase.com/docs/img/icons/ionic-icon.svg)\\
\\
Ionic Vue\\
\\
Learn how to build a user management app with Ionic Vue and Supabase Database, Auth, and Storage functionality.](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-vue) [![Ionic Angular](https://supabase.com/docs/img/icons/ionic-icon.svg)\\
\\
Ionic Angular\\
\\
Learn how to build a user management app with Ionic Angular and Supabase Database, Auth, and Storage functionality.](https://supabase.com/docs/guides/getting-started/tutorials/with-ionic-angular)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_integrations_build_a_supabase_integration_oauth_scopes.md">
Integrations

# Scopes for your OAuth App

## Scopes let you specify the level of access your integration needs

* * *

Scopes are only available for OAuth apps. Check out [**our guide**](https://supabase.com/docs/guides/platform/oauth-apps/build-a-supabase-integration) to learn how to build an OAuth app integration.

Scopes restrict access to the specific [Supabase Management API endpoints](https://supabase.com/docs/reference/api/introduction) for OAuth tokens. All scopes can be specified as read and/or write.

Scopes are set when you [create an OAuth app](https://supabase.com/docs/guides/platform/oauth-apps/build-a-supabase-integration#create-an-oauth-app) in the Supabase Dashboard.

## Available scopes [\#](https://supabase.com/docs/guides/integrations/build-a-supabase-integration/oauth-scopes\#available-scopes)

| Name | Type | Description |
| --- | --- | --- |
| `Auth` | `Read` | Retrieve a project's auth configuration<br>Retrieve a project's SAML SSO providers |
| `Auth` | `Write` | Update a project's auth configuration<br>Create, update, or delete a project's SAML SSO providers |
| `Database` | `Read` | Retrieve the database configuration<br>Retrieve the pooler configuration<br>Retrieve SQL snippets<br>Check if the database is in read-only mode<br>Retrieve a database's SSL enforcement configuration<br>Retrieve a database's schema typescript types |
| `Database` | `Write` | Create a SQL query<br>Enable database webhooks on the project<br>Update the project's database configuration<br>Update the pooler configuration<br>Update a database's SSL enforcement configuration<br>Disable read-only mode for 15mins<br>Create a PITR backup for a database |
| `Domains` | `Read` | Retrieve the custom domains for a project<br>Retrieve the vanity subdomain configuration for a project |
| `Domains` | `Write` | Activate, initialize, reverify, or delete the custom domain for a project<br>Activate, delete or check the availability of a vanity subdomain for a project |
| `Edge Functions` | `Read` | Retrieve information about a project's edge functions |
| `Edge Functions` | `Write` | Create, update, or delete an edge function |
| `Environment` | `Read` | Retrieve branches in a project |
| `Environment` | `Write` | Create, update, or delete a branch |
| `Organizations` | `Read` | Retrieve an organization's metadata<br>Retrieve all members in an organization |
| `Organizations` | `Write` | N/A |
| `Projects` | `Read` | Retrieve a project's metadata<br>Check if a project's database is eligible for upgrade<br>Retrieve a project's network restrictions<br>Retrieve a project's network bans |
| `Projects` | `Write` | Create a project<br>Upgrade a project's database<br>Remove a project's network bans<br>Update a project's network restrictions |
| `Rest` | `Read` | Retrieve a project's PostgREST configuration |
| `Rest` | `Write` | Update a project's PostgREST configuration |
| `Secrets` | `Read` | Retrieve a project's API keys<br>Retrieve a project's secrets<br>Retrieve a project's pgsodium config |
| `Secrets` | `Write` | Create or update a project's secrets<br>Update a project's pgsodium configuration |

### Is this helpful?

NoYes

### On this page

[Available scopes](https://supabase.com/docs/guides/integrations/build-a-supabase-integration/oauth-scopes#available-scopes)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_integrations_build_a_supabase_integration.md">
Integrations

# Build a Supabase Integration (Beta)

## This guide steps through building a Supabase Integration using OAuth2 and the management API, allowing you to manage users' organizations and projects on their behalf.

* * *

Using OAuth2.0 you can retrieve an access and refresh token that grant your application full access to the [Management API](https://supabase.com/docs/reference/api/introduction) on behalf of the user.

## Create an OAuth app [\#](https://supabase.com/docs/guides/integrations/build-a-supabase-integration\#create-an-oauth-app)

1. In your organization's settings, navigate to the [**OAuth Apps**](https://supabase.com/dashboard/org/_/apps) tab.
2. In the upper-right section of the page, click **Add application**.
3. Fill in the required details and click **Confirm**.

## Show a "Connect Supabase" button [\#](https://supabase.com/docs/guides/integrations/build-a-supabase-integration\#show-a-connect-supabase-button)

In your user interface, add a "Connect Supabase" button to kick off the OAuth flow. Follow the design guidelines outlined in our [brand assets](https://supabase.com/brand-assets).

## Implementing the OAuth 2.0 flow [\#](https://supabase.com/docs/guides/integrations/build-a-supabase-integration\#implementing-the-oauth-20-flow)

Once you've published your OAuth App on Supabase, you can use the OAuth 2.0 protocol get authorization from Supabase users to manage their organizations and projects.

You can use your preferred OAuth2 client or follow the steps below. You can see an example implementation in TypeScript using Supabase Edge Functions [on our GitHub](https://github.com/supabase/supabase/tree/master/examples/edge-functions/supabase/functions/connect-supabase).

### Redirecting to the authorize URL [\#](https://supabase.com/docs/guides/integrations/build-a-supabase-integration\#redirecting-to-the-authorize-url)

Within your app's UI, redirect the user to [`https://api.supabase.com/v1/oauth/authorize`](https://api.supabase.com/api/v1#/oauth%20(beta)/authorize). Make sure to include all required query parameters such as:

- `client_id`: Your client id from the app creation above.
- `redirect_uri`: The URL where Supabase will redirect the user to after providing consent.
- `response_type`: Set this to `code`.
- `state`: Information about the state of your app. Note that `redirect_uri` and `state` together cannot exceed 4kB in size.
- (Recommended) PKCE: We strongly recommend using the PKCE flow for increased security. Generate a random value before taking the user to the authorize endpoint. This value is called code verifier. Hash it with SHA256 and include it as the `code_challenge` parameter, while setting `code_challenge_method` to `S256`. In the next step, you would need to provide the code verifier to get the first access and refresh token.
- \[deprecated\] `scope`: Scopes are configured when you create your OAuth app. Read the [docs](https://supabase.com/docs/guides/platform/oauth-apps/oauth-scopes) for more details.

`
router.get('/connect-supabase/login', async (ctx) => {
// Construct the URL for the authorization redirect and get a PKCE codeVerifier.
const { uri, codeVerifier } = await oauth2Client.code.getAuthorizationUri()
console.log(uri.toString())
// console.log: https://api.supabase.com/v1/oauth/authorize?response_type=code&client_id=7673bde9-be72-4d75-bd5e-b0dba2c49b38&redirect_uri=http%3A%2F%2Flocalhost%3A54321%2Ffunctions%2Fv1%2Fconnect-supabase%2Foauth2%2Fcallback&scope=all&code_challenge=jk06R69S1bH9dD4td8mS5kAEFmEbMP5P0YrmGNAUVE0&code_challenge_method=S256
// Store the codeVerifier in the user session (cookie).
ctx.state.session.flash('codeVerifier', codeVerifier)
// Redirect the user to the authorization endpoint.
ctx.response.redirect(uri)
})
`

Find the full example on [GitHub](https://github.com/supabase/supabase/tree/master/examples/edge-functions/supabase/functions/connect-supabase).

### Handling the callback [\#](https://supabase.com/docs/guides/integrations/build-a-supabase-integration\#handling-the-callback)

Once the user consents to providing API access to your OAuth App, Supabase will redirect the user to the `redirect_uri` provided in the previous step. The URL will contain these query parameters:

- `code`: An authorization code you should exchange with Supabase to get the access and refresh token.
- `state`: The value you provided in the previous step, to help you associate the request with the user. The `state` property returned here should be compared to the `state` you sent previously.

Exchange the authorization code for an access and refresh token by calling [`POST https://api.supabase.com/v1/oauth/token`](https://api.supabase.com/api/v1#/oauth%20(beta)/token) with the following query parameters as content-type `application/x-www-form-urlencoded`:

- `grant_type`: The value `authorization_code`.
- `code`: The `code` returned in the previous step.
- `redirect_uri`: This must be exactly the same URL used in the first step.
- (Recommended) `code_verifier`: If you used the PKCE flow in the first step, include the code verifier as `code_verifier`.

If your application need to support dynamically generated Redirect URLs, check out [Handling Dynamic Redirect URLs](https://supabase.com/docs/guides/integrations/build-a-supabase-integration#handling-dynamic-redirect-urls) section below.

As per OAuth2 spec, provide the client id and client secret as basic auth header:

- `client_id`: The unique client ID identifying your OAuth App.
- `client_secret`: The secret that authenticates your OAuth App to Supabase.

``
router.get('/connect-supabase/oauth2/callback', async (ctx) => {
// Make sure the codeVerifier is present for the user's session.
const codeVerifier = ctx.state.session.get('codeVerifier') as string
if (!codeVerifier) throw new Error('No codeVerifier!')
// Exchange the authorization code for an access token.
const tokens = await fetch(config.tokenUri, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/x-www-form-urlencoded',
      Accept: 'application/json',
      Authorization: `Basic ${btoa(`${config.clientId}:${config.clientSecret}`)}`,
    },
    body: new URLSearchParams({
      grant_type: 'authorization_code',
      code: ctx.request.url.searchParams.get('code') || '',
      redirect_uri: config.redirectUri,
      code_verifier: codeVerifier,
    }),
}).then((res) => res.json())
console.log('tokens', tokens)
// Store the tokens in your DB for future use.
ctx.response.body = 'Success'
})
``

Find the full example on [GitHub](https://github.com/supabase/supabase/tree/master/examples/edge-functions/supabase/functions/connect-supabase).

## Refreshing an access token [\#](https://supabase.com/docs/guides/integrations/build-a-supabase-integration\#refreshing-an-access-token)

You can use the [`POST /v1/oauth/token`](https://api.supabase.com/api/v1#/oauth%20(beta)/token) endpoint to refresh an access token using the refresh token returned at the end of the previous section.

If the user has revoked access to your application, you will not be able to refresh a token. Furthermore, access tokens will stop working. Make sure you handle HTTP Unauthorized errors when calling any Supabase API.

## Calling the Management API [\#](https://supabase.com/docs/guides/integrations/build-a-supabase-integration\#calling-the-management-api)

Refer to [the Management API reference](https://supabase.com/docs/reference/api/introduction#authentication) to learn more about authentication with the Management API.

### Use the JavaScript (TypeScript) SDK [\#](https://supabase.com/docs/guides/integrations/build-a-supabase-integration\#use-the-javascript-typescript-sdk)

For convenience, when working with JavaScript/TypeScript, you can use the [supabase-management-js](https://github.com/supabase-community/supabase-management-js#supabase-management-js) library.

`
import { SupabaseManagementAPI } from 'supabase-management-js'
const client = new SupabaseManagementAPI({ accessToken: '<access token>' })
`

## Integration recommendations [\#](https://supabase.com/docs/guides/integrations/build-a-supabase-integration\#integration-recommendations)

There are a couple common patterns you can consider adding to your integration that can facilitate a great user experience.

### Store API keys in env variables [\#](https://supabase.com/docs/guides/integrations/build-a-supabase-integration\#store-api-keys-in-env-variables)

Some integrations, e.g. like [Cloudflare Workers](https://supabase.com/partners/integrations/cloudflare-workers) provide convenient access to the API URL and API keys to allow user to speed up development.

Using the management API, you can retrieve a project's API credentials using the [`/projects/{ref}/api-keys` endpoint](https://api.supabase.com/api/v1#/projects/getProjectApiKeys).

### Pre-fill database connection details [\#](https://supabase.com/docs/guides/integrations/build-a-supabase-integration\#pre-fill-database-connection-details)

If your integration directly connects to the project's database, you can pref-fill the Postgres connection details for the user, it follows this schema:

`
postgresql://postgres:[DB-PASSWORD]@db.[REF].supabase.co:5432/postgres
`

Note that you cannot retrieve the database password via the management API, so for the user's existing projects you will need to collect their database password in your UI.

### Create new projects [\#](https://supabase.com/docs/guides/integrations/build-a-supabase-integration\#create-new-projects)

Use the [`/v1/projects` endpoint](https://api.supabase.com/api/v1#/projects/createProject) to create a new project.

When creating a new project, you can either ask the user to provide a database password, or you can generate a secure password for them. In any case, make sure to securely store the database password on your end which will allow you to construct the Postgres URI.

### Configure custom Auth SMTP [\#](https://supabase.com/docs/guides/integrations/build-a-supabase-integration\#configure-custom-auth-smtp)

You can configure the user's [custom SMTP settings](https://supabase.com/docs/guides/auth/auth-smtp) using the [`/config/auth` endpoint](https://api.supabase.com/api/v1#/projects%20config/updateV1AuthConfig).

### Handling dynamic redirect URLs [\#](https://supabase.com/docs/guides/integrations/build-a-supabase-integration\#handling-dynamic-redirect-urls)

To handle multiple, dynamically generated redirect URLs within the same OAuth app, you can leverage the `state` query parameter. When starting the OAuth process, include the desired, encoded redirect URL in the `state` parameter.
Once authorization is complete, we will sends the `state` value back to your app. You can then verify its integrity and extract the correct redirect URL, decoding it and redirecting the user to the correct URL.

## Current limitations [\#](https://supabase.com/docs/guides/integrations/build-a-supabase-integration\#current-limitations)

Only some features are available until we roll out fine-grained access control. If you need full database access, you will need to prompt the user for their database password.

### Is this helpful?

NoYes

### On this page

[Create an OAuth app](https://supabase.com/docs/guides/integrations/build-a-supabase-integration#create-an-oauth-app) [Show a "Connect Supabase" button](https://supabase.com/docs/guides/integrations/build-a-supabase-integration#show-a-connect-supabase-button) [Implementing the OAuth 2.0 flow](https://supabase.com/docs/guides/integrations/build-a-supabase-integration#implementing-the-oauth-20-flow) [Redirecting to the authorize URL](https://supabase.com/docs/guides/integrations/build-a-supabase-integration#redirecting-to-the-authorize-url) [Handling the callback](https://supabase.com/docs/guides/integrations/build-a-supabase-integration#handling-the-callback) [Refreshing an access token](https://supabase.com/docs/guides/integrations/build-a-supabase-integration#refreshing-an-access-token) [Calling the Management API](https://supabase.com/docs/guides/integrations/build-a-supabase-integration#calling-the-management-api) [Use the JavaScript (TypeScript) SDK](https://supabase.com/docs/guides/integrations/build-a-supabase-integration#use-the-javascript-typescript-sdk) [Integration recommendations](https://supabase.com/docs/guides/integrations/build-a-supabase-integration#integration-recommendations) [Store API keys in env variables](https://supabase.com/docs/guides/integrations/build-a-supabase-integration#store-api-keys-in-env-variables) [Pre-fill database connection details](https://supabase.com/docs/guides/integrations/build-a-supabase-integration#pre-fill-database-connection-details) [Create new projects](https://supabase.com/docs/guides/integrations/build-a-supabase-integration#create-new-projects) [Configure custom Auth SMTP](https://supabase.com/docs/guides/integrations/build-a-supabase-integration#configure-custom-auth-smtp) [Handling dynamic redirect URLs](https://supabase.com/docs/guides/integrations/build-a-supabase-integration#handling-dynamic-redirect-urls) [Current limitations](https://supabase.com/docs/guides/integrations/build-a-supabase-integration#current-limitations)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_integrations_supabase_marketplace.md">
Integrations

# Supabase Marketplace

* * *

The Supabase Marketplace brings together all the tools you need to extend your Supabase project. This includes:

- [Experts](https://supabase.com/partners/experts) \- partners to help you build and support your Supabase project.
- [Integrations](https://supabase.com/partners/integrations) \- extend your projects with external Auth, Caching, Hosting, and Low-code tools.

## Build an integration [\#](https://supabase.com/docs/guides/integrations/supabase-marketplace\#build-an-integration)

Supabase provides several integration points:

- The [Postgres connection](https://supabase.com/docs/guides/database/connecting-to-postgres). Anything that works with Postgres also works with Supabase projects.
- The [Project REST API](https://supabase.com/docs/guides/api#rest-api-overview) & client libraries.
- The [Project GraphQL API](https://supabase.com/docs/guides/api#graphql-api-overview).
- The [Platform API](https://supabase.com/docs/reference/api).

## List your integration [\#](https://supabase.com/docs/guides/integrations/supabase-marketplace\#list-your-integration)

[Apply to the Partners program](https://supabase.com/partners/integrations#become-a-partner) to list your integration in the Partners marketplace and in the Supabase docs.

Integrations are assessed on the following criteria:

- **Business viability**
While we welcome everyone to built an integration, we only list companies that are deemed to be long-term viable. This includes an official business registration and bank account, meaningful revenue, or Venture Capital backing. We require this criteria to ensure the health of the marketplace.
- **Compliance**
Integrations should not infringe on the Supabase brand/trademark. In short, you cannot use "Supabase" in the name. As the listing appears on the Supabase domain, we don't want to mislead developers into thinking that an integration is an official product.
- **Service Level Agreements**
All listings are required to have their own Terms and Conditions, Privacy Policy, and Acceptable Use Policy, and the company must have resources to meet their SLAs.
- **Maintainability**
All integrations are required to be maintained and functional with Supabase, and the company may be assessed on your ability to remain functional over a long time horizon.

### Is this helpful?

NoYes

### On this page

[Build an integration](https://supabase.com/docs/guides/integrations/supabase-marketplace#build-an-integration) [List your integration](https://supabase.com/docs/guides/integrations/supabase-marketplace#list-your-integration)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_integrations_vercel_marketplace.md">
Integrations

# Vercel Marketplace

* * *

## Overview [\#](https://supabase.com/docs/guides/integrations/vercel-marketplace\#overview)

The Vercel Marketplace is a feature that allows you to manage third-party resources, such as Supabase, directly from the Vercel platform. This integration offers a seamless experience with unified billing, streamlined authentication, and easy access management for your team.

When you create an organization and projects through Vercel Marketplace, they function just like those created directly within Supabase. However, the billing is handled through your Vercel account, and you can manage your resources directly from the Vercel dashboard or CLI. Additionally, environment variables are automatically synchronized, making them immediately available for your connected projects.

For more information, see [Introducing the Vercel Marketplace](https://vercel.com/blog/introducing-the-vercel-marketplace) blog post.

Vercel Marketplace is currently in Public Alpha. If you encounter any issues or have feature requests, [contact support](https://supabase.com/dashboard/support/new).

## Quickstart [\#](https://supabase.com/docs/guides/integrations/vercel-marketplace\#quickstart)

### Via template [\#](https://supabase.com/docs/guides/integrations/vercel-marketplace\#via-template)

##### Deploy a Next.js app with Supabase Vercel Storage now

Uses the Next.js Supabase Starter Template

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Fvercel%2Fnext.js%2Ftree%2Fcanary%2Fexamples%2Fhello-world)

### Via Vercel Marketplace [\#](https://supabase.com/docs/guides/integrations/vercel-marketplace\#via-vercel-marketplace)

Details coming soon..

### Connecting to Supabase project [\#](https://supabase.com/docs/guides/integrations/vercel-marketplace\#connecting-to-supabase-project)

Supabase Projects created via Vercel Marketplace are automatically synchronized with connected Vercel projects. This synchronization includes setting essential environment variables, such as:

`
POSTGRES_URL
POSTGRES_PRISMA_URL
POSTGRES_URL_NON_POOLING
POSTGRES_USER
POSTGRES_HOST
POSTGRES_PASSWORD
POSTGRES_DATABASE
SUPABASE_SERVICE_ROLE_KEY
SUPABASE_ANON_KEY
SUPABASE_URL
SUPABASE_JWT_SECRET
NEXT_PUBLIC_SUPABASE_ANON_KEY
NEXT_PUBLIC_SUPABASE_URL
`

These variables ensure your applications can connect securely to the database and interact with Supabase APIs.

## Studio support [\#](https://supabase.com/docs/guides/integrations/vercel-marketplace\#studio-support)

Accessing Supabase Studio is simple through the Vercel dashboard. You can open Supabase Studio from either the Integration installation page or the Vercel Storage page.
Depending on your entry point, you'll either land on the Supabase dashboard homepage or be redirected to the corresponding Supabase Project.

Supabase Studio provides tools such as:

- **SQL Editor:** Run SQL queries against your database.
- **Table Editor:** Create, edit, and delete tables and columns.
- **Log Explorer:** Inspect real-time logs for your database.
- **Postgres Upgrades:** Upgrade your Postgres instance to the latest version.
- **Compute Upgrades:** Scale the compute resources allocated to your database.

## Permissions [\#](https://supabase.com/docs/guides/integrations/vercel-marketplace\#permissions)

There is a direct one-to-one relationship between a Supabase Organization and a Vercel team. Installing the integration or launching your first Supabase Project through Vercel triggers the creation of a corresponding Supabase Organization if one doesnt already exist.

When Vercel users interact with Supabase, they are automatically assigned Supabase accounts. New users get a Supabase account linked to their primary email, while existing users have their Vercel and Supabase accounts linked.

- The user who initiates the creation of a Vercel Storage database is assigned the `owner` role in the new Supabase organization.
- Subsequent users are assigned roles based on their Vercel role, such as `developer` for `member` and `owner` for `owner`.

Role management is handled directly in the Vercel dashboard, and changes are synchronized with Supabase.

Note: you can invite non-Vercel users to your Supabase Organization, but their permissions won't be synchronized with Vercel.

## Pricing [\#](https://supabase.com/docs/guides/integrations/vercel-marketplace\#pricing)

Pricing for databases created through Vercel Marketplace is identical to those created directly within Supabase. Detailed pricing information is available on the [Supabase pricing page](https://supabase.com/pricing).

The [usage page](https://supabase.com/dashboard/org/_/usage) tracks the usage of your Vercel databases, with this information sent to Vercel for billing, which appears on your Vercel invoice.

Note: Supabase Organization billing cycle is separate from Vercel's. Plan changes will reset the billing cycle to the day of the change, with the initial billing cycle starting the day you install the integration.

## Limitations [\#](https://supabase.com/docs/guides/integrations/vercel-marketplace\#limitations)

When using Vercel Marketplace, the following limitations apply:

- Projects can only be created or removed via the Vercel dashboard.
- Organizations cannot be removed manually; they are removed only if you uninstall the Vercel Marketplace Integration.
- Owners cannot be added manually within the Supabase dashboard.
- Invoices and payments must be managed through the Vercel dashboard, not the Supabase dashboard.

### Is this helpful?

NoYes

### On this page

[Overview](https://supabase.com/docs/guides/integrations/vercel-marketplace#overview) [Quickstart](https://supabase.com/docs/guides/integrations/vercel-marketplace#quickstart) [Via template](https://supabase.com/docs/guides/integrations/vercel-marketplace#via-template) [Via Vercel Marketplace](https://supabase.com/docs/guides/integrations/vercel-marketplace#via-vercel-marketplace) [Connecting to Supabase project](https://supabase.com/docs/guides/integrations/vercel-marketplace#connecting-to-supabase-project) [Studio support](https://supabase.com/docs/guides/integrations/vercel-marketplace#studio-support) [Permissions](https://supabase.com/docs/guides/integrations/vercel-marketplace#permissions) [Pricing](https://supabase.com/docs/guides/integrations/vercel-marketplace#pricing) [Limitations](https://supabase.com/docs/guides/integrations/vercel-marketplace#limitations)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_integrations.md">
Integrations

# Integrations

* * *

Supabase integrates with many of your favorite third-party services.

## Vercel Marketplace [\#](https://supabase.com/docs/guides/integrations\#vercel-marketplace)

Create and manage your Supabase projects directly through Vercel. [Get started with Vercel](https://supabase.com/docs/guides/integrations/vercel-marketplace).

## Supabase Marketplace [\#](https://supabase.com/docs/guides/integrations\#supabase-marketplace)

Browse tools for extending your Supabase project. [Browse the Supabase Marketplace](https://supabase.com/partners/integrations).

### Is this helpful?

NoYes

### On this page

[Vercel Marketplace](https://supabase.com/docs/guides/integrations#vercel-marketplace) [Supabase Marketplace](https://supabase.com/docs/guides/integrations#supabase-marketplace)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_local_development_cli_getting_started.md">
Local Development

# Supabase CLI

## Develop locally, deploy to the Supabase Platform, and set up CI/CD workflows

* * *

The Supabase CLI enables you to run the entire Supabase stack locally, on your machine or in a CI environment. With just two commands, you can set up and start a new local project:

1. `supabase init` to create a new local project
2. `supabase start` to launch the Supabase services

## Installing the Supabase CLI [\#](https://supabase.com/docs/guides/local-development/cli/getting-started\#installing-the-supabase-cli)

macOSWindowsLinuxnpm / Bun

Install the CLI with [Homebrew](https://brew.sh/):

`
brew install supabase/tap/supabase
`

## Updating the Supabase CLI [\#](https://supabase.com/docs/guides/local-development/cli/getting-started\#updating-the-supabase-cli)

When a new [version](https://github.com/supabase/cli/releases) is released, you can update the CLI using the same methods.

macOSWindowsLinuxnpm / Bun

`
brew upgrade supabase
`

If you have any Supabase containers running locally, stop them and delete their data volumes before proceeding with the upgrade. This ensures that Supabase managed services can apply new migrations on a clean state of the local database.

##### Backup and stop running containers

Remember to save any local schema and data changes before stopping because the `--no-backup` flag will delete them.

`
supabase db diff -f my_schema
supabase db dump --local --data-only > supabase/seed.sql
supabase stop --no-backup
`

## Running Supabase locally [\#](https://supabase.com/docs/guides/local-development/cli/getting-started\#running-supabase-locally)

The Supabase CLI uses Docker containers to manage the local development stack. Follow the official guide to install and configure [Docker Desktop](https://docs.docker.com/desktop):

macOSWindows

![Docker settings on Mac: Select Integrated, Virtualization Framework, and osxfs](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fcli%2Fdocker-mac-light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

Alternately, you can use a different container tool that offers Docker compatible APIs.

- [Rancher Desktop](https://rancherdesktop.io/) (macOS, Windows, Linux)
- [Podman](https://podman.io/) (macOS, Windows, Linux)
- [OrbStack](https://orbstack.dev/) (macOS)
- [colima](https://github.com/abiosoft/colima) (macOS)

Inside the folder where you want to create your project, run:

`
supabase init
`

This will create a new `supabase` folder. It's safe to commit this folder to your version control system.

Now, to start the Supabase stack, run:

`
supabase start
`

This takes time on your first run because the CLI needs to download the Docker images to your local machine. The CLI includes the entire Supabase toolset, and a few additional images that are useful for local development (like a local SMTP server and a database diff tool).

## Access your project's services [\#](https://supabase.com/docs/guides/local-development/cli/getting-started\#access-your-projects-services)

Once all of the Supabase services are running, you'll see output containing your local Supabase credentials. It should look like this, with urls and keys that you'll use in your local project:

`
Started supabase local development setup.
         API URL: http://localhost:54321
          DB URL: postgresql://postgres:postgres@localhost:54322/postgres
      Studio URL: http://localhost:54323
    Inbucket URL: http://localhost:54324
        anon key: eyJh......
service_role key: eyJh......
`

StudioPostgresAPI GatewayAnalytics

`
# Default URL:
http://localhost:54323
`

The local development environment includes Supabase Studio, a graphical interface for working with your database.

![Local Studio](https://supabase.com/docs/img/guides/cli/local-studio.png)

## Stopping local services [\#](https://supabase.com/docs/guides/local-development/cli/getting-started\#stopping-local-services)

When you are finished working on your Supabase project, you can stop the stack (without resetting your local database):

`
supabase stop
`

## Learn more [\#](https://supabase.com/docs/guides/local-development/cli/getting-started\#learn-more)

- [CLI configuration](https://supabase.com/docs/guides/local-development/cli/config)
- [CLI reference](https://supabase.com/docs/reference/cli)

### Is this helpful?

NoYes

### On this page

[Installing the Supabase CLI](https://supabase.com/docs/guides/local-development/cli/getting-started#installing-the-supabase-cli) [Updating the Supabase CLI](https://supabase.com/docs/guides/local-development/cli/getting-started#updating-the-supabase-cli) [Running Supabase locally](https://supabase.com/docs/guides/local-development/cli/getting-started#running-supabase-locally) [Access your project's services](https://supabase.com/docs/guides/local-development/cli/getting-started#access-your-projects-services) [Stopping local services](https://supabase.com/docs/guides/local-development/cli/getting-started#stopping-local-services) [Learn more](https://supabase.com/docs/guides/local-development/cli/getting-started#learn-more)

![Docker settings on Mac: Select Integrated, Virtualization Framework, and osxfs](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fcli%2Fdocker-mac-light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_local_development_cli_testing_and_linting.md">
Local Development

# Testing and linting

## Using the CLI to test your Supabase project.

* * *

The Supabase CLI provides a set of tools to help you test and lint your Postgres database and Edge\` Functions.

## Testing your database [\#](https://supabase.com/docs/guides/local-development/cli/testing-and-linting\#testing-your-database)

The Supabase CLI provides Postgres linting using the `supabase test db` command.

`
supabase test db --help
Tests local database with pgTAP
Usage:
supabase test db [flags]
`

This is powered by the [pgTAP](https://supabase.com/docs/guides/database/extensions/pgtap) extension. You can find a full guide to writing and running tests in the [Testing your database](https://supabase.com/docs/guides/database/testing) section.

### Test helpers [\#](https://supabase.com/docs/guides/local-development/cli/testing-and-linting\#test-helpers)

Our friends at [Basejump](https://usebasejump.com/) have created a useful set of Database [Test Helpers](https://github.com/usebasejump/supabase-test-helpers), with an accompanying [blog post](https://usebasejump.com/blog/testing-on-supabase-with-pgtap).

### Running database tests in CI [\#](https://supabase.com/docs/guides/local-development/cli/testing-and-linting\#running-database-tests-in-ci)

Use our GitHub Action to [automate your database tests](https://supabase.com/docs/guides/cli/github-action/testing#testing-your-database).

## Testing your Edge Functions [\#](https://supabase.com/docs/guides/local-development/cli/testing-and-linting\#testing-your-edge-functions)

Edge Functions are powered by Deno, which provides a [native set of testing tools](https://deno.land/manual@v1.35.3/basics/testing). We extend this functionality in the Supabase CLI. You can find a detailed guide in the [Edge Functions section](https://supabase.com/docs/guides/functions/unit-test).

## Testing Auth emails [\#](https://supabase.com/docs/guides/local-development/cli/testing-and-linting\#testing-auth-emails)

The Supabase CLI uses [Inbucket](https://github.com/inbucket/inbucket) to capture emails sent from your local machine. This is useful for testing emails sent from Supabase Auth.

### Accessing Inbucket [\#](https://supabase.com/docs/guides/local-development/cli/testing-and-linting\#accessing-inbucket)

By default, Inbucket is available at [localhost:54324](http://localhost:54324/) when you run `supabase start`. Open this URL in your browser to view the emails.

### Going into production [\#](https://supabase.com/docs/guides/local-development/cli/testing-and-linting\#going-into-production)

The "default" email provided by Supabase is only for development purposes. It is [heavily restricted](https://supabase.com/docs/guides/platform/going-into-prod#auth-rate-limits) to ensure that it is not used for spam. Before going into production, you must configure your own email provider. This is as simple as enabling a new SMTP credentials in your [project settings](https://supabase.com/dashboard/project/_/settings/auth).

## Linting your database [\#](https://supabase.com/docs/guides/local-development/cli/testing-and-linting\#linting-your-database)

The Supabase CLI provides Postgres linting using the `supabase db lint` command:

`
supabase db lint --help
Checks local database for typing error
Usage:
supabase db lint [flags]
Flags:
  --level [ warning | error ] Error level to emit. (default warning)
  --linked Lints the linked project for schema errors.
  -s, --schema strings List of schema to include. (default all)
`

This is powered by [plpgsql\_check](https://github.com/okbob/plpgsql_check), which leverages the internal Postgres parser/evaluator so you see any errors that would occur at runtime. It provides the following features:

- validates you are using the correct types for function parameters
- identifies unused variables and function arguments
- detection of dead code (any code after an `RETURN` command)
- detection of missing `RETURN` commands with your Postgres function
- identifies unwanted hidden casts, which can be a performance issue
- checks `EXECUTE` statements against SQL injection vulnerability

Check the Reference Docs for [more information](https://supabase.com/docs/reference/cli/supabase-db-lint).

### Is this helpful?

NoYes

### On this page

[Testing your database](https://supabase.com/docs/guides/local-development/cli/testing-and-linting#testing-your-database) [Test helpers](https://supabase.com/docs/guides/local-development/cli/testing-and-linting#test-helpers) [Running database tests in CI](https://supabase.com/docs/guides/local-development/cli/testing-and-linting#running-database-tests-in-ci) [Testing your Edge Functions](https://supabase.com/docs/guides/local-development/cli/testing-and-linting#testing-your-edge-functions) [Testing Auth emails](https://supabase.com/docs/guides/local-development/cli/testing-and-linting#testing-auth-emails) [Accessing Inbucket](https://supabase.com/docs/guides/local-development/cli/testing-and-linting#accessing-inbucket) [Going into production](https://supabase.com/docs/guides/local-development/cli/testing-and-linting#going-into-production) [Linting your database](https://supabase.com/docs/guides/local-development/cli/testing-and-linting#linting-your-database)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_local_development_customizing_email_templates.md">
Local Development

# Customizing email templates

## Customizing local email templates using config.toml.

* * *

You can customize the email templates for local development [using the `config.toml` settings](https://supabase.com/docs/guides/cli/config#auth-config).

## Configuring templates [\#](https://supabase.com/docs/guides/local-development/customizing-email-templates\#configuring-templates)

You should provide a relative URL to the `content_path` parameter, pointing to an HTML file which contains the template. For example

supabase/config.toml

supabase/templates/invite.html

`
[auth.email.template.invite]
subject = "You are invited to Acme Inc"
content_path = "./supabase/templates/invite.html"
`

## Available email templates [\#](https://supabase.com/docs/guides/local-development/customizing-email-templates\#available-email-templates)

There are several Auth email templates which can be configured:

- `auth.email.template.invite`
- `auth.email.template.confirmation`
- `auth.email.template.recovery`
- `auth.email.template.magic_link`
- `auth.email.template.email_change`

## Template variables [\#](https://supabase.com/docs/guides/local-development/customizing-email-templates\#template-variables)

The templating system provides the following variables for use:

### `ConfirmationURL` [\#](https://supabase.com/docs/guides/local-development/customizing-email-templates\#confirmationurl)

Contains the confirmation URL. For example, a signup confirmation URL would look like:

`
https://project-ref.supabase.co/auth/v1/verify?token={{ .TokenHash }}&type=email&redirect_to=https://example.com/path
`

**Usage**

`
<p>Click here to confirm: {{ .ConfirmationURL }}</p>
`

### `Token` [\#](https://supabase.com/docs/guides/local-development/customizing-email-templates\#token)

Contains a 6-digit One-Time-Password (OTP) that can be used instead of the `ConfirmationURL`.

**Usage**

`
<p>Here is your one time password: {{ .Token }}</p>
`

### `TokenHash` [\#](https://supabase.com/docs/guides/local-development/customizing-email-templates\#tokenhash)

Contains a hashed version of the `Token`. This is useful for constructing your own email link in the email template.

**Usage**

`
<p>Follow this link to confirm your user:</p>
<p>
<a href="{{ .SiteURL }}/auth/confirm?token_hash={{ .TokenHash }}&type=email"
    >Confirm your email</a
>
</p>
`

### `SiteURL` [\#](https://supabase.com/docs/guides/local-development/customizing-email-templates\#siteurl)

Contains your application's Site URL. This can be configured in your project's [authentication settings](https://supabase.com/dashboard/project/_/auth/url-configuration).

**Usage**

`
<p>Visit <a href="{{ .SiteURL }}">here</a> to log in.</p>
`

### `Email` [\#](https://supabase.com/docs/guides/local-development/customizing-email-templates\#email)

Contains the user's email address.

**Usage**

`
<p>A recovery request was sent to {{ .Email }}.</p>
`

### `NewEmail` [\#](https://supabase.com/docs/guides/local-development/customizing-email-templates\#newemail)

Contains the new user's email address. This is only available in the `email_change` email template.

**Usage**

`
<p>You are requesting to update your email address to {{ .NewEmail }}.</p>
`

## Deploying email templates [\#](https://supabase.com/docs/guides/local-development/customizing-email-templates\#deploying-email-templates)

These settings are for local development. To apply the changes locally, stop and restart the Supabase containers:

`
supabase stop && supabase start
`

For hosted projects managed by Supabase, copy the templates into the [Email Templates](https://supabase.com/dashboard/project/_/auth/templates) section of the Dashboard.

### Is this helpful?

NoYes

### On this page

[Configuring templates](https://supabase.com/docs/guides/local-development/customizing-email-templates#configuring-templates) [Available email templates](https://supabase.com/docs/guides/local-development/customizing-email-templates#available-email-templates) [Template variables](https://supabase.com/docs/guides/local-development/customizing-email-templates#template-variables) [ConfirmationURL](https://supabase.com/docs/guides/local-development/customizing-email-templates#confirmationurl) [Token](https://supabase.com/docs/guides/local-development/customizing-email-templates#token) [TokenHash](https://supabase.com/docs/guides/local-development/customizing-email-templates#tokenhash) [SiteURL](https://supabase.com/docs/guides/local-development/customizing-email-templates#siteurl) [Email](https://supabase.com/docs/guides/local-development/customizing-email-templates#email) [NewEmail](https://supabase.com/docs/guides/local-development/customizing-email-templates#newemail) [Deploying email templates](https://supabase.com/docs/guides/local-development/customizing-email-templates#deploying-email-templates)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_local_development_declarative_database_schemas.md">
Local Development

# Declarative database schemas

## Manage your database schemas in one place and generate versioned migrations.

* * *

## Overview [\#](https://supabase.com/docs/guides/local-development/declarative-database-schemas\#overview)

Declarative schemas allow you to reduce code duplications in managing [schema migrations](https://supabase.com/docs/guides/local-development/overview#database-migrations). As your database schema evolves over time, declaring it in one place will help you iterate faster by referring to a single source of truth.

## Schema migrations [\#](https://supabase.com/docs/guides/local-development/declarative-database-schemas\#schema-migrations)

Schema migrations are SQL statements written in Data Definition Language. They are versioned in your `supabase/migrations` directory to ensure schema consistency between local and remote environments.

### Declaring your schema [\#](https://supabase.com/docs/guides/local-development/declarative-database-schemas\#declaring-your-schema)

1

### Create your first schema file

Create a SQL file in `supabase/schemas` directory that defines an `employees` table.

supabase/schemas/employees.sql

`
create table "employees" (
"id" integer not null,
"name" text
);
`

2

### Generate a migration file

Generate a migration file by diffing against your declared schema.

Terminal

`
supabase db diff -f employees_table
`

Make sure your local database is stopped before diffing your schema.

3

### Start the local database

The new migration file will be used when starting the database locally so you can validate your schema using the local Dashboard.

Terminal

`
supabase start
`

### Updating your schema [\#](https://supabase.com/docs/guides/local-development/declarative-database-schemas\#updating-your-schema)

1

### Stop the local database

Before updating your schema files, stop the local development environment.

Terminal

`
supabase stop
`

2

### Add a new column

Edit `supabase/schemas/employees.sql` file to add a new column to `employees` table.

supabase/schemas/employees.sql

`
create table "employees" (
"id" integer not null,
"name" text,
"age" smallint not null
);
`

Some entities like views and enums expect columns to be declared in a specific order. To avoid messy diffs, always append new columns to the end of the table.

3

### Generate a new migration

Diff existing migrations against your declared schema.

Terminal

`
supabase db diff -f add_age
`

4

### Review the generated migration

Verify that the generated migration contain a single incremental change.

supabase/migrations/<timestamp>\_add\_age.sql

`
alter table "public"."employees" add column "age" smallint not null;
`

5

### Apply the pending migration

Start the database locally and apply the pending migration.

Terminal

`
supabase start && supabase migration up
`

### Managing dependencies [\#](https://supabase.com/docs/guides/local-development/declarative-database-schemas\#managing-dependencies)

As your database schema evolves, you will probably start using more advanced entities like views and functions. These entities are notoriously verbose to manage using plain migrations because the entire body must be recreated whenever there is a change. Using declarative schema, you can now edit them in-place so its much easier to review.

supabase/schemas/employees.sql

`
create table "employees" (
"id" integer not null,
"name" text,
"age" smallint not null
);
create view "profiles" as
select id, name from "employees";
create function "get_age"(employee_id integer) RETURNS smallint
LANGUAGE "sql"
AS $$
select age
from employees
where id = employee_id;
$$;
`

Your schema files are run in lexicographic order by default. The order is important when you have foreign keys between multiple tables as the parent table must be created first. For example, your `supabase` directory may end up with the following structure.

`
.
 supabase/
     schemas/
        employees.sql
        managers.sql
     migrations/
         20241004112233_employees_table.sql
         20241005112233_add_employee_age.sql
         20241006112233_add_managers_table.sql
`

For small projects with only a few tables, the default schema order may be sufficient. However, as your project grows, you might need more control over the order in which schemas are applied. To specify a custom order for applying the schemas, you can declare them explicitly in `config.toml`. Any glob patterns will evaluated, deduplicated, and sorted in lexicographic order. For example, the following pattern ensures `employees.sql` is always executed first.

supabase/config.toml

`
[db.migrations]
schema_paths = [\
"./schemas/employees.sql",\
"./schemas/*.sql",\
]
`

### Pulling in your production schema [\#](https://supabase.com/docs/guides/local-development/declarative-database-schemas\#pulling-in-your-production-schema)

To set up declarative schemas on a existing project, you can pull in your production schema by running:

Terminal

`
supabase db dump > supabase/schemas/prod.sql
`

From there, you can start breaking down your schema into smaller files and generate migrations. You can do this all at once, or incrementally as you make changes to your schema.

## Known caveats [\#](https://supabase.com/docs/guides/local-development/declarative-database-schemas\#known-caveats)

The `migra` diff tool used for generating schema diff is capable of tracking most database changes. However, there are edge cases where it can fail.

If you need to use any of the entities below, remember to add them through [versioned migrations](https://supabase.com/docs/guides/deployment/database-migrations) instead.

### Data manipulation language [\#](https://supabase.com/docs/guides/local-development/declarative-database-schemas\#data-manipulation-language)

- DML statements such as `insert`, `update`, `delete`, etc., are not captured by schema diff

### View ownership [\#](https://supabase.com/docs/guides/local-development/declarative-database-schemas\#view-ownership)

- [view owner and grants](https://github.com/djrobstep/migra/issues/160#issuecomment-1702983833)
- [security invoker on views](https://github.com/djrobstep/migra/issues/234)
- [materialized views](https://github.com/djrobstep/migra/issues/194)
- doesnt recreate views when altering column type

### RLS policies [\#](https://supabase.com/docs/guides/local-development/declarative-database-schemas\#rls-policies)

- [alter policy statements](https://github.com/djrobstep/schemainspect/blob/master/schemainspect/pg/obj.py#L228)
- [column privileges](https://github.com/djrobstep/schemainspect/pull/67)

### Other entities [\#](https://supabase.com/docs/guides/local-development/declarative-database-schemas\#other-entities)

- schema privileges are not tracked because each schema is diffed separately
- [comments are not tracked](https://github.com/djrobstep/migra/issues/69)
- [partitions are not tracked](https://github.com/djrobstep/migra/issues/186)
- [`alter publication ... add table ...`](https://github.com/supabase/cli/issues/883)
- [create domain statements are ignored](https://github.com/supabase/cli/issues/2137)
- [grant statements are duplicated from default privileges](https://github.com/supabase/cli/issues/1864)

### Is this helpful?

NoYes

### On this page

[Overview](https://supabase.com/docs/guides/local-development/declarative-database-schemas#overview) [Schema migrations](https://supabase.com/docs/guides/local-development/declarative-database-schemas#schema-migrations) [Declaring your schema](https://supabase.com/docs/guides/local-development/declarative-database-schemas#declaring-your-schema) [Updating your schema](https://supabase.com/docs/guides/local-development/declarative-database-schemas#updating-your-schema) [Managing dependencies](https://supabase.com/docs/guides/local-development/declarative-database-schemas#managing-dependencies) [Pulling in your production schema](https://supabase.com/docs/guides/local-development/declarative-database-schemas#pulling-in-your-production-schema) [Known caveats](https://supabase.com/docs/guides/local-development/declarative-database-schemas#known-caveats) [Data manipulation language](https://supabase.com/docs/guides/local-development/declarative-database-schemas#data-manipulation-language) [View ownership](https://supabase.com/docs/guides/local-development/declarative-database-schemas#view-ownership) [RLS policies](https://supabase.com/docs/guides/local-development/declarative-database-schemas#rls-policies) [Other entities](https://supabase.com/docs/guides/local-development/declarative-database-schemas#other-entities)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_local_development_managing_config.md">
Local Development

# Managing config and secrets

* * *

The Supabase CLI uses a `config.toml` file to manage local configuration. This file is located in the `supabase` directory of your project.

## Config reference [\#](https://supabase.com/docs/guides/local-development/managing-config\#config-reference)

The `config.toml` file is automatically created when you run `supabase init`.

There are a wide variety of options available, which can be found in the [CLI Config Reference](https://supabase.com/docs/guides/cli/config).

For example, to enable the "Apple" OAuth provider for local development, you can append the following information to `config.toml`:

`
[auth.external.apple]
enabled = false
client_id = ""
secret = ""
redirect_uri = "" # Overrides the default auth redirectUrl.
`

## Using secrets inside config.toml [\#](https://supabase.com/docs/guides/local-development/managing-config\#using-secrets-inside-configtoml)

You can reference environment variables within the `config.toml` file using the `env()` function. This will detect any values stored in an `.env` file at the root of your project directory. This is particularly useful for storing sensitive information like API keys, and any other values that you don't want to check into version control.

`
.
 .env
 .env.example
 supabase
     config.toml
`

Do NOT commit your `.env` into git. Be sure to configure your `.gitignore` to exclude this file.

For example, if your `.env` contained the following values:

`
GITHUB_CLIENT_ID=""
GITHUB_SECRET=""
`

Then you would reference them inside of our `config.toml` like this:

`
[auth.external.github]
enabled = true
client_id = "env(GITHUB_CLIENT_ID)"
secret = "env(GITHUB_SECRET)"
redirect_uri = "" # Overrides the default auth redirectUrl.
`

### Is this helpful?

NoYes

### On this page

[Config reference](https://supabase.com/docs/guides/local-development/managing-config#config-reference) [Using secrets inside config.toml](https://supabase.com/docs/guides/local-development/managing-config#using-secrets-inside-configtoml)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_local_development_overview.md">
Local Development

# Local development with schema migrations

## Develop locally with the Supabase CLI and schema migrations.

* * *

Supabase is a flexible platform that lets you decide how you want to build your projects. You can use the Dashboard directly to get up and running quickly, or use a proper local setup. We suggest you work locally and deploy your changes to a linked project on the [Supabase Platform](https://app.supabase.io/).

Develop locally using the CLI to run a local Supabase stack. You can use the integrated Studio Dashboard to make changes, then capture your changes in schema migration files, which can be saved in version control.

Alternatively, if you're comfortable with migration files and SQL, you can write your own migrations and push them to the local database for testing before sharing your changes.

## Database migrations [\#](https://supabase.com/docs/guides/local-development/overview\#database-migrations)

Database changes are managed through "migrations." Database migrations are a common way of tracking changes to your database over time.

How to Manage Database Migration Using Supabase CLI - SupabaseTips - YouTube

Supabase

45.5K subscribers

[How to Manage Database Migration Using Supabase CLI - SupabaseTips](https://www.youtube.com/watch?v=Kx5nHBmIxyQ)

Supabase

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=Kx5nHBmIxyQ "Watch on YouTube")

For this guide, we'll create a table called `employees` and see how we can make changes to it.

1

### Create your first migration file

To get started, generate a [new migration](https://supabase.com/docs/reference/cli/supabase-migration-new) to store the SQL needed to create our `employees` table

`
supabase migration new create_employees_table
`

2

### Add the SQL to your migration file

This creates a new migration: supabase/migrations/<timestamp>
\_create\_employees\_table.sql.

To that file, add the SQL to create this `employees` table

`
create table
employees (
id bigint primary key generated always as identity,
name text,
email text,
created_at timestamptz default now()
);
`

3

### Apply your migration

Now that you have a migration file, you can run this migration and create the `employees` table.

Use the `reset` command here to reset the database to the current migrations

`
supabase db reset
`

4

### Modify your employees table

Now you can visit your new `employees` table in the Dashboard.

Next, modify your `employees` table by adding a column for department. Create a new migration file for that.

`
supabase migration new add_department_to_employees_table
`

5

### Add a new column to your table

This creates a new migration file: supabase/migrations/<timestamp>
\_add\_department\_to\_employees\_table.sql.

To that file, add the SQL to create a new department column

`
alter table
if exists public.employees add department text default 'Hooli';
`

### Add sample data [\#](https://supabase.com/docs/guides/local-development/overview\#add-sample-data)

Now that you are managing your database with migrations scripts, it would be great have some seed data to use every time you reset the database.

For this, you can create a seed script in `supabase/seed.sql`.

1

### Populate your table

Insert data into your `employees` table with your `supabase/seed.sql` file.

`
-- in supabase/seed.sql
insert into
public.employees (name)
values
('Erlich Bachman'),
('Richard Hendricks'),
('Monica Hall');
`

2

### Reset your database

Reset your database (apply current migrations), and populate with seed data

`
supabase db reset
`

You should now see the `employees` table, along with your seed data in the Dashboard! All of your database changes are captured in code, and you can reset to a known state at any time, complete with seed data.

### Diffing changes [\#](https://supabase.com/docs/guides/local-development/overview\#diffing-changes)

This workflow is great if you know SQL and are comfortable creating tables and columns. If not, you can still use the Dashboard to create tables and columns, and then use the CLI to diff your changes and create migrations.

Create a new table called `cities`, with columns `id`, `name` and `population`. To see the corresponding SQL for this, you can use the `supabase db diff --schema public` command. This will show you the SQL that will be run to create the table and columns. The output of `supabase db diff` will look something like this:

`
Diffing schemas: public
Finished supabase db diff on branch main.
create table "public"."cities" (
    "id" bigint primary key generated always as identity,
    "name" text,
    "population" bigint
);
`

Alternately, you can view your table definitions directly from the Table Editor:

![SQL Definition](https://supabase.com/docs/img/guides/cli/sql-definitions.png)

You can then copy this SQL into a new migration file, and run `supabase db reset` to apply the changes.

The last step is deploying these changes to a live Supabase project.

## Deploy your project [\#](https://supabase.com/docs/guides/local-development/overview\#deploy-your-project)

You've been developing your project locally, making changes to your tables via migrations. It's time to deploy your project to the Supabase Platform and start scaling up to millions of users! Head over to [Supabase](https://supabase.com/dashboard) and create a new project to deploy to.

### Log in to the Supabase CLI [\#](https://supabase.com/docs/guides/local-development/overview\#log-in-to-the-supabase-cli)

Terminal

npx

`
supabase login
`

### Link your project [\#](https://supabase.com/docs/guides/local-development/overview\#link-your-project)

Associate your project with your remote project using [`supabase link`](https://supabase.com/docs/reference/cli/usage#supabase-link).

`
supabase link --project-ref <project-id>
# You can get <project-id> from your project's dashboard URL: https://supabase.com/dashboard/project/<project-id>
supabase db pull
# Capture any changes that you have made to your remote database before you went through the steps above
# If you have not made any changes to the remote database, skip this step
`

`supabase/migrations` is now populated with a migration in `<timestamp>_remote_schema.sql`.
This migration captures any changes required for your local database to match the schema of your remote Supabase project.

Review the generated migration file and once happy, apply the changes to your local instance:

`
# To apply the new migration to your local database:
supabase migration up
# To reset your local database completely:
supabase db reset
`

There are a few commands required to link your project. We are in the process of consolidating these commands into a single command. Bear with us!

### Deploy database changes [\#](https://supabase.com/docs/guides/local-development/overview\#deploy-database-changes)

Deploy any local database migrations using [`db push`](https://supabase.com/docs/reference/cli/usage#supabase-db-push):

`
supabase db push
`

Visiting your live project on [Supabase](https://supabase.com/dashboard), you'll see a new `employees` table, complete with the `department` column you added in the second migration above.

### Deploy Edge Functions [\#](https://supabase.com/docs/guides/local-development/overview\#deploy-edge-functions)

If your project uses Edge Functions, you can deploy these using [`functions deploy`](https://supabase.com/docs/reference/cli/usage#supabase-functions-deploy):

`
supabase functions deploy <function_name>
`

### Use Auth locally [\#](https://supabase.com/docs/guides/local-development/overview\#use-auth-locally)

To use Auth locally, update your project's `supabase/config.toml` file that gets created after running `supabase init`. Add any providers you want, and set enabled to `true`.

supabase/config.toml

`
[auth.external.github]
enabled = true
client_id = "env(SUPABASE_AUTH_GITHUB_CLIENT_ID)"
secret = "env(SUPABASE_AUTH_GITHUB_SECRET)"
redirect_uri = "http://localhost:54321/auth/v1/callback"
`

As a best practice, any secret values should be loaded from environment variables. You can add them to `.env` file in your project's root directory for the CLI to automatically substitute them.

.env

`
SUPABASE_AUTH_GITHUB_CLIENT_ID="redacted"
SUPABASE_AUTH_GITHUB_SECRET="redacted"
`

For these changes to take effect, you need to run `supabase stop` and `supabase start` again.

If you have additional triggers or RLS policies defined on your `auth` schema, you can pull them as a migration file locally.

`
supabase db pull --schema auth
`

### Sync storage buckets [\#](https://supabase.com/docs/guides/local-development/overview\#sync-storage-buckets)

Your RLS policies on storage buckets can be pulled locally by specifying `storage` schema. For example,

`
supabase db pull --schema storage
`

The buckets and objects themselves are rows in the storage tables so they won't appear in your schema. You can instead define them via `supabase/config.toml` file. For example,

supabase/config.toml

`
[storage.buckets.images]
public = false
file_size_limit = "50MiB"
allowed_mime_types = ["image/png", "image/jpeg"]
objects_path = "./images"
`

This will upload files from `supabase/images` directory to a bucket named `images` in your project with one command.

`
supabase seed buckets
`

### Sync any schema with `--schema` [\#](https://supabase.com/docs/guides/local-development/overview\#sync-any-schema-with---schema)

You can synchronize your database with a specific schema using the `--schema` option as follows:

`
supabase db pull --schema <schema_name>
`

Using `--schema`

If the local `supabase/migrations` directory is empty, the `db pull` command will ignore the `--schema` parameter.

To fix this, you can pull twice:

`
supabase db pull
supabase db pull --schema <schema_name>
`

## Limitations and considerations [\#](https://supabase.com/docs/guides/local-development/overview\#limitations-and-considerations)

The local development environment is not as feature-complete as the Supabase Platform. Here are some of the differences:

- You cannot update your project settings in the Dashboard. This must be done using the local config file.
- The CLI version determines the local version of Studio used, so make sure you keep your local [Supabase CLI up to date](https://github.com/supabase/cli#getting-started). We're constantly adding new features and bug fixes.

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2FvyHyYpvjaks%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Database migrations](https://supabase.com/docs/guides/local-development/overview#database-migrations) [Add sample data](https://supabase.com/docs/guides/local-development/overview#add-sample-data) [Diffing changes](https://supabase.com/docs/guides/local-development/overview#diffing-changes) [Deploy your project](https://supabase.com/docs/guides/local-development/overview#deploy-your-project) [Log in to the Supabase CLI](https://supabase.com/docs/guides/local-development/overview#log-in-to-the-supabase-cli) [Link your project](https://supabase.com/docs/guides/local-development/overview#link-your-project) [Deploy database changes](https://supabase.com/docs/guides/local-development/overview#deploy-database-changes) [Deploy Edge Functions](https://supabase.com/docs/guides/local-development/overview#deploy-edge-functions) [Use Auth locally](https://supabase.com/docs/guides/local-development/overview#use-auth-locally) [Sync storage buckets](https://supabase.com/docs/guides/local-development/overview#sync-storage-buckets) [Sync any schema with --schema](https://supabase.com/docs/guides/local-development/overview#sync-any-schema-with---schema) [Limitations and considerations](https://supabase.com/docs/guides/local-development/overview#limitations-and-considerations)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_local_development_seeding_your_database.md">
Local Development

# Seeding your database

## Populate your database with initial data for reproducible environments across local and testing.

* * *

## What is seed data? [\#](https://supabase.com/docs/guides/local-development/seeding-your-database\#what-is-seed-data)

Seeding is the process of populating a database with initial data, typically used to provide sample or default records for testing and development purposes. You can use this to create "reproducible environments" for local development, staging, and production.

## Using seed files [\#](https://supabase.com/docs/guides/local-development/seeding-your-database\#using-seed-files)

Seed files are executed every time you run `supabase start` or `supabase db reset`. Seeding occurs _after_ all database migrations have been completed. As a best practice, only include data insertions in your seed files, and avoid adding schema statements.

By default, if no specific configuration is provided, the system will look for a seed file matching the pattern `supabase/seed.sql`. This maintains backward compatibility with earlier versions, where the seed file was placed in the `supabase` folder.

You can add any SQL statements to this file. For example:

`
insert into countries
(name, code)
values
('United States', 'US'),
('Canada', 'CA'),
('Mexico', 'MX');
`

If you want to manage multiple seed files or organize them across different folders, you can configure additional paths or glob patterns in your `config.toml` (see the [next section](https://supabase.com/docs/guides/local-development/seeding-your-database#splitting-up-your-seed-data) for details).

### Splitting up your seed file [\#](https://supabase.com/docs/guides/local-development/seeding-your-database\#splitting-up-your-seed-file)

For better modularity and maintainability, you can split your seed data into multiple files. For example, you can organize your seeds by table and include files such as `countries.sql` and `cities.sql`. Configure them in `config.toml` like so:

supabase/config.toml

`
[db.seed]
enabled = true
sql_paths = ['./countries.sql', './cities.sql']
`

Or to include all `.sql` files under a specific folder you can do:

supabase/config.toml

`
[db.seed]
enabled = true
sql_paths = ['./seeds/*.sql']
`

The CLI processes seed files in the order they are declared in the `sql_paths` array. If a glob pattern is used and matches multiple files, those files are sorted in lexicographic order to ensure consistent execution. Additionally:

- The base folder for the pattern matching is `supabase` so `./countries.sql` will search for `supabase/countries.sql`
- Files matched by multiple patterns will be deduplicated to prevent redundant seeding.
- If a pattern does not match any files, a warning will be logged to help you troubleshoot potential configuration issues.

## Generating seed data [\#](https://supabase.com/docs/guides/local-development/seeding-your-database\#generating-seed-data)

You can generate seed data for local development using [Snaplet](https://github.com/snaplet/seed).

To use Snaplet, you need to have Node.js and npm installed. You can add Node.js to your project by running `npm init -y` in your project directory.

If this is your first time using Snaplet to seed your project, you'll need to set up Snaplet with the following command:

`
npx @snaplet/seed init
`

This command will analyze your database and its structure, and then generate a JavaScript client which can be used to define exactly how your data should be generated using code. The `init` command generates a configuration file, `seed.config.ts` and an example script, `seed.ts`, as a starting point.

During `init` if you are not using an Object Relational Mapper (ORM) or your ORM is not in the supported list, choose `node-postgres`.

In most cases you only want to generate data for specific schemas or tables. This is defined with `select`. Here is an example `seed.config.ts` configuration file:

`
export default defineConfig({
adapter: async () => {
    const client = new Client({
      connectionString: 'postgresql://postgres:postgres@localhost:54322/postgres',
    })
    await client.connect()
    return new SeedPg(client)
},
// We only want to generate data for the public schema
select: ['!*', 'public.*'],
})
`

Suppose you have a database with the following schema:

![An example schema](https://supabase.com/docs/img/guides/cli/snaplet-example-schema.png)

You can use the seed script example generated by Snaplet `seed.ts` to define the values you want to generate. For example:

- A `Post` with the title `"There is a lot of snow around here!"`
- The `Post.createdBy` user with an email address ending in `"@acme.org"`
- Three `Post.comments` from three different users.

seed.ts

`
import { createSeedClient } from '@snaplet/seed'
import { copycat } from '@snaplet/copycat'
async function main() {
const seed = await createSeedClient({ dryRun: true })
await seed.Post([\
    {\
      title: 'There is a lot of snow around here!',\
      createdBy: {\
        email: (ctx) =>\
          copycat.email(ctx.seed, {\
            domain: 'acme.org',\
          }),\
      },\
      Comment: (x) => x(3),\
    },\
])
process.exit()
}
main()
`

Running `npx tsx seed.ts > supabase/seed.sql` generates the relevant SQL statements inside your `supabase/seed.sql` file:

``
-- The `Post.createdBy` user with an email address ending in `"@acme.org"`
INSERT INTO "User" (name, email) VALUES ("John Snow", "snow@acme.org")
--- A `Post` with the title `"There is a lot of snow around here!"`
INSERT INTO "Post" (title, content, createdBy) VALUES (
"There is a lot of snow around here!",
"Lorem ipsum dolar",
1)
--- Three `Post.Comment` from three different users.
INSERT INTO "User" (name, email) VALUES ("Stephanie Shadow", "shadow@domain.com")
INSERT INTO "Comment" (text, userId, postId) VALUES ("I love cheese", 2, 1)
INSERT INTO "User" (name, email) VALUES ("John Rambo", "rambo@trymore.dev")
INSERT INTO "Comment" (text, userId, postId) VALUES ("Lorem ipsum dolar sit", 3, 1)
INSERT INTO "User" (name, email) VALUES ("Steven Plank", "s@plank.org")
INSERT INTO "Comment" (text, userId, postId) VALUES ("Actually, that's not correct...", 4, 1)
``

Whenever your database structure changes, you will need to regenerate `@snaplet/seed` to keep it in sync with the new structure. You can do this by running:

`
npx @snaplet/seed sync
`

You can further enhance your seed script by using Large Language Models to generate more realistic data. To enable this feature, set one of the following environment variables in your `.env` file:

`
OPENAI_API_KEY=<your_openai_api_key>
GROQ_API_KEY=<your_groq_api_key>
`

After setting the environment variables, run the following commands to sync and generate the seed data:

`
npx @snaplet/seed sync
npx tsx seed.ts > supabase/seed.sql
`

For more information, check out Snaplet's [seed documentation](https://snaplet-seed.netlify.app/seed/integrations/supabase)

### Is this helpful?

NoYes

### On this page

[What is seed data?](https://supabase.com/docs/guides/local-development/seeding-your-database#what-is-seed-data) [Using seed files](https://supabase.com/docs/guides/local-development/seeding-your-database#using-seed-files) [Splitting up your seed file](https://supabase.com/docs/guides/local-development/seeding-your-database#splitting-up-your-seed-file) [Generating seed data](https://supabase.com/docs/guides/local-development/seeding-your-database#generating-seed-data)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_local_development_testing_overview.md">
Local Development

# Testing Overview

* * *

Testing is a critical part of database development, especially when working with features like Row Level Security (RLS) policies. This guide provides a comprehensive approach to testing your Supabase database.

## Testing approaches [\#](https://supabase.com/docs/guides/local-development/testing/overview\#testing-approaches)

### Database unit testing with pgTAP [\#](https://supabase.com/docs/guides/local-development/testing/overview\#database-unit-testing-with-pgtap)

[pgTAP](https://pgtap.org/) is a unit testing framework for Postgres that allows testing:

- Database structure: tables, columns, constraints
- Row Level Security (RLS) policies
- Functions and procedures
- Data integrity

This example demonstrates setting up and testing RLS policies for a simple todo application:

1. Create a test table with RLS enabled:



`
   -- Create a simple todos table
create table todos (
id uuid primary key default gen_random_uuid(),
task text not null,
user_id uuid references auth.users not null,
completed boolean default false
);
   -- Enable RLS
alter table todos enable row level security;
   -- Create a policy
create policy "Users can only access their own todos"
on todos for all -- this policy applies to all operations
to authenticated
using ((select auth.uid()) = user_id);
`

2. Set up your testing environment:



`
# Create a new test for our policies using supabase cli
supabase test new todos_rls.test
`

3. Write your RLS tests:



`
begin;
   -- install tests utilities
   -- install pgtap extension for testing
create extension if not exists pgtap with schema extensions;
   -- Start declare we'll have 4 test cases in our test suite
select plan(4);
   -- Setup our testing data
   -- Set up auth.users entries
insert into auth.users (id, email) values
   	('123e4567-e89b-12d3-a456-426614174000', 'user1@test.com'),
   	('987fcdeb-51a2-43d7-9012-345678901234', 'user2@test.com');
   -- Create test todos
insert into public.todos (task, user_id) values
   	('User 1 Task 1', '123e4567-e89b-12d3-a456-426614174000'),
   	('User 1 Task 2', '123e4567-e89b-12d3-a456-426614174000'),
   	('User 2 Task 1', '987fcdeb-51a2-43d7-9012-345678901234');
   -- as User 1
set local role authenticated;
set local request.jwt.claim.sub = '123e4567-e89b-12d3-a456-426614174000';
   -- Test 1: User 1 should only see their own todos
select results_eq(
   	'select count(*) from todos',
   	ARRAY[2::bigint],
   	'User 1 should only see their 2 todos'
);
   -- Test 2: User 1 can create their own todo
select lives_ok(
   	$$insert into todos (task, user_id) values ('New Task', '123e4567-e89b-12d3-a456-426614174000'::uuid)$$,
   	'User 1 can create their own todo'
);
   -- as User 2
set local request.jwt.claim.sub = '987fcdeb-51a2-43d7-9012-345678901234';
   -- Test 3: User 2 should only see their own todos
select results_eq(
   	'select count(*) from todos',
   	ARRAY[1::bigint],
   	'User 2 should only see their 1 todo'
);
   -- Test 4: User 2 cannot modify User 1's todo
SELECT results_ne(
   	$$ update todos set task = 'Hacked!' where user_id = '123e4567-e89b-12d3-a456-426614174000'::uuid returning 1 $$,
   	$$ values(1) $$,
   	'User 2 cannot modify User 1 todos'
);
select * from finish();
rollback;
`

4. Run the tests:



`
supabase test db
psql:todos_rls.test.sql:4: NOTICE:  extension "pgtap" already exists, skipping
./todos_rls.test.sql .. ok
All tests successful.
Files=1, Tests=6,  0 wallclock secs ( 0.01 usr +  0.00 sys =  0.01 CPU)
Result: PASS
`


### Application-Level testing [\#](https://supabase.com/docs/guides/local-development/testing/overview\#application-level-testing)

Testing through application code provides end-to-end verification. Unlike database-level testing with pgTAP, application-level tests cannot use transactions for isolation.

Application-level tests should not rely on a clean database state, as resetting the database before each test can be slow and makes tests difficult to parallelize.
Instead, design your tests to be independent by using unique user IDs for each test case.

Here's an example using TypeScript that mirrors the pgTAP tests above:

``
import { createClient } from '@supabase/supabase-js'
import { beforeAll, describe, expect, it } from 'vitest'
import crypto from 'crypto'
describe('Todos RLS', () => {
// Generate unique IDs for this test suite to avoid conflicts with other tests
const USER_1_ID = crypto.randomUUID()
const USER_2_ID = crypto.randomUUID()
const supabase = createClient(process.env.SUPABASE_URL!, process.env.SUPABASE_ANON_KEY!)
beforeAll(async () => {
    // Setup test data specific to this test suite
    const adminSupabase = createClient(process.env.SUPABASE_URL!, process.env.SERVICE_ROLE_KEY!)
    // Create test users with unique IDs
    await adminSupabase.auth.admin.createUser({
      id: USER_1_ID,
      email: `user1-${USER_1_ID}@test.com`,
      password: 'password123',
      // We want the user to be usable right away without email confirmation
      email_confirm: true,
    })
    await adminSupabase.auth.admin.createUser({
      id: USER_2_ID,
      email: `user2-${USER_2_ID}@test.com`,
      password: 'password123',
      email_confirm: true,
    })
    // Create initial todos
    await adminSupabase.from('todos').insert([\
      { task: 'User 1 Task 1', user_id: USER_1_ID },\
      { task: 'User 1 Task 2', user_id: USER_1_ID },\
      { task: 'User 2 Task 1', user_id: USER_2_ID },\
    ])
})
it('should allow User 1 to only see their own todos', async () => {
    // Sign in as User 1
    await supabase.auth.signInWithPassword({
      email: `user1-${USER_1_ID}@test.com`,
      password: 'password123',
    })
    const { data: todos } = await supabase.from('todos').select('*')
    expect(todos).toHaveLength(2)
    todos?.forEach((todo) => {
      expect(todo.user_id).toBe(USER_1_ID)
    })
})
it('should allow User 1 to create their own todo', async () => {
    await supabase.auth.signInWithPassword({
      email: `user1-${USER_1_ID}@test.com`,
      password: 'password123',
    })
    const { error } = await supabase.from('todos').insert({ task: 'New Task', user_id: USER_1_ID })
    expect(error).toBeNull()
})
it('should allow User 2 to only see their own todos', async () => {
    // Sign in as User 2
    await supabase.auth.signInWithPassword({
      email: `user2-${USER_2_ID}@test.com`,
      password: 'password123',
    })
    const { data: todos } = await supabase.from('todos').select('*')
    expect(todos).toHaveLength(1)
    todos?.forEach((todo) => {
      expect(todo.user_id).toBe(USER_2_ID)
    })
})
it('should prevent User 2 from modifying User 1 todos', async () => {
    await supabase.auth.signInWithPassword({
      email: `user2-${USER_2_ID}@test.com`,
      password: 'password123',
    })
    // Attempt to update the todos we shouldn't have access to
    // result will be a no-op
    await supabase.from('todos').update({ task: 'Hacked!' }).eq('user_id', USER_1_ID)
    // Log back in as User 1 to verify their todos weren't changed
    await supabase.auth.signInWithPassword({
      email: `user1-${USER_1_ID}@test.com`,
      password: 'password123',
    })
    // Fetch User 1's todos
    const { data: todos } = await supabase.from('todos').select('*')
    // Verify that none of the todos were changed to "Hacked!"
    expect(todos).toBeDefined()
    todos?.forEach((todo) => {
      expect(todo.task).not.toBe('Hacked!')
    })
})
})
``

#### Test isolation strategies [\#](https://supabase.com/docs/guides/local-development/testing/overview\#test-isolation-strategies)

For application-level testing, consider these approaches for test isolation:

1. **Unique Identifiers**: Generate unique IDs for each test suite to prevent data conflicts
2. **Cleanup After Tests**: If necessary, clean up created data in an `afterAll` or `afterEach` hook
3. **Isolated Data Sets**: Use prefixes or namespaces in data to separate test cases

### Continuous integration testing [\#](https://supabase.com/docs/guides/local-development/testing/overview\#continuous-integration-testing)

Set up automated database testing in your CI pipeline:

1. Create a GitHub Actions workflow `.github/workflows/db-tests.yml`:

`
name: Database Tests
on:
push:
    branches: [main]
pull_request:
    branches: [main]
jobs:
test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Setup Supabase CLI
        uses: supabase/setup-cli@v1
      - name: Start Supabase
        run: supabase start
      - name: Run Tests
        run: supabase test db
`

## Best practices [\#](https://supabase.com/docs/guides/local-development/testing/overview\#best-practices)

1. **Test Data Setup**
   - Use begin and rollback to ensure test isolation
   - Create realistic test data that covers edge cases
   - Use different user roles and permissions in tests
2. **RLS Policy Testing**
   - Test Create, Read, Update, Delete operations
   - Test with different user roles: anonymous and authenticated
   - Test edge cases and potential security bypasses
   - Always test negative cases: what users should not be able to do
3. **CI/CD Integration**
   - Run tests automatically on every pull request
   - Include database tests in deployment pipeline
   - Keep test runs fast using transactions

## Real-World examples [\#](https://supabase.com/docs/guides/local-development/testing/overview\#real-world-examples)

For more complex, real-world examples of database testing, check out:

- [Database Tests Example Repository](https://github.com/usebasejump/basejump/tree/main/supabase/tests/database) \- A production-grade example of testing RLS policies
- [RLS Guide and Best Practices](https://github.com/orgs/supabase/discussions/14576)

## Troubleshooting [\#](https://supabase.com/docs/guides/local-development/testing/overview\#troubleshooting)

Common issues and solutions:

1. **Test Failures Due to RLS**
   - Ensure you've set the correct role `set local role authenticated;`
   - Verify JWT claims are set `set local "request.jwt.claims"`
   - Check policy definitions match your test assumptions
2. **CI Pipeline Issues**
   - Verify Supabase CLI is properly installed
   - Ensure database migrations are run before tests
   - Check for proper test isolation using transactions

## Additional resources [\#](https://supabase.com/docs/guides/local-development/testing/overview\#additional-resources)

- [pgTAP Documentation](https://pgtap.org/)
- [Supabase CLI Reference](https://supabase.com/docs/reference/cli/supabase-test)
- [pgTAP Supabase reference](https://supabase.com/docs/guides/database/extensions/pgtap?queryGroups=database-method&database-method=sql#testing-rls-policies)
- [Database testing reference](https://supabase.com/docs/guides/database/testing)

### Is this helpful?

NoYes

### On this page

[Testing approaches](https://supabase.com/docs/guides/local-development/testing/overview#testing-approaches) [Database unit testing with pgTAP](https://supabase.com/docs/guides/local-development/testing/overview#database-unit-testing-with-pgtap) [Application-Level testing](https://supabase.com/docs/guides/local-development/testing/overview#application-level-testing) [Continuous integration testing](https://supabase.com/docs/guides/local-development/testing/overview#continuous-integration-testing) [Best practices](https://supabase.com/docs/guides/local-development/testing/overview#best-practices) [Real-World examples](https://supabase.com/docs/guides/local-development/testing/overview#real-world-examples) [Troubleshooting](https://supabase.com/docs/guides/local-development/testing/overview#troubleshooting) [Additional resources](https://supabase.com/docs/guides/local-development/testing/overview#additional-resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_local_development_testing_pgtap_extended.md">
Local Development

# Advanced pgTAP Testing

* * *

While basic pgTAP provides excellent testing capabilities, you can enhance the testing workflow using database development tools and helper packages. This guide covers advanced testing techniques using database.dev and community-maintained test helpers.

## Using database.dev [\#](https://supabase.com/docs/guides/local-development/testing/pgtap-extended\#using-databasedev)

[Database.dev](https://database.dev/) is a package manager for Postgres that allows installation and use of community-maintained packages, including testing utilities.

### Setting up dbdev [\#](https://supabase.com/docs/guides/local-development/testing/pgtap-extended\#setting-up-dbdev)

To use database development tools and packages, install some prerequisites:

`
create extension if not exists http with schema extensions;
create extension if not exists pg_tle;
drop extension if exists "supabase-dbdev";
select pgtle.uninstall_extension_if_exists('supabase-dbdev');
select
    pgtle.install_extension(
        'supabase-dbdev',
        resp.contents ->> 'version',
        'PostgreSQL package manager',
        resp.contents ->> 'sql'
    )
from http(
    (
        'GET',
        'https://api.database.dev/rest/v1/'
        || 'package_versions?select=sql,version'
        || '&package_name=eq.supabase-dbdev'
        || '&order=version.desc'
        || '&limit=1',
        array[\
            ('apiKey', 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InhtdXB0cHBsZnZpaWZyYndtbXR2Iiwicm9sZSI6ImFub24iLCJpYXQiOjE2ODAxMDczNzIsImV4cCI6MTk5NTY4MzM3Mn0.z2CN0mvO2No8wSi46Gw59DFGCTJrzM0AQKsu_5k134s')::http_header\
        ],
        null,
        null
    )
) x,
lateral (
    select
        ((row_to_json(x) -> 'content') #>> '{}')::json -> 0
) resp(contents);
create extension "supabase-dbdev";
select dbdev.install('supabase-dbdev');
-- Drop and recreate the extension to ensure a clean installation
drop extension if exists "supabase-dbdev";
create extension "supabase-dbdev";
`

### Installing test helpers [\#](https://supabase.com/docs/guides/local-development/testing/pgtap-extended\#installing-test-helpers)

The Test Helpers package provides utilities that simplify testing Supabase-specific features:

`
select dbdev.install('basejump-supabase_test_helpers');
create extension if not exists "basejump-supabase_test_helpers" version '0.0.6';
`

## Test helper benefits [\#](https://supabase.com/docs/guides/local-development/testing/pgtap-extended\#test-helper-benefits)

The test helpers package provides several advantages over writing raw pgTAP tests:

1. **Simplified User Management**
   - Create test users with `tests.create_supabase_user()`
   - Switch contexts with `tests.authenticate_as()`
   - Retrieve user IDs using `tests.get_supabase_uid()`
2. **Row Level Security (RLS) Testing Utilities**
   - Verify RLS status with `tests.rls_enabled()`
   - Test policy enforcement
   - Simulate different user contexts
3. **Reduced Boilerplate**
   - No need to manually insert auth.users
   - Simplified JWT claim management
   - Clean test setup and cleanup

## Schema-wide Row Level Security testing [\#](https://supabase.com/docs/guides/local-development/testing/pgtap-extended\#schema-wide-row-level-security-testing)

When working with Row Level Security, it's crucial to ensure that RLS is enabled on all tables that need it. Create a simple test to verify RLS is enabled across an entire schema:

`
begin;
select plan(1);
-- Verify RLS is enabled on all tables in the public schema
select tests.rls_enabled('public');
select * from finish();
rollback;
`

## Test file organization [\#](https://supabase.com/docs/guides/local-development/testing/pgtap-extended\#test-file-organization)

When working with multiple test files that share common setup requirements, it's beneficial to create a single "pre-test" file that handles the global environment setup. This approach reduces duplication and ensures consistent test environments.

### Creating a pre-test hook [\#](https://supabase.com/docs/guides/local-development/testing/pgtap-extended\#creating-a-pre-test-hook)

Since pgTAP test files are executed in alphabetical order, create a setup file that runs first by using a naming convention like `000-setup-tests-hooks.sql`:

`
supabase test new 000-setup-tests-hooks
`

This setup file should contain:

1. All shared extensions and dependencies
2. Common test utilities
3. A simple always green test to verify the setup

Here's an example setup file:

`
-- install tests utilities
-- install pgtap extension for testing
create extension if not exists pgtap with schema extensions;
/*
---------------------
---- install dbdev ----
----------------------
Requires:
  - pg_tle: https://github.com/aws/pg_tle
  - pgsql-http: https://github.com/pramsey/pgsql-http
*/
create extension if not exists http with schema extensions;
create extension if not exists pg_tle;
drop extension if exists "supabase-dbdev";
select pgtle.uninstall_extension_if_exists('supabase-dbdev');
select
    pgtle.install_extension(
        'supabase-dbdev',
        resp.contents ->> 'version',
        'PostgreSQL package manager',
        resp.contents ->> 'sql'
    )
from http(
    (
        'GET',
        'https://api.database.dev/rest/v1/'
        || 'package_versions?select=sql,version'
        || '&package_name=eq.supabase-dbdev'
        || '&order=version.desc'
        || '&limit=1',
        array[\
            ('apiKey', 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InhtdXB0cHBsZnZpaWZyYndtbXR2Iiwicm9sZSI6ImFub24iLCJpYXQiOjE2ODAxMDczNzIsImV4cCI6MTk5NTY4MzM3Mn0.z2CN0mvO2No8wSi46Gw59DFGCTJrzM0AQKsu_5k134s')::http_header\
        ],
        null,
        null
    )
) x,
lateral (
    select
        ((row_to_json(x) -> 'content') #>> '{}')::json -> 0
) resp(contents);
create extension "supabase-dbdev";
select dbdev.install('supabase-dbdev');
drop extension if exists "supabase-dbdev";
create extension "supabase-dbdev";
-- Install test helpers
select dbdev.install('basejump-supabase_test_helpers');
create extension if not exists "basejump-supabase_test_helpers" version '0.0.6';
-- Verify setup with a no-op test
begin;
select plan(1);
select ok(true, 'Pre-test hook completed successfully');
select * from finish();
rollback;
`

### Benefits [\#](https://supabase.com/docs/guides/local-development/testing/pgtap-extended\#benefits)

This approach provides several advantages:

- Reduces code duplication across test files
- Ensures consistent test environment setup
- Makes it easier to maintain and update shared dependencies
- Provides immediate feedback if the setup process fails

Your subsequent test files ( `001-auth-tests.sql`, `002-rls-tests.sql`) can focus solely on their specific test cases, knowing that the environment is properly configured.

## Example: Advanced RLS testing [\#](https://supabase.com/docs/guides/local-development/testing/pgtap-extended\#example-advanced-rls-testing)

Here's a complete example using test helpers to verify RLS policies putting it all together:

`
begin;
-- Assuming 000-setup-tests-hooks.sql file is present to use tests helpers
select plan(4);
-- Set up test data
-- Create test supabase users
select tests.create_supabase_user('user1@test.com');
select tests.create_supabase_user('user2@test.com');
-- Create test data
insert into public.todos (task, user_id) values
('User 1 Task 1', tests.get_supabase_uid('user1@test.com')),
('User 1 Task 2', tests.get_supabase_uid('user1@test.com')),
('User 2 Task 1', tests.get_supabase_uid('user2@test.com'));
-- Test as User 1
select tests.authenticate_as('user1@test.com');
-- Test 1: User 1 should only see their own todos
select results_eq(
'select count(*) from todos',
ARRAY[2::bigint],
'User 1 should only see their 2 todos'
);
-- Test 2: User 1 can create their own todo
select lives_ok(
$$insert into todos (task, user_id) values ('New Task', tests.get_supabase_uid('user1@test.com'))$$,
'User 1 can create their own todo'
);
-- Test as User 2
select tests.authenticate_as('user2@test.com');
-- Test 3: User 2 should only see their own todos
select results_eq(
'select count(*) from todos',
ARRAY[1::bigint],
'User 2 should only see their 1 todo'
);
-- Test 4: User 2 cannot modify User 1's todo
SELECT results_ne(
    $$ update todos set task = 'Hacked!' where user_id = tests.get_supabase_uid('user1@test.com') returning 1 $$,
    $$ values(1) $$,
    'User 2 cannot modify User 1 todos'
);
select * from finish();
rollback;
`

## Not another todo app: Testing complex organizations [\#](https://supabase.com/docs/guides/local-development/testing/pgtap-extended\#not-another-todo-app-testing-complex-organizations)

Todo apps are great for learning, but this section explores testing a more realistic scenario: a multi-tenant content publishing platform. This example demonstrates testing complex permissions, plan restrictions, and content management.

### System overview [\#](https://supabase.com/docs/guides/local-development/testing/pgtap-extended\#system-overview)

This demo app implements:

- Organizations with tiered plans (free/pro/enterprise)
- Role-based access (owner/admin/editor/viewer)
- Content management (posts/comments)
- Premium content restrictions
- Plan-based limitations

### What makes this complex? [\#](https://supabase.com/docs/guides/local-development/testing/pgtap-extended\#what-makes-this-complex)

1. **Layered Permissions**
   - Role hierarchies affect access rights
   - Plan types influence user capabilities
   - Content state (draft/published) affects permissions
2. **Business Rules**
   - Free plan post limits
   - Premium content visibility
   - Cross-organization security

### Testing focus areas [\#](https://supabase.com/docs/guides/local-development/testing/pgtap-extended\#testing-focus-areas)

When writing tests, verify:

- Organization member access control
- Content visibility across roles
- Plan limitation enforcement
- Cross-organization data isolation

#### 1\. App schema definitions [\#](https://supabase.com/docs/guides/local-development/testing/pgtap-extended\#1-app-schema-definitions)

The app schema tables are defined like this:

`
create table public.profiles (
id uuid references auth.users(id) primary key,
username text unique not null,
full_name text,
bio text,
created_at timestamptz default now(),
updated_at timestamptz default now()
);
create table public.organizations (
id bigint primary key generated always as identity,
name text not null,
slug text unique not null,
plan_type text not null check (plan_type in ('free', 'pro', 'enterprise')),
max_posts int not null default 5,
created_at timestamptz default now()
);
create table public.org_members (
org_id bigint references public.organizations(id) on delete cascade,
user_id uuid references auth.users(id) on delete cascade,
role text not null check (role in ('owner', 'admin', 'editor', 'viewer')),
created_at timestamptz default now(),
primary key (org_id, user_id)
);
create table public.posts (
id bigint primary key generated always as identity,
title text not null,
content text not null,
author_id uuid references public.profiles(id) not null,
org_id bigint references public.organizations(id),
status text not null check (status in ('draft', 'published', 'archived')),
is_premium boolean default false,
scheduled_for timestamptz,
category text,
view_count int default 0,
published_at timestamptz,
created_at timestamptz default now(),
updated_at timestamptz default now()
);
create table public.comments (
id bigint primary key generated always as identity,
post_id bigint references public.posts(id) on delete cascade,
author_id uuid references public.profiles(id),
content text not null,
is_deleted boolean default false,
created_at timestamptz default now(),
updated_at timestamptz default now()
);
`

#### 2\. RLS policies declaration [\#](https://supabase.com/docs/guides/local-development/testing/pgtap-extended\#2-rls-policies-declaration)

Now to setup the RLS policies for each tables:

`
-- Create a private schema to store all security definer functions utils
-- As such functions should never be in a API exposed schema
create schema if not exists private;
-- Helper function for role checks
create or replace function private.get_user_org_role(org_id bigint, user_id uuid)
returns text
set search_path = ''
as $$
select role from public.org_members
where org_id = $1 and user_id = $2;
-- Note the use of security definer to avoid RLS checking recursion issue
-- see: https://supabase.com/docs/guides/database/postgres/row-level-security#use-security-definer-functions
$$ language sql security definer;
-- Helper utils to check if an org is below the max post limit
create or replace function private.can_add_post(org_id bigint)
returns boolean
set search_path = ''
as $$
select (select count(*)
          from public.posts p
          where p.org_id = $1) < o.max_posts
from public.organizations o
where o.id = $1
$$ language sql security definer;
-- Enable RLS for all tables
alter table public.profiles enable row level security;
alter table public.organizations enable row level security;
alter table public.org_members enable row level security;
alter table public.posts enable row level security;
alter table public.comments enable row level security;
-- Profiles policies
create policy "Public profiles are viewable by everyone"
on public.profiles for select using (true);
create policy "Users can insert their own profile"
on public.profiles for insert with check ((select auth.uid()) = id);
create policy "Users can update their own profile"
on public.profiles for update using ((select auth.uid()) = id)
with check ((select auth.uid()) = id);
-- Organizations policies
create policy "Public org info visible to all"
on public.organizations for select using (true);
create policy "Org management restricted to owners"
on public.organizations for all using (
    private.get_user_org_role(id, (select auth.uid())) = 'owner'
);
-- Org Members policies
create policy "Members visible to org members"
on public.org_members for select using (
    private.get_user_org_role(org_id, (select auth.uid())) is not null
);
create policy "Member management restricted to admins and owners"
on public.org_members for all using (
    private.get_user_org_role(org_id, (select auth.uid())) in ('owner', 'admin')
);
-- Posts policies
create policy "Complex post visibility"
on public.posts for select using (
    -- Published non-premium posts are visible to all
    (status = 'published' and not is_premium)
    or
    -- Premium posts visible to org members only
    (status = 'published' and is_premium and
    private.get_user_org_role(org_id, (select auth.uid())) is not null)
    or
    -- All posts visible to editors and above
    private.get_user_org_role(org_id, (select auth.uid())) in ('owner', 'admin', 'editor')
);
create policy "Post creation rules"
on public.posts for insert with check (
    -- Must be org member with appropriate role
    private.get_user_org_role(org_id, (select auth.uid())) in ('owner', 'admin', 'editor')
    and
    -- Check org post limits for free plans
    (
      (select o.plan_type != 'free'
      from organizations o
      where o.id = org_id)
      or
      (select private.can_add_post(org_id))
    )
);
create policy "Post update rules"
on public.posts for update using (
    exists (
      select 1
      where
        -- Editors can update non-published posts
        (private.get_user_org_role(org_id, (select auth.uid())) = 'editor' and status != 'published')
        or
        -- Admins and owners can update any post
        private.get_user_org_role(org_id, (select auth.uid())) in ('owner', 'admin')
    )
);
-- Comments policies
create policy "Comments on published posts are viewable by everyone"
on public.comments for select using (
    exists (
      select 1 from public.posts
      where id = post_id
      and status = 'published'
    )
    and not is_deleted
);
create policy "Authenticated users can create comments"
on public.comments for insert with check ((select auth.uid()) = author_id);
create policy "Users can update their own comments"
on public.comments for update using (author_id = (select auth.uid()));
`

#### 3\. Test cases: [\#](https://supabase.com/docs/guides/local-development/testing/pgtap-extended\#3-test-cases)

Now everything is setup, let's write RLS test cases, note that each section could be in its own test:

`
-- Assuming we already have: 000-setup-tests-hooks.sql file we can use tests helpers
begin;
-- Declare total number of tests
select plan(10);
-- Create test users
select tests.create_supabase_user('org_owner', 'owner@test.com');
select tests.create_supabase_user('org_admin', 'admin@test.com');
select tests.create_supabase_user('org_editor', 'editor@test.com');
select tests.create_supabase_user('premium_user', 'premium@test.com');
select tests.create_supabase_user('free_user', 'free@test.com');
select tests.create_supabase_user('scheduler', 'scheduler@test.com');
select tests.create_supabase_user('free_author', 'free_author@test.com');
-- Create profiles for test users
insert into profiles (id, username, full_name)
values
(tests.get_supabase_uid('org_owner'), 'org_owner', 'Organization Owner'),
(tests.get_supabase_uid('org_admin'), 'org_admin', 'Organization Admin'),
(tests.get_supabase_uid('org_editor'), 'org_editor', 'Organization Editor'),
(tests.get_supabase_uid('premium_user'), 'premium_user', 'Premium User'),
(tests.get_supabase_uid('free_user'), 'free_user', 'Free User'),
(tests.get_supabase_uid('scheduler'), 'scheduler', 'Scheduler User'),
(tests.get_supabase_uid('free_author'), 'free_author', 'Free Author');
-- First authenticate as service role to bypass RLS for initial setup
select tests.authenticate_as_service_role();
-- Create test organizations and setup data
with new_org as (
insert into organizations (name, slug, plan_type, max_posts)
values
    ('Test Org', 'test-org', 'pro', 100),
    ('Premium Org', 'premium-org', 'enterprise', 1000),
    ('Schedule Org', 'schedule-org', 'pro', 100),
    ('Free Org', 'free-org', 'free', 2)
returning id, slug
),
-- Setup members and posts
member_setup as (
insert into org_members (org_id, user_id, role)
select
    org.id,
    user_id,
    role
from new_org org cross join (
    values
      (tests.get_supabase_uid('org_owner'), 'owner'),
      (tests.get_supabase_uid('org_admin'), 'admin'),
      (tests.get_supabase_uid('org_editor'), 'editor'),
      (tests.get_supabase_uid('premium_user'), 'viewer'),
      (tests.get_supabase_uid('scheduler'), 'editor'),
      (tests.get_supabase_uid('free_author'), 'editor')
) as members(user_id, role)
where org.slug = 'test-org'
     or (org.slug = 'premium-org' and role = 'viewer')
     or (org.slug = 'schedule-org' and role = 'editor')
     or (org.slug = 'free-org' and role = 'editor')
)
-- Setup initial posts
insert into posts (title, content, org_id, author_id, status, is_premium, scheduled_for)
select
title,
content,
org.id,
author_id,
status,
is_premium,
scheduled_for
from new_org org cross join (
values
    ('Premium Post', 'Premium content', tests.get_supabase_uid('premium_user'), 'published', true, null),
    ('Free Post', 'Free content', tests.get_supabase_uid('premium_user'), 'published', false, null),
    ('Future Post', 'Future content', tests.get_supabase_uid('scheduler'), 'published', false, '2024-01-02 12:00:00+00'::timestamptz)
) as posts(title, content, author_id, status, is_premium, scheduled_for)
where org.slug in ('premium-org', 'schedule-org');
-- Test owner privileges
select tests.authenticate_as('org_owner');
select lives_ok(
$$
    update organizations
    set name = 'Updated Org'
    where id = (select id from organizations limit 1)
$$,
'Owner can update organization'
);
-- Test admin privileges
select tests.authenticate_as('org_admin');
select results_eq(
    $$select count(*) from org_members$$,
    ARRAY[6::bigint],
    'Admin can view all members'
);
-- Test editor restrictions
select tests.authenticate_as('org_editor');
select throws_ok(
$$
    insert into org_members (org_id, user_id, role)
    values (
      (select id from organizations limit 1),
      (select tests.get_supabase_uid('org_editor')),
      'viewer'
    )
$$,
'42501',
'new row violates row-level security policy for table "org_members"',
'Editor cannot manage members'
);
-- Premium Content Access Tests
select tests.authenticate_as('premium_user');
select results_eq(
    $$select count(*) from posts where org_id = (select id from organizations where slug = 'premium-org')$$,
    ARRAY[3::bigint],
    'Premium user can see all posts'
);
select tests.clear_authentication();
select results_eq(
    $$select count(*) from posts where org_id = (select id from organizations where slug = 'premium-org')$$,
    ARRAY[2::bigint],
    'Anonymous users can only see free posts'
);
-- Time-Based Publishing Tests
select tests.authenticate_as('scheduler');
select tests.freeze_time('2024-01-01 12:00:00+00'::timestamptz);
select results_eq(
    $$select count(*) from posts where scheduled_for > now() and org_id = (select id from organizations where slug = 'schedule-org')$$,
    ARRAY[1::bigint],
    'Can see scheduled posts'
);
select tests.freeze_time('2024-01-02 13:00:00+00'::timestamptz);
select results_eq(
    $$select count(*) from posts where scheduled_for < now() and org_id = (select id from organizations where slug = 'schedule-org')$$,
    ARRAY[1::bigint],
    'Can see posts after schedule time'
);
select tests.unfreeze_time();
-- Plan Limit Tests
select tests.authenticate_as('free_author');
select lives_ok(
$$
    insert into posts (title, content, org_id, author_id, status)
    select 'Post 1', 'Content 1', id, auth.uid(), 'draft'
    from organizations where slug = 'free-org' limit 1
$$,
'First post creates successfully'
);
select lives_ok(
$$
    insert into posts (title, content, org_id, author_id, status)
    select 'Post 2', 'Content 2', id, auth.uid(), 'draft'
    from organizations where slug = 'free-org' limit 1
$$,
'Second post creates successfully'
);
select throws_ok(
$$
    insert into posts (title, content, org_id, author_id, status)
    select 'Post 3', 'Content 3', id, auth.uid(), 'draft'
    from organizations where slug = 'free-org' limit 1
$$,
'42501',
'new row violates row-level security policy for table "posts"',
'Cannot exceed free plan post limit'
);
select * from finish();
rollback;
`

## Additional resources [\#](https://supabase.com/docs/guides/local-development/testing/pgtap-extended\#additional-resources)

- [Test Helpers Documentation](https://database.dev/basejump/supabase_test_helpers)
- [Test Helpers Reference](https://github.com/usebasejump/supabase-test-helpers)
- [Row Level Security Writing Guide](https://usebasejump.com/blog/testing-on-supabase-with-pgtap)
- [Database.dev Package Registry](https://database.dev/)
- [Row Level Security Performance and Best Practices](https://github.com/orgs/supabase/discussions/14576)

### Is this helpful?

NoYes

### On this page

[Using database.dev](https://supabase.com/docs/guides/local-development/testing/pgtap-extended#using-databasedev) [Setting up dbdev](https://supabase.com/docs/guides/local-development/testing/pgtap-extended#setting-up-dbdev) [Installing test helpers](https://supabase.com/docs/guides/local-development/testing/pgtap-extended#installing-test-helpers) [Test helper benefits](https://supabase.com/docs/guides/local-development/testing/pgtap-extended#test-helper-benefits) [Schema-wide Row Level Security testing](https://supabase.com/docs/guides/local-development/testing/pgtap-extended#schema-wide-row-level-security-testing) [Test file organization](https://supabase.com/docs/guides/local-development/testing/pgtap-extended#test-file-organization) [Creating a pre-test hook](https://supabase.com/docs/guides/local-development/testing/pgtap-extended#creating-a-pre-test-hook) [Benefits](https://supabase.com/docs/guides/local-development/testing/pgtap-extended#benefits) [Example: Advanced RLS testing](https://supabase.com/docs/guides/local-development/testing/pgtap-extended#example-advanced-rls-testing) [Not another todo app: Testing complex organizations](https://supabase.com/docs/guides/local-development/testing/pgtap-extended#not-another-todo-app-testing-complex-organizations) [System overview](https://supabase.com/docs/guides/local-development/testing/pgtap-extended#system-overview) [What makes this complex?](https://supabase.com/docs/guides/local-development/testing/pgtap-extended#what-makes-this-complex) [Testing focus areas](https://supabase.com/docs/guides/local-development/testing/pgtap-extended#testing-focus-areas) [Additional resources](https://supabase.com/docs/guides/local-development/testing/pgtap-extended#additional-resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_local_development.md">
Local Development

# Local Development & CLI

## Learn how to develop locally and use the Supabase CLI

* * *

Develop locally while running the Supabase stack on your machine.

## Quickstart [\#](https://supabase.com/docs/guides/local-development\#quickstart)

1. Install the Supabase CLI:



npmyarnpnpmbrew







`
npm install supabase --save-dev
`

2. In your repo, initialize the Supabase project:



npmyarnpnpmbrew







`
npx supabase init
`

3. Start the Supabase stack:



npmyarnpnpmbrew







`
npx supabase start
`

4. View your local Supabase instance at [http://localhost:54323](http://localhost:54323/).


## Local development [\#](https://supabase.com/docs/guides/local-development\#local-development)

Local development with Supabase allows you to work on your projects in a self-contained environment on your local machine. Working locally has several advantages:

1. Faster development: You can make changes and see results instantly without waiting for remote deployments.
2. Offline work: You can continue development even without an internet connection.
3. Cost-effective: Local development is free and doesn't consume your project's quota.
4. Enhanced privacy: Sensitive data remains on your local machine during development.
5. Easy testing: You can experiment with different configurations and features without affecting your production environment.

To get started with local development, you'll need to install the [Supabase CLI](https://supabase.com/docs/guides/local-development#cli) and Docker. The Supabase CLI allows you to start and manage your local Supabase stack, while Docker is used to run the necessary services.

Once set up, you can initialize a new Supabase project, start the local stack, and begin developing your application using local Supabase services. This includes access to a local Postgres database, Auth, Storage, and other Supabase features.

## CLI [\#](https://supabase.com/docs/guides/local-development\#cli)

The Supabase CLI is a powerful tool that enables developers to manage their Supabase projects directly from the terminal. It provides a suite of commands for various tasks, including:

- Setting up and managing local development environments
- Generating TypeScript types for your database schema
- Handling database migrations
- Managing environment variables and secrets
- Deploying your project to the Supabase platform

With the CLI, you can streamline your development workflow, automate repetitive tasks, and maintain consistency across different environments. It's an essential tool for both local development and CI/CD pipelines.

See the [CLI Getting Started guide](https://supabase.com/docs/guides/local-development/cli/getting-started) for more information.

### Is this helpful?

NoYes

### On this page

[Quickstart](https://supabase.com/docs/guides/local-development#quickstart) [Local development](https://supabase.com/docs/guides/local-development#local-development) [CLI](https://supabase.com/docs/guides/local-development#cli)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_access_control.md">
Platform

# Access Control

* * *

Supabase provides granular access controls to manage permissions across your organizations and projects.

For each organization and project, a member can have one of the following roles:

- **Owner**: full access to everything in organization and project resources.
- **Administrator**: full access to everything in organization and project resources **except** updating organization settings, transferring projects outside of the organization, and adding new owners.
- **Developer**: read-only access to organization resources and content access to project resources but cannot change any project settings.
- **Read-Only**: read-only access to organization and project resources.

Read-Only role is only available on the [Team and Enterprise plans](https://supabase.com/pricing).

When you first create an account, a default organization is created for you and you'll be assigned as the **Owner**. Any organizations you create will assign you as **Owner** as well.

## Manage organization members [\#](https://supabase.com/docs/guides/platform/access-control\#manage-organization-members)

To invite others to collaborate, visit your organization's team [settings](https://supabase.com/dashboard/org/_/team) to send an invite link to another user's email. The invite is valid for 24 hours. For project scoped roles, you may only assign a role to a single project for the user when sending the invite. You can assign roles to multiple projects after the user accepts the invite.

Invites sent from a SAML SSO account can only be accepted by another SAML SSO account from the same identity provider.

This is a security measure to prevent accidental invites to accounts not managed by your enterprise's identity provider.

### Transferring ownership of an organization [\#](https://supabase.com/docs/guides/platform/access-control\#transferring-ownership-of-an-organization)

Each Supabase organization must have at least one owner. If your organization has other owners then you can relinquish ownership and leave the organization by clicking **Leave team** in your organization's team [settings](https://supabase.com/dashboard/org/_/team).

Otherwise, you'll need to invite a user as **Owner**, and they need to accept the invitation, or promote an existing organization member to **Owner** before you can leave the organization.

### Organization scoped roles vs project scoped roles [\#](https://supabase.com/docs/guides/platform/access-control\#organization-scoped-roles-vs-project-scoped-roles)

Project scoped roles are only available on the [Enterprise Plan](https://supabase.com/pricing)

Each member in the organization can be assigned a role scoped to the organization or to specific projects. If the member has a role at the organization level, they will have the equivalent permissions for that role across all current and future projects in the organization.

With project scoped permissions, you can assign members to roles scoped to specific projects.

### Organization permissions across roles [\#](https://supabase.com/docs/guides/platform/access-control\#organization-permissions-across-roles)

The table below shows the actions each role can take on the resources belonging to the organization.

| Resource | Action | Owner | Administrator | Developer | Read-Only[1](https://supabase.com/docs/guides/platform/access-control#user-content-fn-1) |
| --- | --- | :-: | :-: | :-: | :-: |
| [**Organization**](https://supabase.com/docs/guides/platform/access-control#org-permissions) |  |  |  |  |  |
| Organization Management | Update |  |  |  |  |
|  | Delete |  |  |  |  |
| OpenAI Telemetry Configuration[2](https://supabase.com/docs/guides/platform/access-control#user-content-fn-2) | Update |  |  |  |  |
| [**Members**](https://supabase.com/docs/guides/platform/access-control#member-permissions) |  |  |  |  |  |
| Organization Members | List |  |  |  |  |
| Owner | Add |  |  |  |  |
|  | Remove |  |  |  |  |
| Administrator | Add |  |  |  |  |
|  | Remove |  |  |  |  |
| Developer | Add |  |  |  |  |
|  | Remove |  |  |  |  |
| Owner (Project-Scoped) | Add |  |  |  |  |
|  | Remove |  |  |  |  |
| Administrator (Project-Scoped) | Add |  |  |  |  |
|  | Remove |  |  |  |  |
| Developer (Project-Scoped) | Add |  |  |  |  |
|  | Remove |  |  |  |  |
| Invite | Revoke |  |  |  |  |
|  | Resend |  |  |  |  |
|  | Accept[3](https://supabase.com/docs/guides/platform/access-control#user-content-fn-3) |  |  |  |  |
| [**Billing**](https://supabase.com/docs/guides/platform/access-control#billing-permissions) |  |  |  |  |  |
| Invoices | List |  |  |  |  |
| Billing Email | View |  |  |  |  |
|  | Update |  |  |  |  |
| Subscription | View |  |  |  |  |
|  | Update |  |  |  |  |
| Billing Address | View |  |  |  |  |
|  | Update |  |  |  |  |
| Tax Codes | View |  |  |  |  |
|  | Update |  |  |  |  |
| Payment Methods | View |  |  |  |  |
|  | Update |  |  |  |  |
| Usage | View |  |  |  |  |
| [**Integrations (Org Settings)**](https://supabase.com/docs/guides/platform/access-control#org-integration-permissions) |  |  |  |  |  |
| Authorize GitHub | - |  |  |  |  |
| Add GitHub Repositories | - |  |  |  |  |
| GitHub Connections | Create |  |  |  |  |
|  | Update |  |  |  |  |
|  | Delete |  |  |  |  |
|  | View |  |  |  |  |
| Vercel Connections | Create |  |  |  |  |
|  | Update |  |  |  |  |
|  | Delete |  |  |  |  |
|  | View |  |  |  |  |
| [**OAuth Apps**](https://supabase.com/docs/guides/platform/access-control#oauth-permissions) |  |  |  |  |  |
| OAuth Apps | Create |  |  |  |  |
|  | Update |  |  |  |  |
|  | Delete |  |  |  |  |
|  | List |  |  |  |  |
| [**Audit Logs**](https://supabase.com/docs/guides/platform/access-control#audit-permissions) |  |  |  |  |  |
| View Audit logs | - |  |  |  |  |
| [**Legal Documents**](https://supabase.com/docs/guides/platform/access-control#legal-docs-permissions) |  |  |  |  |  |
| SOC2 Type 2 Report | Download |  |  |  |  |
| Security Questionnaire | Download |  |  |  |  |

### Project permissions across roles [\#](https://supabase.com/docs/guides/platform/access-control\#project-permissions-across-roles)

The table below shows the actions each role can take on the resources belonging to the project.

| Resource | Action | Owner | Admin | Developer | Read-Only[4](https://supabase.com/docs/guides/platform/access-control#user-content-fn-4)[5](https://supabase.com/docs/guides/platform/access-control#user-content-fn-6) |
| --- | --- | :-: | :-: | :-: | :-: |
| [**Project**](https://supabase.com/docs/guides/platform/access-control#project-permissions) |  |  |  |  |  |
| Project Management | Transfer |  |  |  |  |
|  | Create |  |  |  |  |
|  | Delete |  |  |  |  |
|  | Update (Name) |  |  |  |  |
|  | Pause |  |  |  |  |
|  | Restore |  |  |  |  |
|  | Restart |  |  |  |  |
| Custom Domains | View |  |  |  |  |
|  | Update |  |  |  |  |
| Data (Database) | View |  |  |  |  |
|  | Manage |  |  |  |  |
| [**Infrastructure**](https://supabase.com/docs/guides/platform/access-control#infrastructure-permissions) |  |  |  |  |  |
| Read Replicas | List |  |  |  |  |
|  | Create |  |  |  |  |
|  | Delete |  |  |  |  |
| Add-ons | Update |  |  |  |  |
| [**Integrations**](https://supabase.com/docs/guides/platform/access-control#proj-integrations-permissions) |  |  |  |  |  |
| Authorize GitHub | - |  |  |  |  |
| Add GitHub Repositories | - |  |  |  |  |
| GitHub Connections | Create |  |  |  |  |
|  | Update |  |  |  |  |
|  | Delete |  |  |  |  |
|  | View |  |  |  |  |
| Vercel Connections | Create |  |  |  |  |
|  | Update |  |  |  |  |
|  | Delete |  |  |  |  |
|  | View |  |  |  |  |
| [**Database Configuration**](https://supabase.com/docs/guides/platform/access-control#database-config-permissions) |  |  |  |  |  |
| Reset Password | - |  |  |  |  |
| Pooling Settings | View |  |  |  |  |
|  | Update |  |  |  |  |
| SSL Configuration | View |  |  |  |  |
|  | Update |  |  |  |  |
| Disk Size Configuration | View |  |  |  |  |
|  | Update |  |  |  |  |
| Network Restrictions | View |  |  |  |  |
|  | Create |  |  |  |  |
|  | Delete |  |  |  |  |
| Network Bans | View |  |  |  |  |
|  | Unban |  |  |  |  |
| [**API Configuration**](https://supabase.com/docs/guides/platform/access-control#api-config-permissions) |  |  |  |  |  |
| API Keys | Read service key |  |  |  |  |
|  | Read anon key |  |  |  |  |
| JWT Secret | View |  |  |  |  |
|  | Generate new |  |  |  |  |
| API settings | View |  |  |  |  |
|  | Update |  |  |  |  |
| [**Auth Configuration**](https://supabase.com/docs/guides/platform/access-control#auth-config-permissions) |  |  |  |  |  |
| Auth Settings | View |  |  |  |  |
|  | Update |  |  |  |  |
| SMTP Settings | View |  |  |  |  |
|  | Update |  |  |  |  |
| Advanced Settings | View |  |  |  |  |
|  | Update |  |  |  |  |
| [**Storage Configuration**](https://supabase.com/docs/guides/platform/access-control#storage-config-permissions) |  |  |  |  |  |
| Upload Limit | View |  |  |  |  |
|  | Update |  |  |  |  |
| S3 Access Keys | View |  |  |  |  |
|  | Create |  |  |  |  |
|  | Delete |  |  |  |  |
| [**Edge Functions Configuration**](https://supabase.com/docs/guides/platform/access-control#edge-config-permissions) |  |  |  |  |  |
| Secrets | View |  |  |  | [6](https://supabase.com/docs/guides/platform/access-control#user-content-fn-5) |
|  | Create |  |  |  |  |
|  | Delete |  |  |  |  |
| [**SQL Editor**](https://supabase.com/docs/guides/platform/access-control#sql-editor-permissions) |  |  |  |  |  |
| Queries | Create |  |  |  |  |
|  | Update |  |  |  |  |
|  | Delete |  |  |  |  |
|  | View |  |  |  |  |
|  | List |  |  |  |  |
|  | Run |  |  |  | [7](https://supabase.com/docs/guides/platform/access-control#user-content-fn-7) |
| [**Database**](https://supabase.com/docs/guides/platform/access-control#database-permissions) |  |  |  |  |  |
| Scheduled Backups | View |  |  |  |  |
|  | Download |  |  |  |  |
|  | Restore |  |  |  |  |
| Physical backups (PITR) | View |  |  |  |  |
|  | Restore |  |  |  |  |
| [**Authentication**](https://supabase.com/docs/guides/platform/access-control#auth-permissions) |  |  |  |  |  |
| Users | Create |  |  |  |  |
|  | Delete |  |  |  |  |
|  | List |  |  |  |  |
|  | Send OTP |  |  |  |  |
|  | Send password recovery |  |  |  |  |
|  | Send magic link |  |  |  |  |
|  | Remove MFA factors |  |  |  |  |
| Providers | View |  |  |  |  |
|  | Update |  |  |  |  |
| Rate Limits | View |  |  |  |  |
|  | Update |  |  |  |  |
| Email Templates | View |  |  |  |  |
|  | Update |  |  |  |  |
| URL Configuration | View |  |  |  |  |
|  | Update |  |  |  |  |
| Hooks | View |  |  |  |  |
|  | Create |  |  |  |  |
|  | Delete |  |  |  |  |
| [**Storage**](https://supabase.com/docs/guides/platform/access-control#storage-permissions) |  |  |  |  |  |
| Buckets | Create |  |  |  |  |
|  | Update |  |  |  |  |
|  | Delete |  |  |  |  |
|  | View |  |  |  |  |
|  | List |  |  |  |  |
| Files | Create (Upload) |  |  |  |  |
|  | Update |  |  |  |  |
|  | Delete |  |  |  |  |
|  | List |  |  |  |  |
| [**Edge Functions**](https://supabase.com/docs/guides/platform/access-control#edge-permissions) |  |  |  |  |  |
| Edge Functions | Update |  |  |  |  |
|  | Delete |  |  |  |  |
|  | View |  |  |  |  |
|  | List |  |  |  |  |
| [**Reports**](https://supabase.com/docs/guides/platform/access-control#proj-reports-permissions) |  |  |  |  |  |
| Custom Report | Create |  |  |  |  |
|  | Update |  |  |  |  |
|  | Delete |  |  |  |  |
|  | View |  |  |  |  |
|  | List |  |  |  |  |
| [**Logs & Analytics**](https://supabase.com/docs/guides/platform/access-control#proj-logs-permissions) |  |  |  |  |  |
| Queries | Create |  |  |  |  |
|  | Update |  |  |  |  |
|  | Delete |  |  |  |  |
|  | View |  |  |  |  |
|  | List |  |  |  |  |
|  | Run |  |  |  |  |
| Events Collections | Create |  |  |  |  |
|  | Update |  |  |  |  |
|  | Delete |  |  |  |  |
|  | View |  |  |  |  |
|  | List |  |  |  |  |
| Warehouse Access Tokens | Create |  |  |  |  |
|  | Revoke |  |  |  |  |
|  | List |  |  |  |  |
| [**Branching**](https://supabase.com/docs/guides/platform/access-control#branching-permissions) |  |  |  |  |  |
| Enable branching | - |  |  |  |  |
| Disable branching | - |  |  |  |  |
|  | Create |  |  |  |  |
|  | Delete |  |  |  |  |
|  | List |  |  |  |  |

## Footnotes [\#](https://supabase.com/docs/guides/platform/access-control\#footnote-label)

1. Available on the Team and Enterprise Plans. [](https://supabase.com/docs/guides/platform/access-control#user-content-fnref-1)

2. Sending anonymous data to OpenAI is opt in and can improve Studio AI Assistant's responses. [](https://supabase.com/docs/guides/platform/access-control#user-content-fnref-2)

3. Invites sent from a SSO account can only be accepted by another SSO account coming from the same identity provider. This is a security measure that prevents accidental invites to accounts not managed by your company's enterprise systems. [](https://supabase.com/docs/guides/platform/access-control#user-content-fnref-3)

4. Available on the Enterprise Plan. [](https://supabase.com/docs/guides/platform/access-control#user-content-fnref-4)

5. Listed permissions are for the API and Dashboard. [](https://supabase.com/docs/guides/platform/access-control#user-content-fnref-6)

6. Read-Only role is able to access secrets. [](https://supabase.com/docs/guides/platform/access-control#user-content-fnref-5)

7. Limited to executing SELECT queries. SQL Query Snippets run by the Read-Only role are run against the database using the **supabase\_read\_only\_user**. This role has the [predefined Postgres role pg\_read\_all\_data](https://www.postgresql.org/docs/current/predefined-roles.html). [](https://supabase.com/docs/guides/platform/access-control#user-content-fnref-7)


### Is this helpful?

NoYes

### On this page

[Manage organization members](https://supabase.com/docs/guides/platform/access-control#manage-organization-members) [Transferring ownership of an organization](https://supabase.com/docs/guides/platform/access-control#transferring-ownership-of-an-organization) [Organization scoped roles vs project scoped roles](https://supabase.com/docs/guides/platform/access-control#organization-scoped-roles-vs-project-scoped-roles) [Organization permissions across roles](https://supabase.com/docs/guides/platform/access-control#organization-permissions-across-roles) [Project permissions across roles](https://supabase.com/docs/guides/platform/access-control#project-permissions-across-roles) [Footnotes](https://supabase.com/docs/guides/platform/access-control#footnote-label)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_backups.md">
Platform

# Database Backups

* * *

Database backups are an integral part of any disaster recovery plan. Disasters come in many shapes and sizes. It could be as simple as accidentally deleting a table column, the database crashing, or even a natural calamity wiping out the underlying hardware a database is running on. The risks and impact brought by these scenarios can never be fully eliminated, but only minimized or even mitigated. Having database backups is a form of insurance policy. They are essentially snapshots of the database at various points in time. When disaster strikes, database backups allow the project to be brought back to any of these points in time, therefore averting the crisis.

The Supabase team regularly monitors the status of backups. In case of any issues, you can [contact support](https://supabase.com/dashboard/support/new). Also you can check out our [status page](https://status.supabase.com/) at any time.

Once a project is deleted all associated data will be permanently removed, including any backups stored in S3. This action is irreversible and should be carefully considered before proceeding.

## Types of backups [\#](https://supabase.com/docs/guides/platform/backups\#types-of-backups)

Database backups can be categorized into two types: **logical** and **physical**. You can learn more about them [here](https://supabase.com/blog/postgresql-physical-logical-backups).

As a general rule of thumb, projects will either have logical or physical backups based on plan, database size, and add-ons:

| Plan | Database Size (0-15GB) | [Database Size (>15GB)](https://supabase.com/docs/guides/platform/backups#backup-process-for-large-databases) | [PITR](https://supabase.com/docs/guides/platform/backups#point-in-time-recovery) | [Read Replicas](https://supabase.com/docs/guides/platform/read-replicas#prerequisites) |
| --- | --- | --- | --- | --- |
| Pro | logical | physical | physical | physical |
| Team | logical | physical | physical | physical |
| Enterprise | physical | physical | physical | physical |

Once a project satisfies at least one of the requirements for physical backups then logical backups will no longer be taken. However, your project may revert back to logical backups if add-ons are removed.

You can confirm your project's backup type by navigating to [Database Backups > Scheduled backups](https://supabase.com/dashboard/project/_/database/backups/scheduled) and if you can download a backup then it is logical, otherwise it is physical.

However, if your project has the Point-in-Time Recovery (PITR) add-on then the backups are physical and you can view them in [Database Backups > Point in time](https://supabase.com/dashboard/project/_/database/backups/pitr).

## Frequency of backups [\#](https://supabase.com/docs/guides/platform/backups\#frequency-of-backups)

When deciding how often a database should be backed up, the key business metric Recovery Point Objective (RPO) should be considered. RPO is the threshold for how much data, measured in time, a business could lose when disaster strikes. This amount is fully dependent on a business and its underlying requirements. A low RPO would mean that database backups would have to be taken at an increased cadence throughout the day. Each Supabase project has access to two forms of backups, Daily Backups and Point-in-Time Recovery (PITR). The agreed upon RPO would be a deciding factor in choosing which solution best fits a project.

If you enable PITR, Daily Backups will no longer be taken. PITR provides a finer granularity than Daily Backups, so it's unnecessary to run both.

Database backups do not include objects stored via the Storage API, as the database only includes metadata about these objects. Restoring an old backup does not restore objects that have been deleted since then.

## Daily backups [\#](https://supabase.com/docs/guides/platform/backups\#daily-backups)

All Pro, Team and Enterprise Plan Supabase projects are backed up automatically on a daily basis. In terms of Recovery Point Objective (RPO), Daily Backups would be suitable for projects willing to lose up to 24 hours worth of data if disaster hits at the most inopportune time. If a lower RPO is required, enabling Point-in-Time Recovery should be considered.

For security purposes, passwords for custom roles are not stored in daily backups, and will not be found in downloadable files. As such, if you are restoring from a daily backup and are using custom roles, you will need to set their passwords once more following a completed restoration.

### Backup process [\#](https://supabase.com/docs/guides/platform/backups\#daily-backups-process)

The Postgres utility [pg\_dumpall](https://www.postgresql.org/docs/current/app-pg-dumpall.html) is used to perform daily backups. An SQL file is generated, zipped up, and sent to our storage servers for safe keeping.

You can access daily backups in the [Scheduled backups](https://supabase.com/dashboard/project/_/database/backups/scheduled) settings in the Dashboard. Pro Plan projects can access the last 7 days' worth of daily backups. Team Plan projects can access the last 14 days' worth of daily backups, while Enterprise Plan projects can access up to 30 days' worth of daily backups. Users can restore their project to any one of the backups. If you wish to generate a logical backup on your own, you can do so through the [Supabase CLI](https://supabase.com/docs/reference/cli/supabase-db-dump).

#### Backup process for large databases [\#](https://supabase.com/docs/guides/platform/backups\#backup-process-for-large-databases)

Databases larger than 15GB[1](https://supabase.com/docs/guides/platform/backups#user-content-fn-1), if they're on a recent build[2](https://supabase.com/docs/guides/platform/backups#user-content-fn-2) of the Supabase platform, get automatically transitioned[3](https://supabase.com/docs/guides/platform/backups#user-content-fn-3) to use daily physical backups. Physical backups are a more performant backup mechanism that lowers the overhead and impact on the database being backed up, and also avoids holding locks on objects in your database for a long period of time. While restores are unaffected, the backups created using this method cannot be downloaded from the Backups section of the dashboard.

This class of physical backups only allows for recovery to a fixed time each day, similar to daily backups. You can upgrade to [PITR](https://supabase.com/docs/guides/platform/backups#point-in-time-recovery) for access to more granular recovery options.

Once a database is transitioned to using physical backups, it continues to use physical backups, even if the database size falls back below the threshold for the transition.

### Restoration process [\#](https://supabase.com/docs/guides/platform/backups\#daily-backups-restoration-process)

When selecting a backup to restore to, select the closest available one made before the desired point in time to restore to. Earlier backups can always be chosen too but do consider the number of days' worth of data that could be lost.

The Dashboard will then prompt for a confirmation before proceeding with the restoration. The project will be inaccessible following this. As such, do ensure to allot downtime beforehand. This is dependent on the size of the database. The larger it is, the longer the downtime will be. Once the confirmation has been given, the underlying SQL of the chosen backup is then run against the project. The Postgres utility [psql](https://www.postgresql.org/docs/current/app-psql.html) is used to facilitate the restoration. The Dashboard will display a notification once the restoration completes.

If your project is using subscriptions or replication slots, you will need to drop them prior to the restoration, and re-create them afterwards. The slot used by Realtime is exempted from this, and will be handled automatically.

## Point-in-Time recovery [\#](https://supabase.com/docs/guides/platform/backups\#point-in-time-recovery)

Point-in-Time Recovery (PITR) allows a project to be backed up at much shorter intervals. This provides users an option to restore to any chosen point of up to seconds in granularity. Even with daily backups, a day's worth of data could still be lost. With PITR, backups could be performed up to the point of disaster.

Pro, Team and Enterprise Plan projects can enable PITR as an add-on.

Projects interested in PITR will also need to use at least a Small compute add-on, in order to ensure smooth functioning.

If you enable PITR, Daily Backups will no longer be taken. PITR provides a finer granularity than Daily Backups, so it's unnecessary to run both.

### Backup process [\#](https://supabase.com/docs/guides/platform/backups\#pitr-backup-process)

As discussed [here](https://supabase.com/blog/postgresql-physical-logical-backups), PITR is made possible by a combination of taking physical backups of a project, as well as archiving [Write Ahead Log (WAL)](https://www.postgresql.org/docs/current/wal-intro.html) files. Physical backups provide a snapshot of the underlying directory of the database, while WAL files contain records of every change made in the database.

Supabase uses [WAL-G](https://github.com/wal-g/wal-g), an open source archival and restoration tool, to handle both aspects of PITR. On a daily basis, a snapshot of the database is taken and sent to our storage servers. Throughout the day, as database transactions occur, WAL files are generated and uploaded.

By default, WAL files are backed up at two minute intervals. If these files cross a certain file size threshold, they are backed up immediately. As such, during periods of high amount of transactions, WAL file backups become more frequent. Conversely, when there is no activity in the database, WAL file backups are not made. Overall, this would mean that at the worst case scenario or disaster, the PITR achieves a Recovery Point Objective (RPO) of two minutes.

![PITR dashboard](https://supabase.com/docs/img/backups-pitr-dashboard.png)

You can access PITR in the [Point in Time](https://supabase.com/dashboard/project/_/database/backups/pitr) settings in the Dashboard. The recovery period of a project is indicated by the earliest and latest points of recoveries displayed in your preferred timezone. If need be, the maximum amount of this recovery period can be modified accordingly.

Note that the latest restore point of the project could be significantly far from the current time. This occurs when there has not been any recent activity in the database, and therefore no WAL file backups have been made recently. This is perfectly fine as the state of the database at the latest point of recovery would still be indicative of the state of the database at the current time given that no transactions have been made in between.

### Restoration process [\#](https://supabase.com/docs/guides/platform/backups\#pitr-restoration-process)

![PITR: Calendar view](https://supabase.com/docs/img/backups-pitr-calendar-view.png)

A date and time picker will be provided upon pressing the `Start a restore` button. The process will only proceed if the selected date and time fall within the earliest and latest points of recoveries.

![PITR: Confirmation modal](https://supabase.com/docs/img/backups-pitr-confirmation-modal.png)

After locking in the desired point in time to recover to, The Dashboard will then prompt for a review and confirmation before proceeding with the restoration. The project will be inaccessible following this. As such, do ensure to allot for downtime beforehand. This is dependent on the size of the database. The larger it is, the longer the downtime will be. Once the confirmation has been given, the latest physical backup available is downloaded to the project and the database is partially restored. WAL files generated after this physical backup up to the specified point-in-time are then downloaded. The underlying records of transactions in these files are replayed against the database to complete the restoration. The Dashboard will display a notification once the restoration completes.

### Pricing [\#](https://supabase.com/docs/guides/platform/backups\#pricing)

Pricing depends on the recovery retention period, which determines how many days back you can restore data to any chosen point of up to seconds in granularity.

| Recovery Retention Period in Days | Hourly Price USD | Monthly Price USD |
| --- | --- | --- |
| 7 | $0.137 | $100 |
| 14 | $0.274 | $200 |
| 28 | $0.55 | $400 |

For a detailed breakdown of how charges are calculated, refer to [Manage Point-in-Time Recovery usage](https://supabase.com/docs/guides/platform/manage-your-usage/point-in-time-recovery).

## Restore to a new project [\#](https://supabase.com/docs/guides/platform/backups\#restore-to-a-new-project)

Supabase provides a convenient way to restore data from an existing project into a completely new one. Whether you're using physical backups or Point-in-Time recovery (PITR), this feature allows you to duplicate project data with ease, perform testing safely, or recover data for analysis. Access to this feature is exclusive to users on paid plans and requires that physical backups are enabled for the source project.

PITR is an additional add-on available for organizations on a paid plan with physical backups enabled.

To begin, switch to the source projectthe project containing the data you wish to restoreand go to the [database backups](https://supabase.com/dashboard/project/_/database/backups/restore-to-new-project) page. Select the **Restore to a New Project** tab.

A list of available backups is displayed. Select the backup you want to use and click the "Restore" button. For projects with PITR enabled, use the date and time selector to specify the exact point in time from which you wish to restore data.

Once youve made your choice, Supabase takes care of the rest. A new project is automatically created, replicating key configurations from the original, including the compute instance size, disk attributes, SSL enforcement settings, and network restrictions. The data will remain in the same region as the source project to ensure compliance with data residency requirements. The entire process is fully automated.

The time required to complete the restoration can vary depending largely on the volume of data involved. If you have a large amount of data you can opt for higher performing disk attributes on the source project _before_ starting a clone operation. These disk attributes will be replicated to the new project. This incurs additional costs which will be displayed before starting.

There are a few important restrictions to be aware of with the "Restore to a New Project" process:

- Projects that are created through the restoration process cannot themselves be used as a source for further clones at this time.
- The feature is only accessible to paid plan users with physical backups enabled, ensuring that the necessary resources and infrastructure are available for the restore process.

Before starting the restoration, youll be presented with an overview of the costs associated with creating the new project. The new project will incur additional monthly expenses based on the mirrored resources from the source project. Its important to review these costs carefully before proceeding.

Once the restoration is complete, the new project will be available in your dashboard and will include all data, tables, schemas, and selected settings from the chosen backup source. It is recommended to thoroughly review the new project and perform any necessary tests to ensure everything has been restored as expected.

New projects are completely independent of their source, and as such can be modified and used as desired.

As the entire database is copied to the new project, this will include all extensions that were enabled at the source. If the source project included extensions that are configured to carry out external operationsfor example pg\_net, pg\_cron, wrappersthese should be disabled once the copy process has completed to avoid any unwanted actions from taking place.

Restoring to a new project is an excellent way to manage environments more effectively. You can use this feature to create staging environments for testing, experiment with changes without risk to production data, or swiftly recover from unexpected data loss scenarios.

## Troubleshooting [\#](https://supabase.com/docs/guides/platform/backups\#troubleshooting)

### Logical backups [\#](https://supabase.com/docs/guides/platform/backups\#logical-backups)

#### `search_path` issues [\#](https://supabase.com/docs/guides/platform/backups\#searchpath-issues)

During the `pg_restore` process, the `search_path` is set to an empty string for predictability, and security. Using unqualified references to functions or relations can cause restorations using logical backups to fail, as the database will not be able to locate the function or relation being referenced. This can happen even if the database functions without issues during normal operations, as the `search_path` is usually set to include several schemas during normal operations. Therefore, you should always use schema-qualified names within your SQL code.

You can refer to [an example PR](https://github.com/supabase/supabase/pull/28393/files) on how to update SQL code to use schema-qualified names.

#### Invalid check constraints [\#](https://supabase.com/docs/guides/platform/backups\#invalid-check-constraints)

Postgres requires that [check constraints](https://www.postgresql.org/docs/current/ddl-constraints.html#DDL-CONSTRAINTS-CHECK-CONSTRAINTS) be:

1. immutable
2. not reference table data other than the new or updated row being checked

Violating these requirements can result in numerous failure scenarios, including during logical restorations.

Common examples of check constraints that can result in such failures are:

- validating against the current time, e.g. that the row being inserted references a future event
- validating the contents of a row against the contents of another table

## Footnotes [\#](https://supabase.com/docs/guides/platform/backups\#footnote-label)

1. The threshold for transitioning will be slowly lowered over time. Eventually, all projects will be transitioned to using physical backups. [](https://supabase.com/docs/guides/platform/backups#user-content-fnref-1)

2. Projects created or upgraded after the 14th of July 2022 are eligible. [](https://supabase.com/docs/guides/platform/backups#user-content-fnref-2)

3. The transition to physical backups is handled transparently and does not require any user intervention. It involves a single restart of the database to pick up new configuration that can only be loaded at start; the expected downtime for the restart is a few seconds. [](https://supabase.com/docs/guides/platform/backups#user-content-fnref-3)


### Is this helpful?

NoYes

### On this page

[Types of backups](https://supabase.com/docs/guides/platform/backups#types-of-backups) [Frequency of backups](https://supabase.com/docs/guides/platform/backups#frequency-of-backups) [Daily backups](https://supabase.com/docs/guides/platform/backups#daily-backups) [Backup process](https://supabase.com/docs/guides/platform/backups#daily-backups-process) [Restoration process](https://supabase.com/docs/guides/platform/backups#daily-backups-restoration-process) [Point-in-Time recovery](https://supabase.com/docs/guides/platform/backups#point-in-time-recovery) [Backup process](https://supabase.com/docs/guides/platform/backups#pitr-backup-process) [Restoration process](https://supabase.com/docs/guides/platform/backups#pitr-restoration-process) [Pricing](https://supabase.com/docs/guides/platform/backups#pricing) [Restore to a new project](https://supabase.com/docs/guides/platform/backups#restore-to-a-new-project) [Troubleshooting](https://supabase.com/docs/guides/platform/backups#troubleshooting) [Logical backups](https://supabase.com/docs/guides/platform/backups#logical-backups) [Footnotes](https://supabase.com/docs/guides/platform/backups#footnote-label)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_billing_faq.md">
Platform

# Billing FAQ

## This documentation covers frequently asked questions around subscription plans, payments, invoices and billing in general

* * *

## Organizations and projects [\#](https://supabase.com/docs/guides/platform/billing-faq\#organizations-and-projects)

#### What are organizations and projects? [\#](https://supabase.com/docs/guides/platform/billing-faq\#what-are-organizations-and-projects)

The Supabase Platform has "organizations" and "projects". An organization may contain multiple projects. Each project is a dedicated Supabase instance with all of its sub-services including Storage, Auth, Functions and Realtime.
Each organization only has a single subscription with a single plan (Free, Pro, Team or Enterprise). Project add-ons such as [Compute](https://supabase.com/docs/guides/platform/compute-add-ons), [IPv4](https://supabase.com/docs/guides/platform/ipv4-address), [Log Drains](https://supabase.com/docs/guides/platform/log-drains), [Advanced MFA](https://supabase.com/docs/guides/auth/auth-mfa/phone), [Custom Domains](https://supabase.com/docs/guides/platform/custom-domains) and [PITR](https://supabase.com/docs/guides/platform/backups#point-in-time-recovery) are configured per project and are added to your organization subscription.

Read more on [About billing on Supabase](https://supabase.com/docs/guides/platform/billing-on-supabase#organization-based-billing).

#### How many free projects can I have? [\#](https://supabase.com/docs/guides/platform/billing-faq\#how-many-free-projects-can-i-have)

You are entitled to two active free projects. Paused projects do not count towards your quota. Note that within an organization, we count the free project limits from all members that are either Owner or Admin. If youve got another organization member with the Admin or Owner role that has already exhausted their free project quota, you wont be able to launch another free project in that organization. You can create another Free Plan organization or change the role of the affected member in your [organizations team settings](https://supabase.com/dashboard/org/_/team).

#### Can I mix free and paid projects in a single organization? [\#](https://supabase.com/docs/guides/platform/billing-faq\#can-i-mix-free-and-paid-projects-in-a-single-organization)

The subscription plan is set on the organization level and it is not possible to mix paid and non-paid projects inside a single organization. However, you can have a paid and a free organization and make use of the [self-serve project transfers](https://supabase.com/docs/guides/platform/project-transfer) to organize your projects. All projects in an organization benefit from the subscription plan. If your organization is on the Pro Plan, all projects within the organization benefit from no project pausing, automated backups and so on.

#### Can I transfer my projects to another organization? [\#](https://supabase.com/docs/guides/platform/billing-faq\#can-i-transfer-my-projects-to-another-organization)

Yes, you can transfer your projects to another organization. You can find instructions on how to transfer your projects [here](https://supabase.com/docs/guides/platform/project-transfer).

#### Can I transfer my credits to another organization? [\#](https://supabase.com/docs/guides/platform/billing-faq\#can-i-transfer-my-credits-to-another-organization)

Yes, you can transfer the credits to another organization. Submit a [support ticket](https://supabase.help/).

## Pricing [\#](https://supabase.com/docs/guides/platform/billing-faq\#pricing)

See the [Pricing page](https://supabase.com/pricing) for details.

#### Are there any charges for paused projects? [\#](https://supabase.com/docs/guides/platform/billing-faq\#are-there-any-charges-for-paused-projects)

No, we do not charge for paused projects. Compute hours are only counted for active instances. Paused projects do not incur any compute usage charges.

#### How are multiple projects billed under a paid organization? [\#](https://supabase.com/docs/guides/platform/billing-faq\#how-are-multiple-projects-billed-under-a-paid-organization)

We provide a dedicated server for every Supabase project. Each paid organization comes with $10 in Compute Credits to cover one project on the default compute size. Additional projects start at ~$10 a month (billed hourly).

Running 3 projects in a Pro Plan organization on the default Micro instance:

- $25 Pro Plan
- $30 for 3 projects on the default compute size
- $10 Compute credits
 $45 / month

Refer to our [Compute](https://supabase.com/docs/guides/platform/manage-your-usage/compute#billing-examples) docs for more examples and insights.

#### How does compute billing work? [\#](https://supabase.com/docs/guides/platform/billing-faq\#how-does-compute-billing-work)

Each Supabase project is a dedicated VM and Postgres database. By default, your instance runs on the Micro compute instance. You have the option to upgrade your compute size in your [Project settings](https://supabase.com/dashboard/project/_/settings/addons). See [Compute Add-ons](https://supabase.com/docs/guides/platform/compute-add-ons) for available options.

When you change your compute size, there are no immediate upfront charges. Instead, you will be billed based on the compute hours during your billing cycle reset.

If you launch additional instances on your paid plan, we will add the corresponding compute hours to your final invoice.

If you upgrade your project to a larger instance for 10 hours and then downgrade, youll only pay for the larger instance for the 10 hours of usage at the end of your billing cycle. You can see your current compute usage on your [organizations usage page](https://supabase.com/dashboard/org/_/usage).

Read more about [Compute usage](https://supabase.com/docs/guides/platform/manage-your-usage/compute).

#### What is unified egress and how is it billed? [\#](https://supabase.com/docs/guides/platform/billing-faq\#what-is-unified-egress-and-how-is-it-billed)

Unified egress refers to the total egress quota available to each organization. This quota can be utilized for various purposes such as Storage, Realtime, Auth, Functions, Supavisor, Log Drains and Database. Each plan includes a specific egress quota, and any additional usage beyond that quota is billed accordingly.

Read more about [Egress usage](https://supabase.com/docs/guides/platform/manage-your-usage/egress).

## Plans and subscriptions [\#](https://supabase.com/docs/guides/platform/billing-faq\#plans-and-subscriptions)

#### How do I change my subscription plan? [\#](https://supabase.com/docs/guides/platform/billing-faq\#how-do-i-change-my-subscription-plan)

Change your subscription plan in your [organization's billing settings](https://supabase.com/dashboard/org/_/billing). To upgrade to an Enterprise Plan, complete the [Enterprise request form](https://forms.supabase.com/enterprise).

#### What happens if I cancel my subscription? [\#](https://supabase.com/docs/guides/platform/billing-faq\#what-happens-if-i-cancel-my-subscription)

The organization is given [credits](https://supabase.com/docs/guides/platform/credits) for unused time on the subscription plan. The credits will not expire and can be used again in the future. You may see an additional charge for unbilled excessive usage charges from your previous billing cycle.

Read more about [downgrades](https://supabase.com/docs/guides/platform/manage-your-subscription#downgrade).

#### I mistakenly upgraded the wrong organization and then downgraded it. Could you issue a refund? [\#](https://supabase.com/docs/guides/platform/billing-faq\#i-mistakenly-upgraded-the-wrong-organization-and-then-downgraded-it-could-you-issue-a-refund)

We can transfer the amount as [credits](https://supabase.com/docs/guides/platform/credits) to another organization of your choice. You can use these credits to upgrade the organization, or if you have already upgraded, the credits will be used to pay the next month's invoice. Please create a [support ticket](https://supabase.help/) for this case.

## Quotas and spend caps [\#](https://supabase.com/docs/guides/platform/billing-faq\#quotas-and-spend-caps)

#### What will happen when I exceed the Free Plan quota? [\#](https://supabase.com/docs/guides/platform/billing-faq\#what-will-happen-when-i-exceed-the-free-plan-quota)

You will be notified when you exceed the Free Plan quota. It is important to take action at this point. If you continue to exceed the limits without reducing your usage, service restrictions will apply. To avoid service restrictions, you have two options: reduce your usage or upgrade to a paid plan. Learn more about restrictions in the [Fair Use Policy](https://supabase.com/docs/guides/platform/billing-faq#fair-use-policy) section.

#### What will happen when I exceed the Pro Plan quota and have the spend cap on? [\#](https://supabase.com/docs/guides/platform/billing-faq\#what-will-happen-when-i-exceed-the-pro-plan-quota-and-have-the-spend-cap-on)

You will be notified when you exceed your Pro Plan quota. To unblock yourself, you can toggle off your spend cap in your [organizations billing settings](https://supabase.com/dashboard/org/_/billing) to pay for over-usage beyond the Pro plans limits. If you continue to exceed the limits without reducing your usage or turning off the spend cap, restrictions will apply. Learn more about restrictions in the [Fair Use Policy](https://supabase.com/docs/guides/platform/billing-faq#fair-use-policy) section.

#### How do I scale beyond the limits of my Pro Plan? [\#](https://supabase.com/docs/guides/platform/billing-faq\#how-do-i-scale-beyond-the-limits-of-my-pro-plan)

The Pro Plan has a Spend Cap enabled by default to keep costs under control. If you want to scale beyond the plan's included quota, switch off the Spend Cap to pay for additional usage beyond the plans included limits. You can toggle the Spend Cap in the [organization's billing settings](https://supabase.com/dashboard/org/_/billing). Read more about the [Spend Cap](https://supabase.com/docs/guides/platform/cost-control#spend-cap).

## Fair Use Policy [\#](https://supabase.com/docs/guides/platform/billing-faq\#fair-use-policy)

#### What is the Fair Use Policy? [\#](https://supabase.com/docs/guides/platform/billing-faq\#what-is-the-fair-use-policy)

Our Fair Use Policy gives developers the freedom to build and experiment with Supabase, while protecting our infrastructure. Under the Fair Use policy, service restrictions may apply to your organization if:

- You continually exceed the Free Plan quota
- You continually exceed Pro Plan quota and have the spend cap enabled
- You have overdue invoices
- You have an expired credit card

You will receive a notification before Fair Use Policy restrictions are applied. However, in some cases, like suspected abuse of our services, restrictions may be applied without prior notice.

#### How is the Fair Use Policy applied? [\#](https://supabase.com/docs/guides/platform/billing-faq\#how-is-the-fair-use-policy-applied)

The Fair Use Policy is applied through service restrictions. This could mean:

- Pausing projects
- Switching databases to read-only mode
- Disabling new project launches/transfers
- Responding with a [402 status code](https://supabase.com/docs/guides/platform/http-status-codes#402-service-restriction) for all API requests

The Fair Use Policy is generally applied to all projects of the restricted organization.

#### How can I remove restrictions applied from the Fair Use Policy? [\#](https://supabase.com/docs/guides/platform/billing-faq\#how-can-i-remove-restrictions-applied-from-the-fair-use-policy)

To remove restrictions, you will need to address the issue that caused the restriction. This could be reducing your usage, paying overdue invoices, updating your payment method, or any other issue that caused the restriction. Once the issue is resolved, the restriction will be lifted.

Restrictions due to usage limits are lifted with the next billing cycle as your quota refills at the beginning of each cycle. You can see when your current billing cycle ends on the [billing page](https://supabase.com/dashboard/org/_/usage) under "Billing Breakdown". If your organization is on the Free Plan, you can also lift restrictions immediately by [upgrading](https://supabase.com/dashboard/org/_/billing?panel=subscriptionPlan) to Pro.

## Reports and invoices [\#](https://supabase.com/docs/guides/platform/billing-faq\#reports-and-invoices)

#### Where do I find my invoices? [\#](https://supabase.com/docs/guides/platform/billing-faq\#where-do-i-find-my-invoices)

You can find all invoices from your organization on your [organizations invoices page](https://supabase.com/dashboard/org/_/invoices).

#### Where can I see a breakdown of usage? [\#](https://supabase.com/docs/guides/platform/billing-faq\#where-can-i-see-a-breakdown-of-usage)

You can find the breakdown of your usage on your [organizations usage page](https://supabase.com/dashboard/org/_/usage).

#### Where can I check my credit balance? [\#](https://supabase.com/docs/guides/platform/billing-faq\#where-can-i-check-my-credit-balance)

You can check your Credit balance on the [organizations billing page](https://supabase.com/dashboard/org/_/billing). Credits will be used on future invoices before charging your payment method. If you have enough credits to cover an invoice, there is no charge at all.

#### Can I include the VAT number? [\#](https://supabase.com/docs/guides/platform/billing-faq\#can-i-include-the-vat-number)

You can update your VAT number in the Tax ID section of your [organizations billing page](https://supabase.com/dashboard/org/_/billing).

#### Can I change the details of an existing invoice? [\#](https://supabase.com/docs/guides/platform/billing-faq\#can-i-change-the-details-of-an-existing-invoice)

Any changes made to your billing details will only be reflected in your upcoming invoices. Our payment provider cannot regenerate previous invoices. Therefore, make sure to update the billing details before the upcoming invoices are finalized.

## Payments and billing cycle [\#](https://supabase.com/docs/guides/platform/billing-faq\#payments-and-billing-cycle)

#### What payment methods are available? [\#](https://supabase.com/docs/guides/platform/billing-faq\#what-payment-methods-are-available)

We accept credit card payments only. If you cannot pay via credit card, we do offer alternatives for larger upfront payments. Create a [support ticket](https://supabase.help/) in case youre interested.

#### What credit card brands are supported? [\#](https://supabase.com/docs/guides/platform/billing-faq\#what-credit-card-brands-are-supported)

Visa, Mastercard, American Express, Japan Credit Bureau (JCB), China UnionPay (CUP), Cartes Bancaires

#### What currency can I pay in? [\#](https://supabase.com/docs/guides/platform/billing-faq\#what-currency-can-i-pay-in)

All our invoices are issued in USD, but you can pay in any currency so long as the credit card provider allows charging in USD after conversion.

#### Can I change the payment method? [\#](https://supabase.com/docs/guides/platform/billing-faq\#can-i-change-the-payment-method)

Yes, you will have to add the new payment method before being allowed to remove the old one.
This can be done from your dashboard on the [organizations billing page](https://supabase.com/dashboard/org/_/billing).

Read more on [Manage your payment methods](https://supabase.com/docs/guides/platform/manage-your-subscription#manage-your-payment-methods).

#### Can I pay upfront for multiple months? [\#](https://supabase.com/docs/guides/platform/billing-faq\#can-i-pay-upfront-for-multiple-months)

You can top up your credit balance to cover multiple months through your [organizations billing page](https://supabase.com/dashboard/org/_/billing).

Read more on [Credit top-ups](https://supabase.com/docs/guides/platform/credits#credit-top-ups).

#### When are payments taken? [\#](https://supabase.com/docs/guides/platform/billing-faq\#when-are-payments-taken)

Payments are taken at the beginning of each billing cycle. You will be charged once a month. You can see the current billing cycle and upcoming invoice in your [organization's billing settings](https://supabase.com/dashboard/org/_/billing). The subscription plan fee is charged upfront, whereas usage-charges, including compute, are charged in arrears based on your usage.

Read more on [Your monthly invoice](https://supabase.com/docs/guides/platform/your-monthly-invoice).

#### Where can I change my billing details? [\#](https://supabase.com/docs/guides/platform/billing-faq\#where-can-i-change-my-billing-details)

You can update your billing details on the [organizations billing page](https://supabase.com/dashboard/org/_/billing).
Note that any changes made to your billing details will only be reflected in your upcoming invoices. Our payment provider cannot regenerate previous invoices.

#### What happens if I am unable to make the payment? [\#](https://supabase.com/docs/guides/platform/billing-faq\#what-happens-if-i-am-unable-to-make-the-payment)

When an invoice becomes overdue, we will pause your projects and downgrade your organization to the Free Plan. You will be able to restore your projects once you have paid all outstanding invoices.

#### Why am I overdue? [\#](https://supabase.com/docs/guides/platform/billing-faq\#why-am-i-overdue)

We were unable to charge your payment method. This likely means that the payment was not successfully processed with the credit card on your account profile.
You can be overdue when

- A card is expired
- The bank declined the payment
- You had insufficient funds
- There was no card on record

Check your payment methods in your [organizations billing page](https://supabase.com/dashboard/org/_/billing) to ensure there are no expired payment methods and the correct payment method is marked as default.
If you are still facing issues, raise a [support ticket](https://supabase.help/).

Payments are always in USD and may show up as coming from Singapore, given our payment entity is in Singapore. Make sure you allow payments from Singapore and in USD

#### Can I delay my payment? [\#](https://supabase.com/docs/guides/platform/billing-faq\#can-i-delay-my-payment)

No, you cannot delay your payment.

#### Can I get a refund of my unused credits? [\#](https://supabase.com/docs/guides/platform/billing-faq\#can-i-get-a-refund-of-my-unused-credits)

No, we do not provide refunds. Please refer to our [Terms of Service](https://supabase.com/terms#1-fees).

#### What do I do if my bill looks wrong? [\#](https://supabase.com/docs/guides/platform/billing-faq\#what-do-i-do-if-my-bill-looks-wrong)

Take a moment to review our [Your monthly invoice](https://supabase.com/docs/guides/platform/your-monthly-invoice) page, which may help clarify any questions about your invoice. If it still looks wrong, submit a [support ticket](https://supabase.help/) through the dashboard. Select the affected organization and provide the invoice number for us to look at your case.

### Is this helpful?

NoYes

### On this page

[Organizations and projects](https://supabase.com/docs/guides/platform/billing-faq#organizations-and-projects) [Pricing](https://supabase.com/docs/guides/platform/billing-faq#pricing) [Plans and subscriptions](https://supabase.com/docs/guides/platform/billing-faq#plans-and-subscriptions) [Quotas and spend caps](https://supabase.com/docs/guides/platform/billing-faq#quotas-and-spend-caps) [Fair Use Policy](https://supabase.com/docs/guides/platform/billing-faq#fair-use-policy) [Reports and invoices](https://supabase.com/docs/guides/platform/billing-faq#reports-and-invoices) [Payments and billing cycle](https://supabase.com/docs/guides/platform/billing-faq#payments-and-billing-cycle)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_billing_on_supabase.md">
Platform

# About billing on Supabase

* * *

## Subscription plans [\#](https://supabase.com/docs/guides/platform/billing-on-supabase\#subscription-plans)

Supabase offers different subscription plansFree, Pro, Team, and Enterprise. For a closer look at each plan's features and pricing, visit our [pricing page](https://supabase.com/pricing).

### Free Plan [\#](https://supabase.com/docs/guides/platform/billing-on-supabase\#free-plan)

The Free Plan helps you get started and explore the platform. You are granted two free projects. The project limit applies across all organizations where you are an Owner or Administrator. This means you could have two Free Plan organizations with one project each, or one Free Plan organization with two projects. Paused projects do not count towards your free project limit.

### Paid plans [\#](https://supabase.com/docs/guides/platform/billing-on-supabase\#paid-plans)

Upgrading your organization to a paid plan provides additional features, and you receive a higher [usage quota](https://supabase.com/docs/guides/platform/billing-on-supabase#variable-usage-fees-and-quotas). You unlock the benefits of the paid plan for all projects within your organization - for example, no projects in your Pro Plan organization will be paused.

## Organization-based billing [\#](https://supabase.com/docs/guides/platform/billing-on-supabase\#organization-based-billing)

Supabase bills separately for each organization. Each organization has its own subscription, including a unique subscription plan (Free, Pro, Team, or Enterprise), payment method, billing cycle, and invoices.

Different plans cannot be mixed within a single organization. For example, you cannot have both a Pro Plan project and a Free Plan project in the same organization. To have projects on different plans, you must create separate organizations. See [Project Transfers](https://supabase.com/docs/guides/platform/project-transfer) if you need to move a project to a different organization.

![Organization-based billing](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fbilling-overview--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

## Costs [\#](https://supabase.com/docs/guides/platform/billing-on-supabase\#costs)

Monthly costs for paid plans include a fixed subscription fee based on your chosen plan and variable usage fees. To learn more about billing and cost management, refer to the following resources.

- [Your monthly invoice](https://supabase.com/docs/guides/platform/your-monthly-invoice) \- For a detailed breakdown of what a monthly invoice includes
- [Manage your usage](https://supabase.com/docs/guides/platform/manage-your-usage) \- For details on how the different usage items are billed, and how to optimize usage and reduce costs
- [Control your costs](https://supabase.com/docs/guides/platform/billing-on-supabase) \- For details on how you can control your costs in case unexpected high usage occurs

### Compute costs for projects [\#](https://supabase.com/docs/guides/platform/billing-on-supabase\#compute-costs-for-projects)

An organization can have multiple projects. Each project includes a dedicated Postgres instance running on its own server. You are charged for the Compute resources of that server, independent of your database usage.

Each project you launch increases your monthly Compute costs.

Read more about [Compute costs](https://supabase.com/docs/guides/platform/manage-your-usage/compute).

## Variable Usage Fees and Quotas [\#](https://supabase.com/docs/guides/platform/billing-on-supabase\#variable-usage-fees-and-quotas)

Each subscription plan includes a built-in quota for some selected usage items, such as [Egress](https://supabase.com/docs/guides/platform/manage-your-usage/egress), [Storage Size](https://supabase.com/docs/guides/platform/manage-your-usage/storage-size), or [Edge Function Invocations](https://supabase.com/docs/guides/platform/manage-your-usage/edge-function-invocations). This quota represents your free usage allowance. If you stay within it, you incur no extra charges for these items. Only usage beyond the quota is billed as overage.

For usage items without a quota, such as [Compute](https://supabase.com/docs/guides/platform/manage-your-usage/compute) or [Custom Domains](https://supabase.com/docs/guides/platform/manage-your-usage/custom-domains), you are charged for your entire usage.

The quota is applied to your entire organization, independent of how many projects you launch within that organization. For billing purposes, we sum the usage across all projects in a monthly invoice.

| Usage Item | Free | Pro/Team | Enterprise |
| --- | --- | --- | --- |
| Egress | 5 GB | 250 GB included, then $0.09 per GB | Custom |
| Database Size | 500 MB | 8 GB disk per project included, then $0.125 per GB | Custom |
| Monthly Active Users | 50,000 MAU | 100,000 MAU included, then $0.00325 per MAU | Custom |
| Monthly Active Third-Party Users | 50 MAU | 50 MAU included, then $0.00325 per MAU | Custom |
| Monthly Active SSO Users | Unavailable on Free Plan | 50 MAU included, then $0.015 per MAU | Custom |
| Storage Size | 1 GB | 100 GB included, then $0.021 per GB | Custom |
| Storage Images Transformed | Unavailable on Free Plan | 100 included, then $5 per 1000 | Custom |
| Edge Function Invocations | 500,000 | 2 million included, then $2 per million | Custom |
| Realtime Message Count | 2 million | 5 million included, then $2.5 per million | Custom |
| Realtime Peak Connections | 200 | 500 included, then $10 per 1000 | Custom |

You can find a detailed breakdown of all usage items and how they are billed on the [Manage your usage](https://supabase.com/docs/guides/platform/manage-your-usage) page.

## Project add-ons [\#](https://supabase.com/docs/guides/platform/billing-on-supabase\#project-add-ons)

While your subscription plan applies to your entire organization and is charged only once, you can enhance individual projects by opting into various add-ons.

- [Compute](https://supabase.com/docs/guides/platform/compute-and-disk#compute) to scale your database up to 64 cores and 256 GB RAM
- [Read Replicas](https://supabase.com/docs/guides/platform/read-replicas) to scale read operations and provide resiliency
- [Disk](https://supabase.com/docs/guides/platform/compute-and-disk#disk) to provision extra IOPS/throughput or use a high-performance SSD
- [Log Drains](https://supabase.com/docs/guides/telemetry/log-drains) to sync Supabase logs to a logging system of your choice
- [Custom Domains](https://supabase.com/docs/guides/platform/custom-domains) to provide a branded experience
- [PITR](https://supabase.com/docs/guides/platform/backups#point-in-time-recovery) to roll back to any specific point in time, down to the minute
- [IPv4](https://supabase.com/docs/guides/platform/ipv4-address) for a dedicated IPv4 address
- [Advanced MFA](https://supabase.com/docs/guides/auth/auth-mfa/phone) to provide other options than TOTP

### Is this helpful?

NoYes

### On this page

[Subscription plans](https://supabase.com/docs/guides/platform/billing-on-supabase#subscription-plans) [Free Plan](https://supabase.com/docs/guides/platform/billing-on-supabase#free-plan) [Paid plans](https://supabase.com/docs/guides/platform/billing-on-supabase#paid-plans) [Organization-based billing](https://supabase.com/docs/guides/platform/billing-on-supabase#organization-based-billing) [Costs](https://supabase.com/docs/guides/platform/billing-on-supabase#costs) [Compute costs for projects](https://supabase.com/docs/guides/platform/billing-on-supabase#compute-costs-for-projects) [Variable Usage Fees and Quotas](https://supabase.com/docs/guides/platform/billing-on-supabase#variable-usage-fees-and-quotas) [Project add-ons](https://supabase.com/docs/guides/platform/billing-on-supabase#project-add-ons)

![Organization-based billing](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fbilling-overview--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_compute_and_disk.md">
Platform

# Compute and Disk

* * *

## Compute [\#](https://supabase.com/docs/guides/platform/compute-and-disk\#compute)

Every project on the Supabase Platform comes with its own dedicated Postgres instance.

The following table describes the base instances, Nano (free plan) and Micro (paid plans), with additional compute instance sizes available if you need extra performance when scaling up.

##### Nano instances in paid plan organizations

In paid organizations, Nano Compute are billed at the same price as Micro Compute. It is recommended to upgrade your Project from Nano Compute to Micro Compute when it's convenient for you. Compute sizes are not auto-upgraded because of the downtime incurred. See [Supabase Pricing](https://supabase.com/pricing) for more information. You cannot launch Nano instances on paid plans, only Micro and above - but you might have Nano instances after upgrading from Free Plan.

| Compute Size | Hourly Price USD | Monthly Price USD | CPU | Memory | Max DB Size (Recommended)[1](https://supabase.com/docs/guides/platform/compute-and-disk#user-content-fn-2) |
| --- | --- | --- | --- | --- | --- |
| Nano[2](https://supabase.com/docs/guides/platform/compute-and-disk#user-content-fn-3) | $0 | $0 | Shared | Up to 0.5 GB | 500 MB |
| Micro | $0.01344 | ~$10 | 2-core ARM (shared) | 1 GB | 10 GB |
| Small | $0.0206 | ~$15 | 2-core ARM (shared) | 2 GB | 50 GB |
| Medium | $0.0822 | ~$60 | 2-core ARM (shared) | 4 GB | 100 GB |
| Large | $0.1517 | ~$110 | 2-core ARM (dedicated) | 8 GB | 200 GB |
| XL | $0.2877 | ~$210 | 4-core ARM (dedicated) | 16 GB | 500 GB |
| 2XL | $0.562 | ~$410 | 8-core ARM (dedicated) | 32 GB | 1 TB |
| 4XL | $1.32 | ~$960 | 16-core ARM (dedicated) | 64 GB | 2 TB |
| 8XL | $2.562 | ~$1,870 | 32-core ARM (dedicated) | 128 GB | 4 TB |
| 12XL | $3.836 | ~$2,800 | 48-core ARM (dedicated) | 192 GB | 6 TB |
| 16XL | $5.12 | ~$3,730 | 64-core ARM (dedicated) | 256 GB | 10 TB |

Compute sizes can be changed by first selecting your project in the dashboard [here](https://supabase.com/dashboard/project/_/settings/compute-and-disk) and the upgrade process will [incur downtime](https://supabase.com/docs/guides/platform/compute-and-disk#upgrade-downtime).

![Compute Size Selection](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fcompute-size-selection--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

We charge hourly for additional compute based on your usage. Read more about [usage-based billing for compute](https://supabase.com/docs/guides/platform/manage-your-usage/compute).

### Dedicated vs shared CPU [\#](https://supabase.com/docs/guides/platform/compute-and-disk\#dedicated-vs-shared-cpu)

All Postgres databases on Supabase run in isolated environments. Compute instances smaller than `Large` compute size have CPUs which can burst to higher performance levels for short periods of time. Instances bigger than `Large` have predictable performance levels and do not exhibit the same burst behavior.

### Compute upgrades [\#](https://supabase.com/docs/guides/platform/compute-and-disk\#upgrades)

Compute instance changes are usually applied with less than 2 minutes of downtime, but can take longer depending on the underlying Cloud Provider.

When considering compute upgrades, assess whether your bottlenecks are hardware-constrained or software-constrained. For example, you may want to look into [optimizing the number of connections](https://supabase.com/docs/guides/platform/performance#optimizing-the-number-of-connections) or [examining query performance](https://supabase.com/docs/guides/platform/performance#examining-query-performance). When you're happy with your Postgres instance's performance, then you can focus on additional compute resources. For example, you can load test your application in staging to understand your compute requirements. You can also start out on a smaller tier, [create a report](https://supabase.com/dashboard/project/_/reports) in the Dashboard to monitor your CPU utilization, and upgrade as needed.

## Disk [\#](https://supabase.com/docs/guides/platform/compute-and-disk\#disk)

Supabase databases are backed by high performance SSD disks. The _effective performance_ depends on a combination of all the following factors:

- Compute size
- Provisioned Disk Throughput
- Provisioned Disk IOPS: Input/Output Operations per Second, which measures the number of read and write operations.
- Disk type: io2 or gp3
- Disk size

The disk size and the disk type dictate the maximum IOPS and throughput that can be provisioned. The effective IOPS is the lower of the IOPS supported by the compute size or the provisioned IOPS of the disk. Similarly, the effective throughout is the lower of the throughput supported by the compute size and the provisioned throughput of the disk.

The following sections explain how these attributes affect disk performance.

### Compute size [\#](https://supabase.com/docs/guides/platform/compute-and-disk\#compute-size)

The compute size of your project sets the upper limit for disk throughput and IOPS. The table below shows the limits for each instance size. For instance, an 8XL compute instance has a maximum throughput of 9,500 MiB/s and a maximum IOPS of 40,000.

| Compute Instance | Disk Throughput | IOPS |
| --- | --- | --- |
| Nano (free) | 43 MiB/s | 250 IOPS |
| Micro | 87 MiB/s | 500 IOPS |
| Small | 174 MiB/s | 1,000 IOPS |
| Medium | 347 MiB/s | 2,000 IOPS |
| Large | 630 MiB/s | 3,600 IOPS |
| XL | 1,188 MiB/s | 6,000 IOPS |
| 2XL | 2,375 MiB/s | 12,000 IOPS |
| 4XL | 4,750 MiB/s | 20,000 IOPS |
| 8XL | 9,500 MiB/s | 40,000 IOPS |
| 12XL | 14,250 MiB/s | 50,000 IOPS |
| 16XL | 19,000 MiB/s | 80,000 IOPS |

Smaller compute instances like Nano, Micro, Small, and Medium have baseline performance levels that can occasionally be exceeded for short periods of time. If it does exceed the baseline, you should consider upgrading your instance size for a more reliable performance.

Larger compute instances (4XL and above) are designed for sustained, high performance with specific IOPS and throughput limits which you can [configure](https://supabase.com/docs/guides/platform/manage-your-usage/disk-throughput). If you hit your IOPS or throughput limit, throttling will occur.

### Choosing the right compute instance for consistent disk performance [\#](https://supabase.com/docs/guides/platform/compute-and-disk\#choosing-the-right-compute-instance-for-consistent-disk-performance)

If you need consistent disk performance, choose the 4XL or larger compute instance. If you're unsure of how much throughput or IOPS your application requires, you can load test your project and inspect these [metrics in the Dashboard](https://supabase.com/dashboard/project/_/reports). If the `Disk IO % consumed` stat is more than 1%, it indicates that your workload has exceeded the baseline IO throughput during the day. If this metric goes to 100%, the workload has used up all available disk IO budget. Projects that use any disk IO budget are good candidates for upgrading to a larger compute instance with higher throughput.

### Provisioned disk throughput and IOPS [\#](https://supabase.com/docs/guides/platform/compute-and-disk\#provisioned-disk-throughput-and-iops)

The default disk type is gp3, which comes with a baseline throughput of 125 MiB/s and a default IOPS of 3,000. You can provision additional IOPS and throughput from the [Database Settings](https://supabase.com/dashboard/project/_/settings/compute-and-disk) page, but keep in mind that the effective IOPS and throughput will be limited by the compute instance size. This requires Large compute size or above.

Be aware that increasing IOPS or throughput incurs additional charges.

### Disk types [\#](https://supabase.com/docs/guides/platform/compute-and-disk\#disk-types)

When selecting your disk, it's essential to focus on the performance needs of your workload. Here's a comparison of our available disk types:

|  | General Purpose SSD (gp3) | High Performance SSD (io2) |
| --- | --- | --- |
| **Use Case** | General workloads, development environments, small to medium databases | High-performance needs, large-scale databases, mission-critical applications |
| **Max Disk Size** | 16 TB | 60 TB |
| **Max IOPS** | 16,000 IOPS (at 32 GB disk size) | 80,000 IOPS (at 80 GB disk size) |
| **Throughput** | 125 MiB/s (default) to 1,000 MiB/s (maximum) | Automatically scales with IOPS |
| **Best For** | Great value for most use cases | Low latency and very high IOPS requirements |
| **Pricing** | Disk: 8 GB included, then $0.125 per GB<br>IOPS: 3,000 included, then $0.024 per IOPS<br>Throughput: 125 Mbps included, then $0.95 per Mbps | Disk: $0.195 per GB<br>IOPS: $0.119 per IOPS<br>Throughput: Scales with IOPS at no additional cost |

For general, day-to-day operations, gp3 should be more than enough. If you need high throughput and IOPS for critical systems, io2 will provide the performance required.

Compute instance size changes will not change your selected disk type or disk size, but your IO limits may change according to what your selected compute instance size supports.

### Disk size [\#](https://supabase.com/docs/guides/platform/compute-and-disk\#disk-size)

- General Purpose (gp3) disks come with a baseline of 3,000 IOPS and 125 MiB/s. You can provision additional 500 IOPS for every GB of disk size and additional 0.25 MiB/s throughput per provisioned IOPS.
- High Performance (io2) disks can be provisioned with 1,000 IOPS per GB of disk size.

## Limits and constraints [\#](https://supabase.com/docs/guides/platform/compute-and-disk\#limits-and-constraints)

### Postgres replication slots, WAL senders, and connections [\#](https://supabase.com/docs/guides/platform/compute-and-disk\#postgres-replication-slots-wal-senders-and-connections)

[Replication Slots](https://postgresqlco.nf/doc/en/param/max_replication_slots) and [WAL Senders](https://postgresqlco.nf/doc/en/param/max_wal_senders/) are used to enable [Postgres Replication](https://supabase.com/docs/guides/database/replication). Each compute instance also has limits on the maximum number of database connections and connection pooler clients it can handle.

The maximum number of replication slots, WAL senders, database connections, and pooler clients depends on your compute instance size, as follows:

| Compute instance | Max Replication Slots | Max WAL Senders | Database Max Connections[3](https://supabase.com/docs/guides/platform/compute-and-disk#user-content-fn-1) | Connection Pooler Max Clients |
| --- | --- | --- | --- | --- |
| Nano (free) | 5 | 5 | 60 | 200 |
| Micro | 5 | 5 | 60 | 200 |
| Small | 5 | 5 | 90 | 400 |
| Medium | 5 | 5 | 120 | 600 |
| Large | 8 | 8 | 160 | 800 |
| XL | 24 | 24 | 240 | 1,000 |
| 2XL | 80 | 80 | 380 | 1,500 |
| 4XL | 80 | 80 | 480 | 3,000 |
| 8XL | 80 | 80 | 490 | 6,000 |
| 12XL | 80 | 80 | 500 | 9,000 |
| 16XL | 80 | 80 | 500 | 12,000 |

As mentioned in the Postgres [documentation](https://postgresqlco.nf/doc/en/param/max_replication_slots/), setting `max_replication_slots` to a lower value than the current number of replication slots will prevent the server from starting. If you are downgrading your compute instance, ensure that you are using fewer slots than the maximum number of replication slots available for the new compute instance.

### Constraints [\#](https://supabase.com/docs/guides/platform/compute-and-disk\#constraints)

- After **any** disk attribute change, there is a cooldown period of approximately six hours before you can make further adjustments. During this time, no changes are allowed. If you encounter throttling, youll need to wait until the cooldown period concludes before making additional modifications.
- You can increase disk size but cannot decrease it.

## Footnotes [\#](https://supabase.com/docs/guides/platform/compute-and-disk\#footnote-label)

1. Database size for each compute instance is the default recommendation but the actual performance of your database has many contributing factors, including resources available to it and the size of the data contained within it. See the [shared responsibility model](https://supabase.com/docs/guides/platform/shared-responsibility-model) for more information. [](https://supabase.com/docs/guides/platform/compute-and-disk#user-content-fnref-2)

2. Compute resources on the Free plan are subject to change. [](https://supabase.com/docs/guides/platform/compute-and-disk#user-content-fnref-3)

3. Database max connections are recommended values and can be customized depending on your use case. [](https://supabase.com/docs/guides/platform/compute-and-disk#user-content-fnref-1)


### Is this helpful?

NoYes

### On this page

[Compute](https://supabase.com/docs/guides/platform/compute-and-disk#compute) [Dedicated vs shared CPU](https://supabase.com/docs/guides/platform/compute-and-disk#dedicated-vs-shared-cpu) [Compute upgrades](https://supabase.com/docs/guides/platform/compute-and-disk#upgrades) [Disk](https://supabase.com/docs/guides/platform/compute-and-disk#disk) [Compute size](https://supabase.com/docs/guides/platform/compute-and-disk#compute-size) [Choosing the right compute instance for consistent disk performance](https://supabase.com/docs/guides/platform/compute-and-disk#choosing-the-right-compute-instance-for-consistent-disk-performance) [Provisioned disk throughput and IOPS](https://supabase.com/docs/guides/platform/compute-and-disk#provisioned-disk-throughput-and-iops) [Disk types](https://supabase.com/docs/guides/platform/compute-and-disk#disk-types) [Disk size](https://supabase.com/docs/guides/platform/compute-and-disk#disk-size) [Limits and constraints](https://supabase.com/docs/guides/platform/compute-and-disk#limits-and-constraints) [Postgres replication slots, WAL senders, and connections](https://supabase.com/docs/guides/platform/compute-and-disk#postgres-replication-slots-wal-senders-and-connections) [Constraints](https://supabase.com/docs/guides/platform/compute-and-disk#constraints) [Footnotes](https://supabase.com/docs/guides/platform/compute-and-disk#footnote-label)

![Compute Size Selection](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fcompute-size-selection--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_cost_control.md">
Platform

# Control your costs

* * *

## Spend Cap [\#](https://supabase.com/docs/guides/platform/cost-control\#spend-cap)

The Spend Cap determines whether your organization can exceed your subscription plan's quota for any usage item. Scenarios that could lead to high usageand thus high costsinclude system attacks or bugs in your software. The Spend Cap can protect you from these unexpected costs for certain usage items.

This feature is available only with the Pro Plan. However, you will not be charged while using the Free Plan.

### What happens when the Spend Cap is on? [\#](https://supabase.com/docs/guides/platform/cost-control\#what-happens-when-the-spend-cap-is-on)

After exceeding the quota for a usage item, further usage of that item is disallowed until the next billing cycle. You don't get charged for over-usage but your services will be restricted according to our [Fair Use Policy](https://supabase.com/docs/guides/platform/billing-faq#fair-use-policy) if you consistently exceed the quota.

Note that only certain usage items are covered by the Spend Cap.

### What happens when the Spend Cap is off? [\#](https://supabase.com/docs/guides/platform/cost-control\#what-happens-when-the-spend-cap-is-off)

Your projects will continue to operate after exceeding the quota for a usage item. Any additional usage will be charged based on the item's cost per unit, as outlined on the [pricing page](https://supabase.com/pricing).

When the Spend Cap is off, we recommend monitoring your usage and costs on the [organization's\\
usage page](https://supabase.com/dashboard/org/_/usage).

### Usage items covered by the Spend Cap [\#](https://supabase.com/docs/guides/platform/cost-control\#usage-items-covered-by-the-spend-cap)

- [Disk Size](https://supabase.com/docs/guides/platform/manage-your-usage/disk-size)
- [Egress](https://supabase.com/docs/guides/platform/manage-your-usage/egress)
- [Edge Function Invocations](https://supabase.com/docs/guides/platform/manage-your-usage/edge-function-invocations)
- [Monthly Active Users](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users)
- [Monthly Active SSO Users](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-sso)
- [Monthly Active Third Party Users](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-third-party)
- [Realtime Messages](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-messages)
- [Realtime Peak Connections](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-peak-connections)
- [Storage Image Transformations](https://supabase.com/docs/guides/platform/manage-your-usage/storage-image-transformations)
- [Storage Size](https://supabase.com/docs/guides/platform/manage-your-usage/storage-size)

### Usage items not covered by the Spend Cap [\#](https://supabase.com/docs/guides/platform/cost-control\#usage-items-not-covered-by-the-spend-cap)

Usage items that are predictable and explicitly opted into by the user are excluded.

- [Compute](https://supabase.com/docs/guides/platform/manage-your-usage/compute)
- [Branching Compute](https://supabase.com/docs/guides/platform/manage-your-usage/branching)
- [Read Replica Compute](https://supabase.com/docs/guides/platform/manage-your-usage/read-replicas)
- [Custom Domain](https://supabase.com/docs/guides/platform/manage-your-usage/custom-domains)
- Additionally provisioned [Disk IOPS](https://supabase.com/docs/guides/platform/manage-your-usage/disk-iops)
- Additionally provisioned [Disk Throughput](https://supabase.com/docs/guides/platform/manage-your-usage/disk-throughput)
- [IPv4 address](https://supabase.com/docs/guides/platform/manage-your-usage/ipv4)
- [Log Drain Hours](https://supabase.com/docs/guides/platform/manage-your-usage/log-drains#log-drain-hours)
- [Log Drain Events](https://supabase.com/docs/guides/platform/manage-your-usage/log-drains#log-drain-events)
- [Multi-Factor Authentication Phone](https://supabase.com/docs/guides/platform/manage-your-usage/advanced-mfa-phone)
- [Point-in-Time-Recovery](https://supabase.com/docs/guides/platform/manage-your-usage/point-in-time-recovery)

### What the Spend Cap is not [\#](https://supabase.com/docs/guides/platform/cost-control\#what-the-spend-cap-is-not)

The Spend Cap doesn't allow for fine-grained cost control, such as setting budgets for specific usage item or receiving notifications when certain costs are reached. We plan to make cost control more flexible in the future.

### Configure the Spend Cap [\#](https://supabase.com/docs/guides/platform/cost-control\#configure-the-spend-cap)

You can configure the Spend Cap when creating an organization on the Pro Plan or at any time in the Cost Control section of the [organization's billing page](https://supabase.com/dashboard/org/_/billing).

## Keep track of your usage and costs [\#](https://supabase.com/docs/guides/platform/cost-control\#keep-track-of-your-usage-and-costs)

You can monitor your usage on the [organization's usage page](https://supabase.com/dashboard/org/_/usage). The Billing Breakdown section of the [organization's billing page](https://supabase.com/dashboard/org/_/billing) shows your current spending and provides an estimate of your total costs for the billing cycle based on your usage.

### Is this helpful?

NoYes

### On this page

[Spend Cap](https://supabase.com/docs/guides/platform/cost-control#spend-cap) [What happens when the Spend Cap is on?](https://supabase.com/docs/guides/platform/cost-control#what-happens-when-the-spend-cap-is-on) [What happens when the Spend Cap is off?](https://supabase.com/docs/guides/platform/cost-control#what-happens-when-the-spend-cap-is-off) [Usage items covered by the Spend Cap](https://supabase.com/docs/guides/platform/cost-control#usage-items-covered-by-the-spend-cap) [Usage items not covered by the Spend Cap](https://supabase.com/docs/guides/platform/cost-control#usage-items-not-covered-by-the-spend-cap) [What the Spend Cap is not](https://supabase.com/docs/guides/platform/cost-control#what-the-spend-cap-is-not) [Configure the Spend Cap](https://supabase.com/docs/guides/platform/cost-control#configure-the-spend-cap) [Keep track of your usage and costs](https://supabase.com/docs/guides/platform/cost-control#keep-track-of-your-usage-and-costs)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_credits.md">
Platform

# Credits

* * *

## Credit balance [\#](https://supabase.com/docs/guides/platform/credits\#credit-balance)

Each organization has a credit balance. Credits are applied to future invoices to reduce the amount due. As long as the credit balance is greater than $0, credits will be used before charging your payment method on file.

![Subscription upgrade modal](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fcredit-balance--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

You can find the credit balance on the [organization's billing page](https://supabase.com/dashboard/org/_/billing).

### What causes the credit balance to change? [\#](https://supabase.com/docs/guides/platform/credits\#what-causes-the-credit-balance-to-change)

**Subscription plan downgrades:** Upon subscription downgrade, any prepaid subscription fee will be credited back to your organization for unused time in the billing cycle.

As an example, if you start a Pro Plan subscription on January 1 and downgrade to the Free Plan on January 15, your organization will receive about 50% of the subscription fee as credits for the unused time between January 15 and January 31.

**Credit top-ups:** You self-served a credit top-up or have signed an upfront credits deal with our growth team.

## Credit top-ups [\#](https://supabase.com/docs/guides/platform/credits\#credit-top-ups)

You can top up credits at any time, with a maximum of $999 per top-up. These credits do not expire and are non-refundable.

You may want to consider this option to avoid issues with recurring payments, gain more control over how often your credit card is charged, and potentially make things easier for your accounting department.

If you are interested in larger (> $1,000) credit packages, [reach\\
out](https://supabase.com/dashboard/support/new?subject=I%20would%20like%20to%20inquire%20about%20larger%20credit%20packages&category=Billing).

### How to top up credits [\#](https://supabase.com/docs/guides/platform/credits\#how-to-top-up-credits)

1. On the [organization's billing page](https://supabase.com/dashboard/org/_/billing), go to section **Credit Balance**
2. Click **Top Up**
3. Choose the amount
4. Choose a payment method or add a new payment method
5. Click **Top Up**

![Subscription upgrade modal](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fcredit-top-up--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

## Credit FAQ [\#](https://supabase.com/docs/guides/platform/credits\#credit-faq)

### Can I transfer credits to another organization? [\#](https://supabase.com/docs/guides/platform/credits\#can-i-transfer-credits-to-another-organization)

Yes, you can transfer credits to another organization. Submit a [support ticket](https://supabase.help/).

### Can I get a refund of my unused credits? [\#](https://supabase.com/docs/guides/platform/credits\#can-i-get-a-refund-of-my-unused-credits)

No, we do not provide refunds. Please refer to our [Terms of Service](https://supabase.com/terms#1-fees).

### Is this helpful?

NoYes

### On this page

[Credit balance](https://supabase.com/docs/guides/platform/credits#credit-balance) [What causes the credit balance to change?](https://supabase.com/docs/guides/platform/credits#what-causes-the-credit-balance-to-change) [Credit top-ups](https://supabase.com/docs/guides/platform/credits#credit-top-ups) [How to top up credits](https://supabase.com/docs/guides/platform/credits#how-to-top-up-credits) [Credit FAQ](https://supabase.com/docs/guides/platform/credits#credit-faq) [Can I transfer credits to another organization?](https://supabase.com/docs/guides/platform/credits#can-i-transfer-credits-to-another-organization) [Can I get a refund of my unused credits?](https://supabase.com/docs/guides/platform/credits#can-i-get-a-refund-of-my-unused-credits)

![Subscription upgrade modal](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fcredit-top-up--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![Subscription upgrade modal](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fcredit-balance--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_custom_domains.md">
Platform

# Custom Domains

* * *

Custom domains allow you to present a branded experience to your users. These are available as an [add-on for projects on a paid plan](https://supabase.com/dashboard/project/_/settings/addons?panel=customDomain).

How to setup custom domains in your Supabase projects - SupabaseTips - YouTube

Supabase

45.5K subscribers

[How to setup custom domains in your Supabase projects - SupabaseTips](https://www.youtube.com/watch?v=6rcGnW_Mh-0)

Supabase

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=6rcGnW_Mh-0 "Watch on YouTube")

There are two types of domains supported by Supabase:

1. Custom domains, where you use a domain such as `api.example.com` instead of the project's default domain.
2. Vanity subdomains (experimental), where you can set up a different subdomain on `supabase.co` for your project.

You can choose either a custom domain or vanity subdomain for each project.

## Custom domains [\#](https://supabase.com/docs/guides/platform/custom-domains\#custom-domains)

Custom domains change the way your project's URLs appear to your users. This is useful when:

- You are using [OAuth (Social Login)](https://supabase.com/docs/guides/auth/social-login) with Supabase Auth and the project's URL is shown on the OAuth consent screen.
- You are creating APIs for third-party systems, for example, implementing webhooks or external API calls to your project via [Edge Functions](https://supabase.com/docs/guides/functions).
- You are storing URLs in a database or encoding them in QR codes.

Custom domains help you keep your APIs portable for the long term. By using a custom domain you can migrate from one Supabase project to another, or make it easier to version APIs in the future.

### Configure a custom domain using the Supabase dashboard [\#](https://supabase.com/docs/guides/platform/custom-domains\#configure-a-custom-domain-using-the-supabase-dashboard)

Follow the **Custom Domains** steps in the [General Settings](https://supabase.com/dashboard/project/_/settings/general) page in the Dashboard to set up a custom domain for your project.

### Configure a custom domain using the Supabase CLI [\#](https://supabase.com/docs/guides/platform/custom-domains\#configure-a-custom-domain-using-the-supabase-cli)

This example assumes your Supabase project is `abcdefghijklmnopqrst` with a corresponding API URL `abcdefghijklmnopqrst.supabase.co` and configures a custom domain at `api.example.com`.

To get started:

1. [Install](https://supabase.com/docs/guides/resources/supabase-cli) the latest version of the Supabase CLI.
2. [Log in](https://supabase.com/docs/guides/cli/local-development#log-in-to-the-supabase-cli) to your Supabase account using the CLI.
3. Ensure you have [Owner or Admin permissions](https://supabase.com/docs/guides/platform/access-control#manage-team-members) for the project.
4. Get a custom domain from a DNS provider. Currently, only subdomains are supported.
   - Use `api.example.com` instead of `example.com`.

### Add a CNAME record [\#](https://supabase.com/docs/guides/platform/custom-domains\#add-a-cname-record)

You need to add a CNAME record to your domain's DNS settings to ensure your custom domain points to the Supabase project.

If your project's default domain is `abcdefghijklmnopqrst.supabase.co` you should:

- Create a CNAME record for `api.example.com` that resolves to `abcdefghijklmnopqrst.supabase.co.`.
- Use a low TTL value to quickly propagate changes in case you make a mistake.

### Verify ownership of the domain [\#](https://supabase.com/docs/guides/platform/custom-domains\#verify-ownership-of-the-domain)

Register your domain with Supabase to prove that you own it. You need to download two TXT records and add them to your DNS settings.

In the CLI, run [`domains create`](https://supabase.com/docs/reference/cli/supabase-domains-create) to register the domain and Supabase and get your verification records:

`
supabase domains create --project-ref abcdefghijklmnopqrst --custom-hostname api.example.com
`

A single TXT records is returned. For example:

`
[...]
Required outstanding validation records:
        _acme-challenge.api.example.com. TXT -> ca3-F1HvR9i938OgVwpCFwi1jTsbhe1hvT0Ic3efPY3Q
`

Add the record to your domains' DNS settings. Make sure to trim surrounding whitespace. Use a low TTL value so you can quickly change the records if you make a mistake.

Some DNS registrars automatically append your domain name to the DNS entries being created. As such, creating a DNS record for `api.example.com` might instead create a record for `api.example.com.example.com`. In such cases, remove the domain name from the records you're creating; as an example, you would create a TXT record for `api`, instead of `api.example.com`.

### Verify your domain [\#](https://supabase.com/docs/guides/platform/custom-domains\#verify-your-domain)

Make sure you've configured all required DNS settings:

- CNAME for your custom domain pointing to the Supabase project domain.
- TXT record for `_acme-challenge.<your-custom-domain>`.

Use the [`domains reverify`](https://supabase.com/docs/reference/cli/supabase-domains-reverify) command to begin the verification process of your domain. You may need to run this command a few times because DNS records take a while to propagate.

`
supabase domains reverify --project-ref abcdefghijklmnopqrst
`

In the background, Supabase will check your DNS records and use [Let's Encrypt](https://letsencrypt.org/) to issue a SSL certificate for your domain. This process can take up to 30 minutes.

### Prepare to activate your domain [\#](https://supabase.com/docs/guides/platform/custom-domains\#prepare-to-activate-your-domain)

Before you activate your domain, prepare your applications and integrations for the domain change:

- The project's Supabase domain remains active.
  - You do not need to change the Supabase URL in your applications immediately.
  - You can use it interchangeably with the custom domain.
- Supabase Auth will use the custom domain immediately once activated.
  - OAuth flows will advertise the custom domain as a callback URL.
  - SAML will use the custom domain instead. This means that the `EntityID` of your project has changed, and this may cause SAML with existing identity providers to stop working.

To prevent issues for your users, follow these steps:

1. For each of your Supabase OAuth providers:
   - In the provider's developer console (not in the Supabase dashboard), find the OAuth application and add the custom domain Supabase Auth callback URL **in addition to the Supabase project URL.** Example:
     - `https://abcdefghijklmnopqrst.supabase.co/auth/v1/callback` **and**
     - `https://api.example.com/auth/v1/callback`
   - [Sign in with Twitter](https://supabase.com/docs/guides/auth/social-login/auth-twitter) uses cookies bound to the project's domain. Make sure your frontend code uses the custom domain instead of the default project's domain.
2. For each of your SAML identity providers:
   - Contact your provider and ask them to update the metadata for the SAML application. They should use `https://api.example.com/auth/v1/...` instead of `https://abcdefghijklmnopqrst.supabase.co/auth/v1/sso/saml/{metadata,acs,slo}`.
   - Once these changes are made, SAML Single Sign-On will likely stop working until the domain is activated. Plan for this ahead of time.

### Activate your domain [\#](https://supabase.com/docs/guides/platform/custom-domains\#activate-your-domain)

Once you've done the necessary preparations to activate the new domain for your project, you can activate it using the [`domains activate`](https://supabase.com/docs/reference/cli/supabase-domains-activate) CLI command.

`
supabase domains activate --project-ref abcdefghijklmnopqrst
`

When this step completes, Supabase will serve the requests from your new domain. The Supabase project domain **continues to work** and serve requests so you do not need to rush to change client code URLs.

If you wish to use the new domain in client code, change the URL used in your Supabase client libraries:

`
import { createClient } from '@supabase/supabase-js'
// Use a custom domain as the supabase URL
const supabase = createClient('https://api.example.com', 'public-anon-key')
`

### Remove a custom domain [\#](https://supabase.com/docs/guides/platform/custom-domains\#remove-a-custom-domain)

Removing a custom domain may cause some issues when using Supabase Auth with OAuth or SAML. You may have to reverse the changes made in the _[Prepare to activate your domain](https://supabase.com/docs/guides/platform/custom-domains#prepare-to-activate-your-domain)_ step above.

To remove an activated custom domain you can use the [`domains delete`](https://supabase.com/docs/reference/cli/supabase-domains-delete) CLI command.

`
supabase domains delete --project-ref abcdefghijklmnopqrst
`

## Vanity subdomains [\#](https://supabase.com/docs/guides/platform/custom-domains\#vanity-subdomains)

Vanity subdomains allow you to present a basic branded experience, compared to custom domains. They allow you to host your services at a custom subdomain on Supabase (e.g., `my-example-brand.supabase.co`) instead of the default, randomly assigned `abcdefghijklmnopqrst.supabase.co`.

To get started:

1. [Install](https://supabase.com/docs/guides/resources/supabase-cli) the latest version of the Supabase CLI.
2. [Log in](https://supabase.com/docs/guides/cli/local-development#log-in-to-the-supabase-cli) to your Supabase account using the CLI.
3. Ensure that you have [Owner or Admin permissions](https://supabase.com/docs/guides/platform/access-control#manage-team-members) for the project you'd like to set up a vanity subdomain for.
4. Ensure that your organization is on a paid plan (Pro/Team/Enterprise Plan) in the [Billing page of the Dashboard](https://supabase.com/dashboard/org/_/billing).

### Configure a vanity subdomain [\#](https://supabase.com/docs/guides/platform/custom-domains\#configure-a-vanity-subdomain)

You can configure vanity subdomains via the CLI only.

Let's assume your Supabase project's domain is `abcdefghijklmnopqrst.supabase.co` and you wish to configure a vanity subdomain at `my-example-brand.supabase.co`.

### Check subdomain availability [\#](https://supabase.com/docs/guides/platform/custom-domains\#check-subdomain-availability)

Use the [`vanity-subdomains check-availability`](https://supabase.com/docs/reference/cli/supabase-vanity-subdomains-check-availability) command of the CLI to check if your desired subdomain is available for use:

`
supabase vanity-subdomains --project-ref abcdefghijklmnopqrst check-availability --desired-subdomain my-example-brand --experimental
`

### Prepare to activate the subdomain [\#](https://supabase.com/docs/guides/platform/custom-domains\#prepare-to-activate-the-subdomain)

Before you activate your vanity subdomain, prepare your applications and integrations for the subdomain change:

- The project's Supabase domain remains active and will not go away.
  - You do not need to change the Supabase URL in your applications immediately or at once.
  - You can use it interchangeably with the custom domain.
- Supabase Auth will use the subdomain immediately once activated.
  - OAuth flows will advertise the subdomain as a callback URL.
  - SAML will use the subdomain instead. This means that the `EntityID` of your project has changed, and this may cause SAML with existing identity providers to stop working.

To prevent issues for your users, make sure you have gone through these steps:

1. Go through all of your Supabase OAuth providers:
   - In the provider's developer console (not in the Supabase dashboard!), find the OAuth application and add the subdomain Supabase Auth callback URL **in addition to the Supabase project URL.** Example:
     - `https://abcdefghijklmnopqrst.supabase.co/auth/v1/callback` **and**
     - `https://my-example-brand.supabase.co/auth/v1/callback`
   - [Sign in with Twitter](https://supabase.com/docs/guides/auth/social-login/auth-twitter) uses cookies bound to the project's domain. In this case make sure your frontend code uses the subdomain instead of the default project's domain.
2. Go through all of your SAML identity providers:
   - You will need to reach out via email to all of your existing identity providers and ask them to update the metadata for the SAML application (your project). Use `https://example-brand.supabase.co/auth/v1/...` instead of `https://abcdefghijklmnopqrst.supabase.co/auth/v1/sso/saml/{metadata,acs,slo}`.
   - Once these changes are made, SAML Single Sign-On will likely stop working until the domain is activated. Plan for this ahead of time.

### Activate a subdomain [\#](https://supabase.com/docs/guides/platform/custom-domains\#activate-a-subdomain)

Once you've chosen an available subdomain and have done all the necessary preparations for it, you can reconfigure your Supabase project to start using it.

Use the [`vanity-subdomains activate`](https://supabase.com/docs/reference/cli/supabase-vanity-subdomains-activate) command to activate and claim your subdomain:

`
supabase vanity-subdomains --project-ref abcdefghijklmnopqrst activate --desired-subdomain my-example-brand
`

If you wish to use the new domain in client code, you can set it up like so:

`
import { createClient } from '@supabase/supabase-js'
// Use a custom domain as the supabase URL
const supabase = createClient('https://my-example-brand.supabase.co', 'public-anon-key')
`

When using [Sign in with Twitter](https://supabase.com/docs/guides/auth/social-login/auth-twitter) make sure your frontend code is using the subdomain only.

### Remove a vanity subdomain [\#](https://supabase.com/docs/guides/platform/custom-domains\#remove-a-vanity-subdomain)

Removing a subdomain may cause some issues when using Supabase Auth with OAuth or SAML. You may have to reverse the changes made in the _[Prepare to activate the subdomain](https://supabase.com/docs/guides/platform/custom-domains#prepare-to-activate-the-subdomain)_ step above.

Use the [`vanity-subdomains delete`](https://supabase.com/docs/reference/cli/supabase-vanity-subdomains-delete) command of the CLI to remove the subdomain `my-example-brand.supabase.co` from your project.

`
supabase vanity-subdomains delete --project-ref abcdefghijklmnopqrst --experimental
`

## Pricing [\#](https://supabase.com/docs/guides/platform/custom-domains\#pricing)

For a detailed breakdown of how charges are calculated, refer to [Manage Custom Domain usage](https://supabase.com/docs/guides/platform/manage-your-usage/custom-domains).

### Is this helpful?

NoYes

### On this page

[Custom domains](https://supabase.com/docs/guides/platform/custom-domains#custom-domains) [Configure a custom domain using the Supabase dashboard](https://supabase.com/docs/guides/platform/custom-domains#configure-a-custom-domain-using-the-supabase-dashboard) [Configure a custom domain using the Supabase CLI](https://supabase.com/docs/guides/platform/custom-domains#configure-a-custom-domain-using-the-supabase-cli) [Add a CNAME record](https://supabase.com/docs/guides/platform/custom-domains#add-a-cname-record) [Verify ownership of the domain](https://supabase.com/docs/guides/platform/custom-domains#verify-ownership-of-the-domain) [Verify your domain](https://supabase.com/docs/guides/platform/custom-domains#verify-your-domain) [Prepare to activate your domain](https://supabase.com/docs/guides/platform/custom-domains#prepare-to-activate-your-domain) [Activate your domain](https://supabase.com/docs/guides/platform/custom-domains#activate-your-domain) [Remove a custom domain](https://supabase.com/docs/guides/platform/custom-domains#remove-a-custom-domain) [Vanity subdomains](https://supabase.com/docs/guides/platform/custom-domains#vanity-subdomains) [Configure a vanity subdomain](https://supabase.com/docs/guides/platform/custom-domains#configure-a-vanity-subdomain) [Check subdomain availability](https://supabase.com/docs/guides/platform/custom-domains#check-subdomain-availability) [Prepare to activate the subdomain](https://supabase.com/docs/guides/platform/custom-domains#prepare-to-activate-the-subdomain) [Activate a subdomain](https://supabase.com/docs/guides/platform/custom-domains#activate-a-subdomain) [Remove a vanity subdomain](https://supabase.com/docs/guides/platform/custom-domains#remove-a-vanity-subdomain) [Pricing](https://supabase.com/docs/guides/platform/custom-domains#pricing)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_database_size.md">
Platform

# Understanding Database and Disk Size

* * *

Disk metrics refer to the storage usage reported by Postgres. These metrics are updated daily. As you read through this document, we will refer to "database size" and "disk size":

- _Database size_: Displays the actual size of the data within your Postgres database. This can be found on the [Database Reports page](https://supabase.com/dashboard/project/_/reports/database).

- _Disk size_: Shows the overall disk space usage, which includes both the database size and additional files required for Postgres to function like the Write Ahead Log (WAL) and other system log files. You can view this on the [Database Settings page](https://supabase.com/dashboard/project/_/settings/database).


## Database size [\#](https://supabase.com/docs/guides/platform/database-size\#database-size)

This SQL query will show the size of all databases in your Postgres cluster:

`
select
pg_size_pretty(sum(pg_database_size(pg_database.datname)))
from pg_database;
`

This value is reported in the [database report page](https://supabase.com/dashboard/project/_/reports/database).

Database size is consumed primarily by your data, indexes, and materialized views. You can reduce your database size by removing any of these and running a Vacuum operation.

Depending on your billing plan, your database can go into read-only mode which can prevent you inserting and deleting data. There are instructions for managing read-only mode in the [Disk Management](https://supabase.com/docs/guides/platform/database-size#disk-management) section.

### Disk space usage [\#](https://supabase.com/docs/guides/platform/database-size\#disk-space-usage)

Your database size is part of the disk usage for your Supabase project, there are many components to Postgres that consume additional disk space. One of the primary components, is the [Write Ahead Log (WAL)](https://www.postgresql.org/docs/current/wal-intro.html). Postgres will store database changes in log files that are cleared away after they are applied to the database. These same files are also used by [Read Replicas](https://supabase.com/docs/guides/platform/read-replicas) or other replication methods.

If you would like to determine the size of the WAL files stored on disk, Postgres provides `pg_ls_waldir` as a helper function; the following query can be run:

`
select pg_size_pretty(sum(size)) as wal_size from pg_ls_waldir();
`

### Vacuum operations [\#](https://supabase.com/docs/guides/platform/database-size\#vacuum-operations)

Postgres does not immediately reclaim the physical space used by dead tuples (i.e., deleted rows) in the DB. They are marked as "removed" until a [vacuum operation](https://www.postgresql.org/docs/current/routine-vacuuming.html) is executed. As a result, deleting data from your database may not immediately reduce the reported disk usage. You can use the [Supabase CLI](https://supabase.com/docs/guides/cli/getting-started) `inspect db bloat` command to view all dead tuples in your database. Alternatively, you can run the [query](https://github.com/supabase/cli/blob/c9cce58025fded16b4c332747f819a44f45c3b83/internal/inspect/bloat/bloat.go#L17) found in the CLI's GitHub repo in the [SQL Editor](https://supabase.com/dashboard/project/_/sql/)

`
# Login to the CLI
npx supabase login
# Initialize a local supabase directory
npx supabase init
# Link a project
npx supabase link
# Detect bloat
npx supabase inspect db bloat --linked
`

If you find a table you would like to immediately clean, you can run the following in the [SQL Editor](https://supabase.com/dashboard/project/_/sql/new):

`
vacuum full <table name>;
`

Vacuum operations can temporarily increase resource utilization, which may adversely impact the observed performance of your project until the maintenance is completed. The [vacuum full](https://www.postgresql.org/docs/current/sql-vacuum.html) command will lock the table until the operation concludes.

Supabase projects have automatic vacuuming enabled, which ensures that these operations are performed regularly to keep the database healthy and performant.
It is possible to [fine-tune](https://www.percona.com/blog/2018/08/10/tuning-autovacuum-in-postgresql-and-autovacuum-internals/) the [autovacuum parameters](https://www.enterprisedb.com/blog/postgresql-vacuum-and-analyze-best-practice-tips), or [manually initiate](https://www.postgresql.org/docs/current/sql-vacuum.html) vacuum operations.
Running a manual vacuum after deleting large amounts of data from your DB could help reduce the database size reported by Postgres.

### Preoccupied space [\#](https://supabase.com/docs/guides/platform/database-size\#preoccupied-space)

New Supabase projects have a database size of ~40-60mb. This space includes pre-installed extensions, schemas, and default Postgres data. Additional database size is used when installing extensions, even if those extensions are inactive.

## Disk size [\#](https://supabase.com/docs/guides/platform/database-size\#disk-size)

Supabase uses network-attached storage to balance performance with scalability. The disk scaling behavior depends on your billing plan.

### Paid plan behavior [\#](https://supabase.com/docs/guides/platform/database-size\#paid-plan-behavior)

Projects on the Pro Plan and higher have auto-scaling disks.

Disk size expands automatically when the database reaches 90% of the allocated disk size. The disk is expanded to be 50% larger (for example, 8 GB -> 12 GB). Auto-scaling can only take place once every 6 hours. If within those 6 hours you reach 95% of the disk space, your project will enter read-only mode.

The automatic resize operation will add an additional 50% capped to a maximum of 200 GB. If 50% of your current usage is more than 200 GB then only 200 GB will be added to your disk (for example a size of 1500 GB will resize to 1700 GB).

Disk size can also be manually expanded on the [Database settings page](https://supabase.com/dashboard/project/_/settings/database). The maximum disk size for the Pro/Team Plan is 60 TB. If you need more than this, [contact us](https://forms.supabase.com/enterprise) to learn more about the Enterprise Plan.

You may want to import a lot of data into your database which requires multiple disk expansions. for example, uploading more than 1.5x the current size of your database storage will put your database into [read-only mode](https://supabase.com/docs/guides/platform/database-size#read-only-mode). If so, it is highly recommended you increase the disk size manually on the [Database settings page](https://supabase.com/dashboard/project/_/settings/database).

Due to restrictions on the underlying cloud provider, disk expansions can occur only once every six hours. During the six hour cool down window, the disk cannot be resized again.

### Free Plan behavior [\#](https://supabase.com/docs/guides/platform/database-size\#free-plan-behavior)

Free Plan projects enter [read-only](https://supabase.com/docs/guides/platform/database-size#read-only-mode) mode when you exceed the 500 MB limit. Once in read-only mode, you have these options:

- [Upgrade to the Pro Plan](https://supabase.com/dashboard/org/_/billing) to increase the limit to 8 GB. [Disable the Spend Cap](https://app.supabase.com/org/_/billing?panel=costControl) if you want your Pro instance to auto-scale beyond the 8 GB disk size limit.
- [Disable read-only mode](https://supabase.com/docs/guides/platform/database-size#disabling-read-only-mode) and reduce your database size.

### Read-only mode [\#](https://supabase.com/docs/guides/platform/database-size\#read-only-mode)

In some cases Supabase may put your database into read-only mode to prevent your database from exceeding the billing or disk limitations.

In read-only mode, clients will encounter errors such as `cannot execute INSERT in a read-only transaction`. Regular operation (read-write mode) is automatically re-enabled once usage is below 95% of the disk size,

### Disabling read-only mode [\#](https://supabase.com/docs/guides/platform/database-size\#disabling-read-only-mode)

You manually override read-only mode to reduce disk size. To do this, run the following in the [SQL Editor](https://supabase.com/dashboard/project/_/sql):

First, change the [transaction access mode](https://www.postgresql.org/docs/current/sql-set-transaction.html):

`
set session characteristics as transaction read write;
`

This allows you to delete data from within the session. After deleting data, consider running a vacuum to reclaim as much space as possible:

`
vacuum;
`

Once you have reclaimed space, you can run the following to disable [read-only](https://www.postgresql.org/docs/current/runtime-config-client.html#GUC-DEFAULT-TRANSACTION-READ-ONLY) mode:

`
set default_transaction_read_only = 'off';
`

### Disk size distribution [\#](https://supabase.com/docs/guides/platform/database-size\#disk-size-distribution)

You can check the distribution of your disk size on your [project's compute and disk page](https://supabase.com/dashboard/_/settings/compute-and-disk).

![Disk Size Distribution](https://supabase.com/docs/img/guides/platform/database-size/disk-size-distribution.png)

Your disk size usage falls in three categories:

- **Database** \- Disk usage by the database. This includes the actual data, indexes, materialized views, ...
- **WAL** \- Disk usage by the write-ahead log. The usage depends on your WAL settings and the amount of data being written to the database.
- **System** \- Disk usage reserved by the system to ensure the database can operate smoothly. Users cannot modify this and it should only take very little space.

### Reducing disk size [\#](https://supabase.com/docs/guides/platform/database-size\#reducing-disk-size)

Disks don't automatically downsize during normal operation. Once you have [reduced your database size](https://supabase.com/docs/guides/platform/database-size#database-size), they _will_ automatically "right-size" during a [project upgrade](https://supabase.com/docs/guides/platform/upgrading). The final disk size after the upgrade is 1.2x the size of the database with a minimum of 8 GB. For example, if your database size is 100GB, and you have a 200GB disk, the size after a project upgrade will be 120 GB.

In case you have a large WAL directory, you may [modify WAL settings](https://supabase.com/docs/guides/database/custom-postgres-config) such as `max_wal_size`. Use at your own risk as changing these settings can have side effects. To query your current WAL size, use `SELECT SUM(size) FROM pg_ls_waldir()`.

In the event that your project is already on the latest version of Postgres and cannot be upgraded, a new version of Postgres will be released approximately every week which you can then upgrade to once it becomes available.

### Is this helpful?

NoYes

### On this page

[Database size](https://supabase.com/docs/guides/platform/database-size#database-size) [Disk space usage](https://supabase.com/docs/guides/platform/database-size#disk-space-usage) [Vacuum operations](https://supabase.com/docs/guides/platform/database-size#vacuum-operations) [Preoccupied space](https://supabase.com/docs/guides/platform/database-size#preoccupied-space) [Disk size](https://supabase.com/docs/guides/platform/database-size#disk-size) [Paid plan behavior](https://supabase.com/docs/guides/platform/database-size#paid-plan-behavior) [Free Plan behavior](https://supabase.com/docs/guides/platform/database-size#free-plan-behavior) [Read-only mode](https://supabase.com/docs/guides/platform/database-size#read-only-mode) [Disabling read-only mode](https://supabase.com/docs/guides/platform/database-size#disabling-read-only-mode) [Disk size distribution](https://supabase.com/docs/guides/platform/database-size#disk-size-distribution) [Reducing disk size](https://supabase.com/docs/guides/platform/database-size#reducing-disk-size)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_fly_postgres.md">
Platform

# Fly Postgres

* * *

Fly Postgres databases are deployed on the Fly.io edge network. Fly Postgres is supported in [every region](https://fly.io/docs/reference/regions/) where Fly.io operates.

Fly Postgres is being deprecated on March 14, 2025. Head over to the [announcement](https://github.com/orgs/supabase/discussions/33413) for more information.

## Quickstart [\#](https://supabase.com/docs/guides/platform/fly-postgres\#quickstart)

1. Authenticate via the CLI: `flyctl auth login`
2. Access the Supabase dashboard by running `flyctl extensions supabase dashboard <app-name>`

The full list of CLI commands for Fly Postgres are documented in the [Fly docs](https://fly.io/docs/flyctl/extensions-supabase/).

## Connecting to your database [\#](https://supabase.com/docs/guides/platform/fly-postgres\#connecting-to-your-database)

If your network supports IPv6, connect directly to your Fly Postgres database, as its domain name resolves to an IPv6 address which can be directly used from within your Fly applications.

If your network only supports IPv4, use Supavisor instead of connecting to the database directly. Supavisor's domain name resolves to an IPv4 address, allowing networks without IPv6 support to connect.

To find your database's connection strings, visit the Supabase [database settings page](https://supabase.com/dashboard/project/_/settings/database).

## Studio support [\#](https://supabase.com/docs/guides/platform/fly-postgres\#studio-support)

Access the Supabase studio by running the following command: `flyctl extensions supabase dashboard <app-name>`. This command authenticates with Fly via OAuth and then logs you into the Supabase dashboard.

In the dashboard, you gain access to several powerful tools, including:

- SQL editor: Run SQL queries against your database.
- Table editor: Create, edit and delete tables and columns.
- Log explorer: Inspect real-time logs for your database.
- Postgres upgrades: Upgrade your Fly Postgres instance to the latest version.

## Permissions [\#](https://supabase.com/docs/guides/platform/fly-postgres\#permissions)

Supabase and Fly organizations have a direct one-to-one relationship. When you launch your first Fly Postgres database, it triggers the automatic creation of a corresponding Supabase organization if one does not already exist.

User accounts on Supabase are also created on demand. Every Fly user gets a unique Supabase account, and this account is separate from any Supabase accounts you might already have.

Upon launching a Fly Postgres database, the initiating user is granted the owner role within the new Supabase organization. All subsequent users are added with the `developer` role. Roles can be adjusted in the Supabase dashboard as required.

## Limitations [\#](https://supabase.com/docs/guides/platform/fly-postgres\#limitations)

When using Fly Postgres, be aware of the current restrictions:

- Direct database connections are only supported via IPv6. Read more in the [connecting to your database](https://supabase.com/docs/guides/platform/fly-postgres#connecting-to-your-database) section.
- [Network restrictions](https://supabase.com/docs/guides/platform/network-restrictions) are not supported
- Currently, only the database, Supavisor, and PostgREST are supported. Support for additional Supabase products such as Realtime, Storage, and Auth is planned.
- The [pg\_cron](https://supabase.com/docs/guides/database/extensions/pg_cron) extension is not fully supported for Fly projects. Fly projects shut down after 15 minutes of inactivity, but transparently start up when an external request is received. However, this does not apply to pg\_cron jobs, which arent triggered by external requests. ` pg_cron` jobs dont run when the database is shut down due to inactivity.

### Is this helpful?

NoYes

### On this page

[Quickstart](https://supabase.com/docs/guides/platform/fly-postgres#quickstart) [Connecting to your database](https://supabase.com/docs/guides/platform/fly-postgres#connecting-to-your-database) [Studio support](https://supabase.com/docs/guides/platform/fly-postgres#studio-support) [Permissions](https://supabase.com/docs/guides/platform/fly-postgres#permissions) [Limitations](https://supabase.com/docs/guides/platform/fly-postgres#limitations)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_get_set_up_for_billing.md">
Platform

# Get set up for billing

* * *

Correct billing settings are essential for ensuring successful payment processing and uninterrupted services. Additionally, it's important to configure all invoicing-related data early, as this information cannot be changed once an invoice is issued. Review these key points to ensure everything is set up correctly from the start.

## Payments [\#](https://supabase.com/docs/guides/platform/get-set-up-for-billing\#payments)

### Ensuring valid credit card details [\#](https://supabase.com/docs/guides/platform/get-set-up-for-billing\#ensuring-valid-credit-card-details)

Paid plans require a credit card to be on file. Ensure the correct credit card is set as active and

- has not expired
- has sufficient funds
- has a sufficient transaction limit

For more information on managing payment methods, see [Manage your payment methods](https://supabase.com/docs/guides/platform/manage-your-subscription#manage-your-payment-methods).

### Alternatives to monthly charges [\#](https://supabase.com/docs/guides/platform/get-set-up-for-billing\#alternatives-to-monthly-charges)

Instead of having your credit card charged every month, you can make an upfront payment by topping up your credit balance.

You may want to consider this option to avoid issues with recurring payments, gain more control over how often your credit card is charged, and potentially make things easier for your accounting department.

For more information on credits and credit top-ups, see the [Credits page](https://supabase.com/docs/guides/platform/credits).

## Billing details [\#](https://supabase.com/docs/guides/platform/get-set-up-for-billing\#billing-details)

Billing details cannot be changed once an invoice is issued, so it's crucial to configure them correctly from the start.

You can update your billing email address, billing address and tax ID on the [organization's billing page](https://supabase.com/dashboard/org/_/billing).

### Is this helpful?

NoYes

### On this page

[Payments](https://supabase.com/docs/guides/platform/get-set-up-for-billing#payments) [Ensuring valid credit card details](https://supabase.com/docs/guides/platform/get-set-up-for-billing#ensuring-valid-credit-card-details) [Alternatives to monthly charges](https://supabase.com/docs/guides/platform/get-set-up-for-billing#alternatives-to-monthly-charges) [Billing details](https://supabase.com/docs/guides/platform/get-set-up-for-billing#billing-details)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_hipaa_projects.md">
Platform

# HIPAA Projects

* * *

You can use Supabase to store and process Protected Health Information (PHI). If you want to start developing healthcare apps on Supabase, reach out to the Supabase team [here](https://forms.supabase.com/hipaa2) to sign the Business Associate Agreement (BAA).

Organizations must have a signed BAA with Supabase and have the Health Insurance Portability and Accountability Act (HIPAA) add-on enabled when dealing with PHI.

## Configuring a HIPAA project [\#](https://supabase.com/docs/guides/platform/hipaa-projects\#configuring-a-hipaa-project)

When the HIPAA add-on is enabled on an organization, projects within the organization can be configured as _High Compliance_. This configuration can be found in the [General Project Settings page](https://supabase.com/dashboard/project/_/settings) of the dashboard.
Once enabled, additional security checks will be run against the project to ensure the deployed configuration is compliant. These checks are performed on a continual basis and security warnings will appear in the [Security Advisor](https://supabase.com/dashboard/project/_/advisors/security) if a non-compliant setting is detected.

The required project configuration is outlined in the [shared responsibility model](https://supabase.com/docs/guides/deployment/shared-responsibility-model#managing-healthcare-data) for managing healthcare data.

These include:

- Enabling [Point in Time Recovery](https://supabase.com/docs/guides/platform/backups#point-in-time-recovery) which requires at least a [small compute add-on](https://supabase.com/docs/guides/platform/compute-add-ons).
- Turning on [SSL Enforcement](https://supabase.com/docs/guides/platform/ssl-enforcement).
- Enabling [Network Restrictions](https://supabase.com/docs/guides/platform/network-restrictions).

Additional security checks and controls will be added as the security advisor is extended and additional security controls are made available.

### Is this helpful?

NoYes

### On this page

[Configuring a HIPAA project](https://supabase.com/docs/guides/platform/hipaa-projects#configuring-a-hipaa-project)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_manage_your_subscription.md">
Platform

# Manage your subscription

* * *

## Manage your subscription plan [\#](https://supabase.com/docs/guides/platform/manage-your-subscription\#manage-your-subscription-plan)

To change your subscription plan

1. On the [organization's billing page](https://supabase.com/dashboard/org/_/billing), go to section **Subscription Plan**
2. Click **Change subscription plan**
3. On the side panel, choose a subscription plan
4. Follow the prompts

### Upgrade [\#](https://supabase.com/docs/guides/platform/manage-your-subscription\#upgrade)

Upgrades take effect immediately. During the process, you are informed of the associated costs.

![Subscription upgrade modal](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fupgrade-to-pro-plan-modal--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

If you still have credits in your account, we will use the credits first before charging your card.

### Downgrade [\#](https://supabase.com/docs/guides/platform/manage-your-subscription\#downgrade)

Downgrades take effect immediately. During the process, you are informed of the implications.

![Subscription downgrade modal](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fdowngrade-to-free-plan-modal--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

#### Credits upon downgrade [\#](https://supabase.com/docs/guides/platform/manage-your-subscription\#credits-upon-downgrade)

Upon subscription downgrade, any prepaid subscription fee will be credited back to your organization for unused time in the billing cycle. These credits do not expire and will be applied to future invoices.

**Example:**
If you start a Pro Plan subscription on January 1 and downgrade to the Free Plan on January 15, your organization will receive about 50% of the subscription fee as credits for the unused time between January 15 and January 31.

As stated in our [Terms of Service](https://supabase.com/terms#1-fees), we do not offer refunds to the payment method on file.

#### Charges on downgrade [\#](https://supabase.com/docs/guides/platform/manage-your-subscription\#charges-on-downgrade)

When you downgrade from a paid plan to the Free Plan, you will get credits for the unused time on the paid plan. However, you will also be charged for any excessive usage in the billing cycle.

The plan line item (e.g. Pro Plan) gets charged upfront, whereas all usage charges get charged in arrears, as we only know your usage by the end of the billing cycle. Excessive usage is charged whenever a billing cycle resets, so either when your monthly cycle resets, or whenever you do a plan change.

If you got charged after downgrading to the Free Plan, you had excessive usage in the previous billing cycle. You can check your invoices to see what exactly you were charged for.

## Manage your payment methods [\#](https://supabase.com/docs/guides/platform/manage-your-subscription\#manage-your-payment-methods)

You can add multiple payment methods, but only one can be active at a time.

### Add a payment method [\#](https://supabase.com/docs/guides/platform/manage-your-subscription\#add-a-payment-method)

1. On the [organization's billing page](https://supabase.com/dashboard/org/_/billing), go to section **Payment Methods**
2. Click **Add new card**
3. Provide your credit card details
4. Click **Add payment method**

### Delete a payment method [\#](https://supabase.com/docs/guides/platform/manage-your-subscription\#delete-a-payment-method)

1. On the [organization's billing page](https://supabase.com/dashboard/org/_/billing), go to section **Payment Methods**
2. In the context menu of the payment method you want to delete, click **Delete card**
3. Click **Confirm**

### Set a payment method as active [\#](https://supabase.com/docs/guides/platform/manage-your-subscription\#set-a-payment-method-as-active)

1. On the [organization's billing page](https://supabase.com/dashboard/org/_/billing), go to section **Payment Methods**
2. In the context menu of the payment method you want to delete, click **Use this card**
3. Click **Confirm**

## Manage your billing details [\#](https://supabase.com/docs/guides/platform/manage-your-subscription\#manage-your-billing-details)

You can update your billing email address, billing address and tax ID on the [organization's billing page](https://supabase.com/dashboard/org/_/billing).

Any changes made to your billing details will only be reflected in your upcoming invoices. Our payment provider cannot regenerate previous invoices.

### Is this helpful?

NoYes

### On this page

[Manage your subscription plan](https://supabase.com/docs/guides/platform/manage-your-subscription#manage-your-subscription-plan) [Upgrade](https://supabase.com/docs/guides/platform/manage-your-subscription#upgrade) [Downgrade](https://supabase.com/docs/guides/platform/manage-your-subscription#downgrade) [Manage your payment methods](https://supabase.com/docs/guides/platform/manage-your-subscription#manage-your-payment-methods) [Add a payment method](https://supabase.com/docs/guides/platform/manage-your-subscription#add-a-payment-method) [Delete a payment method](https://supabase.com/docs/guides/platform/manage-your-subscription#delete-a-payment-method) [Set a payment method as active](https://supabase.com/docs/guides/platform/manage-your-subscription#set-a-payment-method-as-active) [Manage your billing details](https://supabase.com/docs/guides/platform/manage-your-subscription#manage-your-billing-details)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings


![Subscription upgrade modal](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fupgrade-to-pro-plan-modal--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![Subscription downgrade modal](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fdowngrade-to-free-plan-modal--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)
</file>

<file path="supabase_com_docs_guides_platform_manage_your_usage_advanced_mfa_phone.md">
Platform

# Manage Advanced MFA Phone usage

* * *

## What you are charged for [\#](https://supabase.com/docs/guides/platform/manage-your-usage/advanced-mfa-phone\#what-you-are-charged-for)

You are charged for having the feature [Advanced Multi-Factor Authentication Phone](https://supabase.com/docs/guides/auth/auth-mfa/phone) enabled for your project.

Additional charges apply for each SMS or WhatsApp message sent, depending on your third-party messaging provider (such as Twilio or MessageBird).

## How charges are calculated [\#](https://supabase.com/docs/guides/platform/manage-your-usage/advanced-mfa-phone\#how-charges-are-calculated)

MFA Phone is charged by the hour, meaning you are charged for the exact number of hours that the feature is enabled for a project. If the feature is enabled for part of an hour, you are still charged for the full hour.

### Example [\#](https://supabase.com/docs/guides/platform/manage-your-usage/advanced-mfa-phone\#example)

Your billing cycle runs from January 1 to January 31. On January 10 at 4:30 PM, you enable the MFA Phone feature for your project. At the end of the billing cycle you are billed for 512 hours.

| Time Window | MFA Phone | Hours Billed | Description |
| --- | --- | --- | --- |
| January 1, 00:00 AM - January 10, 4:00 PM | Disabled | 0 |  |
| January 10, 04:00 PM - January 10, 4:30 PM | Disabled | 0 |  |
| January 10, 04:30 PM - January 10, 5:00 PM | Enabled | 1 | full hour is billed |
| January 10, 05:00 PM - January 31, 23:59 PM | Enabled | 511 |  |

### Usage on your invoice [\#](https://supabase.com/docs/guides/platform/manage-your-usage/advanced-mfa-phone\#usage-on-your-invoice)

Usage is shown as "Auth MFA Phone Hours" on your invoice.

## Pricing [\#](https://supabase.com/docs/guides/platform/manage-your-usage/advanced-mfa-phone\#pricing)

$0.1027 per hour ($75 per month) for the first project. $0.0137 per hour ($10 per month) for every additional project.

| Plan | Project 1 per month | Project 2 per month | Project 3 per month |
| --- | --- | --- | --- |
| Pro | $75 | $10 | $10 |
| Team | $75 | $10 | $10 |
| Enterprise | Custom | Custom | Custom |

## Billing examples [\#](https://supabase.com/docs/guides/platform/manage-your-usage/advanced-mfa-phone\#billing-examples)

### One project [\#](https://supabase.com/docs/guides/platform/manage-your-usage/advanced-mfa-phone\#one-project)

The project has MFA Phone activated throughout the entire billing cycle.

| Line Item | Hours | Costs |
| --- | --- | --- |
| Pro Plan | - | $25 |
| Compute Hours Micro Project 1 | 744 | $10 |
| MFA Phone Hours | 744 | $75 |
| **Subtotal** |  | **$110** |
| Compute Credits |  | -$10 |
| **Total** |  | **$100** |

### Multiple projects [\#](https://supabase.com/docs/guides/platform/manage-your-usage/advanced-mfa-phone\#multiple-projects)

All projects have MFA Phone activated throughout the entire billing cycle.

| Line Item | Hours | Costs |
| --- | --- | --- |
| Pro Plan | - | $25 |
|  |  |  |
| Compute Hours Micro Project 1 | 744 | $10 |
| MFA Phone Hours Project 1 | 744 | $75 |
|  |  |  |
| Compute Hours Micro Project 2 | 744 | $10 |
| MFA Phone Hours Project 2 | 744 | $10 |
|  |  |  |
| Compute Hours Micro Project 3 | 744 | $10 |
| MFA Phone Hours Project 3 | 744 | $10 |
|  |  |  |
| **Subtotal** |  | **$150** |
| Compute Credits |  | -$10 |
| **Total** |  | **$140** |

### Is this helpful?

NoYes

### On this page

[What you are charged for](https://supabase.com/docs/guides/platform/manage-your-usage/advanced-mfa-phone#what-you-are-charged-for) [How charges are calculated](https://supabase.com/docs/guides/platform/manage-your-usage/advanced-mfa-phone#how-charges-are-calculated) [Example](https://supabase.com/docs/guides/platform/manage-your-usage/advanced-mfa-phone#example) [Usage on your invoice](https://supabase.com/docs/guides/platform/manage-your-usage/advanced-mfa-phone#usage-on-your-invoice) [Pricing](https://supabase.com/docs/guides/platform/manage-your-usage/advanced-mfa-phone#pricing) [Billing examples](https://supabase.com/docs/guides/platform/manage-your-usage/advanced-mfa-phone#billing-examples) [One project](https://supabase.com/docs/guides/platform/manage-your-usage/advanced-mfa-phone#one-project) [Multiple projects](https://supabase.com/docs/guides/platform/manage-your-usage/advanced-mfa-phone#multiple-projects)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_manage_your_usage_branching.md">
Platform

# Manage Branching usage

* * *

## What you are charged for [\#](https://supabase.com/docs/guides/platform/manage-your-usage/branching\#what-you-are-charged-for)

Each [Preview branch](https://supabase.com/docs/guides/deployment/branching) is a separate environment with all Supabase services (Database, Auth, Storage, etc.). You're charged for usage within that environmentsuch as [Compute](https://supabase.com/docs/guides/platform/manage-your-usage/compute), [Disk Size](https://supabase.com/docs/guides/platform/manage-your-usage/disk-size), [Egress](https://supabase.com/docs/guides/platform/manage-your-usage/egress), and [Storage](https://supabase.com/docs/guides/platform/manage-your-usage/storage-size)just like the project you branched from.

Usage by Preview branches counts toward your subscription plan's quota.

## How charges are calculated [\#](https://supabase.com/docs/guides/platform/manage-your-usage/branching\#how-charges-are-calculated)

Refer to individual [usage items](https://supabase.com/docs/guides/platform/manage-your-usage) for details on how charges are calculated. Branching charges are the sum of all these items.

### Usage on your invoice [\#](https://supabase.com/docs/guides/platform/manage-your-usage/branching\#usage-on-your-invoice)

Compute incurred by Preview branches is shown as "Branching Compute Hours" on your invoice. Other usage items are not shown separately for branches and are rolled up into the project.

## Pricing [\#](https://supabase.com/docs/guides/platform/manage-your-usage/branching\#pricing)

There is no fixed fee for a Preview branch. You only pay for the usage it incurs. With Compute costs of $0.01344 per hour, a branch running on Micro Compute size starts at $0.32 per day.

## Billing examples [\#](https://supabase.com/docs/guides/platform/manage-your-usage/branching\#billing-examples)

The project has a Preview branch "XYZ", that runs for 30 hours, incurring Compute and Egress costs. Disk Size usage remains within the 8 GB included in the subscription plan, so no additional charges apply.

| Line Item | Costs |
| --- | --- |
| Pro Plan | $25 |
|  |  |
| Compute Hours Small Project 1 | $15 |
| Egress Project 1 | $7 |
| Disk Size Project 1 | $3 |
|  |  |
| Compute Hours Micro Branch XYZ | $0.4 |
| Egress Branch XYZ | $1 |
| Disk Size Branch XYZ | $0 |
|  |  |
| **Subtotal** | **$51.4** |
| Compute Credits | -$10 |
| **Total** | **$41.4** |

## View usage [\#](https://supabase.com/docs/guides/platform/manage-your-usage/branching\#view-usage)

You can view Branching usage on the [organization's usage page](https://supabase.com/dashboard/org/_/usage). The page shows the usage of all projects by default. To view the usage for a specific project, select it from the dropdown. You can also select a different time period.

![Usage page navigation bar](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-navbar--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

In the Usage Summary section, you can see how many hours your Preview branches existed during the selected time period. Hover over "Branches Compute Hours" for a detailed breakdown.

![Usage summary Branches Compute Hours](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-summary-branch-hours--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

## Optimize usage [\#](https://supabase.com/docs/guides/platform/manage-your-usage/branching\#optimize-usage)

- Merge Preview branches as soon as they are ready
- Delete Preview branches that are no longer in use
- Check whether your [persistent branches](https://supabase.com/docs/guides/deployment/branching#persistent-branches) need to be defined as persistent, or if they can be ephemeral instead. Persistent branches will remain active even after the underlying PR is closed.

## FAQ [\#](https://supabase.com/docs/guides/platform/manage-your-usage/branching\#faq)

### Do Compute Credits apply to Branching Compute? [\#](https://supabase.com/docs/guides/platform/manage-your-usage/branching\#do-compute-credits-apply-to-branching-compute)

No, Compute Credits do not apply to Branching Compute.

### Is this helpful?

NoYes

### On this page

[What you are charged for](https://supabase.com/docs/guides/platform/manage-your-usage/branching#what-you-are-charged-for) [How charges are calculated](https://supabase.com/docs/guides/platform/manage-your-usage/branching#how-charges-are-calculated) [Usage on your invoice](https://supabase.com/docs/guides/platform/manage-your-usage/branching#usage-on-your-invoice) [Pricing](https://supabase.com/docs/guides/platform/manage-your-usage/branching#pricing) [Billing examples](https://supabase.com/docs/guides/platform/manage-your-usage/branching#billing-examples) [View usage](https://supabase.com/docs/guides/platform/manage-your-usage/branching#view-usage) [Optimize usage](https://supabase.com/docs/guides/platform/manage-your-usage/branching#optimize-usage) [FAQ](https://supabase.com/docs/guides/platform/manage-your-usage/branching#faq) [Do Compute Credits apply to Branching Compute?](https://supabase.com/docs/guides/platform/manage-your-usage/branching#do-compute-credits-apply-to-branching-compute)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings


![Usage summary Branches Compute Hours](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-summary-branch-hours--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![Usage page navigation bar](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-navbar--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)
</file>

<file path="supabase_com_docs_guides_platform_manage_your_usage_compute.md">
Platform

# Manage Compute usage

* * *

## What you are charged for [\#](https://supabase.com/docs/guides/platform/manage-your-usage/compute\#what-you-are-charged-for)

Each project on the Supabase platform includes a dedicated Postgres instance running on its own server. You are charged for the [Compute](https://supabase.com/docs/guides/platform/compute-and-disk#compute) resources of that server, independent of your database usage.

Paused projects do not count towards Compute usage.

## How charges are calculated [\#](https://supabase.com/docs/guides/platform/manage-your-usage/compute\#how-charges-are-calculated)

Compute is charged by the hour, meaning you are charged for the exact number of hours that a project is running and, therefore, incurring Compute usage. If a project runs for part of an hour, you are still charged for the full hour.

Each project you launch increases your monthly Compute costs.

### Example [\#](https://supabase.com/docs/guides/platform/manage-your-usage/compute\#example)

Your billing cycle runs from January 1 to January 31. On January 10 at 4:30 PM, you switch your project from the Micro Compute size to the Small Compute size. At the end of the billing cycle you are billed for 233 hours of Micro Compute size and 511 hours of Small Compute size.

| Time Window | Compute Size | Hours Billed | Description |
| --- | --- | --- | --- |
| January 1, 00:00 AM - January 10, 4:00 PM | Micro | 232 |  |
| January 10, 04:00 PM - January 10, 4:30 PM | Micro | 1 | full hour is billed |
| January 10, 04:30 PM - January 10, 5:00 PM | Small | 1 | full hour is billed |
| January 10, 05:00 PM - January 31, 23:59 PM | Small | 511 |  |

### Usage on your invoice [\#](https://supabase.com/docs/guides/platform/manage-your-usage/compute\#usage-on-your-invoice)

Usage is shown as "Compute Hours" on your invoice.

## Compute Credits [\#](https://supabase.com/docs/guides/platform/manage-your-usage/compute\#compute-credits)

Paid plans include $10 in Compute Credits, which cover one project running on the Micro/Nano Compute size or portions of other Compute sizes. Compute Credits are applied to your Compute costs and are provided to an organization each month. They reset monthly and do not accumulate.

## Pricing [\#](https://supabase.com/docs/guides/platform/manage-your-usage/compute\#pricing)

| Compute Size | Hourly Price USD | Monthly Price USD |
| --- | --- | --- |
| Nano[1](https://supabase.com/docs/guides/platform/manage-your-usage/compute#user-content-fn-1) | $0 | $0 |
| Micro | $0.01344 | ~$10 |
| Small | $0.0206 | ~$15 |
| Medium | $0.0822 | ~$60 |
| Large | $0.1517 | ~$110 |
| XL | $0.2877 | ~$210 |
| 2XL | $0.562 | ~$410 |
| 4XL | $1.32 | ~$960 |
| 8XL | $2.562 | ~$1,870 |
| 12XL | $3.836 | ~$2,800 |
| 16XL | $5.12 | ~$3,730 |

##### Nano Compute size in paid plan organizations

In paid organizations, Nano Compute are billed at the same price as Micro Compute. It is recommended to upgrade your Project from Nano Compute to Micro Compute when it's convenient for you. Compute sizes are not auto-upgraded because of the downtime incurred. See [Supabase Pricing](https://supabase.com/pricing) for more information. You cannot launch Nano instances on paid plans, only Micro and above - but you might have Nano instances after upgrading from Free Plan.

## Billing examples [\#](https://supabase.com/docs/guides/platform/manage-your-usage/compute\#billing-examples)

### One project [\#](https://supabase.com/docs/guides/platform/manage-your-usage/compute\#one-project)

The project runs on the same Compute size throughout the entire billing cycle.

| Line Item | Hours | Costs |
| --- | --- | --- |
| Pro Plan | - | $25 |
| Compute Hours Micro Project 1 | 744 | $10 |
| **Subtotal** |  | **$35** |
| Compute Credits |  | -$10 |
| **Total** |  | **$25** |

### Multiple projects [\#](https://supabase.com/docs/guides/platform/manage-your-usage/compute\#multiple-projects)

All projects run on the same Compute size throughout the entire billing cycle.

| Line Item | Hours | Costs |
| --- | --- | --- |
| Pro Plan | - | $25 |
| Compute Hours Micro Project 1 | 744 | $10 |
| Compute Hours Micro Project 2 | 744 | $10 |
| Compute Hours Micro Project 3 | 744 | $10 |
| **Subtotal** |  | **$55** |
| Compute Credits |  | -$10 |
| **Total** |  | **$45** |

### One project on different Compute sizes [\#](https://supabase.com/docs/guides/platform/manage-your-usage/compute\#one-project-on-different-compute-sizes)

The project's Compute size changes throughout the billing cycle.

| Line Item | Hours | Costs |
| --- | --- | --- |
| Pro Plan | - | $25 |
| Compute Hours Micro Project 1 | 233 | $3 |
| Compute Hours Small Project 1 | 511 | $11 |
| **Subtotal** |  | **$39** |
| Compute Credits |  | -$10 |
| **Total** |  | **$29** |

## View usage [\#](https://supabase.com/docs/guides/platform/manage-your-usage/compute\#view-usage)

You can view Compute usage on the [organization's usage page](https://supabase.com/dashboard/org/_/usage). The page shows the usage of all projects by default. To view the usage for a specific project, select it from the dropdown. You can also select a different time period.

![Usage page navigation bar](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-navbar--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

In the Compute Hours section, you can see how many hours of a specific Compute size your projects have used during the selected time period. Hover over a specific date for a daily breakdown.

![Usage page Compute Hours section](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-compute--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

## Optimize usage [\#](https://supabase.com/docs/guides/platform/manage-your-usage/compute\#optimize-usage)

- Start out on a smaller Compute size, [create a report](https://supabase.com/dashboard/project/_/reports) on the Dashboard to monitor your CPU and memory utilization, and upgrade the Compute size as needed
- Load test your application in staging to understand your Compute requirements
- [Transfer projects](https://supabase.com/docs/guides/platform/project-transfer) to a Free Plan organization to reduce Compute usage
- Delete unused projects

## FAQ [\#](https://supabase.com/docs/guides/platform/manage-your-usage/compute\#faq)

### Do Compute Credits apply to line items other than Compute? [\#](https://supabase.com/docs/guides/platform/manage-your-usage/compute\#do-compute-credits-apply-to-line-items-other-than-compute)

No, Compute Credits apply only to Compute and do not cover other line items, including Read Replica Compute and Branching Compute.

## Footnotes [\#](https://supabase.com/docs/guides/platform/manage-your-usage/compute\#footnote-label)

1. Compute resources on the Free Plan are subject to change. [](https://supabase.com/docs/guides/platform/manage-your-usage/compute#user-content-fnref-1)


### Is this helpful?

NoYes

### On this page

[What you are charged for](https://supabase.com/docs/guides/platform/manage-your-usage/compute#what-you-are-charged-for) [How charges are calculated](https://supabase.com/docs/guides/platform/manage-your-usage/compute#how-charges-are-calculated) [Example](https://supabase.com/docs/guides/platform/manage-your-usage/compute#example) [Usage on your invoice](https://supabase.com/docs/guides/platform/manage-your-usage/compute#usage-on-your-invoice) [Compute Credits](https://supabase.com/docs/guides/platform/manage-your-usage/compute#compute-credits) [Pricing](https://supabase.com/docs/guides/platform/manage-your-usage/compute#pricing) [Billing examples](https://supabase.com/docs/guides/platform/manage-your-usage/compute#billing-examples) [One project](https://supabase.com/docs/guides/platform/manage-your-usage/compute#one-project) [Multiple projects](https://supabase.com/docs/guides/platform/manage-your-usage/compute#multiple-projects) [One project on different Compute sizes](https://supabase.com/docs/guides/platform/manage-your-usage/compute#one-project-on-different-compute-sizes) [View usage](https://supabase.com/docs/guides/platform/manage-your-usage/compute#view-usage) [Optimize usage](https://supabase.com/docs/guides/platform/manage-your-usage/compute#optimize-usage) [FAQ](https://supabase.com/docs/guides/platform/manage-your-usage/compute#faq) [Do Compute Credits apply to line items other than Compute?](https://supabase.com/docs/guides/platform/manage-your-usage/compute#do-compute-credits-apply-to-line-items-other-than-compute) [Footnotes](https://supabase.com/docs/guides/platform/manage-your-usage/compute#footnote-label)

![Usage page navigation bar](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-navbar--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![Usage page Compute Hours section](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-compute--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_manage_your_usage_custom_domains.md">
Platform

# Manage Custom Domain usage

* * *

## What you are charged for [\#](https://supabase.com/docs/guides/platform/manage-your-usage/custom-domains\#what-you-are-charged-for)

You can configure a [custom domain](https://supabase.com/docs/guides/platform/custom-domains) for a project by enabling the [Custom Domain add-on](https://supabase.com/dashboard/project/_/settings/addons?panel=customDomain). You are charged for all custom domains configured across your projects.

## How charges are calculated [\#](https://supabase.com/docs/guides/platform/manage-your-usage/custom-domains\#how-charges-are-calculated)

Custom domains are charged by the hour, meaning you are charged for the exact number of hours that a custom domain is active. If a custom domain is active for part of an hour, you are still charged for the full hour.

### Example [\#](https://supabase.com/docs/guides/platform/manage-your-usage/custom-domains\#example)

Your billing cycle runs from January 1 to January 31. On January 10 at 4:30 PM, you activate a custom domain for your project. At the end of the billing cycle you are billed for 512 hours.

| Time Window | Custom Domain Activated | Hours Billed | Description |
| --- | --- | --- | --- |
| January 1, 00:00 AM - January 10, 4:00 PM | No | 0 |  |
| January 10, 04:00 PM - January 10, 4:30 PM | No | 0 |  |
| January 10, 04:30 PM - January 10, 5:00 PM | Yes | 1 | full hour is billed |
| January 10, 05:00 PM - January 31, 23:59 PM | Yes | 511 |  |

### Usage on your invoice [\#](https://supabase.com/docs/guides/platform/manage-your-usage/custom-domains\#usage-on-your-invoice)

Usage is shown as "Custom Domain Hours" on your invoice.

## Pricing [\#](https://supabase.com/docs/guides/platform/manage-your-usage/custom-domains\#pricing)

$0.0137 per hour ($10 per month).

## Billing examples [\#](https://supabase.com/docs/guides/platform/manage-your-usage/custom-domains\#billing-examples)

### One project [\#](https://supabase.com/docs/guides/platform/manage-your-usage/custom-domains\#one-project)

The project has a custom domain activated throughout the entire billing cycle.

| Line Item | Hours | Costs |
| --- | --- | --- |
| Pro Plan | - | $25 |
| Compute Hours Micro Project 1 | 744 | $10 |
| Custom Domain Hours | 744 | $10 |
| **Subtotal** |  | **$45** |
| Compute Credits |  | -$10 |
| **Total** |  | **$35** |

### Multiple projects [\#](https://supabase.com/docs/guides/platform/manage-your-usage/custom-domains\#multiple-projects)

All projects have a custom domain activated throughout the entire billing cycle.

| Line Item | Hours | Costs |
| --- | --- | --- |
| Pro Plan | - | $25 |
|  |  |  |
| Compute Hours Micro Project 1 | 744 | $10 |
| Custom Domain Hours Project 1 | 744 | $10 |
|  |  |  |
| Compute Hours Micro Project 2 | 744 | $10 |
| Custom Domain Hours Project 2 | 744 | $10 |
|  |  |  |
| **Subtotal** |  | **$65** |
| Compute Credits |  | -$10 |
| **Total** |  | **$55** |

## Optimize usage [\#](https://supabase.com/docs/guides/platform/manage-your-usage/custom-domains\#optimize-usage)

- Regularly check your projects and remove custom domains that are no longer needed
- Use free [Vanity subdomains](https://supabase.com/docs/guides/platform/custom-domains#vanity-subdomains) where applicable

### Is this helpful?

NoYes

### On this page

[What you are charged for](https://supabase.com/docs/guides/platform/manage-your-usage/custom-domains#what-you-are-charged-for) [How charges are calculated](https://supabase.com/docs/guides/platform/manage-your-usage/custom-domains#how-charges-are-calculated) [Example](https://supabase.com/docs/guides/platform/manage-your-usage/custom-domains#example) [Usage on your invoice](https://supabase.com/docs/guides/platform/manage-your-usage/custom-domains#usage-on-your-invoice) [Pricing](https://supabase.com/docs/guides/platform/manage-your-usage/custom-domains#pricing) [Billing examples](https://supabase.com/docs/guides/platform/manage-your-usage/custom-domains#billing-examples) [One project](https://supabase.com/docs/guides/platform/manage-your-usage/custom-domains#one-project) [Multiple projects](https://supabase.com/docs/guides/platform/manage-your-usage/custom-domains#multiple-projects) [Optimize usage](https://supabase.com/docs/guides/platform/manage-your-usage/custom-domains#optimize-usage)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_manage_your_usage_disk_iops.md">
Platform

# Manage Disk IOPS usage

* * *

## What you are charged for [\#](https://supabase.com/docs/guides/platform/manage-your-usage/disk-iops\#what-you-are-charged-for)

Each database has a dedicated disk, and you are charged for its provisioned disk IOPS. However, unless you explicitly opt in for additional IOPS, no charges apply.

Refer to our [disk guide](https://supabase.com/docs/guides/platform/compute-and-disk#disk) for details on how disk IOPS, disk throughput, disk size, disk type and compute size interact, along with their limitations and constraints.

Launching a Read Replica creates an additional database with its own dedicated disk. Read Replicas inherit the primary database's disk IOPS settings. You are charged for the provisioned IOPS of the Read Replica. Refer to [Manage Read Replica usage](https://supabase.com/docs/guides/platform/manage-your-usage/read-replicas) for details on billing.

## How charges are calculated [\#](https://supabase.com/docs/guides/platform/manage-your-usage/disk-iops\#how-charges-are-calculated)

Disk IOPS is charged by IOPS-Hrs. 1 IOPS-Hr represents 1 IOPS being provisioned for 1 hour. For example, having 10 IOPS provisioned for 5 hours results in 50 IOPS-Hrs (10 IOPS  5 hours).

### Usage on your invoice [\#](https://supabase.com/docs/guides/platform/manage-your-usage/disk-iops\#usage-on-your-invoice)

Usage is shown as "Disk IOPS-Hrs" on your invoice.

## Pricing [\#](https://supabase.com/docs/guides/platform/manage-your-usage/disk-iops\#pricing)

Pricing depends on the [disk type](https://supabase.com/docs/guides/platform/compute-and-disk#disk-types), with type gp3 being the default.

### General purpose disks (gp3) [\#](https://supabase.com/docs/guides/platform/manage-your-usage/disk-iops\#general-purpose-disks-gp3)

$0.00003288 per IOPS-Hr ($0.024 per IOPS per month). gp3 disks come with a default IOPS of 3,000. You are only charged for provisioned IOPS exceeding these 3,000 IOPS.

| Plan | Included Disk IOPS | Over-Usage per IOPS per month | Over-Usage per IOPS-Hrs |
| --- | --- | --- | --- |
| Pro | 3,000 | $0.024 | $0.00003288 |
| Team | 3,000 | $0.024 | $0.00003288 |
| Enterprise | Custom | Custom | Custom |

### High performance disks (io2) [\#](https://supabase.com/docs/guides/platform/manage-your-usage/disk-iops\#high-performance-disks-io2)

$0.000163 per IOPS-Hr ($0.119 per IOPS per month).
Unlike general purpose disks, high performance disks are billed from the first provisioned IOPS.

| Plan | Included Disk IOPS | Usage per IOPS per month | Usage per IOPS-Hrs |
| --- | --- | --- | --- |
| Pro | 0 | $0.119 | $0.000163 |
| Team | 0 | $0.119 | $0.000163 |
| Enterprise | Custom | Custom | Custom |

## Billing examples [\#](https://supabase.com/docs/guides/platform/manage-your-usage/disk-iops\#billing-examples)

### Gp3 [\#](https://supabase.com/docs/guides/platform/manage-your-usage/disk-iops\#gp3)

Project 1 doesn't exceed the included IOPS, so no charges for IOPS apply. Project 2 exceeds the included IOPS by 600, incurring charges for this additional usage.

| Line Item | Units | Costs |
| --- | --- | --- |
| Pro Plan | 1 | $25 |
|  |  |  |
| Compute Hours Micro Project 1 | 744 hours | $10 |
| Disk IOPS Project 1 | 3,000 IOPS | $0 |
|  |  |  |
| Compute Hours Large Project 2 | 744 hours | $110 |
| Disk IOPS Project 2 | 3,600 IOPS | $14.40 |
|  |  |  |
| **Subtotal** |  | **$159.40** |
| Compute Credits |  | -$10 |
| **Total** |  | **$149.40** |

### Io2 [\#](https://supabase.com/docs/guides/platform/manage-your-usage/disk-iops\#io2)

This disk type is billed from the first IOPS provisioned, meaning for 8000 IOPS.

| Line Item | Units | Costs |
| --- | --- | --- |
| Pro Plan | 1 | $25 |
| Compute Hours Large Project 1 | 744 hours | $110 |
| Disk IOPS Project 1 | 8,000 IOPS | $952 |
| **Subtotal** |  | **$1,087** |
| Compute Credits |  | -$10 |
| **Total** |  | **$1,077** |

### Is this helpful?

NoYes

### On this page

[What you are charged for](https://supabase.com/docs/guides/platform/manage-your-usage/disk-iops#what-you-are-charged-for) [How charges are calculated](https://supabase.com/docs/guides/platform/manage-your-usage/disk-iops#how-charges-are-calculated) [Usage on your invoice](https://supabase.com/docs/guides/platform/manage-your-usage/disk-iops#usage-on-your-invoice) [Pricing](https://supabase.com/docs/guides/platform/manage-your-usage/disk-iops#pricing) [General purpose disks (gp3)](https://supabase.com/docs/guides/platform/manage-your-usage/disk-iops#general-purpose-disks-gp3) [High performance disks (io2)](https://supabase.com/docs/guides/platform/manage-your-usage/disk-iops#high-performance-disks-io2) [Billing examples](https://supabase.com/docs/guides/platform/manage-your-usage/disk-iops#billing-examples) [Gp3](https://supabase.com/docs/guides/platform/manage-your-usage/disk-iops#gp3) [Io2](https://supabase.com/docs/guides/platform/manage-your-usage/disk-iops#io2)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_manage_your_usage_disk_size.md">
Platform

# Manage Disk size usage

* * *

## What you are charged for [\#](https://supabase.com/docs/guides/platform/manage-your-usage/disk-size\#what-you-are-charged-for)

Each database has a dedicated [disk](https://supabase.com/docs/guides/platform/compute-and-disk#disk). You are charged for the provisioned disk size.

Disk size is not relevant for the Free Plan. Instead Free Plan customers are limited by [Database size](https://supabase.com/docs/guides/platform/database-size).

## How charges are calculated [\#](https://supabase.com/docs/guides/platform/manage-your-usage/disk-size\#how-charges-are-calculated)

Disk size is charged by Gigabyte-Hours (GB-Hrs). 1 GB-Hr represents 1 GB being provisioned for 1 hour.
For example, having 10 GB provisioned for 5 hours results in 50 GB-Hrs (10 GB  5 hours).

### Usage on your invoice [\#](https://supabase.com/docs/guides/platform/manage-your-usage/disk-size\#usage-on-your-invoice)

Usage is shown as "Disk Size GB-Hrs" on your invoice.

## Pricing [\#](https://supabase.com/docs/guides/platform/manage-your-usage/disk-size\#pricing)

Pricing depends on the [disk type](https://supabase.com/docs/guides/platform/compute-and-disk#disk-types), with gp3 being the default disk type.

### General purpose disks (gp3) [\#](https://supabase.com/docs/guides/platform/manage-your-usage/disk-size\#general-purpose-disks-gp3)

$0.000171 per GB-Hr ($0.125 per GB per month). The primary database of your project gets provisioned with an 8 GB disk. You are only charged for provisioned disk size exceeding these 8 GB.

| Plan | Included Disk Size | Over-Usage per GB per month | Over-Usage per GB-Hr |
| --- | --- | --- | --- |
| Pro | 8 GB | $0.125 | $0.000171 |
| Team | 8 GB | $0.125 | $0.000171 |
| Enterprise | Custom | Custom | Custom |

Launching a Read Replica creates an additional database with its own dedicated disk. You are charged from the first byte of provisioned disk for the Read Replica. Refer to [Manage Read Replica usage](https://supabase.com/docs/guides/platform/manage-your-usage/read-replicas) for details on billing.

### High performance disks (io2) [\#](https://supabase.com/docs/guides/platform/manage-your-usage/disk-size\#high-performance-disks-io2)

$0.000267 per GB-Hr ($0.195 per GB per month).
Unlike general purpose disks, high performance disks are billed from the first byte of provisioned disk.

| Plan | Included Disk size | Usage per GB per month | Usage per GB-Hr |
| --- | --- | --- | --- |
| Pro | 0 GB | $0.195 | $0.000267 |
| Team | 0 GB | $0.195 | $0.000267 |
| Enterprise | Custom | Custom | Custom |

## Billing examples [\#](https://supabase.com/docs/guides/platform/manage-your-usage/disk-size\#billing-examples)

### Gp3 [\#](https://supabase.com/docs/guides/platform/manage-your-usage/disk-size\#gp3)

Project 1 and 2 don't exceed the included disk size, so no charges for Disk size apply. Project 3 exceeds the included disk size by 42 GB, incurring charges for this additional usage.

| Line Item | Units | Costs |
| --- | --- | --- |
| Pro Plan | 1 | $25 |
|  |  |  |
| Compute Hours Micro Project 1 | 744 hours | $10 |
| Disk Size Project 1 | 8 GB | $0 |
|  |  |  |
| Compute Hours Micro Project 2 | 744 hours | $10 |
| Disk Size Project 2 | 8 GB | $0 |
|  |  |  |
| Compute Hours Micro Project 3 | 744 hours | $10 |
| Disk Size Project 3 | 50 GB | $5.25 |
|  |  |  |
| **Subtotal** |  | **$50.25** |
| Compute Credits |  | -$10 |
| **Total** |  | **$40.25** |

### Io2 [\#](https://supabase.com/docs/guides/platform/manage-your-usage/disk-size\#io2)

This disk type is billed from the first byte of provisioned disk, meaning for 66 GB across all projects.

| Line Item | Units | Costs |
| --- | --- | --- |
| Pro Plan | 1 | $25 |
|  |  |  |
| Compute Hours Micro Project 1 | 744 hours | $10 |
| Disk Size Project 1 | 8 GB | $1.56 |
|  |  |  |
| Compute Hours Micro Project 2 | 744 hours | $10 |
| Disk Size Project 2 | 8 GB | $1.56 |
|  |  |  |
| Compute Hours Micro Project 3 | 744 hours | $10 |
| Disk Size Project 3 | 50 GB | $9.75 |
|  |  |  |
| **Subtotal** |  | **$67.87** |
| Compute Credits |  | -$10 |
| **Total** |  | **$57.87** |

## View usage [\#](https://supabase.com/docs/guides/platform/manage-your-usage/disk-size\#view-usage)

You can view Disk size usage on the [organization's usage page](https://supabase.com/dashboard/org/_/usage). The page shows the usage of all projects by default. To view the usage for a specific project, select it from the dropdown.

![Usage page navigation bar](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-navbar--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

In the Disk size section, you can see how much disk size your projects have provisioned.

![Usage page Disk Size section](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-disk-size--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Disk size distribution [\#](https://supabase.com/docs/guides/platform/manage-your-usage/disk-size\#disk-size-distribution)

To see how your disk usage is distributed across Database, WAL, and System categories, refer to [Disk size distribution](https://supabase.com/docs/guides/platform/database-size#disk-size-distribution).

## Reduce Disk size [\#](https://supabase.com/docs/guides/platform/manage-your-usage/disk-size\#reduce-disk-size)

To see how you can downsize your disk, refer to [Reducing disk size](https://supabase.com/docs/guides/platform/database-size#reducing-disk-size)

### Is this helpful?

NoYes

### On this page

[What you are charged for](https://supabase.com/docs/guides/platform/manage-your-usage/disk-size#what-you-are-charged-for) [How charges are calculated](https://supabase.com/docs/guides/platform/manage-your-usage/disk-size#how-charges-are-calculated) [Usage on your invoice](https://supabase.com/docs/guides/platform/manage-your-usage/disk-size#usage-on-your-invoice) [Pricing](https://supabase.com/docs/guides/platform/manage-your-usage/disk-size#pricing) [General purpose disks (gp3)](https://supabase.com/docs/guides/platform/manage-your-usage/disk-size#general-purpose-disks-gp3) [High performance disks (io2)](https://supabase.com/docs/guides/platform/manage-your-usage/disk-size#high-performance-disks-io2) [Billing examples](https://supabase.com/docs/guides/platform/manage-your-usage/disk-size#billing-examples) [Gp3](https://supabase.com/docs/guides/platform/manage-your-usage/disk-size#gp3) [Io2](https://supabase.com/docs/guides/platform/manage-your-usage/disk-size#io2) [View usage](https://supabase.com/docs/guides/platform/manage-your-usage/disk-size#view-usage) [Disk size distribution](https://supabase.com/docs/guides/platform/manage-your-usage/disk-size#disk-size-distribution) [Reduce Disk size](https://supabase.com/docs/guides/platform/manage-your-usage/disk-size#reduce-disk-size)

![Usage page navigation bar](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-navbar--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![Usage page Disk Size section](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-disk-size--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_manage_your_usage_disk_throughput.md">
Platform

# Manage Disk Throughput usage

* * *

## What you are charged for [\#](https://supabase.com/docs/guides/platform/manage-your-usage/disk-throughput\#what-you-are-charged-for)

Each database has a dedicated disk, and you are charged for its provisioned disk throughput. However, unless you explicitly opt in for additional throughput, no charges apply.

Refer to our [disk guide](https://supabase.com/docs/guides/platform/compute-and-disk#disk) for details on how disk throughput, disk IOPS, disk size, disk type and compute size interact, along with their limitations and constraints.

Launching a Read Replica creates an additional database with its own dedicated disk. Read Replicas inherit the primary database's disk throughput settings. You are charged for the provisioned throughput of the Read Replica.

## How charges are calculated [\#](https://supabase.com/docs/guides/platform/manage-your-usage/disk-throughput\#how-charges-are-calculated)

Disk throughput is charged by Mbps-Hrs (Mbps stands for megabits per second). 1 Mbps-Hr represents disk throughput of 1 Mbps being provisioned for 1 hour. For example, having 10 Mbps provisioned for 5 hours results in 50 Mbps-Hrs (10 Mbps  5 hours).

### Usage on your invoice [\#](https://supabase.com/docs/guides/platform/manage-your-usage/disk-throughput\#usage-on-your-invoice)

Usage is shown as "Disk Throughput Mbps-Hrs" on your invoice.

## Pricing [\#](https://supabase.com/docs/guides/platform/manage-your-usage/disk-throughput\#pricing)

Pricing depends on the [disk type](https://supabase.com/docs/guides/platform/compute-and-disk#disk-types), with type gp3 being the default.

### General purpose disks (gp3) [\#](https://supabase.com/docs/guides/platform/manage-your-usage/disk-throughput\#general-purpose-disks-gp3)

$0.00013 per Mbps-Hr ($0.095 per Mbps per month). gp3 disks come with a baseline throughput of 125 Mbps. You are only charged for provisioned throughput exceeding these 125 Mbps.

| Plan | Included Disk Throughput | Over-Usage per Mbps per month | Over-Usage per Mbps-Hrs |
| --- | --- | --- | --- |
| Pro | 125 Mbps | $0.095 | $0.00013 |
| Team | 125 Mbps | $0.095 | $0.00013 |
| Enterprise | Custom | Custom | Custom |

### High performance disks (io2) [\#](https://supabase.com/docs/guides/platform/manage-your-usage/disk-throughput\#high-performance-disks-io2)

There are no charges. Throughput scales with IOPS at no additional cost.

## Billing examples [\#](https://supabase.com/docs/guides/platform/manage-your-usage/disk-throughput\#billing-examples)

### No additional throughput configured [\#](https://supabase.com/docs/guides/platform/manage-your-usage/disk-throughput\#no-additional-throughput-configured)

| Line Item | Units | Costs |
| --- | --- | --- |
| Pro Plan | 1 | $25 |
|  |  |  |
| Compute Hours Micro Project 1 | 744 hours | $10 |
| Disk Throughput Project 1 | 125 Mbps | $0 |
|  |  |  |
| **Subtotal** |  | **$35** |
| Compute Credits |  | -$10 |
| **Total** |  | **$25** |

### Additional throughput configured [\#](https://supabase.com/docs/guides/platform/manage-your-usage/disk-throughput\#additional-throughput-configured)

| Line Item | Units | Costs |
| --- | --- | --- |
| Pro Plan | 1 | $25 |
|  |  |  |
| Compute Hours Large Project 1 | 744 hours | $110 |
| Disk Throughput Project 1 | 200 Mbps | $7.13 |
|  |  |  |
| **Subtotal** |  | **$142.13** |
| Compute Credits |  | -$10 |
| **Total** |  | **$132.13** |

### Additional throughput configured with Read Replica [\#](https://supabase.com/docs/guides/platform/manage-your-usage/disk-throughput\#additional-throughput-configured-with-read-replica)

| Line Item | Units | Costs |
| --- | --- | --- |
| Pro Plan | 1 | $25 |
|  |  |  |
| Compute Hours Large Project 1 | 744 hours | $110 |
| Disk Throughput Project 1 | 200 Mbps | $7.13 |
|  |  |  |
| Compute Hours Large Replica | 744 hours | $110 |
| Disk Throughput Replica | 200 Mbps | $7.13 |
|  |  |  |
| **Subtotal** |  | **$259.26** |
| Compute Credits |  | -$10 |
| **Total** |  | **$249.26** |

### Is this helpful?

NoYes

### On this page

[What you are charged for](https://supabase.com/docs/guides/platform/manage-your-usage/disk-throughput#what-you-are-charged-for) [How charges are calculated](https://supabase.com/docs/guides/platform/manage-your-usage/disk-throughput#how-charges-are-calculated) [Usage on your invoice](https://supabase.com/docs/guides/platform/manage-your-usage/disk-throughput#usage-on-your-invoice) [Pricing](https://supabase.com/docs/guides/platform/manage-your-usage/disk-throughput#pricing) [General purpose disks (gp3)](https://supabase.com/docs/guides/platform/manage-your-usage/disk-throughput#general-purpose-disks-gp3) [High performance disks (io2)](https://supabase.com/docs/guides/platform/manage-your-usage/disk-throughput#high-performance-disks-io2) [Billing examples](https://supabase.com/docs/guides/platform/manage-your-usage/disk-throughput#billing-examples) [No additional throughput configured](https://supabase.com/docs/guides/platform/manage-your-usage/disk-throughput#no-additional-throughput-configured) [Additional throughput configured](https://supabase.com/docs/guides/platform/manage-your-usage/disk-throughput#additional-throughput-configured) [Additional throughput configured with Read Replica](https://supabase.com/docs/guides/platform/manage-your-usage/disk-throughput#additional-throughput-configured-with-read-replica)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_manage_your_usage_edge_function_invocations.md">
Platform

# Manage Edge Function Invocations usage

* * *

## What you are charged for [\#](https://supabase.com/docs/guides/platform/manage-your-usage/edge-function-invocations\#what-you-are-charged-for)

You are charged for the number of times your functions get invoked, regardless of the response status code.

## How charges are calculated [\#](https://supabase.com/docs/guides/platform/manage-your-usage/edge-function-invocations\#how-charges-are-calculated)

Edge Function Invocations are billed using Package pricing, with each package representing 1 million invocations. If your usage falls between two packages, you are billed for the next whole package.

### Example [\#](https://supabase.com/docs/guides/platform/manage-your-usage/edge-function-invocations\#example)

For simplicity, let's assume a package size of 1 million and a charge of $2 per package without a free quota.

| Invocations | Packages Billed | Costs |
| --- | --- | --- |
| 999,999 | 1 | $2 |
| 1,000,000 | 1 | $2 |
| 1,000,001 | 2 | $4 |
| 1,500,000 | 2 | $4 |

### Usage on your invoice [\#](https://supabase.com/docs/guides/platform/manage-your-usage/edge-function-invocations\#usage-on-your-invoice)

Usage is shown as "Function Invocations" on your invoice.

## Pricing [\#](https://supabase.com/docs/guides/platform/manage-your-usage/edge-function-invocations\#pricing)

$2 per 1 million invocations. You are only charged for usage exceeding your subscription plan's quota.

| Plan | Quota | Over-Usage |
| --- | --- | --- |
| Free | 500,000 | - |
| Pro | 2 million | $2 per 1 million invocations |
| Team | 2 million | $2 per 1 million invocations |
| Enterprise | Custom | Custom |

## Billing examples [\#](https://supabase.com/docs/guides/platform/manage-your-usage/edge-function-invocations\#billing-examples)

### Within quota [\#](https://supabase.com/docs/guides/platform/manage-your-usage/edge-function-invocations\#within-quota)

The organization's function invocations are within the quota, so no charges apply.

| Line Item | Units | Costs |
| --- | --- | --- |
| Pro Plan | 1 | $25 |
| Compute Hours Micro | 744 hours | $10 |
| Function Invocations | 1,800,000 invocations | $0 |
| **Subtotal** |  | **$35** |
| Compute Credits |  | -$10 |
| **Total** |  | **$25** |

### Exceeding quota [\#](https://supabase.com/docs/guides/platform/manage-your-usage/edge-function-invocations\#exceeding-quota)

The organization's function invocations exceed the quota by 1.4 million, incurring charges for this additional usage.

| Line Item | Units | Costs |
| --- | --- | --- |
| Pro Plan | 1 | $25 |
| Compute Hours Micro | 744 hours | $10 |
| Function Invocations | 3,400,000 invocations | $4 |
| **Subtotal** |  | **$39** |
| Compute Credits |  | -$10 |
| **Total** |  | **$29** |

## View usage [\#](https://supabase.com/docs/guides/platform/manage-your-usage/edge-function-invocations\#view-usage)

You can view Edge Function Invocations usage on the [organization's usage page](https://supabase.com/dashboard/org/_/usage). The page shows the usage of all projects by default. To view the usage for a specific project, select it from the dropdown. You can also select a different time period.

![Usage page navigation bar](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-navbar--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

In the Edge Function Invocations section, you can see how many invocations your projects have had during the selected time period.

![Usage page Edge Function Invocations section](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-function-invocations--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[What you are charged for](https://supabase.com/docs/guides/platform/manage-your-usage/edge-function-invocations#what-you-are-charged-for) [How charges are calculated](https://supabase.com/docs/guides/platform/manage-your-usage/edge-function-invocations#how-charges-are-calculated) [Example](https://supabase.com/docs/guides/platform/manage-your-usage/edge-function-invocations#example) [Usage on your invoice](https://supabase.com/docs/guides/platform/manage-your-usage/edge-function-invocations#usage-on-your-invoice) [Pricing](https://supabase.com/docs/guides/platform/manage-your-usage/edge-function-invocations#pricing) [Billing examples](https://supabase.com/docs/guides/platform/manage-your-usage/edge-function-invocations#billing-examples) [Within quota](https://supabase.com/docs/guides/platform/manage-your-usage/edge-function-invocations#within-quota) [Exceeding quota](https://supabase.com/docs/guides/platform/manage-your-usage/edge-function-invocations#exceeding-quota) [View usage](https://supabase.com/docs/guides/platform/manage-your-usage/edge-function-invocations#view-usage)

![Usage page navigation bar](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-navbar--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![Usage page Edge Function Invocations section](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-function-invocations--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_manage_your_usage_egress.md">
Platform

# Manage Egress usage

* * *

## What you are charged for [\#](https://supabase.com/docs/guides/platform/manage-your-usage/egress\#what-you-are-charged-for)

You are charged for the network data transmitted out of the system to a connected client. Egress is incurred by all services - Database, Auth, Storage, Edge Functions, Realtime and Log Drains.

### Database Egress [\#](https://supabase.com/docs/guides/platform/manage-your-usage/egress\#database-egress)

Data sent to the client when retrieving data stored in your database.

**Example:** A user views their order history in an online shop. The client application requests the database to retrieve the user's past orders. The order data is sent back to the client, contributing to Database Egress.

There are various ways to interact with your database, such as through the PostgREST API using one of the client SDKs or via the Supavisor connection pooler. On the Supabase Dashboard, Egress from the PostgREST API is labeled as **Database Egress**, while Egress through Supavisor is labeled as **Supavisor Egress**.

### Auth Egress [\#](https://supabase.com/docs/guides/platform/manage-your-usage/egress\#auth-egress)

Data sent from Supabase Auth to the client while managing your application's users. This includes actions like signing in, signing out, or creating new users, e.g. via the JavaScript Client SDK.

**Example:** A user signs in to an online shop. The client application requests the Supabase Auth service to authenticate and authorize the user. The session data, including authentication tokens and user profile details, is sent back to the client, contributing to Auth Egress.

### Storage Egress [\#](https://supabase.com/docs/guides/platform/manage-your-usage/egress\#storage-egress)

Data sent from Supabase Storage to the client when retrieving assets. This includes actions like downloading files, images, or other stored content, e.g. via the JavaScript Client SDK.

**Example:** A user downloads an invoice from an online shop. The client application requests Supabase Storage to retrieve the PDF file from the storage bucket. The file is sent back to the client, contributing to Storage Egress.

### Edge Functions Egress [\#](https://supabase.com/docs/guides/platform/manage-your-usage/egress\#edge-functions-egress)

Data sent to the client when executing Edge Functions.

**Example:** A user completes a checkout process in an online shop. The client application triggers an Edge Function to process the payment and confirm the order. The confirmation response, along with any necessary details, is sent back to the client, contributing to Edge Functions Egress.

### Realtime Egress [\#](https://supabase.com/docs/guides/platform/manage-your-usage/egress\#realtime-egress)

Data pushed to clients via Supabase Realtime for subscribed events.

**Example:** When a user views a product page in an online shop, their client subscribes to real-time inventory updates. As stock levels change, Supabase Realtime pushes updates to all subscribed clients, contributing to Realtime Egress.

### Log Drain Egress [\#](https://supabase.com/docs/guides/platform/manage-your-usage/egress\#log-drain-egress)

Data pushed to the connected log drain.

**Example:** You set up a log drain, each log sent to the log drain is considered egress. You can toggle the GZIP option to reduce egress, in case your provider supports it.

## How charges are calculated [\#](https://supabase.com/docs/guides/platform/manage-your-usage/egress\#how-charges-are-calculated)

Egress is charged by gigabyte. Charges apply only for usage exceeding your subscription plan's quota. This quota is called the Unified Egress Quota because it can be used across all services (Database, Auth, Storage etc.).

### Usage on your invoice [\#](https://supabase.com/docs/guides/platform/manage-your-usage/egress\#usage-on-your-invoice)

Usage is shown as "Egress GB" on your invoice.

## Pricing [\#](https://supabase.com/docs/guides/platform/manage-your-usage/egress\#pricing)

$0.09 per GB per month. You are only charged for usage exceeding your subscription plan's quota.

| Plan | Unified Egress Quota | Over-Usage per month |
| --- | --- | --- |
| Free | 5 GB | - |
| Pro | 250 GB | $0.09 per GB |
| Team | 250 GB | $0.09 per GB |
| Enterprise | Custom | Custom |

## Billing examples [\#](https://supabase.com/docs/guides/platform/manage-your-usage/egress\#billing-examples)

### Within quota [\#](https://supabase.com/docs/guides/platform/manage-your-usage/egress\#within-quota)

The organization's Egress usage is within the quota, so no charges for Egress apply.

| Line Item | Units | Costs |
| --- | --- | --- |
| Pro Plan | 1 | $25 |
| Compute Hours Micro | 744 hours | $10 |
| Egress | 200 GB | $0 |
| **Subtotal** |  | **$35** |
| Compute Credits |  | -$10 |
| **Total** |  | **$25** |

### Exceeding quota [\#](https://supabase.com/docs/guides/platform/manage-your-usage/egress\#exceeding-quota)

The organization's Egress usage exceeds the quota by 50 GB, incurring charges for this additional usage.

| Line Item | Units | Costs |
| --- | --- | --- |
| Pro Plan | 1 | $25 |
| Compute Hours Micro | 744 hours | $10 |
| Egress | 300 GB | $4.5 |
| **Subtotal** |  | **$39.5** |
| Compute Credits |  | -$10 |
| **Total** |  | **$29.5** |

## View usage [\#](https://supabase.com/docs/guides/platform/manage-your-usage/egress\#view-usage)

### Usage page [\#](https://supabase.com/docs/guides/platform/manage-your-usage/egress\#usage-page)

You can view Egress usage on the [organization's usage page](https://supabase.com/dashboard/org/_/usage). The page shows the usage of all projects by default. To view the usage for a specific project, select it from the dropdown. You can also select a different time period.

![Usage page navigation bar](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-navbar--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

In the Total Egress section, you can see the usage for the selected time period. Hover over a specific date to view a breakdown by service.

![Unified Egress](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Funified-egress--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Custom report [\#](https://supabase.com/docs/guides/platform/manage-your-usage/egress\#custom-report)

1. On the [reports page](https://supabase.com/dashboard/project/_/reports), click **New custom report** in the left navigation menu
2. After creating a new report, add charts for one or more Supabase services by clicking **Add block**

![Egress report](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fegress-report--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

## Debug usage [\#](https://supabase.com/docs/guides/platform/manage-your-usage/egress\#debug-usage)

To better understand your Egress usage, identify whats driving the most traffic. Check the most frequent database queries, or analyze the most requested API paths to pinpoint high-bandwidth endpoints.

### Frequent database queries [\#](https://supabase.com/docs/guides/platform/manage-your-usage/egress\#frequent-database-queries)

On the Advisors [Query performance view](https://supabase.com/dashboard/project/_/database/query-performance?preset=most_frequent&sort=calls&order=desc) you can see the most frequent queries and the average number of rows returned.

![Most frequent queries](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fadvisor-most-frequent-queries--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Most requested API endpoints [\#](https://supabase.com/docs/guides/platform/manage-your-usage/egress\#most-requested-api-endpoints)

In the [Logs Explorer](https://supabase.com/dashboard/project/_/logs/explorer) you can access Edge Logs, and review the top paths to identify heavily queried endpoints. These logs currently do not include response byte data. That data will be available in the future too.

![Top paths](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Flogs-top-paths--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

## Optimize usage [\#](https://supabase.com/docs/guides/platform/manage-your-usage/egress\#optimize-usage)

- Reduce the number of fields or entries selected when querying your database
- Reduce the number of queries or calls by optimizing client code or using caches
- For update or insert queries, configure your ORM or queries to not return the entire row if not needed
- When running manual backups through Supavisor, remove unneeded tables and/or reduce the frequency
- Refer to the [Storage Optimizations guide](https://supabase.com/docs/guides/storage/production/scaling#egress) for tips on reducing Storage Egress

### Is this helpful?

NoYes

### On this page

[What you are charged for](https://supabase.com/docs/guides/platform/manage-your-usage/egress#what-you-are-charged-for) [Database Egress](https://supabase.com/docs/guides/platform/manage-your-usage/egress#database-egress) [Auth Egress](https://supabase.com/docs/guides/platform/manage-your-usage/egress#auth-egress) [Storage Egress](https://supabase.com/docs/guides/platform/manage-your-usage/egress#storage-egress) [Edge Functions Egress](https://supabase.com/docs/guides/platform/manage-your-usage/egress#edge-functions-egress) [Realtime Egress](https://supabase.com/docs/guides/platform/manage-your-usage/egress#realtime-egress) [Log Drain Egress](https://supabase.com/docs/guides/platform/manage-your-usage/egress#log-drain-egress) [How charges are calculated](https://supabase.com/docs/guides/platform/manage-your-usage/egress#how-charges-are-calculated) [Usage on your invoice](https://supabase.com/docs/guides/platform/manage-your-usage/egress#usage-on-your-invoice) [Pricing](https://supabase.com/docs/guides/platform/manage-your-usage/egress#pricing) [Billing examples](https://supabase.com/docs/guides/platform/manage-your-usage/egress#billing-examples) [Within quota](https://supabase.com/docs/guides/platform/manage-your-usage/egress#within-quota) [Exceeding quota](https://supabase.com/docs/guides/platform/manage-your-usage/egress#exceeding-quota) [View usage](https://supabase.com/docs/guides/platform/manage-your-usage/egress#view-usage) [Usage page](https://supabase.com/docs/guides/platform/manage-your-usage/egress#usage-page) [Custom report](https://supabase.com/docs/guides/platform/manage-your-usage/egress#custom-report) [Debug usage](https://supabase.com/docs/guides/platform/manage-your-usage/egress#debug-usage) [Frequent database queries](https://supabase.com/docs/guides/platform/manage-your-usage/egress#frequent-database-queries) [Most requested API endpoints](https://supabase.com/docs/guides/platform/manage-your-usage/egress#most-requested-api-endpoints) [Optimize usage](https://supabase.com/docs/guides/platform/manage-your-usage/egress#optimize-usage)

![Usage page navigation bar](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-navbar--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![Egress report](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fegress-report--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![Most frequent queries](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fadvisor-most-frequent-queries--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![Top paths](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Flogs-top-paths--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_manage_your_usage_ipv4.md">
Platform

# Manage IPv4 usage

* * *

## What you are charged for [\#](https://supabase.com/docs/guides/platform/manage-your-usage/ipv4\#what-you-are-charged-for)

You can assign a dedicated [IPv4 address](https://supabase.com/docs/guides/platform/ipv4-address) to a database by enabling the [IPv4 add-on](https://supabase.com/dashboard/project/_/settings/addons?panel=ipv4). You are charged for all IPv4 addresses configured across your databases.

If the primary database has a dedicated IPv4 address configured, its Read Replicas are also assigned one, with charges for each.

## How charges are calculated [\#](https://supabase.com/docs/guides/platform/manage-your-usage/ipv4\#how-charges-are-calculated)

IPv4 addresses are charged by the hour, meaning you are charged for the exact number of hours that an IPv4 address is assigned to a database. If an address is assigned for part of an hour, you are still charged for the full hour.

### Example [\#](https://supabase.com/docs/guides/platform/manage-your-usage/ipv4\#example)

Your billing cycle runs from January 1 to January 31. On January 10 at 4:30 PM, you enable the IPv4 add-on for your project. At the end of the billing cycle you are billed for 512 hours.

| Time Window | IPv4 add-on | Hours Billed | Description |
| --- | --- | --- | --- |
| January 1, 00:00 AM - January 10, 4:00 PM | Disabled | 0 |  |
| January 10, 04:00 PM - January 10, 4:30 PM | Disabled | 0 |  |
| January 10, 04:30 PM - January 10, 5:00 PM | Enabled | 1 | full hour is billed |
| January 10, 05:00 PM - January 31, 23:59 PM | Enabled | 511 |  |

### Usage on your invoice [\#](https://supabase.com/docs/guides/platform/manage-your-usage/ipv4\#usage-on-your-invoice)

Usage is shown as "IPv4 Hours" on your invoice.

## Pricing [\#](https://supabase.com/docs/guides/platform/manage-your-usage/ipv4\#pricing)

$0.0055 per hour ($4 per month).

## Billing examples [\#](https://supabase.com/docs/guides/platform/manage-your-usage/ipv4\#billing-examples)

### One project [\#](https://supabase.com/docs/guides/platform/manage-your-usage/ipv4\#one-project)

The project has the IPv4 add-on enabled throughout the entire billing cycle.

| Line Item | Hours | Costs |
| --- | --- | --- |
| Pro Plan | - | $25 |
| Compute Hours Micro Project 1 | 744 | $10 |
| IPv4 Hours | 744 | $4 |
| **Subtotal** |  | **$39** |
| Compute Credits |  | -$10 |
| **Total** |  | **$29** |

### Multiple projects [\#](https://supabase.com/docs/guides/platform/manage-your-usage/ipv4\#multiple-projects)

All projects have the IPv4 add-on enabled throughout the entire billing cycle.

| Line Item | Hours | Costs |
| --- | --- | --- |
| Pro Plan | - | $25 |
|  |  |  |
| Compute Hours Micro Project 1 | 744 | $10 |
| IPv4 Hours Project 1 | 744 | $4 |
|  |  |  |
| Compute Hours Micro Project 2 | 744 | $10 |
| IPv4 Hours Project 2 | 744 | $4 |
|  |  |  |
| Compute Hours Micro Project 3 | 744 | $10 |
| IPv4 Hours Project 3 | 744 | $4 |
|  |  |  |
| **Subtotal** |  | **$67** |
| Compute Credits |  | -$10 |
| **Total** |  | **$57** |

### One project with Read Replicas [\#](https://supabase.com/docs/guides/platform/manage-your-usage/ipv4\#one-project-with-read-replicas)

The project has two Read Replicas and the IPv4 add-on enabled throughout the entire billing cycle.

| Line Item | Hours | Costs |
| --- | --- | --- |
| Pro Plan | - | $25 |
|  |  |  |
| Compute Hours Small Project 1 | 744 | $15 |
| IPv4 Hours Project 1 | 744 | $4 |
|  |  |  |
| Compute Hours Small Replica 1 | 744 | $15 |
| IPv4 Hours Replica 1 | 744 | $4 |
|  |  |  |
| Compute Hours Small Replica 2 | 744 | $15 |
| IPv4 Hours Replica 2 | 744 | $4 |
|  |  |  |
| **Subtotal** |  | **$82** |
| Compute Credits |  | -$10 |
| **Total** |  | **$72** |

## Optimize usage [\#](https://supabase.com/docs/guides/platform/manage-your-usage/ipv4\#optimize-usage)

To see whether your database actually needs a dedicated IPv4 address, refer to [When you need the IPv4 add-on](https://supabase.com/docs/guides/platform/ipv4-address#when-you-need-the-ipv4-add-on).

### Is this helpful?

NoYes

### On this page

[What you are charged for](https://supabase.com/docs/guides/platform/manage-your-usage/ipv4#what-you-are-charged-for) [How charges are calculated](https://supabase.com/docs/guides/platform/manage-your-usage/ipv4#how-charges-are-calculated) [Example](https://supabase.com/docs/guides/platform/manage-your-usage/ipv4#example) [Usage on your invoice](https://supabase.com/docs/guides/platform/manage-your-usage/ipv4#usage-on-your-invoice) [Pricing](https://supabase.com/docs/guides/platform/manage-your-usage/ipv4#pricing) [Billing examples](https://supabase.com/docs/guides/platform/manage-your-usage/ipv4#billing-examples) [One project](https://supabase.com/docs/guides/platform/manage-your-usage/ipv4#one-project) [Multiple projects](https://supabase.com/docs/guides/platform/manage-your-usage/ipv4#multiple-projects) [One project with Read Replicas](https://supabase.com/docs/guides/platform/manage-your-usage/ipv4#one-project-with-read-replicas) [Optimize usage](https://supabase.com/docs/guides/platform/manage-your-usage/ipv4#optimize-usage)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_manage_your_usage_log_drains.md">
Platform

# Manage Log Drain usage

* * *

## What you are charged for [\#](https://supabase.com/docs/guides/platform/manage-your-usage/log-drains\#what-you-are-charged-for)

You can configure log drains in the [project settings](https://supabase.com/dashboard/project/_/settings/log-drains) to send logs to one or more destinations. You are charged for each log drain that is configured (referred to as [Log Drain Hours](https://supabase.com/docs/guides/platform/manage-your-usage/log-drains#log-drain-hours)), the log events sent (referred to as [Log Drain Events](https://supabase.com/docs/guides/platform/manage-your-usage/log-drains#log-drain-events)), and the [Egress](https://supabase.com/docs/guides/platform/manage-your-usage/egress) incurred by the exportacross all your projects.

## Log Drain Hours [\#](https://supabase.com/docs/guides/platform/manage-your-usage/log-drains\#log-drain-hours)

### How charges are calculated [\#](https://supabase.com/docs/guides/platform/manage-your-usage/log-drains\#how-charges-are-calculated)

You are charged by the hour, meaning you are charged for the exact number of hours that a log drain is configured for a project. If a log drain is configured for part of an hour, you are still charged for the full hour.

#### Example [\#](https://supabase.com/docs/guides/platform/manage-your-usage/log-drains\#example)

Your billing cycle runs from January 1 to January 31. On January 10 at 4:30 PM, you configure a log drain for your project. At the end of the billing cycle you are billed for 512 hours.

| Time Window | Log Drain Configured | Hours Billed | Description |
| --- | --- | --- | --- |
| January 1, 00:00 AM - January 10, 4:00 PM | No | 0 |  |
| January 10, 04:00 PM - January 10, 4:30 PM | No | 0 |  |
| January 10, 04:30 PM - January 10, 5:00 PM | Yes | 1 | full hour is billed |
| January 10, 05:00 PM - January 31, 23:59 PM | Yes | 511 |  |

#### Usage on your invoice [\#](https://supabase.com/docs/guides/platform/manage-your-usage/log-drains\#usage-on-your-invoice)

Usage is shown as "Log Drain Hours" on your invoice.

### Pricing [\#](https://supabase.com/docs/guides/platform/manage-your-usage/log-drains\#pricing)

Log Drains are available as a project Add-On for all Team and Enterprise users. Each Log Drain costs $0.0822 per hour ($60 per month).

## Log Drain Events [\#](https://supabase.com/docs/guides/platform/manage-your-usage/log-drains\#log-drain-events)

### How charges are calculated [\#](https://supabase.com/docs/guides/platform/manage-your-usage/log-drains\#how-charges-are-calculated)

Log Drain Events are billed using Package pricing, with each package representing 1 million events. If your usage falls between two packages, you are billed for the next whole package.

#### Example [\#](https://supabase.com/docs/guides/platform/manage-your-usage/log-drains\#example)

| Events | Packages Billed | Costs |
| --- | --- | --- |
| 999,999 | 1 | $0.2 |
| 1,000,000 | 1 | $0.2 |
| 1,000,001 | 2 | $0.4 |
| 1,500,000 | 2 | $0.4 |

#### Usage on your invoice [\#](https://supabase.com/docs/guides/platform/manage-your-usage/log-drains\#usage-on-your-invoice)

Usage is shown as "Log Drain Events" on your invoice.

### Pricing [\#](https://supabase.com/docs/guides/platform/manage-your-usage/log-drains\#pricing)

$0.2 per 1 million events.

## Billing example [\#](https://supabase.com/docs/guides/platform/manage-your-usage/log-drains\#billing-example)

The project has two log drains configured throughout the entire billing cycle with 800,000 and 1.6 million events each. In this example we assume that the organization is exceeding its Unified Egress Quota, so charges for Egress apply.

| Line Item | Units | Costs |
| --- | --- | --- |
| Team Plan | 1 | $599 |
|  |  |  |
| Compute Hours Micro Project 1 | 744 hours | $10 |
|  |  |  |
| Log Drain Hours Drain 1 | 744 hours | $60 |
| Log Drain Events Drain 1 | 800,000 events | $0.2 |
| Egress Drain 1 | 2 GB | $0.18 |
|  |  |  |
| Log Drain Hours Drain 2 | 744 hours | $60 |
| Log Drain Events Drain 2 | 1.6 million events | $0.4 |
| Egress Drain 2 | 4 GB | $0.36 |
|  |  |  |
| **Subtotal** |  | **$730.14** |
| Compute Credits |  | -$10 |
| **Total** |  | **$720.14** |

## View usage [\#](https://supabase.com/docs/guides/platform/manage-your-usage/log-drains\#view-usage)

You can view Log Drain Events usage on the [organization's usage page](https://supabase.com/dashboard/org/_/usage). The page shows the usage of all projects by default. To view the usage for a specific project, select it from the dropdown. You can also select a different time period.

![Usage page usage summary](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-logdrain-events--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[What you are charged for](https://supabase.com/docs/guides/platform/manage-your-usage/log-drains#what-you-are-charged-for) [Log Drain Hours](https://supabase.com/docs/guides/platform/manage-your-usage/log-drains#log-drain-hours) [How charges are calculated](https://supabase.com/docs/guides/platform/manage-your-usage/log-drains#how-charges-are-calculated) [Pricing](https://supabase.com/docs/guides/platform/manage-your-usage/log-drains#pricing) [Log Drain Events](https://supabase.com/docs/guides/platform/manage-your-usage/log-drains#log-drain-events) [How charges are calculated](https://supabase.com/docs/guides/platform/manage-your-usage/log-drains#how-charges-are-calculated) [Pricing](https://supabase.com/docs/guides/platform/manage-your-usage/log-drains#pricing) [Billing example](https://supabase.com/docs/guides/platform/manage-your-usage/log-drains#billing-example) [View usage](https://supabase.com/docs/guides/platform/manage-your-usage/log-drains#view-usage)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_manage_your_usage_monthly_active_users_sso.md">
Platform

# Manage Monthly Active SSO Users usage

* * *

## What you are charged for [\#](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-sso\#what-you-are-charged-for)

You are charged for the number of distinct users who log in or refresh their token during the billing cycle using a SAML 2.0 compatible identity provider. Each unique user is counted only once per billing cycle, regardless of how many times they authenticate. These users are referred to as "SSO MAUs".

### Example [\#](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-sso\#example)

Your billing cycle runs from January 1 to January 31. Although User-1 was signed in multiple times, they are counted as a single SSO MAU for this billing cycle.

1

### Sign User-1 in on January 3

The SSO MAU count increases from 0 to 1.

`
const { data, error } = await supabase.auth.signInWithSSO({
domain: 'company.com'
})
if (data?.url) {
// redirect User-1 to the identity provider's authentication flow
window.location.href = data.url
}
`

2

### Sign User-1 out on January 4

`javascript const {error} = await supabase.auth.signOut() `

3

### Sign User-1 in again on January 17

The SSO MAU count remains 1.

`
const { data, error } = await supabase.auth.signInWithSSO({
domain: 'company.com'
})
if (data?.url) {
// redirect User-1 to the identity provider's authentication flow
window.location.href = data.url
}
`

## How charges are calculated [\#](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-sso\#how-charges-are-calculated)

You are charged by SSO MAU.

### Usage on your invoice [\#](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-sso\#usage-on-your-invoice)

Usage is shown as "Monthly Active SSO Users" on your invoice.

## Pricing [\#](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-sso\#pricing)

$0.015 per SSO MAU. You are only charged for usage exceeding your subscription plan's quota.

The count resets at the start of each billing cycle.

| Plan | Quota | Over-Usage |
| --- | --- | --- |
| Pro | 50 | $0.015 per SSO MAU |
| Team | 50 | $0.015 per SSO MAU |
| Enterprise | Custom | Custom |

## Billing examples [\#](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-sso\#billing-examples)

### Within quota [\#](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-sso\#within-quota)

The organization's SSO MAU usage for the billing cycle is within the quota, so no charges apply.

| Line Item | Units | Costs |
| --- | --- | --- |
| Pro Plan | 1 | $25 |
| Compute Hours Micro | 744 hours | $10 |
| Monthly Active SSO Users | 37 SSO MAU | $0 |
| **Subtotal** |  | **$35** |
| Compute Credits |  | -$10 |
| **Total** |  | **$25** |

### Exceeding quota [\#](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-sso\#exceeding-quota)

The organization's SSO MAU usage for the billing cycle exceeds the quota by 10, incurring charges for this additional usage.

| Line Item | Units | Costs |
| --- | --- | --- |
| Pro Plan | 1 | $25 |
| Compute Hours Micro | 744 hours | $10 |
| Monthly Active SSO Users | 60 SSO MAU | $0.15 |
| **Subtotal** |  | **$35.15** |
| Compute Credits |  | -$10 |
| **Total** |  | **$25.15** |

## View usage [\#](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-sso\#view-usage)

You can view Monthly Active SSO Users usage on the [organization's usage page](https://supabase.com/dashboard/org/_/usage). The page shows the usage of all projects by default. To view the usage for a specific project, select it from the dropdown. You can also select a different time period.

![Usage page navigation bar](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-navbar--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

In the Monthly Active SSO Users section, you can see the usage for the selected time period.

![Usage page Monthly Active SSO Users section](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-mau-sso--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[What you are charged for](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-sso#what-you-are-charged-for) [Example](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-sso#example) [How charges are calculated](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-sso#how-charges-are-calculated) [Usage on your invoice](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-sso#usage-on-your-invoice) [Pricing](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-sso#pricing) [Billing examples](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-sso#billing-examples) [Within quota](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-sso#within-quota) [Exceeding quota](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-sso#exceeding-quota) [View usage](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-sso#view-usage)

![Usage page navigation bar](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-navbar--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_manage_your_usage_monthly_active_users_third_party.md">
Platform

# Manage Monthly Active Third-Party Users usage

* * *

## What you are charged for [\#](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-third-party\#what-you-are-charged-for)

You are charged for the number of distinct users who log in or refresh their token during the billing cycle using a third-party authentication provider. Each unique user is counted only once per billing cycle, regardless of how many times they authenticate. These users are referred to as "Third-Party MAUs".

### Example [\#](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-third-party\#example)

Your billing cycle runs from January 1 to January 31. Although User-1 was signed in multiple times, they are counted as a single SSO MAU for this billing cycle.

1

### User-1 signs in via Auth0 on January 3

The Third-Party MAU count increases
from 0 to 1.

![Third-Party MAU login screen](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fthird-party-mau-auth0-login-screen.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

2

### User-1 signs out on January 4.

3

### User-1 signs in via Auth0 again on January 17

The Third-Party MAU count remains 1.

![Third-Party MAU login screen](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fthird-party-mau-auth0-login-screen.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

## How charges are calculated [\#](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-third-party\#how-charges-are-calculated)

You are charged by Third-Party MAU.

### Usage on your invoice [\#](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-third-party\#usage-on-your-invoice)

Usage is shown as "Monthly Active Third-Party Users" on your invoice.

## Pricing [\#](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-third-party\#pricing)

$0.00325 per Third-Party MAU. You are only charged for usage exceeding your subscription plan's quota.

The count resets at the start of each billing cycle.

| Plan | Quota | Over-Usage |
| --- | --- | --- |
| Free | 50,000 | - |
| Pro | 100,000 | $0.00325 per Third-Party MAU |
| Team | 100,000 | $0.00325 per Third-Party MAU |
| Enterprise | Custom | Custom |

## Billing examples [\#](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-third-party\#billing-examples)

### Within quota [\#](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-third-party\#within-quota)

The organization's Third-Party MAU usage for the billing cycle is within the quota, so no charges apply.

| Line Item | Units | Costs |
| --- | --- | --- |
| Pro Plan | 1 | $25 |
| Compute Hours Micro | 744 hours | $10 |
| Monthly Active Third-Party Users | 37,000 Third-Party MAU | $0 |
| **Subtotal** |  | **$35** |
| Compute Credits |  | -$10 |
| **Total** |  | **$25** |

### Exceeding quota [\#](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-third-party\#exceeding-quota)

The organization's Third-Party MAU usage for the billing cycle exceeds the quota by 4950, incurring charges for this additional usage.

| Line Item | Units | Costs |
| --- | --- | --- |
| Pro Plan | 1 | $25 |
| Compute Hours Micro | 744 hours | $10 |
| Monthly Active Third-Party Users | 130,000 Third-Party MAU | $97.50 |
| **Subtotal** |  | **$132.50** |
| Compute Credits |  | -$10 |
| **Total** |  | **$122.50** |

## View usage [\#](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-third-party\#view-usage)

You can view Monthly Active Third-Party Users usage on the [organization's usage page](https://supabase.com/dashboard/org/_/usage). The page shows the usage of all projects by default. To view the usage for a specific project, select it from the dropdown. You can also select a different time period.

![Usage page Monthly Active SSO Users section](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-mau-third-party--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[What you are charged for](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-third-party#what-you-are-charged-for) [Example](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-third-party#example) [How charges are calculated](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-third-party#how-charges-are-calculated) [Usage on your invoice](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-third-party#usage-on-your-invoice) [Pricing](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-third-party#pricing) [Billing examples](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-third-party#billing-examples) [Within quota](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-third-party#within-quota) [Exceeding quota](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-third-party#exceeding-quota) [View usage](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-third-party#view-usage)

![Third-Party MAU login screen](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fthird-party-mau-auth0-login-screen.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![Third-Party MAU login screen](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fthird-party-mau-auth0-login-screen.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_manage_your_usage_monthly_active_users.md">
Platform

# Manage Monthly Active Users usage

* * *

## What you are charged for [\#](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users\#what-you-are-charged-for)

You are charged for the number of distinct users who log in or refresh their token during the billing cycle. Each unique user is counted only once per billing cycle, regardless of how many times they authenticate. These users are referred to as "MAUs".

### Example [\#](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users\#example)

Your billing cycle runs from January 1 to January 31. Although User-1 was signed in multiple times, they are counted as a single MAU for this billing cycle.

1

### Sign User-1 in on January 3

The MAU count increases from 0 to 1.

`
const {data, error} = await supabase.auth.signInWithPassword({
email: 'user-1@email.com',
password: 'example-password-1',
})
`

2

### Sign User-1 out on January 4

`javascript const {error} = await supabase.auth.signOut() `

3

### Sign User-1 in again on January 17

The MAU count remains 1.

`
const {data, error} = await supabase.auth.signInWithPassword({
email: 'user-1@email.com',
password: 'example-password-1',
})
`

## How charges are calculated [\#](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users\#how-charges-are-calculated)

You are charged by MAU.

### Usage on your invoice [\#](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users\#usage-on-your-invoice)

Usage is shown as "Monthly Active Users" on your invoice.

## Pricing [\#](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users\#pricing)

$0.00325 per MAU. You are only charged for usage exceeding your subscription plan's quota.

The count resets at the start of each billing cycle.

| Plan | Quota | Over-Usage |
| --- | --- | --- |
| Free | 50,000 | - |
| Pro | 100,000 | $0.00325 per MAU |
| Team | 100,000 | $0.00325 per MAU |
| Enterprise | Custom | Custom |

## Billing examples [\#](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users\#billing-examples)

### Within quota [\#](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users\#within-quota)

The organization's MAU usage for the billing cycle is within the quota, so no charges apply.

| Line Item | Units | Costs |
| --- | --- | --- |
| Pro Plan | 1 | $25 |
| Compute Hours Micro | 744 hours | $10 |
| Monthly Active Users | 23,000 MAU | $0 |
| **Subtotal** |  | **$35** |
| Compute Credits |  | -$10 |
| **Total** |  | **$25** |

### Exceeding quota [\#](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users\#exceeding-quota)

The organization's MAU usage for the billing cycle exceeds the quota by 60,000, incurring charges for this additional usage.

| Line Item | Units | Costs |
| --- | --- | --- |
| Pro Plan | 1 | $25 |
| Compute Hours Micro | 744 hours | $10 |
| Monthly Active Users | 160,000 MAU | $195 |
| **Subtotal** |  | **$230** |
| Compute Credits |  | -$10 |
| **Total** |  | **$220** |

## View usage [\#](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users\#view-usage)

You can view Monthly Active Users usage on the [organization's usage page](https://supabase.com/dashboard/org/_/usage). The page shows the usage of all projects by default. To view the usage for a specific project, select it from the dropdown. You can also select a different time period.

![Usage page navigation bar](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-navbar--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

In the Monthly Active Users section, you can see the usage for the selected time period.

![Usage page Monthly Active Users section](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-mau--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[What you are charged for](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users#what-you-are-charged-for) [Example](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users#example) [How charges are calculated](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users#how-charges-are-calculated) [Usage on your invoice](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users#usage-on-your-invoice) [Pricing](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users#pricing) [Billing examples](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users#billing-examples) [Within quota](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users#within-quota) [Exceeding quota](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users#exceeding-quota) [View usage](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users#view-usage)

![Usage page navigation bar](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-navbar--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_manage_your_usage_point_in_time_recovery.md">
Platform

# Manage Point-in-Time Recovery usage

* * *

## What you are charged for [\#](https://supabase.com/docs/guides/platform/manage-your-usage/point-in-time-recovery\#what-you-are-charged-for)

You can configure [Point-in-Time Recovery (PITR)](https://supabase.com/docs/guides/platform/backups#point-in-time-recovery) for a project by enabling the [PITR add-on](https://supabase.com/dashboard/project/_/settings/addons?panel=pitr). You are charged for every enabled PITR add-on across your projects.

## How charges are calculated [\#](https://supabase.com/docs/guides/platform/manage-your-usage/point-in-time-recovery\#how-charges-are-calculated)

PITR is charged by the hour, meaning you are charged for the exact number of hours that PITR is active for a project. If PITR is active for part of an hour, you are still charged for the full hour.

### Example [\#](https://supabase.com/docs/guides/platform/manage-your-usage/point-in-time-recovery\#example)

Your billing cycle runs from January 1 to January 31. On January 10 at 4:30 PM, you activate PITR for your project. At the end of the billing cycle you are billed for 512 hours.

| Time Window | PITR Activated | Hours Billed | Description |
| --- | --- | --- | --- |
| January 1, 00:00 AM - January 10, 4:00 PM | No | 0 |  |
| January 10, 04:00 PM - January 10, 4:30 PM | No | 0 |  |
| January 10, 04:30 PM - January 10, 5:00 PM | Yes | 1 | full hour is billed |
| January 10, 05:00 PM - January 31, 23:59 PM | Yes | 511 |  |

### Usage on your invoice [\#](https://supabase.com/docs/guides/platform/manage-your-usage/point-in-time-recovery\#usage-on-your-invoice)

Usage is shown as "Point-in-time recovery Hours" on your invoice.

## Pricing [\#](https://supabase.com/docs/guides/platform/manage-your-usage/point-in-time-recovery\#pricing)

Pricing depends on the recovery retention period, which determines how many days back you can restore data to any chosen point of up to seconds in granularity.

| Recovery Retention Period in Days | Hourly Price USD | Monthly Price USD |
| --- | --- | --- |
| 7 | $0.137 | $100 |
| 14 | $0.274 | $200 |
| 28 | $0.55 | $400 |

## Billing examples [\#](https://supabase.com/docs/guides/platform/manage-your-usage/point-in-time-recovery\#billing-examples)

### One project [\#](https://supabase.com/docs/guides/platform/manage-your-usage/point-in-time-recovery\#one-project)

The project has PITR with a recovery retention period of 7 days activated throughout the entire billing cycle.

| Line Item | Hours | Costs |
| --- | --- | --- |
| Pro Plan | - | $25 |
| Compute Hours Small Project 1 | 744 | $15 |
| PITR Hours | 744 | $100 |
| **Subtotal** |  | **$140** |
| Compute Credits |  | -$10 |
| **Total** |  | **$130** |

### Multiple projects [\#](https://supabase.com/docs/guides/platform/manage-your-usage/point-in-time-recovery\#multiple-projects)

All projects have PITR with a recovery retention period of 14 days activated throughout the entire billing cycle.

| Line Item | Hours | Costs |
| --- | --- | --- |
| Pro Plan | - | $25 |
|  |  |  |
| Compute Hours Small Project 1 | 744 | $15 |
| PITR Hours Project 1 | 744 | $200 |
|  |  |  |
| Compute Hours Small Project 2 | 744 | $15 |
| PITR Hours Project 2 | 744 | $200 |
|  |  |  |
| **Subtotal** |  | **$455** |
| Compute Credits |  | -$10 |
| **Total** |  | **$445** |

## Optimize usage [\#](https://supabase.com/docs/guides/platform/manage-your-usage/point-in-time-recovery\#optimize-usage)

- Review your [backup frequency](https://supabase.com/docs/guides/platform/backups#frequency-of-backups) needs to determine whether you require PITR or free Daily Backups are sufficient
- Regularly check your projects and disable PITR where no longer needed
- Consider disabling PITR for non-production databases

### Is this helpful?

NoYes

### On this page

[What you are charged for](https://supabase.com/docs/guides/platform/manage-your-usage/point-in-time-recovery#what-you-are-charged-for) [How charges are calculated](https://supabase.com/docs/guides/platform/manage-your-usage/point-in-time-recovery#how-charges-are-calculated) [Example](https://supabase.com/docs/guides/platform/manage-your-usage/point-in-time-recovery#example) [Usage on your invoice](https://supabase.com/docs/guides/platform/manage-your-usage/point-in-time-recovery#usage-on-your-invoice) [Pricing](https://supabase.com/docs/guides/platform/manage-your-usage/point-in-time-recovery#pricing) [Billing examples](https://supabase.com/docs/guides/platform/manage-your-usage/point-in-time-recovery#billing-examples) [One project](https://supabase.com/docs/guides/platform/manage-your-usage/point-in-time-recovery#one-project) [Multiple projects](https://supabase.com/docs/guides/platform/manage-your-usage/point-in-time-recovery#multiple-projects) [Optimize usage](https://supabase.com/docs/guides/platform/manage-your-usage/point-in-time-recovery#optimize-usage)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_manage_your_usage_read_replicas.md">
Platform

# Manage Read Replica usage

* * *

## What you are charged for [\#](https://supabase.com/docs/guides/platform/manage-your-usage/read-replicas\#what-you-are-charged-for)

Each [Read Replica](https://supabase.com/docs/guides/platform/read-replicas) is a dedicated database. You are charged for its resources: [Compute](https://supabase.com/docs/guides/platform/compute-and-disk#compute), [Disk Size](https://supabase.com/docs/guides/platform/database-size#disk-size), provisioned [Disk IOPS](https://supabase.com/docs/guides/platform/compute-and-disk#provisioned-disk-throughput-and-iops), provisioned [Disk Throughput](https://supabase.com/docs/guides/platform/compute-and-disk#provisioned-disk-throughput-and-iops), and [IPv4](https://supabase.com/docs/guides/platform/ipv4-address).

## How charges are calculated [\#](https://supabase.com/docs/guides/platform/manage-your-usage/read-replicas\#how-charges-are-calculated)

Read Replica charges are the total of the charges listed below.

**Compute**
Compute is charged by the hour, meaning you are charged for the exact number of hours that a Read Replica is running and, therefore, incurring Compute usage. If a Read Replica runs for part of an hour, you are still charged for the full hour.

Read Replicas run on the same Compute size as the primary database.

**Disk Size**
Refer to [Manage Disk Size usage](https://supabase.com/docs/guides/platform/manage-your-usage/disk-size) for details on how charges are calculated. The disk size of a Read Replica is 1.25x the size of the primary disk to account for WAL archives. With a Read Replica you go beyond your subscription plan's quota for Disk Size.

**Provisioned Disk IOPS (optional)**
Read Replicas inherit any additional provisioned Disk IOPS from the primary database. Refer to [Manage Disk IOPS usage](https://supabase.com/docs/guides/platform/manage-your-usage/disk-iops) for details on how charges are calculated.

**Provisioned Disk Throughput (optional)**
Read Replicas inherit any additional provisioned Disk Throughput from the primary database. Refer to [Manage Disk Throughput usage](https://supabase.com/docs/guides/platform/manage-your-usage/disk-throughput) for details on how charges are calculated.

**IPv4 (optional)**
If the primary database has a configured IPv4 address, its Read Replicas are also assigned one, with charges for each. Refer to [Manage IPv4 usage](https://supabase.com/docs/guides/platform/manage-your-usage/ipv4) for details on how charges are calculated.

### Usage on your invoice [\#](https://supabase.com/docs/guides/platform/manage-your-usage/read-replicas\#usage-on-your-invoice)

Compute incurred by Read Replicas is shown as "Replica Compute Hours" on your invoice. Disk Size, Disk IOPS, Disk Throughput and IPv4 are not shown separately for Read Replicas and are rolled up into the project.

## Billing examples [\#](https://supabase.com/docs/guides/platform/manage-your-usage/read-replicas\#billing-examples)

### No additional resources configured [\#](https://supabase.com/docs/guides/platform/manage-your-usage/read-replicas\#no-additional-resources-configured)

The project has one Read Replica and no IPv4 and no additional Disk IOPS and Disk Throughput configured.

| Line Item | Units | Costs |
| --- | --- | --- |
| Pro Plan | 1 | $25 |
|  |  |  |
| Compute Hours Small Project 1 | 744 hours | $15 |
| Disk Size Project 1 | 8 GB | $0 |
|  |  |  |
| Compute Hours Small Replica | 744 hours | $15 |
| Disk Size Replica | 10 GB | $1.25 |
|  |  |  |
| **Subtotal** |  | **$56.25** |
| Compute Credits |  | -$10 |
| **Total** |  | **$46.25** |

### Additional resources configured [\#](https://supabase.com/docs/guides/platform/manage-your-usage/read-replicas\#additional-resources-configured)

The project has two Read Replicas and IPv4 and additional Disk IOPS and Disk Throughput configured.

| Line Item | Units | Costs |
| --- | --- | --- |
| Pro Plan | 1 | $25 |
|  |  |  |
| Compute Hours Large Project 1 | 744 hours | $110 |
| Disk Size Project 1 | 8 GB | $0 |
| Disk IOPS Project 1 | 3600 | $14.40 |
| Disk Throughput Project 1 | 200 Mbps | $7.13 |
| IPv4 Hours Project 1 | 744 hours | $4 |
|  |  |  |
| Compute Hours Large Replica 1 | 744 hours | $110 |
| Disk Size Replica 1 | 10 GB | $1.25 |
| Disk IOPS Replica 1 | 3600 | $14.40 |
| Disk Throughput Replica 1 | 200 Mbps | $7.13 |
| IPv4 Hours Replica 1 | 744 hours | $4 |
|  |  |  |
| Compute Hours Large Replica 2 | 744 hours | $110 |
| Disk Size Replica 2 | 10 GB | $1.25 |
| Disk IOPS Replica 2 | 3600 | $14.40 |
| Disk Throughput Replica 2 | 200 Mbps | $7.13 |
| IPv4 Hours Replica 2 | 744 hours | $4 |
|  |  |  |
| **Subtotal** |  | **$434.09** |
| Compute Credits |  | -$10 |
| **Total** |  | **$424.09** |

## FAQ [\#](https://supabase.com/docs/guides/platform/manage-your-usage/read-replicas\#faq)

### Do Compute Credits apply to Read Replica Compute? [\#](https://supabase.com/docs/guides/platform/manage-your-usage/read-replicas\#do-compute-credits-apply-to-read-replica-compute)

No, Compute Credits do not apply to Read Replica Compute.

### Is this helpful?

NoYes

### On this page

[What you are charged for](https://supabase.com/docs/guides/platform/manage-your-usage/read-replicas#what-you-are-charged-for) [How charges are calculated](https://supabase.com/docs/guides/platform/manage-your-usage/read-replicas#how-charges-are-calculated) [Usage on your invoice](https://supabase.com/docs/guides/platform/manage-your-usage/read-replicas#usage-on-your-invoice) [Billing examples](https://supabase.com/docs/guides/platform/manage-your-usage/read-replicas#billing-examples) [No additional resources configured](https://supabase.com/docs/guides/platform/manage-your-usage/read-replicas#no-additional-resources-configured) [Additional resources configured](https://supabase.com/docs/guides/platform/manage-your-usage/read-replicas#additional-resources-configured) [FAQ](https://supabase.com/docs/guides/platform/manage-your-usage/read-replicas#faq) [Do Compute Credits apply to Read Replica Compute?](https://supabase.com/docs/guides/platform/manage-your-usage/read-replicas#do-compute-credits-apply-to-read-replica-compute)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_manage_your_usage_realtime_messages.md">
Platform

# Manage Realtime Messages usage

* * *

## What you are charged for [\#](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-messages\#what-you-are-charged-for)

You are charged for the number of messages going through Supabase Realtime throughout the billing cycle. Includes database changes, Broadcast and Presence.

**Database changes**
Each database change counts as one message per client that listens to the event. For example, if a database change occurs and 5 clients listen to that database event, it counts as 5 messages.

**Broadcast**
Each broadcast message counts as one message sent plus one message per subscribed client that receives it. For example, if you broadcast a message and 4 clients listen to it, it counts as 5 messages1 sent and 4 received.

## How charges are calculated [\#](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-messages\#how-charges-are-calculated)

Realtime Messages are billed using Package pricing, with each package representing 1 million messages. If your usage falls between two packages, you are billed for the next whole package.

### Example [\#](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-messages\#example)

For simplicity, let's assume a package size of 1,000,000 and a charge of $2.50 per package without quota.

| Messages | Packages Billed | Costs |
| --- | --- | --- |
| 999,999 | 1 | $2.50 |
| 1,000,000 | 1 | $2.50 |
| 1,000,001 | 2 | $5.00 |
| 1,500,000 | 2 | $5.00 |

### Usage on your invoice [\#](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-messages\#usage-on-your-invoice)

Usage is shown as "Realtime Messages" on your invoice.

## Pricing [\#](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-messages\#pricing)

$2.50 per 1 million messages. You are only charged for usage exceeding your subscription plan's quota.

| Plan | Quota | Over-Usage |
| --- | --- | --- |
| Free | 2 million | - |
| Pro | 5 million | $2.50 per 1 million messages |
| Team | 5 million | $2.50 per 1 million messages |
| Enterprise | Custom | Custom |

## Billing examples [\#](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-messages\#billing-examples)

### Within quota [\#](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-messages\#within-quota)

The organization's Realtime messages are within the quota, so no charges apply.

| Line Item | Units | Costs |
| --- | --- | --- |
| Pro Plan | 1 | $25 |
| Compute Hours Micro | 744 hours | $10 |
| Realtime Messages | 1.8 million messages | $0 |
| **Subtotal** |  | **$35** |
| Compute Credits |  | -$10 |
| **Total** |  | **$25** |

### Exceeding quota [\#](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-messages\#exceeding-quota)

The organization's Realtime messages exceed the quota by 3.5 million, incurring charges for this additional usage.

| Line Item | Units | Costs |
| --- | --- | --- |
| Pro Plan | 1 | $25 |
| Compute Hours Micro | 744 hours | $10 |
| Realtime Messages | 8.5 million messages | $10 |
| **Subtotal** |  | **$45** |
| Compute Credits |  | -$10 |
| **Total** |  | **$35** |

## View usage [\#](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-messages\#view-usage)

You can view Realtime Messages usage on the [organization's usage page](https://supabase.com/dashboard/org/_/usage). The page shows the usage of all projects by default. To view the usage for a specific project, select it from the dropdown. You can also select a different time period.

![Usage page navigation bar](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-navbar--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

In the Realtime Messages section, you can see the usage for the selected time period.

![Usage page Realtime Messages section](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-realtime-messages--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[What you are charged for](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-messages#what-you-are-charged-for) [How charges are calculated](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-messages#how-charges-are-calculated) [Example](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-messages#example) [Usage on your invoice](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-messages#usage-on-your-invoice) [Pricing](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-messages#pricing) [Billing examples](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-messages#billing-examples) [Within quota](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-messages#within-quota) [Exceeding quota](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-messages#exceeding-quota) [View usage](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-messages#view-usage)

![Usage page navigation bar](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-navbar--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![Usage page Realtime Messages section](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-realtime-messages--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_manage_your_usage_realtime_peak_connections.md">
Platform

# Manage Realtime Peak Connections usage

* * *

## What you are charged for [\#](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-peak-connections\#what-you-are-charged-for)

Realtime Peak Connections are measured by tracking the highest number of concurrent connections for each project during the billing cycle. Regardless of fluctuations, only the peak count per project is used for billing, and the totals from all projects are summed. Only successful connections are counted, connection attempts are not included.

### Example [\#](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-peak-connections\#example)

For simplicity, this example assumes a billing cycle of only three days.

| Project | Peak Connections Day 1 | Peak Connections Day 2 | Peak Connections Day 3 |
| --- | --- | --- | --- |
| Project A | 80 | 100 | 90 |
| Project B | 120 | 110 | 150 |

**Total billed connections:** 100 (Project A) + 150 (Project B) = **250 connections**

## How charges are calculated [\#](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-peak-connections\#how-charges-are-calculated)

Realtime Peak Connections are billed using Package pricing, with each package representing 1,000 peak connections. If your usage falls between two packages, you are billed for the next whole package.

### Example [\#](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-peak-connections\#example)

For simplicity, let's assume a package size of 1,000 and a charge of $10 per package with no quota.

| Peak Connections | Packages Billed | Costs |
| --- | --- | --- |
| 999 | 1 | $10 |
| 1,000 | 1 | $10 |
| 1,001 | 2 | $20 |
| 1,500 | 2 | $20 |

### Usage on your invoice [\#](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-peak-connections\#usage-on-your-invoice)

Usage is shown as "Realtime Peak Connections" on your invoice.

## Pricing [\#](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-peak-connections\#pricing)

$10 per 1,000 peak connections. You are only charged for usage exceeding your subscription plan's quota.

| Plan | Quota | Over-Usage |
| --- | --- | --- |
| Free | 200 | - |
| Pro | 500 | $10 per 1,000 peak connections |
| Team | 500 | $10 per 1,000 peak connections |
| Enterprise | Custom | Custom |

## Billing examples [\#](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-peak-connections\#billing-examples)

### Within quota [\#](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-peak-connections\#within-quota)

The organization's connections are within the quota, so no charges apply.

| Line Item | Units | Costs |
| --- | --- | --- |
| Pro Plan | 1 | $25 |
| Compute Hours Micro | 744 hours | $10 |
| Realtime Peak Connections | 350 connections | $0 |
| **Subtotal** |  | **$35** |
| Compute Credits |  | -$10 |
| **Total** |  | **$25** |

### Exceeding quota [\#](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-peak-connections\#exceeding-quota)

The organization's connections exceed the quota by 1,200, incurring charges for this additional usage.

| Line Item | Units | Costs |
| --- | --- | --- |
| Pro Plan | 1 | $25 |
| Compute Hours Micro | 744 hours | $10 |
| Realtime Peak Connections | 1,700 connections | $20 |
| **Subtotal** |  | **$45** |
| Compute Credits |  | -$10 |
| **Total** |  | **$35** |

## View usage [\#](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-peak-connections\#view-usage)

You can view Realtime Peak Connections usage on the [organization's usage page](https://supabase.com/dashboard/org/_/usage). The page shows the usage of all projects by default. To view the usage for a specific project, select it from the dropdown. You can also select a different time period.

![Usage page navigation bar](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-navbar--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

In the Realtime Peak Connections section, you can see the usage for the selected time period.

![Usage page Realtime Peak Connections section](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-realtime-peak-connections--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[What you are charged for](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-peak-connections#what-you-are-charged-for) [Example](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-peak-connections#example) [How charges are calculated](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-peak-connections#how-charges-are-calculated) [Example](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-peak-connections#example) [Usage on your invoice](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-peak-connections#usage-on-your-invoice) [Pricing](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-peak-connections#pricing) [Billing examples](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-peak-connections#billing-examples) [Within quota](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-peak-connections#within-quota) [Exceeding quota](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-peak-connections#exceeding-quota) [View usage](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-peak-connections#view-usage)

![Usage page navigation bar](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-navbar--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![Usage page Realtime Peak Connections section](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-realtime-peak-connections--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_manage_your_usage_storage_image_transformations.md">
Platform

# Manage Storage Image Transformations usage

* * *

## What you are charged for [\#](https://supabase.com/docs/guides/platform/manage-your-usage/storage-image-transformations\#what-you-are-charged-for)

You are charged for the number of distinct images transformed during the billing period, regardless of how many transformations each image undergoes. We refer to these images as "origin" images.

### Example [\#](https://supabase.com/docs/guides/platform/manage-your-usage/storage-image-transformations\#example)

With these four transformations applied to `image-1.jpg` and `image-2.jpg`, the origin images count is 2.

`
supabase.storage.from('bucket').createSignedUrl('image-1.jpg', 60000, {
transform: {
    width: 200,
    height: 200,
},
})
`

`
supabase.storage.from('bucket').createSignedUrl('image-2.jpg', 60000, {
transform: {
    width: 400,
    height: 300,
},
})
`

`
supabase.storage.from('bucket').createSignedUrl('image-2.jpg', 60000, {
transform: {
    width: 600,
    height: 250,
},
})
`

`
supabase.storage.from('bucket').download('image-2.jpg', {
transform: {
    width: 800,
    height: 300,
},
})
`

## How charges are calculated [\#](https://supabase.com/docs/guides/platform/manage-your-usage/storage-image-transformations\#how-charges-are-calculated)

Storage Image Transformations are billed using Package pricing, with each package representing 1000 origin images. If your usage falls between two packages, you are billed for the next whole package.

### Example [\#](https://supabase.com/docs/guides/platform/manage-your-usage/storage-image-transformations\#example)

For simplicity, let's assume a package size of 1,000 and a charge of $5 per package with no quota.

| Origin Images | Packages Billed | Costs |
| --- | --- | --- |
| 999 | 1 | $5 |
| 1,000 | 1 | $5 |
| 1,001 | 2 | $10 |
| 1,500 | 2 | $10 |

### Usage on your invoice [\#](https://supabase.com/docs/guides/platform/manage-your-usage/storage-image-transformations\#usage-on-your-invoice)

Usage is shown as "Storage Image Transformations" on your invoice.

## Pricing [\#](https://supabase.com/docs/guides/platform/manage-your-usage/storage-image-transformations\#pricing)

$5 per 1,000 origin images. You are only charged for usage exceeding your subscription plan's quota.

The count resets at the start of each billing cycle.

| Plan | Quota | Over-Usage |
| --- | --- | --- |
| Pro | 100 | $5 per 1,000 origin images |
| Team | 100 | $5 per 1,000 origin images |
| Enterprise | Custom | Custom |

## Billing examples [\#](https://supabase.com/docs/guides/platform/manage-your-usage/storage-image-transformations\#billing-examples)

### Within quota [\#](https://supabase.com/docs/guides/platform/manage-your-usage/storage-image-transformations\#within-quota)

The organization's number of origin images for the billing cycle is within the quota, so no charges apply.

| Line Item | Units | Costs |
| --- | --- | --- |
| Pro Plan | 1 | $25 |
| Compute Hours Micro | 744 hours | $10 |
| Image Transformations | 74 origin images | $0 |
| **Subtotal** |  | **$35** |
| Compute Credits |  | -$10 |
| **Total** |  | **$25** |

### Exceeding quota [\#](https://supabase.com/docs/guides/platform/manage-your-usage/storage-image-transformations\#exceeding-quota)

The organization's number of origin images for the billing cycle exceeds the quota by 750, incurring charges for this additional usage.

| Line Item | Units | Costs |
| --- | --- | --- |
| Pro Plan | 1 | $25 |
| Compute Hours Micro | 744 hours | $10 |
| Image Transformations | 850 origin images | $5 |
| **Subtotal** |  | **$40** |
| Compute Credits |  | -$10 |
| **Total** |  | **$30** |

## View usage [\#](https://supabase.com/docs/guides/platform/manage-your-usage/storage-image-transformations\#view-usage)

You can view Storage Image Transformations usage on the [organization's usage page](https://supabase.com/dashboard/org/_/usage). The page shows the usage of all projects by default. To view the usage for a specific project, select it from the dropdown. You can also select a different time period.

![Usage page navigation bar](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-navbar--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

In the Storage Image Transformations section, you can see how many origin images were transformed during the selected time period.

![Usage page Storage Image Transformations section](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-image-transformations--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

## Optimize usage [\#](https://supabase.com/docs/guides/platform/manage-your-usage/storage-image-transformations\#optimize-usage)

- Pre-generate common variants  instead of transforming images on the fly, generate and store commonly used sizes in advance
- Optimize original image sizes  upload images in an optimized format and resolution to reduce the need for excessive transformations
- Leverage [Smart CDN](https://supabase.com/docs/guides/storage/cdn/smart-cdn) caching or any other caching solution to serve transformed images efficiently and avoid unnecessary repeated transformations
- Control how long assets are stored in the browser using the `Cache-Control` header

### Is this helpful?

NoYes

### On this page

[What you are charged for](https://supabase.com/docs/guides/platform/manage-your-usage/storage-image-transformations#what-you-are-charged-for) [Example](https://supabase.com/docs/guides/platform/manage-your-usage/storage-image-transformations#example) [How charges are calculated](https://supabase.com/docs/guides/platform/manage-your-usage/storage-image-transformations#how-charges-are-calculated) [Example](https://supabase.com/docs/guides/platform/manage-your-usage/storage-image-transformations#example) [Usage on your invoice](https://supabase.com/docs/guides/platform/manage-your-usage/storage-image-transformations#usage-on-your-invoice) [Pricing](https://supabase.com/docs/guides/platform/manage-your-usage/storage-image-transformations#pricing) [Billing examples](https://supabase.com/docs/guides/platform/manage-your-usage/storage-image-transformations#billing-examples) [Within quota](https://supabase.com/docs/guides/platform/manage-your-usage/storage-image-transformations#within-quota) [Exceeding quota](https://supabase.com/docs/guides/platform/manage-your-usage/storage-image-transformations#exceeding-quota) [View usage](https://supabase.com/docs/guides/platform/manage-your-usage/storage-image-transformations#view-usage) [Optimize usage](https://supabase.com/docs/guides/platform/manage-your-usage/storage-image-transformations#optimize-usage)

![Usage page navigation bar](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-navbar--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![Usage page Storage Image Transformations section](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-image-transformations--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_manage_your_usage_storage_size.md">
Platform

# Manage Storage size usage

* * *

## What you are charged for [\#](https://supabase.com/docs/guides/platform/manage-your-usage/storage-size\#what-you-are-charged-for)

You are charged for the total size of all assets in your buckets.

## How charges are calculated [\#](https://supabase.com/docs/guides/platform/manage-your-usage/storage-size\#how-charges-are-calculated)

Storage size is charged by Gigabyte-Hours (GB-Hrs). 1 GB-Hr represents the use of 1 GB of storage for 1 hour.
For example, storing 10 GB of data for 5 hours results in 50 GB-Hrs (10 GB  5 hours).

### Usage on your invoice [\#](https://supabase.com/docs/guides/platform/manage-your-usage/storage-size\#usage-on-your-invoice)

Usage is shown as "Storage Size GB-Hrs" on your invoice.

## Pricing [\#](https://supabase.com/docs/guides/platform/manage-your-usage/storage-size\#pricing)

$0.00002919 per GB-Hr ($0.021 per GB per month). You are only charged for usage exceeding your subscription plan's quota.

| Plan | Quota in GB | Over-Usage per GB | Quota in GB-Hrs | Over-Usage per GB-Hrs |
| --- | --- | --- | --- | --- |
| Free | 1 | - | 744 | - |
| Pro | 100 | $0.021 | 74,400 | $0.00002919 |
| Team | 100 | $0.021 | 74,400 | $0.00002919 |
| Enterprise | Custom | Custom | Custom | Custom |

## Billing examples [\#](https://supabase.com/docs/guides/platform/manage-your-usage/storage-size\#billing-examples)

### Within quota [\#](https://supabase.com/docs/guides/platform/manage-your-usage/storage-size\#within-quota)

The organization's Storage size usage is within the quota, so no charges for Storage size apply.

| Line Item | Units | Costs |
| --- | --- | --- |
| Pro Plan | 1 | $25 |
| Compute Hours Micro | 744 hours | $10 |
| Storage Size | 85 GB | $0 |
| **Subtotal** |  | **$35** |
| Compute Credits |  | -$10 |
| **Total** |  | **$25** |

### Exceeding quota [\#](https://supabase.com/docs/guides/platform/manage-your-usage/storage-size\#exceeding-quota)

The organization's Storage size usage exceeds the quota by 257 GB, incurring charges for this additional usage.

| Line Item | Units | Costs |
| --- | --- | --- |
| Pro Plan | 1 | $25 |
| Compute Hours Micro | 744 hours | $10 |
| Storage Size | 357 GB | $5.4 |
| **Subtotal** |  | **$40.4** |
| Compute Credits |  | -$10 |
| **Total** |  | **$30.4** |

## View usage [\#](https://supabase.com/docs/guides/platform/manage-your-usage/storage-size\#view-usage)

### Usage page [\#](https://supabase.com/docs/guides/platform/manage-your-usage/storage-size\#usage-page)

You can view Storage size usage on the [organization's usage page](https://supabase.com/dashboard/org/_/usage). The page shows the usage of all projects by default. To view the usage for a specific project, select it from the dropdown. You can also select a different time period.

![Usage page navigation bar](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-navbar--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

In the Storage size section, you can see how much storage your projects have used during the selected time period.

![Usage page Storage Size section](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-storage-size--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### SQL Editor [\#](https://supabase.com/docs/guides/platform/manage-your-usage/storage-size\#sql-editor)

Since we designed Storage to work as an integrated part of your Postgres database on Supabase, you can query information about your Storage objects in the `storage` schema.

List files larger than 5 MB:

`
select
    name,
    bucket_id as bucket,
    case
        when (metadata->>'size')::int >= 1073741824 then
            ((metadata->>'size')::int / 1073741824.0)::numeric(10, 2) || ' GB'
        when (metadata->>'size')::int >= 1048576 then
            ((metadata->>'size')::int / 1048576.0)::numeric(10, 2) || ' MB'
        when (metadata->>'size')::int >= 1024 then
            ((metadata->>'size')::int / 1024.0)::numeric(10, 2) || ' KB'
        else
            (metadata->>'size')::int || ' bytes'
        end as size
from
    storage.objects
where
    (metadata->>'size')::int > 1048576 * 5
order by (metadata->>'size')::int desc
`

List buckets with their total size:

`
select
    bucket_id,
    (sum((metadata->>'size')::int) / 1048576.0)::numeric(10, 2) as total_size_megabyte
from
    storage.objects
group by
    bucket_id
order by
    total_size_megabyte desc;
`

## Optimize usage [\#](https://supabase.com/docs/guides/platform/manage-your-usage/storage-size\#optimize-usage)

- [Limit the upload size](https://supabase.com/docs/guides/storage/production/scaling#limit-the-upload-size) for your buckets
- [Delete assets](https://supabase.com/docs/guides/storage/management/delete-objects) that are no longer in use

### Is this helpful?

NoYes

### On this page

[What you are charged for](https://supabase.com/docs/guides/platform/manage-your-usage/storage-size#what-you-are-charged-for) [How charges are calculated](https://supabase.com/docs/guides/platform/manage-your-usage/storage-size#how-charges-are-calculated) [Usage on your invoice](https://supabase.com/docs/guides/platform/manage-your-usage/storage-size#usage-on-your-invoice) [Pricing](https://supabase.com/docs/guides/platform/manage-your-usage/storage-size#pricing) [Billing examples](https://supabase.com/docs/guides/platform/manage-your-usage/storage-size#billing-examples) [Within quota](https://supabase.com/docs/guides/platform/manage-your-usage/storage-size#within-quota) [Exceeding quota](https://supabase.com/docs/guides/platform/manage-your-usage/storage-size#exceeding-quota) [View usage](https://supabase.com/docs/guides/platform/manage-your-usage/storage-size#view-usage) [Usage page](https://supabase.com/docs/guides/platform/manage-your-usage/storage-size#usage-page) [SQL Editor](https://supabase.com/docs/guides/platform/manage-your-usage/storage-size#sql-editor) [Optimize usage](https://supabase.com/docs/guides/platform/manage-your-usage/storage-size#optimize-usage)

![Usage page Storage Size section](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-storage-size--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![Usage page navigation bar](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fusage-navbar--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_manage_your_usage.md">
Platform

# Manage your usage

* * *

Each subpage breaks down a specific usage item and details what you're charged for, how costs are calculated, and how to optimize usage and reduce costs.

- [Compute](https://supabase.com/docs/guides/platform/manage-your-usage/compute)
- [Read Replicas](https://supabase.com/docs/guides/platform/manage-your-usage/read-replicas)
- [Branching](https://supabase.com/docs/guides/platform/manage-your-usage/branching)
- [Egress](https://supabase.com/docs/guides/platform/manage-your-usage/egress)
- [Disk Size](https://supabase.com/docs/guides/platform/manage-your-usage/disk-size)
- [Disk Throughput](https://supabase.com/docs/guides/platform/manage-your-usage/disk-throughput)
- [Disk IOPS](https://supabase.com/docs/guides/platform/manage-your-usage/disk-iops)
- [Monthly Active Users](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users)
- [Monthly Active Third-Party Users](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-third-party)
- [Monthly Active SSO Users](https://supabase.com/docs/guides/platform/manage-your-usage/monthly-active-users-sso)
- [Storage Size](https://supabase.com/docs/guides/platform/manage-your-usage/storage-size)
- [Storage Image Transformations](https://supabase.com/docs/guides/platform/manage-your-usage/storage-image-transformations)
- [Edge Function Invocations](https://supabase.com/docs/guides/platform/manage-your-usage/edge-function-invocations)
- [Realtime Messages](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-messages)
- [Realtime Peak Connections](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-peak-connections)
- [Custom Domains](https://supabase.com/docs/guides/platform/manage-your-usage/custom-domains)
- [Point-in-Time Recovery](https://supabase.com/docs/guides/platform/manage-your-usage/point-in-time-recovery)
- [IPv4](https://supabase.com/docs/guides/platform/manage-your-usage/ipv4)
- [MFA Phone](https://supabase.com/docs/guides/platform/manage-your-usage/advanced-mfa-phone)
- [Log Drains](https://supabase.com/docs/guides/platform/manage-your-usage/log-drains)

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_migrating_to_supabase_amazon_rds.md">
Platform

# Migrate from Amazon RDS to Supabase

## Migrate your Amazon RDS MySQL or MS SQL database to Supabase.

* * *

This guide aims to exhibit the process of transferring your Amazon RDS database from any of these engines Postgres, MySQL or MS SQL to Supabase's Postgres database. Although Amazon RDS is a favored managed database service provided by AWS, it may not suffice for all use cases. Supabase, on the other hand, provides an excellent free and open source option that encompasses all the necessary backend features to develop a product: a Postgres database, authentication, instant APIs, edge functions, real-time subscriptions, and storage.

Supabase's core is Postgres, enabling the use of row-level security and providing access to over 40 Postgres extensions. By migrating from Amazon RDS to Supabase, you can leverage Postgres to its fullest potential and acquire all the features you need to complete your project.

## Retrieve your Amazon RDS database credentials [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/amazon-rds\#retrieve-rds-credentials)

1. Log in to your [Amazon RDS account](https://aws.amazon.com/rds/).
2. Select the region where your RDS database is located.
3. Navigate to the **Databases** tab.
4. Select the database that you want to migrate.
5. In the **Connectivity & Security** tab, note down the Endpoint and the port number.
6. In the **Configuration** tab, note down the Database name and the Username.
7. If you do not have the password, create a new one and note it down.

![Copying RDS credentials from AWS Management Console](https://supabase.com/docs/img/guides/resources/migrating-to-supabase/amazon-rds/amazon-rds_credentials.png)

## Retrieve your Supabase host [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/amazon-rds\#retrieve-supabase-host)

1. If you're new to Supabase, [create a project](https://database.new/). Make a note of your password, you will need this later. If you forget it, you can [reset it here](https://supabase.com/dashboard/project/_/settings/database).
2. Go to the [Database settings](https://supabase.com/dashboard/project/_/settings/database) for your project in the Supabase Dashboard.
3. Under **Connection Info**, note your Host ( `$SUPABASE_HOST`).

![Finding Supabase host address](https://supabase.com/docs/img/guides/resources/migrating-to-supabase/amazon-rds/database-settings-host.png)

## Migrate the database [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/amazon-rds\#migrate-the-database)

The fastest way to migrate your database is with the Supabase migration tool on
[Google Colab](https://colab.research.google.com/github/mansueli/Supa-Migrate/blob/main/Amazon_RDS_to_Supabase.ipynb).

Alternatively, you can use [pgloader](https://github.com/dimitri/pgloader), a flexible and powerful data migration tool that supports a wide range of source database engines, including MySQL and MS SQL, and migrates the data to a Postgres database. For databases using the Postgres engine, we recommend using the [`pg_dump`](https://www.postgresql.org/docs/current/app-pgdump.html) and [psql](https://www.postgresql.org/docs/current/app-psql.html) command line tools, which are included in a full Postgres installation.

Migrate using ColabMigrate from MySQL with pgloaderMigrate from MSSQL

1. Select the Database Engine from the Source database in the dropdown
2. Set the environment variables ( `HOST`, `USER`, `SOURCE_DB`, `PASSWORD`, `SUPABASE_URL`, and `SUPABASE_PASSWORD`) in the Colab notebook.
3. Run the first two steps in [the notebook](https://colab.research.google.com/github/mansueli/Supa-Migrate/blob/main/Amazon_RDS_to_Supabase.ipynb) in order. The first sets engine and installs the necessary files.
4. Run the third step to start the migration. This will take a few minutes.

- If you're planning to migrate a database larger than 6 GB, we recommend [upgrading to at least a Large compute add-on](https://supabase.com/docs/guides/platform/compute-add-ons). This will ensure you have the necessary resources to handle the migration efficiently.

- For databases smaller than 150 GB, you can increase the size of the disk on paid projects by navigating to [Database Settings](https://supabase.com/dashboard/project/_/settings/database).

- If you're dealing with a database larger than 150 GB, we strongly advise you to [contact our support team](https://supabase.com/dashboard/support/new) for assistance in provisioning the required resources and ensuring a smooth migration process.


## Enterprise [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/amazon-rds\#enterprise)

[Contact us](https://forms.supabase.com/enterprise) if you need more help migrating your project.

### Is this helpful?

NoYes

### On this page

[Retrieve your Amazon RDS database credentials](https://supabase.com/docs/guides/platform/migrating-to-supabase/amazon-rds#retrieve-rds-credentials) [Retrieve your Supabase host](https://supabase.com/docs/guides/platform/migrating-to-supabase/amazon-rds#retrieve-supabase-host) [Migrate the database](https://supabase.com/docs/guides/platform/migrating-to-supabase/amazon-rds#migrate-the-database) [Enterprise](https://supabase.com/docs/guides/platform/migrating-to-supabase/amazon-rds#enterprise)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_migrating_to_supabase_auth0.md">
Platform

# Migrate from Auth0 to Supabase Auth

## Learn how to migrate your users from Auth0

* * *

You can migrate your users from Auth0 to Supabase Auth.

Changing authentication providers for a production app is an important operation. It can affect most aspects of your application. Prepare in advance by reading this guide, and develop a plan for handling the key migration steps and possible problems.

With advance planning, a smooth and safe Auth migration is possible.

## Before you begin [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/auth0\#before-you-begin)

Before beginning, consider the answers to the following questions. They will help you need decide if you need to migrate, and which strategy to use:

- How do Auth provider costs scale as your user base grows?
- Does the new Auth provider provide all needed features? (for example, OAuth, password logins, Security Assertion Markup Language (SAML), Multi-Factor Authentication (MFA))
- Is downtime acceptable during the migration?
- What is your timeline to migrate before terminating the old Auth provider?

## Migration strategies [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/auth0\#migration-strategies)

Depending on your evaluation, you may choose to go with one of the following strategies:

1. Rolling migration
2. One-off migration

| Strategy | Advantages | Disadvantages |
| --- | --- | --- |
| Rolling | - 0 downtime<br>- Users may need to log in again | - Need to maintain 2 different Auth services, which may be more costly in the short-term<br>- Need to maintain separate codepaths for the period of the migration<br>- Some existing users may be inactive and have not signed in with the new provider. This means that you eventually need to backfill these users. However, this is a much smaller-scale one-off migration with lower risks since these users are inactive. |
| One-off | - No need to maintain 2 different auth services for an extended period of time | - Some downtime<br>- Users will need to log in again. Risky for active users. |

## Migration steps [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/auth0\#migration-steps)

Auth provider migrations require 2 main steps:

1. Export your user data from the old provider (Auth0)
2. Import the data into your new provider (Supabase Auth)

### Step 1: Export your user data [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/auth0\#step-1-export-your-user-data)

Auth0 provides two methods for exporting user data:

1. Use the [Auth0 data export feature](https://auth0.com/docs/troubleshoot/customer-support/manage-subscriptions/export-data)
2. Use the [Auth0 management API](https://auth0.com/docs/api/management/v2/users/get-users). This endpoint has a rate limit, so you may need to export your users in several batches.

To export password hashes and MFA factors, contact Auth0 support.

### Step 2: Import your users into Supabase Auth [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/auth0\#step-2-import-your-users-into-supabase-auth)

The steps for importing your users depends on the login methods that you support.

See the following sections for how to import users with:

- [Password-based login](https://supabase.com/docs/guides/platform/migrating-to-supabase/auth0#password-based-methods)
- [Passwordless login](https://supabase.com/docs/guides/platform/migrating-to-supabase/auth0#passwordless-methods)
- [OAuth](https://supabase.com/docs/guides/platform/migrating-to-supabase/auth0#oauth)

#### Password-based methods [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/auth0\#password-based-methods)

For users who sign in with passwords, we recommend a hybrid approach to reduce downtime:

1. For new users, use Supabase Auth for sign up.
2. Migrate existing users in a one-off migration.

##### Sign up new users

Sign up new users using Supabase Auth's [signin methods](https://supabase.com/docs/guides/auth/passwords#signing-up-with-an-email-and-password).

##### Migrate existing users to Supabase Auth

Migrate existing users to Supabase Auth. This requires two main steps: first, check which users need to be migrated, then create their accounts using the Supabase admin endpoints.

1. Get your Auth 0 user export and password hash export lists.

2. Filter for users who use password login.
   - Under the `identities` field in the user object, these users will have `auth0` as a provider. In the same identity object, you can find their Auth0 `user_id`.
   - Check that the user has a corresponding password hash by comparing their Auth0 `user_id` to the `oid` field in the password hash export.
3. Use Supabase Auth's [admin create user](https://supabase.com/docs/reference/javascript/auth-admin-createuser) method to recreate the user in Supabase Auth. If the user has a confirmed email address or phone number, set `email_confirm` or `phone_confirm` to `true`.



`
const { data, error } = await supabase.auth.admin.createUser({
email: 'valid.email@supabase.io',
password_hash: '$2y$10$a9pghn27d7m0ltXvlX8LiOowy7XfFw0hW0G80OjKYQ1jaoejaA7NC',
email_confirm: true,
})
`





##### Supported password hashing algorithms





Supabase supports bcrypt and Argon2 password hashes.





If you have a plaintext password instead of a hash, you can provide that instead. Supabase Auth will handle hashing the password for you. (Passwords are **always** stored hashed.)



`
const { data, error } = await supabase.auth.admin.createUser({
email: 'valid.email@supabase.io',
password: 'supersecurepassword123!',
})
`

4. To sign in your migrated users, use the Supabase Auth [sign in methods](https://supabase.com/docs/reference/javascript/auth-signinwithpassword).

To check for edge cases where users aren't successfully migrated, use a fallback strategy. This ensures that users can continue to sign in seamlessly:
1. Try to sign in the user with Supabase Auth.
2. If the signin fails, try to sign in with Auth0.
3. If Auth0 signin succeeds, call the admin create user method again to create the user in Supabase Auth.

#### Passwordless methods [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/auth0\#passwordless-methods)

For passwordless signin via email or phone, check for users with verified email addresses or phone numbers. Create these users in Supabase Auth with `email_confirm` or `phone_confirm` set to `true`:

`
const { data, error } = await supabase.auth.admin.createUser({
email: 'valid.email@supabase.io',
email_confirm: true,
})
`

Check your Supabase Auth [email configuration](https://supabase.com/docs/guides/auth/auth-smtp) and configure your [email template](https://supabase.com/dashboard/project/_/auth/templates) for use with magic links. See the [Email templates guide](https://supabase.com/docs/guides/auth/auth-email-templates) to learn more.

Once you have imported your users, you can sign them in using the [`signInWithOtp`](https://supabase.com/docs/reference/javascript/auth-signinwithotp) method.

#### OAuth [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/auth0\#oauth)

Configure your OAuth providers in Supabase by following the [Social login guides](https://supabase.com/docs/guides/auth/social-login).

For both new and existing users, sign in the user using the [`signInWithOAuth`](https://supabase.com/docs/reference/javascript/auth-signinwithoauth) method. This works without pre-migrating existing users, since the user always needs to sign in through the OAuth provider before being redirected to your service.

After the user has completed the OAuth flow successfully, you can check if the user is a new or existing user in Auth0 by mapping their social provider id to Auth0. Auth0 stores the social provider ID in the user ID, which has the format `provider_name|provider_id` (for example, `github|123456`). See the [Auth0 identity docs](https://auth0.com/docs/manage-users/user-accounts/identify-users) to learn more.

## Mapping between Auth0 and Supabase Auth [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/auth0\#mapping-between-auth0-and-supabase-auth)

Each Auth provider has its own schema for tracking users and user information.

In Supabase Auth, your users are stored in your project's database under the `auth` schema. Every user has an identity (unless the user is an anonymous user), which represents the signin method they can use with Supabase. This is represented by the `auth.users` and `auth.identities` table.

See the [Users](https://supabase.com/docs/guides/auth/users) and [Identities](https://supabase.com/docs/guides/auth/identities) sections to learn more.

### Mapping user metadata and custom claims [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/auth0\#mapping-user-metadata-and-custom-claims)

Supabase Auth provides 2 fields which you can use to map user-specific metadata from Auth0:

- `auth.users.raw_user_meta_data` : For storing non-sensitive user metadata that the user can update (e.g full name, age, favorite color).
- `auth.users.raw_app_meta_data` : For storing non-sensitive user metadata that the user should not be able to update (e.g pricing plan, access control roles).

Both columns are accessible from the admin user methods. To create a user with custom metadata, you can use the following method:

`
const { data, error } = await supabase.auth.admin.createUser({
email: 'valid.email@supabase.io',
user_metadata: {
    full_name: 'Foo Bar',
},
app_metadata: {
    role: 'admin',
},
})
`

These fields will be exposed in the user's access token JWT so it is recommended not to store excessive metadata in these fields.

These fields are stored as columns in the `auth.users` table using the `jsonb` type. Both fields can be updated by using the admin [`updateUserById` method](https://supabase.com/docs/reference/javascript/auth-admin-updateuserbyid). If you want to allow the user to update their own `raw_user_meta_data` , you can use the [`updateUser` method](https://supabase.com/docs/reference/javascript/auth-updateuser).

If you have a lot of user-specific metadata to store, it is recommended to create your own table in a private schema that uses the user id as a foreign key:

`
create table private.user_metadata (
	id int generated always as identity,
	user_id uuid references auth.users(id) on delete cascade,
	user_metadata jsonb
);
`

## Frequently Asked Questions (FAQ) [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/auth0\#frequently-asked-questions-faq)

I have IDs assigned to existing users in my database, how can I maintain these IDs?

How can I allow my users to retain their existing password?

My users have multi-factor authentication (MFA) enabled, how do I make sure they don't have to set up MFA again?

How do I migrate existing SAML Single Sign-On (SSO) connections?

How do I migrate my Auth0 organizations to Supabase?

## Useful references [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/auth0\#useful-references)

- [Migrating 125k users from Auth0 to Supabase](https://kevcodez.medium.com/migrating-125-000-users-from-auth0-to-supabase-81c0568de307)
- [Loper to Supabase migration](https://eigen.sh/posts/auth-migration)

### Is this helpful?

NoYes

### On this page

[Before you begin](https://supabase.com/docs/guides/platform/migrating-to-supabase/auth0#before-you-begin) [Migration strategies](https://supabase.com/docs/guides/platform/migrating-to-supabase/auth0#migration-strategies) [Migration steps](https://supabase.com/docs/guides/platform/migrating-to-supabase/auth0#migration-steps) [Step 1: Export your user data](https://supabase.com/docs/guides/platform/migrating-to-supabase/auth0#step-1-export-your-user-data) [Step 2: Import your users into Supabase Auth](https://supabase.com/docs/guides/platform/migrating-to-supabase/auth0#step-2-import-your-users-into-supabase-auth) [Mapping between Auth0 and Supabase Auth](https://supabase.com/docs/guides/platform/migrating-to-supabase/auth0#mapping-between-auth0-and-supabase-auth) [Mapping user metadata and custom claims](https://supabase.com/docs/guides/platform/migrating-to-supabase/auth0#mapping-user-metadata-and-custom-claims) [Frequently Asked Questions (FAQ)](https://supabase.com/docs/guides/platform/migrating-to-supabase/auth0#frequently-asked-questions-faq) [Useful references](https://supabase.com/docs/guides/platform/migrating-to-supabase/auth0#useful-references)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_migrating_to_supabase_firebase_auth.md">
Platform

# Migrate from Firebase Auth to Supabase

## Migrate Firebase auth users to Supabase Auth.

* * *

Supabase provides several [tools](https://github.com/supabase-community/firebase-to-supabase/tree/main/auth) to help migrate auth users from a Firebase project to a Supabase project. There are two parts to the migration process:

- `firestoreusers2json` ( [TypeScript](https://github.com/supabase-community/firebase-to-supabase/blob/main/auth/firestoreusers2json.ts), [JavaScript](https://github.com/supabase-community/firebase-to-supabase/blob/main/auth/firestoreusers2json.js)) exports users from an existing Firebase project to a `.json` file on your local system.
- `import_users` ( [TypeScript](https://github.com/supabase-community/firebase-to-supabase/blob/main/auth/import_users.ts), [JavaScript](https://github.com/supabase-community/firebase-to-supabase/blob/main/auth/import_users.js)) imports users from a saved `.json` file into your Supabase project (inserting those users into the `auth.users` table of your `Postgres` database instance).

## Set up the migration tool [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-auth\#set-up-migration-tool)

1. Clone the [`firebase-to-supabase`](https://github.com/supabase-community/firebase-to-supabase) repository:



`
git clone https://github.com/supabase-community/firebase-to-supabase.git
`

2. In the `/auth` directory, create a file named `supabase-service.json` with the following contents:



`
{
"host": "database.server.com",
"password": "secretpassword",
"user": "postgres",
"database": "postgres",
"port": 5432
}
`

3. Go to the [Database settings](https://supabase.com/dashboard/project/_/settings/database) for your project in the Supabase Dashboard.

4. Under `Connection parameters`, enable `Use connection pooling` and set the mode to `Session`. Replace the `Host` and `User` fields with the values shown.

5. Enter the password you used when you created your Supabase project in the `password` entry in the `supabase-service.json` file.


## Generate a Firebase private key [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-auth\#generate-firebase-private-key)

1. Log in to your [Firebase Console](https://console.firebase.google.com/project) and open your project.
2. Click the gear icon next to **Project Overview** in the sidebar and select **Project Settings**.
3. Click **Service Accounts** and select **Firebase Admin SDK**.
4. Click **Generate new private key**.
5. Rename the downloaded file to `firebase-service.json`.

## Save your Firebase password hash parameters [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-auth\#save-firebase-hash-parameters)

1. Log in to your [Firebase Console](https://console.firebase.google.com/project) and open your project.
2. Select **Authentication** (Build section) in the sidebar.
3. Select **Users** in the top menu.
4. At the top right of the users list, open the menu (3 dots) and click **Password hash parameters**.
5. Copy and save the parameters for `base64_signer_key`, `base64_salt_separator`, `rounds`, and `mem_cost`.

Sample

`
hash_config {
algorithm: SCRYPT,
base64_signer_key: XXXX/XXX+XXXXXXXXXXXXXXXXX+XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX==,
base64_salt_separator: Aa==,
rounds: 8,
mem_cost: 14,
}
`

## Command line options [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-auth\#command-line-options)

### Dump Firestore users to a JSON file [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-auth\#dump-firestore-users)

`node firestoreusers2json.js [<filename.json>] [<batch_size>]`

- `filename.json`: (optional) output filename (defaults to `./users.json`)
- `batchSize`: (optional) number of users to fetch in each batch (defaults to 100)

### Import JSON users file to Supabase Auth (Postgres: `auth.users` [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-auth\#import-json-users-file)

`node import_users.js <path_to_json_file> [<batch_size>]`

- `path_to_json_file`: full local path and filename of JSON input file (of users)
- `batch_size`: (optional) number of users to process in a batch (defaults to 100)

## Notes [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-auth\#notes)

For more advanced migrations, including the use of a middleware server component for verifying a user's existing Firebase password and updating that password in your Supabase project the first time a user logs in, see the [`firebase-to-supabase` repo](https://github.com/supabase-community/firebase-to-supabase/tree/main/auth).

## Resources [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-auth\#resources)

- [Supabase vs Firebase](https://supabase.com/alternatives/supabase-vs-firebase)
- [Firestore Data Migration](https://supabase.com/docs/guides/migrations/firestore-data)
- [Firestore Storage Migration](https://supabase.com/docs/guides/migrations/firebase-storage)

## Enterprise [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-auth\#enterprise)

[Contact us](https://forms.supabase.com/enterprise) if you need more help migrating your project.

### Is this helpful?

NoYes

### On this page

[Set up the migration tool](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-auth#set-up-migration-tool) [Generate a Firebase private key](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-auth#generate-firebase-private-key) [Save your Firebase password hash parameters](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-auth#save-firebase-hash-parameters) [Command line options](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-auth#command-line-options) [Dump Firestore users to a JSON file](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-auth#dump-firestore-users) [Import JSON users file to Supabase Auth (Postgres: auth.users](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-auth#import-json-users-file) [Notes](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-auth#notes) [Resources](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-auth#resources) [Enterprise](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-auth#enterprise)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_migrating_to_supabase_firebase_storage.md">
Platform

# Migrated from Firebase Storage to Supabase

## Migrate Firebase Storage files to Supabase Storage.

* * *

Supabase provides several [tools](https://github.com/supabase-community/firebase-to-supabase/tree/main/storage) to convert storage files from Firebase Storage to Supabase Storage. Conversion is a two-step process:

1. Files are downloaded from a Firebase storage bucket to a local filesystem.
2. Files are uploaded from the local filesystem to a Supabase storage bucket.

## Set up the migration tool [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-storage\#set-up-migration-tool)

1. Clone the [`firebase-to-supabase`](https://github.com/supabase-community/firebase-to-supabase) repository:



`
git clone https://github.com/supabase-community/firebase-to-supabase.git
`

2. In the `/storage` directory, rename [supabase-keys-sample.js](https://github.com/supabase-community/firebase-to-supabase/blob/main/storage/supabase-keys-sample.js) to `supabase-keys.js`.

3. Go to your Supabase project's [API settings](https://supabase.com/dashboard/project/_/settings/api) in the Dashboard.

4. Copy the **Project URL** and update the `SUPABASE_URL` value in `supabase-keys.js`.

5. Under **Project API keys**, copy the **service\_role** key and update the `SUPABASE_KEY` value in `supabase-keys.js`.


## Generate a Firebase private key [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-storage\#generate-firebase-private-key)

1. Log in to your [Firebase Console](https://console.firebase.google.com/project) and open your project.
2. Click the gear icon next to **Project Overview** in the sidebar and select **Project Settings**.
3. Click **Service Accounts** and select **Firebase Admin SDK**.
4. Click **Generate new private key**.
5. Rename the downloaded file to `firebase-service.json`.

## Command line options [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-storage\#command-line-options)

### Download Firestore Storage bucket to a local filesystem folder [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-storage\#download-firestore-storage-bucket)

`node download.js <prefix> [<folder>] [<batchSize>] [<limit>] [<token>]`

- `<prefix>`: The prefix of the files to download. To process the root bucket, use an empty prefix: "".
- `<folder>`: (optional) Name of subfolder for downloaded files. The selected folder is created as a subfolder of the current folder (e.g., `./downloads/`). The default is `downloads`.
- `<batchSize>`: (optional) The default is 100.
- `<limit>`: (optional) Stop after processing this many files. For no limit, use `0`.
- `<token>`: (optional) Begin processing at this `pageToken`.

To process in batches using multiple command-line executions, you must use the same parameters with a new `<token>` on subsequent calls. Use the token displayed on the last call to continue the process at a given point.

### Upload files to Supabase Storage bucket [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-storage\#upload-to-supabase-storage-bucket)

`node upload.js <prefix> <folder> <bucket>`

- `<prefix>`: The prefix of the files to download. To process all files, use an empty prefix: "".
- `<folder>`: Name of subfolder of files to upload. The selected folder is read as a subfolder of the current folder (e.g., `./downloads/`). The default is `downloads`.
- `<bucket>`: Name of the bucket to upload to.

If the bucket doesn't exist, it's created as a `non-public` bucket. You must set permissions on this new bucket in the [Supabase Dashboard](https://supabase.com/dashboard/project/_/storage/buckets) before users can download any files.

## Resources [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-storage\#resources)

- [Supabase vs Firebase](https://supabase.com/alternatives/supabase-vs-firebase)
- [Firestore Data Migration](https://supabase.com/docs/guides/migrations/firestore-data)
- [Firebase Auth Migration](https://supabase.com/docs/guides/migrations/firebase-auth)

## Enterprise [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-storage\#enterprise)

[Contact us](https://forms.supabase.com/enterprise) if you need more help migrating your project.

### Is this helpful?

NoYes

### On this page

[Set up the migration tool](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-storage#set-up-migration-tool) [Generate a Firebase private key](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-storage#generate-firebase-private-key) [Command line options](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-storage#command-line-options) [Download Firestore Storage bucket to a local filesystem folder](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-storage#download-firestore-storage-bucket) [Upload files to Supabase Storage bucket](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-storage#upload-to-supabase-storage-bucket) [Resources](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-storage#resources) [Enterprise](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-storage#enterprise)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_migrating_to_supabase_firestore_data.md">
Platform

# Migrated from Firebase Firestore to Supabase

## Migrate your Firebase Firestore database to a Supabase Postgres database.

* * *

Supabase provides several [tools](https://github.com/supabase-community/firebase-to-supabase/tree/main/firestore) to convert data from a Firebase Firestore database to a Supabase Postgres database. The process copies the entire contents of a single Firestore `collection` to a single Postgres `table`.

The Firestore `collection` is "flattened" and converted to a table with basic columns of one of the following types: `text`, `numeric`, `boolean`, or `jsonb`. If your structure is more complex, you can write a program to split the newly-created `json` file into multiple, related tables before you import your `json` file(s) to Supabase.

## Set up the migration tool [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/firestore-data\#set-up-migration-tool)

1. Clone the [`firebase-to-supabase`](https://github.com/supabase-community/firebase-to-supabase) repository:



`
git clone https://github.com/supabase-community/firebase-to-supabase.git
`

2. In the `/firestore` directory, create a file named `supabase-service.json` with the following contents:



`
{
"host": "database.server.com",
"password": "secretpassword",
"user": "postgres",
"database": "postgres",
"port": 5432
}
`

3. Go to the [Database settings](https://supabase.com/dashboard/project/_/settings/database) for your project in the Supabase Dashboard.

4. Under `Connection parameters`, enable `Use connection pooling` and set the mode to `Session`. Replace the `Host` and `User` fields with the values shown.

5. Enter the password you used when you created your Supabase project in the `password` entry in the `supabase-service.json` file.


## Generate a Firebase private key [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/firestore-data\#generate-firebase-private-key)

1. Log in to your [Firebase Console](https://console.firebase.google.com/project) and open your project.
2. Click the gear icon next to **Project Overview** in the sidebar and select **Project Settings**.
3. Click **Service Accounts** and select **Firebase Admin SDK**.
4. Click **Generate new private key**.
5. Rename the downloaded file to `firebase-service.json`.

## Command line options [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/firestore-data\#command-line-options)

### List all Firestore collections [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/firestore-data\#list-all-firestore-collections)

`node collections.js`

### Dump Firestore collection to JSON file [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/firestore-data\#dump-firestore-collection-to-json-file)

`node firestore2json.js <collectionName> [<batchSize>] [<limit>]`

- `batchSize` (optional) defaults to 1000
- output filename is `<collectionName>.json`
- `limit` (optional) defaults to 0 (no limit)

#### Customize the JSON file with hooks [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/firestore-data\#customize-the-json-file-with-hooks)

You can customize the way your JSON file is written using a [custom hook](https://supabase.com/docs/guides/platform/migrating-to-supabase/firestore-data#custom-hooks). A common use for this is to "flatten" the JSON file, or to split nested data into separate, related database tables. For example, you could take a Firestore document that looks like this:

Firestore

`
[{ "user": "mark", "score": 100, "items": ["hammer", "nail", "glue"] }]
`

And split it into two files (one table for users and one table for items):

Users

`
[{ "user": "mark", "score": 100 }]
`

Items

`
[\
{ "user": "mark", "item": "hammer" },\
{ "user": "mark", "item": "nail" },\
{ "user": "mark", "item": "glue" }\
]
`

### Import JSON file to Supabase (Postgres) [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/firestore-data\#import-to-supabase)

`node json2supabase.js <path_to_json_file> [<primary_key_strategy>] [<primary_key_name>]`

- `<path_to_json_file>` The full path of the file you created in the previous step ( `Dump Firestore collection to JSON file `), such as `./my_collection.json`
- `[<primary_key_strategy>]` (optional) Is one of:
  - `none` (default) No primary key is added to the table.
  - `smallserial` Creates a key using `(id SMALLSERIAL PRIMARY KEY)` (autoincrementing 2-byte integer).
  - `serial` Creates a key using `(id SERIAL PRIMARY KEY)` (autoincrementing 4-byte integer).
  - `bigserial` Creates a key using `(id BIGSERIAL PRIMARY KEY)` (autoincrementing 8-byte integer).
  - `uuid` Creates a key using `(id UUID PRIMARY KEY DEFAULT gen_random_uuid())` (randomly generated UUID).
  - `firestore_id` Creates a key using `(id TEXT PRIMARY KEY)` (uses existing `firestore_id` random text as key).
- `[<primary_key_name>]` (optional) Name of primary key. Defaults to "id".

## Custom hooks [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/firestore-data\#custom-hooks)

Hooks are used to customize the process of exporting a collection of Firestore documents to JSON. They can be used for:

- Customizing or modifying keys
- Calculating data
- Flattening nested documents into related SQL tables

### Write a custom hook [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/firestore-data\#write-a-custom-hook)

#### Create a `.js` file for your collection [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/firestore-data\#create-a-js-file-for-your-collection)

If your Firestore collection is called `users`, create a file called `users.js` in the current folder.

#### Construct your `.js` file [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/firestore-data\#construct-your-js-file)

The basic format of a hook file looks like this:

`
module.exports = (collectionName, doc, recordCounters, writeRecord) => {
// modify the doc here
return doc
}
`

##### Parameters

- `collectionName`: The name of the collection you are processing.
- `doc`: The current document (JSON object) being processed.
- `recordCounters`: An internal object that keeps track of how many records have been processed in each collection.
- `writeRecord`: This function automatically handles the process of writing data to other JSON files (useful for "flatting" your document into separate JSON files to be written to separate database tables). `writeRecord` takes the following parameters:
  - `name`: Name of the JSON file to write to.
  - `doc`: The document to write to the file.
  - `recordCounters`: The same `recordCounters` object that was passed to this hook (just passes it on).

### Examples [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/firestore-data\#examples)

#### Add a new (unique) numeric key to a collection [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/firestore-data\#add-a-new-unique-numeric-key-to-a-collection)

`
module.exports = (collectionName, doc, recordCounters, writeRecord) => {
doc.unique_key = recordCounter[collectionName] + 1
return doc
}
`

#### Add a timestamp of when this record was dumped from Firestore [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/firestore-data\#add-a-timestamp-of-when-this-record-was-dumped-from-firestore)

`
module.exports = (collectionName, doc, recordCounters, writeRecord) => {
doc.dump_time = new Date().toISOString()
return doc
}
`

#### Flatten JSON into separate files [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/firestore-data\#flatten-json-into-separate-files)

Flatten the `users` collection into separate files:

`
[\
{\
    "uid": "abc123",\
    "name": "mark",\
    "score": 100,\
    "weapons": ["toothpick", "needle", "rock"]\
},\
{\
    "uid": "xyz789",\
    "name": "chuck",\
    "score": 9999999,\
    "weapons": ["hand", "foot", "head"]\
}\
]
`

The `users.js` hook file:

`
module.exports = (collectionName, doc, recordCounters, writeRecord) => {
for (let i = 0; i < doc.weapons.length; i++) {
    const weapon = {
      uid: doc.uid,
      weapon: doc.weapons[i],
    }
    writeRecord('weapons', weapon, recordCounters)
}
delete doc.weapons // moved to separate file
return doc
}
`

The result is two separate JSON files:

users.json

`
[\
{ "uid": "abc123", "name": "mark", "score": 100 },\
{ "uid": "xyz789", "name": "chuck", "score": 9999999 }\
]
`

weapons.json

`
[\
{ "uid": "abc123", "weapon": "toothpick" },\
{ "uid": "abc123", "weapon": "needle" },\
{ "uid": "abc123", "weapon": "rock" },\
{ "uid": "xyz789", "weapon": "hand" },\
{ "uid": "xyz789", "weapon": "foot" },\
{ "uid": "xyz789", "weapon": "head" }\
]
`

## Resources [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/firestore-data\#resources)

- [Supabase vs Firebase](https://supabase.com/alternatives/supabase-vs-firebase)
- [Firestore Storage Migration](https://supabase.com/docs/guides/migrations/firebase-storage)
- [Firebase Auth Migration](https://supabase.com/docs/guides/migrations/firebase-auth)

## Enterprise [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/firestore-data\#enterprise)

[Contact us](https://forms.supabase.com/enterprise) if you need more help migrating your project.

### Is this helpful?

NoYes

### On this page

[Set up the migration tool](https://supabase.com/docs/guides/platform/migrating-to-supabase/firestore-data#set-up-migration-tool) [Generate a Firebase private key](https://supabase.com/docs/guides/platform/migrating-to-supabase/firestore-data#generate-firebase-private-key) [Command line options](https://supabase.com/docs/guides/platform/migrating-to-supabase/firestore-data#command-line-options) [List all Firestore collections](https://supabase.com/docs/guides/platform/migrating-to-supabase/firestore-data#list-all-firestore-collections) [Dump Firestore collection to JSON file](https://supabase.com/docs/guides/platform/migrating-to-supabase/firestore-data#dump-firestore-collection-to-json-file) [Import JSON file to Supabase (Postgres)](https://supabase.com/docs/guides/platform/migrating-to-supabase/firestore-data#import-to-supabase) [Custom hooks](https://supabase.com/docs/guides/platform/migrating-to-supabase/firestore-data#custom-hooks) [Write a custom hook](https://supabase.com/docs/guides/platform/migrating-to-supabase/firestore-data#write-a-custom-hook) [Examples](https://supabase.com/docs/guides/platform/migrating-to-supabase/firestore-data#examples) [Resources](https://supabase.com/docs/guides/platform/migrating-to-supabase/firestore-data#resources) [Enterprise](https://supabase.com/docs/guides/platform/migrating-to-supabase/firestore-data#enterprise)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_migrating_to_supabase_heroku.md">
Platform

# Migrate from Heroku to Supabase

## Migrate your Heroku Postgres database to Supabase.

* * *

Supabase is one of the best [free alternatives to Heroku Postgres](https://supabase.com/alternatives/supabase-vs-heroku-postgres). This guide shows how to migrate your Heroku Postgres database to Supabase. This migration requires the [pg\_dump](https://www.postgresql.org/docs/current/app-pgdump.html) and [psql](https://www.postgresql.org/docs/current/app-psql.html) CLI tools, which are installed automatically as part of the complete Postgres installation package.

Alternatively, use the [Heroku to Supabase migration tool](https://migrate.supabase.com/) to migrate in just a few clicks.

## Quick demo [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/heroku\#quick-demo)

Migrate Your Heroku Database to Supabase - YouTube

Supabase

45.5K subscribers

[Migrate Your Heroku Database to Supabase](https://www.youtube.com/watch?v=xsRhPMphtZ4)

Supabase

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=xsRhPMphtZ4 "Watch on YouTube")

## Retrieve your Heroku database credentials [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/heroku\#retrieve-heroku-credentials)

1. Log in to your [Heroku account](https://heroku.com/) and select the project you want to migrate.
2. Click **Resources** in the menu and select your **Heroku Postgres** database.
3. Click **Settings** in the menu.
4. Click **View Credentials** and save the following information:
   - Host ( `$HEROKU_HOST`)
   - Database ( `$HEROKU_DATABASE`)
   - User ( `$HEROKU_USER`)
   - Password ( `$HEROKU_PASSWORD`)

## Retrieve your Supabase connection string [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/heroku\#retrieve-supabase-connection-string)

1. If you're new to Supabase, [create a project](https://supabase.com/dashboard).
2. Go to the [Database settings](https://supabase.com/dashboard/project/_/settings/database) for your project in the Supabase Dashboard.
3. Under **Connection string**, make sure `Use connection pooling` is enabled. Copy the URI and replace the password placeholder with your database password.

## Export your Heroku database to a file [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/heroku\#export-heroku-database)

Use `pg_dump` with your Heroku credentials to export your Heroku database to a file (e.g., `heroku_dump.sql`).

`
pg_dump --clean --if-exists --quote-all-identifiers \
 -h $HEROKU_HOST -U $HEROKU_USER -d $HEROKU_DATABASE \
 --no-owner --no-privileges > heroku_dump.sql
`

## Import the database to your Supabase project [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/heroku\#import-database-to-supabase)

Use `psql` to import the Heroku database file to your Supabase project.

`
psql -d "$YOUR_CONNECTION_STRING" -f heroku_dump.sql
`

## Additional options [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/heroku\#additional-options)

- To only migrate a single database schema, add the `--schema=PATTERN` parameter to your `pg_dump` command.
- To exclude a schema: `--exclude-schema=PATTERN`.
- To only migrate a single table: `--table=PATTERN`.
- To exclude a table: `--exclude-table=PATTERN`.

Run `pg_dump --help` for a full list of options.

- If you're planning to migrate a database larger than 6 GB, we recommend [upgrading to at least a Large compute add-on](https://supabase.com/docs/guides/platform/compute-add-ons). This will ensure you have the necessary resources to handle the migration efficiently.

- For databases smaller than 150 GB, you can increase the size of the disk on paid projects by navigating to [Database Settings](https://supabase.com/dashboard/project/_/settings/database).

- If you're dealing with a database larger than 150 GB, we strongly advise you to [contact our support team](https://supabase.com/dashboard/support/new) for assistance in provisioning the required resources and ensuring a smooth migration process.


## Enterprise [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/heroku\#enterprise)

[Contact us](https://forms.supabase.com/enterprise) if you need more help migrating your project.

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2FxsRhPMphtZ4%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Quick demo](https://supabase.com/docs/guides/platform/migrating-to-supabase/heroku#quick-demo) [Retrieve your Heroku database credentials](https://supabase.com/docs/guides/platform/migrating-to-supabase/heroku#retrieve-heroku-credentials) [Retrieve your Supabase connection string](https://supabase.com/docs/guides/platform/migrating-to-supabase/heroku#retrieve-supabase-connection-string) [Export your Heroku database to a file](https://supabase.com/docs/guides/platform/migrating-to-supabase/heroku#export-heroku-database) [Import the database to your Supabase project](https://supabase.com/docs/guides/platform/migrating-to-supabase/heroku#import-database-to-supabase) [Additional options](https://supabase.com/docs/guides/platform/migrating-to-supabase/heroku#additional-options) [Enterprise](https://supabase.com/docs/guides/platform/migrating-to-supabase/heroku#enterprise)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_migrating_to_supabase_mssql.md">
Platform

# Migrate from MSSQL to Supabase

## Migrate your Microsoft SQL Server database to Supabase.

* * *

This guide aims to demonstrate the process of transferring your Microsoft SQL Server database to Supabase's Postgres database. Supabase is a powerful and open-source platform offering a wide range of backend features, including a Postgres database, authentication, instant APIs, edge functions, real-time subscriptions, and storage. Migrating your MSSQL database to Supabase's Postgres enables you to leverage Postgres's capabilities and access all the features you need for your project.

## Retrieve your MSSQL database credentials [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/mssql\#retrieve-your-mssql-database-credentials)

Before you begin the migration, you need to collect essential information about your MSSQL database. Follow these steps:

1. Log in to your MSSQL database provider.
2. Locate and note the following database details:
   - Hostname or IP address
   - Database name
   - Username
   - Password

## Retrieve your Supabase host [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/mssql\#retrieve-supabase-host)

1. If you're new to Supabase, [create a project](https://supabase.com/dashboard).
Make a note of your password, you will need this later. If you forget it, you can [reset it here](https://supabase.com/dashboard/project/_/settings/database).

2. Go to the [Database settings](https://supabase.com/dashboard/project/_/settings/database) for your project in the Supabase Dashboard.

3. Under **Connection Info**, note your Host ( `$SUPABASE_HOST`).


![Finding Supabase host address](https://supabase.com/docs/img/guides/resources/migrating-to-supabase/mssql/database-settings-host.png)

## Migrate the database [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/mssql\#migrate-the-database)

The fastest way to migrate your database is with the Supabase migration tool on
[Google Colab](https://colab.research.google.com/github/mansueli/Supa-Migrate/blob/main/Amazon_RDS_to_Supabase.ipynb).

Alternatively, you can use [pgloader](https://github.com/dimitri/pgloader), a flexible and powerful data migration tool that supports a wide range of source database engines, including MySQL and MS SQL, and migrates the data to a Postgres database. For databases using the Postgres engine, we recommend using the [`pg_dump`](https://www.postgresql.org/docs/current/app-pgdump.html) and [psql](https://www.postgresql.org/docs/current/app-psql.html) command line tools, which are included in a full Postgres installation.

Migrate using ColabMigrate from MSSQL

1. Select the Database Engine from the Source database in the dropdown.
2. Set the environment variables ( `HOST`, `USER`, `SOURCE_DB`, `PASSWORD`, `SUPABASE_URL`, and `SUPABASE_PASSWORD`) in the Colab notebook.
3. Run the first two steps in [the notebook](https://colab.research.google.com/github/mansueli/Supa-Migrate/blob/main/Amazon_RDS_to_Supabase.ipynb) in order. The first sets engine and installs the necessary files.
4. Run the third step to start the migration. This will take a few minutes.

- If you're planning to migrate a database larger than 6 GB, we recommend [upgrading to at least a Large compute add-on](https://supabase.com/docs/guides/platform/compute-add-ons). This will ensure you have the necessary resources to handle the migration efficiently.

- For databases smaller than 150 GB, you can increase the size of the disk on paid projects by navigating to [Database Settings](https://supabase.com/dashboard/project/_/settings/database).

- If you're dealing with a database larger than 150 GB, we strongly advise you to [contact our support team](https://supabase.com/dashboard/support/new) for assistance in provisioning the required resources and ensuring a smooth migration process.


## Enterprise [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/mssql\#enterprise)

[Contact us](https://forms.supabase.com/enterprise) if you need more help migrating your project.

### Is this helpful?

NoYes

### On this page

[Retrieve your MSSQL database credentials](https://supabase.com/docs/guides/platform/migrating-to-supabase/mssql#retrieve-your-mssql-database-credentials) [Retrieve your Supabase host](https://supabase.com/docs/guides/platform/migrating-to-supabase/mssql#retrieve-supabase-host) [Migrate the database](https://supabase.com/docs/guides/platform/migrating-to-supabase/mssql#migrate-the-database) [Enterprise](https://supabase.com/docs/guides/platform/migrating-to-supabase/mssql#enterprise)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_migrating_to_supabase_mysql.md">
Platform

# Migrate from MySQL to Supabase

## Migrate your MySQL database to Supabase Postgres database.

* * *

This guide aims to exhibit the process of transferring your MySQL database to Supabase's Postgres database. Supabase is a robust and open-source platform offering a wide range of backend features, including a Postgres database, authentication, instant APIs, edge functions, real-time subscriptions, and storage. Migrating your MySQL database to Supabase's Postgres enables you to leverage PostgreSQL's capabilities and access all the features you need for your project.

## Retrieve your MySQL database credentials [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/mysql\#retrieve-your-mysql-database-credentials)

Before you begin the migration, you need to collect essential information about your MySQL database. Follow these steps:

1. Log in to your MySQL database provider.

2. Locate and note the following database details:
   - Hostname or IP address
   - Database name
   - Username
   - Password

## Retrieve your Supabase host [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/mysql\#retrieve-supabase-host)

1. If you're new to Supabase, [create a project](https://supabase.com/dashboard).
Make a note of your password, you will need this later. If you forget it, you can [reset it here](https://supabase.com/dashboard/project/_/settings/database).

2. Go to the [Database settings](https://supabase.com/dashboard/project/_/settings/database) for your project in the Supabase Dashboard.

3. Under **Connection Info**, note your Host ( `$SUPABASE_HOST`).


![Finding Supabase host address](https://supabase.com/docs/img/guides/resources/migrating-to-supabase/mysql/database-settings-host.png)

## Migrate the database [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/mysql\#migrate-the-database)

The fastest way to migrate your database is with the Supabase migration tool on
[Google Colab](https://colab.research.google.com/github/mansueli/Supa-Migrate/blob/main/Amazon_RDS_to_Supabase.ipynb).

Alternatively, you can use [pgloader](https://github.com/dimitri/pgloader), a flexible and powerful data migration tool that supports a wide range of source database engines, including MySQL and MS SQL, and migrates the data to a Postgres database. For databases using the Postgres engine, we recommend using the [`pg_dump`](https://www.postgresql.org/docs/current/app-pgdump.html) and [psql](https://www.postgresql.org/docs/current/app-psql.html) command line tools, which are included in a full Postgres installation.

Migrate using ColabMigrate from MySQL with pgloader

1. Select the Database Engine from the Source database in the dropdown
2. Set the environment variables ( `HOST`, `USER`, `SOURCE_DB`, `PASSWORD`, `SUPABASE_URL`, and `SUPABASE_PASSWORD`) in the Colab notebook.
3. Run the first two steps in [the notebook](https://colab.research.google.com/github/mansueli/Supa-Migrate/blob/main/Amazon_RDS_to_Supabase.ipynb) in order. The first sets engine and installs the necessary files.
4. Run the third step to start the migration. This will take a few minutes.

- If you're planning to migrate a database larger than 6 GB, we recommend [upgrading to at least a Large compute add-on](https://supabase.com/docs/guides/platform/compute-add-ons). This will ensure you have the necessary resources to handle the migration efficiently.

- For databases smaller than 150 GB, you can increase the size of the disk on paid projects by navigating to [Database Settings](https://supabase.com/dashboard/project/_/settings/database).

- If you're dealing with a database larger than 150 GB, we strongly advise you to [contact our support team](https://supabase.com/dashboard/support/new) for assistance in provisioning the required resources and ensuring a smooth migration process.


## Enterprise [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/mysql\#enterprise)

[Contact us](https://forms.supabase.com/enterprise) if you need more help migrating your project.

### Is this helpful?

NoYes

### On this page

[Retrieve your MySQL database credentials](https://supabase.com/docs/guides/platform/migrating-to-supabase/mysql#retrieve-your-mysql-database-credentials) [Retrieve your Supabase host](https://supabase.com/docs/guides/platform/migrating-to-supabase/mysql#retrieve-supabase-host) [Migrate the database](https://supabase.com/docs/guides/platform/migrating-to-supabase/mysql#migrate-the-database) [Enterprise](https://supabase.com/docs/guides/platform/migrating-to-supabase/mysql#enterprise)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_migrating_to_supabase_neon.md">
Platform

# Migrate from Neon to Supabase

## Migrate your existing Neon database to Supabase.

* * *

This guide demonstrates how to migrate your Neon database to Supabase to get the most out of Postgres while gaining access to all the features you need to build a project.

## Retrieve your Neon database credentials [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/neon\#retrieve-credentials)

1. Log in to your Neon Console [https://console.neon.tech/login](https://console.neon.tech/login).
2. Select **Projects** on the left.
3. Click on your project in the list.
4. From your Project Dashboard find your **Connection string** and click **Copy snippet** to copy it to the clipboard (do not check "pooled connection").

Example:

`
postgresql://neondb_owner:xxxxxxxxxxxxxxx-random-word-yyyyyyyy.us-west-2.aws.neon.tech/neondb?sslmode=require
`

## Set your `OLD_DB_URL` environment variable [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/neon\#set-your-olddburl-environment-variable)

Set the **OLD\_DB\_URL** environment variable at the command line using your Neon database credentials from the clipboard.

Example:

`
export OLD_DB_URL="postgresql://neondb_owner:xxxxxxxxxxxxxxx-random-word-yyyyyyyy.us-west-2.aws.neon.tech/neondb?sslmode=require"
`

## Retrieve your Supabase connection string [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/neon\#retrieve-supabase-connection-string)

1. If you're new to Supabase, [create a project](https://supabase.com/dashboard).
Make a note of your password, you will need this later. If you forget it, you can [reset it here](https://supabase.com/dashboard/project/_/settings/database).

2. Go to the [Database settings](https://supabase.com/dashboard/project/_/settings/database) for your project in the Supabase Dashboard.

3. Under **Connection string**, select **URI**, make sure **Display connection pooler** is checked, and **Mode: Session** is set.

4. Click the **Copy** button to the right of your connection string to copy it to the clipboard.


## Set your `NEW_DB_URL` environment variable [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/neon\#set-your-newdburl-environment-variable)

Set the **NEW\_DB\_URL** environment variable at the command line using your Supabase connection string. You will need to replace `[YOUR-PASSWORD]` with your actual database password.

Example:

`
export NEW_DB_URL="postgresql://postgres.xxxxxxxxxxxxxxxxxxxx:[YOUR-PASSWORD]@aws-0-us-west-1.pooler.supabase.com:5432/postgres"
`

## Migrate the database [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/neon\#migrate-the-database)

You will need the [pg\_dump](https://www.postgresql.org/docs/current/app-pgdump.html) and [psql](https://www.postgresql.org/docs/current/app-psql.html) command line tools, which are included in a full [Postgres installation](https://www.postgresql.org/download).

1. Export your database to a file in console

Use `pg_dump` with your Postgres credentials to export your database to a file (e.g., `dump.sql`).


`
pg_dump "$OLD_DB_URL" \
  --clean \
  --if-exists \
  --quote-all-identifiers \
  --no-owner \
  --no-privileges \
> dump.sql
`

2. Import the database to your Supabase project

Use `psql` to import the Postgres database file to your Supabase project.



`
psql -d "$NEW_DB_URL" -f dump.sql
`


Additional options

- To only migrate a single database schema, add the `--schema=PATTERN` parameter to your `pg_dump` command.
- To exclude a schema: `--exclude-schema=PATTERN`.
- To only migrate a single table: `--table=PATTERN`.
- To exclude a table: `--exclude-table=PATTERN`.

Run `pg_dump --help` for a full list of options.

- If you're planning to migrate a database larger than 6 GB, we recommend [upgrading to at least a Large compute add-on](https://supabase.com/docs/guides/platform/compute-add-ons). This will ensure you have the necessary resources to handle the migration efficiently.

- For databases smaller than 150 GB, you can increase the size of the disk on paid projects by navigating to [Database Settings](https://supabase.com/dashboard/project/_/settings/database).

- If you're dealing with a database larger than 150 GB, we strongly advise you to [contact our support team](https://supabase.com/dashboard/support/new) for assistance in provisioning the required resources and ensuring a smooth migration process.


## Enterprise [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/neon\#enterprise)

[Contact us](https://forms.supabase.com/enterprise) if you need more help migrating your project.

### Is this helpful?

NoYes

### On this page

[Retrieve your Neon database credentials](https://supabase.com/docs/guides/platform/migrating-to-supabase/neon#retrieve-credentials) [Set your OLD\_DB\_URL environment variable](https://supabase.com/docs/guides/platform/migrating-to-supabase/neon#set-your-olddburl-environment-variable) [Retrieve your Supabase connection string](https://supabase.com/docs/guides/platform/migrating-to-supabase/neon#retrieve-supabase-connection-string) [Set your NEW\_DB\_URL environment variable](https://supabase.com/docs/guides/platform/migrating-to-supabase/neon#set-your-newdburl-environment-variable) [Migrate the database](https://supabase.com/docs/guides/platform/migrating-to-supabase/neon#migrate-the-database) [Enterprise](https://supabase.com/docs/guides/platform/migrating-to-supabase/neon#enterprise)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_migrating_to_supabase_postgres.md">
Platform

# Migrate from Postgres to Supabase

## Migrate your existing Postgres database to Supabase.

* * *

This is a guide for migrating your Postgres database to [Supabase](https://supabase.com/).
Supabase is a robust and open-source platform. Supabase provide all the backend features developers need to build a product: a Postgres database, authentication, instant APIs, edge functions, realtime subscriptions, and storage. Postgres is the core of Supabasefor example, you can use row-level security and there are more than 40 Postgres extensions available.

This guide demonstrates how to migrate your Postgres database to Supabase to get the most out of Postgres while gaining access to all the features you need to build a project.

## Retrieve your Postgres database credentials [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/postgres\#retrieve-credentials)

1. Log in to your provider to get the connection details for your Postgres database.
2. Click on **PSQL Command** and edit it adding the content after `PSQL_COMMAND=`.

Example:

`
%env PSQL_COMMAND=PGPASSWORD=RgaMDfTS_password_FTPa7 psql -h dpg-a_server_in.oregon-postgres.provider.com -U my_db_pxl0_user my_db_pxl0
`

## Retrieve your Supabase connection string [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/postgres\#retrieve-supabase-connection-string)

1. If you're new to Supabase, [create a project](https://supabase.com/dashboard).
Make a note of your password, you will need this later. If you forget it, you can [reset it here](https://supabase.com/dashboard/project/_/settings/database).

2. Go to the [Database settings](https://supabase.com/dashboard/project/_/settings/database) for your project in the Supabase Dashboard.

3. Under **Connection string**, make sure `Use connection pooling` is enabled. Copy the URI and replace the password placeholder with your database password.


![Finding Supabase host address](https://supabase.com/docs/img/guides/resources/migrating-to-supabase/postgres/database-settings-host.png)

## Migrate the database [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/postgres\#migrate-the-database)

The fastest way to migrate your database is with the Supabase migration tool on [Google Colab](https://colab.research.google.com/github/mansueli/Supa-Migrate/blob/main/Migrate_Postgres_Supabase.ipynb). Alternatively, you can use the [pg\_dump](https://www.postgresql.org/docs/current/app-pgdump.html) and [psql](https://www.postgresql.org/docs/current/app-psql.html) command line tools, which are included in a full Postgres installation.

Migrate using ColabMigrate using CLI tools

1. Set the environment variables ( `PSQL_COMMAND`, `SUPABASE_HOST`, `SUPABASE_PASSWORD`) in the Colab notebook.
2. Run the first two steps in [the notebook](https://colab.research.google.com/github/mansueli/Supa-Migrate/blob/main/Migrate_Postgres_Supabase.ipynb) in order. The first sets the variables and the second installs PSQL and the migration script.
3. Run the third step to start the migration. This will take a few minutes.

- If you're planning to migrate a database larger than 6 GB, we recommend [upgrading to at least a Large compute add-on](https://supabase.com/docs/guides/platform/compute-add-ons). This will ensure you have the necessary resources to handle the migration efficiently.

- For databases smaller than 150 GB, you can increase the size of the disk on paid projects by navigating to [Database Settings](https://supabase.com/dashboard/project/_/settings/database).

- If you're dealing with a database larger than 150 GB, we strongly advise you to [contact our support team](https://supabase.com/dashboard/support/new) for assistance in provisioning the required resources and ensuring a smooth migration process.


## Enterprise [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/postgres\#enterprise)

[Contact us](https://forms.supabase.com/enterprise) if you need more help migrating your project.

### Is this helpful?

NoYes

### On this page

[Retrieve your Postgres database credentials](https://supabase.com/docs/guides/platform/migrating-to-supabase/postgres#retrieve-credentials) [Retrieve your Supabase connection string](https://supabase.com/docs/guides/platform/migrating-to-supabase/postgres#retrieve-supabase-connection-string) [Migrate the database](https://supabase.com/docs/guides/platform/migrating-to-supabase/postgres#migrate-the-database) [Enterprise](https://supabase.com/docs/guides/platform/migrating-to-supabase/postgres#enterprise)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_migrating_to_supabase_render.md">
Platform

# Migrate from Render to Supabase

## Migrate your Render Postgres database to Supabase.

* * *

Render is a popular Web Hosting service in the online services category that also has a managed Postgres service. Render has a great developer experience, allowing users to deploy straight from GitHub or GitLab. This is the core of their product and they do it really well. However, when it comes to Postgres databases, it may not be the best option.

Supabase is one of the best free alternative to Render Postgres. Supabase provide all the backend features developers need to build a product: a Postgres database, authentication, instant APIs, edge functions, realtime subscriptions, and storage. Postgres is the core of Supabasefor example, you can use row-level security and there are more than 40 Postgres extensions available.

This guide demonstrates how to migrate from Render to Supabase to get the most out of Postgres while gaining access to all the features you need to build a project.

## Retrieve your Render database credentials [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/render\#retrieve-render-credentials)

1. Log in to your [Render account](https://render.com/) and select the project you want to migrate.
2. Click **Dashboard** in the menu and click in your **Postgres** database.
3. Scroll down in the **Info** tab.
4. Click on **PSQL Command** and edit it adding the content after `PSQL_COMMAND=`.

![Copying PSQL command from Render dashboard](https://supabase.com/docs/img/guides/resources/migrating-to-supabase/render/render_dashboard.png)
Example:

`
%env PSQL_COMMAND=PGPASSWORD=RgaMDfTS_password_FTPa7 psql -h dpg-a_server_in.oregon-postgres.render.com -U my_db_pxl0_user my_db_pxl0
`

## Retrieve your Supabase connection string [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/render\#retrieve-supabase-connection-string)

1. If you're new to Supabase, [create a project](https://supabase.com/dashboard).
Make a note of your password, you will need this later. If you forget it, you can [reset it here](https://supabase.com/dashboard/project/_/settings/database).

2. Go to the [Database settings](https://supabase.com/dashboard/project/_/settings/database) for your project in the Supabase Dashboard.

3. Under **Connection string**, make sure `Use connection pooling` is enabled. Copy the URI and replace the password placeholder with your database password.


## Migrate the database [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/render\#migrate-the-database)

The fastest way to migrate your database is with the Supabase migration tool on [Google Colab](https://colab.research.google.com/github/mansueli/Supa-Migrate/blob/main/Migrate_Postgres_Supabase.ipynb). Alternatively, you can use the [pg\_dump](https://www.postgresql.org/docs/current/app-pgdump.html) and [psql](https://www.postgresql.org/docs/current/app-psql.html) command line tools, which are included in a full Postgres installation.

Migrate using ColabMigrate using CLI tools

1. Set the environment variables ( `PSQL_COMMAND`, `SUPABASE_HOST`, `SUPABASE_PASSWORD`) in the Colab notebook.
2. Run the first two steps in [the notebook](https://colab.research.google.com/github/mansueli/Supa-Migrate/blob/main/Migrate_Postgres_Supabase.ipynb) in order. The first sets the variables and the second installs PSQL and the migration script.
3. Run the third step to start the migration. This will take a few minutes.

- If you're planning to migrate a database larger than 6 GB, we recommend [upgrading to at least a Large compute add-on](https://supabase.com/docs/guides/platform/compute-add-ons). This will ensure you have the necessary resources to handle the migration efficiently.

- For databases smaller than 150 GB, you can increase the size of the disk on paid projects by navigating to [Database Settings](https://supabase.com/dashboard/project/_/settings/database).

- If you're dealing with a database larger than 150 GB, we strongly advise you to [contact our support team](https://supabase.com/dashboard/support/new) for assistance in provisioning the required resources and ensuring a smooth migration process.


## Enterprise [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/render\#enterprise)

[Contact us](https://forms.supabase.com/enterprise) if you need more help migrating your project.

### Is this helpful?

NoYes

### On this page

[Retrieve your Render database credentials](https://supabase.com/docs/guides/platform/migrating-to-supabase/render#retrieve-render-credentials) [Retrieve your Supabase connection string](https://supabase.com/docs/guides/platform/migrating-to-supabase/render#retrieve-supabase-connection-string) [Migrate the database](https://supabase.com/docs/guides/platform/migrating-to-supabase/render#migrate-the-database) [Enterprise](https://supabase.com/docs/guides/platform/migrating-to-supabase/render#enterprise)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_migrating_to_supabase_vercel_postgres.md">
Platform

# Migrate from Vercel Postgres to Supabase

## Migrate your existing Vercel Postgres database to Supabase.

* * *

This guide demonstrates how to migrate your Vercel Postgres database to Supabase to get the most out of Postgres while gaining access to all the features you need to build a project.

## Retrieve your Vercel Postgres database credentials [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/vercel-postgres\#retrieve-credentials)

1. Log in to your Vercel Dashboard [https://vercel.com/login](https://vercel.com/login).
2. Click on the **Storage** tab.
3. Click on your Postgres Database.
4. Under the **Quickstart** section, select **psql** then click **Show Secret** to reveal your database password.
5. Copy the string after `psql ` to the clipboard.

Example:

`
psql "postgres://default:xxxxxxxxxxxx@yy-yyyyy-yyyyyy-yyyyyyy.us-west-2.aws.neon.tech:5432/verceldb?sslmode=require"
`

Copy this part to your clipboard:

`
"postgres://default:xxxxxxxxxxxx@yy-yyyyy-yyyyyy-yyyyyyy.us-west-2.aws.neon.tech:5432/verceldb?sslmode=require"
`

## Set your `OLD_DB_URL` environment variable [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/vercel-postgres\#set-your-olddburl-environment-variable)

Set the **OLD\_DB\_URL** environment variable at the command line using your Vercel Postgres Database credentials.

Example:

`
export OLD_DB_URL="postgres://default:xxxxxxxxxxxx@yy-yyyyy-yyyyyy-yyyyyyy.us-west-2.aws.neon.tech:5432/verceldb?sslmode=require"
`

## Retrieve your Supabase connection string [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/vercel-postgres\#retrieve-supabase-connection-string)

1. If you're new to Supabase, [create a project](https://supabase.com/dashboard).
Make a note of your password, you will need this later. If you forget it, you can [reset it here](https://supabase.com/dashboard/project/_/settings/database).

2. Go to the [Database settings](https://supabase.com/dashboard/project/_/settings/database) for your project in the Supabase Dashboard.

3. Under **Connection string**, select **URI**, make sure **Display connection pooler** is checked, and **Mode: Session** is set.

4. Click the **Copy** button to the right of your connection string to copy it to the clipboard.


## Set your `NEW_DB_URL` environment variable [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/vercel-postgres\#set-your-newdburl-environment-variable)

Set the **NEW\_DB\_URL** environment variable at the command line using your Supabase connection string. You will need to replace `[YOUR-PASSWORD]` with your actual database password.

Example:

`
export NEW_DB_URL="postgresql://postgres.xxxxxxxxxxxxxxxxxxxx:[YOUR-PASSWORD]@aws-0-us-west-1.pooler.supabase.com:5432/postgres"
`

## Migrate the database [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/vercel-postgres\#migrate-the-database)

You will need the [pg\_dump](https://www.postgresql.org/docs/current/app-pgdump.html) and [psql](https://www.postgresql.org/docs/current/app-psql.html) command line tools, which are included in a full [Postgres installation](https://www.postgresql.org/download).

1. Export your database to a file in console

Use `pg_dump` with your Postgres credentials to export your database to a file (e.g., `dump.sql`).


`
pg_dump "$OLD_DB_URL" \
  --clean \
  --if-exists \
  --quote-all-identifiers \
  --no-owner \
  --no-privileges \
> dump.sql
`

2. Import the database to your Supabase project

Use `psql` to import the Postgres database file to your Supabase project.



`
psql -d "$NEW_DB_URL" -f dump.sql
`


Additional options

- To only migrate a single database schema, add the `--schema=PATTERN` parameter to your `pg_dump` command.
- To exclude a schema: `--exclude-schema=PATTERN`.
- To only migrate a single table: `--table=PATTERN`.
- To exclude a table: `--exclude-table=PATTERN`.

Run `pg_dump --help` for a full list of options.

- If you're planning to migrate a database larger than 6 GB, we recommend [upgrading to at least a Large compute add-on](https://supabase.com/docs/guides/platform/compute-add-ons). This will ensure you have the necessary resources to handle the migration efficiently.

- For databases smaller than 150 GB, you can increase the size of the disk on paid projects by navigating to [Database Settings](https://supabase.com/dashboard/project/_/settings/database).

- If you're dealing with a database larger than 150 GB, we strongly advise you to [contact our support team](https://supabase.com/dashboard/support/new) for assistance in provisioning the required resources and ensuring a smooth migration process.


## Enterprise [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase/vercel-postgres\#enterprise)

[Contact us](https://forms.supabase.com/enterprise) if you need more help migrating your project.

### Is this helpful?

NoYes

### On this page

[Retrieve your Vercel Postgres database credentials](https://supabase.com/docs/guides/platform/migrating-to-supabase/vercel-postgres#retrieve-credentials) [Set your OLD\_DB\_URL environment variable](https://supabase.com/docs/guides/platform/migrating-to-supabase/vercel-postgres#set-your-olddburl-environment-variable) [Retrieve your Supabase connection string](https://supabase.com/docs/guides/platform/migrating-to-supabase/vercel-postgres#retrieve-supabase-connection-string) [Set your NEW\_DB\_URL environment variable](https://supabase.com/docs/guides/platform/migrating-to-supabase/vercel-postgres#set-your-newdburl-environment-variable) [Migrate the database](https://supabase.com/docs/guides/platform/migrating-to-supabase/vercel-postgres#migrate-the-database) [Enterprise](https://supabase.com/docs/guides/platform/migrating-to-supabase/vercel-postgres#enterprise)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_migrating_to_supabase.md">
Platform

# Migrating to Supabase

* * *

Learn how to migrate to Supabase from another database service.

## Migration guides [\#](https://supabase.com/docs/guides/platform/migrating-to-supabase\#migration-guides)

[![Auth0](https://supabase.com/docs/img/icons/auth0-icon-light.svg)\\
\\
Auth0](https://supabase.com/docs/guides/platform/migrating-to-supabase/auth0) [![Firebase Auth](https://supabase.com/docs/img/icons/firebase-icon.svg)\\
\\
Firebase Auth](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-auth) [![Firestore Data](https://supabase.com/docs/img/icons/firebase-icon.svg)\\
\\
Firestore Data](https://supabase.com/docs/guides/platform/migrating-to-supabase/firestore-data) [![Firebase Storage](https://supabase.com/docs/img/icons/firebase-icon.svg)\\
\\
Firebase Storage](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-storage) [![Heroku](https://supabase.com/docs/img/icons/heroku-icon.svg)\\
\\
Heroku](https://supabase.com/docs/guides/platform/migrating-to-supabase/heroku) [![Render](https://supabase.com/docs/img/icons/render-icon.svg)\\
\\
Render](https://supabase.com/docs/guides/platform/migrating-to-supabase/render) [![Amazon RDS](https://supabase.com/docs/img/icons/aws-rds-icon.svg)\\
\\
Amazon RDS](https://supabase.com/docs/guides/platform/migrating-to-supabase/amazon-rds) [![Postgres](https://supabase.com/docs/img/icons/postgres-icon.svg)\\
\\
Postgres](https://supabase.com/docs/guides/platform/migrating-to-supabase/postgres) [![Vercel Postgres](https://supabase.com/docs/img/icons/vercel-icon-light.svg)\\
\\
Vercel Postgres](https://supabase.com/docs/guides/platform/migrating-to-supabase/vercel-postgres) [![Neon](https://supabase.com/docs/img/icons/neon-icon-light.svg)\\
\\
Neon](https://supabase.com/docs/guides/platform/migrating-to-supabase/neon) [![MySQL](https://supabase.com/docs/img/icons/mysql-icon.svg)\\
\\
MySQL](https://supabase.com/docs/guides/platform/migrating-to-supabase/mysql) [![MSSQL](https://supabase.com/docs/img/icons/mssql-icon.svg)\\
\\
MSSQL](https://supabase.com/docs/guides/platform/migrating-to-supabase/mssql)

### Is this helpful?

NoYes

### On this page

[Migration guides](https://supabase.com/docs/guides/platform/migrating-to-supabase#migration-guides)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_migrating_within_supabase_backup_restore.md">
Platform

# Backup and Restore using the CLI

## Learn how to backup and restore projects using the Supabase CLI

* * *

## Backup database using the CLI [\#](https://supabase.com/docs/guides/platform/migrating-within-supabase/backup-restore\#backup-database-using-the-cli)

1

### Install the Supabase CLI

Install the [Supabase CLI](https://supabase.com/docs/guides/local-development/cli/getting-started).

2

### Install Docker Desktop

Install [Docker Desktop](https://www.docker.com/) for your platform.

3

### Get the new database connection string

Go to the [project page](https://supabase.com/dashboard/project/_/) and click the " **Connect**" button at the top of the page for the connection string.

Use the Session pooler connection string by default. If your ISP supports IPv6, use the direct connection string.

Session pooler connection string:

`
postgresql://postgres.[PROJECT-REF]:[YOUR-PASSWORD]@aws-0-us-east-1.pooler.supabase.com:5432/postgres
`

Direct connection string:

`
postgresql://postgres.[PROJECT-REF]:[YOUR-PASSWORD]@db.[PROJECT-REF].supabase.com:5432/postgres
`

4

### Get the database password

Reset the password in the [Database Settings](https://supabase.com/dashboard/project/_/settings/database).

Replace `[YOUR-PASSWORD]` in the connection string with the database password.

5

### Backup database

Run these commands after replacing `[CONNECTION_STRING]` with your connection string from the previous steps:

`
supabase db dump --db-url [CONNECTION_STRING] -f roles.sql --role-only
`

`
supabase db dump --db-url [CONNECTION_STRING] -f schema.sql
`

`
supabase db dump --db-url [CONNECTION_STRING] -f data.sql --use-copy --data-only
`

## Before you begin [\#](https://supabase.com/docs/guides/platform/migrating-within-supabase/backup-restore\#before-you-begin)

Install Postgres and psql

## Restore backup using CLI [\#](https://supabase.com/docs/guides/platform/migrating-within-supabase/backup-restore\#restore-backup-using-cli)

1

### Create project

Create a [new project](https://database.new/)

2

### Configure newly created project

In the new project:

- If Webhooks were used in the old database, enable [Database Webhooks](https://supabase.com/dashboard/project/_/database/hooks).
- If any non-default extensions were used in the old database, enable the [Extensions](https://supabase.com/dashboard/project/_/database/extensions).
- If Replication for Realtime was used in the old database, enable [Publication](https://supabase.com/dashboard/project/_/database/publications) on the tables necessary

3

### Get the new database connection string

Go to the [project page](https://supabase.com/dashboard/project/_/) and click the " **Connect**" button at the top of the page for the connection string.

Use the Session pooler connection string by default. If your ISP supports IPv6, use the direct connection string.

Session pooler connection string:

`
postgresql://postgres.[PROJECT-REF]:[YOUR-PASSWORD]@aws-0-us-east-1.pooler.supabase.com:5432/postgres
`

Direct connection string:

`
postgresql://postgres.[PROJECT-REF]:[YOUR-PASSWORD]@db.[PROJECT-REF].supabase.com:5432/postgres
`

4

### Get the database password

Reset the password in the [Database Settings](https://supabase.com/dashboard/project/_/settings/database).

Replace `[YOUR-PASSWORD]` in the connection string with the database password.

5

### Restore your Project with the CLI

Column encryption disabledColumn encryption enabled

Run these commands after replacing `[CONNECTION_STRING]` with your connection string from the previous steps:

`
psql \
  --single-transaction \
  --variable ON_ERROR_STOP=1 \
  --file roles.sql \
  --file schema.sql \
  --command 'SET session_replication_role = replica' \
  --file data.sql \
  --dbname [CONNECTION_STRING]
`

## Important project restoration notes [\#](https://supabase.com/docs/guides/platform/migrating-within-supabase/backup-restore\#important-project-restoration-notes)

### Troubleshooting notes [\#](https://supabase.com/docs/guides/platform/migrating-within-supabase/backup-restore\#troubleshooting-notes)

- Setting the `session_replication_role` to `replica` disables all triggers so that columns are not double encrypted.
- If you have created any [custom roles](https://supabase.com/dashboard/project/_/database/roles) with `login` attribute, you have to manually set their passwords in the new project.
- If you run into any permission errors related to `supabase_admin` during restore, edit the `schema.sql` file and comment out any lines containing `ALTER ... OWNER TO "supabase_admin"`.

### Preserving migration history [\#](https://supabase.com/docs/guides/platform/migrating-within-supabase/backup-restore\#preserving-migration-history)

If you were using Supabase CLI for managing migrations on your old database and would like to preserve the migration history in your newly restored project, you need to insert the migration records separately using the following commands.

`
supabase db dump --db-url "$OLD_DB_URL" -f history_schema.sql --schema supabase_migrations
supabase db dump --db-url "$OLD_DB_URL" -f history_data.sql --use-copy --data-only --schema supabase_migrations
psql \
  --single-transaction \
  --variable ON_ERROR_STOP=1 \
  --file history_schema.sql \
  --file history_data.sql \
  --dbname "$NEW_DB_URL"
`

### Schema changes to `auth` and `storage` [\#](https://supabase.com/docs/guides/platform/migrating-within-supabase/backup-restore\#schema-changes-to-auth-and-storage)

If you have modified the `auth` and `storage` schemas in your old project, such as adding triggers or Row Level Security(RLS) policies, you have to restore them separately. The Supabase CLI can help you diff the changes to these schemas using the following commands.

`
supabase link --project-ref "$OLD_PROJECT_REF"
supabase db diff --linked --schema auth,storage > changes.sql
`

### Migrate storage objects [\#](https://supabase.com/docs/guides/platform/migrating-within-supabase/backup-restore\#migrate-storage-objects)

The new project has the old project's Storage buckets, but the Storage objects need to be migrated manually. Use this script to move storage objects from one project to another.

``
// npm install @supabase/supabase-js@1
const { createClient } = require('@supabase/supabase-js')
const OLD_PROJECT_URL = 'https://xxx.supabase.co'
const OLD_PROJECT_SERVICE_KEY = 'old-project-service-key-xxx'
const NEW_PROJECT_URL = 'https://yyy.supabase.co'
const NEW_PROJECT_SERVICE_KEY = 'new-project-service-key-yyy'
;(async () => {
const oldSupabaseRestClient = createClient(OLD_PROJECT_URL, OLD_PROJECT_SERVICE_KEY, {
    db: {
      schema: 'storage',
    },
})
const oldSupabaseClient = createClient(OLD_PROJECT_URL, OLD_PROJECT_SERVICE_KEY)
const newSupabaseClient = createClient(NEW_PROJECT_URL, NEW_PROJECT_SERVICE_KEY)
// make sure you update max_rows in postgrest settings if you have a lot of objects
// or paginate here
const { data: oldObjects, error } = await oldSupabaseRestClient.from('objects').select()
if (error) {
    console.log('error getting objects from old bucket')
    throw error
}
for (const objectData of oldObjects) {
    console.log(`moving ${objectData.id}`)
    try {
      const { data, error: downloadObjectError } = await oldSupabaseClient.storage
        .from(objectData.bucket_id)
        .download(objectData.name)
      if (downloadObjectError) {
        throw downloadObjectError
      }
      const { _, error: uploadObjectError } = await newSupabaseClient.storage
        .from(objectData.bucket_id)
        .upload(objectData.name, data, {
          upsert: true,
          contentType: objectData.metadata.mimetype,
          cacheControl: objectData.metadata.cacheControl,
        })
      if (uploadObjectError) {
        throw uploadObjectError
      }
    } catch (err) {
      console.log('error moving ', objectData)
      console.log(err)
    }
}
})()
``

### Is this helpful?

NoYes

### On this page

[Backup database using the CLI](https://supabase.com/docs/guides/platform/migrating-within-supabase/backup-restore#backup-database-using-the-cli) [Before you begin](https://supabase.com/docs/guides/platform/migrating-within-supabase/backup-restore#before-you-begin) [Restore backup using CLI](https://supabase.com/docs/guides/platform/migrating-within-supabase/backup-restore#restore-backup-using-cli) [Important project restoration notes](https://supabase.com/docs/guides/platform/migrating-within-supabase/backup-restore#important-project-restoration-notes) [Troubleshooting notes](https://supabase.com/docs/guides/platform/migrating-within-supabase/backup-restore#troubleshooting-notes) [Preserving migration history](https://supabase.com/docs/guides/platform/migrating-within-supabase/backup-restore#preserving-migration-history) [Schema changes to auth and storage](https://supabase.com/docs/guides/platform/migrating-within-supabase/backup-restore#schema-changes-to-auth-and-storage) [Migrate storage objects](https://supabase.com/docs/guides/platform/migrating-within-supabase/backup-restore#migrate-storage-objects)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_migrating_within_supabase_dashboard_restore.md">
Platform

# Restore Dashboard backup

## Learn how to restore your dashboard backup to a new Supabase project

* * *

## Before you begin [\#](https://supabase.com/docs/guides/platform/migrating-within-supabase/dashboard-restore\#before-you-begin)

Install Postgres and psql

Create and configure a new project

## Things to keep in mind [\#](https://supabase.com/docs/guides/platform/migrating-within-supabase/dashboard-restore\#things-to-keep-in-mind)

Here are some things that are not stored directly in your database and will require you to re-create or setup on the new project:

- Edge Functions
- Auth Settings and API keys
- Realtime settings
- Database extensions and settings
- Read Replicas

Here is a non-exhaustive list of items that are commonly asked about and will be migrated with your backup restoration:

- Database triggers
- Database functions

## Restore backup [\#](https://supabase.com/docs/guides/platform/migrating-within-supabase/dashboard-restore\#restore-backup)

1

### Get the new database connection string

Go to the [project page](https://supabase.com/dashboard/project/_/) and click the " **Connect**" button at the top of the page for the connection string.

Use the Session pooler connection string by default. If your ISP supports IPv6, use the direct connection string.

Session pooler connection string:

`
postgresql://postgres.[PROJECT-REF]:[YOUR-PASSWORD]@aws-0-us-east-1.pooler.supabase.com:5432/postgres
`

Direct connection string:

`
postgresql://postgres.[PROJECT-REF]:[YOUR-PASSWORD]@db.[PROJECT-REF].supabase.com:5432/postgres
`

2

### Get the database password

It can take a few minutes for the database password reset to take effect. Especially if multiple password resets are done.

Reset the password in the [Database Settings](https://supabase.com/dashboard/project/_/settings/database).

Replace `[YOUR-PASSWORD]` in the connection string with the database password.

3

### Get the backup file path

Get the relative file path of the downloaded backup file.

If the restore is done in the same directory as the downloaded backup, the file path would look like this:

`./backup_name.backup`

4

### Verify the backup file format

The backup file will be gzipped with a .gz extension. You will need to unzip the file to look like this:

`backup_name.backup`

5

### Restore your backup

`
psql -d [CONNECTION_STRING] -f /file/path
`

Replace `[CONNECTION_STRING]` with connection string from Steps 1 & 2.

Replace `/file/path` with the file path from Step 3.

Run the command with the replaced values to restore the backup to your new project.

## Migrate storage objects to new project's S3 storage [\#](https://supabase.com/docs/guides/platform/migrating-within-supabase/dashboard-restore\#migrate-storage-objects-to-new-projects-s3-storage)

After restoring the backup, the buckets and files metadata will show up in the dashboard of the new project.
However, the storage files stored in the S3 buckets would not be present.

Use the following Google Colab script provided below to migrate your downloaded storage objects to your new project's S3 buckets.

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PLyn/supabase-storage-migrate/blob/main/Supabase_Storage_migration.ipynb)

This method requires uploading to Google Colab and then to the S3 buckets. This could add significant upload time if there are large storage objects.

## Common errors with the backup restore process [\#](https://supabase.com/docs/guides/platform/migrating-within-supabase/dashboard-restore\#common-errors-with-the-backup-restore-process)

" **object already exists**"
" **constraint x for relation y already exists**"
" **Many other variations of errors**"

These errors are expected when restoring to a new Supabase project. The backup from the dashboard is a full dump which contains the CREATE commands for all schemas. This is by design as the full dump allows you to rebuild the entire database from scratch even outside of Supabase.

One side effect of this method is that a new Supabase project has these commands already applied to schemas like storage and auth. The errors from this are not an issue because it skips to the next command to run. Another side effect of this is that all triggers will run during the restoration process which is not ideal but generally is not a problem.

There are circumstances where this method can fail and if it does, you should reach out to Supabase support for help.

" **psql: error: connection to server at "aws-0-us-east-1.pooler.supabase.com" (44.216.29.125), port 5432 failed: received invalid response to GSSAPI negotiation:**"

You are possibly using psql and Postgres version 15 or lower. Completely remove the Postgres installation and install the latest version as per the instructions above to resolve this issue.

" **psql: error: connection to server at "aws-0-us-east-1.pooler.supabase.com" (44.216.29.125), port 5432 failed: error received from server in SCRAM exchange: Wrong password**"

If the database password was reset, it may take a few minutes for it to reflect. Try again after a few minutes if you did a password reset.

### Is this helpful?

NoYes

### On this page

[Before you begin](https://supabase.com/docs/guides/platform/migrating-within-supabase/dashboard-restore#before-you-begin) [Things to keep in mind](https://supabase.com/docs/guides/platform/migrating-within-supabase/dashboard-restore#things-to-keep-in-mind) [Restore backup](https://supabase.com/docs/guides/platform/migrating-within-supabase/dashboard-restore#restore-backup) [Migrate storage objects to new project's S3 storage](https://supabase.com/docs/guides/platform/migrating-within-supabase/dashboard-restore#migrate-storage-objects-to-new-projects-s3-storage) [Common errors with the backup restore process](https://supabase.com/docs/guides/platform/migrating-within-supabase/dashboard-restore#common-errors-with-the-backup-restore-process)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_migrating_within_supabase.md">
Platform

# Migrating within Supabase

## Learn how to migrate from one Supabase project to another

* * *

If you are on a Paid Plan and have physical backups enabled, you should instead use the [Restore\\
to another project feature](https://supabase.com/docs/guides/platform/backups#restore-to-a-new-project)

## Database migration guides [\#](https://supabase.com/docs/guides/platform/migrating-within-supabase\#database-migration-guides)

If you need to migrate from one Supabase project to another, choose the appropriate guide below:

### Backup file from the dashboard (\*.backup) [\#](https://supabase.com/docs/guides/platform/migrating-within-supabase\#backup-file-from-the-dashboard-backup)

Follow the [Restore dashboard backup guide](https://supabase.com/docs/guides/platform/migrating-within-supabase/dashboard-restore)

### SQL backup files (\*.sql) [\#](https://supabase.com/docs/guides/platform/migrating-within-supabase\#sql-backup-files-sql)

Follow the [Backup and Restore using the CLI guide](https://supabase.com/docs/guides/platform/migrating-within-supabase/backup-restore)

## Transfer project to a different organization [\#](https://supabase.com/docs/guides/platform/migrating-within-supabase\#transfer-project-to-a-different-organization)

Project migration is primarily for changing regions or upgrading to new major versions of the platform in some scenarios. If you need to move your project to a different organization without touching the infrastructure, see [project transfers](https://supabase.com/docs/guides/platform/project-transfer).

### Is this helpful?

NoYes

### On this page

[Database migration guides](https://supabase.com/docs/guides/platform/migrating-within-supabase#database-migration-guides) [Backup file from the dashboard (\*.backup)](https://supabase.com/docs/guides/platform/migrating-within-supabase#backup-file-from-the-dashboard-backup) [SQL backup files (\*.sql)](https://supabase.com/docs/guides/platform/migrating-within-supabase#sql-backup-files-sql) [Transfer project to a different organization](https://supabase.com/docs/guides/platform/migrating-within-supabase#transfer-project-to-a-different-organization)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_multi_factor_authentication.md">
Platform

# Multi-factor Authentication

## Enable multi-factor authentication (MFA) to keep your account secure.

* * *

This guide is for adding MFA to your Supabase user account. If you want to enable MFA for users in your Supabase project, refer to [**this guide**](https://supabase.com/docs/guides/auth/auth-mfa) instead.

Multi-factor authentication (MFA) adds an additional layer of security to your user account, by requiring a second factor to verify your user identity. Supabase allows users to enable MFA on their account and set it as a requirement for subsequent logins.

## Supported authentication factors [\#](https://supabase.com/docs/guides/platform/multi-factor-authentication\#supported-authentication-factors)

Currently, Supabase supports adding a unique time-based one-time password (TOTP) to your user account as an additional security factor. You can manage your TOTP factor using apps such as 1Password, Authy, Google Authenticator or Apple's Keychain.

## Enable MFA [\#](https://supabase.com/docs/guides/platform/multi-factor-authentication\#enable-mfa)

You can enable MFA for your user account under your [Supabase account settings](https://supabase.com/dashboard/account/security). Enabling MFA will result in all other user sessions to be automatically logged out and forced to sign-in again with MFA.

Supabase does not return recovery codes. Instead, we recommend that you register a backup TOTP factor to use in an event that you lose access to your primary TOTP factor. Make sure you use a different device and app, or store the secret in a secure location different than your primary one.

For security reasons, we will not be able to restore access to your account if you lose all your two-factor authentication credentials. Do register a backup factor if necessary.

## Login with MFA [\#](https://supabase.com/docs/guides/platform/multi-factor-authentication\#login-with-mfa)

Once you've enabled MFA for your Supabase user account, you will be prompted to enter your second factor challenge code as seen in your preferred TOTP app.

## Disable MFA [\#](https://supabase.com/docs/guides/platform/multi-factor-authentication\#disable-mfa)

You can disable MFA for your user account under your [Supabase account settings](https://supabase.com/dashboard/account/security). On subsequent login attempts, you will not be prompted to enter a MFA code.

We strongly recommend that you do not disable MFA to avoid unauthorized access to your user account.

### Is this helpful?

NoYes

### On this page

[Supported authentication factors](https://supabase.com/docs/guides/platform/multi-factor-authentication#supported-authentication-factors) [Enable MFA](https://supabase.com/docs/guides/platform/multi-factor-authentication#enable-mfa) [Login with MFA](https://supabase.com/docs/guides/platform/multi-factor-authentication#login-with-mfa) [Disable MFA](https://supabase.com/docs/guides/platform/multi-factor-authentication#disable-mfa)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_network_restrictions.md">
Platform

# Network Restrictions

* * *

If you can't find the Network Restrictions section at the bottom of your [Database Settings](https://supabase.com/dashboard/project/_/settings/database), update your version of Postgres in the [Infrastructure Settings](https://supabase.com/dashboard/project/_/settings/infrastructure).

Each Supabase project comes with configurable restrictions on the IP ranges that are allowed to connect to Postgres and its pooler ("your database"). These restrictions are enforced before traffic reaches your database. If a connection is not restricted by IP, it still needs to authenticate successfully with valid database credentials.

If direct connections to your database [resolve to a IPv6 address](https://supabase.com/dashboard/project/_/settings/database), you need to add both IPv4 and IPv6 CIDRs to the list of allowed CIDRs. Network Restrictions will be applied to all database connection routes, whether pooled or direct. You will need to add both the IPv4 and IPv6 networks you want to allow. There are two exceptions: If you have been granted an extension on the IPv6 migration OR if you have purchased the [IPv4 add-on](https://supabase.com/dashboard/project/_/settings/addons), you need only add IPv4 CIDRs.

## To get started via the Dashboard: [\#](https://supabase.com/docs/guides/platform/network-restrictions\#to-get-started-via-the-dashboard)

Network restrictions can be configured in the [Database Settings](https://supabase.com/dashboard/project/_/settings/database) page. Ensure that you have [Owner or Admin permissions](https://supabase.com/docs/guides/platform/access-control#manage-team-members) for the project that you are enabling network restrictions.

## To get started via the CLI: [\#](https://supabase.com/docs/guides/platform/network-restrictions\#to-get-started-via-the-cli)

1. [Install](https://supabase.com/docs/guides/cli) the Supabase CLI 1.22.0+.
2. [Log in](https://supabase.com/docs/guides/cli/local-development#log-in-to-the-supabase-cli) to your Supabase account using the CLI.
3. If your project was created before 23rd December 2022, it will need to be [upgraded to the latest Supabase version](https://supabase.com/docs/guides/platform/migrating-and-upgrading-projects) before Network Restrictions can be used.
4. Ensure that you have [Owner or Admin permissions](https://supabase.com/docs/guides/platform/access-control#manage-team-members) for the project that you are enabling network restrictions.

### Check restrictions [\#](https://supabase.com/docs/guides/platform/network-restrictions\#check-restrictions)

You can use the `get` subcommand of the CLI to retrieve the restrictions currently in effect.

If restrictions have been applied, the output of the `get` command will reflect the IP ranges allowed to connect:

`
> supabase network-restrictions --project-ref {ref} get --experimental
DB Allowed IPv4 CIDRs: &[183.12.1.1/24]
DB Allowed IPv6 CIDRs: &[2001:db8:3333:4444:5555:6666:7777:8888/64]
Restrictions applied successfully: true
`

If restrictions have never been applied to your project, the list of allowed CIDRs will be empty, but they will also not have been applied ("Restrictions applied successfully: false"). As a result, all IPs are allowed to connect to your database:

`
> supabase network-restrictions --project-ref {ref} get --experimental
DB Allowed IPv4 CIDRs: []
DB Allowed IPv6 CIDRs: []
Restrictions applied successfully: false
`

### Update restrictions [\#](https://supabase.com/docs/guides/platform/network-restrictions\#update-restrictions)

The `update` subcommand is used to apply network restrictions to your project:

`
> supabase network-restrictions --project-ref {ref} update --db-allow-cidr 183.12.1.1/24 --db-allow-cidr 2001:db8:3333:4444:5555:6666:7777:8888/64 --experimental
DB Allowed IPv4 CIDRs: &[183.12.1.1/24]
DB Allowed IPv6 CIDRs: &[2001:db8:3333:4444:5555:6666:7777:8888/64]
Restrictions applied successfully: true
`

The restrictions specified (in the form of CIDRs) replaces any restrictions that might have been applied in the past.
To add to the existing restrictions, you must include the existing restrictions within the list of CIDRs provided to the `update` command.

### Remove restrictions [\#](https://supabase.com/docs/guides/platform/network-restrictions\#remove-restrictions)

To remove all restrictions on your project, you can use the `update` subcommand with the CIDR `0.0.0.0/0`:

`
> supabase network-restrictions --project-ref {ref} update --db-allow-cidr 0.0.0.0/0 --db-allow-cidr ::/0 --experimental
DB Allowed IPv4 CIDRs: &[0.0.0.0/0]
DB Allowed IPv6 CIDRs: &[::/0]
Restrictions applied successfully: true
`

## Limitations [\#](https://supabase.com/docs/guides/platform/network-restrictions\#limitations)

- The current iteration of Network Restrictions applies to connections to Postgres and the database pooler; it doesn't currently apply to APIs offered over HTTPS (e.g., PostgREST, Storage, and Auth). This includes using Supabase client libraries like [supabase-js](https://supabase.com/docs/reference/javascript).
- If network restrictions are enabled, direct access to your database from Edge Functions will always be blocked. Using the Supabase client library [supabase-js](https://supabase.com/docs/reference/javascript) is recommended to connect to a database with network restrictions from Edge Functions.

### Is this helpful?

NoYes

### On this page

[To get started via the Dashboard:](https://supabase.com/docs/guides/platform/network-restrictions#to-get-started-via-the-dashboard) [To get started via the CLI:](https://supabase.com/docs/guides/platform/network-restrictions#to-get-started-via-the-cli) [Check restrictions](https://supabase.com/docs/guides/platform/network-restrictions#check-restrictions) [Update restrictions](https://supabase.com/docs/guides/platform/network-restrictions#update-restrictions) [Remove restrictions](https://supabase.com/docs/guides/platform/network-restrictions#remove-restrictions) [Limitations](https://supabase.com/docs/guides/platform/network-restrictions#limitations)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_performance.md">
Platform

# Performance Tuning

* * *

The Supabase platform automatically optimizes your Postgres database to take advantage of the compute resources of the plan your project is on. However, these optimizations are based on assumptions about the type of workflow the project is being utilized for, and it is likely that better results can be obtained by tuning the database for your particular workflow.

## Examining query performance [\#](https://supabase.com/docs/guides/platform/performance\#examining-query-performance)

Unoptimized queries are a major cause of poor database performance. To analyze the performance of your queries, see the [Debugging and monitoring guide](https://supabase.com/docs/guides/database/inspect).

## Optimizing the number of connections [\#](https://supabase.com/docs/guides/platform/performance\#optimizing-the-number-of-connections)

The default connection limits for Postgres and Supavisor is based on your compute size. See the default connection numbers in the [Compute Add-ons](https://supabase.com/docs/guides/platform/compute-add-ons) section.

If the number of connections is insufficient, you will receive the following error upon connecting to the DB:

`
$ psql -U postgres -h ...
FATAL: remaining connection slots are reserved for non-replication superuser connections
`

In such a scenario, you can consider:

- [upgrading to a larger compute add-on](https://supabase.com/dashboard/project/_/settings/compute-and-disk)
- configuring your clients to use fewer connections
- manually configuring the database for a higher number of connections

### Configuring clients to use fewer connections [\#](https://supabase.com/docs/guides/platform/performance\#configuring-clients-to-use-fewer-connections)

You can use the [pg\_stat\_activity](https://www.postgresql.org/docs/current/monitoring-stats.html#MONITORING-PG-STAT-ACTIVITY-VIEW) view to debug which clients are holding open connections on your DB. `pg_stat_activity` only exposes information on direct connections to the database. Information on the number of connections to Supavisor is available [via the metrics endpoint](https://supabase.com/docs/guides/platform/metrics).

Depending on the clients involved, you might be able to configure them to work with fewer connections (e.g. by imposing a limit on the maximum number of connections they're allowed to use), or shift specific workloads to connect via [Supavisor](https://supabase.com/docs/guides/database/connecting-to-postgres#connection-pooler) instead. Transient workflows, which can quickly scale up and down in response to traffic (e.g. serverless functions), can especially benefit from using a connection pooler rather than connecting to the DB directly.

### Allowing higher number of connections [\#](https://supabase.com/docs/guides/platform/performance\#allowing-higher-number-of-connections)

You can configure Postgres connection limit among other parameters by using [Custom Postgres Config](https://supabase.com/docs/guides/platform/custom-postgres-config#custom-postgres-config).

### Enterprise [\#](https://supabase.com/docs/guides/platform/performance\#enterprise)

[Contact us](https://forms.supabase.com/enterprise) if you need help tuning your database for your specific workflow.

### Is this helpful?

NoYes

### On this page

[Examining query performance](https://supabase.com/docs/guides/platform/performance#examining-query-performance) [Optimizing the number of connections](https://supabase.com/docs/guides/platform/performance#optimizing-the-number-of-connections) [Configuring clients to use fewer connections](https://supabase.com/docs/guides/platform/performance#configuring-clients-to-use-fewer-connections) [Allowing higher number of connections](https://supabase.com/docs/guides/platform/performance#allowing-higher-number-of-connections) [Enterprise](https://supabase.com/docs/guides/platform/performance#enterprise)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_permissions.md">
Platform

# Permissions

* * *

The Supabase platform offers additional services (e.g. Storage) on top of the Postgres database that comes with each project. These services default to storing their operational data within your database, to ensure that you retain complete control over it.

However, these services assume a base level of access to their data, in order to e.g. be able to run migrations over it. Breaking these assumptions runs the risk of rendering these services inoperational for your project:

- all entities under the `storage` schema are owned by `supabase_storage_admin`
- all entities under the `auth` schema are owned by `supabase_auth_admin`

It is possible for violations of these assumptions to not cause an immediate outage, but take effect at a later time when a newer migration becomes available.

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_project_transfer.md">
Platform

# Project Transfers

* * *

You can freely transfer projects between different organizations. Head to your [projects' general settings](https://supabase.com/dashboard/project/_/settings/general) to initiate a project transfer.

![Project Transfer: General Settings](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fproject-transfer-overview--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![Project Transfer: Confirmation Modal](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fproject-transfer-modal--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

Source organization - the organization the project currently belongs to
Target organization - the organization you want to move the project to

## Pre-Requirements [\#](https://supabase.com/docs/guides/platform/project-transfer\#pre-requirements)

- You need to be the owner of the source organization.
- You need to be at least a member of the target organization you want to move the project to.
- Projects with support tier add-ons cannot be transferred at this point. [Open a support ticket](https://supabase.com/dashboard/support/new?category=billing&subject=Transfer%20project).

## Usage-billing and project add-ons [\#](https://supabase.com/docs/guides/platform/project-transfer\#usage-billing-and-project-add-ons)

For usage metrics such as disk size, egress or image transformations and project add-ons such as [Compute Add-On](https://supabase.com/docs/guides/platform/compute-add-ons), [Point-In-Time-Recovery](https://supabase.com/docs/guides/platform/backups#point-in-time-recovery), [IPv4](https://supabase.com/docs/guides/platform/ipv4-address), [Log Drains](https://supabase.com/docs/guides/platform/log-drains), [Advanced MFA](https://supabase.com/docs/guides/auth/auth-mfa/phone) or a [Custom Domain](https://supabase.com/docs/guides/platform/custom-domains), the source organization will still be charged for the usage up until the transfer. The charges will be added to the invoice when the billing cycle resets.

The target organization will be charged at the end of the billing cycle for usage after the project transfer.

## Things to watch out for [\#](https://supabase.com/docs/guides/platform/project-transfer\#things-to-watch-out-for)

- Transferring a project might come with a short 1-2 minute downtime if you're moving a project from a paid to a Free Plan.
- You could lose access to certain project features depending on the plan of the target organization, i.e. moving a project from a Pro Plan to a Free Plan.
- When moving your project to a Free Plan, we also ensure youre not exceeding your two free project limit. In these cases, it is best to upgrade your target organization to Pro Plan first.
- You could have less rights on the project depending on your role in the target organization, i.e. you were an Owner in the previous organization and only have a Read-Only role in the target organization.

## Transfer to a different region [\#](https://supabase.com/docs/guides/platform/project-transfer\#transfer-to-a-different-region)

Note that project transfers are only transferring your projects across an organization and cannot be used to transfer between different regions. To move your project to a different region, see [migrating your project](https://supabase.com/docs/guides/platform/migrating-and-upgrading-projects#migrate-your-project).

### Is this helpful?

NoYes

### On this page

[Pre-Requirements](https://supabase.com/docs/guides/platform/project-transfer#pre-requirements) [Usage-billing and project add-ons](https://supabase.com/docs/guides/platform/project-transfer#usage-billing-and-project-add-ons) [Things to watch out for](https://supabase.com/docs/guides/platform/project-transfer#things-to-watch-out-for) [Transfer to a different region](https://supabase.com/docs/guides/platform/project-transfer#transfer-to-a-different-region)

![Project Transfer: Confirmation Modal](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fproject-transfer-modal--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![Project Transfer: General Settings](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fproject-transfer-overview--light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_read_replicas.md">
Platform

# Read Replicas

## Deploy read-only databases across multiple regions, for lower latency and better resource management.

* * *

Read Replicas are additional databases that are kept in sync with your Primary database. You can read your data from a Read Replica, which helps with:

- **Load balancing:** Read Replicas reduce load on the Primary database. For example, you can use a Read Replica for complex analytical queries and reserve the Primary for user-facing create, update, and delete operations.
- **Improved latency:** For projects with a global user base, additional databases can be deployed closer to users to reduce latency.
- **Redundancy:** Read Replicas provide data redundancy.

![Map view of all project databases.](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fread-replicas%2Fmap-view.png%3Fv%3D1&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

## About Read Replicas [\#](https://supabase.com/docs/guides/platform/read-replicas\#about-read-replicas)

The database you start with when launching a Supabase project is your Primary database. Read Replicas are kept in sync with the Primary through a process called "replication." Replication is asynchronous to ensure that transactions on the Primary aren't blocked. There is a delay between an update on the Primary and the time that a Read Replica receives the change. This delay is called "replication lag."

You can only read data from a Read Replica. This is in contrast to a Primary database, where you can both read and write:

|  | select | insert | update | delete |
| --- | --- | --- | --- | --- |
| Primary |  |  |  |  |
| Read Replica |  | - | - | - |

## Prerequisites [\#](https://supabase.com/docs/guides/platform/read-replicas\#prerequisites)

Read Replicas are available for all projects on the Pro, Team and Enterprise plans. Spin one up now over at the [Infrastructure Settings page](https://supabase.com/dashboard/project/_/settings/infrastructure).

Projects must meet these requirements to use Read Replicas:

1. Running on AWS.
   - Support for projects on Fly.io is coming.
2. Running on at least a [Small compute add-on](https://supabase.com/docs/guides/platform/compute-add-ons).
   - Read Replicas are started on the same compute instance as the Primary to keep up with changes.
3. Running on Postgres 15+.
   - For projects running on older versions of Postgres, you will need to [upgrade to the latest platform version](https://supabase.com/docs/guides/platform/migrating-and-upgrading-projects#pgupgrade).
4. Using [physical backups](https://supabase.com/docs/guides/platform/backups#point-in-time-recovery)
   - Physical backups are automatically enabled if using [PITR](https://supabase.com/docs/guides/platform/backups#point-in-time-recovery)
   - If you're not using PITR, you'll be able to switch to physical backups as part of the Read Replica setup process. Note that physical backups can't be downloaded from the dashboard in the way logical backups can.

## Getting started [\#](https://supabase.com/docs/guides/platform/read-replicas\#getting-started)

To add a Read Replica, go to the [Infrastructure Settings page](https://supabase.com/dashboard/project/_/settings/infrastructure) in your dashboard.

Projects on an XL compute add-on or larger can create up to five Read Replicas. Projects on compute add-ons smaller than XL can create up to two Read Replicas. All Read Replicas inherit the compute size of their Primary database.

### Deploying a Read Replica [\#](https://supabase.com/docs/guides/platform/read-replicas\#deploying-a-read-replica)

A Read Replica is deployed by using a physical backup as a starting point, and a combination of WAL file archives and direct replication from the Primary database to catch up. Both components may take significant time to complete. The duration of restoring from a physical backup is roughly dependent and directly related to the database size of your project. The time taken to catch up to the primary using WAL archives and direct replication is dependent on the level of activity on the Primary database; a more active database will produce a larger number of WAL files that will need to be processed.

Along with the progress of the deployment, the dashboard displays rough estimates for each component.

### What does it mean when "Init failed" is observed? [\#](https://supabase.com/docs/guides/platform/read-replicas\#what-does-it-mean-when-init-failed-is-observed)

The status `Init failed` indicates that the Read Replica has failed to deploy. Some possible scenarios as to why a Read Replica may have failed to be deployed:

- Underlying instance failed to come up.
- Network issue leading to inability to connect to the Primary database.
- Possible incompatible database settings between the Primary and Read Replica databases.
- Platform issues.

It is safe to drop this failed Read Replica, and in the event of a transient issue, attempt to spin up another one. If however spinning up Read Replicas for your project consistently fails, do check out our [status page](https://status.supabase.com/) for any ongoing incidents, or open a support ticket [here](https://supabase.com/dashboard/support/new). To aid the investigation, do not bring down the recently failed Read Replica.

## Features [\#](https://supabase.com/docs/guides/platform/read-replicas\#features)

Read Replicas offer the following features:

### Dedicated endpoints [\#](https://supabase.com/docs/guides/platform/read-replicas\#dedicated-endpoints)

Each Read Replica has its own dedicated database and API endpoints.

- Find the database endpoint on the [Database Settings page](https://supabase.com/dashboard/project/_/settings/database) under **Connection Info**
- Find the API endpoint on the [API Settings page](https://supabase.com/dashboard/project/_/settings/api) under **Project URL**

Read Replicas only support `GET` requests from the [REST API](https://supabase.com/docs/guides/api). If you are calling a read-only Postgres function through the REST API, make sure to set the `get: true` [option](https://supabase.com/docs/reference/javascript/rpc?queryGroups=example&example=call-a-read-only-postgres-function).

Requests to other Supabase products, such as Auth, Storage, and Realtime, aren't able to use a Read Replica or its API endpoint. Support for more products will be added in the future.

If you're using an [IPv4 add-on](https://supabase.com/docs/guides/platform/ipv4-address#read-replicas), the database endpoints for your Read Replicas will also use an IPv4 add-on.

### Dedicated connection pool [\#](https://supabase.com/docs/guides/platform/read-replicas\#dedicated-connection-pool)

A connection pool through Supavisor is also available for each Read Replica. Find the connection string on the [Database Settings page](https://supabase.com/dashboard/project/_/settings/database) under **Connection String**.

### API load balancer [\#](https://supabase.com/docs/guides/platform/read-replicas\#api-load-balancer)

A load balancer is deployed to automatically balance requests between your Primary database and Read Replicas. Find its endpoint on the [API Settings page](https://supabase.com/dashboard/project/_/settings/api).

The load balancer uses a round-robin strategy to route `GET` requests to all available API endpoints, including the Primary database. This means that `GET` requests are randomly and evenly split among databases. Non- `GET` requests can also be sent through this endpoint, and will be routed to the Primary database.

To call a read-only Postgres function on Read Replicas through the REST API, use the `get: true` [option](https://supabase.com/docs/reference/javascript/rpc?queryGroups=example&example=call-a-read-only-postgres-function).

If you remove all Read Replicas from your project, the load balancer and its endpoint are removed as well. Make sure to redirect requests back to your Primary database before removal.

#### Experimental routing [\#](https://supabase.com/docs/guides/platform/read-replicas\#experimental-routing)

The API load balancer offers an experimental routing mode that builds on top of the existing functionality. It is now possible to use a load balancer endpoint for all Supabase services (Auth, Edge Functions, Realtime, and Storage) meaning there is no need to worry about which endpoint to use in which situations.

Due to the requirements of the Auth service, all Auth requests are handled by the Primary, even when sent over the load balancer endpoint. This is similar to how non-Read requests for the Data API (PostgREST) are exclusively handled by the Primary.

The experimental routing mode can be enabled by sending the header `sb-lb-routing-mode: alpha-all-services` along with requests. This gives the option to opt-in and try out the new routing, but still have the peace of mind that the original behavior is there should it be needed.

What follows is an example of using the `supabase-js` library to create a new client with the appropriate headers and make an Auth request to create a new user.

./create-user.ts

`
import { createClient } from '@supabase/supabase-js'
import * as dotenv from 'dotenv'
// Load environment variables from .env file
dotenv.config()
// Supabase credentials
const supabaseUrl = process.env.SUPABASE_URL as string
const supabaseKey = process.env.SUPABASE_KEY as string
// Initialize the Supabase client with custom headers
const supabase = createClient(supabaseUrl, supabaseKey, {
global: {
    headers: {
      'sb-lb-routing-mode': 'alpha-all-services',
    },
},
})
/**
* @description simple user creation function
*/
async function createUser() {
// Make the Auth call to create a user
const { data, error } = await supabase.auth.signUp({
    email: 'valid.email@supabase.io',
    password: 'my--really-strong-password',
})
// Throw on an error
if (error) {
    throw new Error(error.message)
}
// Output the response
console.dir(data)
}
// Register a random user
createUser()
`

The client creation function, with experimental routing header, can be used throughout an application to take advantage of load balancer experimental routing.

If you use a [custom domain](https://supabase.com/docs/guides/platform/custom-domains), requests will not be routed through the load balancer. You should instead use the dedicated endpoints provided in the dashboard.

### Querying through the SQL editor [\#](https://supabase.com/docs/guides/platform/read-replicas\#querying-through-the-sql-editor)

In the SQL editor, you can choose if you want to run the query on a particular Read Replica.

![SQL editor view.](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fread-replicas%2Fsql-editor.png%3Fv%3D1&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Logging [\#](https://supabase.com/docs/guides/platform/read-replicas\#logging)

When a Read Replica is deployed, it emits logs from the following services:

- [API](https://supabase.com/dashboard/project/_/logs/edge-logs)
- [Postgres](https://supabase.com/dashboard/project/_/logs/postgres-logs)
- [PostgREST](https://supabase.com/dashboard/project/_/logs/postgrest-logs)
- [Supavisor](https://supabase.com/dashboard/project/_/logs/pooler-logs)

Views on [Log Explorer](https://supabase.com/docs/guides/platform/logs) are automatically filtered by databases, with the logs of the Primary database displayed by default. Viewing logs from other databases can be toggled with the `Source` button found on the upper-right part section of the Logs Explorer page.

For API logs, logs can originate from the API Load Balancer as well. The upstream database or the one that eventually handles the request can be found under the `Redirect Identifier` field. This is equivalent to `metadata.load_balancer_redirect_identifier` when querying the underlying logs.

### Metrics [\#](https://supabase.com/docs/guides/platform/read-replicas\#metrics)

Observability and metrics for Read Replicas are available on the Supabase Dashboard. Resource utilization for a specific Read Replica can be viewed on the [Database Reports page](https://supabase.com/dashboard/project/_/reports/database) by toggling for `Source`. Likewise, metrics on API requests going through either a Read Replica or Load Balancer API endpoint are also available on the dashboard through the [API Reports page](https://supabase.com/dashboard/project/_/reports/api-overview)

We recommend ingesting your [project's metrics](https://supabase.com/docs/guides/platform/metrics#accessing-the-metrics-endpoint) into your own environment. If you have an existing ingestion pipeline set up for your project, you can [update it](https://github.com/supabase/supabase-grafana?tab=readme-ov-file#read-replica-support) to additionally ingest metrics from your Read Replicas.

### Centralized configuration management [\#](https://supabase.com/docs/guides/platform/read-replicas\#centralized-configuration-management)

All settings configured through the dashboard will be propagated across all databases of a project. This ensures that no Read Replica get out of sync with the Primary database or with other Read Replicas.

## Operations blocked by Read Replicas [\#](https://supabase.com/docs/guides/platform/read-replicas\#operations-blocked-by-read-replicas)

### Project upgrades and data restorations [\#](https://supabase.com/docs/guides/platform/read-replicas\#project-upgrades-and-data-restorations)

The following procedures require all Read Replicas for a project to be brought down before they can be performed:

1. [Project upgrades](https://supabase.com/docs/guides/platform/migrating-and-upgrading-projects#pgupgrade)
2. [Data restorations](https://supabase.com/docs/guides/platform/backups#pitr-restoration-process)

These operations need to be completed before Read Replicas can be re-deployed.

## About replication [\#](https://supabase.com/docs/guides/platform/read-replicas\#about-replication)

We use a hybrid approach to replicate data from a Primary to its Read Replicas, combining the native methods of streaming replication and file-based log shipping.

### Streaming replication [\#](https://supabase.com/docs/guides/platform/read-replicas\#streaming-replication)

Postgres generates a Write Ahead Log (WAL) as database changes occur. With streaming replication, these changes stream from the Primary to the Read Replica server. The WAL alone is sufficient to reconstruct the database to its current state.

This replication method is fast, since changes are streamed directly from the Primary to the Read Replica. On the other hand, it faces challenges when the Read Replica can't keep up with the WAL changes from its Primary. This can happen when the Read Replica is too small, running on degraded hardware, or has a heavier workload running.

To address this, Postgres does provide tunable configuration, like `wal_keep_size`, to adjust the WAL retained by the Primary. If the Read Replica fails to catch up before the WAL surpasses the `wal_keep_size` setting, the replication is terminated. Tuning is a bit of an art - the amount of WAL required is variable for every situation.

### File-based log shipping [\#](https://supabase.com/docs/guides/platform/read-replicas\#file-based-log-shipping)

In this replication method, the Primary continuously buffers WAL changes to a local file and then sends the file to the Read Replica. If multiple Read Replicas are present, files could also be sent to an intermediary location accessible by all. The Read Replica then reads the WAL files and applies those changes. There is higher replication lag than streaming replication since the Primary buffers the changes locally first. It also means there is a small chance that WAL changes do not reach Read Replicas if the Primary goes down before the file is transferred. In these cases, if the Primary fails a Replica using streaming replication would (in most cases) be more up-to-date than a Replica using file-based log shipping.

### File-based log shipping  streaming replication [\#](https://supabase.com/docs/guides/platform/read-replicas\#file-based-log-shipping--streaming-replication)

![Map view of Primary and Read Replica databases](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fread-replicas%2Fstreaming-replication-dark.png%3Fv%3D1&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

Map view of Primary and Read Replica databases

We bring these two methods together to achieve quick, stable, and reliable replication. Each method addresses the limitations of the other. Streaming replication minimizes replication lag, while file-based log shipping provides a fallback. For file-based log shipping, we use our existing Point In Time Recovery (PITR) infrastructure. We regularly archive files from the Primary using [WAL-G](https://github.com/wal-g/wal-g), an open source archival and restoration tool, and ship the WAL files to S3.

We combine it with streaming replication to reduce replication lag. Once WAL-G files have been synced from S3, Read Replicas connect to the Primary and stream the WAL directly.

### Monitoring replication lag [\#](https://supabase.com/docs/guides/platform/read-replicas\#monitoring-replication-lag)

Replication lag for a specific Read Replica can be monitored through the dashboard. On the [Database Reports page](https://supabase.com/dashboard/project/_/reports/database) Read Replicas will have an additional chart under `Replica Information` displaying historical replication lag in seconds. Realtime replication lag in seconds can be observed on the [Infrastructure Settings page](https://supabase.com/dashboard/project/_/settings/infrastructure). This is the value on top of the Read Replica. Do note that there is no single threshold to indicate when replication lag should be addressed. It would be fully dependent on the requirements of your project.

If you are already ingesting your [project's metrics](https://supabase.com/docs/guides/platform/metrics#accessing-the-metrics-endpoint) into your own environment, you can also keep track of replication lag and set alarms accordingly with the metric: `physical_replication_lag_physical_replica_lag_seconds`.

Some common sources of high replication lag include:

1. Exclusive locks on tables on the Primary.
Operations such as `drop table`, `reindex` (amongst others) take an Access Exclusive lock on the table. This can result in increasing replication lag for the duration of the lock.
2. Resource Constraints on the database
Heavy utilization on the primary or the replica, if run on an under-resourced project, can result in high replication lag. This includes the characteristics of the disk being utilized (IOPS, Throughput).
3. Long-running transactions on the Primary.
Transactions that run for a long-time on the primary can also result in high replication lag. You can use the `pg_stat_activity` view to identify and terminate such transactions if needed. `pg_stat_activity` is a live view, and does not offer historical data on transactions that might have been active for a long time in the past.

High replication lag can result in stale data being returned for queries being executed against the affected read replicas.

You can [consult](https://cloud.google.com/sql/docs/postgres/replication/replication-lag) [additional](https://repost.aws/knowledge-center/rds-postgresql-replication-lag) [resources](https://severalnines.com/blog/what-look-if-your-postgresql-replication-lagging/) on the subject as well.

## Misc [\#](https://supabase.com/docs/guides/platform/read-replicas\#misc)

### Restart or compute add-on change behaviour [\#](https://supabase.com/docs/guides/platform/read-replicas\#restart-or-compute-add-on-change-behaviour)

When a project that utilizes Read Replicas is restarted, or the compute add-on size is changed, the Primary database gets restarted first. During this period, the Read Replicas remain available.

Once the Primary database has completed restarting (or resizing, in case of a compute add-on change) and become available for usage, all the Read Replicas are restarted (and resized, if needed) concurrently.

## Pricing [\#](https://supabase.com/docs/guides/platform/read-replicas\#pricing)

For a detailed breakdown of how charges are calculated, refer to [Manage Read Replica usage](https://supabase.com/docs/guides/platform/manage-your-usage/read-replicas).

### Is this helpful?

NoYes

### On this page

[About Read Replicas](https://supabase.com/docs/guides/platform/read-replicas#about-read-replicas) [Prerequisites](https://supabase.com/docs/guides/platform/read-replicas#prerequisites) [Getting started](https://supabase.com/docs/guides/platform/read-replicas#getting-started) [Deploying a Read Replica](https://supabase.com/docs/guides/platform/read-replicas#deploying-a-read-replica) [What does it mean when "Init failed" is observed?](https://supabase.com/docs/guides/platform/read-replicas#what-does-it-mean-when-init-failed-is-observed) [Features](https://supabase.com/docs/guides/platform/read-replicas#features) [Dedicated endpoints](https://supabase.com/docs/guides/platform/read-replicas#dedicated-endpoints) [Dedicated connection pool](https://supabase.com/docs/guides/platform/read-replicas#dedicated-connection-pool) [API load balancer](https://supabase.com/docs/guides/platform/read-replicas#api-load-balancer) [Querying through the SQL editor](https://supabase.com/docs/guides/platform/read-replicas#querying-through-the-sql-editor) [Logging](https://supabase.com/docs/guides/platform/read-replicas#logging) [Metrics](https://supabase.com/docs/guides/platform/read-replicas#metrics) [Centralized configuration management](https://supabase.com/docs/guides/platform/read-replicas#centralized-configuration-management) [Operations blocked by Read Replicas](https://supabase.com/docs/guides/platform/read-replicas#operations-blocked-by-read-replicas) [Project upgrades and data restorations](https://supabase.com/docs/guides/platform/read-replicas#project-upgrades-and-data-restorations) [About replication](https://supabase.com/docs/guides/platform/read-replicas#about-replication) [Streaming replication](https://supabase.com/docs/guides/platform/read-replicas#streaming-replication) [File-based log shipping](https://supabase.com/docs/guides/platform/read-replicas#file-based-log-shipping) [File-based log shipping  streaming replication](https://supabase.com/docs/guides/platform/read-replicas#file-based-log-shipping--streaming-replication) [Monitoring replication lag](https://supabase.com/docs/guides/platform/read-replicas#monitoring-replication-lag) [Misc](https://supabase.com/docs/guides/platform/read-replicas#misc) [Restart or compute add-on change behaviour](https://supabase.com/docs/guides/platform/read-replicas#restart-or-compute-add-on-change-behaviour) [Pricing](https://supabase.com/docs/guides/platform/read-replicas#pricing)

![SQL editor view.](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fread-replicas%2Fsql-editor.png%3Fv%3D1&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![Map view of all project databases.](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fread-replicas%2Fmap-view.png%3Fv%3D1&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![Map view of Primary and Read Replica databases](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fread-replicas%2Fstreaming-replication-dark.png%3Fv%3D1&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_regions.md">
Platform

# Available regions

## Spin up Supabase projects in our global regions

* * *

The following regions are available for your Supabase projects.

## AWS [\#](https://supabase.com/docs/guides/platform/regions\#aws)

- West US (North California) `us-west-1`
- East US (North Virginia) `us-east-1`
- East US (Ohio) `us-east-2`
- Canada (Central) `ca-central-1`
- West EU (Ireland) `eu-west-1`
- West Europe (London) `eu-west-2`
- West EU (Paris) `eu-west-3`
- Central EU (Frankfurt) `eu-central-1`
- Central Europe (Zurich) `eu-central-2`
- North EU (Stockholm) `eu-north-1`
- South Asia (Mumbai) `ap-south-1`
- Southeast Asia (Singapore) `ap-southeast-1`
- Northeast Asia (Tokyo) `ap-northeast-1`
- Northeast Asia (Seoul) `ap-northeast-2`
- Oceania (Sydney) `ap-southeast-2`
- South America (So Paulo) `sa-east-1`

## Fly [\#](https://supabase.com/docs/guides/platform/regions\#fly)

Our [Fly Postgres](https://supabase.com/docs/guides/platform/fly-postgres) offering (in private alpha) is supported in every region where Fly operates.

### Is this helpful?

NoYes

### On this page

[AWS](https://supabase.com/docs/guides/platform/regions#aws) [Fly](https://supabase.com/docs/guides/platform/regions#fly)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_ssl_enforcement.md">
Platform

# Postgres SSL Enforcement

* * *

Your Supabase project supports connecting to the Postgres DB without SSL enabled to maximize client compatibility. For increased security, you can prevent clients from connecting if they're not using SSL.

Disabling SSL enforcement only applies to connections to Postgres and Supavisor ("Connection Pooler"); all HTTP APIs offered by Supabase (e.g., PostgREST, Storage, Auth) automatically enforce SSL on all incoming connections.

Projects need to be at least on Postgres 13.3.0 to enable SSL enforcement. You can find the Postgres version of your project in the [Infrastructure Settings page](https://supabase.com/dashboard/project/_/settings/infrastructure). If your project is on an older version, you will need to
[upgrade](https://supabase.com/docs/guides/platform/migrating-and-upgrading-projects#upgrade-your-project) to use this feature.

## Manage SSL enforcement via the dashboard [\#](https://supabase.com/docs/guides/platform/ssl-enforcement\#manage-ssl-enforcement-via-the-dashboard)

SSL enforcement can be configured via the "Enforce SSL on incoming connections" setting under the SSL Configuration section in [Database Settings page](https://supabase.com/dashboard/project/_/settings/database) of the dashboard.

## Manage SSL enforcement via the CLI [\#](https://supabase.com/docs/guides/platform/ssl-enforcement\#manage-ssl-enforcement-via-the-cli)

To get started:

1. [Install](https://supabase.com/docs/guides/cli) the Supabase CLI 1.37.0+.
2. [Log in](https://supabase.com/docs/guides/getting-started/local-development#log-in-to-the-supabase-cli) to your Supabase account using the CLI.
3. Ensure that you have [Owner or Admin permissions](https://supabase.com/docs/guides/platform/access-control#manage-team-members) for the project that you are enabling SSL enforcement.

### Check enforcement status [\#](https://supabase.com/docs/guides/platform/ssl-enforcement\#check-enforcement-status)

You can use the `get` subcommand of the CLI to check whether SSL is currently being enforced:

`
supabase ssl-enforcement --project-ref {ref} get --experimental
`

Response if SSL is being enforced:

`
SSL is being enforced.
`

Response if SSL is not being enforced:

`
SSL is *NOT* being enforced.
`

### Update enforcement [\#](https://supabase.com/docs/guides/platform/ssl-enforcement\#update-enforcement)

The `update` subcommand is used to change the SSL enforcement status for your project:

`
supabase ssl-enforcement --project-ref {ref} update --enable-db-ssl-enforcement --experimental
`

Similarly, to disable SSL enforcement:

`
supabase ssl-enforcement --project-ref {ref} update --disable-db-ssl-enforcement --experimental
`

### A note about Postgres SSL modes [\#](https://supabase.com/docs/guides/platform/ssl-enforcement\#a-note-about-postgres-ssl-modes)

Postgres supports [multiple SSL modes](https://www.postgresql.org/docs/current/libpq-ssl.html#LIBPQ-SSL-PROTECTION) on the client side. These modes provide different levels of protection. Depending on your needs, it is important to verify that the SSL mode in use is performing the required level of enforcement and verification of SSL connections.

The strongest mode offered by Postgres is `verify-full` and this is the mode you most likely want to use when SSL enforcement is enabled. To use `verify-full` you will need to download the Supabase CA certificate for your database. The certificate is available through the dashboard under the SSL Configuration section in the [Database Settings page](https://supabase.com/dashboard/project/_/settings/database).

Once the CA certificate has been downloaded, add it to the certificate authority list used by Postgres.

`
cat {location of downloaded prod-ca-2021.crt} >> ~/.postgres/root.crt
`

With the CA certificate added to the trusted certificate authorities list, use `psql` or your client library to connect to Supabase:

`
psql "postgresql://aws-0-eu-central-1.pooler.supabase.com:6543/postgres?sslmode=verify-full" -U postgres.<user>
`

### Is this helpful?

NoYes

### On this page

[Manage SSL enforcement via the dashboard](https://supabase.com/docs/guides/platform/ssl-enforcement#manage-ssl-enforcement-via-the-dashboard) [Manage SSL enforcement via the CLI](https://supabase.com/docs/guides/platform/ssl-enforcement#manage-ssl-enforcement-via-the-cli) [Check enforcement status](https://supabase.com/docs/guides/platform/ssl-enforcement#check-enforcement-status) [Update enforcement](https://supabase.com/docs/guides/platform/ssl-enforcement#update-enforcement) [A note about Postgres SSL modes](https://supabase.com/docs/guides/platform/ssl-enforcement#a-note-about-postgres-ssl-modes)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_sso_azure.md">
Platform

# Set Up SSO with Azure AD

* * *

This feature is only available on the Team and Enterprise Plans. Contact [Sales](https://forms.supabase.com/enterprise) before doing these steps.

Looking for docs on how to add Single Sign-On support in your Supabase project? Head on over to [Single Sign-On with SAML 2.0 for Projects](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml).

Supabase supports single sign-on (SSO) using Microsoft Azure AD.

## Step 1: Add and register an Enterprise application [\#](https://supabase.com/docs/guides/platform/sso/azure\#add-and-register-enterprise-application)

Open up the [Azure Active Directory](https://portal.azure.com/#view/Microsoft_AAD_IAM/ActiveDirectoryMenuBlade/~/Overview) dashboard for your Azure account.

Click the _Add_ button then _Enterprise application_.

![Azure AD console: Default Directory Overview](https://supabase.com/docs/img/sso-azure-step-01.png)

## Step 2: Choose to create your own application [\#](https://supabase.com/docs/guides/platform/sso/azure\#create-application)

You'll be using the custom enterprise application setup for Supabase.

![Azure AD console: Browse Azure AD Gallery, select: Create your own application](https://supabase.com/docs/img/sso-azure-step-02.png)

## Step 3: Fill in application details [\#](https://supabase.com/docs/guides/platform/sso/azure\#add-application-details)

In the modal titled _Create your own application_, enter a display name for Supabase. This is the name your Azure AD users see when signing in to Supabase from Azure. `Supabase` works in most cases.

Make sure to choose the third option: _Integrate any other application you_
_don't find in the gallery (Non-gallery)_.

![Azure AD console: Create your own application modal](https://supabase.com/docs/img/sso-azure-step-03.png)

## Step 4: Set up single sign-on [\#](https://supabase.com/docs/guides/platform/sso/azure\#set-up-single-sign-on)

Before you get to assigning users and groups, which would allow accounts in Azure AD to access Supabase, you need to configure the SAML details that allows Supabase to accept sign in requests from Azure AD.

![Azure AD console: Supabase custom enterprise application, selected Set up single sign-on](https://supabase.com/docs/img/sso-azure-step-04.png)

## Step 5: Select SAML single sign-on method [\#](https://supabase.com/docs/guides/platform/sso/azure\#saml-sso)

Supabase only supports the SAML 2.0 protocol for Single Sign-On, which is an industry standard.

![Azure AD console: Supabase application, Single sign-on configuration screen, selected SAML](https://supabase.com/docs/img/sso-azure-step-05.png)

## Step 6: Upload SAML-based sign-on metadata file [\#](https://supabase.com/docs/guides/platform/sso/azure\#upload-saml-metadata)

First you need to download Supabase's SAML metadata file. Click the button below to initiate a download of the file.

[Download Supabase SAML Metadata File](https://alt.supabase.io/auth/v1/sso/saml/metadata?download=true)

Alternatively, visit this page to initiate a download: `https://alt.supabase.io/auth/v1/sso/saml/metadata?download=true`

Click on the _Upload metadata file_ option in the toolbar and select the file you just downloaded.

![Azure AD console: Supabase application, SAML-based Sign-on screen, selected Upload metadata file button](https://supabase.com/docs/img/sso-azure-step-06-1.png)

All of the correct information should automatically populate the _Basic SAML Configuration_ screen as shown.

![Azure AD console: Supabase application, SAML-based Sign-on screen, Basic SAML Configuration shown](https://supabase.com/docs/img/sso-azure-step-06-2.png)

**Make sure you input these additional settings.**

| Setting | Value |
| --- | --- |
| Sign on URL | `https://supabase.com/dashboard/sign-in-sso` |
| Relay State | `https://supabase.com/dashboard` |

Finally, click the _Save_ button to save the configuration.

## Step 7: Obtain metadata URL and send to Supabase [\#](https://supabase.com/docs/guides/platform/sso/azure\#send-metadata-url)

Supabase needs to finalize enabling single sign-on with your Azure AD application. To do this, copy and send the link under **App Federation Metadata URL** in \*section 3 **SAML Certificates\*** to your support contact and await further instructions. If you're not clear who to send this link to or need further assistance, reach out to [Supabase Support](https://supabase.help/).

**Do not test the login until you have heard back from the support contact.**

![Azure AD console: Supabase application, SAML Certificates card shown, App Federation Metadata Url highlighted](https://supabase.com/docs/img/sso-azure-step-07.png)

## Step 8: Wait for confirmation [\#](https://supabase.com/docs/guides/platform/sso/azure\#confirmation)

Wait for confirmation or further instructions from your support contact at Supabase before proceeding to the next step. It usually takes us 1 business day to configure SSO for you.

## Step 9: Test single sign-on [\#](https://supabase.com/docs/guides/platform/sso/azure\#testing)

_Testing sign-on before your Azure AD has been registered with Supabase will not work. Make sure you've received confirmation from your support contact at Supabase as laid out in the [confirmation](https://supabase.com/docs/guides/platform/sso/azure#confirmation) step._

Once youve received confirmation from your support contact at Supabase that SSO setup has been completed for your enterprise, you can ask some of your users to sign in via their Azure AD account.

You ask them to enter their email address on the [Sign in with SSO](https://supabase.com/dashboard/sign-in-sso) page.

If sign in is not working correctly, reach out to your support contact at Supabase for further guidance.

### Is this helpful?

NoYes

### On this page

[Step 1: Add and register an Enterprise application](https://supabase.com/docs/guides/platform/sso/azure#add-and-register-enterprise-application) [Step 2: Choose to create your own application](https://supabase.com/docs/guides/platform/sso/azure#create-application) [Step 3: Fill in application details](https://supabase.com/docs/guides/platform/sso/azure#add-application-details) [Step 4: Set up single sign-on](https://supabase.com/docs/guides/platform/sso/azure#set-up-single-sign-on) [Step 5: Select SAML single sign-on method](https://supabase.com/docs/guides/platform/sso/azure#saml-sso) [Step 6: Upload SAML-based sign-on metadata file](https://supabase.com/docs/guides/platform/sso/azure#upload-saml-metadata) [Step 7: Obtain metadata URL and send to Supabase](https://supabase.com/docs/guides/platform/sso/azure#send-metadata-url) [Step 8: Wait for confirmation](https://supabase.com/docs/guides/platform/sso/azure#confirmation) [Step 9: Test single sign-on](https://supabase.com/docs/guides/platform/sso/azure#testing)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_sso_gsuite.md">
Platform

# Set Up SSO with Google Workspace

* * *

This feature is only available on the Team and Enterprise Plans. Contact [Sales](https://forms.supabase.com/enterprise) before doing these steps.

Looking for docs on how to add Single Sign-On support in your Supabase project? Head on over to [Single Sign-On with SAML 2.0 for Projects](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml).

Supabase supports single sign-on (SSO) using Google Workspace (formerly known as G Suite).

## Step 1: Open the Google Workspace web and mobile apps console [\#](https://supabase.com/docs/guides/platform/sso/gsuite\#google-workspace-console)

![Google Workspace: Web and mobile apps admin console](https://supabase.com/docs/img/sso-gsuite-step-01.png)

## Step 2: Choose to add custom SAML app [\#](https://supabase.com/docs/guides/platform/sso/gsuite\#add-custom-saml-app)

From the _Add app_ button in the toolbar choose _Add custom SAML app_.

![Google Workspace: Web and mobile apps admin console, Add custom SAML app selected](https://supabase.com/docs/img/sso-gsuite-step-02.png)

## Step 3: Fill out app details [\#](https://supabase.com/docs/guides/platform/sso/gsuite\#add-app-details)

The information you enter here is for visibility into your Google Workspace. You can choose any values you like. `Supabase` as a name works well for most use cases. Optionally enter a description.

![Google Workspace: Web and mobile apps admin console, Add custom SAML, App details screen](https://supabase.com/docs/img/sso-gsuite-step-03.png)

## Step 4: Download IdP metadata [\#](https://supabase.com/docs/guides/platform/sso/gsuite\#download-idp-metadata)

This is a very important step. Click on _DOWNLOAD METADATA_ and save the file that was downloaded.

![Google Workspace: Web and mobile apps admin console, Add custom SAML, Google Identity Provider details screen](https://supabase.com/docs/img/sso-gsuite-step-04.png)

It's very important to send this file to your support contact at Supabase to complete the SSO setup process. If you're not sure where to send this file, you can always reach out to [Supabase Support](https://supabase.help/).

**Important: Make sure the certificate as shown on screen has at least 1 year before it expires. Mark down this date in your calendar so you will be reminded that you need to update the certificate without any downtime for your users.**

## Step 5: Add service provider details [\#](https://supabase.com/docs/guides/platform/sso/gsuite\#add-service-provider-details)

Fill out these service provider details on the next screen.

| Detail | Value |
| --- | --- |
| ACS URL | `https://alt.supabase.io/auth/v1/sso/saml/acs` |
| Entity ID | `https://alt.supabase.io/auth/v1/sso/saml/metadata` |
| Start URL | `https://supabase.com/dashboard` |
| Name ID format | PERSISTENT |
| Name ID | _Basic Information > Primary email_ |

![Google Workspace: Web and mobile apps admin console, Add custom SAML, Service provider details screen](https://supabase.com/docs/img/sso-gsuite-step-05.png)

## Step 6: Configure attribute mapping [\#](https://supabase.com/docs/guides/platform/sso/gsuite\#configure-attribute-mapping)

Attribute mappings allow Supabase to get information about your Google Workspace users on each login.

**A _Primary email_ to `email` mapping is required.** Other mappings shown below are optional and configurable depending on your Google Workspace setup. If in doubt, replicate the same config as shown.

Share any changes, if any, from this screen with your Supabase support contact.

![Google Workspace: Web and mobile apps admin console, Add custom SAML, Attribute mapping](https://supabase.com/docs/img/sso-gsuite-step-06.png)

## Step 7: Wait for confirmation [\#](https://supabase.com/docs/guides/platform/sso/gsuite\#confirmation)

Once youve configured the Google Workspace app as shown above, make sure you send the [metadata file you downloaded](https://supabase.com/docs/guides/platform/sso/gsuite#download-idp-metadata) and information regarding the [attribute mapping](https://supabase.com/docs/guides/platform/sso/gsuite#configure-attribute-mappings) (if any changes are applicable) to your support contact at Supabase.

This information needs to be entered into Supabase before SSO is activated end-to-end.

Wait for confirmation that this information has successfully been added to Supabase. It usually takes us 1 business day to configure this information for you.

## Step 8: Configure user access [\#](https://supabase.com/docs/guides/platform/sso/gsuite\#configure-user-access)

You can configure which Google Workspace user accounts will get access to Supabase. This is important if you wish to limit access to your software engineering teams.

You can configure this access by clicking on the _User access_ card (or down-arrow). Follow the instructions on screen.

Changes from this step sometimes take a while to propagate across Googles systems. Wait at least 15 minutes before proceeding to the next step.

![Google Workspace: Web and mobile apps admin console, Supabase app screen](https://supabase.com/docs/img/sso-gsuite-step-08.png)

## Step 9: Test single sign-on [\#](https://supabase.com/docs/guides/platform/sso/gsuite\#testing)

Once youve turned on access to Supabase for users in your organization, ask one of those users to help you out in testing the setup.

It often helps to ask them to log out of their Google account and log back in.

Ask them to enter their email address in the [Sign in with SSO](https://supabase.com/dashboard/sign-in-sso) page.

If sign in is not working correctly, reach out to your support contact at Supabase.

### Is this helpful?

NoYes

### On this page

[Step 1: Open the Google Workspace web and mobile apps console](https://supabase.com/docs/guides/platform/sso/gsuite#google-workspace-console) [Step 2: Choose to add custom SAML app](https://supabase.com/docs/guides/platform/sso/gsuite#add-custom-saml-app) [Step 3: Fill out app details](https://supabase.com/docs/guides/platform/sso/gsuite#add-app-details) [Step 4: Download IdP metadata](https://supabase.com/docs/guides/platform/sso/gsuite#download-idp-metadata) [Step 5: Add service provider details](https://supabase.com/docs/guides/platform/sso/gsuite#add-service-provider-details) [Step 6: Configure attribute mapping](https://supabase.com/docs/guides/platform/sso/gsuite#configure-attribute-mapping) [Step 7: Wait for confirmation](https://supabase.com/docs/guides/platform/sso/gsuite#confirmation) [Step 8: Configure user access](https://supabase.com/docs/guides/platform/sso/gsuite#configure-user-access) [Step 9: Test single sign-on](https://supabase.com/docs/guides/platform/sso/gsuite#testing)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_sso_okta.md">
Platform

# Set Up SSO with Okta

* * *

This feature is only available on the Team and Enterprise Plans. Contact [Sales](https://forms.supabase.com/enterprise) before doing these steps.

Looking for docs on how to add Single Sign-On support in your Supabase project? Head on over to [Single Sign-On with SAML 2.0 for Projects](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml).

Supabase supports single sign-on (SSO) using Okta.

## Step 1: Choose to create an app integration in the applications dashboard [\#](https://supabase.com/docs/guides/platform/sso/okta\#create-app-integration)

Navigate to the Applications dashboard of the Okta admin console. Click _Create App Integration_.

![Okta dashboard: Create App Integration button](https://supabase.com/docs/img/sso-okta-step-01.png)

## Step 2: Choose SAML 2.0 in the app integration dialog [\#](https://supabase.com/docs/guides/platform/sso/okta\#create-saml-app)

Supabase supports the SAML 2.0 SSO protocol. Choose it from the _Create a new app integration_ dialog.

![Okta dashboard: Create new app integration dialog](https://supabase.com/docs/img/sso-okta-step-02.png)

## Step 3: Fill out general settings [\#](https://supabase.com/docs/guides/platform/sso/okta\#add-general-settings)

The information you enter here is for visibility into your Okta applications menu. You can choose any values you like. `Supabase` as a name works well for most use cases.

![Okta dashboard: Create SAML Integration wizard](https://supabase.com/docs/img/sso-okta-step-03.png)

## Step 4: Fill out SAML settings [\#](https://supabase.com/docs/guides/platform/sso/okta\#add-saml-settings)

These settings let Supabase use SAML 2.0 properly with your Okta application. Make sure you enter this information exactly as shown on in this table and screenshot.

| Setting | Value |
| --- | --- |
| Single sign-on URL | `https://alt.supabase.io/auth/v1/sso/saml/acs` |
| Use this for Recipient URL and Destination URL |  |
| Audience URI (SP Entity ID) | `https://alt.supabase.io/auth/v1/sso/saml/metadata` |
| Default `RelayState` | `https://supabase.com/dashboard` |
| Name ID format | `EmailAddress` |
| Application username | Email |
| Update application username on | Create and update |

![Okta dashboard: Create SAML Integration wizard, Configure SAML step](https://supabase.com/docs/img/sso-okta-step-04.png)

## Step 5: Fill out attribute statements [\#](https://supabase.com/docs/guides/platform/sso/okta\#add-attribute-statements)

Attribute Statements allow Supabase to get information about your Okta users on each login.

**A `email` to `user.email` statement is required.** Other mappings shown below are optional and configurable depending on your Okta setup. If in doubt, replicate the same config as shown.

Share any changes, if any, from this screen with your Supabase support contact.

![Okta dashboard: Attribute Statements configuration screen](https://supabase.com/docs/img/sso-okta-step-05.png)

## Step 6: Obtain IdP metadata URL [\#](https://supabase.com/docs/guides/platform/sso/okta\#idp-metadata-url)

Supabase needs to finalize enabling single sign-on with your Okta application.

To do this scroll down to the _SAML Signing Certificates_ section on the _Sign On_ tab of the _Supabase_ application. Pick the the _SHA-2_ row with an _Active_ status. Click on the _Actions_ dropdown button and then on the _View IdP Metadata_.

This will open up the SAML 2.0 Metadata XML file in a new tab in your browser. Copy this URL and send it to your support contact and await further instructions. If you're not clear who to send this link to or need further assistance, contact [Supabase Support](https://supabase.help/).

The link usually has this structure: `https://<okta-org>.okta.com/apps/<app-id>/sso/saml/metadata`

![Okta dashboard: SAML Signing Certificates, Actions button highlighted](https://supabase.com/docs/img/sso-okta-step-06.png)

## Step 7: Wait for confirmation [\#](https://supabase.com/docs/guides/platform/sso/okta\#confirmation)

Once youve configured the Okta app as shown above, make sure you send the [metadata URL](https://supabase.com/docs/guides/platform/sso/okta#idp-metadata-url) and information regarding the [attribute statements](https://supabase.com/docs/guides/platform/sso/okta#add-attribute-statements) (if any changes are applicable) to your support contact at Supabase.

Wait for confirmation that this information has successfully been added to Supabase. It usually takes us 1 business day to configure this information for you.

## Step 8: Test single sign-on [\#](https://supabase.com/docs/guides/platform/sso/okta\#testing)

Once youve received confirmation from your support contact at Supabase that SSO setup has been completed for your enterprise, you can ask some of your users to sign in via their Okta account.

You ask them to enter their email address on the [Sign in with SSO](https://supabase.com/dashboard/sign-in-sso) page.

If sign in is not working correctly, reach out to your support contact at Supabase for further guidance.

### Is this helpful?

NoYes

### On this page

[Step 1: Choose to create an app integration in the applications dashboard](https://supabase.com/docs/guides/platform/sso/okta#create-app-integration) [Step 2: Choose SAML 2.0 in the app integration dialog](https://supabase.com/docs/guides/platform/sso/okta#create-saml-app) [Step 3: Fill out general settings](https://supabase.com/docs/guides/platform/sso/okta#add-general-settings) [Step 4: Fill out SAML settings](https://supabase.com/docs/guides/platform/sso/okta#add-saml-settings) [Step 5: Fill out attribute statements](https://supabase.com/docs/guides/platform/sso/okta#add-attribute-statements) [Step 6: Obtain IdP metadata URL](https://supabase.com/docs/guides/platform/sso/okta#idp-metadata-url) [Step 7: Wait for confirmation](https://supabase.com/docs/guides/platform/sso/okta#confirmation) [Step 8: Test single sign-on](https://supabase.com/docs/guides/platform/sso/okta#testing)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_sso.md">
Platform

# Enable SSO for Your Organization

* * *

Looking for docs on how to add Single Sign-On support in your Supabase project? Head on over to [Single Sign-On with SAML 2.0 for Projects](https://supabase.com/docs/guides/auth/enterprise-sso/auth-sso-saml).

Supabase offers single sign-on (SSO) as a login option to provide additional account security for your team. This allows company administrators to enforce the use of an identity provider when logging into Supabase. SSO improves the onboarding and offboarding experience of the company as the employee only needs a single set of credentials to access third-party applications or tools which can also be revoked by an administrator.

Supabase currently provides SAML SSO for [Team and Enterprise plan customers](https://supabase.com/pricing). Contact [Sales](https://forms.supabase.com/team) to have this enabled for your organization.

## Setup and limitations [\#](https://supabase.com/docs/guides/platform/sso\#setup-and-limitations)

Supabase supports practically all identity providers that support the SAML 2.0 SSO protocol. We've prepared these guides for commonly used identity providers to help you get started. If you use a different provider, our support stands ready to support you.

- [Google Workspaces (formerly G Suite)](https://supabase.com/docs/guides/platform/sso/gsuite)
- [Azure Active Directory](https://supabase.com/docs/guides/platform/sso/azure)
- [Okta](https://supabase.com/docs/guides/platform/sso/okta)

Accounts signing in with SSO have certain limitations.
The following sections outline the limitations when SSO is enabled or disabled for your team.

### Enable SSO for your team [\#](https://supabase.com/docs/guides/platform/sso\#enable-sso)

- Organization invites are restricted to company members belonging to the same identity provider.
- Every user has an organization created by default. They can create as many projects as they want.
- An SSO user will not be able to update or reset their password since the company administrator manages their access via the identity provider.
- If an SSO user with the following email of `alice@foocorp.com` attempts to sign in with a GitHub account that uses the same email, a separate Supabase account is created and will not be linked to the SSO user's account.
- An SSO user will not be able to see all organizations/projects created under the same identity provider. They will need to be invited to the Supabase organization first. Refer to [access control](https://supabase.com/docs/guides/platform/access-control) for more information.

### Disable SSO for your team [\#](https://supabase.com/docs/guides/platform/sso\#disable-sso)

- You can prevent a user's account from further access to Supabase by removing or disabling their account in your identity provider.
- You should also remove or downgrade their permissions from any organizations inside Supabase.

### Is this helpful?

NoYes

### On this page

[Setup and limitations](https://supabase.com/docs/guides/platform/sso#setup-and-limitations) [Enable SSO for your team](https://supabase.com/docs/guides/platform/sso#enable-sso) [Disable SSO for your team](https://supabase.com/docs/guides/platform/sso#disable-sso)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_upgrading.md">
Platform

# Upgrading

* * *

Supabase ships fast and we endeavor to add all new features to existing projects wherever possible. In some cases, access to new features require upgrading or migrating your Supabase project.

You can upgrade your project using `pg_upgrade` or by pausing and restoring your project.

## `pg_upgrade` [\#](https://supabase.com/docs/guides/platform/upgrading\#pgupgrade)

This upgrade method is currently in Beta.

For security purposes, passwords for custom roles are not backed up and, following a restore, they
would need to be reset. See [here](https://supabase.com/docs/guides/platform/backups#daily-backups) for more details

pg\_upgrade performs an in-place upgrade on your database. For projects larger than 1GB, pg\_upgrade is generally faster than a pause+restore cycle, and the speed advantage grows with the size of the database.

1. Plan for an appropriate downtime window, and ensure you have reviewed the [caveats](https://supabase.com/docs/guides/platform/upgrading#caveats) section of this document before executing the upgrade.
2. Use the "Upgrade project" button on the [Infrastructure](https://supabase.com/dashboard/project/_/settings/infrastructure) section of your dashboard.

Additionally, if a pg\_upgrade upgrade should fail, your original DB would be brought back up online and be able to service requests.

As a rough rule of thumb, pg\_upgrade operates at ~100mbps (when executing an upgrade on your data). Using the size of your database, you can use this metric to derive an approximate sense of the downtime window necessary for the upgrade. During this window, you should plan for your DB and associated services to be unavailable.

## Pause and restore [\#](https://supabase.com/docs/guides/platform/upgrading\#pause-and-restore)

We recommend using the pg\_upgrade method, as it is faster, and more reliable. Additionally, only Free-tier projects are eligible to use the Pause + Restore method.

When you pause and restore a project, the restored database includes the latest features. This method _does_ include downtime, so be aware that your project will be inaccessible for a short period of time.

1. On the [General Settings](https://supabase.com/dashboard/project/_/settings/general) page in the Dashboard, click **Pause project**. You will be redirected to the home screen as your project is pausing. This process can take several minutes.
2. After your project is paused, click **Restore project**. The restoration can take several minutes depending on how much data your database has. You will receive an email once the restoration is complete.

Note that a pause + restore upgrade involves tearing down your project's resources before bringing them back up again. If the restore process should fail, manual intervention from Supabase support will be required to bring your project back online.

### Caveats [\#](https://supabase.com/docs/guides/platform/upgrading\#caveats)

Regardless of the upgrade method, a few caveats apply:

#### Logical replication [\#](https://supabase.com/docs/guides/platform/upgrading\#logical-replication)

If you are using logical replication, the replication slots will not be preserved by the upgrade process. You will need to manually recreate them after the upgrade with the method `pg_create_logical_replication_slot`. Refer to the Postgres docs on [Replication Management Functions](https://www.postgresql.org/docs/current/functions-admin.html#FUNCTIONS-REPLICATION) for more details about the method.

#### Breaking changes [\#](https://supabase.com/docs/guides/platform/upgrading\#breaking-changes)

Newer versions of services can break functionality or change the performance characteristics you rely on. If your project is eligible for an upgrade, you will be able to find your current service versions from within [the Supabase dashboard](https://supabase.com/dashboard/project/_/settings/infrastructure).

Breaking changes are generally only present in major version upgrades of Postgres and PostgREST. You can find their respective release notes at:

- [Postgres](https://www.postgresql.org/docs/release/)
- [PostgREST](https://github.com/PostgREST/postgrest/releases)

If you are upgrading from a significantly older version, you will need to consider the release notes for any intermediary releases as well.

#### Time limits [\#](https://supabase.com/docs/guides/platform/upgrading\#time-limits)

Starting from 2024-06-24, when a project is paused, users then have a 90-day window to restore the project on the platform from within Supabase Studio.

The 90-day window allows Supabase to introduce platform changes that may not be backwards compatible with older backups. Unlike active projects, static backups can't be updated to accommodate such changes.

During the 90-day restore window a paused project can be restored to the platform with a single button click from [Studio's dashboard page](https://supabase.com/dashboard/projects).

![Project Paused: 90 Days Remaining](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fpaused-90-day.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

After the 90-day restore window, you can download your project's backup file, and Storage objects from the project dashboard. See [restoring a backup locally](https://supabase.com/docs/guides/platform/upgrading#restoring-a-downloaded-backup-locally) for instructions on how to load that backup locally to recover your data.

![Project Paused: 90 Days Remaining](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fpaused-dl-backup.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

If you upgrade to a paid plan while your project is paused, any expired one-click restore options are reenabled. Since the backup was taken outside the backwards compatibility window, it may fail to restore. If you have a problem restoring your backup after upgrading, contact [Support](https://supabase.com/support).

![Project Paused: 90 Days Remaining](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fpaused-paid-tier.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

#### Restoring a downloaded backup locally [\#](https://supabase.com/docs/guides/platform/upgrading\#restoring-a-downloaded-backup-locally)

If you want to restore your backup to a hosted Supabase project, you will need to use the
[Migrating within Supabase guide](https://supabase.com/docs/guides/platform/migrating-within-supabase)

If the 90 day project restore window has expired but you need to access data contained within your project using SQL, you can use the [Supabase CLI](https://supabase.com/docs/guides/local-development) to restore the project into a local Postgres instance.

First, download your project's backup file from dashboard and identify its backup image version (following the `PG:` prefix):

![Project Paused: 90 Days Remaining](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fpaused-dl-image-version.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

Given Postgres version `15.6.1.115`, start Postgres locally with `db_cluster.backup` being the path to your backup file.

`
supabase init
echo '15.6.1.115' > supabase/.temp/postgres-version
supabase db start --from-backup db_cluster.backup
`

Note that the earliest Supabase Postgres version that supports a local restore is `15.1.0.55`. If your hosted project was running on earlier versions, you will likely run into errors during restore. Before submitting any support ticket, make sure you have attached the error logs from `supabase_db_*` docker container.

Once your local database starts up successfully, you can connect using psql to verify that all your data is restored.

`
psql 'postgresql://postgres:postgres@localhost:54322/postgres'
`

If you want to use other services like Auth, Storage, and Studio dashboard together with your restored database, restart the local development stack.

`
supabase stop
supabase start
`

A Postgres database started with Supabase CLI is not production ready and should not be used outside of local development.

#### Disk sizing [\#](https://supabase.com/docs/guides/platform/upgrading\#disk-sizing)

When upgrading, the Supabase platform will "right-size" your disk based on the current size of the database. For example, if your database is 100GB in size, and you have a 200GB disk, the upgrade will reduce the disk size to 120GB (1.2x the size of your database).

#### Objects dependent on Postgres extensions [\#](https://supabase.com/docs/guides/platform/upgrading\#objects-dependent-on-postgres-extensions)

pg\_upgrade does not support upgrading of databases containing reg\* data types referencing system OIDs.
If you have created any objects that depend on the following extensions, you will need to recreate them after the upgrade.

#### `pg_cron` records [\#](https://supabase.com/docs/guides/platform/upgrading\#pgcron-records)

[pg\_cron](https://github.com/citusdata/pg_cron#viewing-job-run-details) does not automatically clean up historical records. This can lead to extremely large `cron.job_run_details` tables if the records are not regularly pruned; you should clean unnecessary records from this table prior to an upgrade.

During the `pg_upgrade` process, the `pg_cron` extension gets dropped and recreated. Prior to this process, the `cron.job_run_details` table is duplicated to avoid losing historical logs. The instantaneous disk pressure created by duplicating an extremely large details table can cause at best unnecessary performance degradation, or at worst, upgrade process failures.

#### Extensions [\#](https://supabase.com/docs/guides/platform/upgrading\#extensions)

pg\_upgrade does not currently support upgrading of databases using extensions older than the following versions:

- TimescaleDB 2.16.1
- plv8 3.1.10

To upgrade to a newer version of Postgres, you will need to drop the extensions before the upgrade, and recreate them after the upgrade.

#### Authentication method changes - deprecating md5 in favor of scram-sha-256 [\#](https://supabase.com/docs/guides/platform/upgrading\#authentication-method-changes---deprecating-md5-in-favor-of-scram-sha-256)

The md5 hashing method has [known weaknesses](https://en.wikipedia.org/wiki/MD5#Security) that make it unsuitable for cryptography.
As such, we are deprecating md5 in favor of [scram-sha-256](https://www.postgresql.org/docs/current/auth-password.html), which is the default and most secure authentication method used in the latest Postgres versions.

We automatically migrate Supabase-managed roles' passwords to scram-sha-256 during the upgrade process, but you will need to manually migrate the passwords of any custom roles you have created, else you won't be able to connect using them after the upgrade.

To identify roles using the md5 hashing method and migrate their passwords, you can use the following SQL statements after the upgrade:

`
-- List roles using md5 hashing method
SELECT
rolname
FROM pg_authid
WHERE rolcanlogin = true
AND rolpassword LIKE 'md5%';
-- Migrate a role's password to scram-sha-256
ALTER ROLE <role_name> WITH PASSWORD '<password>';
`

#### Database size reduction [\#](https://supabase.com/docs/guides/platform/upgrading\#database-size-reduction)

As part of the upgrade process, maintenance operations such as [vacuuming](https://www.postgresql.org/docs/current/routine-vacuuming.html#ROUTINE-VACUUMING) are also executed. This can result in a reduction in the reported database size.

#### Post-upgrade validation [\#](https://supabase.com/docs/guides/platform/upgrading\#post-upgrade-validation)

Supabase performs extensive pre- and post-upgrade validations to ensure that the database has been correctly upgraded. However, you should plan for your own application-level validations, as there might be changes you might not have anticipated, and this should be budgeted for when planning your downtime window.

### Is this helpful?

NoYes

### On this page

[pg\_upgrade](https://supabase.com/docs/guides/platform/upgrading#pgupgrade) [Pause and restore](https://supabase.com/docs/guides/platform/upgrading#pause-and-restore) [Caveats](https://supabase.com/docs/guides/platform/upgrading#caveats)

![Project Paused: 90 Days Remaining](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fpaused-90-day.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![Project Paused: 90 Days Remaining](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fpaused-dl-backup.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![Project Paused: 90 Days Remaining](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fpaused-paid-tier.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

![Project Paused: 90 Days Remaining](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fpaused-dl-image-version.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform_your_monthly_invoice.md">
Platform

# Your monthly invoice

* * *

## Billing cycle [\#](https://supabase.com/docs/guides/platform/your-monthly-invoice\#billing-cycle)

When you sign up for a paid plan you get charged once a month at the beginning of the billing cycle. A billing cycle starts with the creation of a Supabase organization. If you create an organization on the sixth of January your billing cycle resets on the sixth of each month. If the anchored day is not present in the current month, then the last day of the month is used.

## Your invoice explained [\#](https://supabase.com/docs/guides/platform/your-monthly-invoice\#your-invoice-explained)

When your billing cycle resets an invoice gets issued. That invoice contains line items from both the current and the previous billing cycle. Fixed fees for the current billing cycle, usage based fees for the previous billing cycle.

### Fixed fees [\#](https://supabase.com/docs/guides/platform/your-monthly-invoice\#fixed-fees)

Fixed fees are independent of usage and paid in-advance. Whether you have one or several projects, hundreds or millions of active users, the fee is always the same, and doesn't vary. Examples are the subscription fee, the fee for HIPAA and for priority support.

### Usage based fees [\#](https://supabase.com/docs/guides/platform/your-monthly-invoice\#usage-based-fees)

Fees vary depending on usage and are paid in arrears. The more usage you have, the higher the fee. Examples are fees for monthly active users and storage size.

### Discounted line items [\#](https://supabase.com/docs/guides/platform/your-monthly-invoice\#discounted-line-items)

Paid plans come with a usage quota for certain line items. You only pay for usage that goes beyond the quota. The quota for Storage for example is 100 GB. If you use 105 GB, you pay for 5 GB. If you use 95 GB, you pay nothing. This quota is declared as a discount on your invoice.

#### Compute Credits [\#](https://supabase.com/docs/guides/platform/your-monthly-invoice\#compute-credits)

Paid plans come with $10 in Compute Credits per month. This suffices for a single project using a Nano or Micro compute instance. Every additional project adds compute fees to your monthly invoice though.

### Example invoice [\#](https://supabase.com/docs/guides/platform/your-monthly-invoice\#example-invoice)

The following invoice was issued on January 6, 2025 with the previous billing cycle from December 6, 2024 - January 5, 2025, and the current billing cycle from January 6 - February 5, 2025.

![Example Invoice](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fexample-invoice.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

1. The final amount due
2. Fixed subscription fee for the current billing cycle
3. Usage based fee for Compute for the previous billing cycle. There were two projects ( `wsmmedyqtlrvbcesxdew`, `wwxdpovgtfcmcnxwsaad`) running 744 hours (24 hours \* 31 days). These projects incurred $10 in Compute fees each. With $10 in Compute Credits deducted, the final Compute fees are $10.
4. Usage based fee for Custom Domain for the previous billing cycle. There is no free usage quota for Custom Domain. You get charged for the 744 hours (24 hours \* 31 days) a Custom Domain was active. The final Custom Domain fees are $10.19.
5. Usage based fee for Egress for the previous billing cycle. There is a free usage quota of 250 GB for Egress. You get charged for usage beyond 250 GB only, meaning for 2,119.47 GB. The final Egress fees are $190.75.
6. Usage based fee for Monthly Active Users for the previous billing cycle. There is a free usage quota of 100,000 users. With 141 users there is no charge for this line item.

### Why is my invoice more than $25? [\#](https://supabase.com/docs/guides/platform/your-monthly-invoice\#why-is-my-invoice-more-than-25)

The amount due of your invoice being higher than the $25 subscription fee for the Pro Plan can have several reasons.

- **Running several projects:** You had more than one project running in the previous billing cycle. Supabase provides a dedicated server and database for every project. That means that every project you launch incurs compute costs. While the $10 Compute Credits cover a single project using a Nano or Micro compute instance, every additional project adds at least $10 compute costs to your invoice.
- **Usage beyond quota:** You exceeded the included usage quota for one or more line items in the previous billing cycle while having the Spend Cap disabled.
- **Usage that is not covered by the Spend Cap:** You had usage in the previous billing cycle that is not covered by the [Spend Cap](https://supabase.com/docs/guides/platform/cost-control#spend-cap). For example using an IPv4 address or a custom domain.

## How to settle your invoices [\#](https://supabase.com/docs/guides/platform/your-monthly-invoice\#how-to-settle-your-invoices)

Monthly invoices are auto-collected by charging the payment method marked as "active" for an organization.

### Payment failure [\#](https://supabase.com/docs/guides/platform/your-monthly-invoice\#payment-failure)

If your payment fails, Supabase retries the charge several times. We send you a Payment Failure email with the reason for the failure. Follow the steps outlined in this email. You can manually trigger a charge at any time via

- the link in the Payment Failure email
- the "Pay Now" button on the [organization's invoices page](https://supabase.com/dashboard/org/_/invoices)

## Where to find your invoices [\#](https://supabase.com/docs/guides/platform/your-monthly-invoice\#where-to-find-your-invoices)

Your invoice is sent to you via email. You can also find your invoices on the [organization's invoices page](https://supabase.com/dashboard/org/_/invoices).

### Is this helpful?

NoYes

### On this page

[Billing cycle](https://supabase.com/docs/guides/platform/your-monthly-invoice#billing-cycle) [Your invoice explained](https://supabase.com/docs/guides/platform/your-monthly-invoice#your-invoice-explained) [Fixed fees](https://supabase.com/docs/guides/platform/your-monthly-invoice#fixed-fees) [Usage based fees](https://supabase.com/docs/guides/platform/your-monthly-invoice#usage-based-fees) [Discounted line items](https://supabase.com/docs/guides/platform/your-monthly-invoice#discounted-line-items) [Example invoice](https://supabase.com/docs/guides/platform/your-monthly-invoice#example-invoice) [Why is my invoice more than $25?](https://supabase.com/docs/guides/platform/your-monthly-invoice#why-is-my-invoice-more-than-25) [How to settle your invoices](https://supabase.com/docs/guides/platform/your-monthly-invoice#how-to-settle-your-invoices) [Payment failure](https://supabase.com/docs/guides/platform/your-monthly-invoice#payment-failure) [Where to find your invoices](https://supabase.com/docs/guides/platform/your-monthly-invoice#where-to-find-your-invoices)

![Example Invoice](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Fplatform%2Fexample-invoice.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_platform.md">
Platform

# Supabase Platform

* * *

Supabase is a hosted platform which makes it very simple to get started without needing to manage any infrastructure.

Visit [supabase.com/dashboard](https://supabase.com/dashboard) and sign in to start creating projects.

## Projects [\#](https://supabase.com/docs/guides/platform\#projects)

Each project on Supabase comes with:

- A dedicated [Postgres database](https://supabase.com/docs/guides/database)
- [Auto-generated APIs](https://supabase.com/docs/guides/database/api)
- [Auth and user management](https://supabase.com/docs/guides/auth)
- [Edge Functions](https://supabase.com/docs/guides/functions)
- [Realtime API](https://supabase.com/docs/guides/realtime)
- [Storage](https://supabase.com/docs/guides/storage)

## Organizations [\#](https://supabase.com/docs/guides/platform\#organizations)

Organizations are a way to group your projects. Each organization can be configured with different team members and billing settings.
Refer to [access control](https://supabase.com/docs/guides/platform/access-control) for more information on how to manage team members within an organization.

## Platform status [\#](https://supabase.com/docs/guides/platform\#platform-status)

If Supabase experiences outages, we keep you as informed as possible, as early as possible. We provide the following feedback channels:

- Status page: [status.supabase.com](https://status.supabase.com/)
- RSS Feed: [status.supabase.com/history.rss](https://status.supabase.com/history.rss)
- Atom Feed: [status.supabase.com/history.atom](https://status.supabase.com/history.atom)
- Slack Alerts: You can receive updates via the RSS feed, using Slack's [built-in RSS functionality](https://slack.com/help/articles/218688467-Add-RSS-feeds-to-Slack)

`/feed subscribe https://status.supabase.com/history.atom`

Make sure to review our [SLA](https://supabase.com/docs/company/sla) for details on our commitment to Platform Stability.

### Is this helpful?

NoYes

### On this page

[Projects](https://supabase.com/docs/guides/platform#projects) [Organizations](https://supabase.com/docs/guides/platform#organizations) [Platform status](https://supabase.com/docs/guides/platform#platform-status)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_queues_api.md">
Queues

# API

* * *

When you create a Queue in Supabase, you can choose to create helper database functions in the `pgmq_public` schema. This schema exposes operations to manage Queue Messages to consumers client-side, but does not expose functions for creating or dropping Queues.

Database functions in `pgmq_public` can be exposed via Supabase Data API so consumers client-side can call them. Visit the [Quickstart](https://supabase.com/docs/guides/queues/quickstart) for an example.

### `pgmq_public.pop(queue_name)` [\#](https://supabase.com/docs/guides/queues/api\#pgmqpublicpopqueuename)

Retrieves the next available message and deletes it from the specified Queue.

- `queue_name` ( `text`): Queue name

* * *

### `pgmq_public.send(queue_name, message, sleep_seconds)` [\#](https://supabase.com/docs/guides/queues/api\#pgmqpublicsendqueuename-message-sleepseconds)

Adds a Message to the specified Queue, optionally delaying its visibility to all consumers by a number of seconds.

- `queue_name` ( `text`): Queue name
- `message` ( `jsonb`): Message payload to send
- `sleep_seconds` ( `integer`, optional): Delay message visibility by specified seconds. Defaults to 0

* * *

### `pgmq_public.send_batch(queue_name, messages, sleep_seconds)` [\#](https://supabase.com/docs/guides/queues/api\#pgmqpublicsendbatchqueuename-messages-sleepseconds)

Adds a batch of Messages to the specified Queue, optionally delaying their availability to all consumers by a number of seconds.

- `queue_name` ( `text`): Queue name
- `messages` ( `jsonb[]`): Array of message payloads to send
- `sleep_seconds` ( `integer`, optional): Delay messages visibility by specified seconds. Defaults to 0

* * *

### `pgmq_public.archive(queue_name, message_id)` [\#](https://supabase.com/docs/guides/queues/api\#pgmqpublicarchivequeuename-messageid)

Archives a Message by moving it from the Queue table to the Queue's archive table.

- `queue_name` ( `text`): Queue name
- `message_id` ( `bigint`): ID of the Message to archive

* * *

### `pgmq_public.delete(queue_name, message_id)` [\#](https://supabase.com/docs/guides/queues/api\#pgmqpublicdeletequeuename-messageid)

Permanently deletes a Message from the specified Queue.

- `queue_name` ( `text`): Queue name
- `message_id` ( `bigint`): ID of the Message to delete

* * *

### `pgmq_public.read(queue_name, sleep_seconds, n)` [\#](https://supabase.com/docs/guides/queues/api\#pgmqpublicreadqueuename-sleepseconds-n)

Reads up to "n" Messages from the specified Queue with an optional "sleep\_seconds" (visibility timeout).

- `queue_name` ( `text`): Queue name
- `sleep_seconds` ( `integer`): Visibility timeout in seconds
- `n` ( `integer`): Maximum number of Messages to read

### Is this helpful?

NoYes

### On this page

[pgmq\_public.pop(queue\_name)](https://supabase.com/docs/guides/queues/api#pgmqpublicpopqueuename) [pgmq\_public.send(queue\_name, message, sleep\_seconds)](https://supabase.com/docs/guides/queues/api#pgmqpublicsendqueuename-message-sleepseconds) [pgmq\_public.send\_batch(queue\_name, messages, sleep\_seconds)](https://supabase.com/docs/guides/queues/api#pgmqpublicsendbatchqueuename-messages-sleepseconds) [pgmq\_public.archive(queue\_name, message\_id)](https://supabase.com/docs/guides/queues/api#pgmqpublicarchivequeuename-messageid) [pgmq\_public.delete(queue\_name, message\_id)](https://supabase.com/docs/guides/queues/api#pgmqpublicdeletequeuename-messageid) [pgmq\_public.read(queue\_name, sleep\_seconds, n)](https://supabase.com/docs/guides/queues/api#pgmqpublicreadqueuename-sleepseconds-n)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_queues_pgmq.md">
Queues

# PGMQ Extension

* * *

pgmq is a lightweight message queue built on Postgres.

## Features [\#](https://supabase.com/docs/guides/queues/pgmq\#features)

- Lightweight - No background worker or external dependencies, just Postgres functions packaged in an extension
- "exactly once" delivery of messages to a consumer within a visibility timeout
- API parity with AWS SQS and RSMQ
- Messages stay in the queue until explicitly removed
- Messages can be archived, instead of deleted, for long-term retention and replayability

## Enable the extension [\#](https://supabase.com/docs/guides/queues/pgmq\#enable-the-extension)

`
create extension pgmq;
`

## Usage [\#](https://supabase.com/docs/guides/queues/pgmq\#get-usage)

### Queue management [\#](https://supabase.com/docs/guides/queues/pgmq\#queue-management)

#### `create` [\#](https://supabase.com/docs/guides/queues/pgmq\#create)

Create a new queue.

`
pgmq.create(queue_name text)
returns void
`

**Parameters:**

| Parameter | Type | Description |
| :-- | :-- | :-- |
| queue\_name | text | The name of the queue |

Example:

`
select from pgmq.create('my_queue');
create
--------
`

#### `create_unlogged` [\#](https://supabase.com/docs/guides/queues/pgmq\#createunlogged)

Creates an unlogged table. This is useful when write throughput is more important than durability.
See Postgres documentation for [unlogged tables](https://www.postgresql.org/docs/current/sql-createtable.html#SQL-CREATETABLE-UNLOGGED) for more information.

`
pgmq.create_unlogged(queue_name text)
returns void
`

**Parameters:**

| Parameter | Type | Description |
| :-- | :-- | :-- |
| queue\_name | text | The name of the queue |

Example:

`
select pgmq.create_unlogged('my_unlogged');
create_unlogged
-----------------
`

* * *

#### `detach_archive` [\#](https://supabase.com/docs/guides/queues/pgmq\#detacharchive)

Drop the queue's archive table as a member of the PGMQ extension. Useful for preventing the queue's archive table from being drop when `drop extension pgmq` is executed.
This does not prevent the further archives() from appending to the archive table.

`
pgmq.detach_archive(queue_name text)
`

**Parameters:**

| Parameter | Type | Description |
| :-- | :-- | :-- |
| queue\_name | text | The name of the queue |

Example:

`
select * from pgmq.detach_archive('my_queue');
detach_archive
----------------
`

* * *

#### `drop_queue` [\#](https://supabase.com/docs/guides/queues/pgmq\#dropqueue)

Deletes a queue and its archive table.

`
pgmq.drop_queue(queue_name text)
returns boolean
`

**Parameters:**

| Parameter | Type | Description |
| :-- | :-- | :-- |
| queue\_name | text | The name of the queue |

Example:

`
select * from pgmq.drop_queue('my_unlogged');
drop_queue
------------
t
`

### Sending messages [\#](https://supabase.com/docs/guides/queues/pgmq\#sending-messages)

#### `send` [\#](https://supabase.com/docs/guides/queues/pgmq\#send)

Send a single message to a queue.

`
pgmq.send(
    queue_name text,
    msg jsonb,
    delay integer default 0
)
returns setof bigint
`

**Parameters:**

| Parameter | Type | Description |
| :-- | :-- | :-- |
| `queue_name` | `text` | The name of the queue |
| `msg` | `jsonb` | The message to send to the queue |
| `delay` | `integer` | Time in seconds before the message becomes visible. Defaults to 0. |

Example:

`
select * from pgmq.send('my_queue', '{"hello": "world"}');
send
------
    4
`

* * *

#### `send_batch` [\#](https://supabase.com/docs/guides/queues/pgmq\#sendbatch)

Send 1 or more messages to a queue.

`
pgmq.send_batch(
    queue_name text,
    msgs jsonb[],
    delay integer default 0
)
returns setof bigint
`

**Parameters:**

| Parameter | Type | Description |
| :-- | :-- | :-- |
| `queue_name` | `text` | The name of the queue |
| `msgs` | `jsonb[]` | Array of messages to send to the queue |
| `delay` | `integer` | Time in seconds before the messages becomes visible. Defaults to 0. |

`
select * from pgmq.send_batch(
    'my_queue',
    array[\
      '{"hello": "world_0"}'::jsonb,\
      '{"hello": "world_1"}'::jsonb\
    ]
);
send_batch
------------
          1
          2
`

* * *

### Reading messages [\#](https://supabase.com/docs/guides/queues/pgmq\#reading-messages)

#### `read` [\#](https://supabase.com/docs/guides/queues/pgmq\#read)

Read 1 or more messages from a queue. The VT specifies the delay in seconds between reading and the message becoming invisible to other consumers.

`
pgmq.read(
    queue_name text,
    vt integer,
    qty integer
)
returns setof pgmq.message_record
`

**Parameters:**

| Parameter | Type | Description |
| :-- | :-- | :-- |
| `queue_name` | `text` | The name of the queue |
| `vt` | `integer` | Time in seconds that the message become invisible after reading |
| `qty` | `integer` | The number of messages to read from the queue. Defaults to 1 |

Example:

`
select * from pgmq.read('my_queue', 10, 2);
msg_id | read_ct |          enqueued_at          |              vt               |       message
--------+---------+-------------------------------+-------------------------------+----------------------
      1 |       1 | 2023-10-28 19:14:47.356595-05 | 2023-10-28 19:17:08.608922-05 | {"hello": "world_0"}
      2 |       1 | 2023-10-28 19:14:47.356595-05 | 2023-10-28 19:17:08.608974-05 | {"hello": "world_1"}
(2 rows)
`

* * *

#### `read_with_poll` [\#](https://supabase.com/docs/guides/queues/pgmq\#readwithpoll)

Same as read(). Also provides convenient long-poll functionality.
When there are no messages in the queue, the function call will wait for `max_poll_seconds` in duration before returning.
If messages reach the queue during that duration, they will be read and returned immediately.

`
pgmq.read_with_poll(
    queue_name text,
    vt integer,
    qty integer,
    max_poll_seconds integer default 5,
    poll_interval_ms integer default 100
)
returns setof pgmq.message_record
`

**Parameters:**

| Parameter | Type | Description |
| :-- | :-- | :-- |
| `queue_name` | `text` | The name of the queue |
| `vt` | `integer` | Time in seconds that the message become invisible after reading. |
| `qty` | `integer` | The number of messages to read from the queue. Defaults to 1. |
| `max_poll_seconds` | `integer` | Time in seconds to wait for new messages to reach the queue. Defaults to 5. |
| `poll_interval_ms` | `integer` | Milliseconds between the internal poll operations. Defaults to 100. |

Example:

`
select * from pgmq.read_with_poll('my_queue', 1, 1, 5, 100);
msg_id | read_ct |          enqueued_at          |              vt               |      message
--------+---------+-------------------------------+-------------------------------+--------------------
      1 |       1 | 2023-10-28 19:09:09.177756-05 | 2023-10-28 19:27:00.337929-05 | {"hello": "world"}
`

* * *

#### `pop` [\#](https://supabase.com/docs/guides/queues/pgmq\#pop)

Reads a single message from a queue and deletes it upon read.

Note: utilization of pop() results in at-most-once delivery semantics if the consuming application does not guarantee processing of the message.

`
pgmq.pop(queue_name text)
returns setof pgmq.message_record
`

**Parameters:**

| Parameter | Type | Description |
| :-- | :-- | :-- |
| queue\_name | text | The name of the queue |

Example:

`
pgmq=# select * from pgmq.pop('my_queue');
msg_id | read_ct |          enqueued_at          |              vt               |      message
--------+---------+-------------------------------+-------------------------------+--------------------
      1 |       2 | 2023-10-28 19:09:09.177756-05 | 2023-10-28 19:27:00.337929-05 | {"hello": "world"}
`

* * *

### Deleting/Archiving messages [\#](https://supabase.com/docs/guides/queues/pgmq\#deletingarchiving-messages)

#### `delete` (single) [\#](https://supabase.com/docs/guides/queues/pgmq\#delete-single)

Deletes a single message from a queue.

`
pgmq.delete (queue_name text, msg_id: bigint)
returns boolean
`

**Parameters:**

| Parameter | Type | Description |
| :-- | :-- | :-- |
| `queue_name` | `text` | The name of the queue |
| `msg_id` | `bigint` | Message ID of the message to delete |

Example:

`
select pgmq.delete('my_queue', 5);
delete
--------
t
`

* * *

#### `delete` (batch) [\#](https://supabase.com/docs/guides/queues/pgmq\#delete-batch)

Delete one or many messages from a queue.

`
pgmq.delete (queue_name text, msg_ids: bigint[])
returns setof bigint
`

**Parameters:**

| Parameter | Type | Description |
| :-- | :-- | :-- |
| `queue_name` | `text` | The name of the queue |
| `msg_ids` | `bigint[]` | Array of message IDs to delete |

Examples:

Delete two messages that exist.

`
select * from pgmq.delete('my_queue', array[2, 3]);
delete
--------
      2
      3
`

Delete two messages, one that exists and one that does not. Message `999` does not exist.

`
select * from pgmq.delete('my_queue', array[6, 999]);
delete
--------
      6
`

* * *

#### `purge_queue` [\#](https://supabase.com/docs/guides/queues/pgmq\#purgequeue)

Permanently deletes all messages in a queue. Returns the number of messages that were deleted.

`
purge_queue(queue_name text)
returns bigint
`

**Parameters:**

| Parameter | Type | Description |
| :-- | :-- | :-- |
| queue\_name | text | The name of the queue |

Example:

Purge the queue when it contains 8 messages;

`
select * from pgmq.purge_queue('my_queue');
purge_queue
-------------
           8
`

* * *

#### `archive` (single) [\#](https://supabase.com/docs/guides/queues/pgmq\#archive-single)

Removes a single requested message from the specified queue and inserts it into the queue's archive.

`
pgmq.archive(queue_name text, msg_id bigint)
returns boolean
`

**Parameters:**

| Parameter | Type | Description |
| :-- | :-- | :-- |
| `queue_name` | `text` | The name of the queue |
| `msg_id` | `bigint` | Message ID of the message to archive |

Returns
Boolean value indicating success or failure of the operation.

Example; remove message with ID 1 from queue `my_queue` and archive it:

`
select * from pgmq.archive('my_queue', 1);
archive
---------
       t
`

* * *

#### `archive` (batch) [\#](https://supabase.com/docs/guides/queues/pgmq\#archive-batch)

Deletes a batch of requested messages from the specified queue and inserts them into the queue's archive.
Returns an array of message ids that were successfully archived.

`
pgmq.archive(queue_name text, msg_ids bigint[])
RETURNS SETOF bigint
`

**Parameters:**

| Parameter | Type | Description |
| :-- | :-- | :-- |
| `queue_name` | `text` | The name of the queue |
| `msg_ids` | `bigint[]` | Array of message IDs to archive |

Examples:

Delete messages with ID 1 and 2 from queue `my_queue` and move to the archive.

`
select * from pgmq.archive('my_queue', array[1, 2]);
archive
---------
       1
       2
`

Delete messages 4, which exists and 999, which does not exist.

`
select * from pgmq.archive('my_queue', array[4, 999]);
archive
---------
       4
`

* * *

### Utilities [\#](https://supabase.com/docs/guides/queues/pgmq\#utilities)

#### `set_vt` [\#](https://supabase.com/docs/guides/queues/pgmq\#setvt)

Sets the visibility timeout of a message to a specified time duration in the future. Returns the record of the message that was updated.

`
pgmq.set_vt(
    queue_name text,
    msg_id bigint,
    vt_offset integer
)
returns pgmq.message_record
`

**Parameters:**

| Parameter | Type | Description |
| :-- | :-- | :-- |
| `queue_name` | `text` | The name of the queue |
| `msg_id` | `bigint` | ID of the message to set visibility time |
| `vt_offset` | `integer` | Duration from now, in seconds, that the message's VT should be set to |

Example:

Set the visibility timeout of message 1 to 30 seconds from now.

`
select * from pgmq.set_vt('my_queue', 11, 30);
msg_id | read_ct |          enqueued_at          |              vt               |       message
--------+---------+-------------------------------+-------------------------------+----------------------
     1 |       0 | 2023-10-28 19:42:21.778741-05 | 2023-10-28 19:59:34.286462-05 | {"hello": "world_0"}
`

* * *

#### `list_queues` [\#](https://supabase.com/docs/guides/queues/pgmq\#listqueues)

List all the queues that currently exist.

`
list_queues()
RETURNS TABLE(
    queue_name text,
    created_at timestamp with time zone,
    is_partitioned boolean,
    is_unlogged boolean
)
`

Example:

`
select * from pgmq.list_queues();
      queue_name      |          created_at           | is_partitioned | is_unlogged
----------------------+-------------------------------+----------------+-------------
my_queue             | 2023-10-28 14:13:17.092576-05 | f              | f
my_partitioned_queue | 2023-10-28 19:47:37.098692-05 | t              | f
my_unlogged          | 2023-10-28 20:02:30.976109-05 | f              | t
`

* * *

#### `metrics` [\#](https://supabase.com/docs/guides/queues/pgmq\#metrics)

Get metrics for a specific queue.

`
pgmq.metrics(queue_name: text)
returns table(
    queue_name text,
    queue_length bigint,
    newest_msg_age_sec integer,
    oldest_msg_age_sec integer,
    total_messages bigint,
    scrape_time timestamp with time zone
)
`

**Parameters:**

| Parameter | Type | Description |
| :-- | :-- | :-- |
| queue\_name | text | The name of the queue |

**Returns:**

\| Attribute \| Type \| Description \|
\| :\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\- \| :\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\- \| :\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\- \| \-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\- \|
\| `queue_name` \| `text` \| The name of the queue \|
\| `queue_length` \| `bigint` \| Number of messages currently in the queue \|
\| `newest_msg_age_sec` \| `integer                   | null` \| Age of the newest message in the queue, in seconds \|
\| `oldest_msg_age_sec` \| `integer                   | null` \| Age of the oldest message in the queue, in seconds \|
\| `total_messages` \| `bigint` \| Total number of messages that have passed through the queue over all time \|
\| `scrape_time` \| `timestamp with time zone` \| The current timestamp \|

Example:

`
select * from pgmq.metrics('my_queue');
queue_name | queue_length | newest_msg_age_sec | oldest_msg_age_sec | total_messages |          scrape_time
------------+--------------+--------------------+--------------------+----------------+-------------------------------
my_queue   |           16 |               2445 |               2447 |             35 | 2023-10-28 20:23:08.406259-05
`

* * *

#### `metrics_all` [\#](https://supabase.com/docs/guides/queues/pgmq\#metricsall)

Get metrics for all existing queues.

`
pgmq.metrics_all()
RETURNS TABLE(
    queue_name text,
    queue_length bigint,
    newest_msg_age_sec integer,
    oldest_msg_age_sec integer,
    total_messages bigint,
    scrape_time timestamp with time zone
)
`

**Returns:**

\| Attribute \| Type \| Description \|
\| :\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\- \| :\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\- \| :\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\- \| \-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\- \|
\| `queue_name` \| `text` \| The name of the queue \|
\| `queue_length` \| `bigint` \| Number of messages currently in the queue \|
\| `newest_msg_age_sec` \| `integer                   | null` \| Age of the newest message in the queue, in seconds \|
\| `oldest_msg_age_sec` \| `integer                   | null` \| Age of the oldest message in the queue, in seconds \|
\| `total_messages` \| `bigint` \| Total number of messages that have passed through the queue over all time \|
\| `scrape_time` \| `timestamp with time zone` \| The current timestamp \|

`
select * from pgmq.metrics_all();
      queue_name      | queue_length | newest_msg_age_sec | oldest_msg_age_sec | total_messages |          scrape_time
----------------------+--------------+--------------------+--------------------+----------------+-------------------------------
my_queue             |           16 |               2563 |               2565 |             35 | 2023-10-28 20:25:07.016413-05
my_partitioned_queue |            1 |                 11 |                 11 |              1 | 2023-10-28 20:25:07.016413-05
my_unlogged          |            1 |                  3 |                  3 |              1 | 2023-10-28 20:25:07.016413-05
`

### Types [\#](https://supabase.com/docs/guides/queues/pgmq\#types)

#### `message_record` [\#](https://supabase.com/docs/guides/queues/pgmq\#messagerecord)

The complete representation of a message in a queue.

| Attribute Name | Type | Description |
| :-- | :-- | :-- |
| `msg_id` | `bigint` | Unique ID of the message |
| `read_ct` | `bigint` | Number of times the message has been read. Increments on read(). |
| `enqueued_at` | `timestamp with time zone` | time that the message was inserted into the queue |
| `vt` | `timestamp with time zone` | Timestamp when the message will become available for consumers to read |
| `message` | `jsonb` | The message payload |

Example:

`
msg_id | read_ct |          enqueued_at          |              vt               |      message
--------+---------+-------------------------------+-------------------------------+--------------------
      1 |       1 | 2023-10-28 19:06:19.941509-05 | 2023-10-28 19:06:27.419392-05 | {"hello": "world"}
`

## Resources [\#](https://supabase.com/docs/guides/queues/pgmq\#resources)

- Official Docs: [pgmq/api](https://tembo.io/pgmq/#creating-a-queue)

### Is this helpful?

NoYes

### On this page

[Features](https://supabase.com/docs/guides/queues/pgmq#features) [Enable the extension](https://supabase.com/docs/guides/queues/pgmq#enable-the-extension) [Usage](https://supabase.com/docs/guides/queues/pgmq#get-usage) [Queue management](https://supabase.com/docs/guides/queues/pgmq#queue-management) [Sending messages](https://supabase.com/docs/guides/queues/pgmq#sending-messages) [Reading messages](https://supabase.com/docs/guides/queues/pgmq#reading-messages) [Deleting/Archiving messages](https://supabase.com/docs/guides/queues/pgmq#deletingarchiving-messages) [Utilities](https://supabase.com/docs/guides/queues/pgmq#utilities) [Types](https://supabase.com/docs/guides/queues/pgmq#types) [Resources](https://supabase.com/docs/guides/queues/pgmq#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_queues_quickstart.md">
Queues

# Quickstart

## Learn how to use Supabase Queues to add and read messages

* * *

This guide is an introduction to interacting with Supabase Queues via the Dashboard and official client library. Check out [Queues API Reference](https://supabase.com/docs/guides/queues/api) for more details on our API.

## Concepts [\#](https://supabase.com/docs/guides/queues/quickstart\#concepts)

Supabase Queues is a pull-based Message Queue consisting of three main components: Queues, Messages, and Queue Types.

### Pull-Based Queue [\#](https://supabase.com/docs/guides/queues/quickstart\#pull-based-queue)

A pull-based Queue is a Message storage and delivery system where consumers actively fetch Messages when they're ready to process them - similar to constantly refreshing a webpage to display the latest updates. Our pull-based Queues process Messages in a First-In-First-Out (FIFO) manner without priority levels.

### Message [\#](https://supabase.com/docs/guides/queues/quickstart\#message)

A Message in a Queue is a JSON object that is stored until a consumer explicitly processes and removes it, like a task waiting in a to-do list until someone checks and completes it.

### Queue types [\#](https://supabase.com/docs/guides/queues/quickstart\#queue-types)

Supabase Queues offers three types of Queues:

- **Basic Queue**: A durable Queue that stores Messages in a logged table.

- **Unlogged Queue**: A transient Queue that stores Messages in an unlogged table for better performance but may result in loss of Queue Messages.

- **Partitioned Queue** ( _Coming Soon_): A durable and scalable Queue that stores Messages in multiple table partitions for better performance.


## Create Queues [\#](https://supabase.com/docs/guides/queues/quickstart\#create-queues)

To get started, navigate to the [Supabase Queues](https://supabase.com/dashboard/project/_/integrations/queues/overview) Postgres Module under Integrations in the Dashboard and enable the `pgmq` extension.

`pgmq` extension is available in Postgres version 15.6.1.143 or later.

![Supabase Dashboard Integrations page, showing the Queues Postgres Module](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fqueues-quickstart-install.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

On the [Queues page](https://supabase.com/dashboard/project/_/integrations/queues/queues):

- Click **Add a new queue** button

If you've already created a Queue click the **Create a queue** button instead.

- Name your queue

Queue names can only be lowercase and hyphens and underscores are permitted.

- Select your [Queue Type](https://supabase.com/docs/guides/queues/quickstart#queue-types)

![Create a Queue from the Supabase Dashboard](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fqueues-quickstart-create.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### What happens when you create a queue? [\#](https://supabase.com/docs/guides/queues/quickstart\#what-happens-when-you-create-a-queue)

Every new Queue creates two tables in the `pgmq` schema. These tables are `pgmq.q_<queue_name>` to store and process active messages and `pgmq.a_<queue_name>` to store any archived messages.

A "Basic Queue" will create `pgmq.q_<queue_name>` and `pgmq.a_<queue_name>` tables as logged tables.

However, an "Unlogged Queue" will create `pgmq.q_<queue_name>` as an unlogged table for better performance while sacrificing durability. The `pgmq.a_<queue_name>` table will still be created as a logged table so your archived messages remain safe and secure.

## Expose Queues to client-side consumers [\#](https://supabase.com/docs/guides/queues/quickstart\#expose-queues-to-client-side-consumers)

Queues, by default, are not exposed over Supabase Data API and are only accessible via Postgres clients.

However, you may grant client-side consumers access to your Queues by enabling the Supabase Data API and granting permissions to the Queues API, which is a collection of database functions in the `pgmq_public` schema that wraps the database functions in the `pgmq` schema.

This is to prevent direct access to the `pgmq` schema and its tables (RLS is not enabled by default on any tables) and database functions.

To get started, navigate to the Queues [Settings page](https://supabase.com/dashboard/project/_/integrations/queues/settings) and toggle on Expose Queues via PostgREST. Once enabled, Supabase creates and exposes a `pgmq_public` schema containing database function wrappers to a subset of `pgmq`'s database functions.

![Screenshot of Queues settings with toggle to expose to PostgREST](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fqueues-quickstart-settings.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Enable RLS on your tables in `pgmq` schema [\#](https://supabase.com/docs/guides/queues/quickstart\#enable-rls-on-your-tables-in-pgmq-schema)

For security purposes, you must enable Row Level Security (RLS) on all Queue tables (all tables in `pgmq` schema that begin with `q_`) if the Data API is enabled.

Youll want to create RLS policies for any Queues you want your client-side consumers to interact with.

![Screenshot of creating an RLS policy from the Queues settings](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fqueues-quickstart-rls.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Grant permissions to `pgmq_public` database functions [\#](https://supabase.com/docs/guides/queues/quickstart\#grant-permissions-to-pgmqpublic-database-functions)

On top of enabling RLS and writing RLS policies on the underlying Queue tables, you must grant the correct permissions to the `pgmq_public` database functions for each Data API role.

The permissions required for each Queue API database function:

| **Operations** | **Permissions Required** |
| --- | --- |
| `send` `send_batch` | `Select` `Insert` |
| `read` `pop` | `Select` `Update` |
| `archive` `delete` | `Select` `Delete` |

To manage your queue permissions, click on the Queue Settings button.

![Screenshot of accessing queue settings](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fqueues-quickstart-queue-settings.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

Then enable the required roles permissions.

![Screenshot of configuring API access for roles from the Queues settings](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fqueues-quickstart-roles-light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

`postgres` and `service_role` roles should never be exposed client-side.

### Enqueueing and dequeueing messages [\#](https://supabase.com/docs/guides/queues/quickstart\#enqueueing-and-dequeueing-messages)

Once your Queue has been created, you can begin enqueueing and dequeueing Messages.

Here's a TypeScript example using the official Supabase client library:

`
import { createClient } from '@supabase/supabase-js'
const supabaseUrl = 'supabaseURL'
const supabaseKey = 'supabaseKey'
const supabase = createClient(supabaseUrl, supabaseKey)
const QueuesTest: React.FC = () => {
//Add a Message
const sendToQueue = async () => {
    const result = await supabase.schema('pgmq_public').rpc('send', {
      queue_name: 'foo',
      message: { hello: 'world' },
      sleep_seconds: 30,
    })
    console.log(result)
}
//Dequeue Message
const popFromQueue = async () => {
    const result = await supabase.schema('pgmq_public').rpc('pop', { queue_name: 'foo' })
    console.log(result)
}
return (
    <div className="p-6">
      <h2 className="text-2xl font-bold mb-4">Queue Test Component</h2>
      <button
        onClick={sendToQueue}
        className="bg-blue-500 text-white px-4 py-2 rounded hover:bg-blue-600 mr-4"
      >
        Add Message
      </button>
      <button
        onClick={popFromQueue}
        className="bg-blue-500 text-white px-4 py-2 rounded hover:bg-blue-600"
      >
        Pop Message
      </button>
    </div>
)
}
export default QueuesTest
`

### Is this helpful?

NoYes

### On this page

[Concepts](https://supabase.com/docs/guides/queues/quickstart#concepts) [Pull-Based Queue](https://supabase.com/docs/guides/queues/quickstart#pull-based-queue) [Message](https://supabase.com/docs/guides/queues/quickstart#message) [Queue types](https://supabase.com/docs/guides/queues/quickstart#queue-types) [Create Queues](https://supabase.com/docs/guides/queues/quickstart#create-queues) [What happens when you create a queue?](https://supabase.com/docs/guides/queues/quickstart#what-happens-when-you-create-a-queue) [Expose Queues to client-side consumers](https://supabase.com/docs/guides/queues/quickstart#expose-queues-to-client-side-consumers) [Enable RLS on your tables in pgmq schema](https://supabase.com/docs/guides/queues/quickstart#enable-rls-on-your-tables-in-pgmq-schema) [Grant permissions to pgmq\_public database functions](https://supabase.com/docs/guides/queues/quickstart#grant-permissions-to-pgmqpublic-database-functions) [Enqueueing and dequeueing messages](https://supabase.com/docs/guides/queues/quickstart#enqueueing-and-dequeueing-messages)

![Create a Queue from the Supabase Dashboard](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fqueues-quickstart-create.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_queues.md">
Queues

# Supabase Queues

## Durable Message Queues with Guaranteed Delivery in Postgres

* * *

Supabase Queues is a Postgres-native durable Message Queue system with guaranteed delivery built on the [pgmq database extension](https://github.com/tembo-io/pgmq). It offers developers a seamless way to persist and process Messages in the background while improving the resiliency and scalability of their applications and services.

Queues couples the reliability of Postgres with the simplicity Supabase's platform and developer experience, enabling developers to manage Background Tasks with zero configuration.

## Features [\#](https://supabase.com/docs/guides/queues\#features)

- **Postgres Native**

Built on top of the `pgmq` database extension, create and manage Queues with any Postgres tooling.
- **Guaranteed Message Delivery**

Messages added to Queues are guaranteed to be delivered to your consumers.
- **Exactly Once Message Delivery**

A Message is delivered exactly once to a consumer within a customizable visibility window.
- **Message Durability and Archival**

Messages are stored in Postgres and you can choose to archive them for analytical or auditing purposes.
- **Granular Authorization**

Control client-side consumer access to Queues with API permissions and Row Level Security (RLS) policies.
- **Queue Management and Monitoring**

Create, manage, and monitor Queues and Messages in the Supabase Dashboard.

## Resources [\#](https://supabase.com/docs/guides/queues\#resources)

- [Quickstart](https://supabase.com/docs/guides/queues/quickstart)
- [API Reference](https://supabase.com/docs/guides/queues/api)
- [`pgmq` GitHub Repository](https://github.com/tembo-io/pgmq)

### Is this helpful?

NoYes

### On this page

[Features](https://supabase.com/docs/guides/queues#features) [Resources](https://supabase.com/docs/guides/queues#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_realtime_architecture.md">
Realtime

# Realtime Architecture

* * *

Realtime is a globally distributed Elixir cluster. Clients can connect to any node in the cluster via WebSockets and send messages to any other client connected to the cluster.

Realtime is written in [Elixir](https://elixir-lang.org/), which compiles to [Erlang](https://www.erlang.org/), and utilizes many tools the [Phoenix Framework](https://www.phoenixframework.org/) provides out of the box.

![Global Architecture](https://supabase.com/docs/img/guides/realtime/realtime-arch.png)

## Elixir & Phoenix [\#](https://supabase.com/docs/guides/realtime/architecture\#elixir--phoenix)

Phoenix is fast and able to handle millions of concurrent connections.

Phoenix can handle many concurrent connections because Elixir provides lightweight processes (not OS processes) to work with.

Client-facing WebSocket servers need to handle many concurrent connections. Elixir & Phoenix let the Supabase Realtime cluster do this easily.

## Channels [\#](https://supabase.com/docs/guides/realtime/architecture\#channels)

Channels are implemented using [Phoenix Channels](https://hexdocs.pm/phoenix/channels.html) which uses [Phoenix.PubSub](https://hexdocs.pm/phoenix_pubsub/Phoenix.PubSub.html) with the default `Phoenix.PubSub.PG2` adapter.

The PG2 adapter utilizes Erlang [process groups](https://www.erlang.org/docs/18/man/pg2.html) to implement the PubSub model where a publisher can send messages to many subscribers.

## Global cluster [\#](https://supabase.com/docs/guides/realtime/architecture\#global-cluster)

Presence is an in-memory key-value store backed by a CRDT. When a user is connected to the cluster the state of that user is sent to all connected Realtime nodes.

Broadcast lets you send a message from any connected client to a Channel. Any other client connected to that same Channel will receive that message.

This works globally. A client connected to a Realtime node in the United States can send a message to another client connected to a node in Singapore. Connect two clients to the same Realtime Channel and they'll all receive the same messages.

Broadcast is useful for getting messages to users in the same location very quickly. If a group of clients are connected to a node in Singapore, the message only needs to go to that Realtime node in Singapore and back down. If users are close to a Realtime node they'll get Broadcast messages in the time it takes to ping the cluster.

Thanks to the Realtime cluster, you (an amazing Supabase user) don't have to think about which regions your clients are connected to.

If you're using Broadcast, Presence, or streaming database changes, messages will always get to your users via the shortest path possible.

## Connecting to a database [\#](https://supabase.com/docs/guides/realtime/architecture\#connecting-to-a-database)

Realtime allows you to listen to changes from your Postgres database. When a new client connects to Realtime and initializes the `postgres_changes` Realtime Extension the cluster will connect to your Postgres database and start streaming changes from a replication slot.

Realtime knows the region your database is in, and connects to it from the closest region possible.

Every Realtime region has at least two nodes so if one node goes offline the other node should reconnect and start streaming changes again.

## Streaming the Write-Ahead Log [\#](https://supabase.com/docs/guides/realtime/architecture\#streaming-the-write-ahead-log)

A Postgres logical replication slot is acquired when connecting to your database.

Realtime delivers changes by polling the replication slot and appending channel subscription IDs to each wal record.

Subscription IDs are Erlang processes representing underlying sockets on the cluster. These IDs are globally unique and messages to processes are routed automatically by the Erlang virtual machine.

After receiving results from the polling query, with subscription IDs appended, Realtime delivers records to those clients.

### Is this helpful?

NoYes

### On this page

[Elixir & Phoenix](https://supabase.com/docs/guides/realtime/architecture#elixir--phoenix) [Channels](https://supabase.com/docs/guides/realtime/architecture#channels) [Global cluster](https://supabase.com/docs/guides/realtime/architecture#global-cluster) [Connecting to a database](https://supabase.com/docs/guides/realtime/architecture#connecting-to-a-database) [Streaming the Write-Ahead Log](https://supabase.com/docs/guides/realtime/architecture#streaming-the-write-ahead-log)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_realtime_authorization.md">
Realtime

# Realtime Authorization

* * *

You can control client access to Realtime [Broadcast](https://supabase.com/docs/guides/realtime/broadcast) and [Presence](https://supabase.com/docs/guides/realtime/presence) by adding Row Level Security policies to the `realtime.messages` table. Each RLS policy can map to a specific action a client can take:

- Control which clients can broadcast to a Channel
- Control which clients can receive broadcasts from a Channel
- Control which clients can publish their presence to a Channel
- Control which clients can receive messages about the presence of other clients

Realtime Authorization is in Public Alpha. To use Authorization for your Realtime Channels, use `supabase-js` version `v2.44.0` or later.

## How it works [\#](https://supabase.com/docs/guides/realtime/authorization\#how-it-works)

Realtime uses the `messages` table in your database's `realtime` schema to generate access policies for your clients when they connect to a Channel topic.

By creating RLS polices on the `realtime.messages` table you can control the access users have to a Channel topic, and features within a Channel topic.

The validation is done when the user connects. When their WebSocket connection is established and a Channel topic is joined, their permissions are calculated based on:

- The RLS policies on the `realtime.messages` table
- The user information sent as part of their [Auth JWT](https://supabase.com/docs/guides/auth/jwts)
- The request headers
- The Channel topic the user is trying to connect to

When Realtime generates a policy for a client it performs a query on the `realtime.messages` table and then rolls it back. Realtime does not store any messages in your `realtime.messages` table.

Using Realtime Authorization involves two steps:

- In your database, create RLS policies on the `realtime.messages`
- In your client, instantiate the Realtime Channel with the `config` option `private: true`

Increased RLS complexity can impact database performance and connection time, leading to higher connection latency and decreased join rates.

## Helper functions [\#](https://supabase.com/docs/guides/realtime/authorization\#helper-functions)

You can use the following helper functions when writing RLS policies:

### `realtime.topic` [\#](https://supabase.com/docs/guides/realtime/authorization\#realtimetopic)

Returns the Channel topic the user is attempting to connect to.

`
create policy "authenticated can read all messages on topic"
on "realtime"."messages"
for select
to authenticated
using (
(select realtime.topic()) = 'room-1'
);
`

## Examples [\#](https://supabase.com/docs/guides/realtime/authorization\#examples)

The following examples use this schema:

`
create table public.rooms (
    id bigint generated by default as identity primary key,
    topic text not null unique
);
alter table public.rooms enable row level security;
create table public.profiles (
id uuid not null references auth.users on delete cascade,
email text NOT NULL,
primary key (id)
);
alter table public.profiles enable row level security;
create table public.rooms_users (
user_id uuid references auth.users (id),
room_topic text references public.rooms (topic),
created_at timestamptz default current_timestamp
);
alter table public.rooms_users enable row level security;
`

### Broadcast [\#](https://supabase.com/docs/guides/realtime/authorization\#broadcast)

The `extension` field on the `realtime.messages` table records the message type. For Broadcast messages, the value of `realtime.messages.extension` is `broadcast`. You can check for this in your RLS policies.

#### Allow a user to join (and read) a Broadcast topic [\#](https://supabase.com/docs/guides/realtime/authorization\#allow-a-user-to-join-and-read-a-broadcast-topic)

To join a Broadcast Channel, a user must have at least one read or write permission on the Channel topic.

Here, we allow reads ( `select` s) for users who are linked to the requested topic within the relationship table `public.room_users`:

`
create policy "authenticated can receive broadcast"
on "realtime"."messages"
for select
to authenticated
using (
exists (
    select
      user_id
    from
      rooms_users
    where
      user_id = (select auth.uid())
      and topic = (select realtime.topic())
      and realtime.messages.extension in ('broadcast')
)
);
`

Then, to join a topic with RLS enabled, instantiate the Channel with the `private` option set to `true`.

JavaScriptDartSwiftKotlinPython

`
const channel = supabase.channel('room-1', {
config: { private: true },
})
channel
.on('broadcast', { event: 'test' }, (payload) => console.log(payload))
.subscribe((status, err) => {
    if (status === 'SUBSCRIBED') {
      console.log('Connected!')
    } else {
      console.error(err)
    }
})
`

#### Allow a user to send a Broadcast message [\#](https://supabase.com/docs/guides/realtime/authorization\#allow-a-user-to-send-a-broadcast-message)

To authorize sending Broadcast messages, create a policy for `insert` where the value of `realtime.messages.extension` is `broadcast`.

Here, we allow writes (sends) for users who are linked to the requested topic within the relationship table `public.room_users`:

`
create policy "authenticated can send broadcast on topic"
on "realtime"."messages"
for insert
to authenticated
with check (
exists (
    select
      user_id
    from
      rooms_users
    where
      user_id = (select auth.uid())
      and topic = (select realtime.topic())
      and realtime.messages.extension in ('broadcast')
)
);
`

### Presence [\#](https://supabase.com/docs/guides/realtime/authorization\#presence)

The `extension` field on the `realtime.messages` table records the message type. For Presence messages, the value of `realtime.messages.extension` is `presence`. You can check for this in your RLS policies.

#### Allow users to listen to Presence messages on a Channel [\#](https://supabase.com/docs/guides/realtime/authorization\#allow-users-to-listen-to-presence-messages-on-a-channel)

Create a policy for `select` on `realtime.messages` where `realtime.messages.extension` is `presence`.

`
create policy "authenticated can listen to presence in topic"
on "realtime"."messages"
for select
to authenticated
using (
exists (
    select
      user_id
    from
      rooms_users
    where
      user_id = (select auth.uid())
      and topic = (select realtime.topic())
      and realtime.messages.extension in ('presence')
)
);
`

#### Allow users to send Presence messages on a channel [\#](https://supabase.com/docs/guides/realtime/authorization\#allow-users-to-send-presence-messages-on-a-channel)

To update the Presence status for a user create a policy for `insert` on `realtime.messages` where the value of `realtime.messages.extension` is `presence`.

`
create policy "authenticated can track presence on topic"
on "realtime"."messages"
for insert
to authenticated
with check (
exists (
    select
      user_id
    from
      rooms_users
    where
      user_id = (select auth.uid())
      and name = (select realtime.topic())
      and realtime.messages.extension in ('presence')
)
);
`

### Presence and Broadcast [\#](https://supabase.com/docs/guides/realtime/authorization\#presence-and-broadcast)

Authorize both Presence and Broadcast by including both extensions in the `where` filter.

#### Broadcast and Presence read [\#](https://supabase.com/docs/guides/realtime/authorization\#broadcast-and-presence-read)

Authorize Presence and Broadcast read in one RLS policy.

`
create policy "authenticated can listen to broadcast and presence on topic"
on "realtime"."messages"
for select
to authenticated
using (
exists (
    select
      user_id
    from
      rooms_users
    where
      user_id = (select auth.uid())
      and topic = (select realtime.topic())
      and realtime.messages.extension in ('broadcast', 'presence')
)
);
`

#### Broadcast and Presence write [\#](https://supabase.com/docs/guides/realtime/authorization\#broadcast-and-presence-write)

Authorize Presence and Broadcast write in one RLS policy.

`
create policy "authenticated can send broadcast and presence on topic"
on "realtime"."messages"
for insert
to authenticated
with check (
exists (
    select
      user_id
    from
      rooms_users
    where
      user_id = (select auth.uid())
      and name = (select realtime.topic())
      and realtime.messages.extension in ('broadcast', 'presence')
)
);
`

## Interaction with Postgres Changes [\#](https://supabase.com/docs/guides/realtime/authorization\#interaction-with-postgres-changes)

Realtime Postgres Changes are separate from Channel authorization. The `private` Channel option does not apply to Postgres Changes.

When using Postgres Changes with RLS, database records are sent only to clients who are allowed to read them based on your RLS policies.

## Updating RLS policies [\#](https://supabase.com/docs/guides/realtime/authorization\#updating-rls-policies)

Client access polices are cached for the duration of the connection. Your database is not queried for every Channel message.

Realtime updates the access policy cache for a client based on your RLS polices when:

- A client connects to Realtime and subscribes to a Channel
- A new JWT is sent to Realtime from a client via the [`access_token` message](https://supabase.com/docs/guides/realtime/protocol#access-token)

If a new JWT is never received on the Channel, the client will be disconnected when the JWT expires.

Make sure to keep the JWT expiration window short.

### Is this helpful?

NoYes

### On this page

[How it works](https://supabase.com/docs/guides/realtime/authorization#how-it-works) [Helper functions](https://supabase.com/docs/guides/realtime/authorization#helper-functions) [realtime.topic](https://supabase.com/docs/guides/realtime/authorization#realtimetopic) [Examples](https://supabase.com/docs/guides/realtime/authorization#examples) [Broadcast](https://supabase.com/docs/guides/realtime/authorization#broadcast) [Presence](https://supabase.com/docs/guides/realtime/authorization#presence) [Presence and Broadcast](https://supabase.com/docs/guides/realtime/authorization#presence-and-broadcast) [Interaction with Postgres Changes](https://supabase.com/docs/guides/realtime/authorization#interaction-with-postgres-changes) [Updating RLS policies](https://supabase.com/docs/guides/realtime/authorization#updating-rls-policies)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_realtime_benchmarks.md">
Realtime

# Benchmarks

## Benchmark results for Supabase Realtime.

* * *

This guide explores what can be expected from Realtime's Postgres Changes, broadcast and presence performance. A set of load tests demonstrates its scaling capabilities.

## Methodology [\#](https://supabase.com/docs/guides/realtime/benchmarks\#methodology)

The benchmarks were conducted using k6, an open-source load testing tool, against a Realtime Cluster deployed on AWS. The cluster configurations used 2-6 nodes, tested in both single-region and multi-region setups, all connected to a single Supabase project. The load generators (k6 servers) were also deployed on AWS to minimize network latency impact on the results. Tests were executed with the full load from the start without warm-up runs.

The metrics collected include message throughput, latency percentiles, CPU and memory utilization, and connection success rates. It's worth noting that performance in production environments may vary based on factors such as network conditions, hardware specifications, and specific usage patterns.

## Workloads [\#](https://supabase.com/docs/guides/realtime/benchmarks\#workloads)

The proposed workloads are designed to demonstrate Supabase Realtime's throughput and scalability capabilities. These benchmarks focus on core functionality and common usage patterns.

The benchmarking results include the following workloads:

1. **Broadcast Performance**
2. **Payload Size Impact on Broadcast**
3. **Large-Scale Broadcasting**
4. **Authentication and New Connection Rate**
5. **Database Events**

## Results [\#](https://supabase.com/docs/guides/realtime/benchmarks\#results)

### Realtime broadcast performance [\#](https://supabase.com/docs/guides/realtime/benchmarks\#realtime-broadcast-performance)

This workload evaluates the system's capacity to handle multiple concurrent WebSocket connections and message broadcasting. Each virtual user (VU) in the test:

- Establishes and maintains a WebSocket connection
- Joins two distinct channels:
  - An echo channel (1 user per channel) for direct message reflection
  - A broadcast channel (6 users per channel) for group communication
- Generates traffic by sending 2 messages per second to each joined channel for 10 minutes

![Broadcast Performance](https://supabase.com/docs/img/guides/realtime/broadcast-performance.png)

| Metric | Value |
| --- | --- |
| Concurrent Users | 32\_000 |
| Total Channel Joins | 64\_000 |
| Message Throughput | 224\_000 msgs/sec |
| Median Latency | 6 ms |
| Latency (p95) | 28 ms |
| Latency (p99) | 213 ms |
| Data Received | 47.2 MB/s (29.6 GB total) |
| Data Sent | 15.2 MB/s (9.6 GB total) |
| New Connection Rate | 320 conn/sec |
| Channel Join Rate | 640 joins/sec |

### Payload size impact [\#](https://supabase.com/docs/guides/realtime/benchmarks\#payload-size-impact)

This workload tests the system's performance with different message payload sizes to understand how data volume affects throughput and latency. Each virtual user (VU) follows the same connection pattern as the broadcast test, but with varying message sizes:

- Establishes and maintains a WebSocket connection
- Joins two distinct channels:
  - An echo channel (1 user per channel) for direct message reflection
  - A broadcast channel (6 users per channel) for group communication
- Sends messages with payloads of 1KB, 10KB, and 50KB
- Generates traffic by sending 2 messages per second to each joined channel for 5 minutes

#### 1KB payload [\#](https://supabase.com/docs/guides/realtime/benchmarks\#1kb-payload)

![1KB Payload Broadcast Performance](https://supabase.com/docs/img/guides/realtime/payload-size-1kb.png)

#### 10KB payload [\#](https://supabase.com/docs/guides/realtime/benchmarks\#10kb-payload)

![10KB Payload Broadcast Performance](https://supabase.com/docs/img/guides/realtime/payload-size-10kb.png)

#### 50KB payload [\#](https://supabase.com/docs/guides/realtime/benchmarks\#50kb-payload)

![50KB Payload Broadcast Performance](https://supabase.com/docs/img/guides/realtime/payload-size-50kb-small.png)

| Metric | 1KB Payload | 10KB Payload | 50KB Payload | 50KB Payload (Reduced Load) |
| --- | --- | --- | --- | --- |
| Concurrent Users | 4\_000 | 4\_000 | 4\_000 | 2\_000 |
| Message Throughput | 28\_000 msgs/sec | 28\_000 msgs/sec | 28\_000 msgs/sec | 14\_000 msgs/sec |
| Median Latency | 13 ms | 16 ms | 27 ms | 19 ms |
| Latency (p95) | 36 ms | 42 ms | 81 ms | 39 ms |
| Latency (p99) | 85 ms | 93 ms | 146 ms | 82 ms |
| Data Received | 31.2 MB/s (10.4 GB) | 268 MB/s (72 GB) | 1284 MB/s (348 GB) | 644 MB/s (176 GB) |
| Data Sent | 9.2 MB/s (3.1 GB) | 76 MB/s (20.8 GB) | 384 MB/s (104 GB) | 192 MB/s (52 GB) |

> Note: The final column shows results with reduced load (2,000 users) for the 50KB payload test, demonstrating how the system performs with larger payloads under different concurrency levels.

### Large-Scale broadcasting [\#](https://supabase.com/docs/guides/realtime/benchmarks\#large-scale-broadcasting)

This workload demonstrates Realtime's capability to handle high-scale scenarios with a large number of concurrent users and broadcast channels. The test simulates a scenario where each user participates in group communications with periodic message broadcasts:

- Each virtual user (VU):
  - Establishes and maintains a WebSocket connection (30-120 minutes)
  - Joins 2 broadcast channels
  - Sends 1 message per minute to each joined channel
  - Each message is broadcast to 100 other users

![Large Broadcast Performance](https://supabase.com/docs/img/guides/realtime/broadcast-large.png)

| Metric | Value |
| --- | --- |
| Concurrent Users | 250\_000 |
| Total Channel Joins | 500\_000 |
| Users per Channel | 100 |
| Message Throughput | >800\_000 msgs/sec |
| Median Latency | 58 ms |
| Latency (p95) | 279 ms |
| Latency (p99) | 508 ms |
| Data Received | 68 MB/s (600 GB) |
| Data Sent | 0.64 MB/s (5.7 GB) |

### Realtime Auth [\#](https://supabase.com/docs/guides/realtime/benchmarks\#realtime-auth)

This workload demonstrates Realtime's capability to handle large amounts of new connections per second and channel joins per second with Authentication Row Level Security (RLS) enabled for these channels. The test simulates a scenario where large volumes of users connect to realtime and participate in auth protected communications:

- Each virtual user (VU):
  - Establishes and maintains a WebSocket connection (2.5 minutes)
  - Joins 2 broadcast channels
  - Sends 1 message per minute to each joined channel
  - Each message is broadcast to 100 other users

![Broadcast Auth Performance](https://supabase.com/docs/img/guides/realtime/broadcast-auth.png)

| Metric | Value |
| --- | --- |
| Concurrent Users | 50\_000 |
| Total Channel Joins | 100\_000 |
| Users per Channel | 100 |
| Message Throughput | >150\_000 msgs/sec |
| New Connection Rate | 500 conn/sec |
| Channel Join Rate | 1000 joins/sec |
| Median Latency | 19 ms |
| Latency (p95) | 49 ms |
| Latency (p99) | 96 ms |

### Realtime's Postgres Changes [\#](https://supabase.com/docs/guides/realtime/benchmarks\#realtimes-postgres-changes)

Realtime systems usually require forethought because of their scaling dynamics. For the `Postgres Changes` feature, every change event must be checked to see if the subscribed user has access. For instance, if you have 100 users subscribed to a table where you make a single insert, it will then trigger 100 "reads": one for each user.

There can be a database bottleneck which limits message throughput. If your database cannot authorize the changes rapidly enough, the changes will be delayed until you receive a timeout.

Database changes are processed on a single thread to maintain the change order. That means compute upgrades don't have a large effect on the performance of Postgres change subscriptions. You can estimate the expected maximum throughput for your database below.

If you are using Postgres Changes at scale, you should consider using a separate "public" table without RLS and filters. Alternatively, you can use Realtime server-side only and then re-stream the changes to your clients using a Realtime Broadcast.

Enter your database settings to estimate the maximum throughput for your instance:

#### Set your expected parameters

Compute:

MicroSmall to mediumLarge to 16XL

Filters:

NoYes

RLS:

NoYes

Connected clients:

5005,00010,00030,000

#### Current maximum possible throughput

| Total DB changes /sec | Max messages per client /sec | Max total messages /sec | Latency p95 |
| --- | --- | --- | --- |
| 64 | 64 | 32,000 | 238ms |

View raw throughput table

Don't forget to run your own benchmarks to make sure that the performance is acceptable for your use case.

Supabase continues to make improvements to Realtime's Postgres Changes. If you are uncertain about your use case performance, reach out using the [Support Form](https://supabase.com/dashboard/support/new). The support team can advise on the best solution for each use-case.

### Is this helpful?

NoYes

### On this page

[Methodology](https://supabase.com/docs/guides/realtime/benchmarks#methodology) [Workloads](https://supabase.com/docs/guides/realtime/benchmarks#workloads) [Results](https://supabase.com/docs/guides/realtime/benchmarks#results) [Realtime broadcast performance](https://supabase.com/docs/guides/realtime/benchmarks#realtime-broadcast-performance) [Payload size impact](https://supabase.com/docs/guides/realtime/benchmarks#payload-size-impact) [Large-Scale broadcasting](https://supabase.com/docs/guides/realtime/benchmarks#large-scale-broadcasting) [Realtime Auth](https://supabase.com/docs/guides/realtime/benchmarks#realtime-auth) [Realtime's Postgres Changes](https://supabase.com/docs/guides/realtime/benchmarks#realtimes-postgres-changes)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_realtime_broadcast.md">
Realtime

# Broadcast

## Send and receive messages using Realtime Broadcast

* * *

Let's explore how to implement Realtime Broadcast to send messages between clients using either WebSockets, REST API or triggers from your database.

## Usage [\#](https://supabase.com/docs/guides/realtime/broadcast\#usage)

You can use the Supabase client libraries to send and receive Broadcast messages.

### Initialize the client [\#](https://supabase.com/docs/guides/realtime/broadcast\#initialize-the-client)

Go to your Supabase project's [API Settings](https://supabase.com/dashboard/project/_/settings/api) and grab the `URL` and `anon` public API key.

JavaScriptDartSwiftKotlinPython

`
import { createClient } from '@supabase/supabase-js'
const SUPABASE_URL = 'https://<project>.supabase.co'
const SUPABASE_KEY = '<your-anon-key>'
const supabase = createClient(SUPABASE_URL, SUPABASE_KEY)
`

### Listening to broadcast messages [\#](https://supabase.com/docs/guides/realtime/broadcast\#listening-to-broadcast-messages)

You can provide a callback for the `broadcast` channel to receive message. This example will receive any `broadcast` messages in `room-1`:

JavaScriptDartSwiftKotlinPython

`
// Join a room/topic. Can be anything except for 'realtime'.
const channelA = supabase.channel('room-1')
// Simple function to log any messages we receive
function messageReceived(payload) {
console.log(payload)
}
// Subscribe to the Channel
channelA
.on(
    'broadcast',
    { event: 'test' },
    (payload) => messageReceived(payload)
)
.subscribe()
`

### Sending broadcast messages [\#](https://supabase.com/docs/guides/realtime/broadcast\#sending-broadcast-messages)

JavaScriptAsync JavaScriptDartSwiftKotlinPython

We can send Broadcast messages using `channelB.send()`. Let's set up another client to send messages.

`
// Join a room/topic. Can be anything except for 'realtime'.
const channelB = supabase.channel('room-1')
channelB.subscribe((status) => {
// Wait for successful connection
if (status !== 'SUBSCRIBED') {
    return null
}
// Send a message once the client is subscribed
channelB.send({
    type: 'broadcast',
    event: 'test',
    payload: { message: 'hello, world' },
})
})
`

Before sending messages we need to ensure the client is connected, which we have done within the `subscribe()` callback.

## Broadcast options [\#](https://supabase.com/docs/guides/realtime/broadcast\#broadcast-options)

You can pass configuration options while initializing the Supabase Client.

### Self-send messages [\#](https://supabase.com/docs/guides/realtime/broadcast\#self-send-messages)

JavaScriptDartSwiftKotlinPython

By default, broadcast messages are only sent to other clients. You can broadcast messages back to the sender by setting Broadcast's `self` parameter to `true`.

`
const myChannel = supabase.channel('room-2', {
config: {
    broadcast: { self: true },
},
})
myChannel.on(
'broadcast',
{ event: 'test-my-messages' },
(payload) => console.log(payload)
)
myChannel.subscribe((status) => {
if (status !== 'SUBSCRIBED') { return }
channelC.send({
    type: 'broadcast',
    event: 'test-my-messages',
    payload: { message: 'talking to myself' },
})
})
`

### Acknowledge messages [\#](https://supabase.com/docs/guides/realtime/broadcast\#acknowledge-messages)

JavaScriptDartSwiftKotlinPython

You can confirm that Realtime received your message by setting Broadcast's `ack` config to `true`.

`
const myChannel = supabase.channel('room-3', {
config: {
    broadcast: { ack: true },
},
})
myChannel.subscribe(async (status) => {
if (status !== 'SUBSCRIBED') { return }
const serverResponse = await myChannel.send({
    type: 'broadcast',
    event: 'acknowledge',
    payload: {},
})
console.log('serverResponse', serverResponse)
})
`

Use this to guarantee that the server has received the message before resolving `channelD.send`'s promise. If the `ack` config is not set to `true` when creating the channel, the promise returned by `channelD.send` will resolve immediately.

### Send messages using REST calls [\#](https://supabase.com/docs/guides/realtime/broadcast\#send-messages-using-rest-calls)

You can also send a Broadcast message by making an HTTP request to Realtime servers. This is useful when you want to send messages from your server or client without having to first establish a WebSocket connection.

JavaScriptDartSwiftKotlinPython

This is currently available only in the Supabase JavaScript client version 2.37.0 and later.

`
const channel = supabase.channel('test-channel')
// No need to subscribe to channel
channel
.send({
    type: 'broadcast',
    event: 'test',
    payload: { message: 'Hi' },
})
.then((resp) => console.log(resp))
// Remember to clean up the channel
supabase.removeChannel(channel)
`

## Trigger broadcast messages from your database [\#](https://supabase.com/docs/guides/realtime/broadcast\#trigger-broadcast-messages-from-your-database)

This feature is currently in Public Alpha. If you have any issues [submit a support ticket](https://supabase.help/).

### How it works [\#](https://supabase.com/docs/guides/realtime/broadcast\#how-it-works)

Broadcast Changes allows you to trigger messages from your database. To achieve it Realtime is directly reading your WAL (Write Append Log) file using a publication against the `realtime.messages` table so whenever a new insert happens a message is sent to connected users.

It uses partitioned tables per day which allows the deletion your previous messages in a performant way by dropping the physical tables of this partitioned table. Tables older than 3 days old are deleted.

Broadcasting from the database works like a client-side broadcast, using WebSockets to send JSON packages. [Realtime Authorization](https://supabase.com/docs/guides/realtime/authorization) is required and enabled by default to protect your data.

The database broadcast feature provides two functions to help you send messages:

- `realtime.send` will insert a message into realtime.messages without a specific format.
- `realtime.broadcast_changes` will insert a message with the required fields to emit database changes to clients. This helps you set up triggers on your tables to emit changes.

### Broadcasting a message from your database [\#](https://supabase.com/docs/guides/realtime/broadcast\#broadcasting-a-message-from-your-database)

The `realtime.send` function provides the most flexibility by allowing you to broadcast messages from your database without a specific format. This allows you to use database broadcast for messages that aren't necessarily tied to the shape of a Postgres row change.

`
SELECT realtime.send (
	to_jsonb ('{}'::text), -- JSONB Payload
	'event', -- Event name
	'topic', -- Topic
	FALSE -- Public / Private flag
);
`

### Broadcast record changes [\#](https://supabase.com/docs/guides/realtime/broadcast\#broadcast-record-changes)

#### Setup realtime authorization [\#](https://supabase.com/docs/guides/realtime/broadcast\#setup-realtime-authorization)

Realtime Authorization is required and enabled by default. To allow your users to listen to messages from topics, create a RLS (Row Level Security) policy:

`
CREATE POLICY "authenticated can receive broadcasts"
ON "realtime"."messages"
FOR SELECT
TO authenticated
USING ( true );
`

See the [Realtime Authorization](https://supabase.com/docs/guides/realtime/authorization) docs to learn how to set up more specific policies.

#### Set up trigger function [\#](https://supabase.com/docs/guides/realtime/broadcast\#set-up-trigger-function)

First, set up a trigger function that uses `realtime.broadcast_changes` to insert an event whenever it is triggered. The event is set up to include data on the schema, table, operation, and field changes that triggered it.

For this example use case, we want to have a topic with the name `topic:<record id>` to which we're going to broadcast events.

`
CREATE OR REPLACE FUNCTION public.your_table_changes() RETURNS trigger AS $$
BEGIN
    PERFORM realtime.broadcast_changes(
	    'topic:' || NEW.id::text,   -- topic
		   TG_OP,                          -- event
		   TG_OP,                          -- operation
		   TG_TABLE_NAME,                  -- table
		   TG_TABLE_SCHEMA,                -- schema
		   NEW,                            -- new record
		   OLD                             -- old record
		);
    RETURN NULL;
END;
$$ LANGUAGE plpgsql;
`

Of note are the Postgres native trigger special variables used:

- `TG_OP` \- the operation that triggered the function
- `TG_TABLE_NAME` \- the table that caused the trigger
- `TG_TABLE_SCHEMA` \- the schema of the table that caused the trigger invocation
- `NEW` \- the record after the change
- `OLD` \- the record before the change

You can read more about them in this [guide](https://www.postgresql.org/docs/current/plpgsql-trigger.html#PLPGSQL-DML-TRIGGER).

#### Set up trigger [\#](https://supabase.com/docs/guides/realtime/broadcast\#set-up-trigger)

Next, set up a trigger so the function runs whenever your target table has a change.

`
CREATE TRIGGER broadcast_changes_for_your_table_trigger
AFTER INSERT OR UPDATE OR DELETE ON public.your_table
FOR EACH ROW
EXECUTE FUNCTION your_table_changes ();
`

As you can see, it will be broadcasting all operations so our users will receive events when records are inserted, updated or deleted from `public.your_table` .

#### Listen on client side [\#](https://supabase.com/docs/guides/realtime/broadcast\#listen-on-client-side)

Finally, client side will requires to be set up to listen to the topic `topic:<record id>` to receive the events.

``
const gameId = 'id'
await supabase.realtime.setAuth() // Needed for Realtime Authorization
const changes = supabase
.channel(`topic:${gameId}`)
.on('broadcast', { event: 'INSERT' }, (payload) => console.log(payload))
.on('broadcast', { event: 'UPDATE' }, (payload) => console.log(payload))
.on('broadcast', { event: 'DELETE' }, (payload) => console.log(payload))
.subscribe()
``

### Is this helpful?

NoYes

### On this page

[Usage](https://supabase.com/docs/guides/realtime/broadcast#usage) [Initialize the client](https://supabase.com/docs/guides/realtime/broadcast#initialize-the-client) [Listening to broadcast messages](https://supabase.com/docs/guides/realtime/broadcast#listening-to-broadcast-messages) [Sending broadcast messages](https://supabase.com/docs/guides/realtime/broadcast#sending-broadcast-messages) [Broadcast options](https://supabase.com/docs/guides/realtime/broadcast#broadcast-options) [Self-send messages](https://supabase.com/docs/guides/realtime/broadcast#self-send-messages) [Acknowledge messages](https://supabase.com/docs/guides/realtime/broadcast#acknowledge-messages) [Send messages using REST calls](https://supabase.com/docs/guides/realtime/broadcast#send-messages-using-rest-calls) [Trigger broadcast messages from your database](https://supabase.com/docs/guides/realtime/broadcast#trigger-broadcast-messages-from-your-database) [How it works](https://supabase.com/docs/guides/realtime/broadcast#how-it-works) [Broadcasting a message from your database](https://supabase.com/docs/guides/realtime/broadcast#broadcasting-a-message-from-your-database) [Broadcast record changes](https://supabase.com/docs/guides/realtime/broadcast#broadcast-record-changes)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_realtime_concepts.md">
Realtime

# Realtime Concepts

## Learn about Channels and other extensions in Supabase Realtime

* * *

You can use Supabase Realtime to build real-time applications with collaborative/multiplayer functionality. It includes 3 core extensions:

- [Broadcast](https://supabase.com/docs/guides/realtime/broadcast): sends rapid, ephemeral messages to other connected clients. You can use it to track mouse movements, for example.
- [Presence](https://supabase.com/docs/guides/realtime/presence): sends user state between connected clients. You can use it to show an "online" status, which disappears when a user is disconnected.
- [Postgres Changes](https://supabase.com/docs/guides/realtime/postgres-changes): receives database changes in real-time.

## Channels [\#](https://supabase.com/docs/guides/realtime/concepts\#channels)

A Channel is the basic building block of Realtime. You can think of a Channel as a chatroom, similar to a Discord or Slack channel, where participants are able to see who's online and send and receive messages.

When you initialize your Supabase Realtime client, you define a `topic` that uniquely references a channel. Clients can bi-directionally send and receive messages over a Channel.

`
import { createClient } from '@supabase/supabase-js'
const supabase = createClient('https://<project>.supabase.co', '<your-anon-key>')
const roomOne = supabase.channel('room-one') // set your topic here
`

## Broadcast [\#](https://supabase.com/docs/guides/realtime/concepts\#broadcast)

Realtime Broadcast follows the [publish-subscribe pattern](https://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern) where a client publishes messages to a channel based on a unique topic. For example, a user could send a message to a channel with topic `room-one`.

`
roomOne.send({
type: 'broadcast',
event: 'test',
payload: { message: 'hello, world' },
})
`

Other clients can receive the message in real-time by subscribing to the Channel with topic `room-one`. These clients continue to receive messages as long as they are subscribed and connected to the same Channel topic.

An example use-case is sharing a user's cursor position with other clients in an online game.

## Presence [\#](https://supabase.com/docs/guides/realtime/concepts\#presence)

Presence can be used to share an individual's state with others within a Channel.

`
const presenceTrackStatus = await roomOne.track({
user: 'user-1',
online_at: new Date().toISOString(),
})
`

Each client maintains their own state, and this is then combined into a "shared state" for that Channel topic. It's commonly used for sharing statuses (e.g. "online" or "inactive"). The neat thing about Presence is that if a client is suddenly disconnected (for example, they go offline), their state is automatically removed from the shared state. If you've ever tried to build an I'm online feature which handles unexpected disconnects, you'll appreciate how useful this is.
When a new client subscribes to a channel, it will immediately receive the channel's latest state in a single message because the state is held by the Realtime server.

## Postgres Changes [\#](https://supabase.com/docs/guides/realtime/concepts\#postgres-changes)

The Postgres Changes extension listens for database changes and sends them to clients. Clients are required to subscribe with a JWT dictating which changes they are allowed to receive based on the database's [Row Level Security](https://supabase.com/docs/guides/database/postgres/row-level-security).

`
const allChanges = supabase
.channel('schema-db-changes')
.on(
    'postgres_changes',
    {
      event: '*',
      schema: 'public',
    },
    (payload) => console.log(payload)
)
.subscribe()
`

Anyone with access to a valid JWT signed with the project's JWT secret is able to listen to your database's changes, unless tables have [Row Level Security](https://supabase.com/docs/guides/database/postgres/row-level-security) enabled and policies in place.

Clients can choose to receive `INSERT`, `UPDATE`, `DELETE`, or `*` (all) changes for all changes in a schema, a table in a schema, or a column's value in a table. Your clients should only listen to tables in the `public` schema and you must first enable the tables you want your clients to listen to.

## Choosing between Broadcast and Presence [\#](https://supabase.com/docs/guides/realtime/concepts\#choosing-between-broadcast-and-presence)

We recommend using Broadcast by default, and then Presence when required. Presence utilizes an in-memory conflict-free replicated data type (CRDT) to track and synchronize shared state in an eventually consistent manner. It computes the difference between existing state and new state changes and sends the necessary updates to clients via Broadcast. This is computationally heavy, so you should use it sparingly. If you use Presence, it's best to throttle your changes so that you are sending updates less frequently.

### Is this helpful?

NoYes

### On this page

[Channels](https://supabase.com/docs/guides/realtime/concepts#channels) [Broadcast](https://supabase.com/docs/guides/realtime/concepts#broadcast) [Presence](https://supabase.com/docs/guides/realtime/concepts#presence) [Postgres Changes](https://supabase.com/docs/guides/realtime/concepts#postgres-changes) [Choosing between Broadcast and Presence](https://supabase.com/docs/guides/realtime/concepts#choosing-between-broadcast-and-presence)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_realtime_error_codes.md">
Realtime

# Operational Error Codes

## List of operational codes to help understand your deployment and usage.

* * *

| Code | Description | Action |
| --- | --- | --- |
| `RealtimeDisabledForConfiguration` | The configuration provided to Realtime on connect will not be able to provide you any Postgres Changes | Verify your configuration on channel startup as you might not have your tables properly registered |
| `TenantNotFound` | The tenant you are trying to connect to does not exist | Verify the tenant name you are trying to connect to exists in the realtime.tenants table |
| `ErrorConnectingToWebSocket` | Error when trying to connect to the WebSocket server | Verify user information on connect |
| `ErrorAuthorizingWebSocket` | Error when trying to authorize the WebSocket connection | Verify user information on connect |
| `TableHasSpacesInName` | The table you are trying to listen to has spaces in its name which we are unable to support | Change the table name to not have spaces in it |
| `UnableToDeleteTenant` | Error when trying to delete a tenant | Contact Support |
| `UnableToSetPolicies` | Error when setting up Authorization Policies | Contact Support |
| `UnableCheckoutConnection` | Error when trying to checkout a connection from the tenant pool | Contact Support |
| `UnableToSubscribeToPostgres` | Error when trying to subscribe to Postgres changes | Contact Support |
| `ChannelRateLimitReached` | The number of channels you can create has reached its limit | Contact support to increase your rate limits |
| `ConnectionRateLimitReached` | The number of connected clients as reached its limit | Contact support to increase your rate limits |
| `ClientJoinRateLimitReached` | The rate of joins per second from your clients as reached the channel limits | Contact support to increase your rate limits |
| `UnableToConnectToTenantDatabase` | Realtime was not able to connect to the tenant's database | Contact support for further instructions |
| `RealtimeNodeDisconnected` | Realtime is a distributed application and this means that one the system is unable to communicate with one of the distributed nodes | Contact support for further instructions |
| `MigrationsFailedToRun` | Error when running the migrations against the Tenant database that are required by Realtime | Contact support for further instructions |
| `ErrorStartingPostgresCDCStream` | Error when starting the Postgres CDC stream which is used for Postgres Changes | Contact support for further instructions |
| `UnknownDataProcessed` | An unknown data type was processed by the Realtime system | Contact support for further instructions |
| `ErrorStartingPostgresCDC` | Error when starting the Postgres CDC extension which is used for Postgres Changes | Contact support for further instructions |
| `ReplicationSlotBeingUsed` | The replication slot is being used by another transaction | Contact support for further instructions |
| `PoolingReplicationPreparationError` | Error when preparing the replication slot | Contact support for further instructions |
| `PoolingReplicationError` | Error when pooling the replication slot | Contact support for further instructions |
| `SubscriptionDeletionFailed` | Error when trying to delete a subscription for Postgres changes | Contact support for further instructions |
| `UnableToDeletePhantomSubscriptions` | Error when trying to delete subscriptions that are no longer being used | Contact support for further instructions |
| `UnableToCheckProcessesOnRemoteNode` | Error when trying to check the processes on a remote node | Contact support for further instructions |
| `UnableToCreateCounter` | Error when trying to create a counter to track rate limits for a tenant | Contact support for further instructions |
| `UnableToIncrementCounter` | Error when trying to increment a counter to track rate limits for a tenant | Contact support for further instructions |
| `UnableToDecrementCounter` | Error when trying to decrement a counter to track rate limits for a tenant | Contact support for further instructions |
| `UnableToUpdateCounter` | Error when trying to update a counter to track rate limits for a tenant | Contact support for further instructions |
| `UnableToFindCounter` | Error when trying to find a counter to track rate limits for a tenant | Contact support for further instructions |
| `UnhandledProcessMessage` | Unhandled message received by a Realtime process | Contact support for further instructions |
| `UnknownError` | An unknown error occurred | Contact support for further instructions |

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_realtime_migrate_from_postgres_changes.md">
Realtime

# Migrate to Broadcast Changes

## How to migrate from Postgres Changes to Broadcast Changes

* * *

Postgres Changes has some [limitations](https://supabase.com/docs/guides/realtime/postgres-changes#limitations) as your application scales. To continue broadcasting database changes to users as you scale, you can use Broadcast Changes.

## Example application using Postgres Changes [\#](https://supabase.com/docs/guides/realtime/migrate-from-postgres-changes\#example-application-using-postgres-changes)

Here we have a simple chess application that has a game id and we want to track whenever we have new moves happening for a given game id.

We store this information in a `public.moves` table and every time a new move is added to a given `game_id` we want to receive the changes in our connected Realtime client

![Schema used for our example](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fguides%2Frealtime%2Frealtime-broadcast-changes-migration-schema-example-light.png&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

In our client we will have our implementation to receive insert events with the usual code:

``
const gameId = '4a8bbe89-f601-4414-bd47-8d0f7ab2a31a'
const changes = supabase
.channel('chess-moves')
.on(
    'postgres_changes',
    {
      event: 'INSERT',
      schema: 'public',
      table: 'moves',
      filter: `game_id=eq.${gameId}`,
    },
    (payload) => console.log(payload)
)
.subscribe()
...
``

## Migrate to broadcast changes [\#](https://supabase.com/docs/guides/realtime/migrate-from-postgres-changes\#migrate-to-broadcast-changes)

To use Broadcast Changes, first familiarize yourself with the [Broadcast Changes implementation](https://supabase.com/docs/guides/realtime/broadcast#trigger-broadcast-messages-from-your-database).

### Set up authorization [\#](https://supabase.com/docs/guides/realtime/migrate-from-postgres-changes\#set-up-authorization)

Broadcast Changes is private by default, using [Realtime Authorization](https://supabase.com/docs/guides/realtime/authorization) to control access. First, set up RLS policies to control user access to relevant messages:

`
CREATE POLICY "authenticated can listen to game moves"
ON "realtime"."messages"
FOR SELECT
TO authenticated
USING (
EXISTS (
    SELECT 1
    FROM game_users
    WHERE (SELECT auth.uid()) = user_id
      AND (select realtime.topic()) = 'games:' || game_id::text
      AND realtime.messages.extension = 'broadcast'
)
);
`

### Set up trigger function [\#](https://supabase.com/docs/guides/realtime/migrate-from-postgres-changes\#set-up-trigger-function)

We need to define our trigger function to adapt to our use case and use the provided function `realtime.broadcast_changes`

`
CREATE OR REPLACE FUNCTION public.broadcast_moves() RETURNS trigger AS $$
BEGIN
    PERFORM realtime.broadcast_changes(
	    'games:' || NEW.game_id::text,   -- topic
		   TG_OP,                          -- event
		   TG_OP,                          -- operation
		   TG_TABLE_NAME,                  -- table
		   TG_TABLE_SCHEMA,                -- schema
		   NEW,                            -- new record
		   OLD                             -- old record
		);
    RETURN NULL;
END;
$$ LANGUAGE plpgsql;
`

### Setup trigger with created function [\#](https://supabase.com/docs/guides/realtime/migrate-from-postgres-changes\#setup-trigger-with-created-function)

Now we need to setup our trigger to capture the events we want

`
CREATE TRIGGER chess_move_changes
AFTER INSERT ON public.moves
FOR EACH ROW
EXECUTE FUNCTION public.broadcast_moves();
`

### **Listen to changes in client** [\#](https://supabase.com/docs/guides/realtime/migrate-from-postgres-changes\#listen-to-changes-in-client)

Finally you can setup your client to listen for your events

``
const gameId = '4a8bbe89-f601-4414-bd47-8d0f7ab2a31a'
await supabase.realtime.setAuth() // Needed for Realtime Authorization
const changes = supabase
.channel(`games:${gameId}`)
.on(
    'broadcast',
    {
      event: 'INSERT',
    },
    (payload) => console.log(payload)
)
.subscribe()
``

### Is this helpful?

NoYes

### On this page

[Example application using Postgres Changes](https://supabase.com/docs/guides/realtime/migrate-from-postgres-changes#example-application-using-postgres-changes) [Migrate to broadcast changes](https://supabase.com/docs/guides/realtime/migrate-from-postgres-changes#migrate-to-broadcast-changes) [Set up authorization](https://supabase.com/docs/guides/realtime/migrate-from-postgres-changes#set-up-authorization) [Set up trigger function](https://supabase.com/docs/guides/realtime/migrate-from-postgres-changes#set-up-trigger-function) [Setup trigger with created function](https://supabase.com/docs/guides/realtime/migrate-from-postgres-changes#setup-trigger-with-created-function) [Listen to changes in client](https://supabase.com/docs/guides/realtime/migrate-from-postgres-changes#listen-to-changes-in-client)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_realtime_postgres_changes.md">
Realtime

# Postgres Changes

## Listen to Postgres changes using Supabase Realtime.

* * *

Let's explore how to use Realtime's Postgres Changes feature to listen to database events.

## Quick start [\#](https://supabase.com/docs/guides/realtime/postgres-changes\#quick-start)

In this example we'll set up a database table, secure it with Row Level Security, and subscribe to all changes using the Supabase client libraries.

1

### Set up a Supabase project with a 'todos' table

[Create a new project](https://app.supabase.com/) in the Supabase Dashboard.

After your project is ready, create a table in your Supabase database. You can do this with either the Table interface or the [SQL Editor](https://app.supabase.com/project/_/sql).

SQLDashboard

`
-- Create a table called "todos"
-- with a column to store tasks.
create table todos (
id serial primary key,
task text
);
`

2

### Allow anonymous access

In this example we'll turn on [Row Level Security](https://supabase.com/docs/guides/database/postgres/row-level-security) for this table and allow anonymous access. In production, be sure to secure your application with the appropriate permissions.

`
-- Turn on security
alter table "todos"
enable row level security;
-- Allow anonymous access
create policy "Allow anonymous access"
on todos
for select
to anon
using (true);
`

3

### Enable Postgres replication

Go to your project's [Publications settings](https://supabase.com/dashboard/project/_/database/publications), and under `supabase_realtime`, toggle on the tables you want to listen to.

4

### Install the client

Install the Supabase JavaScript client.

`
npm install @supabase/supabase-js
`

5

### Create the client

This client will be used to listen to Postgres changes.

`
import { createClient } from '@supabase/supabase-js'
const supabase = createClient(
    'https://<project>.supabase.co',
    '<your-anon-key>'
)
`

6

### Listen to changes by schema

Listen to changes on all tables in the `public` schema by setting the `schema` property to 'public' and event name to `*`. The event name can be one of:

- `INSERT`
- `UPDATE`
- `DELETE`
- `*`

The channel name can be any string except 'realtime'.

`
const channelA = supabase
    .channel('schema-db-changes')
    .on(
      'postgres_changes',
      {
        event: '*',
        schema: 'public',
      },
      (payload) => console.log(payload)
    )
    .subscribe()
`

7

### Insert dummy data

Now we can add some data to our table which will trigger the `channelA` event handler.

`
insert into todos (task)
values
('Change!');
`

## Usage [\#](https://supabase.com/docs/guides/realtime/postgres-changes\#usage)

You can use the Supabase client libraries to subscribe to database changes.

### Listening to specific schemas [\#](https://supabase.com/docs/guides/realtime/postgres-changes\#listening-to-specific-schemas)

Subscribe to specific schema events using the `schema` parameter:

JavaScriptDartSwiftKotlinPython

`
const changes = supabase
.channel('schema-db-changes')
.on(
    'postgres_changes',
    {
      schema: 'public', // Subscribes to the "public" schema in Postgres
      event: '*',       // Listen to all changes
    },
    (payload) => console.log(payload)
)
.subscribe()
`

The channel name can be any string except 'realtime'.

### Listening to `INSERT` events [\#](https://supabase.com/docs/guides/realtime/postgres-changes\#listening-to-insert-events)

JavaScriptDartSwiftKotlinPython

Use the `event` parameter to listen only to database `INSERT` s:

`
const changes = supabase
.channel('schema-db-changes')
.on(
    'postgres_changes',
    {
      event: 'INSERT', // Listen only to INSERTs
      schema: 'public',
    },
    (payload) => console.log(payload)
)
.subscribe()
`

The channel name can be any string except 'realtime'.

### Listening to `UPDATE` events [\#](https://supabase.com/docs/guides/realtime/postgres-changes\#listening-to-update-events)

JavaScriptDartSwiftKotlinPython

Use the `event` parameter to listen only to database `UPDATE` s:

`
const changes = supabase
.channel('schema-db-changes')
.on(
    'postgres_changes',
    {
      event: 'UPDATE', // Listen only to UPDATEs
      schema: 'public',
    },
    (payload) => console.log(payload)
)
.subscribe()
`

The channel name can be any string except 'realtime'.

### Listening to `DELETE` events [\#](https://supabase.com/docs/guides/realtime/postgres-changes\#listening-to-delete-events)

JavaScriptDartSwiftKotlinPython

Use the `event` parameter to listen only to database `DELETE` s:

`
const changes = supabase
.channel('schema-db-changes')
.on(
    'postgres_changes',
    {
      event: 'DELETE', // Listen only to DELETEs
      schema: 'public',
    },
    (payload) => console.log(payload)
)
.subscribe()
`

The channel name can be any string except 'realtime'.

### Listening to specific tables [\#](https://supabase.com/docs/guides/realtime/postgres-changes\#listening-to-specific-tables)

Subscribe to specific table events using the `table` parameter:

JavaScriptDartSwiftKotlinPython

`
const changes = supabase
.channel('table-db-changes')
.on(
    'postgres_changes',
    {
      event: '*',
      schema: 'public',
      table: 'todos',
    },
    (payload) => console.log(payload)
)
.subscribe()
`

The channel name can be any string except 'realtime'.

### Listening to multiple changes [\#](https://supabase.com/docs/guides/realtime/postgres-changes\#listening-to-multiple-changes)

To listen to different events and schema/tables/filters combinations with the same channel:

JavaScriptDartSwiftKotlinPython

`
const channel = supabase
.channel('db-changes')
.on(
    'postgres_changes',
    {
      event: '*',
      schema: 'public',
      table: 'messages',
    },
    (payload) => console.log(payload)
)
.on(
    'postgres_changes',
    {
      event: 'INSERT',
      schema: 'public',
      table: 'users',
    },
    (payload) => console.log(payload)
)
.subscribe()
`

### Filtering for specific changes [\#](https://supabase.com/docs/guides/realtime/postgres-changes\#filtering-for-specific-changes)

Use the `filter` parameter for granular changes:

JavaScriptDartSwiftKotlinPython

`
const changes = supabase
.channel('table-filter-changes')
.on(
    'postgres_changes',
    {
      event: 'INSERT',
      schema: 'public',
      table: 'todos',
      filter: 'id=eq.1',
    },
    (payload) => console.log(payload)
)
.subscribe()
`

## Available filters [\#](https://supabase.com/docs/guides/realtime/postgres-changes\#available-filters)

Realtime offers filters so you can specify the data your client receives at a more granular level.

### Equal to ( `eq`) [\#](https://supabase.com/docs/guides/realtime/postgres-changes\#equal-to--eq-)

To listen to changes when a column's value in a table equals a client-specified value:

JavaScriptDartSwiftKotlinPython

`
const channel = supabase
.channel('changes')
.on(
    'postgres_changes',
    {
      event: 'UPDATE',
      schema: 'public',
      table: 'messages',
      filter: 'body=eq.hey',
    },
    (payload) => console.log(payload)
)
.subscribe()
`

This filter uses Postgres's `=` filter.

### Not equal to ( `neq`) [\#](https://supabase.com/docs/guides/realtime/postgres-changes\#not-equal-to--neq-)

To listen to changes when a column's value in a table does not equal a client-specified value:

JavaScriptDartSwiftKotlinPython

`
const channel = supabase
.channel('changes')
.on(
    'postgres_changes',
    {
      event: 'INSERT',
      schema: 'public',
      table: 'messages',
      filter: 'body=neq.bye',
    },
    (payload) => console.log(payload)
)
.subscribe()
`

This filter uses Postgres's `!=` filter.

### Less than ( `lt`) [\#](https://supabase.com/docs/guides/realtime/postgres-changes\#less-than--lt-)

To listen to changes when a column's value in a table is less than a client-specified value:

JavaScriptDartSwiftKotlinPython

`
const channel = supabase
.channel('changes')
.on(
    'postgres_changes',
    {
      event: 'INSERT',
      schema: 'public',
      table: 'profiles',
      filter: 'age=lt.65',
    },
    (payload) => console.log(payload)
)
.subscribe()
`

This filter uses Postgres's `<` filter, so it works for non-numeric types. Make sure to check the expected behavior of the compared data's type.

### Less than or equal to ( `lte`) [\#](https://supabase.com/docs/guides/realtime/postgres-changes\#less-than-or-equal-to--lte-)

To listen to changes when a column's value in a table is less than or equal to a client-specified value:

JavaScriptDartSwiftKotlinPython

`
const channel = supabase
.channel('changes')
.on(
    'postgres_changes',
    {
      event: 'UPDATE',
      schema: 'public',
      table: 'profiles',
      filter: 'age=lte.65',
    },
    (payload) => console.log(payload)
)
.subscribe()
`

This filter uses Postgres' `<=` filter, so it works for non-numeric types. Make sure to check the expected behavior of the compared data's type.

### Greater than ( `gt`) [\#](https://supabase.com/docs/guides/realtime/postgres-changes\#greater-than--gt-)

To listen to changes when a column's value in a table is greater than a client-specified value:

JavaScriptDartSwiftKotlinPython

`
const channel = supabase
.channel('changes')
.on(
    'postgres_changes',
    {
      event: 'INSERT',
      schema: 'public',
      table: 'products',
      filter: 'quantity=gt.10',
    },
    (payload) => console.log(payload)
)
.subscribe()
`

This filter uses Postgres's `>` filter, so it works for non-numeric types. Make sure to check the expected behavior of the compared data's type.

### Greater than or equal to ( `gte`) [\#](https://supabase.com/docs/guides/realtime/postgres-changes\#greater-than-or-equal-to--gte-)

To listen to changes when a column's value in a table is greater than or equal to a client-specified value:

JavaScriptDartSwiftKotlinPython

`
const channel = supabase
.channel('changes')
.on(
    'postgres_changes',
    {
      event: 'INSERT',
      schema: 'public',
      table: 'products',
      filter: 'quantity=gte.10',
    },
    (payload) => console.log(payload)
)
.subscribe()
`

This filter uses Postgres's `>=` filter, so it works for non-numeric types. Make sure to check the expected behavior of the compared data's type.

### Contained in list (in) [\#](https://supabase.com/docs/guides/realtime/postgres-changes\#contained-in-list-in)

To listen to changes when a column's value in a table equals any client-specified values:

JavaScriptDartSwiftKotlinPython

`
const channel = supabase
.channel('changes')
.on(
    'postgres_changes',
    {
      event: 'INSERT',
      schema: 'public',
      table: 'colors',
      filter: 'name=in.(red, blue, yellow)',
    },
    (payload) => console.log(payload)
)
.subscribe()
`

This filter uses Postgres's `= ANY`. Realtime allows a maximum of 100 values for this filter.

## Receiving `old` records [\#](https://supabase.com/docs/guides/realtime/postgres-changes\#receiving-old-records)

By default, only `new` record changes are sent but if you want to receive the `old` record (previous values) whenever you `UPDATE` or `DELETE` a record, you can set the `replica identity` of your table to `full`:

`
alter table
messages replica identity full;
`

RLS policies are not applied to `DELETE` statements, because there is no way for Postgres to verify that a user has access to a deleted record. When RLS is enabled and `replica identity` is set to `full` on a table, the `old` record contains only the primary key(s).

## Private schemas [\#](https://supabase.com/docs/guides/realtime/postgres-changes\#private-schemas)

Postgres Changes works out of the box for tables in the `public` schema. You can listen to tables in your private schemas by granting table `SELECT` permissions to the database role found in your access token. You can run a query similar to the following:

`
grant select on "non_private_schema"."some_table" to authenticated;
`

We strongly encourage you to enable RLS and create policies for tables in private schemas. Otherwise, any role you grant access to will have unfettered read access to the table.

## Custom tokens [\#](https://supabase.com/docs/guides/realtime/postgres-changes\#custom-tokens)

You may choose to sign your own tokens to customize claims that can be checked in your RLS policies.

Your project JWT secret is found with your [Project API keys](https://app.supabase.com/project/_/settings/api) in your dashboard.

Do not expose the `service_role` token on the client because the role is authorized to bypass row-level security.

To use your own JWT with Realtime make sure to set the token after instantiating the Supabase client and before connecting to a Channel.

JavaScriptDartSwiftKotlinPython

`
const { createClient } = require('@supabase/supabase-js')
const supabase = createClient(process.env.SUPABASE_URL, process.env.SUPABASE_KEY, {})
// Set your custom JWT here
supabase.realtime.setAuth('your-custom-jwt')
const channel = supabase
.channel('db-changes')
.on(
    'postgres_changes',
    {
      event: '*',
      schema: 'public',
      table: 'messages',
      filter: 'body=eq.bye',
    },
    (payload) => console.log(payload)
)
.subscribe()
`

### Refreshed tokens [\#](https://supabase.com/docs/guides/realtime/postgres-changes\#refreshed-tokens)

You will need to refresh tokens on your own, but once generated, you can pass them to Realtime.

JavaScriptDartSwiftKotlinPython

For example, if you're using the `supabase-js` `v2` client then you can pass your token like this:

`
// Client setup
supabase.realtime.setAuth('fresh-token')
`

## Limitations [\#](https://supabase.com/docs/guides/realtime/postgres-changes\#limitations)

### Delete events are not filterable [\#](https://supabase.com/docs/guides/realtime/postgres-changes\#delete-events-are-not-filterable)

You can't filter Delete events when tracking Postgres Changes. This limitation is due to the way changes are pulled from Postgres.

### Spaces in table names [\#](https://supabase.com/docs/guides/realtime/postgres-changes\#spaces-in-table-names)

Realtime currently does not work when table names contain spaces.

### Database instance and realtime performance [\#](https://supabase.com/docs/guides/realtime/postgres-changes\#database-instance-and-realtime-performance)

Realtime systems usually require forethought because of their scaling dynamics. For the `Postgres Changes` feature, every change event must be checked to see if the subscribed user has access. For instance, if you have 100 users subscribed to a table where you make a single insert, it will then trigger 100 "reads": one for each user.

There can be a database bottleneck which limits message throughput. If your database cannot authorize the changes rapidly enough, the changes will be delayed until you receive a timeout.

Database changes are processed on a single thread to maintain the change order. That means compute upgrades don't have a large effect on the performance of Postgres change subscriptions. You can estimate the expected maximum throughput for your database below.

If you are using Postgres Changes at scale, you should consider using separate "public" table without RLS and filters. Alternatively, you can use Realtime server-side only and then re-stream the changes to your clients using a Realtime Broadcast.

Enter your database settings to estimate the maximum throughput for your instance:

#### Set your expected parameters

Compute:

MicroSmall to mediumLarge to 16XL

Filters:

NoYes

RLS:

NoYes

Connected clients:

5005,00010,00030,000

#### Current maximum possible throughput

| Total DB changes /sec | Max messages per client /sec | Max total messages /sec | Latency p95 |
| --- | --- | --- | --- |
| 64 | 64 | 32,000 | 238ms |

View raw throughput table

Don't forget to run your own benchmarks to make sure that the performance is acceptable for your use case.

We are making many improvements to Realtime's Postgres Changes. If you are uncertain about the performance of your use case, reach out using [Support Form](https://supabase.com/dashboard/support/new) and we will be happy to help you. We have a team of engineers that can advise you on the best solution for your use-case.

### Is this helpful?

NoYes

### On this page

[Quick start](https://supabase.com/docs/guides/realtime/postgres-changes#quick-start) [Usage](https://supabase.com/docs/guides/realtime/postgres-changes#usage) [Listening to specific schemas](https://supabase.com/docs/guides/realtime/postgres-changes#listening-to-specific-schemas) [Listening to INSERT events](https://supabase.com/docs/guides/realtime/postgres-changes#listening-to-insert-events) [Listening to UPDATE events](https://supabase.com/docs/guides/realtime/postgres-changes#listening-to-update-events) [Listening to DELETE events](https://supabase.com/docs/guides/realtime/postgres-changes#listening-to-delete-events) [Listening to specific tables](https://supabase.com/docs/guides/realtime/postgres-changes#listening-to-specific-tables) [Listening to multiple changes](https://supabase.com/docs/guides/realtime/postgres-changes#listening-to-multiple-changes) [Filtering for specific changes](https://supabase.com/docs/guides/realtime/postgres-changes#filtering-for-specific-changes) [Available filters](https://supabase.com/docs/guides/realtime/postgres-changes#available-filters) [Equal to (eq)](https://supabase.com/docs/guides/realtime/postgres-changes#equal-to--eq-) [Not equal to (neq)](https://supabase.com/docs/guides/realtime/postgres-changes#not-equal-to--neq-) [Less than (lt)](https://supabase.com/docs/guides/realtime/postgres-changes#less-than--lt-) [Less than or equal to (lte)](https://supabase.com/docs/guides/realtime/postgres-changes#less-than-or-equal-to--lte-) [Greater than (gt)](https://supabase.com/docs/guides/realtime/postgres-changes#greater-than--gt-) [Greater than or equal to (gte)](https://supabase.com/docs/guides/realtime/postgres-changes#greater-than-or-equal-to--gte-) [Contained in list (in)](https://supabase.com/docs/guides/realtime/postgres-changes#contained-in-list-in) [Receiving old records](https://supabase.com/docs/guides/realtime/postgres-changes#receiving-old-records) [Private schemas](https://supabase.com/docs/guides/realtime/postgres-changes#private-schemas) [Custom tokens](https://supabase.com/docs/guides/realtime/postgres-changes#custom-tokens) [Refreshed tokens](https://supabase.com/docs/guides/realtime/postgres-changes#refreshed-tokens) [Limitations](https://supabase.com/docs/guides/realtime/postgres-changes#limitations) [Delete events are not filterable](https://supabase.com/docs/guides/realtime/postgres-changes#delete-events-are-not-filterable) [Spaces in table names](https://supabase.com/docs/guides/realtime/postgres-changes#spaces-in-table-names) [Database instance and realtime performance](https://supabase.com/docs/guides/realtime/postgres-changes#database-instance-and-realtime-performance)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_realtime_presence.md">
Realtime

# Presence

## Share state between users with Realtime Presence.

* * *

Let's explore how to implement Realtime Presence to track state between multiple users.

## Usage [\#](https://supabase.com/docs/guides/realtime/presence\#usage)

You can use the Supabase client libraries to track Presence state between users.

### Initialize the client [\#](https://supabase.com/docs/guides/realtime/presence\#initialize-the-client)

Go to your Supabase project's [API Settings](https://supabase.com/dashboard/project/_/settings/api) and grab the `URL` and `anon` public API key.

JavaScriptDartSwiftKotlinPython

`
import { createClient } from '@supabase/supabase-js'
const SUPABASE_URL = 'https://<project>.supabase.co'
const SUPABASE_KEY = '<your-anon-key>'
const supabase = createClient(SUPABASE_URL, SUPABASE_KEY)
`

### Sync and track state [\#](https://supabase.com/docs/guides/realtime/presence\#sync-and-track-state)

JavaScriptDartSwiftKotlinPython

Listen to the `sync`, `join`, and `leave` events triggered whenever any client joins or leaves the channel or changes their slice of state:

`
const roomOne = supabase.channel('room_01')
roomOne
.on('presence', { event: 'sync' }, () => {
    const newState = roomOne.presenceState()
    console.log('sync', newState)
})
.on('presence', { event: 'join' }, ({ key, newPresences }) => {
    console.log('join', key, newPresences)
})
.on('presence', { event: 'leave' }, ({ key, leftPresences }) => {
    console.log('leave', key, leftPresences)
})
.subscribe()
`

### Sending state [\#](https://supabase.com/docs/guides/realtime/presence\#sending-state)

You can send state to all subscribers using `track()`:

JavaScriptDartSwiftKotlinPython

`
const roomOne = supabase.channel('room_01')
const userStatus = {
user: 'user-1',
online_at: new Date().toISOString(),
}
roomOne.subscribe(async (status) => {
if (status !== 'SUBSCRIBED') { return }
const presenceTrackStatus = await roomOne.track(userStatus)
console.log(presenceTrackStatus)
})
`

A client will receive state from any other client that is subscribed to the same topic (in this case `room_01`). It will also automatically trigger its own `sync` and `join` event handlers.

### Stop tracking [\#](https://supabase.com/docs/guides/realtime/presence\#stop-tracking)

You can stop tracking presence using the `untrack()` method. This will trigger the `sync` and `leave` event handlers.

JavaScriptDartSwiftKotlinPython

`
const untrackPresence = async () => {
const presenceUntrackStatus = await roomOne.untrack()
console.log(presenceUntrackStatus)
}
untrackPresence()
`

## Presence options [\#](https://supabase.com/docs/guides/realtime/presence\#presence-options)

You can pass configuration options while initializing the Supabase Client.

### Presence key [\#](https://supabase.com/docs/guides/realtime/presence\#presence-key)

By default, Presence will generate a unique `UUIDv1` key on the server to track a client channel's state. If you prefer, you can provide a custom key when creating the channel. This key should be unique among clients.

JavaScriptDartSwiftKotlinPython

`
import { createClient } from '@supabase/supabase-js'
const channelC = supabase.channel('test', {
config: {
    presence: {
      key: 'userId-123',
    },
},
})
`

### Is this helpful?

NoYes

### On this page

[Usage](https://supabase.com/docs/guides/realtime/presence#usage) [Initialize the client](https://supabase.com/docs/guides/realtime/presence#initialize-the-client) [Sync and track state](https://supabase.com/docs/guides/realtime/presence#sync-and-track-state) [Sending state](https://supabase.com/docs/guides/realtime/presence#sending-state) [Stop tracking](https://supabase.com/docs/guides/realtime/presence#stop-tracking) [Presence options](https://supabase.com/docs/guides/realtime/presence#presence-options) [Presence key](https://supabase.com/docs/guides/realtime/presence#presence-key)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_realtime_pricing.md">
Realtime

# Realtime Pricing

* * *

You are charged for the number of Realtime messages and the number of Realtime peak connections.

## Messages [\#](https://supabase.com/docs/guides/realtime/pricing\#messages)

$2.50 per 1 million messages. You are only charged for usage exceeding your subscription plan's quota.

| Plan | Quota | Over-Usage |
| --- | --- | --- |
| Free | 2 million | - |
| Pro | 5 million | $2.50 per 1 million messages |
| Team | 5 million | $2.50 per 1 million messages |
| Enterprise | Custom | Custom |

For a detailed explanation of how charges are calculated, refer to [Manage Realtime Messages usage](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-messages).

## Peak connections [\#](https://supabase.com/docs/guides/realtime/pricing\#peak-connections)

$10 per 1,000 peak connections. You are only charged for usage exceeding your subscription plan's quota.

| Plan | Quota | Over-Usage |
| --- | --- | --- |
| Free | 200 | - |
| Pro | 500 | $10 per 1,000 peak connections |
| Team | 500 | $10 per 1,000 peak connections |
| Enterprise | Custom | Custom |

For a detailed explanation of how charges are calculated, refer to [Manage Realtime Peak Connections usage](https://supabase.com/docs/guides/platform/manage-your-usage/realtime-peak-connections).

### Is this helpful?

NoYes

### On this page

[Messages](https://supabase.com/docs/guides/realtime/pricing#messages) [Peak connections](https://supabase.com/docs/guides/realtime/pricing#peak-connections)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_realtime_protocol.md">
Realtime

# Realtime Protocol

* * *

The Realtime Protocol is a set of message formats used for communication over a WebSocket connection between a Realtime client and server. These messages are used to initiate a connection, update access tokens, receive system status updates, and receive real-time updates from the Postgres database.

## Connection [\#](https://supabase.com/docs/guides/realtime/protocol\#connection)

In the initial message, the client sends a message specifying the features they want to use (Broadcast, Presence, Postgres Changes).

`
{
"event": "phx_join",
"topic": string,
"payload": {
      "config": {
         "broadcast": {
            "self": boolean
         },
         "presence": {
            "key": string
         },
         "postgres_changes": [\
            {\
               "event": "*" | "INSERT" | "UPDATE" | "DELETE",\
               "schema": string,\
               "table": string,\
               "filter": string + '=' + "eq" | "neq" | "gt" | "gte" | "lt" | "lte" | "in" +  '.' + string\
            }\
         ]
      }
},
"ref": string
}
`

The `in` filter has the format `COLUMN_NAME=in.(value1,value2,value3)`. However, other filters use the format `COLUMN_NAME=FILTER_NAME.value`.

In response, the server sends the Postgres configuration with a unique ID. With this ID, the client should route incoming changes to the appropriate callback.

`
{
"event": "phx_reply",
"topic": string,
"payload": {
      "response": {
         "postgres_changes": [\
            {\
               "id": number,\
               "event": "*" | "INSERT" | "UPDATE" | "DELETE",\
               "schema": string,\
               "table": string,\
               "filter": string + '=' + "eq" | "neq" | "gt" | "gte" | "lt" | "lte" | "in" +  '.' + string\
            }\
         ]
      },
      "status": "ok" | "error"
},
"ref": string
}
`

## System messages [\#](https://supabase.com/docs/guides/realtime/protocol\#system-messages)

System message are used to inform a client about the status of the Postgres subscription. The `payload.status` indicates if the subscription successful or not.
The body of the `payload.message` can be "Subscribed to Postgres" or "Subscribing to Postgres failed" with subscription params.

`
{
"event": "system",
"topic": string,
"payload":{
      "channel": string,
      "extension": "postgres_changes",
      "message": "Subscribed to PostgreSQL" | "Subscribing to PostgreSQL failed",
      "status": "ok" | "error"
},
"ref": null,
}
`

## Heartbeat [\#](https://supabase.com/docs/guides/realtime/protocol\#heartbeat)

The heartbeat message should be sent every 30 seconds to avoid a connection timeout.

`
{
"event": "heartbeat",
"topic": "phoenix",
"payload": {},
"ref": string
}
`

## Access token [\#](https://supabase.com/docs/guides/realtime/protocol\#access-token)

To update the access token, you need to send to the server a message specifying a new token in the `payload.access_token` value.

`
{
"event": "access_token",
"topic": string,
"payload":{
      "access_token": string
},
"ref": string
}
`

## Postgres CDC message [\#](https://supabase.com/docs/guides/realtime/protocol\#postgres-cdc-message)

Realtime sends a message with the following structure. By default, the payload only includes new record changes, and the `old` entry includes the changed row's primary id. If you want to receive old records, you can set the replicate identity of your table to full. Check out [this section of the guide](https://supabase.com/docs/guides/realtime/postgres-changes#receiving-old-records).

`
{
"event": "postgres_changes",
"topic": string,
"payload": {
      "data": {
         schema: string,
         table: string,
         commit_timestamp: string,
         eventType: "*" | "INSERT" | "UPDATE" | "DELETE",
         new: {[key: string]: boolean | number | string | null},
         old: {[key: string]: number | string},
         errors: string | null
      },
      "ids": Array<number>
},
"ref": null
}
`

## Broadcast message [\#](https://supabase.com/docs/guides/realtime/protocol\#broadcast-message)

Structure of the broadcast event

`
{
"event": "broadcast",
"topic": string,
"payload": {
      "event": string,
      "payload": {[key: string]: boolean | number | string | null | undefined},
      "type": "broadcast"
},
"ref": null
}
`

## Presence message [\#](https://supabase.com/docs/guides/realtime/protocol\#presence-message)

The Presence events allow clients to monitor the online status of other clients in real-time.

### State update [\#](https://supabase.com/docs/guides/realtime/protocol\#state-update)

After joining, the server sends a `presence_state` message to a client with presence information. The payload field contains keys in UUID format, where each key represents a client and its value is a JSON object containing information about that client.

`
{
"event": "presence_state",
"topic": string,
"payload": {
      [key: string]: {metas: Array<{phx_ref: string, name: string, t: float}>}
},
"ref": null
}
`

### Diff update [\#](https://supabase.com/docs/guides/realtime/protocol\#diff-update)

After a change to the presence state, such as a client joining or leaving, the server sends a presence\_diff message to update the client's view of the presence state. The payload field contains two keys, `joins` and `leaves`, which represent clients that have joined and left, respectively. The values associated with each key are UUIDs of the clients.

`
{
"event": "presence_diff",
"topic": string,
"payload": {
      "joins": {metas: Array<{phx_ref: string, name: string, t: float}>},
      "leaves": {metas: Array<{phx_ref: string, name: string, t: float}>}
},
"ref": null
}
`

### Is this helpful?

NoYes

### On this page

[Connection](https://supabase.com/docs/guides/realtime/protocol#connection) [System messages](https://supabase.com/docs/guides/realtime/protocol#system-messages) [Heartbeat](https://supabase.com/docs/guides/realtime/protocol#heartbeat) [Access token](https://supabase.com/docs/guides/realtime/protocol#access-token) [Postgres CDC message](https://supabase.com/docs/guides/realtime/protocol#postgres-cdc-message) [Broadcast message](https://supabase.com/docs/guides/realtime/protocol#broadcast-message) [Presence message](https://supabase.com/docs/guides/realtime/protocol#presence-message) [State update](https://supabase.com/docs/guides/realtime/protocol#state-update) [Diff update](https://supabase.com/docs/guides/realtime/protocol#diff-update)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_realtime_quotas.md">
Realtime

# Realtime Quotas

* * *

Our cluster supports millions of concurrent connections and message throughput for production workloads.

Upgrade your plan to increase your quotas. Without a spend cap, or on an Enterprise plan, some quotas are still in place to protect budgets. All quotas are configurable per project. [Contact support](https://supabase.com/dashboard/support/new) if you need your quotas increased.

## Quotas by plan [\#](https://supabase.com/docs/guides/realtime/quotas\#quotas-by-plan)

|  | Free | Pro | Pro (no spend cap) | Team | Enterprise |
| --- | --- | --- | --- | --- | --- |
| **Concurrent connections** | 200 | 500 | 10,000 | 10,000 | 10,000+ |
| **Messages per second** | 100 | 500 | 2,500 | 2,500 | 2,500+ |
| **Channel joins per second** | 100 | 500 | 2,500 | 2,500 | 2,500+ |
| **Channels per connection** | 100 | 100 | 100 | 100 | 100+ |
| **Presence keys per object** | 10 | 10 | 10 | 10 | 10+ |
| **Presence messages per second** | 20 | 50 | 1,000 | 1,000 | 1,000+ |
| **Broadcast payload size KB** | 256 | 3,000 | 3,000 | 3,000 | 3,000+ |
| **Postgres change payload size KB ( [**read more**](https://supabase.com/docs/guides/realtime/quotas#postgres-changes-payload-quota))** | 1,024 | 1,024 | 1,024 | 1,024 | 1,024+ |

Beyond the Free and Pro Plan you can customize your quotas by [contacting support](https://supabase.com/dashboard/support/new).

## Quota errors [\#](https://supabase.com/docs/guides/realtime/quotas\#quota-errors)

When you exceed a quota, errors will appear in the backend logs and client-side messages in the WebSocket connection.

- **Logs**: check the [Realtime logs](https://supabase.com/dashboard/project/_/database/realtime-logs) inside your project Dashboard.
- **WebSocket errors**: Use your browser's developer tools to find the WebSocket initiation request and view individual messages.

##### Realtime Inspector

You can use the [Realtime Inspector](https://realtime.supabase.com/inspector/new) to reproduce an error and share those connection details with Supabase support.

Some quotas can cause a Channel join to be refused. Realtime will reply with one of the following WebSocket messages:

### `too_many_channels` [\#](https://supabase.com/docs/guides/realtime/quotas\#toomanychannels)

Too many channels currently joined for a single connection.

### `too_many_connections` [\#](https://supabase.com/docs/guides/realtime/quotas\#toomanyconnections)

Too many total concurrent connections for a project.

### `too_many_joins` [\#](https://supabase.com/docs/guides/realtime/quotas\#toomanyjoins)

Too many Channel joins per second.

### `tenant_events` [\#](https://supabase.com/docs/guides/realtime/quotas\#tenantevents)

Connections will be disconnected if your project is generating too many messages per second. `supabase-js` will reconnect automatically when the message throughput decreases below your plan quota. An `event` is a WebSocket message delivered to, or sent from a client.

## Postgres changes payload quota [\#](https://supabase.com/docs/guides/realtime/quotas\#postgres-changes-payload-quota)

When this quota is reached, the `new` and `old` record payloads only include the fields with a value size of less than or equal to 64 bytes.

### Is this helpful?

NoYes

### On this page

[Quotas by plan](https://supabase.com/docs/guides/realtime/quotas#quotas-by-plan) [Quota errors](https://supabase.com/docs/guides/realtime/quotas#quota-errors) [too\_many\_channels](https://supabase.com/docs/guides/realtime/quotas#toomanychannels) [too\_many\_connections](https://supabase.com/docs/guides/realtime/quotas#toomanyconnections) [too\_many\_joins](https://supabase.com/docs/guides/realtime/quotas#toomanyjoins) [tenant\_events](https://supabase.com/docs/guides/realtime/quotas#tenantevents) [Postgres changes payload quota](https://supabase.com/docs/guides/realtime/quotas#postgres-changes-payload-quota)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_realtime_realtime_listening_flutter.md">
Realtime

# Listening to Postgres Changes with Flutter

* * *

The Postgres Changes extension listens for database changes and sends them to clients which enables you to receive database changes in real-time.

Listening to real-time changes on the database with Flutter and Supabase - YouTube

Supabase

45.5K subscribers

[Listening to real-time changes on the database with Flutter and Supabase](https://www.youtube.com/watch?v=gboTC2lcgzw)

Supabase

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=gboTC2lcgzw "Watch on YouTube")

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_realtime_realtime_user_presence.md">
Realtime

# Using Realtime Presence with Flutter

* * *

Use Supabase Presence to display the currently online users on your Flutter application.

Displaying the list of currently online users is a common feature for real-time collaborative applications. Supabase Presence makes it easy to track users joining and leaving the session so that you can make a collaborative app.

Track online users with Supabase Realtime Presence \| Flutter Figma Clone #3 - YouTube

Supabase

45.5K subscribers

[Track online users with Supabase Realtime Presence \| Flutter Figma Clone #3](https://www.youtube.com/watch?v=B2NZvZ2uLNs)

Supabase

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=B2NZvZ2uLNs "Watch on YouTube")

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_realtime_realtime_with_nextjs.md">
Realtime

# Using Realtime with Next.js

* * *

In this guide, we explore the best ways to receive real-time Postgres changes with your Next.js application.
We'll show both client and server side updates, and explore which option is best.

Client vs Server Components in Next.js app directory // Merging server state with realtime updates - YouTube

Supabase

45.5K subscribers

[Client vs Server Components in Next.js app directory // Merging server state with realtime updates](https://www.youtube.com/watch?v=YR-xP6PPXXA)

Supabase

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=YR-xP6PPXXA "Watch on YouTube")

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_realtime_subscribing_to_database_changes.md">
Realtime

# Subscribing to Database Changes

* * *

Supabase allows you to subscribe to real-time changes on your database from your client application.

You can listen to database changes using the [Postgres Changes](https://supabase.com/docs/guides/realtime/postgres-changes) extension.
The following video shows how you can enable this feature for your tables.

## Demo [\#](https://supabase.com/docs/guides/realtime/subscribing-to-database-changes\#demo)

How to subscribe to real-time changes on your database - SupabaseTips - YouTube

Supabase

45.5K subscribers

[How to subscribe to real-time changes on your database - SupabaseTips](https://www.youtube.com/watch?v=2rUjcmgZDwQ)

Supabase

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=2rUjcmgZDwQ "Watch on YouTube")

## Setup [\#](https://supabase.com/docs/guides/realtime/subscribing-to-database-changes\#setup)

You'll first need to create a `supabase_realtime` publication and add your tables (that you want to subscribe to) to the publication:

`
begin;
-- remove the supabase_realtime publication
drop
publication if exists supabase_realtime;
-- re-create the supabase_realtime publication with no tables
create publication supabase_realtime;
commit;
-- add a table called 'messages' to the publication
-- (update this to match your tables)
alter
publication supabase_realtime add table messages;
`

## Streaming inserts [\#](https://supabase.com/docs/guides/realtime/subscribing-to-database-changes\#streaming-inserts)

You can use the `INSERT` event to stream all new rows.

`
import { createClient } from '@supabase/supabase-js'
const supabase = createClient(process.env.SUPABASE_URL, process.env.SUPABASE_KEY)
const channel = supabase
.channel('schema-db-changes')
.on(
    'postgres_changes',
    {
      event: 'INSERT',
      schema: 'public',
    },
    (payload) => console.log(payload)
)
.subscribe()
`

## Streaming updates [\#](https://supabase.com/docs/guides/realtime/subscribing-to-database-changes\#streaming-updates)

You can use the `UPDATE` event to stream all updated rows.

`
import { createClient } from '@supabase/supabase-js'
const supabase = createClient(process.env.SUPABASE_URL, process.env.SUPABASE_KEY)
const channel = supabase
.channel('schema-db-changes')
.on(
    'postgres_changes',
    {
      event: 'UPDATE',
      schema: 'public',
    },
    (payload) => console.log(payload)
)
.subscribe()
`

## More resources [\#](https://supabase.com/docs/guides/realtime/subscribing-to-database-changes\#more-resources)

- Learn more about the [Postgres Changes](https://supabase.com/docs/guides/realtime/postgres-changes) extension.
- Client Libraries:
  - [JavaScript](https://supabase.com/docs/reference/javascript/subscribe)
  - [Flutter](https://supabase.com/docs/reference/dart/stream)
  - [Python](https://supabase.com/docs/reference/python/subscribe)
  - [C#](https://supabase.com/docs/reference/csharp/subscribe)

### Is this helpful?

NoYes

### On this page

[Demo](https://supabase.com/docs/guides/realtime/subscribing-to-database-changes#demo) [Setup](https://supabase.com/docs/guides/realtime/subscribing-to-database-changes#setup) [Streaming inserts](https://supabase.com/docs/guides/realtime/subscribing-to-database-changes#streaming-inserts) [Streaming updates](https://supabase.com/docs/guides/realtime/subscribing-to-database-changes#streaming-updates) [More resources](https://supabase.com/docs/guides/realtime/subscribing-to-database-changes#more-resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_realtime.md">
Realtime

# Realtime

## Send and receive messages to connected clients.

* * *

Supabase provides a globally distributed cluster of [Realtime](https://github.com/supabase/realtime) servers that enable the following functionality:

- [Broadcast](https://supabase.com/docs/guides/realtime/broadcast): Send ephemeral messages from client to clients with low latency.
- [Presence](https://supabase.com/docs/guides/realtime/presence): Track and synchronize shared state between clients.
- [Postgres Changes](https://supabase.com/docs/guides/realtime/postgres-changes): Listen to Postgres database changes and send them to authorized clients.

### Realtime API [\#](https://supabase.com/docs/guides/realtime\#realtime-api)

By default Realtime is disabled on your database. Let's turn on Realtime for a `todos` table.

DashboardSQL

1. Go to the [Database](https://supabase.com/dashboard/project/_/database/tables) page in the Dashboard.
2. Click on **Publications** in the sidebar.
3. Control which database events are sent by toggling **Insert**, **Update**, and **Delete**.
4. Control which tables broadcast changes by selecting **Source** and toggling each table.

From the client, we can listen to any new data that is inserted into the `todos` table:

JavaScriptDartSwiftPython

`
// Initialize the JS client
import { createClient } from '@supabase/supabase-js'
const supabase = createClient(SUPABASE_URL, SUPABASE_ANON_KEY)
// Create a function to handle inserts
const handleInserts = (payload) => {
console.log('Change received!', payload)
}
// Listen to inserts
supabase
.channel('todos')
.on('postgres_changes', { event: 'INSERT', schema: 'public', table: 'todos' }, handleInserts)
.subscribe()
`

Use [subscribe()](https://supabase.com/docs/reference/javascript/subscribe) to listen to database changes.
The Realtime API works through PostgreSQL's replication functionality. Postgres sends database changes to a [publication](https://supabase.com/docs/guides/database/replication#publications)
called `supabase_realtime`, and by managing this publication you can control which data is broadcast.

## Examples [\#](https://supabase.com/docs/guides/realtime\#examples)

[Multiplayer.dev\\
\\
Mouse movements and chat messages.](https://multiplayer.dev/)

## Resources [\#](https://supabase.com/docs/guides/realtime\#resources)

Find the source code and documentation in the Supabase GitHub repository.

[Supabase Realtime\\
\\
View the source code.](https://github.com/supabase/realtime)

[Realtime: Multiplayer Edition\\
\\
Read more about Supabase Realtime.](https://supabase.com/blog/supabase-realtime-multiplayer-general-availability)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_resources_glossary.md">
Resources

# Glossary

* * *

Definitions for terminology and acronyms used in the Supabase documentation.

## Access token [\#](https://supabase.com/docs/guides/resources/glossary\#access-token)

An access token is a short-lived (usually no more than 1 hour) token that authorizes a client to access resources on a server. It comes in the form of a [JSON Web Token (JWT)](https://supabase.com/docs/guides/resources/glossary#json-web-token-jwt).

## Authentication [\#](https://supabase.com/docs/guides/resources/glossary\#authentication)

Authentication (often abbreviated `authn.`) is the process of verifying the identity of a user. Verification of the identity of a user can happen in multiple ways:

1. Asking users for something they know. For example: password, passphrase.
2. Checking that users have access to something they own. For example: an email address, a phone number, a hardware key, recovery codes.
3. Confirming that users have some biological features. For example: a fingerprint, a certain facial structure, an iris print.

## Authenticator app [\#](https://supabase.com/docs/guides/resources/glossary\#authenticator-app)

An authenticator app generates time-based one-time passwords (TOTPs). These passwords are generated based off a long and difficult to guess secret string. The secret is initially passed to the application by scanning a QR code.

## Authorization [\#](https://supabase.com/docs/guides/resources/glossary\#authorization)

Authorization (often abbreviated `authz.`) is the process of verifying if a certain identity is allowed to access resources. Authorization often occurs by verifying an access token.

## Identity provider [\#](https://supabase.com/docs/guides/resources/glossary\#identity-provider)

An identity provider is software or service that allows third-party applications to identify users without the exchange of passwords. Social login and enterprise single-sign on won't be possible without identity providers.

Social login platforms typically use the OAuth protocol, while enterprise single-sign on is based on the OIDC or SAML protocols.

## JSON Web Token (JWT) [\#](https://supabase.com/docs/guides/resources/glossary\#json-web-token-jwt)

A [JSON Web Token](https://jwt.io/introduction) is a type of data structure, represented as a string, that usually contains identity and authorization information about a user. It encodes information about its lifetime and is signed with cryptographic key making it tamper resistant.

Access tokens are JWTs and by inspecting the information they contain you can allow or deny access to resources. Row level security policies are based on the information present in JWTs.

## JWT signing secret [\#](https://supabase.com/docs/guides/resources/glossary\#jwt-signing-secret)

JWTs issued by Supabase are signed using the HMAC-SHA256 algorithm. The secret key used in the signing is called the JWT signing secret. You should not share this secret with someone or some thing you don't trust, nor should you post it publicly. Anyone with access to the secret can create arbitrary JWTs.

## Multi-factor authentication (MFA or 2FA) [\#](https://supabase.com/docs/guides/resources/glossary\#multi-factor-authentication-mfa-or-2fa)

Multi-factor authentication is the process of authenticating a user's identity by using a combination of factors: something users know, something users have or something they are.

## Nonce [\#](https://supabase.com/docs/guides/resources/glossary\#nonce)

Nonce means number used once. In reality though, it is a unique and difficult to guess string used to either initialize a protocol or algorithm securely, or detect abuse in various forms of replay attacks.

## OAuth [\#](https://supabase.com/docs/guides/resources/glossary\#oauth)

OAuth is a protocol allowing third-party applications to request and receive authorization from their users. It is typically used to implement social login, and serves as a base for enterprise single-sign on in the OIDC protocol. Applications can request different levels of access, including basic user identification information such as name, email address, and user ID.

## OIDC [\#](https://supabase.com/docs/guides/resources/glossary\#oidc)

OIDC stands for OpenID Connect and is a protocol that enables single-sign on for enterprises. OIDC is based on modern web technologies such as OAuth and JSON Web Tokens. It is commonly used instead of the older SAML protocol.

## One-time password (OTP) [\#](https://supabase.com/docs/guides/resources/glossary\#one-time-password-otp)

A one-time password is a short, randomly generated and difficult to guess password or code that is sent to a device (like a phone number) or generated by a device or application.

## Password hashing function [\#](https://supabase.com/docs/guides/resources/glossary\#password-hashing-function)

Password hashing functions are specially-designed algorithms that allow web servers to verify a password without storing it as-is. Unlike other difficult to guess strings generated from secure random number generators, passwords are picked by users and often are easy to guess by attackers. These algorithms slow down and make it very costly for attackers to guess passwords.

There are three generally accepted password hashing functions: Argon2, bcrypt and scrypt.

## Password strength [\#](https://supabase.com/docs/guides/resources/glossary\#password-strength)

Password strength is a measurement of how difficult a password is to guess. Simple measurement includes calculating the number of possibilities given the types of characters used in the password. For example a password of only letters has fewer variations than ones with letters and digits. Better measurements include strategies such as looking for similarity to words, phrases or already known passwords.

## PKCE [\#](https://supabase.com/docs/guides/resources/glossary\#pkce)

Proof Key for Code Exchange is an extension to the OAuth protocol that enables secure exchange of refresh and access tokens between an application (web app, single-page app or mobile app) and the authorization server. It is used in places where the exchange of the refresh and access token may be intercepted by third parties such as other applications running in the operating system. This is a common problem on mobile devices where the operating system may hand out URLs to other applications. This can sometimes be also exploited in single-page apps too.

## Provider refresh token [\#](https://supabase.com/docs/guides/resources/glossary\#provider-refresh-token)

A provider refresh token is a refresh token issued by a third-party identity provider which can be used to refresh the provider token returned.

## Provider tokens [\#](https://supabase.com/docs/guides/resources/glossary\#provider-tokens)

A provider token is a long-lived token issued by a third-party identity provider. These are issued by social login services (e.g., Google, Twitter, Apple, Microsoft) and uniquely identify a user on those platforms.

## Refresh token [\#](https://supabase.com/docs/guides/resources/glossary\#refresh-token)

A refresh token is a long-lived (in most cases with an indefinite lifetime) token that is meant to be stored and exchanged for a new refresh and access tokens only once. Once a refresh token is exchanged it becomes invalid, and can't be exchanged again. In practice, though, a refresh token can be exchanged multiple times but in a short time window.

## Refresh token flow [\#](https://supabase.com/docs/guides/resources/glossary\#refresh-token-flow)

The refresh token flow is a mechanism that issues a new refresh and access token on the basis of a valid refresh token. It is used to extend authorization access for an application. An application that is being constantly used will invoke the refresh token flow just before the access token expires.

## Replay attack [\#](https://supabase.com/docs/guides/resources/glossary\#replay-attack)

A replay attack is when sensitive information is stolen or intercepted by attackers who then attempt to use it again (thus replay) in an effort to compromise a system. Commonly replay attacks can be mitigated with the proper use of nonces.

## Row level security policies (RLS) [\#](https://supabase.com/docs/guides/resources/glossary\#row-level-security-policies-rls)

Row level security policies are special objects within the Postgres database that limit the available operations or data returned to clients. RLS policies use information contained in a JWT to identify users and the actions and data they are allowed to perform or view.

## SAML [\#](https://supabase.com/docs/guides/resources/glossary\#saml)

SAML stands for Security Assertion Markup Language and is a protocol that enables single-sign on for enterprises. SAML was invented in the early 2000s and is based on XML technology. It is the de facto standard for enabling single-sign on for enterprises, although the more recent OIDC (OpenID Connect) protocol is gaining popularity.

## Session [\#](https://supabase.com/docs/guides/resources/glossary\#session)

A session or authentication session is the concept that binds a verified user identity to a web browser. A session usually is long-lived, and can be terminated by the user logging out. An access and refresh token pair represent a session in the browser, and they are stored in local storage or as cookies.

## Single-sign on (SSO) [\#](https://supabase.com/docs/guides/resources/glossary\#single-sign-on-sso)

Single-sign on allows enterprises to centrally manage accounts and access to applications. They use identity provider software or services to organize employee information in directories and connect those accounts with applications via OIDC or SAML protocols.

## Time-based one-time password (TOTP) [\#](https://supabase.com/docs/guides/resources/glossary\#time-based-one-time-password-totp)

A time-based one-time password is a one-time password generated at regular time intervals from a secret, usually from an application in a mobile device (e.g., Google Authenticator, 1Password).

### Is this helpful?

NoYes

### On this page

[Access token](https://supabase.com/docs/guides/resources/glossary#access-token) [Authentication](https://supabase.com/docs/guides/resources/glossary#authentication) [Authenticator app](https://supabase.com/docs/guides/resources/glossary#authenticator-app) [Authorization](https://supabase.com/docs/guides/resources/glossary#authorization) [Identity provider](https://supabase.com/docs/guides/resources/glossary#identity-provider) [JSON Web Token (JWT)](https://supabase.com/docs/guides/resources/glossary#json-web-token-jwt) [JWT signing secret](https://supabase.com/docs/guides/resources/glossary#jwt-signing-secret) [Multi-factor authentication (MFA or 2FA)](https://supabase.com/docs/guides/resources/glossary#multi-factor-authentication-mfa-or-2fa) [Nonce](https://supabase.com/docs/guides/resources/glossary#nonce) [OAuth](https://supabase.com/docs/guides/resources/glossary#oauth) [OIDC](https://supabase.com/docs/guides/resources/glossary#oidc) [One-time password (OTP)](https://supabase.com/docs/guides/resources/glossary#one-time-password-otp) [Password hashing function](https://supabase.com/docs/guides/resources/glossary#password-hashing-function) [Password strength](https://supabase.com/docs/guides/resources/glossary#password-strength) [PKCE](https://supabase.com/docs/guides/resources/glossary#pkce) [Provider refresh token](https://supabase.com/docs/guides/resources/glossary#provider-refresh-token) [Provider tokens](https://supabase.com/docs/guides/resources/glossary#provider-tokens) [Refresh token](https://supabase.com/docs/guides/resources/glossary#refresh-token) [Refresh token flow](https://supabase.com/docs/guides/resources/glossary#refresh-token-flow) [Replay attack](https://supabase.com/docs/guides/resources/glossary#replay-attack) [Row level security policies (RLS)](https://supabase.com/docs/guides/resources/glossary#row-level-security-policies-rls) [SAML](https://supabase.com/docs/guides/resources/glossary#saml) [Session](https://supabase.com/docs/guides/resources/glossary#session) [Single-sign on (SSO)](https://supabase.com/docs/guides/resources/glossary#single-sign-on-sso) [Time-based one-time password (TOTP)](https://supabase.com/docs/guides/resources/glossary#time-based-one-time-password-totp)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_resources.md">
Resources

# Resources

* * *

[Examples\\
\\
Official GitHub examples, curated content from the community, and more.](https://supabase.com/docs/guides/resources/examples) [Glossary\\
\\
Definitions for terminology and acronyms used in the Supabase documentation.](https://supabase.com/docs/guides/resources/glossary)

### Migrate to Supabase [\#](https://supabase.com/docs/guides/resources\#migrate-to-supabase)

[![Auth0 Icon](https://supabase.com/docs/img/icons/auth0-icon-light.svg)\\
\\
**Auth0**\\
\\
Move your auth users from Auth0 to a Supabase project.Learn more](https://supabase.com/docs/guides/resources/migrating-to-supabase/auth0) [![Firebase Auth Icon](https://supabase.com/docs/img/icons/firebase-icon.svg)\\
\\
**Firebase Auth**\\
\\
Move your auth users from a Firebase project to a Supabase project.Learn more](https://supabase.com/docs/guides/resources/migrating-to-supabase/firebase-auth) [![Firestore Data Icon](https://supabase.com/docs/img/icons/firebase-icon.svg)\\
\\
**Firestore Data**\\
\\
Migrate the contents of a Firestore collection to a single PostgreSQL table.Learn more](https://supabase.com/docs/guides/resources/migrating-to-supabase/firestore-data) [![Firebase Storage Icon](https://supabase.com/docs/img/icons/firebase-icon.svg)\\
\\
**Firebase Storage**\\
\\
Convert your Firebase Storage files to Supabase Storage.Learn more](https://supabase.com/docs/guides/resources/migrating-to-supabase/firebase-storage) [![Heroku Icon](https://supabase.com/docs/img/icons/heroku-icon.svg)\\
\\
**Heroku**\\
\\
Migrate your Heroku Postgres database to Supabase.Learn more](https://supabase.com/docs/guides/resources/migrating-to-supabase/heroku) [![Render Icon](https://supabase.com/docs/img/icons/render-icon.svg)\\
\\
**Render**\\
\\
Migrate your Render Postgres database to Supabase.Learn more](https://supabase.com/docs/guides/resources/migrating-to-supabase/render) [![Amazon RDS Icon](https://supabase.com/docs/img/icons/aws-rds-icon.svg)\\
\\
**Amazon RDS**\\
\\
Migrate your Amazon RDS database to Supabase.Learn more](https://supabase.com/docs/guides/resources/migrating-to-supabase/amazon-rds) [![Postgres Icon](https://supabase.com/docs/img/icons/postgres-icon.svg)\\
\\
**Postgres**\\
\\
Migrate your Postgres database to Supabase.Learn more](https://supabase.com/docs/guides/resources/migrating-to-supabase/postgres) [![MySQL Icon](https://supabase.com/docs/img/icons/mysql-icon.svg)\\
\\
**MySQL**\\
\\
Migrate your MySQL database to Supabase.Learn more](https://supabase.com/docs/guides/resources/migrating-to-supabase/mysql) [![Microsoft SQL Server Icon](https://supabase.com/docs/img/icons/mssql-icon.svg)\\
\\
**Microsoft SQL Server**\\
\\
Migrate your Microsoft SQL Server database to Supabase.Learn more](https://supabase.com/docs/guides/resources/migrating-to-supabase/mssql)

### Postgres resources [\#](https://supabase.com/docs/guides/resources\#postgres-resources)

[Managing Indexes\\
\\
Improve query performance using various index types in Postgres.](https://supabase.com/docs/guides/database/postgres/indexes) [Cascade Deletes\\
\\
Understand the types of foreign key constraint deletes.](https://supabase.com/docs/guides/database/postgres/cascade-deletes) [Drop all tables in schema\\
\\
Delete all tables in a given schema.](https://supabase.com/docs/guides/database/postgres/dropping-all-tables-in-schema) [Select first row per group\\
\\
Retrieve the first row in each distinct group.](https://supabase.com/docs/guides/database/postgres/first-row-in-group) [Print PostgreSQL version\\
\\
Find out which version of Postgres you are running.](https://supabase.com/docs/guides/database/postgres/which-version-of-postgres)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_security_hipaa_compliance.md">
Security

# HIPAA Compliance and Supabase

* * *

The [Health Insurance Portability and Accountability Act (HIPAA)](https://www.hhs.gov/hipaa/for-professionals/privacy/laws-regulations/index.html) is a comprehensive law that protects individuals' health information while ensuring the continuity of health insurance coverage. It sets standards for privacy and security that must be followed by all entities that handle Protected Health Information (PHI), also known as electronic PHI (ePHI). HIPAA is specific to the United States, however many countries have similar or laws already in place or under legislation.

Under HIPAA, both covered entities and business associates have distinct responsibilities to ensure the protection of PHI. Supabase acts as a business associate for customers (the covered entity) who wish to provide healthcare related services. As a business associate, Supabase has a number of obligations and has undergone auditing of the security and privacy controls that are in place to meet these. Supabase has signed a Business Associate Agreement (BAA) with all of our vendors who would have access to ePHI, such as AWS, and ensure that we follow their terms listed in the agreements. Similarly when a customer signs a BAA with us, they have some responsibilities they agree to when using Supabase to store PHI.

### Customer responsibilities [\#](https://supabase.com/docs/guides/security/hipaa-compliance\#customer-responsibilities)

Covered entities (the customer) are organizations that directly handle PHI, such as health plans, healthcare clearinghouses, and healthcare providers that conduct certain electronic transactions.

1. **Compliance with HIPAA Rules**: Covered entities must comply with the [HIPAA Privacy Rule](https://www.hhs.gov/hipaa/for-professionals/privacy/index.html), [Security Rule](https://www.hhs.gov/hipaa/for-professionals/security/index.html), and [Breach Notification Rule](https://www.hhs.gov/hipaa/for-professionals/breach-notification/index.html) to protect the privacy and security of ePHI.
2. **Business Associate Agreements (BAAs)**: Customers must sign a BAA with Supabase. When the covered entity engages a business associate to help carry out its healthcare activities, it must have a written BAA. This agreement outlines the business associate's responsibilities and requires them to comply with HIPAA Rules.
3. **Internal Compliance Programs**: Customers must [configure their HIPAA projects](https://supabase.com/docs/guides/platform/hipaa-projects) and follow the guidance given by the security advisor. Covered entities are responsible for implementing internal processes and compliance programs to ensure they meet HIPAA requirements.

### Supabase responsibilities [\#](https://supabase.com/docs/guides/security/hipaa-compliance\#supabase-responsibilities)

Supabase as the business associate, and the vendors used by Supabase, are the entities that perform functions or activities on behalf of the customer.

1. **Direct Liability**: Supabase is directly liable for compliance with certain provisions of the HIPAA Rules. This means Supabase has to implement safeguards to protect ePHI and report breaches to the customer.
2. **Compliance with BAAs**: Supabase must comply with the terms of the BAA, which includes implementing appropriate administrative, physical, and technical safeguards to protect ePHI.
3. **Vendor Management**: Supabase must also ensure that our vendors, who may have access to ePHI, comply with HIPAA Rules. This is done through a BAA with each vendor.

## Staying compliant and secure [\#](https://supabase.com/docs/guides/security/hipaa-compliance\#staying-compliant-and-secure)

Compliance is a continuous process and should not be treated as a point-in-time audit of controls. Supabase applies all the necessary privacy and security controls to ensure HIPAA compliance at audit time, but also has additional checks and monitoring in place to ensure those controls are not disabled or altered in between audit periods. Customers commit to doing the same in their HIPAA environments. Supabase provides a growing set of checks that warn customers of changes to their projects that disable or weaken HIPAA required controls. Customers will receive warnings and guidance via the Security Advisor, however the responsibility of applying the recommended controls falls directly to the customer.

Our [shared responsibility model](https://supabase.com/docs/guides/deployment/shared-responsibility-model#managing-healthcare-data) document discusses both HIPAA and general data management best practices, how this responsibility is shared between customers and Supabase, and how to stay compliant.

## Frequently asked questions [\#](https://supabase.com/docs/guides/security/hipaa-compliance\#frequently-asked-questions)

**What is the difference between SOC 2 and HIPAA?**

Both are frameworks for protecting sensitive data, however they serve two different purposes. They share many security and privacy controls and meeting the controls of one normally means being close to complying with the other.

The main differentiator comes down to purpose and scope.

- SOC 2 is not industry-specific and can be applied to any service organization that handles customer data.
- HIPAA is a federal regulation in the United States. HIPAA sets standards for the privacy and security of PHI/ePHI, ensuring that patient data is handled confidentially and securely.

**Are Supabase HIPAA environments also SOC 2 compliant?**

Yes. Supabase applies the same SOC 2 controls to all environments, with additional controls being applied to HIPAA environments.

**How often is Supabase audited?**

Supabase undergoes annual audits. The HIPAA controls are audited during the same audit period as the SOC 2 controls.

## Resources [\#](https://supabase.com/docs/guides/security/hipaa-compliance\#resources)

1. [Health Insurance Portability and Accountability Act (HIPAA)](https://www.hhs.gov/hipaa/for-professionals/privacy/laws-regulations/index.html)
2. [HIPAA Privacy Rule](https://www.hhs.gov/hipaa/for-professionals/privacy/index.html)
3. [Security Rule](https://www.hhs.gov/hipaa/for-professionals/security/index.html)
4. [Breach Notification Rule](https://www.hhs.gov/hipaa/for-professionals/breach-notification/index.html)
5. [Configuring HIPAA projects](https://supabase.com/docs/guides/platform/hipaa-projects) on Supabase
6. [Shared Responsibility Model](https://supabase.com/docs/guides/deployment/shared-responsibility-model)
7. [HIPAA shared responsibility](https://supabase.com/docs/guides/deployment/shared-responsibility-model#managing-healthcare-data)

### Is this helpful?

NoYes

### On this page

[Customer responsibilities](https://supabase.com/docs/guides/security/hipaa-compliance#customer-responsibilities) [Supabase responsibilities](https://supabase.com/docs/guides/security/hipaa-compliance#supabase-responsibilities) [Staying compliant and secure](https://supabase.com/docs/guides/security/hipaa-compliance#staying-compliant-and-secure) [Frequently asked questions](https://supabase.com/docs/guides/security/hipaa-compliance#frequently-asked-questions) [Resources](https://supabase.com/docs/guides/security/hipaa-compliance#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_security_product_security.md">
Security

# Secure configuration of Supabase products

* * *

The Supabase [production checklist](https://supabase.com/docs/guides/deployment/going-into-prod) provides detailed advice on preparing an app for production. While our [SOC 2](https://supabase.com/docs/guides/security/soc-2-compliance) and [HIPAA](https://supabase.com/docs/guides/security/hipaa-compliance) compliance documents outline the roles and responsibilities for building a secure and compliant app.

Various products at Supabase have their own hardening and configuration guides, below is a definitive list of these to help guide your way.

## Auth [\#](https://supabase.com/docs/guides/security/product-security\#auth)

- [Password security](https://supabase.com/docs/guides/auth/password-security)
- [Rate limits](https://supabase.com/docs/guides/auth/rate-limits)
- [Bot detection / Prevention](https://supabase.com/docs/guides/auth/auth-captcha)
- [JWTs](https://supabase.com/docs/guides/auth/jwts)

## Database [\#](https://supabase.com/docs/guides/security/product-security\#database)

- [Row Level Security](https://supabase.com/docs/guides/database/postgres/row-level-security)
- [Column Level Security](https://supabase.com/docs/guides/database/postgres/column-level-security)
- [Hardening the Data API](https://supabase.com/docs/guides/database/hardening-data-api)
- [Additional security controls for the Data API](https://supabase.com/docs/guides/api/securing-your-api)
- [Custom claims and role based access control](https://supabase.com/docs/guides/database/postgres/custom-claims-and-role-based-access-control-rbac)
- [Managing Postgres roles](https://supabase.com/docs/guides/database/postgres/roles)
- [Managing secrets with Vault](https://supabase.com/docs/guides/database/vault)
- [Superuser access and unsupported operations](https://supabase.com/docs/guides/security/docs/guides/database/postgres/roles-superuser)

## Storage [\#](https://supabase.com/docs/guides/security/product-security\#storage)

- [Object ownership](https://supabase.com/docs/guides/storage/security/ownership)
- [Access control](https://supabase.com/docs/guides/storage/security/access-control)
  - The Storage API docs contain hints about required [RLS policy permissions](https://supabase.com/docs/reference/javascript/storage-createbucket)
- [Custom roles with the storage schema](https://supabase.com/docs/guides/storage/schema/custom-roles)

## Realtime [\#](https://supabase.com/docs/guides/security/product-security\#realtime)

- [Authorization](https://supabase.com/docs/guides/security/docs/guides/realtime/authorization)

### Is this helpful?

NoYes

### On this page

[Auth](https://supabase.com/docs/guides/security/product-security#auth) [Database](https://supabase.com/docs/guides/security/product-security#database) [Storage](https://supabase.com/docs/guides/security/product-security#storage) [Realtime](https://supabase.com/docs/guides/security/product-security#realtime)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_security_soc_2_compliance.md">
Security

# SOC 2 Compliance and Supabase

* * *

Supabase is Systems and Organization Controls 2 (SOC 2) Type 2 compliant and is assessed annually to ensure continued adherence to the SOC 2 security framework. SOC 2 assesses Supabases adherence to, and implementation of, controls governing the security, availability, processing integrity, confidentiality, and privacy on the Supabase platform. These controls define requirements for the management and storage of customer data on the platform. These controls applied to Supabase, as a service provider, serve two customer data environments.

The first environment is the customer relationship with Supabase, this refers to the data Supabase has on a customer of the platform. All billing, contact, usage and contract information is managed and stored according to SOC 2 requirements.

The second environment is the backend as a service (the product) that Supabase provides to customers. Supabase implements the controls from the SOC 2 framework to ensure the security of the platform, which hosts the backend as a service (the product), including the Postgres Database, Storage, Authentication, Realtime, Edge Functions and Data API features. Supabase can assert that the environment hosting customer data, stored within the product, adheres to SOC 2 requirements. And the management and storage of data within this environment (the product) is strictly controlled and kept secure.

Supabases SOC 2 compliance does not transfer to environments outside of the Supabase product or Supabases control. This is known as the security or compliance boundary and forms part of the Shared Responsibility Model that Supabase and their customers enter into.

SOC 2 does not cover, nor is it a substitute for, compliance with the Health Insurance Portability and Accountability Act (HIPAA).
Organizations must have a signed Business Associate Agreement (BAA) with Supabase and have the HIPAA add-on enabled when dealing with Protected Health Information (PHI).

Our [HIPAA documentation](https://supabase.com/docs/guides/security/hipaa-compliance) provides more information about the responsibilities and requirements for HIPAA on Supabase.

# Meeting compliance requirements

SOC 2 compliance is a critical aspect of data security for Supabase and our customers. Being fully SOC 2 compliant is a shared responsibility and heres a breakdown of the responsibilities for both parties:

### Supabase responsibilities [\#](https://supabase.com/docs/guides/security/soc-2-compliance\#supabase-responsibilities)

1. **Security Measures**: Supabase implements robust security controls to protect customer data. These includes measures to prevent data breaches and ensure the confidentiality and integrity of the information managed and stored by the platform. Supabase is obliged to be vigilant about security risks and must demonstrate that our security measures meet industry standards through regular audits.
2. **Compliance Audits**: Supabase undergoes SOC 2 audits yearly to verify that our data management practices comply with the Trust Services Criteria (TSC), which include security, availability, processing integrity, confidentiality, and privacy. These audits are conducted by an independent third party.
3. **Incident Response**: Supabase has an incident response plan in place to handle data breaches efficiently. This plan outlines how the organization detects issues, responds to incidents, and manages system vulnerabilities.
4. **Reporting**: Upon a successful audit, Supabase receive a SOC 2 report that details our compliance status. This report is available to customers as a SOC 2 Type 2 report, and allows customers and stakeholders to assure that Supabase has implemented adequate and the requisite safeguards to protect sensitive information.

### Customer responsibilities [\#](https://supabase.com/docs/guides/security/soc-2-compliance\#customer-responsibilities)

1. **Compliance Requirements**: Understand your own compliance requirements. While SOC 2 compliance is not a legal requirement, many enterprise customers require their providers to have a SOC 2 report. This is because it provides assurance that the provider has implemented robust controls to protect customer data.
2. **Due Diligence**: Customers must perform due diligence when selecting Supabase as a provider. This includes reviewing the SOC 2 Type 2 report to ensure that Supabase meets the expected security standards. Customers should also understand the division of responsibilities between themselves and Supabase to avoid duplication of effort.
3. **Monitoring and Review**: Customers should regularly monitor and review Supabases compliance status.
4. **Control Compliance**: If a customer needs to be SOC 2 compliant, they should themselves implement the requisite controls and undergo a SOC 2 audit.

### Shared responsibilities [\#](https://supabase.com/docs/guides/security/soc-2-compliance\#shared-responsibilities)

1. **Data Security**: Both customers and Supabase share the responsibility of ensuring data security. While the Supabase, as the provider, implements the security controls, the customer must ensure that their use of the Supabase platform does not compromise these controls.
2. **Control Compliance**: Supabase asserts through our SOC 2 that all requisite security controls are met. Customers wishing to also be SOC 2 compliant need to go through their own SOC 2 audit, verifying that security controls are met on the customer's side.

In summary, SOC 2 compliance involves a shared responsibility between Supabase and our customers to ensure the security and integrity of data. Supabase, as a provider, must implement and maintain robust security measures, customers must perform due diligence and monitor Supabase's compliance status, while also implement their own compliance controls to protect their sensitive information.

## Frequently asked questions [\#](https://supabase.com/docs/guides/security/soc-2-compliance\#frequently-asked-questions)

**How often is Supabase SOC 2 audited?**

Supabase has obtained SOC 2 Type 2 certification, which means Supabase's controls are fully audited annually. The auditor's reports on these examinations are issued as soon as they are ready after the audit. Supabase makes the SOC 2 Type 2 report available to [Enterprise and Team Plan](https://supabase.com/pricing) customers. The audit report covers a rolling 12-month window, known as the audit period, and runs from 1 March to 28 February of the next calendar year.

**How to obtain Supabase's SOC 2 Type 2 report?**

To access the SOC 2 Type 2 report, you must be a Enterprise or Team Plan Supabase customer. The report is downloadable from the [Legal Documents](https://supabase.com/dashboard/org/_/documents) section in the organization dashboard.

**Why does it matter that Supabase is SOC 2 Compliant?**

SOC 2 is used to assert that controls are in place to ensure the proper management and storage of data. SOC 2 provides a framework for measuring how secure a service provider is and re-evaluates the provider on an annual basis. This provides the confidence and assurance that data stored within the Supabase platform is correctly secured and managed.

**If Supabases SOC 2 does not transfer to the customer, why does it matter that Supabase has SOC 2?**

Even though Supabases SOC 2 compliance does not transfer outside of the product, it does provide the assurance that all data within the product is correctly managed and stored. Supabase can assert that only authorized persons have access to the data, and security controls are in place to prevent, detect and respond to data intrusions. This forms part of a customers own adherence to the SOC 2 framework and relieves part of the burden of data management and storage on the customer. In many organizations' security and risk departments require all vendors or sub-processors to be SOC 2 compliant.

**What is the security or compliance boundary?**

This defines the boundary or border between Supabase and customer responsibility for data security within the Shared Responsibility Model. Customer data stored within the Supabase product, on the Supabase side of the security boundary, is managed and secured by Supabase. Supabase ensures the safe handling and storage of data within this environment. This includes controls for preventing unauthorized access, monitoring data access, alerting, data backups and redundancy. Data on the customer side of the boundary, the data that enters and leaves the Supabase product, is the responsibility of the customer. Management and possible storage of such data outside of Supabase should be performed by the customer, and any security and compliance controls are the responsibility of the customer.

**Does SOC 2 cover health related data (HIPAA)?**

SOC 2 is non-industry specific and provides a framework for the security and privacy of data. This is however not sufficient in most cases when dealing with Protected Healthcare Information (PHI), which requires additional privacy and legal controls.
When dealing with PHI in the United States or for United States customers, HIPAA is mandatory.

## Resources [\#](https://supabase.com/docs/guides/security/soc-2-compliance\#resources)

1. [System and Organization Controls: SOC Suite of Services](https://www.aicpa-cima.com/resources/landing/system-and-organization-controls-soc-suite-of-services)
2. [Shared Responsibility Model](https://supabase.com/docs/guides/deployment/shared-responsibility-model)

### Is this helpful?

NoYes

### On this page

[Supabase responsibilities](https://supabase.com/docs/guides/security/soc-2-compliance#supabase-responsibilities) [Customer responsibilities](https://supabase.com/docs/guides/security/soc-2-compliance#customer-responsibilities) [Shared responsibilities](https://supabase.com/docs/guides/security/soc-2-compliance#shared-responsibilities) [Frequently asked questions](https://supabase.com/docs/guides/security/soc-2-compliance#frequently-asked-questions) [Resources](https://supabase.com/docs/guides/security/soc-2-compliance#resources)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_security.md">
Security

# Supabase Security

* * *

Supabase is a hosted platform which makes it very simple to get started without needing to manage any infrastructure. The hosted platform comes with many security and compliance controls managed by Supabase.

# Compliance

Supabase is SOC 2 Type 2 compliant and regularly audited. All projects at Supabase are governed by the same set of compliance controls.
The [SOC 2 Compliance Guide](https://supabase.com/docs/guides/security/soc-2-compliance) explains Supabase's SOC 2 responsibilities and controls in more detail.

The [HIPAA Compliance Guide](https://supabase.com/docs/guides/security/hipaa-compliance) explains Supabase's HIPAA responsibilities. Additional [security and compliance controls](https://supabase.com/docs/guides/deployment/shared-responsibility-model#managing-healthcare-data) for projects that deal with electronic Protected Health Information (ePHI) and require HIPAA compliance are available through the HIPAA add-on.

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_self_hosting_docker.md">
Self-Hosting

# Self-Hosting with Docker

## Learn how to configure and deploy Supabase with Docker.

* * *

Docker is the easiest way to get started with self-hosted Supabase. It should only take you a few minutes to get up and running. This guide assumes you are running the command from the machine you intend to host from.

## Contents [\#](https://supabase.com/docs/guides/self-hosting/docker\#contents)

1. [Before you begin](https://supabase.com/docs/guides/self-hosting/docker#before-you-begin)
2. [Installing and running Supabase](https://supabase.com/docs/guides/self-hosting/docker#installing-and-running-supabase)
3. [Accessing your services](https://supabase.com/docs/guides/self-hosting/docker#accessing-supabase-studio)
4. [Updating your services](https://supabase.com/docs/guides/self-hosting/docker#updating-your-services)
5. [Securing your services](https://supabase.com/docs/guides/self-hosting/docker#securing-your-services)

## Before you begin [\#](https://supabase.com/docs/guides/self-hosting/docker\#before-you-begin)

You need the following installed in your system: [Git](https://git-scm.com/downloads) and Docker ( [Windows](https://docs.docker.com/desktop/install/windows-install/), [macOS](https://docs.docker.com/desktop/install/mac-install/), or [Linux](https://docs.docker.com/desktop/install/linux-install/)).

## Installing and running Supabase [\#](https://supabase.com/docs/guides/self-hosting/docker\#installing-and-running-supabase)

Follow these steps to start Supabase on your machine:

GeneralAdvanced

`
# Get the code
git clone --depth 1 https://github.com/supabase/supabase
# Go to the docker folder
cd supabase/docker
# Copy the fake env vars
cp .env.example .env
# Pull the latest images
docker compose pull
# Start the services (in detached mode)
docker compose up -d
`

If you are using rootless docker, edit `.env` and set `DOCKER_SOCKET_LOCATION` to your docker socket location. For example: `/run/user/1000/docker.sock`. Otherwise, you will see an error like `container supabase-vector exited (0)`.

After all the services have started you can see them running in the background:

`
docker compose ps
`

All of the services should have a status `running (healthy)`. If you see a status like `created` but not `running`, try starting that service manually with `docker compose start <service-name>`.

Your app is now running with default credentials.
[Secure your services](https://supabase.com/docs/guides/self-hosting/docker#securing-your-services) as soon as possible using the instructions below.

### Accessing Supabase Studio [\#](https://supabase.com/docs/guides/self-hosting/docker\#accessing-supabase-studio)

You can access Supabase Studio through the API gateway on port `8000`. For example: `http://<your-ip>:8000`, or [localhost:8000](http://localhost:8000/) if you are running Docker locally.

You will be prompted for a username and password. By default, the credentials are:

- Username: `supabase`
- Password: `this_password_is_insecure_and_should_be_updated`

You should change these credentials as soon as possible using the [instructions](https://supabase.com/docs/guides/self-hosting/docker#dashboard-authentication) below.

### Accessing the APIs [\#](https://supabase.com/docs/guides/self-hosting/docker\#accessing-the-apis)

Each of the APIs are available through the same API gateway:

- REST: `http://<your-ip>:8000/rest/v1/`
- Auth: `http://<your-domain>:8000/auth/v1/`
- Storage: `http://<your-domain>:8000/storage/v1/`
- Realtime: `http://<your-domain>:8000/realtime/v1/`

### Accessing your Edge Functions [\#](https://supabase.com/docs/guides/self-hosting/docker\#accessing-your-edge-functions)

Edge Functions are stored in `volumes/functions`. The default setup has a `hello` Function that you can invoke on `http://<your-domain>:8000/functions/v1/hello`.

You can add new Functions as `volumes/functions/<FUNCTION_NAME>/index.ts`. Restart the `functions` service to pick up the changes: `docker compose restart functions --no-deps`

### Accessing Postgres [\#](https://supabase.com/docs/guides/self-hosting/docker\#accessing-postgres)

By default, the Supabase stack runs the [Supavisor](https://supabase.github.io/supavisor/development/docs/) connection pooler. Supavisor provides efficient management of database connections.

You can connect to the Postgres database using the following methods:

1. For session-based connections (equivalent to direct Postgres connections):

`
psql 'postgres://postgres.your-tenant-id:your-super-secret-and-long-postgres-password@localhost:5432/postgres'
`

2. For pooled transactional connections:

`
psql 'postgres://postgres.your-tenant-id:your-super-secret-and-long-postgres-password@localhost:6543/postgres'
`

The default tenant ID is `your-tenant-id`, and the default password is `your-super-secret-and-long-postgres-password`. You should change these as soon as possible using the [instructions below](https://supabase.com/docs/guides/self-hosting/docker#update-secrets).

By default, the database is not accessible from outside the local machine but the pooler is. You can [change this](https://supabase.com/docs/guides/self-hosting/docker#exposing-your-postgres-database) by updating the `docker-compose.yml` file.

## Updating your services [\#](https://supabase.com/docs/guides/self-hosting/docker\#updating-your-services)

For security reasons, we "pin" the versions of each service in the docker-compose file (these versions are updated ~monthly). If you want to update any services immediately, you can do so by updating the version number in the docker compose file and then running `docker compose pull`. You can find all the latest docker images in the [Supabase Docker Hub](https://hub.docker.com/u/supabase).

You should update your services frequently to get the latest features and bug fixes and security patches. Note that you will need to restart the services to pick up the changes, which will result in some downtime for your services.

**Example**
You'll want to update the Studio(Dashboard) frequently to get the latest features and bug fixes. To update the Dashboard:

1. Visit the [supabase/studio](https://hub.docker.com/r/supabase/studio/tags) image in the [Supabase Docker Hub](https://hub.docker.com/u/supabase)
2. Find the latest version (tag) number. It will look something like `20241029-46e1e40`
3. Update the `image` field in the `docker-compose.yml` file to the new version. It should look like this: `image: supabase/studio:20241028-a265374`
4. Run `docker compose pull` and then `docker compose up -d` to restart the service with the new version.

## Securing your services [\#](https://supabase.com/docs/guides/self-hosting/docker\#securing-your-services)

While we provided you with some example secrets for getting started, you should NEVER deploy your Supabase setup using the defaults we have provided. Follow all of the steps in this section to ensure you have a secure setup, and then [restart all services](https://supabase.com/docs/guides/self-hosting/docker#restarting-all-services) to pick up the changes.

### Generate API keys [\#](https://supabase.com/docs/guides/self-hosting/docker\#generate-api-keys)

We need to generate secure keys for accessing your services. We'll use the `JWT Secret` to generate `anon` and `service` API keys using the form below.

1. **Obtain a Secret**: Use the 40-character secret provided, or create your own. If creating, ensure it's a strong, random string of 40 characters.
2. **Store Securely**: Save the secret in a secure location on your local machine. Don't share this secret publicly or commit it to version control.
3. **Generate a JWT**: Use the form below to generate a new `JWT` using your secret.

JWT Secret:

Key:

ANON\_KEYSERVICE\_KEY

The JWT will be generated from this info:

Generate JWT

### Update API keys [\#](https://supabase.com/docs/guides/self-hosting/docker\#update-api-keys)

Run this form twice to generate new `anon` and `service` API keys. Replace the values in the `./docker/.env` file:

- `ANON_KEY` \- replace with an `anon` key
- `SERVICE_ROLE_KEY` \- replace with a `service` key

You will need to [restart](https://supabase.com/docs/guides/self-hosting/docker#restarting-all-services) the services for the changes to take effect.

### Update secrets [\#](https://supabase.com/docs/guides/self-hosting/docker\#update-secrets)

Update the `./docker/.env` file with your own secrets. In particular, these are required:

- `POSTGRES_PASSWORD`: the password for the `postgres` role.
- `JWT_SECRET`: used by PostgREST and GoTrue, among others.
- `SITE_URL`: the base URL of your site.
- `SMTP_*`: mail server credentials. You can use any SMTP server.
- `POOLER_TENANT_ID`: the tenant-id that will be used by Supavisor pooler for your connection string

You will need to [restart](https://supabase.com/docs/guides/self-hosting/docker#restarting-all-services) the services for the changes to take effect.

### Dashboard authentication [\#](https://supabase.com/docs/guides/self-hosting/docker\#dashboard-authentication)

The Dashboard is protected with basic authentication. The default user and password MUST be updated before using Supabase in production.
Update the following values in the `./docker/.env` file:

- `DASHBOARD_USERNAME`: The default username for the Dashboard
- `DASHBOARD_PASSWORD`: The default password for the Dashboard

You can also add more credentials for multiple users in `./docker/volumes/api/kong.yml`. For example:

docker/volumes/api/kong.yml

`
basicauth_credentials:
  - consumer: DASHBOARD
    username: user_one
    password: password_one
  - consumer: DASHBOARD
    username: user_two
    password: password_two
`

To enable all dashboard features outside of `localhost`, update the following value in the `./docker/.env` file:

- `SUPABASE_PUBLIC_URL`: The URL or IP used to access the dashboard

You will need to [restart](https://supabase.com/docs/guides/self-hosting/docker#restarting-all-services) the services for the changes to take effect.

## Restarting all services [\#](https://supabase.com/docs/guides/self-hosting/docker\#restarting-all-services)

You can restart services to pick up any configuration changes by running:

`
# Stop and remove the containers
docker compose down
# Recreate and start the containers
docker compose up -d
`

Be aware that this will result in downtime. Simply restarting the services does not apply configuration changes.

## Stopping all services [\#](https://supabase.com/docs/guides/self-hosting/docker\#stopping-all-services)

You can stop Supabase by running `docker compose stop` in same directory as your `docker-compose.yml` file.

## Uninstalling [\#](https://supabase.com/docs/guides/self-hosting/docker\#uninstalling)

You can stop Supabase by running the following in same directory as your `docker-compose.yml` file:

`
# Stop docker and remove volumes:
docker compose down -v
# Remove Postgres data:
rm -rf volumes/db/data/
`

This will destroy all data in the database and storage volumes, so be careful!

## Managing your secrets [\#](https://supabase.com/docs/guides/self-hosting/docker\#managing-your-secrets)

Many components inside Supabase use secure secrets and passwords. These are listed in the self-hosting [env file](https://github.com/supabase/supabase/blob/master/docker/.env.example), but we strongly recommend using a secrets manager when deploying to production. Plain text files like dotenv lead to accidental costly leaks.

Some suggested systems include:

- [Doppler](https://www.doppler.com/)
- [Infisical](https://infisical.com/)
- [Key Vault](https://docs.microsoft.com/en-us/azure/key-vault/general/overview) by Azure (Microsoft)
- [Secrets Manager](https://aws.amazon.com/secrets-manager/) by AWS
- [Secrets Manager](https://cloud.google.com/secret-manager) by GCP
- [Vault](https://www.hashicorp.com/products/vault) by HashiCorp

## Advanced [\#](https://supabase.com/docs/guides/self-hosting/docker\#advanced)

Everything beyond this point in the guide helps you understand how the system works and how you can modify it to suit your needs.

### Architecture [\#](https://supabase.com/docs/guides/self-hosting/docker\#architecture)

Supabase is a combination of open source tools, each specifically chosen for Enterprise-readiness.

If the tools and communities already exist, with an MIT, Apache 2, or equivalent open license, we will use and support that tool.
If the tool doesn't exist, we build and open source it ourselves.

![Diagram showing the architecture of Supabase. The Kong API gateway sits in front of 7 services: GoTrue, PostgREST, Realtime, Storage, pg_meta, Functions, and pg_graphql. All the services talk to a single Postgres instance.](https://supabase.com/docs/_next/image?url=%2Fdocs%2Fimg%2Fsupabase-architecture--light.svg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

- [Kong](https://github.com/Kong/kong) is a cloud-native API gateway.
- [GoTrue](https://github.com/supabase/gotrue) is an JWT based API for managing users and issuing JWT tokens.
- [PostgREST](http://postgrest.org/) is a web server that turns your Postgres database directly into a RESTful API
- [Realtime](https://github.com/supabase/realtime) is an Elixir server that allows you to listen to Postgres inserts, updates, and deletes using WebSockets. Realtime polls Postgres' built-in replication functionality for database changes, converts changes to JSON, then broadcasts the JSON over WebSockets to authorized clients.
- [Storage](https://github.com/supabase/storage-api) provides a RESTful interface for managing Files stored in S3, using Postgres to manage permissions.
- [`postgres-meta`](https://github.com/supabase/postgres-meta) is a RESTful API for managing your Postgres, allowing you to fetch tables, add roles, and run queries, etc.
- [Postgres](https://www.postgresql.org/) is an object-relational database system with over 30 years of active development that has earned it a strong reputation for reliability, feature robustness, and performance.
- [Supavisor](https://github.com/supabase/supavisor) is a scalable connection pooler for Postgres, allowing for efficient management of database connections.

For the system to work cohesively, some services require additional configuration within the Postgres database. For example, the APIs and Auth system require several [default roles](https://supabase.com/docs/guides/database/postgres/roles) and the `pgjwt` Postgres extension.

You can find all the default extensions inside the [schema migration scripts repo](https://github.com/supabase/postgres/tree/develop/migrations). These scripts are mounted at `/docker-entrypoint-initdb.d` to run automatically when starting the database container.

### Configuring services [\#](https://supabase.com/docs/guides/self-hosting/docker\#configuring-services)

Each system has a number of configuration options which can be found in the relevant product documentation.

- [Postgres](https://hub.docker.com/_/postgres/)
- [PostgREST](https://postgrest.org/en/stable/configuration.html)
- [Realtime](https://github.com/supabase/realtime#server)
- [Auth](https://github.com/supabase/auth)
- [Storage](https://github.com/supabase/storage-api)
- [Kong](https://docs.konghq.com/gateway/latest/install/docker/)
- [Supavisor](https://supabase.github.io/supavisor/development/docs/)

These configuration items are generally added to the `env` section of each service, inside the `docker-compose.yml` section. If these configuration items are sensitive, they should be stored in a [secret manager](https://supabase.com/docs/guides/self-hosting#managing-your-secrets) or using an `.env` file and then referenced using the `${}` syntax.

docker-compose.yml

.env

`
services:
rest:
    image: postgrest/postgrest
    environment:
      PGRST_JWT_SECRET: ${JWT_SECRET}
`

### Common configuration [\#](https://supabase.com/docs/guides/self-hosting/docker\#common-configuration)

Each system can be [configured](https://supabase.com/docs/guides/self-hosting#configuration) independently. Some of the most common configuration options are listed below.

#### Configuring an email server [\#](https://supabase.com/docs/guides/self-hosting/docker\#configuring-an-email-server)

You will need to use a production-ready SMTP server for sending emails. You can configure the SMTP server by updating the following environment variables:

.env

`
SMTP_ADMIN_EMAIL=
SMTP_HOST=
SMTP_PORT=
SMTP_USER=
SMTP_PASS=
SMTP_SENDER_NAME=
`

We recommend using [AWS SES](https://aws.amazon.com/ses/). It's extremely cheap and reliable. Restart all services to pick up the new configuration.

#### Configuring S3 Storage [\#](https://supabase.com/docs/guides/self-hosting/docker\#configuring-s3-storage)

By default all files are stored locally on the server. You can configure the Storage service to use S3 by updating the following environment variables:

docker-compose.yml

`
storage:
environment: STORAGE_BACKEND=s3
    GLOBAL_S3_BUCKET=name-of-your-s3-bucket
    REGION=region-of-your-s3-bucket
`

You can find all the available options in the [storage repository](https://github.com/supabase/storage-api/blob/master/.env.sample). Restart the `storage` service to pick up the changes: `docker compose restart storage --no-deps`

#### Configuring Supabase AI Assistant [\#](https://supabase.com/docs/guides/self-hosting/docker\#configuring-supabase-ai-assistant)

Configuring the Supabase AI Assistant is optional. By adding your own `OPENAI_API_KEY`, you can enable AI services, which help with writing SQL queries, statements, and policies.

docker-compose.yml

.env

`
services:
studio:
    image: supabase/studio
    environment:
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
`

#### Setting database's `log_min_messages` [\#](https://supabase.com/docs/guides/self-hosting/docker\#setting-databases-logminmessages)

By default, `docker compose` sets the database's `log_min_messages` configuration to `fatal` to prevent redundant logs generated by Realtime. You can configure `log_min_messages` using any of the Postgres [Severity Levels](https://www.postgresql.org/docs/current/runtime-config-logging.html#RUNTIME-CONFIG-SEVERITY-LEVELS).

#### Accessing Postgres through Supavisor [\#](https://supabase.com/docs/guides/self-hosting/docker\#accessing-postgres-through-supavisor)

By default, the Postgres database is accessible through the Supavisor connection pooler. This allows for more efficient management of database connections. You can connect to the pooled database using the `POOLER_PROXY_PORT_TRANSACTION` port and `POSTGRES_PORT` for session based connections.

For more information on configuring and using Supavisor, see the [Supavisor documentation](https://supabase.github.io/supavisor/).

#### Exposing your Postgres database [\#](https://supabase.com/docs/guides/self-hosting/docker\#exposing-your-postgres-database)

If you need direct access to the Postgres database without going through Supavisor, you can expose it by updating the `docker-compose.yml` file:

docker-compose.yml

`
# Comment or remove the supavisor section of the docker-compose file
#  supavisor:
#    ports:
# ...
db:
ports:
    - ${POSTGRES_PORT}:${POSTGRES_PORT}
`

This is less-secure, so make sure you are running a firewall in front of your server.

#### File storage backend on macOS [\#](https://supabase.com/docs/guides/self-hosting/docker\#file-storage-backend-on-macos)

By default, Storage backend is set to `file`, which is to use local files as the storage backend. For macOS compatibility, you need to choose `VirtioFS` as the Docker container file sharing implementation (in Docker Desktop -> Preferences -> General).

#### Setting up logging with the Analytics server [\#](https://supabase.com/docs/guides/self-hosting/docker\#setting-up-logging-with-the-analytics-server)

Additional configuration is required for self-hosting the Analytics server. For the full setup instructions, see [Self Hosting Analytics](https://supabase.com/docs/reference/self-hosting-analytics/introduction#getting-started).

### Upgrading Analytics [\#](https://supabase.com/docs/guides/self-hosting/docker\#upgrading-analytics)

Due to the changes in the Analytics server, you will need to run the following commands to upgrade your Analytics server:

All data in analytics will be deleted when you run the commands below.

`
### Destroy analytics to transition to postgres self hosted solution without other data loss
# Enter the container and use your .env POSTGRES_PASSWORD value to login
docker exec -it $(docker ps | grep supabase-db | awk '{print $1}') psql -U supabase_admin --password
# Drop all the data in the _analytics schema
DROP PUBLICATION logflare_pub; DROP SCHEMA _analytics CASCADE; CREATE SCHEMA _analytics;\q
# Drop the analytics container
docker rm supabase-analytics
`

* * *

## Demo [\#](https://supabase.com/docs/guides/self-hosting/docker\#demo)

A minimal setup working on Ubuntu, hosted on DigitalOcean.

Self-hosting Supabase on Ubuntu with Digital Ocean - YouTube

Supabase

45.5K subscribers

[Self-hosting Supabase on Ubuntu with Digital Ocean](https://www.youtube.com/watch?v=FqiQKRKsfZE)

Supabase

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=FqiQKRKsfZE "Watch on YouTube")

### Demo using DigitalOcean [\#](https://supabase.com/docs/guides/self-hosting/docker\#demo-using-digitalocean)

1. A DigitalOcean Droplet with 1 GB memory and 25 GB solid-state drive (SSD) is sufficient to start
2. To access the Dashboard, use the ipv4 IP address of your Droplet.
3. If you're unable to access Dashboard, run `docker compose ps` to see if the Studio service is running and healthy.

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2FFqiQKRKsfZE%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Contents](https://supabase.com/docs/guides/self-hosting/docker#contents) [Before you begin](https://supabase.com/docs/guides/self-hosting/docker#before-you-begin) [Installing and running Supabase](https://supabase.com/docs/guides/self-hosting/docker#installing-and-running-supabase) [Accessing Supabase Studio](https://supabase.com/docs/guides/self-hosting/docker#accessing-supabase-studio) [Accessing the APIs](https://supabase.com/docs/guides/self-hosting/docker#accessing-the-apis) [Accessing your Edge Functions](https://supabase.com/docs/guides/self-hosting/docker#accessing-your-edge-functions) [Accessing Postgres](https://supabase.com/docs/guides/self-hosting/docker#accessing-postgres) [Updating your services](https://supabase.com/docs/guides/self-hosting/docker#updating-your-services) [Securing your services](https://supabase.com/docs/guides/self-hosting/docker#securing-your-services) [Generate API keys](https://supabase.com/docs/guides/self-hosting/docker#generate-api-keys) [Update API keys](https://supabase.com/docs/guides/self-hosting/docker#update-api-keys) [Update secrets](https://supabase.com/docs/guides/self-hosting/docker#update-secrets) [Dashboard authentication](https://supabase.com/docs/guides/self-hosting/docker#dashboard-authentication) [Restarting all services](https://supabase.com/docs/guides/self-hosting/docker#restarting-all-services) [Stopping all services](https://supabase.com/docs/guides/self-hosting/docker#stopping-all-services) [Uninstalling](https://supabase.com/docs/guides/self-hosting/docker#uninstalling) [Managing your secrets](https://supabase.com/docs/guides/self-hosting/docker#managing-your-secrets) [Advanced](https://supabase.com/docs/guides/self-hosting/docker#advanced) [Architecture](https://supabase.com/docs/guides/self-hosting/docker#architecture) [Configuring services](https://supabase.com/docs/guides/self-hosting/docker#configuring-services) [Common configuration](https://supabase.com/docs/guides/self-hosting/docker#common-configuration) [Upgrading Analytics](https://supabase.com/docs/guides/self-hosting/docker#upgrading-analytics) [Demo](https://supabase.com/docs/guides/self-hosting/docker#demo) [Demo using DigitalOcean](https://supabase.com/docs/guides/self-hosting/docker#demo-using-digitalocean)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_self_hosting.md">
Self-Hosting

# Self-Hosting

## Host Supabase on your own infrastructure.

* * *

There are several ways to host Supabase on your own computer, server, or cloud.

## Officially supported [\#](https://supabase.com/docs/guides/self-hosting\#officially-supported)

Most common
[Docker\\
\\
Deploy Supabase within your own infrastructure using Docker Compose.](https://supabase.com/docs/guides/self-hosting/docker)

[BYO Cloud\\
\\
Contact our Enterprise sales team if you need Supabase managed in your own cloud.](https://supabase.com/pricing)

Supabase is also a hosted platform. If you want to get started for free, visit [supabase.com/dashboard](https://supabase.com/dashboard).

## Community supported [\#](https://supabase.com/docs/guides/self-hosting\#community-supported)

There are several community-driven projects to help you deploy Supabase. We encourage you to try them out and contribute back to the community.

[Kubernetes\\
\\
Helm charts to deploy a Supabase on Kubernetes.](https://github.com/supabase-community/supabase-kubernetes)

[Terraform\\
\\
A community-driven Terraform Provider for Supabase.](https://github.com/supabase-community/supabase-terraform)

[Traefik\\
\\
A self-hosted Supabase setup with Traefik as a reverse proxy.](https://github.com/supabase-community/supabase-traefik)

[AWS\\
\\
A CloudFormation template for Supabase.](https://github.com/supabase-community/supabase-on-aws)

## Third-party guides [\#](https://supabase.com/docs/guides/self-hosting\#third-party-guides)

The following third-party providers have shown consistent support for the self-hosted version of Supabase:.

[Digital Ocean\\
\\
Deploys using Terraform.](https://docs.digitalocean.com/developer-center/hosting-supabase-on-digitalocean/)

[StackGres\\
\\
Deploys using Kubernetes.](https://stackgres.io/blog/running-supabase-on-top-of-stackgres/)

[Pigsty\\
\\
Deploys using Ansible.](https://pigsty.io/blog/db/supabase/)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_storage_buckets_creating_buckets.md">
Storage

# Creating Buckets

* * *

You can create a bucket using the Supabase Dashboard. Since storage is interoperable with your Postgres database, you can also use SQL or our client libraries.
Here we create a bucket called "avatars":

JavaScriptDashboardSQLDartSwiftPython

`
// Use the JS library to create a bucket.
const { data, error } = await supabase.storage.createBucket('avatars', {
public: true, // default: false
})
`

[Reference.](https://supabase.com/docs/reference/javascript/storage-createbucket)

## Restricting uploads [\#](https://supabase.com/docs/guides/storage/buckets/creating-buckets\#restricting-uploads)

When creating a bucket you can add additional configurations to restrict the type or size of files you want this bucket to contain.
For example, imagine you want to allow your users to upload only images to the `avatars` bucket and the size must not be greater than 1MB.

You can achieve the following by providing: `allowedMimeTypes` and `maxFileSize`

`
// Use the JS library to create a bucket.
const { data, error } = await supabase.storage.createBucket('avatars', {
public: true,
allowedMimeTypes: ['image/*'],
fileSizeLimit: '1MB',
})
`

If an upload request doesn't meet the above restrictions it will be rejected.

For more information check [File Limits](https://supabase.com/docs/guides/storage/uploads/file-limits) Section.

### Is this helpful?

NoYes

### On this page

[Restricting uploads](https://supabase.com/docs/guides/storage/buckets/creating-buckets#restricting-uploads)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_storage_buckets_fundamentals.md">
Storage

# Storage Buckets

* * *

Buckets allow you to keep your files organized and determines the [Access Model](https://supabase.com/docs/guides/storage/buckets/fundamentals#access-model) for your assets. [Upload restrictions](https://supabase.com/docs/guides/storage/buckets/creating-buckets#restricting-uploads) like max file size and allowed content types are also defined at the bucket level.

## Access model [\#](https://supabase.com/docs/guides/storage/buckets/fundamentals\#access-model)

There are 2 access models for buckets, **public** and **private** buckets.

### Private buckets [\#](https://supabase.com/docs/guides/storage/buckets/fundamentals\#private-buckets)

When a bucket is set to **Private** all operations are subject to access control via [RLS policies](https://supabase.com/docs/guides/storage/security/access-control). This also applies when downloading assets. Buckets are private by default.

The only ways to download assets within a private bucket is to:

- Use the [download method](https://supabase.com/docs/reference/javascript/storage-from-download) by providing a authorization header containing your user's JWT. The RLS policy you create on the `storage.objects` table will use this user to determine if they have access.
- Create a signed URL with the [`createSignedUrl` method](https://supabase.com/docs/reference/javascript/storage-from-createsignedurl) that can be accessed for a limited time.

#### Example use cases: [\#](https://supabase.com/docs/guides/storage/buckets/fundamentals\#example-use-cases)

- Uploading users' sensitive documents
- Securing private assets by using RLS to set up fine-grain access controls

### Public buckets [\#](https://supabase.com/docs/guides/storage/buckets/fundamentals\#public-buckets)

When a bucket is designated as 'Public,' it effectively bypasses access controls for both retrieving and serving files within the bucket. This means that anyone who possesses the asset URL can readily access the file.

Access control is still enforced for other types of operations including uploading, deleting, moving, and copying.

#### Example use cases: [\#](https://supabase.com/docs/guides/storage/buckets/fundamentals\#example-use-cases)

- User profile pictures
- User public media
- Blog post content

Public buckets are more performant than private buckets since they are [cached differently](https://supabase.com/docs/guides/storage/cdn/fundamentals#public-vs-private-buckets).

### Is this helpful?

NoYes

### On this page

[Access model](https://supabase.com/docs/guides/storage/buckets/fundamentals#access-model) [Private buckets](https://supabase.com/docs/guides/storage/buckets/fundamentals#private-buckets) [Public buckets](https://supabase.com/docs/guides/storage/buckets/fundamentals#public-buckets)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_storage_cdn_fundamentals.md">
Storage

# Storage CDN

* * *

All assets uploaded to Supabase Storage are cached on a Content Delivery Network (CDN) to improve the latency for users all around the world. CDNs are a geographically distributed set of servers or **nodes** which cache content from an **origin server**. For Supabase Storage, the origin is the storage server running in the [same region as your project](https://supabase.com/dashboard/project/_/settings/general). Aside from performance, CDNs also help with security and availability by mitigating Distributed Denial of Service (DDoS) and other application attacks.

### Example [\#](https://supabase.com/docs/guides/storage/cdn/fundamentals\#example)

Let's walk through an example of how a CDN helps with performance.

A new bucket is created for a Supabase project launched in Singapore. All requests to the Supabase Storage API are routed to the CDN first.

A user from the United States requests an object and is routed to the U.S. CDN. At this point, that CDN node does not have the object in its cache and pings the origin server in Singapore.
![CDN cache miss](https://supabase.com/docs/img/cdn-cache-miss.png)

Another user, also in the United States, requests the same object and is served directly from the CDN cache in the United States instead of routing the request back to Singapore.
![CDN cache hit](https://supabase.com/docs/img/cdn-cache-hit.png)

Note that CDNs might still evict your object from their cache if it has not been requested for a while from a specific region. For example, if no user from United States requests your object, it will be removed from the CDN cache even if we set a very long cache control duration.

The cache status of a particular request is sent in the `cf-cache-status` header. A cache status of `MISS` indicates that the CDN node did not have the object in its cache and had to ping the origin to get it. A cache status of `HIT` indicates that the object was sent directly from the CDN.

### Public vs private buckets [\#](https://supabase.com/docs/guides/storage/cdn/fundamentals\#public-vs-private-buckets)

Objects in public buckets do not require any authorization to access objects. This leads to a better cache hit rate compared to private buckets.

For private buckets, permissions for accessing each object is checked on a per user level. For example, if two different users access the same object in a private bucket from the same region, it results in a cache miss for both the users since they might have different security policies attached to them.
On the other hand, if two different users access the same object in a public bucket from the same region, it results in a cache hit for the second user.

### Is this helpful?

NoYes

### On this page

[Example](https://supabase.com/docs/guides/storage/cdn/fundamentals#example) [Public vs private buckets](https://supabase.com/docs/guides/storage/cdn/fundamentals#public-vs-private-buckets)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_storage_cdn_metrics.md">
Storage

# Cache Metrics

* * *

Cache hits can be determined via the `metadata.response.headers.cf_cache_status` key in our [Logs Explorer](https://supabase.com/docs/guides/platform/logs#logs-explorer). Any value that corresponds to either `HIT`, `STALE`, `REVALIDATED`, or `UPDATING` is categorized as a cache hit.
The following example query will show the top cache misses from the `edge_logs`:

`
select
r.path as path,
r.search as search,
count(id) as count
from
edge_logs as f
cross join unnest(f.metadata) as m
cross join unnest(m.request) as r
cross join unnest(m.response) as res
cross join unnest(res.headers) as h
where
starts_with(r.path, '/storage/v1/object')
and r.method = 'GET'
and h.cf_cache_status in ('MISS', 'NONE/UNKNOWN', 'EXPIRED', 'BYPASS', 'DYNAMIC')
group by path, search
order by count desc
limit 50;
`

Try out [this query](https://supabase.com/dashboard/project/_/logs/explorer?q=%0Aselect%0A++r.path+as+path%2C%0A++r.search+as+search%2C%0A++count%28id%29+as+count%0Afrom%0A++edge_logs+as+f%0A++cross+join+unnest%28f.metadata%29+as+m%0A++cross+join+unnest%28m.request%29+as+r%0A++cross+join+unnest%28m.response%29+as+res%0A++cross+join+unnest%28res.headers%29+as+h%0Awhere%0A++starts_with%28r.path%2C+%27%2Fstorage%2Fv1%2Fobject%27%29%0A++and+r.method+%3D+%27GET%27%0A++and+h.cf_cache_status+in+%28%27MISS%27%2C+%27NONE%2FUNKNOWN%27%2C+%27EXPIRED%27%2C+%27BYPASS%27%2C+%27DYNAMIC%27%29%0Agroup+by+path%2C+search%0Aorder+by+count+desc%0Alimit+50%3B) in the Logs Explorer.

Your cache hit ratio over time can then be determined using the following query:

`
select
timestamp_trunc(timestamp, hour) as timestamp,
countif(h.cf_cache_status in ('HIT', 'STALE', 'REVALIDATED', 'UPDATING')) / count(f.id) as ratio
from
edge_logs as f
cross join unnest(f.metadata) as m
cross join unnest(m.request) as r
cross join unnest(m.response) as res
cross join unnest(res.headers) as h
where starts_with(r.path, '/storage/v1/object') and r.method = 'GET'
group by timestamp
order by timestamp desc;
`

Try out [this query](https://supabase.com/dashboard/project/_/logs/explorer?q=%0Aselect%0A++timestamp_trunc%28timestamp%2C+hour%29+as+timestamp%2C%0A++countif%28h.cf_cache_status+in+%28%27HIT%27%2C+%27STALE%27%2C+%27REVALIDATED%27%2C+%27UPDATING%27%29%29+%2F+count%28f.id%29+as+ratio%0Afrom%0A++edge_logs+as+f%0A++cross+join+unnest%28f.metadata%29+as+m%0A++cross+join+unnest%28m.request%29+as+r%0A++cross+join+unnest%28m.response%29+as+res%0A++cross+join+unnest%28res.headers%29+as+h%0Awhere+starts_with%28r.path%2C+%27%2Fstorage%2Fv1%2Fobject%27%29+and+r.method+%3D+%27GET%27%0Agroup+by+timestamp%0Aorder+by+timestamp+desc%3B) in the Logs Explorer.

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_storage_cdn_smart_cdn.md">
Storage

# Smart CDN

* * *

With Smart CDN caching enabled, the asset metadata in your database is synchronized to the edge. This automatically revalidates the cache when the asset is changed or deleted.

Moreover, the Smart CDN achieves a greater cache hit rate by shielding the origin server from asset requests that remain unchanged, even when different query strings are used in the URL.

Smart CDN caching is automatically enabled for [Pro Plan and above](https://supabase.com/pricing).

## Cache duration [\#](https://supabase.com/docs/guides/storage/cdn/smart-cdn\#cache-duration)

When Smart CDN is enabled, the asset is cached on the CDN for as long as possible. You can still control how long assets are stored in the browser using the [`cacheControl`](https://supabase.com/docs/reference/javascript/storage-from-upload) option when uploading a file. Smart CDN caching works with all types of storage operations including signed URLs.

When a file is updated or deleted, the CDN cache is automatically invalidated to reflect the change (including transformed images). It can take **up to 60 seconds** for the CDN cache to be invalidated as the asset metadata has to propagate across all the data-centers around the globe.

When an asset is invalidated at the CDN level, browsers may not update its cache. This is where cache eviction comes into play.

## Cache eviction [\#](https://supabase.com/docs/guides/storage/cdn/smart-cdn\#cache-eviction)

Even when an asset is marked as invalidated at the CDN level, browsers may not refresh their cache for that asset.

If you have assets that undergo frequent updates, it is advisable to upload the new asset to a different path. This approach ensures that you always have the most up-to-date asset accessible.

If you anticipate that your asset might be deleted, it's advisable to set a shorter browser Time-to-Live (TTL) value using the `cacheControl` option. The default TTL is typically set to 1 hour, which is generally a reasonable default value.

## Bypassing cache [\#](https://supabase.com/docs/guides/storage/cdn/smart-cdn\#bypassing-cache)

If you need to ensure assets refresh directly from the origin server and bypass the cache, you can achieve this by adding a unique query string to the URL.

For instance, you can use a URL like `/storage/v1/object/sign/profile-pictures/cat.jpg?version=1` with a long browser cache (e.g., 1 year). To update the picture, increment the version query parameter in the URL, like `/storage/v1/object/sign/profile-pictures/cat.jpg?version=2`. The CDN will recognize it as a new object and fetch the updated version from the origin.

### Is this helpful?

NoYes

### On this page

[Cache duration](https://supabase.com/docs/guides/storage/cdn/smart-cdn#cache-duration) [Cache eviction](https://supabase.com/docs/guides/storage/cdn/smart-cdn#cache-eviction) [Bypassing cache](https://supabase.com/docs/guides/storage/cdn/smart-cdn#bypassing-cache)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_storage_debugging_error_codes.md">
Storage

# Error Codes

## Learn about the Storage error codes and how to resolve them

* * *

## Storage error codes [\#](https://supabase.com/docs/guides/storage/debugging/error-codes\#storage-error-codes)

We are transitioning to a new error code system. For backwards compatibility you'll still be able
to see the old error codes

Error codes in Storage are returned as part of the response body. They are useful for debugging and understanding what went wrong with your request.
The error codes are returned in the following format:

`
{
"code": "error_code",
"message": "error_message"
}
`

Here is the full list of error codes and their descriptions:

| `ErrorCode` | Description | `StatusCode` | Resolution |
| --- | --- | --- | --- |
| `NoSuchBucket` | The specified bucket does not exist. | 404 | Verify the bucket name and ensure it exists in the system, if it exists you don't have permissions to access it. |
| `NoSuchKey` | The specified key does not exist. | 404 | Check the key name and ensure it exists in the specified bucket, if it exists you don't have permissions to access it. |
| `NoSuchUpload` | The specified upload does not exist. | 404 | The upload ID provided might not exists or the Upload was previously aborted |
| `InvalidJWT` | The provided JWT (JSON Web Token) is invalid. | 401 | The JWT provided might be expired or malformed, provide a valid JWT |
| `InvalidRequest` | The request is not properly formed. | 400 | Review the request parameters and structure, ensure they meet the API's requirements, the error message will provide more details |
| `TenantNotFound` | The specified tenant does not exist. | 404 | The Storage service had issues while provisioning, [Contact Support](https://supabase.com/dashboard/support/new) |
| `EntityTooLarge` | The entity being uploaded is too large. | 413 | Verify the max-file-limit is equal or higher to the resource you are trying to upload, you can change this value on the [Project Setting](https://supabase.com/dashboard/project/_/settings/storage) |
| `InternalError` | An internal server error occurred. | 500 | Investigate server logs to identify the cause of the internal error. If you think it's a Storage error [Contact Support](https://supabase.com/dashboard/support/new) |
| `ResourceAlreadyExists` | The specified resource already exists. | 409 | Use a different name or identifier for the resource to avoid conflicts. Use `x-upsert:true` header to overwrite the resource. |
| `InvalidBucketName` | The specified bucket name is invalid. | 400 | Ensure the bucket name follows the naming conventions and does not contain invalid characters. |
| `InvalidKey` | The specified key is invalid. | 400 | Verify the key name and ensure it follows the naming conventions. |
| `InvalidRange` | The specified range is not valid. | 416 | Make sure that range provided is within the file size boundary and follow the [HTTP Range spec](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Range) |
| `InvalidMimeType` | The specified MIME type is not valid. | 400 | Provide a valid MIME type, ensure using the standard MIME type format |
| `InvalidUploadId` | The specified upload ID is invalid. | 400 | The upload ID provided is invalid or missing. Make sure to provide a active upload ID |
| `KeyAlreadyExists` | The specified key already exists. | 409 | Use a different key name to avoid conflicts with existing keys. Use `x-upsert:true` header to overwrite the resource. |
| `BucketAlreadyExists` | The specified bucket already exists. | 409 | Choose a unique name for the bucket that does not conflict with existing buckets. |
| `DatabaseTimeout` | Timeout occurred while accessing the database. | 504 | Investigate database performance and increase the default pool size. If this error still occurs, upgrade your instance |
| `InvalidSignature` | The signature provided does not match the calculated signature. | 403 | Check that you are providing the correct signature format, for more information refer to [SignatureV4](https://docs.aws.amazon.com/AmazonS3/latest/API/sig-v4-authenticating-requests.html) |
| `SignatureDoesNotMatch` | The request signature does not match the calculated signature. | 403 | Check your credentials, access key id / access secret key / region that are all correct, refer to [S3 Authentication](https://supabase.com/docs/guides/storage/s3/authentication). |
| `AccessDenied` | Access to the specified resource is denied. | 403 | Check that you have the correct RLS policy to allow access to this resource |
| `ResourceLocked` | The specified resource is locked. | 423 | This resource cannot be altered while there is a lock. Wait and try the request again |
| `DatabaseError` | An error occurred while accessing the database. | 500 | Investigate database logs and system configuration to identify and address the database error. |
| `MissingContentLength` | The Content-Length header is missing. | 411 | Ensure the Content-Length header is included in the request with the correct value. |
| `MissingParameter` | A required parameter is missing in the request. | 400 | Provide all required parameters in the request to fulfill the API's requirements. The message field will contain more details |
| `InvalidUploadSignature` | The provided upload signature is invalid. | 403 | The `MultiPartUpload` record was altered while the upload was ongoing, the signature do not match. Do not alter the upload record |
| `LockTimeout` | Timeout occurred while waiting for a lock. | 423 | The lock couldn't be acquired within the specified timeout. Wait and try the request again |
| `S3Error` | An error occurred related to Amazon S3. | - | Refer to Amazon S3 documentation or [Contact Support](https://supabase.com/dashboard/support/new) for assistance with resolving the S3 error. |
| `S3InvalidAccessKeyId` | The provided AWS access key ID is invalid. | 403 | Verify the AWS access key ID provided and ensure it is correct and active. |
| `S3MaximumCredentialsLimit` | The maximum number of credentials has been reached. | 400 | The maximum limit of credentials is reached. |
| `InvalidChecksum` | The checksum of the entity does not match. | 400 | Recalculate the checksum of the entity and ensure it matches the one provided in the request. |
| `MissingPart` | A part of the entity is missing. | 400 | Ensure all parts of the entity are included in the request before completing the operation. |
| `SlowDown` | The request rate is too high and has been throttled. | 503 | Reduce the request rate or implement exponential backoff and retry mechanisms to handle throttling. |

## Legacy error codes [\#](https://supabase.com/docs/guides/storage/debugging/error-codes\#legacy-error-codes)

As we are transitioning to a new error code system, you might still see the following error format:

`
{
"httpStatusCode": 400,
"code": "error_code",
"message": "error_message"
}
`

Here's a list of the most common error codes and their potential resolutions:

### 404 `not_found` [\#](https://supabase.com/docs/guides/storage/debugging/error-codes\#404-notfound)

Indicates that the resource is not found or you don't have the correct permission to access it
**Resolution:**

- Add a RLS policy to grant permission to the resource. See our [Access Control docs](https://supabase.com/docs/guides/storage/uploads/access-control) for more information.
- Ensure you include the user `Authorization` header
- Verify the object exists

### 409 `already_exists` [\#](https://supabase.com/docs/guides/storage/debugging/error-codes\#409-alreadyexists)

Indicates that the resource already exists.
**Resolution:**

- Use the `upsert` functionality in order to overwrite the file. Find out more [here](https://supabase.com/docs/guides/storage/uploads/standard-uploads#overwriting-files).

### 403 `unauthorized` [\#](https://supabase.com/docs/guides/storage/debugging/error-codes\#403-unauthorized)

You don't have permission to action this request
**Resolution:**

- Add RLS policy to grant permission. See our [Access Control docs](https://supabase.com/docs/guides/storage/security/access-control) for more information.
- Ensure you include the user `Authorization` header

### 429 `too many requests` [\#](https://supabase.com/docs/guides/storage/debugging/error-codes\#429-too-many-requests)

This problem typically arises when a large number of clients are concurrently interacting with the Storage service, and the pooler has reached its `max_clients` limit.

**Resolution:**

- Increase the max\_clients limits of the pooler.
- Upgrade to a bigger project compute instance [here](https://supabase.com/dashboard/project/_/settings/addons).

### 544 `database_timeout` [\#](https://supabase.com/docs/guides/storage/debugging/error-codes\#544-databasetimeout)

This problem arises when a high number of clients are concurrently using the Storage service, and Postgres doesn't have enough available connections to efficiently handle requests to Storage.

**Resolution:**

- Increase the pool\_size limits of the pooler.
- Upgrade to a bigger project compute instance [here](https://supabase.com/dashboard/project/_/settings/addons).

### 500 `internal_server_error` [\#](https://supabase.com/docs/guides/storage/debugging/error-codes\#500-internalservererror)

This issue occurs where there is a unhandled error.
**Resolution:**

- File a support ticket to Storage team [here](https://supabase.com/dashboard/support/new)

### Is this helpful?

NoYes

### On this page

[Storage error codes](https://supabase.com/docs/guides/storage/debugging/error-codes#storage-error-codes) [Legacy error codes](https://supabase.com/docs/guides/storage/debugging/error-codes#legacy-error-codes) [404 not\_found](https://supabase.com/docs/guides/storage/debugging/error-codes#404-notfound) [409 already\_exists](https://supabase.com/docs/guides/storage/debugging/error-codes#409-alreadyexists) [403 unauthorized](https://supabase.com/docs/guides/storage/debugging/error-codes#403-unauthorized) [429 too many requests](https://supabase.com/docs/guides/storage/debugging/error-codes#429-too-many-requests) [544 database\_timeout](https://supabase.com/docs/guides/storage/debugging/error-codes#544-databasetimeout) [500 internal\_server\_error](https://supabase.com/docs/guides/storage/debugging/error-codes#500-internalservererror)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_storage_debugging_logs.md">
Storage

# Logs

* * *

Accessing the [Storage Logs](https://supabase.com/dashboard/project/__/logs/explorer?q=select+id%2C+storage_logs.timestamp%2C+event_message+from+storage_logs%0A++%0A++order+by+timestamp+desc%0A++limit+100%0A++) allows you to examine all incoming request logs to your Storage service. You can also filter logs and delve into specific aspects of your requests.

### Common log queries [\#](https://supabase.com/docs/guides/storage/debugging/logs\#common-log-queries)

#### Filter by status 5XX error [\#](https://supabase.com/docs/guides/storage/debugging/logs\#filter-by-status-5xx-error)

`
select
id,
storage_logs.timestamp,
event_message,
r.statusCode,
e.message as errorMessage,
e.raw as rawError
from
storage_logs
cross join unnest(metadata) as m
cross join unnest(m.res) as r
cross join unnest(m.error) as e
where r.statusCode >= 500
order by timestamp desc
limit 100;
`

#### Filter by status 4XX error [\#](https://supabase.com/docs/guides/storage/debugging/logs\#filter-by-status-4xx-error)

`
select
id,
storage_logs.timestamp,
event_message,
r.statusCode,
e.message as errorMessage,
e.raw as rawError
from
storage_logs
cross join unnest(metadata) as m
cross join unnest(m.res) as r
cross join unnest(m.error) as e
where r.statusCode >= 400 and r.statusCode < 500
order by timestamp desc
limit 100;
`

#### Filter by method [\#](https://supabase.com/docs/guides/storage/debugging/logs\#filter-by-method)

`
select id, storage_logs.timestamp, event_message, r.method
from
storage_logs
cross join unnest(metadata) as m
cross join unnest(m.req) as r
where r.method in ("POST")
order by timestamp desc
limit 100;
`

#### Filter by IP address [\#](https://supabase.com/docs/guides/storage/debugging/logs\#filter-by-ip-address)

`
select id, storage_logs.timestamp, event_message, r.remoteAddress
from
storage_logs
cross join unnest(metadata) as m
cross join unnest(m.req) as r
where r.remoteAddress in ("IP_ADDRESS")
order by timestamp desc
limit 100;
`

### Is this helpful?

NoYes

### On this page

[Common log queries](https://supabase.com/docs/guides/storage/debugging/logs#common-log-queries)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_storage_management_copy_move_objects.md">
Storage

# Copy Objects

## Learn how to copy and move objects

* * *

## Copy objects [\#](https://supabase.com/docs/guides/storage/management/copy-move-objects\#copy-objects)

You can copy objects between buckets or within the same bucket. Currently only objects up to 5 GB can be copied using the API.

When making a copy of an object, the owner of the new object will be the user who initiated the copy operation.

### Copying objects within the same bucket [\#](https://supabase.com/docs/guides/storage/management/copy-move-objects\#copying-objects-within-the-same-bucket)

To copy an object within the same bucket, use the `copy` method.

`
await supabase.storage.from('avatars').copy('public/avatar1.png', 'private/avatar2.png')
`

### Copying objects across buckets [\#](https://supabase.com/docs/guides/storage/management/copy-move-objects\#copying-objects-across-buckets)

To copy an object across buckets, use the `copy` method and specify the destination bucket.

`
await supabase.storage.from('avatars').copy('public/avatar1.png', 'private/avatar2.png', {
destinationBucket: 'avatars2',
})
`

## Move objects [\#](https://supabase.com/docs/guides/storage/management/copy-move-objects\#move-objects)

You can move objects between buckets or within the same bucket. Currently only objects up to 5GB can be moved using the API.

When moving an object, the owner of the new object will be the user who initiated the move operation. Once the object is moved, the original object will no longer exist.

### Moving objects within the same bucket [\#](https://supabase.com/docs/guides/storage/management/copy-move-objects\#moving-objects-within-the-same-bucket)

To move an object within the same bucket, you can use the `move` method.

`
const { data, error } = await supabase.storage
.from('avatars')
.move('public/avatar1.png', 'private/avatar2.png')
`

### Moving objects across buckets [\#](https://supabase.com/docs/guides/storage/management/copy-move-objects\#moving-objects-across-buckets)

To move an object across buckets, use the `move` method and specify the destination bucket.

`
await supabase.storage.from('avatars').move('public/avatar1.png', 'private/avatar2.png', {
destinationBucket: 'avatars2',
})
`

## Permissions [\#](https://supabase.com/docs/guides/storage/management/copy-move-objects\#permissions)

For a user to move and copy objects, they need `select` permission on the source object and `insert` permission on the destination object. For example:

`
create policy "User can select their own objects (in any buckets)"
on storage.objects
for select
to authenticated
using (
    owner_id = (select auth.uid())
);
create policy "User can upload in their own folders (in any buckets)"
on storage.objects
for insert
to authenticated
with check (
    (storage.folder(name))[1] = (select auth.uid())
);
`

### Is this helpful?

NoYes

### On this page

[Copy objects](https://supabase.com/docs/guides/storage/management/copy-move-objects#copy-objects) [Copying objects within the same bucket](https://supabase.com/docs/guides/storage/management/copy-move-objects#copying-objects-within-the-same-bucket) [Copying objects across buckets](https://supabase.com/docs/guides/storage/management/copy-move-objects#copying-objects-across-buckets) [Move objects](https://supabase.com/docs/guides/storage/management/copy-move-objects#move-objects) [Moving objects within the same bucket](https://supabase.com/docs/guides/storage/management/copy-move-objects#moving-objects-within-the-same-bucket) [Moving objects across buckets](https://supabase.com/docs/guides/storage/management/copy-move-objects#moving-objects-across-buckets) [Permissions](https://supabase.com/docs/guides/storage/management/copy-move-objects#permissions)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_storage_management_delete_objects.md">
Storage

# Delete Objects

## Learn about deleting objects

* * *

When you delete one or more objects from a bucket, the files are permanently removed and not recoverable. You can delete a single object or multiple objects at once.

Deleting objects should always be done via the **Storage API** and NOT via a **SQL query**. Deleting objects via a SQL query will not remove the object from the bucket and will result in the object being orphaned.

## Delete objects [\#](https://supabase.com/docs/guides/storage/management/delete-objects\#delete-objects)

To delete one or more objects, use the `remove` method.

`
await supabase.storage.from('bucket').remove(['object-path-2', 'folder/avatar2.png'])
`

## RLS [\#](https://supabase.com/docs/guides/storage/management/delete-objects\#rls)

To delete an object, the user must have the `delete` permission on the object. For example:

`
create policy "User can delete their own objects"
on storage.objects
for delete
TO authenticated
USING (
    owner = (select auth.uid()::text)
);
`

### Is this helpful?

NoYes

### On this page

[Delete objects](https://supabase.com/docs/guides/storage/management/delete-objects#delete-objects) [RLS](https://supabase.com/docs/guides/storage/management/delete-objects#rls)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_storage_management_pricing.md">
Storage

# Pricing

* * *

You are charged for the total size of all assets in your buckets.

$0.00002919 per GB-Hr ($0.021 per GB per month). You are only charged for usage exceeding your subscription plan's quota.

| Plan | Quota in GB | Over-Usage per GB | Quota in GB-Hrs | Over-Usage per GB-Hrs |
| --- | --- | --- | --- | --- |
| Free | 1 | - | 744 | - |
| Pro | 100 | $0.021 | 74,400 | $0.00002919 |
| Team | 100 | $0.021 | 74,400 | $0.00002919 |
| Enterprise | Custom | Custom | Custom | Custom |

For a detailed explanation of how charges are calculated, refer to [Manage Storage size usage](https://supabase.com/docs/guides/platform/manage-your-usage/storage-size).

If you use [Storage Image Transformations](https://supabase.com/docs/guides/storage/serving/image-transformations), additional charges apply.

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_storage_production_scaling.md">
Storage

# Storage Optimizations

## Scaling Storage

* * *

Here are some optimizations that you can consider to improve performance and reduce costs as you start scaling Storage.

## Egress [\#](https://supabase.com/docs/guides/storage/production/scaling\#egress)

If your project has high egress, these optimizations can help reducing it.

#### Resize images [\#](https://supabase.com/docs/guides/storage/production/scaling\#resize-images)

Images typically make up most of your egress. By keeping them as small as possible, you can cut down on egress and boost your application's performance. You can take advantage of our [Image Transformation](https://supabase.com/docs/guides/storage/serving/image-transformations) service to optimize any image on the fly.

#### Set a high cache-control value [\#](https://supabase.com/docs/guides/storage/production/scaling\#set-a-high-cache-control-value)

Using the browser cache can effectively lower your egress since the asset remains stored in the user's browser after the initial download. Setting a high `cache-control` value ensures the asset stays in the user's browser for an extended period, decreasing the need to download it from the server repeatedly. Read more [here](https://supabase.com/docs/guides/storage/cdn/smart-cdn#cache-duration)

#### Limit the upload size [\#](https://supabase.com/docs/guides/storage/production/scaling\#limit-the-upload-size)

You have the option to set a maximum upload size for your bucket. Doing this can prevent users from uploading and then downloading excessively large files. You can control the maximum file size by configuring this option at the [bucket level](https://supabase.com/docs/guides/storage/buckets/creating-buckets).

## Optimize listing objects [\#](https://supabase.com/docs/guides/storage/production/scaling\#optimize-listing-objects)

Once you have a substantial number of objects, you might observe that the `supabase.storage.list()` method starts to slow down. This occurs because the endpoint is quite generic and attempts to retrieve both folders and objects in a single query. While this approach is very useful for building features like the Storage viewer on the Supabase dashboard, it can impact performance with a large number of objects.

If your application doesn't need the entire hierarchy computed you can speed up drastically the query execution for listing your objects by creating a Postgres function as following:

`
create or replace function list_objects(
    bucketid text,
    prefix text,
    limits int default 100,
    offsets int default 0
) returns table (
    name text,
    id uuid,
    updated_at timestamptz,
    created_at timestamptz,
    last_accessed_at timestamptz,
    metadata jsonb
) as $$
begin
    return query SELECT
        objects.name,
        objects.id,
        objects.updated_at,
        objects.created_at,
        objects.last_accessed_at,
        objects.metadata
    FROM storage.objects
    WHERE objects.name like prefix || '%'
    AND bucket_id = bucketid
    ORDER BY name ASC
    LIMIT limits
    OFFSET offsets;
end;
$$ language plpgsql stable;
`

You can then use the your Postgres function as following:

Using SQL:

`
select * from list_objects('bucket_id', '', 100, 0);
`

Using the SDK:

`
const { data, error } = await supabase.rpc('list_objects', {
bucketid: 'yourbucket',
prefix: '',
limit: 100,
offset: 0,
})
`

## Optimizing RLS [\#](https://supabase.com/docs/guides/storage/production/scaling\#optimizing-rls)

When creating RLS policies against the storage tables you can add indexes to the interested columns to speed up the lookup

### Is this helpful?

NoYes

### On this page

[Egress](https://supabase.com/docs/guides/storage/production/scaling#egress) [Optimize listing objects](https://supabase.com/docs/guides/storage/production/scaling#optimize-listing-objects) [Optimizing RLS](https://supabase.com/docs/guides/storage/production/scaling#optimizing-rls)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_storage_quickstart.md">
Storage

# Storage Quickstart

## Learn how to use Supabase to store and serve files.

* * *

This guide shows the basic functionality of Supabase Storage. Find a full [example application on GitHub](https://github.com/supabase/supabase/tree/master/examples/user-management/nextjs-user-management).

## Concepts [\#](https://supabase.com/docs/guides/storage/quickstart\#concepts)

Supabase Storage consists of Files, Folders, and Buckets.

### Files [\#](https://supabase.com/docs/guides/storage/quickstart\#files)

Files can be any sort of media file. This includes images, GIFs, and videos. It is best practice to store files outside of your database because of their sizes. For security, HTML files are returned as plain text.

### Folders [\#](https://supabase.com/docs/guides/storage/quickstart\#folders)

Folders are a way to organize your files (just like on your computer). There is no right or wrong way to organize your files. You can store them in whichever folder structure suits your project.

### Buckets [\#](https://supabase.com/docs/guides/storage/quickstart\#buckets)

Buckets are distinct containers for files and folders. You can think of them like "super folders". Generally you would create distinct buckets for different Security and Access Rules. For example, you might keep all video files in a "video" bucket, and profile pictures in an "avatar" bucket.

File, Folder, and Bucket names **must follow** [AWS object key naming guidelines](https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-keys.html) and avoid use of any other characters.

## Create a bucket [\#](https://supabase.com/docs/guides/storage/quickstart\#create-a-bucket)

You can create a bucket using the Supabase Dashboard. Since the storage is interoperable with your Postgres database, you can also use SQL or our client libraries. Here we create a bucket called "avatars":

DashboardSQLJavaScriptDartSwiftPython

1. Go to the [Storage](https://supabase.com/dashboard/project/_/storage/buckets) page in the Dashboard.
2. Click **New Bucket** and enter a name for the bucket.
3. Click **Create Bucket**.

## Upload a file [\#](https://supabase.com/docs/guides/storage/quickstart\#upload-a-file)

You can upload a file from the Dashboard, or within a browser using our JS libraries.

DashboardJavaScriptDart

1. Go to the [Storage](https://supabase.com/dashboard/project/_/storage/buckets) page in the Dashboard.
2. Select the bucket you want to upload the file to.
3. Click **Upload File**.
4. Select the file you want to upload.

## Download a file [\#](https://supabase.com/docs/guides/storage/quickstart\#download-a-file)

You can download a file from the Dashboard, or within a browser using our JS libraries.

DashboardJavaScriptDartSwiftPython

1. Go to the [Storage](https://supabase.com/dashboard/project/_/storage/buckets) page in the Dashboard.
2. Select the bucket that contains the file.
3. Select the file that you want to download.
4. Click **Download**.

## Add security rules [\#](https://supabase.com/docs/guides/storage/quickstart\#add-security-rules)

To restrict access to your files you can use either the Dashboard or SQL.

DashboardSQL

1. Go to the [Storage](https://supabase.com/dashboard/project/_/storage/buckets) page in the Dashboard.
2. Click **Policies** in the sidebar.
3. Click **Add Policies** in the `OBJECTS` table to add policies for Files. You can also create policies for Buckets.
4. Choose whether you want the policy to apply to downloads (SELECT), uploads (INSERT), updates (UPDATE), or deletes (DELETE).
5. Give your policy a unique name.
6. Write the policy using SQL.

* * *

Introduction to Supabase Storage - SupabaseTips - YouTube

Supabase

45.5K subscribers

[Introduction to Supabase Storage - SupabaseTips](https://www.youtube.com/watch?v=J9mTPY8rIXE)

Supabase

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=J9mTPY8rIXE "Watch on YouTube")

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2FJ9mTPY8rIXE%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Concepts](https://supabase.com/docs/guides/storage/quickstart#concepts) [Files](https://supabase.com/docs/guides/storage/quickstart#files) [Folders](https://supabase.com/docs/guides/storage/quickstart#folders) [Buckets](https://supabase.com/docs/guides/storage/quickstart#buckets) [Create a bucket](https://supabase.com/docs/guides/storage/quickstart#create-a-bucket) [Upload a file](https://supabase.com/docs/guides/storage/quickstart#upload-a-file) [Download a file](https://supabase.com/docs/guides/storage/quickstart#download-a-file) [Add security rules](https://supabase.com/docs/guides/storage/quickstart#add-security-rules)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_storage_s3_authentication.md">
Storage

# S3 Authentication

## Learn about authenticating with Supabase Storage S3.

* * *

You have two options to authenticate with Supabase Storage S3:

- Using the generated S3 access keys from your [project settings](https://supabase.com/dashboard/project/_/settings/storage) (Intended exclusively for server-side use)
- Using a Session Token, which will allow you to authenticate with a user JWT token and provide limited access via Row Level Security (RLS).

## S3 access keys [\#](https://supabase.com/docs/guides/storage/s3/authentication\#s3-access-keys)

##### Keep these credentials secure

S3 access keys provide full access to all S3 operations across all buckets and bypass RLS policies. These are meant to be used only on the server.

To authenticate with S3, generate a pair of credentials (Access Key ID and Secret Access Key), copy the endpoint and region from the [project settings page](https://supabase.com/dashboard/project/_/settings/storage).

This is all the information you need to connect to Supabase Storage using any S3-compatible service.

![Storage S3 Access keys](https://supabase.com/docs/img/storage/s3-credentials.png)

aws-sdk-jsAWS Credentials

`
import { S3Client } from '@aws-sdk/client-s3';
const client = new S3Client({
forcePathStyle: true,
region: 'project_region',
endpoint: 'https://project_ref.supabase.co/storage/v1/s3',
credentials: {
    accessKeyId: 'your_access_key_id',
    secretAccessKey: 'your_secret_access_key',
}
})
`

## Session token [\#](https://supabase.com/docs/guides/storage/s3/authentication\#session-token)

You can authenticate to Supabase S3 with a user JWT token to provide limited access via RLS to all S3 operations. This is useful when you want initialize the S3 client on the server scoped to a specific user, or use the S3 client directly from the client side.

All S3 operations performed with the Session Token are scoped to the authenticated user. RLS policies on the Storage Schema are respected.

To authenticate with S3 using a Session Token, use the following credentials:

- access\_key\_id: `project_ref`
- secret\_access\_key: `anonKey`
- session\_token: `valid jwt token`

For example, using the `aws-sdk` library:

`
import { S3Client } from '@aws-sdk/client-s3'
const {
data: { session },
} = await supabase.auth.getSession()
const client = new S3Client({
forcePathStyle: true,
region: 'project_region',
endpoint: 'https://project_ref.supabase.co/storage/v1/s3',
credentials: {
    accessKeyId: 'project_ref',
    secretAccessKey: 'anonKey',
    sessionToken: session.access_token,
},
})
`

### Is this helpful?

NoYes

### On this page

[S3 access keys](https://supabase.com/docs/guides/storage/s3/authentication#s3-access-keys) [Session token](https://supabase.com/docs/guides/storage/s3/authentication#session-token)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_storage_s3_compatibility.md">
Storage

# S3 Compatibility

## Learn about the compatibility of Supabase Storage with S3.

* * *

Supabase Storage is compatible with the S3 protocol. You can use any S3 client to interact with your Storage objects.

Storage supports [standard](https://supabase.com/docs/guides/storage/uploads/standard-uploads), [resumable](https://supabase.com/docs/guides/storage/uploads/resumable-uploads) and [S3 uploads](https://supabase.com/docs/guides/storage/uploads/s3-uploads) and all these protocols are interoperable. You can upload a file with the S3 protocol and list it with the REST API or upload with Resumable uploads and list with S3.

Storage supports presigning a URL using query parameters. Specifically, Supabase Storage expects requests to be made using [AWS Signature Version 4](https://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-query-string-auth.html). To enable this feature, enable the S3 connection via S3 protocol in the Settings page for Supabase Storage.

The S3 protocol is currently in Public Alpha. If you encounter any issues or have feature requests, [contact us](https://supabase.com/dashboard/support/new).

## Implemented endpoints [\#](https://supabase.com/docs/guides/storage/s3/compatibility\#implemented-endpoints)

The most commonly used endpoints are implemented, and more will be added. Implemented S3 endpoints are marked with  in the following tables.

### Bucket operations [\#](https://supabase.com/docs/guides/storage/s3/compatibility\#bucket-operations)

| API Name | Feature |
| --- | --- |
|  [ListBuckets](https://docs.aws.amazon.com/AmazonS3/latest/API/API_ListBuckets.html) |  |
|  [HeadBucket](https://docs.aws.amazon.com/AmazonS3/latest/API/API_HeadBucket.html) |  Bucket Owner:<br>  x-amz-expected-bucket-owner |
|  [CreateBucket](https://docs.aws.amazon.com/AmazonS3/latest/API/API_CreateBucket.html) |  ACL:<br>  x-amz-acl<br>  x-amz-grant-full-control<br>  x-amz-grant-read<br>  x-amz-grant-read-acp<br>  x-amz-grant-write<br>  x-amz-grant-write-acp<br> Object Locking:<br>  x-amz-bucket-object-lock-enabled<br> Bucket Owner:<br>  x-amz-expected-bucket-owner |
|  [DeleteBucket](https://docs.aws.amazon.com/AmazonS3/latest/API/API_DeleteBucket.html) |  Bucket Owner:<br>  x-amz-expected-bucket-owner |
|  [GetBucketLocation](https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetBucketLocation.html) |  Bucket Owner:<br>  x-amz-expected-bucket-owner |
|  [DeleteBucketCors](https://docs.aws.amazon.com/AmazonS3/latest/API/API_DeleteBucketCors.html) |  Bucket Owner:<br>  x-amz-expected-bucket-owner |
|  [GetBucketEncryption](https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetBucketEncryption.html) |  Bucket Owner:<br>  x-amz-expected-bucket-owner |
|  [GetBucketLifecycleConfiguration](https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetBucketLifecycleConfiguration.html) |  Bucket Owner:<br>  x-amz-expected-bucket-owner |
|  [GetBucketCors](https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetBucketCors.html) |  Bucket Owner:<br>  x-amz-expected-bucket-owner |
|  [PutBucketCors](https://docs.aws.amazon.com/AmazonS3/latest/API/API_PutBucketCors.html) |  Checksums:<br>  x-amz-sdk-checksum-algorithm<br>  x-amz-checksum-algorithm<br> Bucket Owner:<br>  x-amz-expected-bucket-owner |
|  [PutBucketLifecycleConfiguration](https://docs.aws.amazon.com/AmazonS3/latest/API/API_PutBucketLifecycleConfiguration.html) |  Checksums:<br>  x-amz-sdk-checksum-algorithm<br>  x-amz-checksum-algorithm<br> Bucket Owner:<br>  x-amz-expected-bucket-owner |

### Object operations [\#](https://supabase.com/docs/guides/storage/s3/compatibility\#object-operations)

| API Name | Feature |
| --- | --- |
|  [HeadObject](https://docs.aws.amazon.com/AmazonS3/latest/API/API_HeadObject.html) |  Conditional Operations:<br>  If-Match<br>  If-Modified-Since<br>  If-None-Match<br>  If-Unmodified-Since<br> Range:<br>  Range (has no effect in HeadObject)<br>  partNumber<br> SSE-C:<br>  x-amz-server-side-encryption-customer-algorithm<br>  x-amz-server-side-encryption-customer-key<br>  x-amz-server-side-encryption-customer-key-MD5<br> Request Payer:<br>  x-amz-request-payer<br> Bucket Owner:<br>  x-amz-expected-bucket-owner |
|  [ListObjects](https://docs.aws.amazon.com/AmazonS3/latest/API/API_ListObjects.html) | Query Parameters:<br>  delimiter<br>  encoding-type<br>  marker<br>  max-keys<br>  prefix<br> Request Payer:<br>  x-amz-request-payer<br> Bucket Owner:<br>  x-amz-expected-bucket-owner |
|  [ListObjectsV2](https://docs.aws.amazon.com/AmazonS3/latest/API/API_ListObjectsV2.html) | Query Parameters:<br>  list-type<br>  continuation-token<br>  delimiter<br>  encoding-type<br>  fetch-owner<br>  max-keys<br>  prefix<br>  start-after<br> Request Payer:<br>  x-amz-request-payer<br> Bucket Owner:<br>  x-amz-expected-bucket-owner |
|  [GetObject](https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObject.html) |  Conditional Operations:<br>  If-Match<br>  If-Modified-Since<br>  If-None-Match<br>  If-Unmodified-Since<br> Range:<br>  Range<br>  PartNumber<br> SSE-C:<br>  x-amz-server-side-encryption-customer-algorithm<br>  x-amz-server-side-encryption-customer-key<br>  x-amz-server-side-encryption-customer-key-MD5<br> Request Payer:<br>  x-amz-request-payer<br> Bucket Owner:<br>  x-amz-expected-bucket-owner |
|  [PutObject](https://docs.aws.amazon.com/AmazonS3/latest/API/API_PutObject.html) | System Metadata:<br>  Content-Type<br>  Cache-Control<br>  Content-Disposition<br>  Content-Encoding<br>  Content-Language<br>  Expires<br>  Content-MD5<br> Object Lifecycle<br> Website:<br>  x-amz-website-redirect-location<br> SSE-C:<br>  x-amz-server-side-encryption<br>  x-amz-server-side-encryption-customer-algorithm<br>  x-amz-server-side-encryption-customer-key<br>  x-amz-server-side-encryption-customer-key-MD5<br>  x-amz-server-side-encryption-aws-kms-key-id<br>  x-amz-server-side-encryption-context<br>  x-amz-server-side-encryption-bucket-key-enabled<br> Request Payer:<br>  x-amz-request-payer<br> Tagging:<br>  x-amz-tagging<br> Object Locking:<br>  x-amz-object-lock-mode<br>  x-amz-object-lock-retain-until-date<br>  x-amz-object-lock-legal-hold<br> ACL:<br>  x-amz-acl<br>  x-amz-grant-full-control<br>  x-amz-grant-read<br>  x-amz-grant-read-acp<br>  x-amz-grant-write-acp<br> Bucket Owner:<br>  x-amz-expected-bucket-owner |
|  [DeleteObject](https://docs.aws.amazon.com/AmazonS3/latest/API/API_DeleteObject.html) |  Multi-factor authentication:<br>  x-amz-mfa<br> Object Locking:<br>  x-amz-bypass-governance-retention<br> Request Payer:<br>  x-amz-request-payer<br> Bucket Owner:<br>  x-amz-expected-bucket-owner |
|  [DeleteObjects](https://docs.aws.amazon.com/AmazonS3/latest/API/API_DeleteObjects.html) |  Multi-factor authentication:<br>  x-amz-mfa<br> Object Locking:<br>  x-amz-bypass-governance-retention<br> Request Payer:<br>  x-amz-request-payer<br> Bucket Owner:<br>  x-amz-expected-bucket-owner |
|  [ListMultipartUploads](https://docs.aws.amazon.com/AmazonS3/latest/API/API_ListMultipartUploads.html) |  Query Parameters:<br>  delimiter<br>  encoding-type<br>  key-marker<br>  max-uploads<br>  prefix<br>  upload-id-marker |
|  [CreateMultipartUpload](https://docs.aws.amazon.com/AmazonS3/latest/API/API_CreateMultipartUpload.html) |  System Metadata:<br>  Content-Type<br>  Cache-Control<br>  Content-Disposition<br>  Content-Encoding<br>  Content-Language<br>  Expires<br>  Content-MD5<br> Website:<br>  x-amz-website-redirect-location<br> SSE-C:<br>  x-amz-server-side-encryption<br>  x-amz-server-side-encryption-customer-algorithm<br>  x-amz-server-side-encryption-customer-key<br>  x-amz-server-side-encryption-customer-key-MD5<br>  x-amz-server-side-encryption-aws-kms-key-id<br>  x-amz-server-side-encryption-context<br>  x-amz-server-side-encryption-bucket-key-enabled<br> Request Payer:<br>  x-amz-request-payer<br> Tagging:<br>  x-amz-tagging<br> Object Locking:<br>  x-amz-object-lock-mode<br>  x-amz-object-lock-retain-until-date<br>  x-amz-object-lock-legal-hold<br> ACL:<br>  x-amz-acl<br>  x-amz-grant-full-control<br>  x-amz-grant-read<br>  x-amz-grant-read-acp<br>  x-amz-grant-write-acp<br> Storage class:<br>  x-amz-storage-class<br> Bucket Owner:<br>  x-amz-expected-bucket-owner |
|  [CompleteMultipartUpload](https://docs.aws.amazon.com/AmazonS3/latest/API/API_CompleteMultipartUpload.html) |  Bucket Owner:<br>  x-amz-expected-bucket-owner<br> Request Payer:<br>  x-amz-request-payer |
|  [AbortMultipartUpload](https://docs.aws.amazon.com/AmazonS3/latest/API/API_AbortMultipartUpload.html) |  Request Payer:<br>  x-amz-request-payer |
|  [CopyObject](https://docs.aws.amazon.com/AmazonS3/latest/API/API_CopyObject.html) |  Operation Metadata:<br>  x-amz-metadata-directive<br> System Metadata:<br>  Content-Type<br>  Cache-Control<br>  Content-Disposition<br>  Content-Encoding<br>  Content-Language<br>  Expires<br> Conditional Operations:<br>  x-amz-copy-source<br>  x-amz-copy-source-if-match<br>  x-amz-copy-source-if-modified-since<br>  x-amz-copy-source-if-none-match<br>  x-amz-copy-source-if-unmodified-since<br> ACL:<br>  x-amz-acl<br>  x-amz-grant-full-control<br>  x-amz-grant-read<br>  x-amz-grant-read-acp<br>  x-amz-grant-write-acp<br> Website:<br>  x-amz-website-redirect-location<br> SSE-C:<br>  x-amz-server-side-encryption<br>  x-amz-server-side-encryption-customer-algorithm<br>  x-amz-server-side-encryption-customer-key<br>  x-amz-server-side-encryption-customer-key-MD5<br>  x-amz-server-side-encryption-aws-kms-key-id<br>  x-amz-server-side-encryption-context<br>  x-amz-server-side-encryption-bucket-key-enabled<br>  x-amz-copy-source-server-side-encryption-customer-algorithm<br>  x-amz-copy-source-server-side-encryption-customer-key<br>  x-amz-copy-source-server-side-encryption-customer-key-MD5<br> Request Payer:<br>  x-amz-request-payer<br> Tagging:<br>  x-amz-tagging<br>  x-amz-tagging-directive<br> Object Locking:<br>  x-amz-object-lock-mode<br>  x-amz-object-lock-retain-until-date<br>  x-amz-object-lock-legal-hold<br> Bucket Owner:<br>  x-amz-expected-bucket-owner<br>  x-amz-source-expected-bucket-owner<br> Checksums:<br>  x-amz-checksum-algorithm |
|  [UploadPart](https://docs.aws.amazon.com/AmazonS3/latest/API/API_UploadPart.html) |  System Metadata:<br> Content-MD5<br> SSE-C:<br>  x-amz-server-side-encryption<br>  x-amz-server-side-encryption-customer-algorithm<br>  x-amz-server-side-encryption-customer-key<br>  x-amz-server-side-encryption-customer-key-MD5<br> Request Payer:<br>  x-amz-request-payer<br> Bucket Owner:<br>  x-amz-expected-bucket-owner |
|  [UploadPartCopy](https://docs.aws.amazon.com/AmazonS3/latest/API/API_UploadPartCopy.html) |  Conditional Operations:<br>  x-amz-copy-source<br>  x-amz-copy-source-if-match<br>  x-amz-copy-source-if-modified-since<br>  x-amz-copy-source-if-none-match<br>  x-amz-copy-source-if-unmodified-since<br> Range:<br>  x-amz-copy-source-range<br> SSE-C:<br>  x-amz-server-side-encryption-customer-algorithm<br>  x-amz-server-side-encryption-customer-key<br>  x-amz-server-side-encryption-customer-key-MD5<br>  x-amz-copy-source-server-side-encryption-customer-algorithm<br>  x-amz-copy-source-server-side-encryption-customer-key<br>  x-amz-copy-source-server-side-encryption-customer-key-MD5<br> Request Payer:<br>  x-amz-request-payer<br> Bucket Owner:<br>  x-amz-expected-bucket-owner<br>  x-amz-source-expected-bucket-owner |
|  [ListParts](https://docs.aws.amazon.com/AmazonS3/latest/API/API_ListParts.html) | Query Parameters:<br>  max-parts<br>  part-number-marker<br> Request Payer:<br>  x-amz-request-payer<br> Bucket Owner:<br>  x-amz-expected-bucket-owner |

### Is this helpful?

NoYes

### On this page

[Implemented endpoints](https://supabase.com/docs/guides/storage/s3/compatibility#implemented-endpoints) [Bucket operations](https://supabase.com/docs/guides/storage/s3/compatibility#bucket-operations) [Object operations](https://supabase.com/docs/guides/storage/s3/compatibility#object-operations)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_storage_schema_custom_roles.md">
Storage

# Custom Roles

## Learn about using custom roles with storage schema

* * *

In this guide, you will learn how to create and use custom roles with Storage to manage role-based access to objects and buckets. The same approach can be used to use custom roles with any other Supabase service.

Supabase Storage uses the same role-based access control system as any other Supabase service using RLS (Row Level Security).

## Create a custom role [\#](https://supabase.com/docs/guides/storage/schema/custom-roles\#create-a-custom-role)

Let's create a custom role `manager` to provide full read access to a specific bucket. For a more advanced setup, see the [RBAC Guide](https://supabase.com/docs/guides/auth/custom-claims-and-role-based-access-control-rbac#create-auth-hook-to-apply-user-role).

`
create role 'manager';
-- Important to grant the role to the authenticator and anon role
grant manager to authenticator;
grant anon to manager;
`

## Create a policy [\#](https://supabase.com/docs/guides/storage/schema/custom-roles\#create-a-policy)

Let's create a policy that gives full read permissions to all objects in the bucket `teams` for the `manager` role.

`
create policy "Manager can view all files in the bucket 'teams'"
on storage.objects
for select
to manager
using (
bucket_id = 'teams'
);
`

## Test the policy [\#](https://supabase.com/docs/guides/storage/schema/custom-roles\#test-the-policy)

To impersonate the `manager` role, you will need a valid JWT token with the `manager` role.
You can quickly create one using the `jsonwebtoken` library in Node.js.

Signing a new JWT requires your `JWT_SECRET`. You must store this secret securely. Never expose it in frontend code, and do not check it into version control.

`
const jwt = require('jsonwebtoken')
const JWT_SECRET = 'your-jwt-secret' // You can find this in your Supabase project settings under API. Store this securely.
const USER_ID = '' // the user id that we want to give the manager role
const token = jwt.sign({ role: 'manager', sub: USER_ID }, JWT_SECRET, {
expiresIn: '1h',
})
`

Now you can use this token to access the Storage API.

``
const { StorageClient } = require('@supabase/storage-js')
const PROJECT_URL = 'https://your-project-id.supabase.co/storage/v1'
const storage = new StorageClient(PROJECT_URL, {
authorization: `Bearer ${token}`,
})
await storage.from('teams').list()
``

### Is this helpful?

NoYes

### On this page

[Create a custom role](https://supabase.com/docs/guides/storage/schema/custom-roles#create-a-custom-role) [Create a policy](https://supabase.com/docs/guides/storage/schema/custom-roles#create-a-policy) [Test the policy](https://supabase.com/docs/guides/storage/schema/custom-roles#test-the-policy)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_storage_schema_design.md">
Storage

# The Storage Schema

## Learn about the storage schema

* * *

Storage uses Postgres to store metadata regarding your buckets and objects. Users can use RLS (Row-Level Security) policies for access control. This data is stored in a dedicated schema within your project called `storage`.

When working with SQL, it's crucial to consider all records in Storage tables as read-only. All operations, including uploading, copying, moving, and deleting, should **exclusively go through the API**.

This is important because the storage schema only stores the metadata and the actual objects are stored in a provider like S3. Deleting the metadata doesn't remove the object in the underlying storage provider. This results in your object being inaccessible, but you'll still be billed for it.

Here is the schema that represents the Storage service:

![Storage schema design](https://supabase.com/docs/img/storage/schema-design.png)

You have the option to query this table directly to retrieve information about your files in Storage without the need to go through our API.

## Modifying the schema [\#](https://supabase.com/docs/guides/storage/schema/design\#modifying-the-schema)

We strongly recommend refraining from making any alterations to the `storage` schema and treating it as read-only. This approach is important because any modifications to the schema on your end could potentially clash with our future updates, leading to downtime.

However, we encourage you to add custom indexes as they can significantly improve the performance of the RLS policies you create for enforcing access control.

### Is this helpful?

NoYes

### On this page

[Modifying the schema](https://supabase.com/docs/guides/storage/schema/design#modifying-the-schema)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_storage_schema_helper_functions.md">
Storage

# Storage Helper Functions

## Learn the storage schema

* * *

Supabase Storage provides SQL helper functions which you can use to write RLS policies.

### `storage.filename()` [\#](https://supabase.com/docs/guides/storage/schema/helper-functions\#storagefilename)

Returns the name of a file. For example, if your file is stored in `public/subfolder/avatar.png` it would return: `'avatar.png'`

**Usage**

This example demonstrates how you would allow any user to download a file called `favicon.ico`:

`
create policy "Allow public downloads"
on storage.objects
for select
to public
using (
storage.filename(name) = 'favicon.ico'
);
`

### `storage.foldername()` [\#](https://supabase.com/docs/guides/storage/schema/helper-functions\#storagefoldername)

Returns an array path, with all of the subfolders that a file belongs to. For example, if your file is stored in `public/subfolder/avatar.png` it would return: `[ 'public', 'subfolder' ]`

**Usage**

This example demonstrates how you would allow authenticated users to upload files to a folder called `private`:

`
create policy "Allow authenticated uploads"
on storage.objects
for insert
to authenticated
with check (
(storage.foldername(name))[1] = 'private'
);
`

### `storage.extension()` [\#](https://supabase.com/docs/guides/storage/schema/helper-functions\#storageextension)

Returns the extension of a file. For example, if your file is stored in `public/subfolder/avatar.png` it would return: `'png'`

**Usage**

This example demonstrates how you would allow restrict uploads to only PNG files inside a bucket called `cats`:

`
create policy "Only allow PNG uploads"
on storage.objects
for insert
to authenticated
with check (
bucket_id = 'cats' and storage.extension(name) = 'png'
);
`

### Is this helpful?

NoYes

### On this page

[storage.filename()](https://supabase.com/docs/guides/storage/schema/helper-functions#storagefilename) [storage.foldername()](https://supabase.com/docs/guides/storage/schema/helper-functions#storagefoldername) [storage.extension()](https://supabase.com/docs/guides/storage/schema/helper-functions#storageextension)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_storage_security_access_control.md">
Storage

# Storage Access Control

* * *

Supabase Storage is designed to work perfectly with Postgres [Row Level Security](https://supabase.com/docs/guides/database/postgres/row-level-security) (RLS).

You can use RLS to create [Security Access Policies](https://www.postgresql.org/docs/current/sql-createpolicy.html) that are incredibly powerful and flexible, allowing you to restrict access based on your business needs.

## Access policies [\#](https://supabase.com/docs/guides/storage/security/access-control\#access-policies)

By default Storage does not allow any uploads to buckets without RLS policies. You selectively allow certain operations by creating RLS policies on the `storage.objects` table.

You can find the documentation for the storage schema [here](https://supabase.com/docs/guides/storage/schema/design) , and to simplify the process of crafting your policies, you can utilize these [helper functions](https://supabase.com/docs/guides/storage/schema/helper-functions) .

The RLS policies required for different operations are documented [here](https://supabase.com/docs/reference/javascript/storage-createbucket)

For example, the only RLS policy required for [uploading](https://supabase.com/docs/reference/javascript/storage-from-upload) objects is to grant the `INSERT` permission to the `storage.objects` table.

To allow overwriting files using the `upsert` functionality you will need to additionally grant `SELECT` and `UPDATE` permissions.

## Policy examples [\#](https://supabase.com/docs/guides/storage/security/access-control\#policy-examples)

An easy way to get started would be to create RLS policies for `SELECT`, `INSERT`, `UPDATE`, `DELETE` operations and restrict the policies to meet your security requirements. For example, one can start with the following `INSERT` policy:

`
create policy "policy_name"
ON storage.objects
for insert with check (
true
);
`

and modify it to only allow authenticated users to upload assets to a specific bucket by changing it to:

`
create policy "policy_name"
on storage.objects for insert to authenticated with check (
    -- restrict bucket
    bucket_id = 'my_bucket_id'
);
`

This example demonstrates how you would allow authenticated users to upload files to a folder called `private` inside `my_bucket_id`:

`
create policy "Allow authenticated uploads"
on storage.objects
for insert
to authenticated
with check (
bucket_id = 'my_bucket_id' and
(storage.foldername(name))[1] = 'private'
);
`

This example demonstrates how you would allow authenticated users to upload files to a folder called with their `users.id` inside `my_bucket_id`:

`
create policy "Allow authenticated uploads"
on storage.objects
for insert
to authenticated
with check (
bucket_id = 'my_bucket_id' and
(storage.foldername(name))[1] = (select auth.uid()::text)
);
`

Allow a user to access a file that was previously uploaded by the same user:

`
create policy "Individual user Access"
on storage.objects for select
to authenticated
using ( (select auth.uid()) = owner_id::uuid );
`

* * *

How to Configure Access Control on Your Supabase Storage Buckets - SupabaseTips - YouTube

Supabase

45.5K subscribers

[How to Configure Access Control on Your Supabase Storage Buckets - SupabaseTips](https://www.youtube.com/watch?v=4ERX__Y908k)

Supabase

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=4ERX__Y908k "Watch on YouTube")

## Bypassing access controls [\#](https://supabase.com/docs/guides/storage/security/access-control\#bypassing-access-controls)

If you exclusively use Storage from trusted clients, such as your own servers, and need to bypass the RLS policies, you can use the `service key` in the `Authorization` header. Service keys entirely bypass RLS policies, granting you unrestricted access to all Storage APIs.

Remember you should not share the service key publicly.

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2F4ERX__Y908k%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Access policies](https://supabase.com/docs/guides/storage/security/access-control#access-policies) [Policy examples](https://supabase.com/docs/guides/storage/security/access-control#policy-examples) [Bypassing access controls](https://supabase.com/docs/guides/storage/security/access-control#bypassing-access-controls)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_storage_security_ownership.md">
Storage

# Ownership

* * *

When creating new buckets or objects in Supabase Storage, an owner is automatically assigned to the bucket or object. The owner is the user who created the resource and the value is derived from the `sub` claim in the JWT.
We store the `owner` in the `owner_id` column.

When using the `service_key` to create a resource, the owner will not be set and the resource will be owned by anyone. This is also the case when you are creating Storage resources via the Dashboard.

The Storage schema has 2 fields to represent ownership: `owner` and `owner_id`. `owner` is deprecated and will be removed. Use `owner_id` instead.

## Access control [\#](https://supabase.com/docs/guides/storage/security/ownership\#access-control)

By itself, the ownership of a resource does not provide any access control. However, you can enforce the ownership by implementing access control against storage resources scoped to their owner.

For example, you can implement a policy where only the owner of an object can delete it. To do this, check the `owner_id` field of the object and compare it with the `sub` claim of the JWT:

`
create policy "User can delete their own objects"
on storage.objects
for delete
to authenticated
using (
    owner_id = (select auth.uid())
);
`

The use of RLS policies is just one way to enforce access control. You can also implement access control in your server code by following the same pattern.

### Is this helpful?

NoYes

### On this page

[Access control](https://supabase.com/docs/guides/storage/security/ownership#access-control)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_storage_serving_bandwidth.md">
Storage

# Bandwidth & Storage Egress

## Bandwidth & Storage Egress

* * *

## Bandwidth & Storage egress [\#](https://supabase.com/docs/guides/storage/serving/bandwidth\#bandwidth--storage-egress)

Free Plan Organizations in Supabase have a limit of 5 GB of bandwidth. This limit is calculated by the sum of all the data transferred from the Supabase servers to the client. This includes all the data transferred from the database, storage, and functions.

### Checking Storage egress requests in Logs Explorer: [\#](https://supabase.com/docs/guides/storage/serving/bandwidth\#checking-storage-egress-requests-in-logs-explorer)

We have a template query that you can use to get the number of requests for each object in [Logs Explorer](https://supabase.com/dashboard/project/_/logs/explorer/templates).

`
select
r.method as http_verb,
r.path as filepath,
count(*) as num_requests
from
edge_logs
cross join unnest(metadata) as m
cross join unnest(m.request) as r
cross join unnest(r.headers) as h
where (path like '%storage/v1/object/%' or path like '%storage/v1/render/%') and r.method = 'GET'
group by r.path, r.method
order by num_requests desc
limit 100;
`

Example of the output:

`
[\
    {"filepath":"/storage/v1/object/sign/large%20bucket/20230902_200037.gif",\
    "http_verb":"GET",\
    "num_requests":100\
    },\
    {"filepath":"/storage/v1/object/public/demob/Sports/volleyball.png",\
    "http_verb":"GET",\
    "num_requests":168\
    }\
]
`

### Calculating egress: [\#](https://supabase.com/docs/guides/storage/serving/bandwidth\#calculating-egress)

If you already know the size of those files, you can calculate the egress by multiplying the number of requests by the size of the file.
You can also get the size of the file with the following cURL:

`
curl -s -w "%{size_download}\n" -o /dev/null "https://my_project.supabase.co/storage/v1/object/large%20bucket/20230902_200037.gif"
`

This will return the size of the file in bytes.
For this example, let's say that `20230902_200037.gif` has a file size of 3 megabytes and `volleyball.png` has a file size of 570 kilobytes.

Now, we have to sum all the egress for all the files to get the total egress:

`
100 * 3MB = 300MB
168 * 570KB = 95.76MB
Total Egress = 395.76MB
`

You can see that these values can get quite large, so it's important to keep track of the egress and optimize the files.

### Optimizing egress: [\#](https://supabase.com/docs/guides/storage/serving/bandwidth\#optimizing-egress)

If you are on the Pro Plan, you can use the [Supabase Image Transformations](https://supabase.com/docs/guides/storage/image-transformations) to optimize the images and reduce the egress.

### Is this helpful?

NoYes

### On this page

[Bandwidth & Storage egress](https://supabase.com/docs/guides/storage/serving/bandwidth#bandwidth--storage-egress) [Checking Storage egress requests in Logs Explorer:](https://supabase.com/docs/guides/storage/serving/bandwidth#checking-storage-egress-requests-in-logs-explorer) [Calculating egress:](https://supabase.com/docs/guides/storage/serving/bandwidth#calculating-egress) [Optimizing egress:](https://supabase.com/docs/guides/storage/serving/bandwidth#optimizing-egress)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_storage_serving_downloads.md">
Storage

# Serving assets from Storage

## Serving assets from Storage

* * *

## Public buckets [\#](https://supabase.com/docs/guides/storage/serving/downloads\#public-buckets)

As mentioned in the [Buckets Fundamentals](https://supabase.com/docs/guides/storage/buckets/fundamentals) all files uploaded in a public bucket are publicly accessible and benefit a high CDN cache HIT ratio.

You can access them by using this conventional URL:

`
https://[project_id].supabase.co/storage/v1/object/public/[bucket]/[asset-name]
`

You can also use the Supabase SDK `getPublicUrl` to generate this URL for you

`
const { data } = supabase.storage.from('bucket').getPublicUrl('filePath.jpg')
console.log(data.publicUrl)
`

### Downloading [\#](https://supabase.com/docs/guides/storage/serving/downloads\#downloading)

If you want the browser to start an automatic download of the asset instead of trying serving it, you can add the `?download` query string parameter.

By default it will use the asset name to save the file on disk. You can optionally pass a custom name to the `download` parameter as following: `?download=customname.jpg`

## Private buckets [\#](https://supabase.com/docs/guides/storage/serving/downloads\#private-buckets)

Assets stored in a non-public bucket are considered private and are not accessible via a public URL like the public buckets.

You can access them only by:

- Signing a time limited URL on the Server, for example with Edge Functions.
- with a GET request the URL `https://[project_id].supabase.co/storage/v1/object/authenticated/[bucket]/[asset-name]` and the user Authorization header

### Signing URLs [\#](https://supabase.com/docs/guides/storage/serving/downloads\#signing-urls)

You can sign a time-limited URL that you can share to your users by invoking the `createSignedUrl` method on the SDK.

`
const { data, error } = await supabase.storage
.from('bucket')
.createSignedUrl('private-document.pdf', 3600)
if (data) {
console.log(data.signedUrl)
}
`

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2FdLqSmxX3r7I%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Public buckets](https://supabase.com/docs/guides/storage/serving/downloads#public-buckets) [Downloading](https://supabase.com/docs/guides/storage/serving/downloads#downloading) [Private buckets](https://supabase.com/docs/guides/storage/serving/downloads#private-buckets) [Signing URLs](https://supabase.com/docs/guides/storage/serving/downloads#signing-urls)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_storage_serving_image_transformations.md">
Storage

# Storage Image Transformations

## Transform images with Storage

* * *

Supabase Storage offers the functionality to optimize and resize images on the fly. Any image stored in your buckets can be transformed and optimized for fast delivery.

Image Resizing is currently enabled for [Pro Plan and above](https://supabase.com/pricing).

## Get a public URL for a transformed image [\#](https://supabase.com/docs/guides/storage/serving/image-transformations\#get-a-public-url-for-a-transformed-image)

Our client libraries methods like `getPublicUrl` and `createSignedUrl` support the `transform` option. This returns the URL that serves the transformed image.

JavaScriptDartSwiftKotlinPython

`
supabase.storage.from('bucket').getPublicUrl('image.jpg', {
transform: {
    width: 500,
    height: 600,
},
})
`

An example URL could look like this:

``
https://project_id.supabase.co/storage/v1/render/image/public/bucket/image.jpg?width=500&height=600`
``

## Signing URLs with transformation options [\#](https://supabase.com/docs/guides/storage/serving/image-transformations\#signing-urls-with-transformation-options)

To share a transformed image in a private bucket for a fixed amount of time, provide the transform option when you create the signed URL:

JavaScriptDartSwiftKotlin

`
supabase.storage.from('bucket').createSignedUrl('image.jpg', 60000, {
transform: {
    width: 200,
    height: 200,
},
})
`

The transformation options are embedded into the token attached to the URL  they cannot be changed once signed.

## Downloading images [\#](https://supabase.com/docs/guides/storage/serving/image-transformations\#downloading-images)

To download a transformed image, pass the `transform` option to the `download` function.

JavaScriptDartSwiftKotlinPython

`
supabase.storage.from('bucket').download('image.jpg', {
transform: {
    width: 800,
    height: 300,
},
})
`

## Automatic image optimization (WebP) [\#](https://supabase.com/docs/guides/storage/serving/image-transformations\#automatic-image-optimization-webp)

When using the image transformation API, Storage will automatically find the best format supported by the client and return that to the client, without any code change. For instance, if you use Chrome when viewing a JPEG image and using transformation options, you'll see that images are automatically optimized as `webp` images.

As a result, this will lower the bandwidth that you send to your users and your application will load much faster.

We currently only support WebP. AVIF support will come in the near future.

**Disabling automatic optimization:**

In case you'd like to return the original format of the image and **opt-out** from the automatic image optimization detection, you can pass the `format=origin` parameter when requesting a transformed image, this is also supported in the JavaScript SDK starting from v2.2.0

JavaScriptDartSwiftKotlinPython

`
await supabase.storage.from('bucket').download('image.jpeg', {
transform: {
    width: 200,
    height: 200,
    format: 'origin',
},
})
`

## Next.js loader [\#](https://supabase.com/docs/guides/storage/serving/image-transformations\#nextjs-loader)

You can use Supabase Image Transformation to optimize your Next.js images using a custom [Loader](https://nextjs.org/docs/api-reference/next/image#loader-configuration).

To get started, create a `supabase-image-loader.js` file in your Next.js project which exports a default function:

``
const projectId = '' // your supabase project id
export default function supabaseLoader({ src, width, quality }) {
return `https://${projectId}.supabase.co/storage/v1/render/image/public/${src}?width=${width}&quality=${quality || 75}`
}
``

In your `nextjs.config.js` file add the following configuration to instruct Next.js to use our custom loader

`
module.exports = {
images: {
    loader: 'custom',
    loaderFile: './supabase-image-loader.js',
},
}
`

At this point you are ready to use the `Image` component provided by Next.js

`
import Image from 'next/image'
const MyImage = (props) => {
return <Image src="bucket/image.png" alt="Picture of the author" width={500} height={500} />
}
`

## Transformation options [\#](https://supabase.com/docs/guides/storage/serving/image-transformations\#transformation-options)

We currently support a few transformation options focusing on optimizing, resizing, and cropping images.

### Optimizing [\#](https://supabase.com/docs/guides/storage/serving/image-transformations\#optimizing)

You can set the quality of the returned image by passing a value from 20 to 100 (with 100 being the highest quality) to the `quality` parameter. This parameter defaults to 80.

Example:

JavaScriptDartSwiftKotlinPython

`
supabase.storage.from('bucket').download('image.jpg', {
transform: {
    quality: 50,
},
})
`

### Resizing [\#](https://supabase.com/docs/guides/storage/serving/image-transformations\#resizing)

You can use `width` and `height` parameters to resize an image to a specific dimension. If only one parameter is specified, the image will be resized and cropped, maintaining the aspect ratio.

### Modes [\#](https://supabase.com/docs/guides/storage/serving/image-transformations\#modes)

You can use different resizing modes to fit your needs, each of them uses a different approach to resize the image:

Use the `resize` parameter with one of the following values:

- `cover` : resizes the image while keeping the aspect ratio to fill a given size and crops projecting parts. (default)

- `contain` : resizes the image while keeping the aspect ratio to fit a given size.

- `fill` : resizes the image without keeping the aspect ratio.


Example:

JavaScriptDartSwiftKotlinPython

`
supabase.storage.from('bucket').download('image.jpg', {
transform: {
    width: 800,
    height: 300,
    resize: 'contain', // 'cover' | 'fill'
},
})
`

### Limits [\#](https://supabase.com/docs/guides/storage/serving/image-transformations\#limits)

- Width and height must be an integer value between 1-2500.
- The image size cannot exceed 25MB.
- The image resolution cannot exceed 50MP.

### Supported image formats [\#](https://supabase.com/docs/guides/storage/serving/image-transformations\#supported-image-formats)

| Format | Extension | Source | Result |
| --- | --- | --- | --- |
| PNG | `png` |  |  |
| JPEG | `jpg` |  |  |
| WebP | `webp` |  |  |
| AVIF | `avif` |  |  |
| GIF | `gif` |  |  |
| ICO | `ico` |  |  |
| SVG | `svg` |  |  |
| HEIC | `heic` |  |  |
| BMP | `bmp` |  |  |
| TIFF | `tiff` |  |  |

## Pricing [\#](https://supabase.com/docs/guides/storage/serving/image-transformations\#pricing)

$5 per 1,000 origin images. You are only charged for usage exceeding your subscription plan's quota.

The count resets at the start of each billing cycle.

| Plan | Quota | Over-Usage |
| --- | --- | --- |
| Pro | 100 | $5 per 1,000 origin images |
| Team | 100 | $5 per 1,000 origin images |
| Enterprise | Custom | Custom |

For a detailed breakdown of how charges are calculated, refer to [Manage Storage Image Transformations usage](https://supabase.com/docs/guides/platform/manage-your-usage/storage-image-transformations).

## Self hosting [\#](https://supabase.com/docs/guides/storage/serving/image-transformations\#self-hosting)

Our solution to image resizing and optimization can be self-hosted as with any other Supabase product. Under the hood we use [imgproxy](https://imgproxy.net/)

#### imgproxy configuration: [\#](https://supabase.com/docs/guides/storage/serving/image-transformations\#imgproxy-configuration)

Deploy an imgproxy container with the following configuration:

`
imgproxy:
image: darthsim/imgproxy
environment:
    - IMGPROXY_ENABLE_WEBP_DETECTION=true
    - IMGPROXY_JPEG_PROGRESSIVE=true
`

Note: make sure that this service can only be reachable within an internal network and not exposed to the public internet

#### Storage API configuration: [\#](https://supabase.com/docs/guides/storage/serving/image-transformations\#storage-api-configuration)

Once [imgproxy](https://imgproxy.net/) is deployed we need to configure a couple of environment variables in your self-hosted [`storage-api`](https://github.com/supabase/storage-api) service as follows:

`
ENABLE_IMAGE_TRANSFORMATION=true
IMGPROXY_URL=yourinternalimgproxyurl.internal.com
`

How to resize images on the fly with Supabase - SupabaseTips - YouTube

Supabase

45.5K subscribers

[How to resize images on the fly with Supabase - SupabaseTips](https://www.youtube.com/watch?v=dLqSmxX3r7I)

Supabase

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/ Live



[Watch on YouTube](https://www.youtube.com/watch?v=dLqSmxX3r7I "Watch on YouTube")

Watch video guide

![Video guide preview](https://supabase.com/docs/_next/image?url=https%3A%2F%2Fimg.youtube.com%2Fvi%2FdLqSmxX3r7I%2F0.jpg&w=3840&q=75&dpl=dpl_9xAnUGkSbk4dufV62sNRezafXykJ)

### Is this helpful?

NoYes

### On this page

[Get a public URL for a transformed image](https://supabase.com/docs/guides/storage/serving/image-transformations#get-a-public-url-for-a-transformed-image) [Signing URLs with transformation options](https://supabase.com/docs/guides/storage/serving/image-transformations#signing-urls-with-transformation-options) [Downloading images](https://supabase.com/docs/guides/storage/serving/image-transformations#downloading-images) [Automatic image optimization (WebP)](https://supabase.com/docs/guides/storage/serving/image-transformations#automatic-image-optimization-webp) [Next.js loader](https://supabase.com/docs/guides/storage/serving/image-transformations#nextjs-loader) [Transformation options](https://supabase.com/docs/guides/storage/serving/image-transformations#transformation-options) [Optimizing](https://supabase.com/docs/guides/storage/serving/image-transformations#optimizing) [Resizing](https://supabase.com/docs/guides/storage/serving/image-transformations#resizing) [Modes](https://supabase.com/docs/guides/storage/serving/image-transformations#modes) [Limits](https://supabase.com/docs/guides/storage/serving/image-transformations#limits) [Supported image formats](https://supabase.com/docs/guides/storage/serving/image-transformations#supported-image-formats) [Pricing](https://supabase.com/docs/guides/storage/serving/image-transformations#pricing) [Self hosting](https://supabase.com/docs/guides/storage/serving/image-transformations#self-hosting)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_storage_uploads_file_limits.md">
Storage

# Limits

## Learn how to increase Supabase file limits.

* * *

## Global file size [\#](https://supabase.com/docs/guides/storage/uploads/file-limits\#global-file-size)

You can set the max file size across all your buckets by setting this global value in the dashboard [here](https://supabase.com/dashboard/project/_/settings/storage). For Free projects, the limit can't exceed 50 MB. On the Pro Plan and up, you can set this value to up to 50 GB. If you need more than 50 GB, [contact us](https://supabase.com/dashboard/support/new).

| Plan | Max File Size Limit |
| --- | --- |
| Free | 50 MB |
| Pro | 50 GB |
| Team | 50 GB |
| Enterprise | Custom |

This option is a global limit, which applies to all your buckets.

Additionally, you can specify the max file size on a per [bucket level](https://supabase.com/docs/guides/storage/buckets/creating-buckets#restricting-uploads) but it can't be higher than this global limit. As a good practice, the global limit should be set to the highest possible file size that your application accepts, and apply per bucket limits.

## Per bucket restrictions [\#](https://supabase.com/docs/guides/storage/uploads/file-limits\#per-bucket-restrictions)

You can have different restrictions on a per bucket level such as restricting the file types (e.g. `pdf`, `images`, `videos`) or the max file size, which should be lower than the global limit. To apply these limit on a bucket level see [Creating Buckets](https://supabase.com/docs/guides/storage/buckets/creating-buckets#restricting-uploads).

### Is this helpful?

NoYes

### On this page

[Global file size](https://supabase.com/docs/guides/storage/uploads/file-limits#global-file-size) [Per bucket restrictions](https://supabase.com/docs/guides/storage/uploads/file-limits#per-bucket-restrictions)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_storage_uploads_resumable_uploads.md">
Storage

# Resumable Uploads

## Learn how to upload files to Supabase Storage.

* * *

The resumable upload method is recommended when:

- Uploading large files that may exceed 6MB in size
- Network stability is a concern
- You want to have progress events for your uploads

Supabase Storage implements the [TUS protocol](https://tus.io/) to enable resumable uploads. TUS stands for The Upload Server and is an open protocol for supporting resumable uploads. The protocol allows the upload process to be resumed from where it left off in case of interruptions. This method can be implemented using the [`tus-js-client`](https://github.com/tus/tus-js-client) library, or other client-side libraries like [Uppy](https://uppy.io/docs/tus/) that support the TUS protocol.

JavaScriptReactKotlinPython

Here's an example of how to upload a file using `tus-js-client`:

``
const tus = require('tus-js-client')
const projectId = ''
async function uploadFile(bucketName, fileName, file) {
    const { data: { session } } = await supabase.auth.getSession()
    return new Promise((resolve, reject) => {
        var upload = new tus.Upload(file, {
            endpoint: `https://${projectId}.supabase.co/storage/v1/upload/resumable`,
            retryDelays: [0, 3000, 5000, 10000, 20000],
            headers: {
                authorization: `Bearer ${session.access_token}`,
                'x-upsert': 'true', // optionally set upsert to true to overwrite existing files
            },
            uploadDataDuringCreation: true,
            removeFingerprintOnSuccess: true, // Important if you want to allow re-uploading the same file https://github.com/tus/tus-js-client/blob/main/docs/api.md#removefingerprintonsuccess
            metadata: {
                bucketName: bucketName,
                objectName: fileName,
                contentType: 'image/png',
                cacheControl: 3600,
            },
            chunkSize: 6 * 1024 * 1024, // NOTE: it must be set to 6MB (for now) do not change it
            onError: function (error) {
                console.log('Failed because: ' + error)
                reject(error)
            },
            onProgress: function (bytesUploaded, bytesTotal) {
                var percentage = ((bytesUploaded / bytesTotal) * 100).toFixed(2)
                console.log(bytesUploaded, bytesTotal, percentage + '%')
            },
            onSuccess: function () {
                console.log('Download %s from %s', upload.file.name, upload.url)
                resolve()
            },
        })
        // Check if there are any previous uploads to continue.
        return upload.findPreviousUploads().then(function (previousUploads) {
            // Found previous uploads so we select the first one.
            if (previousUploads.length) {
                upload.resumeFromPreviousUpload(previousUploads[0])
            }
            // Start the upload
            upload.start()
        })
    })
}
``

### Upload URL [\#](https://supabase.com/docs/guides/storage/uploads/resumable-uploads\#upload-url)

When uploading using the resumable upload endpoint, the storage server creates a unique URL for each upload, even for multiple uploads to the same path. All chunks will be uploaded to this URL using the `PATCH` method.

This unique upload URL will be valid for **up to 24 hours**. If the upload is not completed within 24 hours, the URL will expire and you'll need to start the upload again. TUS client libraries typically create a new URL if the previous one expires.

### Concurrency [\#](https://supabase.com/docs/guides/storage/uploads/resumable-uploads\#concurrency)

When two or more clients upload to the same upload URL only one of them will succeed. The other clients will receive a `409 Conflict` error. Only 1 client can upload to the same upload URL at a time which prevents data corruption.

When two or more clients upload a file to the same path using different upload URLs, the first client to complete the upload will succeed and the other clients will receive a `409 Conflict` error.

If you provide the `x-upsert` header the last client to complete the upload will succeed instead.

### Uppy example [\#](https://supabase.com/docs/guides/storage/uploads/resumable-uploads\#uppy-example)

You can check a [full example using Uppy](https://github.com/supabase/supabase/tree/master/examples/storage/resumable-upload-uppy).

Uppy has integrations with different frameworks:

- [React](https://uppy.io/docs/react/)
- [Svelte](https://uppy.io/docs/svelte/)
- [Vue](https://uppy.io/docs/vue/)
- [Angular](https://uppy.io/docs/angular/)

## Overwriting files [\#](https://supabase.com/docs/guides/storage/uploads/resumable-uploads\#overwriting-files)

When uploading a file to a path that already exists, the default behavior is to return a `400 Asset Already Exists` error.
If you want to overwrite a file on a specific path you can set the `x-upsert` header to `true`.

We do advise against overwriting files when possible, as the CDN will take some time to propagate the changes to all the edge nodes leading to stale content.
Uploading a file to a new path is the recommended way to avoid propagation delays and stale content.

To learn more, see the [CDN](https://supabase.com/docs/guides/storage/cdn/fundamentals) guide.

### Is this helpful?

NoYes

### On this page

[Upload URL](https://supabase.com/docs/guides/storage/uploads/resumable-uploads#upload-url) [Concurrency](https://supabase.com/docs/guides/storage/uploads/resumable-uploads#concurrency) [Uppy example](https://supabase.com/docs/guides/storage/uploads/resumable-uploads#uppy-example) [Overwriting files](https://supabase.com/docs/guides/storage/uploads/resumable-uploads#overwriting-files)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_storage_uploads_s3_uploads.md">
Storage

# S3 Uploads

## Learn how to upload files to Supabase Storage using S3.

* * *

You can use the S3 protocol to upload files to Supabase Storage. To get started with S3, see the [S3 setup guide](https://supabase.com/docs/guides/storage/s3/authentication).

The S3 protocol supports file upload using:

- A single request
- Multiple requests via Multipart Upload

## Single request uploads [\#](https://supabase.com/docs/guides/storage/uploads/s3-uploads\#single-request-uploads)

The `PutObject` action uploads the file in a single request. This matches the behavior of the Supabase SDK [Standard Upload](https://supabase.com/docs/guides/storage/uploads/standard-uploads).

Use `PutObject` to upload smaller files, where retrying the entire upload won't be an issue. The maximum file size on paid plans is 50 GB.

For example, using JavaScript and the `aws-sdk` client:

`
import { S3Client, PutObjectCommand } from '@aws-sdk/client-s3'
const s3Client = new S3Client({...})
const file = fs.createReadStream('path/to/file')
const uploadCommand = new PutObjectCommand({
Bucket: 'bucket-name',
Key: 'path/to/file',
Body: file,
ContentType: 'image/jpeg',
})
await s3Client.send(uploadCommand)
`

## Multipart uploads [\#](https://supabase.com/docs/guides/storage/uploads/s3-uploads\#multipart-uploads)

Multipart Uploads split the file into smaller parts and upload them in parallel, maximizing the upload speed on a fast network. When uploading large files, this allows you to retry the upload of individual parts in case of network issues.

This method is preferable over [Resumable Upload](https://supabase.com/docs/guides/storage/uploads/resumable-uploads) for server-side uploads, when you want to maximize upload speed at the cost of resumability. The maximum file size on paid plans is 50 GB.

### Upload a file in parts [\#](https://supabase.com/docs/guides/storage/uploads/s3-uploads\#upload-a-file-in-parts)

Use the `Upload` class from an S3 client to upload a file in parts. For example, using JavaScript:

`
import { S3Client } from '@aws-sdk/client-s3'
import { Upload } from '@aws-sdk/lib-storage'
const s3Client = new S3Client({...})
const file = fs.createReadStream('path/to/very-large-file')
const upload = new Upload(s3Client, {
Bucket: 'bucket-name',
Key: 'path/to/file',
ContentType: 'image/jpeg',
Body: file,
})
await uploader.done()
`

### Aborting multipart uploads [\#](https://supabase.com/docs/guides/storage/uploads/s3-uploads\#aborting-multipart-uploads)

All multipart uploads are automatically aborted after 24 hours. To abort a multipart upload before that, you can use the [`AbortMultipartUpload`](https://docs.aws.amazon.com/AmazonS3/latest/API/API_AbortMultipartUpload.html) action.

### Is this helpful?

NoYes

### On this page

[Single request uploads](https://supabase.com/docs/guides/storage/uploads/s3-uploads#single-request-uploads) [Multipart uploads](https://supabase.com/docs/guides/storage/uploads/s3-uploads#multipart-uploads) [Upload a file in parts](https://supabase.com/docs/guides/storage/uploads/s3-uploads#upload-a-file-in-parts) [Aborting multipart uploads](https://supabase.com/docs/guides/storage/uploads/s3-uploads#aborting-multipart-uploads)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_storage_uploads_standard_uploads.md">
Storage

# Standard Uploads

## Learn how to upload files to Supabase Storage.

* * *

## Uploading [\#](https://supabase.com/docs/guides/storage/uploads/standard-uploads\#uploading)

The standard file upload method is ideal for small files that are not larger than 6MB.

It uses the traditional `multipart/form-data` format and is simple to implement using the supabase-js SDK. Here's an example of how to upload a file using the standard upload method:

Though you can upload up to 5GB files using the standard upload method, we recommend using [TUS Resumable Upload](https://supabase.com/docs/guides/storage/uploads/resumable-uploads) for uploading files greater than 6MB in size for better reliability.

JavaScriptDartSwiftKotlinPython

`
import { createClient } from '@supabase/supabase-js'
// Create Supabase client
const supabase = createClient('your_project_url', 'your_supabase_api_key')
// Upload file using standard upload
async function uploadFile(file) {
const { data, error } = await supabase.storage.from('bucket_name').upload('file_path', file)
if (error) {
    // Handle error
} else {
    // Handle success
}
}
`

## Overwriting files [\#](https://supabase.com/docs/guides/storage/uploads/standard-uploads\#overwriting-files)

When uploading a file to a path that already exists, the default behavior is to return a `400 Asset Already Exists` error.
If you want to overwrite a file on a specific path you can set the `upsert` options to `true` or using the `x-upsert` header.

JavaScriptDartSwiftKotlinPython

`
// Create Supabase client
const supabase = createClient('your_project_url', 'your_supabase_api_key')
await supabase.storage.from('bucket_name').upload('file_path', file, {
upsert: true,
})
`

We do advise against overwriting files when possible, as our Content Delivery Network will take sometime to propagate the changes to all the edge nodes leading to stale content.
Uploading a file to a new path is the recommended way to avoid propagation delays and stale content.

## Content type [\#](https://supabase.com/docs/guides/storage/uploads/standard-uploads\#content-type)

By default, Storage will assume the content type of an asset from the file extension. If you want to specify the content type for your asset, pass the `contentType` option during upload.

JavaScriptDartSwiftKotlinPython

`
// Create Supabase client
const supabase = createClient('your_project_url', 'your_supabase_api_key')
await supabase.storage.from('bucket_name').upload('file_path', file, {
contentType: 'image/jpeg',
})
`

## Concurrency [\#](https://supabase.com/docs/guides/storage/uploads/standard-uploads\#concurrency)

When two or more clients upload a file to the same path, the first client to complete the upload will succeed and the other clients will receive a `400 Asset Already Exists` error.
If you provide the `x-upsert` header the last client to complete the upload will succeed instead.

### Is this helpful?

NoYes

### On this page

[Uploading](https://supabase.com/docs/guides/storage/uploads/standard-uploads#uploading) [Overwriting files](https://supabase.com/docs/guides/storage/uploads/standard-uploads#overwriting-files) [Content type](https://supabase.com/docs/guides/storage/uploads/standard-uploads#content-type) [Concurrency](https://supabase.com/docs/guides/storage/uploads/standard-uploads#concurrency)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_storage.md">
Storage

# Storage

## Use Supabase to store and serve files.

* * *

Supabase Storage makes it simple to upload and serve files of any size, providing a robust framework for file access controls.

## Features [\#](https://supabase.com/docs/guides/storage\#features)

You can use Supabase Storage to store images, videos, documents, and any other file type. Serve your assets with a global CDN to reduce latency from over 285 cities globally. Supabase Storage includes a built-in image optimizer, so you can resize and compress your media files on the fly.

## Examples [\#](https://supabase.com/docs/guides/storage\#examples)

Check out all of the Storage [templates and examples](https://github.com/supabase/supabase/tree/master/examples/storage) in our GitHub repository.

[![Resumable Uploads with Uppy](https://supabase.com/docs/img/icons/github-icon-light.svg)\\
\\
Resumable Uploads with Uppy\\
\\
Use Uppy to upload files to Supabase Storage using the TUS protocol (resumable uploads).](https://github.com/supabase/supabase/tree/master/examples/storage/resumable-upload-uppy)

## Resources [\#](https://supabase.com/docs/guides/storage\#resources)

Find the source code and documentation in the Supabase GitHub repository.

[Supabase Storage API\\
\\
View the source code.](https://github.com/supabase/storage-api)

[OpenAPI Spec\\
\\
See the Swagger Documentation for Supabase Storage.](https://supabase.github.io/storage/)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_telemetry_advanced_log_filtering.md">
Telemetry

# Advanced Log Filtering

* * *

# Querying the logs

## Understanding field references [\#](https://supabase.com/docs/guides/telemetry/advanced-log-filtering\#understanding-field-references)

The log tables are queried with a subset of BigQuery SQL syntax. They all have three columns: `event_message`, `timestamp`, and `metadata`.

| column | description |
| --- | --- |
| timestamp | time event was recorded |
| event\_message | the log's message |
| metadata | information about the event |

The `metadata` column is an array of JSON objects that stores important details about each recorded event. For example, in the Postgres table, the `metadata.parsed.error_severity` field indicates the error level of an event. To work with its values, you need to `unnest` them using a `cross join`.

This approach is commonly used with JSON and array columns, so it might look a bit unfamiliar if you're not used to working with these data types.

`
select
event_message,
parsed.error_severity,
parsed.user_name
from
postgres_logs
  -- extract first layer
cross join unnest(postgres_logs.metadata) as metadata
  -- extract second layer
cross join unnest(metadata.parsed) as parsed;
`

## Expanding results [\#](https://supabase.com/docs/guides/telemetry/advanced-log-filtering\#expanding-results)

Logs returned by queries may be difficult to read in table format. A row can be double-clicked to expand the results into more readable JSON:

![Expanding log results](https://supabase.com/docs/img/guides/platform/expanded-log-results.png)

## Filtering with [regular expressions](https://en.wikipedia.org/wiki/Regular_expression) [\#](https://supabase.com/docs/guides/telemetry/advanced-log-filtering\#filtering-with-regular-expressions)

The Logs use BigQuery Style regular expressions with the [regexp\_contains function](https://cloud.google.com/bigquery/docs/reference/standard-sql/string_functions#regexp_contains). In its most basic form, it will check if a string is present in a specified column.

`
select
cast(timestamp as datetime) as timestamp,
event_message,
metadata
from postgres_logs
where regexp_contains(event_message, 'is present');
`

There are multiple operators that you should consider using:

### Find messages that start with a phrase [\#](https://supabase.com/docs/guides/telemetry/advanced-log-filtering\#find-messages-that-start-with-a-phrase)

`^` only looks for values at the start of a string

`
-- find only messages that start with connection
regexp_contains(event_message, '^connection')
`

### Find messages that end with a phrase: [\#](https://supabase.com/docs/guides/telemetry/advanced-log-filtering\#find-messages-that-end-with-a-phrase)

`$` only looks for values at the end of the string

`
-- find only messages that ends with port=12345
regexp_contains(event_message, '$port=12345')
`

### Ignore case sensitivity: [\#](https://supabase.com/docs/guides/telemetry/advanced-log-filtering\#ignore-case-sensitivity)

`(?i)` ignores capitalization for all proceeding characters

`
-- find all event_messages with the word "connection"
regexp_contains(event_message, '(?i)COnnecTion')
`

### Wildcards: [\#](https://supabase.com/docs/guides/telemetry/advanced-log-filtering\#wildcards)

`.` can represent any string of characters

`
-- find event_messages like "hello<anything>world"
regexp_contains(event_message, 'hello.world')
`

### Alphanumeric ranges: [\#](https://supabase.com/docs/guides/telemetry/advanced-log-filtering\#alphanumeric-ranges)

`[1-9a-zA-Z]` finds any strings with only numbers and letters

`
-- find event_messages that contain a number between 1 and 5 (inclusive)
regexp_contains(event_message, '[1-5]')
`

### Repeated values: [\#](https://supabase.com/docs/guides/telemetry/advanced-log-filtering\#repeated-values)

`x*` zero or more x
`x+` one or more x
`x?` zero or one x
`x{4,}` four or more x
`x{3}` exactly 3 x

`
-- find event_messages that contains any sequence of 3 digits
regexp_contains(event_message, '[0-9]{3}')
`

### Escaping reserved characters: [\#](https://supabase.com/docs/guides/telemetry/advanced-log-filtering\#escaping-reserved-characters)

`\.` interpreted as period `.` instead of as a wildcard

`
-- escapes .
regexp_contains(event_message, 'hello world\.')
`

### `or` statements: [\#](https://supabase.com/docs/guides/telemetry/advanced-log-filtering\#or-statements)

`x|y` any string with `x` or `y` present

`
-- find event_messages that have the word 'started' followed by either the word "host" or "authenticated"
regexp_contains(event_message, 'started host|authenticated')
`

### `and`/ `or`/ `not` statements in SQL: [\#](https://supabase.com/docs/guides/telemetry/advanced-log-filtering\#and--or--not-statements-in-sql)

`and`, `or`, and `not` are all native terms in SQL and can be used in conjunction with regular expressions to filter results

`
select
cast(timestamp as datetime) as timestamp,
event_message,
metadata
from postgres_logs
where
(regexp_contains(event_message, 'connection') and regexp_contains(event_message, 'host'))
or not regexp_contains(event_message, 'received');
`

### Filtering and unnesting example [\#](https://supabase.com/docs/guides/telemetry/advanced-log-filtering\#filtering-and-unnesting-example)

**Filter for Postgres**

`
select
cast(postgres_logs.timestamp as datetime) as timestamp,
parsed.error_severity,
parsed.user_name,
event_message
from
postgres_logs
cross join unnest(metadata) as metadata
cross join unnest(metadata.parsed) as parsed
where regexp_contains(parsed.error_severity, 'ERROR|FATAL|PANIC')
order by timestamp desc
limit 100;
`

## Limitations [\#](https://supabase.com/docs/guides/telemetry/advanced-log-filtering\#limitations)

### Log tables cannot be joined together [\#](https://supabase.com/docs/guides/telemetry/advanced-log-filtering\#log-tables-cannot-be-joined-together)

Each product table operates independently without the ability to join with other log tables. This may change in the future.

### The `with` keyword and subqueries are not supported [\#](https://supabase.com/docs/guides/telemetry/advanced-log-filtering\#the-with-keyword-and-subqueries-are-not-supported)

The parser does not yet support `with` and subquery statements.

### The `ilike` and `similar to` keywords are not supported [\#](https://supabase.com/docs/guides/telemetry/advanced-log-filtering\#the-ilike-and-similar-to-keywords-are-not-supported)

Although `like` and other comparison operators can be used, `ilike` and `similar to` are incompatible with BigQuery's variant of SQL. `regexp_contains` can be used as an alternative.

### The wildcard operator `*` to select columns is not supported [\#](https://supabase.com/docs/guides/telemetry/advanced-log-filtering\#the-wildcard-operator--to-select-columns-is-not-supported)

The log parser is not able to parse the `*` operator for column selection. Instead, you can access all fields from the `metadata` column:

`
select
cast(postgres_logs.timestamp as datetime) as timestamp,
event_message,
metadata
from
<log_table_name>
order by timestamp desc
limit 100;
`

### Is this helpful?

NoYes

### On this page

[Understanding field references](https://supabase.com/docs/guides/telemetry/advanced-log-filtering#understanding-field-references) [Expanding results](https://supabase.com/docs/guides/telemetry/advanced-log-filtering#expanding-results) [Filtering with regular expressions](https://supabase.com/docs/guides/telemetry/advanced-log-filtering#https://en.wikipedia.org/wiki/Regular_expression) [Find messages that start with a phrase](https://supabase.com/docs/guides/telemetry/advanced-log-filtering#find-messages-that-start-with-a-phrase) [Find messages that end with a phrase:](https://supabase.com/docs/guides/telemetry/advanced-log-filtering#find-messages-that-end-with-a-phrase) [Ignore case sensitivity:](https://supabase.com/docs/guides/telemetry/advanced-log-filtering#ignore-case-sensitivity) [Wildcards:](https://supabase.com/docs/guides/telemetry/advanced-log-filtering#wildcards) [Alphanumeric ranges:](https://supabase.com/docs/guides/telemetry/advanced-log-filtering#alphanumeric-ranges) [Repeated values:](https://supabase.com/docs/guides/telemetry/advanced-log-filtering#repeated-values) [Escaping reserved characters:](https://supabase.com/docs/guides/telemetry/advanced-log-filtering#escaping-reserved-characters) [or statements:](https://supabase.com/docs/guides/telemetry/advanced-log-filtering#or-statements) [and/or/not statements in SQL:](https://supabase.com/docs/guides/telemetry/advanced-log-filtering#and--or--not-statements-in-sql) [Filtering and unnesting example](https://supabase.com/docs/guides/telemetry/advanced-log-filtering#filtering-and-unnesting-example) [Limitations](https://supabase.com/docs/guides/telemetry/advanced-log-filtering#limitations) [Log tables cannot be joined together](https://supabase.com/docs/guides/telemetry/advanced-log-filtering#log-tables-cannot-be-joined-together) [The with keyword and subqueries are not supported](https://supabase.com/docs/guides/telemetry/advanced-log-filtering#the-with-keyword-and-subqueries-are-not-supported) [The ilike and similar to keywords are not supported](https://supabase.com/docs/guides/telemetry/advanced-log-filtering#the-ilike-and-similar-to-keywords-are-not-supported) [The wildcard operator \* to select columns is not supported](https://supabase.com/docs/guides/telemetry/advanced-log-filtering#the-wildcard-operator--to-select-columns-is-not-supported)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_telemetry_log_drains.md">
Telemetry

# Log Drains

* * *

Log drains will send all logs of the Supabase stack to one or more desired destinations. It is only available for customers on Team and Enterprise Plans. Log drains is available in the dashboard under [Project Settings > Log Drains](https://supabase.com/dashboard/project/_/settings/log-drains).

You can read about the initial announcement [here](https://supabase.com/blog/log-drains) and vote for your preferred drains in [this discussion](https://github.com/orgs/supabase/discussions/28324?sort=top).

# Supported destinations

The following table lists the supported destinations and the required setup configuration:

| Destination | Transport Method | Configuration |
| --- | --- | --- |
| Generic HTTP endpoint | HTTP | URL <br> HTTP Version <br> Gzip <br> Headers |
| DataDog | HTTP | API Key <br> Region |

HTTP requests are batched with a max of 250 logs or 1 second intervals, whichever happens first. Logs are compressed via Gzip if the destination supports it.

## Generic HTTP endpoint [\#](https://supabase.com/docs/guides/telemetry/log-drains\#generic-http-endpoint)

Logs are sent as a POST request with a JSON body. Both HTTP/1 and HTTP/2 protocols are supported.
Custom headers can optionally be configured for all requests.

Note that requests are **unsigned**.

Unsigned requests to HTTP endpoints are temporary and all requests will signed in the near future.

Edge Function Walkthrough (Uncompressed)

Edge Function Gzip Example

## DataDog logs [\#](https://supabase.com/docs/guides/telemetry/log-drains\#datadog-logs)

Logs sent to DataDog have the name of the log source set on the `service` field of the event and the source set to `Supabase`. Logs are gzipped before they are sent to DataDog.

The payload message is a JSON string of the raw log event, prefixed with the event timestamp.

To setup DataDog log drain, generate a DataDog API key [here](https://app.datadoghq.com/organization-settings/api-keys) and the location of your DataDog site.

Walkthrough

Example destination configuration

If you are interested in other log drains, upvote them [here](https://github.com/orgs/supabase/discussions/28324)

## Pricing [\#](https://supabase.com/docs/guides/telemetry/log-drains\#pricing)

For a detailed breakdown of how charges are calculated, refer to [Manage Log Drain usage](https://supabase.com/docs/guides/platform/manage-your-usage/log-drains).

### Is this helpful?

NoYes

### On this page

[Generic HTTP endpoint](https://supabase.com/docs/guides/telemetry/log-drains#generic-http-endpoint) [DataDog logs](https://supabase.com/docs/guides/telemetry/log-drains#datadog-logs) [Pricing](https://supabase.com/docs/guides/telemetry/log-drains#pricing)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_telemetry_logs.md">
Telemetry

# Logging

* * *

The Supabase Platform includes a Logs Explorer that allows log tracing and debugging. Log retention is based on your [project's pricing plan](https://supabase.com/pricing).

## Product logs [\#](https://supabase.com/docs/guides/telemetry/logs\#product-logs)

Supabase provides a logging interface specific to each product. You can use simple regular expressions for keywords and patterns to search log event messages. You can also export and download the log events matching your query as a spreadsheet.

APIPostgresAuthStorageRealtimeEdge Functions

[API logs](https://supabase.com/dashboard/project/_/logs/edge-logs) show all network requests and response for the REST and GraphQL [APIs](https://supabase.com/docs/guides/database/api). If [Read Replicas](https://supabase.com/docs/guides/platform/read-replicas) are enabled, logs are automatically filtered between databases as well as the [API Load Balancer](https://supabase.com/docs/guides/platform/read-replicas#api-load-balancer) endpoint. Logs for a specific endpoint can be toggled with the `Source` button on the upper-right section of the dashboard.

When viewing logs originating from the API Load Balancer endpoint, the upstream database or the one that eventually handles the request can be found under the `Redirect Identifier` field. This is equivalent to `metadata.load_balancer_redirect_identifier` when querying the underlying logs.

![API Logs](https://supabase.com/docs/img/guides/platform/logs/logs-api.png)

* * *

## Working with API logs [\#](https://supabase.com/docs/guides/telemetry/logs\#working-with-api-logs)

[API logs](https://supabase.com/dashboard/project/_/logs/edge-logs) run through the Cloudflare edge servers and will have attached Cloudflare metadata under the `metadata.request.cf.*` fields.

### Allowed headers [\#](https://supabase.com/docs/guides/telemetry/logs\#allowed-headers)

A strict list of request and response headers are permitted in the API logs. Request and response headers will still be received by the server(s) and client(s), but will not be attached to the API logs generated.

Request headers:

- `accept`
- `cf-connecting-ip`
- `cf-ipcountry`
- `host`
- `user-agent`
- `x-forwarded-proto`
- `referer`
- `content-length`
- `x-real-ip`
- `x-client-info`
- `x-forwarded-user-agent`
- `range`
- `prefer`

Response headers:

- `cf-cache-status`
- `cf-ray`
- `content-location`
- `content-range`
- `content-type`
- `content-length`
- `date`
- `transfer-encoding`
- `x-kong-proxy-latency`
- `x-kong-upstream-latency`
- `sb-gateway-mode`
- `sb-gateway-version`

### Additional request metadata [\#](https://supabase.com/docs/guides/telemetry/logs\#additional-request-metadata)

To attach additional metadata to a request, it is recommended to use the `User-Agent` header for purposes such as device or version identification.

For example:

`
node MyApp/1.2.3 (device-id:abc123)
Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:47.0) Gecko/20100101 Firefox/47.0 MyApp/1.2.3 (Foo v1.3.2; Bar v2.2.2)
`

Do not log Personal Identifiable Information (PII) within the `User-Agent` header, to avoid infringing data protection privacy laws. Overly fine-grained and detailed user agents may allow fingerprinting and identification of the end user through PII.

## Logging Postgres queries [\#](https://supabase.com/docs/guides/telemetry/logs\#logging-postgres-queries)

To enable query logs for other categories of statements:

1. [Enable the pgAudit extension](https://supabase.com/dashboard/project/_/database/extensions).
2. Configure `pgaudit.log` (see below). Perform a fast reboot if needed.
3. View your query logs under [Logs > Postgres Logs](https://supabase.com/dashboard/project/_/logs/postgres-logs).

### Configuring `pgaudit.log` [\#](https://supabase.com/docs/guides/telemetry/logs\#configuring-pgauditlog)

The stored value under `pgaudit.log` determines the classes of statements that are logged by [pgAudit extension](https://www.pgaudit.org/). Refer to the pgAudit documentation for the [full list of values](https://github.com/pgaudit/pgaudit/blob/master/README.md#pgauditlog).

To enable logging for function calls/do blocks, writes, and DDL statements for a single session, execute the following within the session:

`
-- temporary single-session config update
set pgaudit.log = 'function, write, ddl';
`

To _permanently_ set a logging configuration (beyond a single session), execute the following, then perform a fast reboot:

`
-- equivalent permanent config update.
alter role postgres set pgaudit.log to 'function, write, ddl';
`

To help with debugging, we recommend adjusting the log scope to only relevant statements as having too wide of a scope would result in a lot of noise in your Postgres logs.

Note that in the above example, the role is set to `postgres`. To log user-traffic flowing through the [HTTP APIs](https://supabase.com/docs/guides/database/api#rest-api-overview) powered by PostgREST, set your configuration values for the `authenticator`.

`
-- for API-related logs
alter role authenticator set pgaudit.log to 'write';
`

By default, the log level will be set to `log`. To view other levels, run the following:

`
-- adjust log level
alter role postgres set pgaudit.log_level to 'info';
alter role postgres set pgaudit.log_level to 'debug5';
`

Note that as per the pgAudit [log\_level documentation](https://github.com/pgaudit/pgaudit/blob/master/README.md#pgauditlog_level), `error`, `fatal`, and `panic` are not allowed.

To reset system-wide settings, execute the following, then perform a fast reboot:

`
-- resets stored config.
alter role postgres reset pgaudit.log
`

If any permission errors are encountered when executing `alter role postgres ...`, it is likely that your project has yet to receive the patch to the latest version of [supautils](https://github.com/supabase/supautils), which is currently being rolled out.

## Logging realtime connections [\#](https://supabase.com/docs/guides/telemetry/logs\#logging-realtime-connections)

Realtime doesn't log new WebSocket connections or Channel joins by default. Enable connection logging per client by including an `info` `log_level` parameter when instantiating the Supabase client.

`
import { createClient } from '@supabase/supabase-js'
const options = {
realtime: {
    params: {
      log_level: 'info',
    },
},
}
const supabase = createClient('https://xyzcompany.supabase.co', 'public-anon-key', options)
`

## Logs Explorer [\#](https://supabase.com/docs/guides/telemetry/logs\#logs-explorer)

The [Logs Explorer](https://supabase.com/dashboard/project/_/logs-explorer) exposes logs from each part of the Supabase stack as a separate table that can be queried and joined using SQL.

![Logs Explorer](https://supabase.com/docs/img/guides/platform/logs/logs-explorer.png)

You can access the following logs from the **Sources** drop-down:

- `auth_logs`: GoTrue server logs, containing authentication/authorization activity.
- `edge_logs`: Edge network logs, containing request and response metadata retrieved from Cloudflare.
- `function_edge_logs`: Edge network logs for only edge functions, containing network requests and response metadata for each execution.
- `function_logs`: Function internal logs, containing any `console` logging from within the edge function.
- `postgres_logs`: Postgres database logs, containing statements executed by connected applications.
- `realtime_logs`: Realtime server logs, containing client connection information.
- `storage_logs`: Storage server logs, containing object upload and retrieval information.

## Querying with the Logs Explorer [\#](https://supabase.com/docs/guides/telemetry/logs\#querying-with-the-logs-explorer)

The Logs Explorer uses BigQuery and supports all [available SQL functions and operators](https://cloud.google.com/bigquery/docs/reference/standard-sql/functions-and-operators).

### Timestamp display and behavior [\#](https://supabase.com/docs/guides/telemetry/logs\#timestamp-display-and-behavior)

Each log entry is stored with a `timestamp` as a `TIMESTAMP` data type. Use the appropriate [timestamp function](https://cloud.google.com/bigquery/docs/reference/standard-sql/timestamp_functions#timestamp) to utilize the `timestamp` field in a query.

Raw top-level timestamp values are rendered as unix microsecond. To render the timestamps in a human-readable format, use the `DATETIME()` function to convert the unix timestamp display into an ISO-8601 timestamp.

`
-- timestamp column without datetime()
select timestamp from ....
--  1664270180000
-- timestamp column with datetime()
select datetime(timestamp) from ....
-- 2022-09-27T09:17:10.439Z
`

### Unnesting arrays [\#](https://supabase.com/docs/guides/telemetry/logs\#unnesting-arrays)

Each log event stores metadata an array of objects with multiple levels, and can be seen by selecting single log events in the Logs Explorer. To query arrays, use `unnest()` on each array field and add it to the query as a join. This allows you to reference the nested objects with an alias and select their individual fields.

For example, to query the edge logs without any joins:

`
select timestamp, metadata from edge_logs as t;
`

The resulting `metadata` key is rendered as an array of objects in the Logs Explorer. In the following diagram, each box represents a nested array of objects:

![Without Unnesting](https://supabase.com/docs/img/unnesting-none.png)

Perform a `cross join unnest()` to work with the keys nested in the `metadata` key.

To query for a nested value, add a join for each array level:

`
select timestamp, request.method, header.cf_ipcountry
from
edge_logs as t
cross join unnest(t.metadata) as metadata
cross join unnest(metadata.request) as request
cross join unnest(request.headers) as header;
`

This surfaces the following columns available for selection:
![With Two Level Unnesting](https://supabase.com/docs/img/unnesting-2.png)

This allows you to select the `method` and `cf_ipcountry` columns. In JS dot notation, the full paths for each selected column are:

- `metadata[].request[].method`
- `metadata[].request[].headers[].cf_ipcountry`

### LIMIT and result row limitations [\#](https://supabase.com/docs/guides/telemetry/logs\#limit-and-result-row-limitations)

The Logs Explorer has a maximum of 1000 rows per run. Use `LIMIT` to optimize your queries by reducing the number of rows returned further.

### Best practices [\#](https://supabase.com/docs/guides/telemetry/logs\#best-practices)

1. Include a filter over **timestamp**

Querying your entire log history might seem appealing. For **Enterprise** customers that have a large retention range, you run the risk of timeouts due additional time required to scan the larger dataset.

2. Avoid selecting large nested objects. Select individual values instead.

When querying large objects, the columnar storage engine selects each column associated with each nested key, resulting in a large number of columns being selected. This inadvertently impacts the query speed and may result in timeouts or memory errors, especially for projects with a lot of logs.

Instead, select only the values required.

`
--  Avoid doing this
select
datetime(timestamp),
m as metadata -- <- metadata contains many nested keys
from
edge_logs as t
cross join unnest(t.metadata) as m;
--  Do this
select
datetime(timestamp),
r.method -- <- select only the required values
from
edge_logs as t
cross join unnest(t.metadata) as m
cross join unnest(m.request) as r;
`

### Examples and templates [\#](https://supabase.com/docs/guides/telemetry/logs\#examples-and-templates)

The Logs Explorer includes **Templates** (available in the Templates tab or the dropdown in the Query tab) to help you get started.

For example, you can enter the following query in the SQL Editor to retrieve each user's IP address:

`
select datetime(timestamp), h.x_real_ip
from
edge_logs
cross join unnest(metadata) as m
cross join unnest(m.request) as r
cross join unnest(r.headers) as h
where h.x_real_ip is not null and r.method = "GET";
`

### Logs field reference [\#](https://supabase.com/docs/guides/telemetry/logs\#logs-field-reference)

Refer to the full field reference for each available source below. Do note that in order to access each nested key, you would need to perform the [necessary unnesting joins](https://supabase.com/docs/guides/telemetry/logs#unnesting-arrays)

API EdgeAuthStorageFunction EdgeFunction RuntimePostgresRealtimePostgRESTSupavisor

| Path | Type |
| --- | --- |
| id | string |
| timestamp | datetime |
| event\_message | string |
| identifier | string |
| metadata.load\_balancer\_redirect\_identifier | string |
| metadata.request.cf.asOrganization | string |
| metadata.request.cf.asn | number |
| metadata.request.cf.botManagement.corporateProxy | boolean |
| metadata.request.cf.botManagement.detectionIds | number\[\] |
| metadata.request.cf.botManagement.ja3Hash | string |
| metadata.request.cf.botManagement.score | number |
| metadata.request.cf.botManagement.staticResource | boolean |
| metadata.request.cf.botManagement.verifiedBot | boolean |
| metadata.request.cf.city | string |
| metadata.request.cf.clientTcpRtt | number |
| metadata.request.cf.clientTrustScore | number |
| metadata.request.cf.colo | string |
| metadata.request.cf.continent | string |
| metadata.request.cf.country | string |
| metadata.request.cf.edgeRequestKeepAliveStatus | number |
| metadata.request.cf.httpProtocol | string |
| metadata.request.cf.latitude | string |
| metadata.request.cf.longitude | string |
| metadata.request.cf.metroCode | string |
| metadata.request.cf.postalCode | string |
| metadata.request.cf.region | string |
| metadata.request.cf.timezone | string |
| metadata.request.cf.tlsCipher | string |
| metadata.request.cf.tlsClientAuth.certPresented | string |
| metadata.request.cf.tlsClientAuth.certRevoked | string |
| metadata.request.cf.tlsClientAuth.certVerified | string |
| metadata.request.cf.tlsExportedAuthenticator.clientFinished | string |
| metadata.request.cf.tlsExportedAuthenticator.clientHandshake | string |
| metadata.request.cf.tlsExportedAuthenticator.serverFinished | string |
| metadata.request.cf.tlsExportedAuthenticator.serverHandshake | string |
| metadata.request.cf.tlsVersion | string |
| metadata.request.headers.cf\_connecting\_ip | string |
| metadata.request.headers.cf\_ipcountry | string |
| metadata.request.headers.cf\_ray | string |
| metadata.request.headers.host | string |
| metadata.request.headers.referer | string |
| metadata.request.headers.x\_client\_info | string |
| metadata.request.headers.x\_forwarded\_proto | string |
| metadata.request.headers.x\_real\_ip | string |
| metadata.request.host | string |
| metadata.request.method | string |
| metadata.request.path | string |
| metadata.request.protocol | string |
| metadata.request.search | string |
| metadata.request.url | string |
| metadata.response.headers.cf\_cache\_status | string |
| metadata.response.headers.cf\_ray | string |
| metadata.response.headers.content\_location | string |
| metadata.response.headers.content\_range | string |
| metadata.response.headers.content\_type | string |
| metadata.response.headers.date | string |
| metadata.response.headers.sb\_gateway\_version | string |
| metadata.response.headers.transfer\_encoding | string |
| metadata.response.headers.x\_kong\_proxy\_latency | string |
| metadata.response.origin\_time | number |
| metadata.response.status\_code | number |

### Is this helpful?

NoYes

### On this page

[Product logs](https://supabase.com/docs/guides/telemetry/logs#product-logs) [Working with API logs](https://supabase.com/docs/guides/telemetry/logs#working-with-api-logs) [Allowed headers](https://supabase.com/docs/guides/telemetry/logs#allowed-headers) [Additional request metadata](https://supabase.com/docs/guides/telemetry/logs#additional-request-metadata) [Logging Postgres queries](https://supabase.com/docs/guides/telemetry/logs#logging-postgres-queries) [Configuring pgaudit.log](https://supabase.com/docs/guides/telemetry/logs#configuring-pgauditlog) [Logging realtime connections](https://supabase.com/docs/guides/telemetry/logs#logging-realtime-connections) [Logs Explorer](https://supabase.com/docs/guides/telemetry/logs#logs-explorer) [Querying with the Logs Explorer](https://supabase.com/docs/guides/telemetry/logs#querying-with-the-logs-explorer) [Timestamp display and behavior](https://supabase.com/docs/guides/telemetry/logs#timestamp-display-and-behavior) [Unnesting arrays](https://supabase.com/docs/guides/telemetry/logs#unnesting-arrays) [LIMIT and result row limitations](https://supabase.com/docs/guides/telemetry/logs#limit-and-result-row-limitations) [Best practices](https://supabase.com/docs/guides/telemetry/logs#best-practices) [Examples and templates](https://supabase.com/docs/guides/telemetry/logs#examples-and-templates) [Logs field reference](https://supabase.com/docs/guides/telemetry/logs#logs-field-reference)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_telemetry_metrics.md">
Telemetry

# Metrics

* * *

In addition to the reports and charts built in to the Supabase dashboard, each project hosted on the Supabase platform comes with a [Prometheus](https://prometheus.io/)-compatible metrics endpoint, updated every minute, which can be used to gather insight into the health and status of your project.

You can use this endpoint to ingest data into your own monitoring and alerting infrastructure, as long as it is capable of scraping Prometheus-compatible endpoints, in order to set up custom rules beyond those supported by the Supabase dashboard.

The endpoint discussed in this article is in beta, and the metrics returned by it might evolve or be changed in the future to increase its utility.

The endpoint discussed in this article is not available on self-hosted.

## Accessing the metrics endpoint [\#](https://supabase.com/docs/guides/telemetry/metrics\#accessing-the-metrics-endpoint)

Your project's metrics endpoint is accessible at `https://<project-ref>.supabase.co/customer/v1/privileged/metrics`. Access to the endpoint is secured via HTTP Basic Auth; the username is `service_role`, while the password is the service role JWT available through the Supabase dashboard.

`
> curl https://<project-ref>.supabase.co/customer/v1/privileged/metrics --user 'service_role:<service-role-jwt>'
`

## Supabase Grafana [\#](https://supabase.com/docs/guides/telemetry/metrics\#supabase-grafana)

The pre-configured Supabase Grafana Dashboard is an advanced version of the [Dashboard's Database Reports](https://supabase.com/dashboard/project/_/reports/database). It visualizes over 200 database performance and health metrics.

![Supabase Grafana](https://supabase.com/docs/img/guides/platform/supabase-grafana-prometheus.png)

Instructions are included in the README for deploying the repository using docker.

## Using the metrics endpoint in production [\#](https://supabase.com/docs/guides/telemetry/metrics\#using-the-metrics-endpoint-in-production)

To set up monitoring for your project, you will need two things:

1. A datastore - a place to store the metrics coming from your Supabase project over time
2. A dashboard - a place to visualize the state of your Supabase project for a defined period

### Setting up a metrics datastore [\#](https://supabase.com/docs/guides/telemetry/metrics\#setting-up-a-metrics-datastore)

One of the more well-known options is [Prometheus](https://prometheus.io/docs/introduction/overview/) and it is the tool used in this guide.

You can [self-host](https://prometheus.io/docs/prometheus/latest/installation/) Prometheus or choose a managed service to store your metrics. Some of the providers offering managed Prometheus are:

- [Digital Ocean](https://marketplace.digitalocean.com/apps/prometheus)
- [AWS](https://aws.amazon.com/prometheus/)
- [Grafana Cloud](https://grafana.com/products/cloud/metrics/)

Follow the guides for the deployment option you choose

#### Adding a scrape job to Prometheus [\#](https://supabase.com/docs/guides/telemetry/metrics\#adding-a-scrape-job-to-prometheus)

For Prometheus, modify your `prometheus.yaml` file to add a Supabase job, and set the `metrics_path`, `scheme`, `basic_auth` and `targets` parameters. For example:

`
scrape_configs:
  - job_name: "MySupabaseJob"
    metrics_path: "/customer/v1/privileged/metrics"
    scheme: https
    basic_auth:
      username: "service_role"
      password: "<your service_role JWT>"
    static_configs:
      - targets: [\
        "<your Supabase Project ID>.supabase.co:443"\
          ]
        labels:
          group: "MyGroupLabel"
`

### Setting up a dashboard [\#](https://supabase.com/docs/guides/telemetry/metrics\#setting-up-a-dashboard)

For this guide, we will be using [Grafana](https://grafana.com/docs/grafana/latest/introduction/).

You can [self-host](https://grafana.com/docs/grafana/latest/setup-grafana/installation/) Grafana or many providers offer managed Grafana, some of which are listed below:

- [DigitalOcean](https://marketplace.digitalocean.com/apps/grafana)
- [AWS](https://aws.amazon.com/grafana/)
- [Grafana Cloud](https://grafana.com/grafana/)

Follow the guides of the provider you choose to get Grafana up and running.

### Adding a data source to Grafana [\#](https://supabase.com/docs/guides/telemetry/metrics\#adding-a-data-source-to-grafana)

In the left-hand menu, select `Data sources` and click `Add new data source`.

Select `Prometheus` and enter the connection details for the Prometheus instance you have set up.

Under **Interval behavior**, set the **scraping interval** to 60s and test the data source. Once it has passed, save it.

### Adding the Supabase dashboard [\#](https://supabase.com/docs/guides/telemetry/metrics\#adding-the-supabase-dashboard)

In the left-hand menu, select `Dashboards` and click `New`. From the drop-down, select `Import`.

Copy the raw file from our [supabase-grafana](https://raw.githubusercontent.com/supabase/supabase-grafana/refs/heads/main/grafana/dashboard.json) repository and paste it (or upload the file).

Click `Load` and the dashboard will load from the project specified in your Prometheus job.

### Monitoring your project [\#](https://supabase.com/docs/guides/telemetry/metrics\#monitoring-your-project)

You can configure alerts from Prometheus or Grafana. The `supabase-grafana` repository has a selection of [example alerts](https://github.com/supabase/supabase-grafana/blob/main/docs/example-alerts.md) that can be configured.

Grafana Cloud has an unofficial integration for scraping Supabase metrics. See their
[docs](https://grafana.com/docs/grafana-cloud/monitor-infrastructure/integrations/integration-reference/integration-supabase/)
for instructions on how to configure it but note that it is not full-featured nor is it supported
by Supabase.

### Is this helpful?

NoYes

### On this page

[Accessing the metrics endpoint](https://supabase.com/docs/guides/telemetry/metrics#accessing-the-metrics-endpoint) [Supabase Grafana](https://supabase.com/docs/guides/telemetry/metrics#supabase-grafana) [Using the metrics endpoint in production](https://supabase.com/docs/guides/telemetry/metrics#using-the-metrics-endpoint-in-production) [Setting up a metrics datastore](https://supabase.com/docs/guides/telemetry/metrics#setting-up-a-metrics-datastore) [Setting up a dashboard](https://supabase.com/docs/guides/telemetry/metrics#setting-up-a-dashboard) [Adding a data source to Grafana](https://supabase.com/docs/guides/telemetry/metrics#adding-a-data-source-to-grafana) [Adding the Supabase dashboard](https://supabase.com/docs/guides/telemetry/metrics#adding-the-supabase-dashboard) [Monitoring your project](https://supabase.com/docs/guides/telemetry/metrics#monitoring-your-project)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_telemetry_sentry_monitoring.md">
Telemetry

# Sentry integration

## Integrate Sentry to monitor errors from a Supabase client

* * *

You can use [Sentry](https://sentry.io/welcome/) to monitor errors thrown from a Supabase JavaScript client. Install the [Supabase Sentry integration](https://github.com/supabase-community/sentry-integration-js) to get started.

The Sentry integration supports browser, Node, and edge environments.

## Installation [\#](https://supabase.com/docs/guides/telemetry/sentry-monitoring\#installation)

Install the Sentry integration using your package manager:

npmyarnpnpm

`
npm install @supabase/sentry-js-integration
`

## Use [\#](https://supabase.com/docs/guides/telemetry/sentry-monitoring\#use)

If you are using Sentry JavaScript SDK v7, reference [`supabase-community/sentry-integration-js` repository](https://github.com/supabase-community/sentry-integration-js/blob/master/README-7v.md) instead.

To use the Supabase Sentry integration, add it to your `integrations` list when initializing your Sentry client.

You can supply either the Supabase Client constructor or an already-initiated instance of a Supabase Client.

With constructorWith instance

`
import * as Sentry from '@sentry/browser'
import { SupabaseClient } from '@supabase/supabase-js'
import { supabaseIntegration } from '@supabase/sentry-js-integration'
Sentry.init({
dsn: SENTRY_DSN,
integrations: [\
    supabaseIntegration(SupabaseClient, Sentry, {\
      tracing: true,\
      breadcrumbs: true,\
      errors: true,\
    }),\
],
})
`

All available configuration options are available in our [`supabase-community/sentry-integration-js` repository](https://github.com/supabase-community/sentry-integration-js/blob/master/README.md#options).

## Deduplicating spans [\#](https://supabase.com/docs/guides/telemetry/sentry-monitoring\#deduplicating-spans)

If you're already monitoring HTTP errors in Sentry, for example with the HTTP, Fetch, or Undici integrations, you will get duplicate spans for Supabase calls. You can deduplicate the spans by skipping them in your other integration:

``
import * as Sentry from '@sentry/browser'
import { SupabaseClient } from '@supabase/supabase-js'
import { supabaseIntegration } from '@supabase/sentry-js-integration'
Sentry.init({
dsn: SENTRY_DSN,
integrations: [\
    supabaseIntegration(SupabaseClient, Sentry, {\
      tracing: true,\
      breadcrumbs: true,\
      errors: true,\
    }),\
    // @sentry/browser\
    Sentry.browserTracingIntegration({\
      shouldCreateSpanForRequest: (url) => {\
        return !url.startsWith(`${SUPABASE_URL}/rest`)\
      },\
    }),\
    // or @sentry/node\
    Sentry.httpIntegration({\
      tracing: {\
        ignoreOutgoingRequests: (url) => {\
          return url.startsWith(`${SUPABASE_URL}/rest`)\
        },\
      },\
    }),\
    // or @sentry/node with Fetch support\
    Sentry.nativeNodeFetchIntegration({\
      ignoreOutgoingRequests: (url) => {\
        return url.startsWith(`${SUPABASE_URL}/rest`)\
      },\
    }),\
    // or @sentry/WinterCGFetch for Next.js Middleware & Edge Functions\
    Sentry.winterCGFetchIntegration({\
      breadcrumbs: true,\
      shouldCreateSpanForRequest: (url) => {\
        return !url.startsWith(`${SUPABASE_URL}/rest`)\
      },\
    }),\
],
})
``

## Example Next.js configuration [\#](https://supabase.com/docs/guides/telemetry/sentry-monitoring\#example-nextjs-configuration)

See this example for a setup with Next.js to cover browser, server, and edge environments. First, run through the [Sentry Next.js wizard](https://docs.sentry.io/platforms/javascript/guides/nextjs/#install) to generate the base Next.js configuration. Then add the Supabase Sentry Integration to all your `Sentry.init` calls with the appropriate filters.

BrowserServerMiddleware & EdgeInstrumentation

sentry.client.config.ts

``
import * as Sentry from '@sentry/nextjs'
import { SupabaseClient } from '@supabase/supabase-js'
import { supabaseIntegration } from '@supabase/sentry-js-integration'
Sentry.init({
dsn: SENTRY_DSN,
integrations: [\
    supabaseIntegration(SupabaseClient, Sentry, {\
      tracing: true,\
      breadcrumbs: true,\
      errors: true,\
    }),\
    Sentry.browserTracingIntegration({\
      shouldCreateSpanForRequest: (url) => {\
        return !url.startsWith(`${process.env.NEXT_PUBLIC_SUPABASE_URL}/rest`)\
      },\
    }),\
],
// Adjust this value in production, or use tracesSampler for greater control
tracesSampleRate: 1,
// Setting this option to true will print useful information to the console while you're setting up Sentry.
debug: true,
})
``

Afterwards, build your application ( `npm run build`) and start it locally ( `npm run start`). You will now see the transactions being logged in the terminal when making supabase-js requests.

### Is this helpful?

NoYes

### On this page

[Installation](https://supabase.com/docs/guides/telemetry/sentry-monitoring#installation) [Use](https://supabase.com/docs/guides/telemetry/sentry-monitoring#use) [Deduplicating spans](https://supabase.com/docs/guides/telemetry/sentry-monitoring#deduplicating-spans) [Example Next.js configuration](https://supabase.com/docs/guides/telemetry/sentry-monitoring#example-nextjs-configuration)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_telemetry.md">
Telemetry

# Telemetry

* * *

Telemetry helps you understand whats happening inside your app by collecting logs, metrics, and traces.

- **Logs** capture individual events, such as errors or warnings, providing details about what happened at a specific moment.
- **Metrics** track numerical data over time, like request latency or database query performance, helping you spot trends.
- **Traces** show the flow of a request through different services, helping you debug slow or failing operations.

Supabase is working towards full support for the [OpenTelemetry](https://opentelemetry.io/) standard, making it easier to integrate with observability tools.

This section provides guidance on telemetry in Supabase, including how to work with Supabase Logs.

### Is this helpful?

NoYes

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_42501__permission_denied_for_table_httprequestqueue_KnozmQ.md">
# 42501 : permission denied for table http\_request\_queue

Last edited: 2/21/2025

* * *

If you're currently blocked by the above error, run the following in your Supabase SQL editor:

- Check `select * from net.http_request_queue` and make sure it's empty.
- Try `drop extension pg_net; create extension pg_net schema extensions;`
- If that doesn't work (e.g. because some objects depend on it), then [contact support](https://supabase.com/support).

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_all_about_supabase_egress_a_Sg_e.md">
# All about Supabase Egress

Last edited: 2/12/2025

* * *

**What is Egress?**

Egress (also known as bandwidth) is any amount of network packets/bytes being streamed back to a connected client. Means, the data that is leaving the Supabase platform. Egress in Supabase includes any calls through PostgREST, to Storage, Realtime, Auth, Edge Functions, Database and Supavisor.

You can read about Unified egress, included quota, and how to check the egress usage here: [https://supabase.com/docs/guides/platform/manage-your-usage/egress](https://supabase.com/docs/guides/platform/manage-your-usage/egress). Additionally, the [project reports](https://supabase.com/dashboard/project/_/reports) have a few egress related stats. You can create a custom report to look into daily egress.

- Example: Log Explorer -> Custom Reports -> Add/Remove charts -> Database API -> API Egress.

**What is contributing to Egress?**

While pointing out the exact cause for egress may not be straightforward, there are various steps you can take to determine the source of these issues:

- Picking the "Top Paths" from the [log explorer](https://app.supabase.com/project/_/logs/explorer/templates) will help you identify heavily queried paths
- By finding the most requested queries from Query performance report: [https://app.supabase.com/project/\_/reports/query-performance](https://app.supabase.com/project/_/reports/query-performance)
- Supavisor Egress is independent of client. There is no direct relation between a single query and Supavisor egress, it is harder to debug and identify. But you can make use of frequent queries from the link in above step that also displays average number of rows which will help to identify queries with a large number of rows returned. While this does not display Supavisor queries specifically, it will give an overview of queries with lots of rows that can help.
- For Storage Egress, all outgoing traffic for storage-related requests to download/view your Storage items are considered as Storage egress. We have a "Storage Egress Requests" template in logs explorer that you can use to get the number of requests for each Storage object
- If you pull 1mb of data out of the database using the Supavisor connection in your edge function, but only sends 100kb back to the user, you will have the Egress from the Supavisor to your Edge function plus from the edge function to your user

**How can you decrease egress?**

- Reduce the number of fields selected or entries when querying
- Reduce the number of queries/calls by optimising client code or use caches to reduce the number of requests/queries being done: [https://github.com/psteinroe/supabase-cache-helpers/](https://github.com/psteinroe/supabase-cache-helpers/)
- In case of update/insert queries, if you dont need the entire row to be returned, configure your ORM/queries to not return the entire row
- In case of running manual backups through Supavisor, remove unneeded tables and/or reduce the frequency
- For Storage, if you start using the [Smart CDN](https://supabase.com/docs/guides/storage/cdn/smart-cdn) Storage Egress usage can be managed. You can also use the [Supabase Image Transformations](https://supabase.com/docs/guides/storage/image-transformations) to optimize the images and reduce the egress.

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_an_invalid_response_was_received_from_the_upstream_server_error_when_querying_auth_RI4Vl_.md">
# An "invalid response was received from the upstream server" error when querying auth

Last edited: 2/21/2025

* * *

If you are observing an "invalid response was received from the upstream server" error when making requests to Supabase Auth, it could mean that the respective service is down. One way to confirm this is to visit the [logs explorer](https://supabase.com/dashboard/project/_/logs/explorer) and look at the auth logs to see if there are any errors with the following lines:

- `running db migrations: error executing migrations/20221208132122_backfill_email_last_sign_in_at.up.sql`

We're currently investigating an issue where the tables responsible for keeping track of migrations ran by Auth ( `auth.schema_migrations`) are not being restored properly, which leads to the service(s) retrying those migrations. In such cases, migrations which are not idempotent will run into issues.

We've documented some of the migrations that run into this issue and their corresponding fix here:

### Auth: `operator does not exist: uuid = text` [\#](https://supabase.com/docs/guides/troubleshooting/an-invalid-response-was-received-from-the-upstream-server-error-when-querying-auth-RI4Vl-\#auth-operator-does-not-exist-uuid--text)

Temporary fix: Run `insert into auth.schema_migrations values ('20221208132122');` via the [SQL editor](https://supabase.com/dashboard/project/_/sql/new) to fix the issue.

If the migration error you're seeing looks different, reach out to [supabase.help](https://supabase.help/) for assistance.

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_are_all_features_available_in_self_hosted_supabase_THPcqw.md">
# Are all features available in self-hosted Supabase?

Last edited: 1/15/2025

* * *

### Overview [\#](https://supabase.com/docs/guides/troubleshooting/are-all-features-available-in-self-hosted-supabase-THPcqw\#overview)

The self-hosted version is pretty similar to the hosted one. It might not always have the latest features right away, but it includes everything you need to get your application up and running.

### Feature availability [\#](https://supabase.com/docs/guides/troubleshooting/are-all-features-available-in-self-hosted-supabase-THPcqw\#feature-availability)

To know what features are available in the self-hosted version, refer to the comprehensive list here:
[Supabase Features](https://supabase.com/docs/guides/getting-started/features#generally-available)

### Self-hosting documentation [\#](https://supabase.com/docs/guides/troubleshooting/are-all-features-available-in-self-hosted-supabase-THPcqw\#self-hosting-documentation)

For detailed steps and guidance on how to set up and manage your self-hosted Supabase instance, follow the documentation provided:
[Self-Hosting Guide](https://supabase.com/docs/guides/self-hosting)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_auth_error_401_invalid_claim_missing_sub__AFwMR.md">
# Auth error: {401: invalid claim: missing sub}

Last edited: 2/4/2025

* * *

The missing sub claim error is returned when `supabase.auth.getUser()` is called with an invalid JWT in the session or when the user attempts to register/sign in but hasn't completed the sign in when the `getUser` call is made.

A common pitfall, is inadvertently using a Supabase API key (such as the anon or service\_role keys) instead of the Supabase Auth access token.

**Why Does This Happen?**

- The Supabase API keys are designed for different purposes and, while they are recognized by the Supabase Auth system, they do not carry the sub claim. The sub claim is essential as it encodes the user ID, which is a mandatory field for authentication processes. This mistake leads to the "missing sub claim" error because the system expects a token that contains user identification information.

**How to Avoid This Issue:**

- Ensure that the token being passed to `supabase.auth.getUser()` is, indeed, an Auth access token and not one of the API keys.

- Are you creating the client on a per-request basis or are you creating a global client to be shared? If you're creating the client on a per-request basis, then you need to pass the session with the user's JWT from the client to the server somehow. This can be done by sending the user's JWT in a header like an `Authorization: Bearer <user_jwt>` . You can then get this header and call `supabase.auth.getUser(user_jwt)` with the user's JWT.

- Examine how the Supabase client is being initialized, especially in server-side scenarios.


1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_avoiding_timeouts_in_long_running_queries_6nmbdN.md">
# Avoiding timeouts in long running queries

Last edited: 2/21/2025

* * *

This page covers long-running queries via the Dashboard or external interfaces. For Supabase Client API timeout errors, check this [guide](https://github.com/orgs/supabase/discussions/14256) instead.

Certain queries, like indexing a table or changing a column's data type, are inherently time-consuming. The [Dashboard's SQL Editor](https://supabase.com/dashboard/project/_/sql/) has a 1-minute timeout limit.

To execute long-running queries, follow the below steps.

### Install an external SQL client [\#](https://supabase.com/docs/guides/troubleshooting/avoiding-timeouts-in-long-running-queries-6nmbdN\#install-an-external-sql-client)

The guide focuses on [psql](https://supabase.com/docs/guides/database/psql) but you can use any Postgres client.

Some other options include:

- [pgAdmin](https://supabase.com/docs/guides/database/pgadmin)
- [DBeaver](https://supabase.com/docs/guides/database/dbeaver)

You can install PSQL in [macOS](https://stackoverflow.com/a/49689589/2188186) and [Windows](https://www.postgresql.org/download/windows/) by following these links and instructions. For Linux (Debian) you can run the following:

`
sudo apt-get update
sudo apt-get install postgresql-client
`

Once installed, you can find your PSQL string in the [Database Settings](https://supabase.com/dashboard/project/_/settings/database). Make sure if you are using the pooler connection that it is in session mode (port 5432).

If you are working in an [IPv6 environment](https://github.com/orgs/supabase/discussions/27034) or have the IPv4 Add-On, it is preferable to use the direct connection.

### Increase the query timeout [\#](https://supabase.com/docs/guides/troubleshooting/avoiding-timeouts-in-long-running-queries-6nmbdN\#increase-the-query-timeout)

Then you can increase the query timeout solely for your session:

Long timeout

`
set statement_timeout = '120min';
`

Disable timeout

`
set statement_timeout = '0';
`

If your task is particularly long, you can may want to consider boosting your computing power temporarily. Compute size on Supabase is charged by the hour, so you can increase it for an hour or two, complete your task faster, then scale it back afterwards.

If you want to temporarily upgrade, you can find the add-ons for your project in your [Dashboard's Add-ons Settings.](https://supabase.green/dashboard/project/_/settings/addons)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_canceling_statement_due_to_statement_timeout_581wFv.md">
# Canceling statement due to "statement timeout"

Last edited: 2/4/2025

* * *

> If encountering 504 or timeout errors in the Dashboard, check out this [guide](https://github.com/orgs/supabase/discussions/21133#discussioncomment-9573776)

You can run this query to check the current settings set for your roles: `SELECT rolname, rolconfig FROM  pg_roles;`

To increase the `statement_timeout` for a specific role, you may follow the instructions [here](https://supabase.com/docs/guides/database/timeouts#changing-the-default-timeout). Note that it may require a quick reboot for the changes to take effect.

Additionally, to check how long a query is taking, you can check the Query Performance report which can give you more information on the query's performance: [https://app.supabase.com/project/\_/reports/query-performance](https://app.supabase.com/project/_/reports/query-performance). You can use the [query plan analyzer](https://www.postgresql.org/docs/current/sql-explain.html) on any expensive queries that you have identified: `explain analyze <query-statement-here>;`. For supabase-js/ PostgREST queries you can use `.explain()`.

You can also make use of Postgres logs that will give you useful information like when the query was executed: [https://app.supabase.com/project/\_/logs/postgres-logs](https://app.supabase.com/project/_/logs/postgres-logs).

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_certain_operations_are_too_complex_to_perform_directly_using_the_client_libraries_8JaphH.md">
# Certain operations are too complex to perform directly using the client libraries.

Last edited: 2/21/2025

* * *

**Solution**
In cases where operations are overly complex or not feasible to implement directly using the client libraries, it might be beneficial to leverage stored functions within your database.

Follow these steps to create and run a stored function:

**Create the Stored Function:**

Go to the [SQL query editor](https://supabase.com/dashboard/project/_/sql/new) on your database dashboard.
Run the following SQL script to create a stored function tailored to your specific complex query:

`
DROP FUNCTION IF EXISTS get_my_complex_query;
CREATE FUNCTION get_my_complex_query(parameter INT)
RETURNS TABLE (column1 INTEGER, column2 VARCHAR, column3 DATE) AS
$$
BEGIN
    RETURN QUERY
    SELECT t1.column1, t1.column2, t2.column3
    FROM "TableName1" AS t1
    INNER JOIN "TableName2" AS t2 ON t1.column = t2.column
    INNER JOIN "TableName3" AS t3 ON t2.another_column = t3.another_column
    LEFT JOIN "TableName4" AS t4 ON t3.some_column = t4.some_column
    WHERE t2.column = parameter
    AND t3.column_name = 'some_value';
END;
$$
LANGUAGE plpgsql VOLATILE;
`

**Call the Stored Function:**

Use the supabase.rpc method to call the stored function from your application code. Replace "get\_my\_complex\_query" with the appropriate function name and provide the necessary parameters:

`
supabase.rpc("get_my_complex_query", { parameter: 1 })
.then(response => {
    // Handle the response
})
.catch(error => {
    // Handle errors
});
`

**Further Resources:**

For more information on Postgres database functions, refer to the following resource:
[Supabase Stored Procedures](https://supabase.com/docs/guides/database/functions#quick-demo)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_change_email_associated_with_supabase_account_T5eHNT.md">
# Change email associated with Supabase account

Last edited: 2/4/2025

* * *

Currently, there isn't a direct way to change the email address of an existing Supabase account.

If you are using Email Authentication to login into your Supabase account:

- Invite a new email address to your Supabase Organization(s) as an Organization owner.
- After signing up for a new account with your new email address and confirming you have access to the Organization(s) with your new account, you can leave the Organization(s) from your previous account.

If you are using GitHub Authentication to login into your Supabase account:

- Log out of Supabase.
- Change Primary Email in GitHub
- Log out of GitHub.
- Log back into GitHub (with the new, desired email set as primary)
- Log back into Supabase.

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_change_project_region_eWJo5Z.md">
# Change Project Region

Last edited: 1/17/2025

* * *

The process to change the region of a Supabase Project is to create a new project in the desired region and migrate your existing project to the new project using this guide: [https://supabase.com/docs/guides/database#migrating-between-projects](https://supabase.com/docs/guides/database#migrating-between-projects)

If you are using third-party auth(Facebook, Google, etc.), you need to manually copy over your client id/secret pairs in the dashboard. Also, you'd need to change your API URL/Anon or Service Keys, which is usually done via ENV vars on your web host.

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_check_usage_for_monthly_active_users_mau_MwZaBs.md">
# Check usage for monthly active users (MAU)

Last edited: 1/17/2025

* * *

You can see the usage in your [projects usage page](https://app.supabase.com/project/_/settings/billing/usage).

For MAU, we rely on the [Auth Server](https://github.com/supabase/auth) logs. MAU count is relative to your billing cycle and resets whenever your billing cycle resets. You can check your Auth logs in your [projects logs & analytics section](https://supabase.com/dashboard/project/_/logs/auth-logs).

We do a distinct count of all user ids in the billing cycle. An Auth event can be a login, token refresh, logout, ... If an authenticated user does any of this, we count it towards the MAU. A user is only counted once towards MAU in a billing cycle.

The log retention for you as a user (accessible time) depends on your plan. Free plan users can access the logs of the last day, Pro plan users 7 days, Team plan users 28 days, Enterprise users 90 days. Unless you're on an Enterprise plan, you won't be able to execute the query to determine MAU yourself, as you don't have access to the logs in the past 30ish days (depending on your billing cycle).

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_converted_github_account_to_organisation___lost_supabase_account_access_5wsE_1.md">
# Converted Github account to organization - Lost Supabase account access

Last edited: 1/17/2025

* * *

[Converting](https://docs.github.com/en/account-and-profile/setting-up-and-managing-your-personal-account-on-github/managing-your-personal-account/converting-a-user-into-an-organization) your GitHub account to a [GitHub organization](https://docs.github.com/en/get-started/learning-about-github/types-of-github-accounts#organization-accounts) will cause you to lose access to all other accounts using GitHub sign-ins.

However, Supabase can help you transfer ownership of an existing organization on your account by inviting a new owner to your organization. This new user will need to have a different email from the previous one, and you will need to email [support@supabase.com](mailto:support@supabase.com) with that new email as well to confirm that you own the email address.

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_customizing_emails_by_language_KZ_38Q.md">
# Customizing Emails by Language

Last edited: 2/4/2025

* * *

When you register a user, you can create meta-data about them.

Creating meta-data with the JS-Client's [signUp function](https://supabase.com/docs/reference/javascript/auth-signup?example=sign-up-with-additional-user-metadata)

`
const { data, error } = await supabase.auth.signUp({
email: 'email@some_[email.com](http://email.com/)',
password: 'example-password',
options: {
    data: {
      first_name: 'John',
      last_name: 'Doe',
      age: 27,
    },
},
})
`

The above example creates a user entry that includes information about their name and age. The data is stored in the auth.users table in the `auth.raw_user_meta_data` column. You can view it in the auth schema with the [SQL Editor](https://supabase.com/dashboard/project/_/editor).

It can be accessed in a project's [Email Templates](https://supabase.com/dashboard/project/_/auth/templates). Below is an example:

![image](https://supabase.com/docs/img/troubleshooting/3eeb2435-dd1c-41bc-9557-44cabff38f59.png)

If you need to update a user's meta-data, you can do so with the [`updateUser`](https://supabase.com/docs/reference/javascript/auth-updateuser?example=update-the-users-metadata) function.

The meta-data can be used to store a users language preferences. You could then use "if statements" in the email template to set the response for a specific language:

`
{{if eq .Data.langauge "en" }}
<h1>Welcome!</h1>
{{ else if eq .Data.langauge "pl" }}
<h1>Witamy!</h1>
{{ else }}
<h1>chuS'ugh, tera' je (Klingon)</h1>
{{end}}
`

Supabase uses the [Go Templating Language](https://pkg.go.dev/text/template) to render emails. It has advanced features for conditions that you may want to [explore](https://gohugo.io/templates/introduction/). For more examples, there is a [GitHub discussion](https://github.com/supabase/gotrue/issues/80#issuecomment-1552264148) that discusses advanced language templates.

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_dashboard_errors_when_managing_users_N1ls4A.md">
# Dashboard errors when managing users

Last edited: 2/4/2025

* * *

## PROBLEM [\#](https://supabase.com/docs/guides/troubleshooting/dashboard-errors-when-managing-users-N1ls4A\#problem)

### Receiving the following or _similar_ error messages in the Dashboard when managing users. [\#](https://supabase.com/docs/guides/troubleshooting/dashboard-errors-when-managing-users-N1ls4A\#receiving-the-following-or-similar-error-messages-in-the-dashboard-when-managing-users)

> ... Database error
> ... Error sending

![](https://github.com/supabase/supabase/assets/91111415/91732e7d-0e83-4bc8-8ce3-57ebd871d981)![](https://github.com/supabase/supabase/assets/91111415/30f4cd9f-3736-40ae-8606-2f060cfac0d0)![](https://github.com/supabase/supabase/assets/91111415/50961019-b461-44cb-9e4b-f1361aa3ad5d)

### Or, receiving a comparable 500 error from the Auth REST API: [\#](https://supabase.com/docs/guides/troubleshooting/dashboard-errors-when-managing-users-N1ls4A\#or-receiving-a-comparable-500-error-from-the-auth-rest-api)

> Database error ...

![Screenshot 2024-02-13 at 10 59 17 PM](https://github.com/supabase/supabase/assets/91111415/cd151dda-5160-415c-925c-cea332887641)

## SOLUTION 1 (trigger related) [\#](https://supabase.com/docs/guides/troubleshooting/dashboard-errors-when-managing-users-N1ls4A\#solution-1-trigger-related)

Check if the auth schema contains any triggers in the [Dashboard's trigger section](https://supabase.com/dashboard/project/_/database/triggers). Remove all triggers by dropping their functions with a CASCADE modifier:

`
DROP FUNCTION <function name>() CASCADE;
-- If you'd prefer, you can drop the trigger alone with the following query:
-- DROP TRIGGER <trigger_name> on auth.<table_name>;
`

Then recreate the functions with a [security definer](https://supabase.com/docs/guides/database/functions#security-definer-vs-invoker) modifier before recreating the triggers.

The [SQL Editor](https://supabase.com/dashboard/project/_/sql/) contains a template for [User Management](https://supabase.com/dashboard/project/_/sql/quickstarts). Within it, there is a working example of how to setup triggers with security definer that may be worth referencing:

`
create table profiles (
id uuid references auth.users on delete cascade not null primary key,
updated_at timestamp with time zone,
username text unique,
full_name text,
avatar_url text,
website text,
constraint username_length check (char_length(username) >= 3)
);
create function public.handle_new_user()
returns trigger as $$
begin
insert into public.profiles (id, full_name, avatar_url)
values (new.id, new.raw_user_meta_data->>'full_name', new.raw_user_meta_data->>'avatar_url');
return new;
end;
$$ language plpgsql security definer;
create trigger on_auth_user_created
after insert on auth.users
for each row execute procedure public.handle_new_user();
`

### EXPLANATION [\#](https://supabase.com/docs/guides/troubleshooting/dashboard-errors-when-managing-users-N1ls4A\#explanation)

One of the most common design patterns in Supabase is to add a trigger to the `auth.users` table. The database role managing authentication (supabase\_auth\_admin) only has the necessary permissions it needs to perform its duties. So, when a trigger operated by the supabase\_auth\_admin interacts outside the auth schema, it causes a permission error.

A security definer function retains the privileges of the database user that created it. As long as it is the `postgres` role, your auth triggers should be able to engage with outside tables.

## SOLUTION 2 (constraint related) [\#](https://supabase.com/docs/guides/troubleshooting/dashboard-errors-when-managing-users-N1ls4A\#solution-2-constraint-related)

If you did not create a trigger, check if you created a foreign/primary key relationship between the auth.users table and another table. If you did, then ALTER the [behavior](https://stackoverflow.com/questions/5383612/setting-up-table-relations-what-do-cascade-set-null-and-restrict-do) of the relationship and recreate it with a less [restrictive constraint](https://stackoverflow.com/questions/3359329/how-to-change-the-foreign-key-referential-action-behavior).

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_database_error_remaining_connection_slots_are_reserved_for_non_replication_superuser_connections_3V3nIb.md">
# Database Error: remaining connection slots are reserved for non-replication superuser connections

Last edited: 1/18/2025

* * *

This error usually occurs when the database reaches the maximum number of connections allowed based on the compute add-on.

To overcome this, the connections need to be optimized as mentioned here: [https://supabase.com/docs/guides/platform/performance#optimizing-the-number-of-connections](https://supabase.com/docs/guides/platform/performance#optimizing-the-number-of-connections)

Additionally, you can try using the connection pool to help solve this issue:
[https://supabase.com/docs/guides/database/connecting-to-postgres#connection-pooler](https://supabase.com/docs/guides/database/connecting-to-postgres#connection-pooler)

If you're already using connection pooling and still hitting the maximum connections, then it is suggested to upgrade your compute add-on that allows more connections: [https://supabase.com/docs/guides/platform/compute-add-ons](https://supabase.com/docs/guides/platform/compute-add-ons)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_database_error_saving_new_user_RU_EwB.md">
# Database error saving new user

Last edited: 1/17/2025

* * *

You generally get this error when trying to invite a new user from the dashboard or when trying to insert a user into a table using the table editor in the Supabase dashboard.

This error is normally associated with a side effect of a database transaction.

**Common causes of this error:**

- You have a trigger/trigger function setup on the `auth.users` table
- You have added a constraint on the `auth.users` table which isn't being met
- You are using Prisma and it has broken all the permissions on the `auth.users` table

**Debugging this error:**

- You can use the [Auth logs explorer](https://app.supabase.com/project/_/logs/auth-logs) to find the issue with more information
- You can use the [Postgres logs explorer](https://app.supabase.com/project/_/logs/postgres-logs)

[https://user-images.githubusercontent.com/79497/225517698-b6e3ccaf-cd70-4acd-8124-ffbcee310d63.mp4](https://user-images.githubusercontent.com/79497/225517698-b6e3ccaf-cd70-4acd-8124-ffbcee310d63.mp4)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_deprecated_rls_features_Pm77Zs.md">
# Deprecated RLS features

Last edited: 3/7/2025

* * *

## The `auth.role()` function is now deprecated [\#](https://supabase.com/docs/guides/troubleshooting/deprecated-rls-features-Pm77Zs\#the-authrole-function-is-now-deprecated)

The `auth.role()` function has been deprecated in favour of using the `TO` field, natively supported within Postgres:

`
-- DEPRECATED
create policy "Public profiles are viewable by everyone."
on profiles for select using (
auth.role() = 'authenticated' or auth.role() = 'anon'
);
-- RECOMMENDED
create policy "Public profiles are viewable by everyone."
on profiles for select
to authenticated, anon
using (
true
);
`

## The `auth.email()` function is now deprecated [\#](https://supabase.com/docs/guides/troubleshooting/deprecated-rls-features-Pm77Zs\#the-authemail-function-is-now-deprecated)

The `auth.email()` function has been deprecated in favour a more generic function to return the full JWT:

`
- DEPRECATED
create policy "User can view their profile."
on profiles for select using (
auth.email() = email
);
-- RECOMMENDED
create policy "User can view their profile."
on profiles for select using (
(auth.jwt() ->> 'email') = email
);
`

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_disabling_prepared_statements_qL8lEL.md">
# Disabling Prepared statements

Last edited: 2/4/2025

* * *

### It is important to note that although the direct connections and Supavisor in session mode support prepared statements, Supavisor in transaction mode does not. [\#](https://supabase.com/docs/guides/troubleshooting/disabling-prepared-statements-qL8lEL\#it-is-important-to-note-that-although-the-direct-connections-and-supavisor-in-session-mode-support-prepared-statements-supavisor-in-transaction-mode-does-not)

## How to disable prepared statements for Supavisor in transaction mode [\#](https://supabase.com/docs/guides/troubleshooting/disabling-prepared-statements-qL8lEL\#how-to-disable-prepared-statements-for-supavisor-in-transaction-mode)

Each ORM or library configures prepared statements differently. Here are settings for some common ones. If you don't see yours, make a comment

# Prisma:

add ?pgbouncer=true to end of connection string:

`
postgres://[db-user].[project-ref]:[db-password]@aws-0-[aws-region].pooler.supabase.com:6543/[db-name]?pgbouncer=true
`

# Drizzle:

Add a prepared false flag to the client:

`
export const client = postgres(connectionString, { prepare: false })
`

# Node Postgres

[Just omit the "name" value in a query definition](https://node-postgres.com/features/queries#prepared-statements):

`
const query = {
name: 'fetch-user', // <--------- DO NOT INCLUDE
text: 'SELECT * FROM user WHERE id = $1',
values: [1],
}
`

# Psycopg

set the [prepare\_threshold](https://www.psycopg.org/psycopg3/docs/api/connections.html#psycopg.Connection.prepare_threshold) to `None`.

# asyncpg

Follow the recommendation in the [asyncpg docs](https://magicstack.github.io/asyncpg/current/faq.html#why-am-i-getting-prepared-statement-errors)

> disable automatic use of prepared statements by passing `statement_cache_size=0` to [asyncpg.connect()](https://magicstack.github.io/asyncpg/current/api/index.html#asyncpg.connection.connect) and [asyncpg.create\_pool()](https://magicstack.github.io/asyncpg/current/api/index.html#asyncpg.pool.create_pool) (and, obviously, avoid the use of [Connection.prepare()](https://magicstack.github.io/asyncpg/current/api/index.html#asyncpg.connection.Connection.prepare));

# Rust's Deadpool or `tokio-postgres`:

- Check [GitHub Discussion](https://github.com/bikeshedder/deadpool/issues/340#event-13642472475)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_discovering_and_interpreting_api_errors_in_the_logs_7xREI9.md">
# Discovering and Interpreting API Errors in the Logs

Last edited: 2/21/2025

* * *

> A complimentary [guide](https://github.com/orgs/supabase/discussions/26224) was made for the Postgres logs

# Navigating the API logs:

The Database API is powered by a [PostgREST web-server](https://postgrest.org/en/v12/), recording every request to the API Edge Network logs. To precisely navigate them, use the [Log Explorer](https://supabase.com/dashboard/project/_/logs/explorer). These logs are managed through [Logflare](https://supabase.com/blog/supabase-logs-self-hosted) and can be queried with a subset of BigQuery SQL syntax.

The log table that contains API requests is `edge_logs`.

Notably, it contains:

| field | description |
| --- | --- |
| event\_message | the log's message |
| timestamp | time event was recorded |
| request metadata | metadata about the REST request |
| response metadata | metadata about the REST response |

The request and response columns are arrays in the metadata field and must be unnested. This is done with a `cross join`.

**Unnesting example**

`
select
  -- the event message does not require unnesting
event_message,
  -- unnested status_code column from metadata.response field
status_code
from
edge_logs
  -- Unpack data stored in the 'metadata' field
cross join unnest(metadata) as metadata
  -- After unpacking the 'metadata' field, extract the 'response' field from it
cross join unnest(response) as response;
`

The most useful fields for debugging are:

> NOTE: not every field is included below. For a full list, check the API Edge field reference in the [Log Explorer](https://supabase.com/dashboard/project/_/logs/explorer)

## Request object [\#](https://supabase.com/docs/guides/troubleshooting/discovering-and-interpreting-api-errors-in-the-logs-7xREI9\#request-object)

### Cloudflare geographic data: [\#](https://supabase.com/docs/guides/troubleshooting/discovering-and-interpreting-api-errors-in-the-logs-7xREI9\#cloudflare-geographic-data)

**Suggested use cases:**

- Detecting abuse from a specific region
- Detecting activity spikes from certain regions

| Column | Description | Sample value |
| --- | --- | --- |
| request.cf.city | Requester's city | Munich |
| request.cf.country | Requester's country | [DE](https://www.iso.org/iso-3166-country-codes.html) |
| request.cf.continent | Requester's continent | EU |
| request.cf.region | Requester's region | Bavaria |
| request.cf.latitudex | Requester's latitude | 48.10840 |
| request.cf.longitude | Requester's longitude | 11.61020 |
| request.cf.timezone | Requester's timezone | Europe/Berlin |

**Unnesting example:**

`
select
city
from
edge_logs
-- Unpack 'metadata' field
cross join unnest(metadata) AS metadata
-- unpack 'request' from 'metadata'
cross join unnest(request) AS request;
-- unpack 'cf' from 'request'
cross join unnest(cf) AS cf;
`

### IP and browser/environment data: [\#](https://supabase.com/docs/guides/troubleshooting/discovering-and-interpreting-api-errors-in-the-logs-7xREI9\#ip-and-browserenvironment-data)

**Suggested use cases:**

- Detecting request behavior from IP
- Detecting abuse by IP
- Detecting errors by user\_agent

| Column | Description | Sample value |
| --- | --- | --- |
| request.headers.cf\_connecting\_ip | Requester's IP | 80.81.18.138 |
| request.headers.user\_agent | Requester's browser or app environment | Mozilla/5.0 (Linux; Android 11; K) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Mobile Safari/537.36 |

**Unnesting example:**

`
select
cf_connecting_ip
from
edge_logs
-- Unpack 'metadata' field
cross join unnest(metadata) AS metadata
-- unpack 'request' from 'metadata'
cross join unnest(request) AS request;
-- unpack 'headers' from 'request'
cross join unnest(headers) AS headers;
`

### Query type and formatting data: [\#](https://supabase.com/docs/guides/troubleshooting/discovering-and-interpreting-api-errors-in-the-logs-7xREI9\#query-type-and-formatting-data)

**Suggested use cases:**

- identify problematic queries
- identify unusual behavior by authenticated users

| Column | Description | Sample value |
| --- | --- | --- |
| request.method | Request Method (PATCH, GET, PUT...) | GET |
| request.url | Request URL, which contains the PostgREST formatted query | [https://yuhplfrsdxxxtldakizi.supabase.co/rest/v1/users?select=username&id=eq.63b6190e-214f-4b8a-b72d-3af6e1921411&limit=1](https://yuhplfrsdxxxtldakizi.supabase.co/rest/v1/users?select=username&id=eq.63b6190e-214f-4b8a-b72d-3af6e1921411&limit=1) |
| request.sb.auth\_users | authenticated user's ID | 63b6190e-214f-4b8a-b72d-3af6e1921411 |

**Unnesting example:**

`
select
method,
url,
auth_users
from
edge_logs
-- Unpack 'metadata' field
cross join unnest(metadata) AS metadata
-- unpack 'request' from 'metadata'
cross join unnest(request) AS request;
-- unpack 'sb' from 'request'
cross join unnest(sb) AS sb;
`

## Response object [\#](https://supabase.com/docs/guides/troubleshooting/discovering-and-interpreting-api-errors-in-the-logs-7xREI9\#response-object)

### Status code: [\#](https://supabase.com/docs/guides/troubleshooting/discovering-and-interpreting-api-errors-in-the-logs-7xREI9\#status-code)

**Suggested use cases:**

- detect success/errors

| Column | Description | Sample value |
| --- | --- | --- |
| response.status\_code | Response status code (200, 404, 500...) | 404 |

**Unnesting example:**

`
select
status_code
from
edge_logs
  -- Unpack 'metadata' field
cross join unnest(metadata) as metadata
  -- unpack 'response' from 'metadata'
cross join unnest(response) as response;
`

# Finding errors

### API level errors [\#](https://supabase.com/docs/guides/troubleshooting/discovering-and-interpreting-api-errors-in-the-logs-7xREI9\#api-level-errors)

The `metadata.request.url` contains PostgREST formatted queries.

For example, the following call to the JS client:

`
let { data: countries, error } = await supabase.from('countries').select('name')
`

translates to calling the following endpoint:

`
https://<project ref>.supabase.co/rest/v1/countries?select=name
`

You can use regex ( [Advanced Regex Guide](https://github.com/orgs/supabase/discussions/22640)) to find the objects related to your query. Try isolating by:

- function names
- column names
- table names
- query methods (select, insert, ...)

Example:

`
select
cast(timestamp as datetime) as timestamp,
status_code,
url,
event_message
from edge_logs
cross join unnest(metadata) as metadata
cross join unnest(response) AS request;
cross join unnest(response) AS response;
where
  -- find all errors
status_code >= 400
    and
  -- find queries featuring the a specific <table_name> and <column_name>
(
    regexp_contains(url, '<table_name>')
    and
    regexp_contains(event_message, '<column_name1>|<column_name2>')
)
`

PostgREST has an [error reference table](https://postgrest.org/en/v12/references/errors.html) that you can use to interpret status codes.

### Database-level errors [\#](https://supabase.com/docs/guides/troubleshooting/discovering-and-interpreting-api-errors-in-the-logs-7xREI9\#database-level-errors)

However, some errors that are reported through the Database API occur at the Postgres level. If it is not clear which error occurred you should reference the timestamp of the error and try to see if you can find it in the Postgres logs.

`
select
cast(postgres_logs.timestamp as datetime) as timestamp,
error_severity,
user_name,
query,
detail,
sql_state_code,
event_message
from postgres_logs
cross join unnest(metadata) as metadata
cross join unnest(metadata.parsed) as parsed
where
  -- filter only for error events
regexp_contains(parsed.error_severity, 'ERROR|FATAL|PANIC')
    and
  -- All DB API requests are registered as the authenticator role
parsed.user_name = 'authenticator'
    and
  -- find failed queries featuring the function <function_name>
regexp_contains(parsed.query, '<function_name>')
    and
  -- limit the time of the search to be around the time of the failed API request
postgres_logs.timestamp between '2024-04-15 10:50:00' AND '2024-04-15 10:50:27'
order by
timestamp desc
limit 100;
`

Like PostgREST, Postgres has a [reference table](https://www.postgresql.org/docs/current/errcodes-appendix.html) for interpreting error codes.

## PostgREST server and Cloudflare errors [\#](https://supabase.com/docs/guides/troubleshooting/discovering-and-interpreting-api-errors-in-the-logs-7xREI9\#postgrest-server-and-cloudflare-errors)

In some cases, errors may emerge because of Cloudflare or PostgREST server errors. For 500 and above errors, you may want to check your [PostgREST](https://supabase.com/dashboard/project/_/logs/postgrest-logs) logs and the [Cloudflare docs.](https://developers.cloudflare.com/support/troubleshooting/cloudflare-errors/troubleshooting-cloudflare-5xx-errors/#error-502-bad-gateway-or-error-504-gateway-timeout))

# Practical examples:

**Find All Errors:**

`
select
cast(timestamp as datetime) as timestamp,
status_code,
event_message,
path
from
edge_logs
cross join unnest(metadata) as metadata
cross join unnest(response) as response
cross join unnest(request) as request
where
  -- find all errors
status_code >= 400
and regexp_contains(path, '^/rest/v1/');
-- only look at DB API
`

**Group errors by path and code:**

`
select
status_code,
path,
count(path) as reoccurrence_per_path
from
edge_logs
cross join unnest(metadata) as metadata
cross join unnest(response) as response
cross join unnest(request) as request
where
  -- find all errors
status_code >= 400
and regexp_contains(path, '^/rest/v1/') -- only look at DB API
group by path, status_code
order by reoccurrence_per_path;
`

**Find requests by region:**

`
select
path,
region,
count(region) as region_count
from
edge_logs
cross join unnest(metadata) as metadata
cross join unnest(request) as request
cross join unnest(cf) as cf
where
  -- only look at DB API
regexp_contains(path, '^/rest/v1/')
group by region, path
order by requester_region_count;
`

**Find total requests by IP:**

`
select
cf_connecting_ip as ip,
count(cf_connecting_ip) as ip_count
from
edge_logs
cross join unnest(metadata) as metadata
cross join unnest(request) as request
cross join unnest(headers) as headers
cross join unnest(cf) as cf
cross join unnest(response) as response
where regexp_contains(path, '^/auth/v1/')
group by ip
order by ip_count;
`

**Search frequented query paths by authenticated user:**

`
select
  -- only available for front-end clients
auth_users,
path,
count(auth_users) as ip_count
from
edge_logs
cross join unnest(metadata) as metadata
cross join unnest(request) as request
cross join unnest(sb) as sb
where
  -- only look at DB API
regexp_contains(path, '^/rest/v1/')
group by auth_users, path;
`

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_do_i_need_to_expose_security_definer_functions_in_row_level_security_policies_iI0uOw.md">
# Do I need to expose "security definer" Functions in Row Level Security Policies?

Last edited: 3/7/2025

* * *

PostgREST supports 2 config parameters:

- Exposed Schemas
- Extra Search Path

![image](https://supabase.com/docs/img/troubleshooting/d756aeb0-515f-425d-b737-75a935935b73.png)

You do not need to add your "security definer" Functions to either of these if you are using them in your Policies.

PostgREST doesnt need to know about this function on extra search path or exposed schemas, as long as you explicitly use the schema inside RLS (e.g.: `security.rls_func`).

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_download_logical_backups.md">
# How to download logical backups in Supabase with physical backups enabled?

Last edited: 2/21/2025

* * *

If you're unable to download backups due to physical backups being enabled, you can use the Supabase CLI command `pgdump` as an alternative.
For step-by-step instructions, check out our guide: [Backup & Restore](https://supabase.com/docs/guides/platform/migrating-within-supabase/backup-restore).

You can also learn more about how backups work in Supabase here: [Database Backups](https://supabase.com/docs/guides/platform/backups).

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_edge_function_wall_clock_time_limit_reached_Nk38bW.md">
# Edge Function 'wall clock time limit reached'

Last edited: 1/17/2025

* * *

**What Does "Wall Clock Time Limit Reached" Mean?**

The message "wall clock time limit reached" typically indicates that a process has reached the maximum time allowed for execution. This time is measured by a clock, similar to a system clock or a clock on the wall. It encompasses the entire duration a process takes to complete, including any periods of inactivity or waiting.

When this message appears in the context of your edge function, it means that the function has emitted a Shutdown event either after reaching the specified wall clock duration or when it hits a resource limit such as CPU time used or memory utilized.

**Current Limits Explained**

- Wall Clock Time Limit: Currently set at 400 seconds for the total duration your edge function can run.
- CPU Execution Time: Limited to 200 milliseconds of active computing.

This means that if your edge function completes its task within these time constraints, there's no need to be concerned about the "wall clock time limit reached" error message.

Because the "wall clock time limit reached" warning can be expected in some cases. This message is hard-coded to be printed out when the worker has been terminated, even if it hasn't reached the time limit. However, if your function terminates with this warning and returns a 546 error response, then this indicates that your function is exceeding the allowed execution time, signaling a long-running task.

**Steps to Troubleshoot**
If you're facing the "wall clock time limit reached" error with a 546 error code, here are actions to take:

- Review Your Function's Logic: Examine the operations within your edge function for any inefficiencies or prolonged processes. Consider optimizing code, minimizing unnecessary calculations, and implementing asynchronous operations where possible.

- Divide Complex Tasks: For functions handling complex or extensive tasks, try breaking them down into smaller, discrete functions. This approach can help manage workloads more effectively and stay within time limits.

- Monitor Execution Time: Use our logging or monitoring tools available to keep an eye on your function's performance. This can pinpoint where optimizations are necessary. To access logs visit: [Supabase Project Functions](https://app.supabase.com/project/_/functions) Select your function and click on Logs.

- Check Our Guides: For more tips, refer to our debugging guide here: [Debugging Edge Functions](https://supabase.com/docs/guides/functions/debugging#logs--debugging)


**Future Considerations**
There are plans to make the wall clock time limit configurable per project in the future. However, currently, the only way to adjust this limit is by self-hosting [Edge Functions](https://github.com/supabase/edge-runtime/).

Stay updated on changes by regularly checking our changelog [here](https://github.com/orgs/supabase/discussions/categories/changelog).

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_error_connection_refused_when_trying_to_connect_to_supabase_database_hwG0Dr.md">
# Error: "Connection refused" when trying to connect to Supabase database

Last edited: 1/18/2025

* * *

If you're not able to connect to the Supabase database and see the error `connect ECONNREFUSED 1.2.3.4:5432`or `psql: error: connection to server at "db.xxxxxxxxxxxxxxxxxxxx.supabase.co" (1.2.3.4), port 5432 failed: Connection refused Is the server running on that host and accepting TCP/IP connections?`, this could be because there are banned IPs on your project caused by Fail2ban as it kicks in when attempting 2 wrong passwords in a row.

These bans will clear after 30mins but you can unban the IPs using the Supabase CLI [https://supabase.com/docs/guides/cli](https://supabase.com/docs/guides/cli) following the commands below.

How to list the banned IPs:

`
% supabase network-bans get --project-ref <project_reference_id> --experimental
`

How to unban the IPs:

`
% supabase network-bans remove --db-unban-ip <ip_address> --project-ref <project_reference_id> --experimental
`

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_error_index_row_size_exceeds_btree_version_4_maximum_for_index_LMmoeU.md">
# Error: index row size exceeds btree version 4 maximum for index

Last edited: 2/4/2025

* * *

## Error [\#](https://supabase.com/docs/guides/troubleshooting/error-index-row-size-exceeds-btree-version-4-maximum-for-index-LMmoeU\#error)

`
index row size exceeds btree version 4 maximum 2704 for index "idx_name"
`

## Summary [\#](https://supabase.com/docs/guides/troubleshooting/error-index-row-size-exceeds-btree-version-4-maximum-for-index-LMmoeU\#summary)

PG has a limit on a B-tree tuple(=row) size. It needs to fit at least 3 B-tree tuples on a 8Kb page. That could not be changed.

B-tree row can be a single attribute or multiple attributes. These cases are better addressed separately.

## B-tree is built with multiple attributes [\#](https://supabase.com/docs/guides/troubleshooting/error-index-row-size-exceeds-btree-version-4-maximum-for-index-LMmoeU\#b-tree-is-built-with-multiple-attributes)

B-tree with multiple attributes will perform better than several only in case the likely SELECT queries use several attributes that include the first attributes that are in the index. I.e. select by 1-st, 2-nd, 3-d but not by 2-nd, 3-d and 5-th index attributes.

The other case when multiple attributes B-tree is good is when we have INSERT/UPDATE workload that is comparable to SELECT load (generally SELECTS a way more often). Then we can save speed-up updating a single index instead of several at INSERT/UPDATE at cost of SELECT performance decrease.

But most likely we have multiple attributes B-tree index due to some automation tool, not by intention. Even without the mentioned error it's best to build separate single-attribute indexes for each attribute from it. Then drop multiple attributes B-tree index. This is a must and the only solution when we have this error though.

## B-tree is built on a single attribute that is very long [\#](https://supabase.com/docs/guides/troubleshooting/error-index-row-size-exceeds-btree-version-4-maximum-for-index-LMmoeU\#b-tree-is-built-on-a-single-attribute-that-is-very-long)

This can be if the index is built on text, JSON column etc. It's not prohibited to build B-tree on these datatypes, but it's also ineffective. Why?

One of the measures of index efficiency is the ratio of index entries to the width of all possible values space for this datatype. If we have say 100000 distinct values of int32 in the index then the ratio is 1/40000. If we have text with length of 2704 bytes (maximum for B-tree index) we can hardly imagine the number of distinct values that gives us even a comparable ratio. That said indexing of that long values stores much redundancy in the index.

The solution is simple: use some king of hashing to transfer the values to much narrower space. I.e. md5. The solution is simple, you build a functional index (=index by expression):

`
CREATE INDEX ON table_name(MD5(column_name));
`

instead of:

`
CREATE INDEX ON table_name(column_name);
`

Then you must modify you SELECTs to be using the same function (otherwise the functional index will not be used in SELECT queries). I.e.

`
select * from table_name where MD5(column_name) = MD5('search_value');
`

instead of

`
select * from table_name where column_name = 'search_value';
`

[More on building index by expression](https://www.postgresql.org/docs/current/sql-createindex.html)

For some datatypes other than text that allows queries by partial inclusion (i.e. that the pair key-value is includes in a JSON or for implementing tsvector phrase search) you'd just use GIST/GIN indexes that inherently have values space much narrower that the whole to be indexed.

[More on GIN/GiST indexes](https://www.postgresql.org/docs/15/textsearch-indexes.html)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_error_invalid_totp_code_entered_CukLCj.md">
# Error: "Invalid TOTP code entered"

Last edited: 2/21/2025

* * *

This error would generally happen if there is an incorrect device clock setting and there is no time sync. Check and make sure your device clock shows the correct local time, date, and time zone to work properly.

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_error_no_pghbaconf_entry_for_host_xxxxxxxxxxx_user_postgres_database_postgres_ssl_off_GOt5Ja.md">
# error: no pg\_hba.conf entry for host "xx.xxx.xxx.xxx", user "postgres", database "postgres", SSL off

Last edited: 1/18/2025

* * *

This error indicates a failed authentication attempt to the database and the connection couldn't be established.

In Supabase, this is generally seen when [SSL enforcement](https://supabase.com/docs/guides/platform/ssl-enforcement) is enabled on your Supabase Project. The authentication failed because the incoming connection didn't use SSL encryption when connecting to the database.

You can ignore this message if the attempt is from an unknown user. If you want this connection attempt to be successful, you will either need to connect with SSL or disable SSL enforcement on your Supabase project.

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_error_prepared_statement_xxx_already_exists_3laqeM.md">
# Error: prepared statement "XXX" already exists

Last edited: 1/17/2025

* * *

This error occurs when you are trying to connect to the database using PgBouncer. PgBouncer does not support prepared statements. If you have prepared statements in use, you will need to use direct connections - port 5432.

There is a special parameter in the query string for Prisma to work with PgBouncer
[https://www.prisma.io/docs/guides/performance-and-optimization/connection-management/configure-pg-bouncer](https://www.prisma.io/docs/guides/performance-and-optimization/connection-management/configure-pg-bouncer)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_exhaust_disk_io.md">
# High Disk I/O

Last edited: 2/28/2025

* * *

## Understanding disk IO and disk IO budget [\#](https://supabase.com/docs/guides/troubleshooting/exhaust-disk-io\#understanding-disk-io-and-disk-io-budget)

Disk IO refers to two metrics: throughput in Megabits per Second and IOPS which are Input/Output Operations per Second. Depending on the compute add-on of your instance you will have [different baseline performances](https://supabase.com/docs/guides/platform/compute-add-ons#compute-size).

Smaller compute instances can burst and exceed their baseline performance for a short quota of time every day. This is represented as your Disk IO Budget and once your Disk IO Budget is consumed, your instance reverts back to its baseline performance. Learn more about [choosing the right compute instance for consistent disk performance](https://supabase.com/docs/guides/platform/compute-add-ons#choosing-the-right-compute-instance-for-consistent-disk-performance).

## Depleting your disk IO budget [\#](https://supabase.com/docs/guides/troubleshooting/exhaust-disk-io\#depleting-your-disk-io-budget)

Running out of Disk IO Budget means that your instance is using more disk than its compute add-on can handle and essentially gets throttled. This could have a wide range of implications:

- Response times on requests can increase noticeably
- CPU usage rises noticeably due to IO wait
- Disruption of [daily backup](https://supabase.com/docs/guides/platform/backups#daily-backups) routines
- Disruption of internal Postgres processes such as [autovacuuming](https://supabase.com/docs/guides/platform/database-size#vacuum-operations)
- Your instance may become unresponsive

## Monitor your disk IO budget [\#](https://supabase.com/docs/guides/troubleshooting/exhaust-disk-io\#monitor-your-disk-io-budget)

To check your Disk IO Budget on the Supabase Platform, head over to [Database Health in the Reports section](https://supabase.com/dashboard/project/_/reports/database).

It is also possible to monitor your resources and set up alerts using Prometheus/Grafana. With Grafana you will be able to pinpoint potential causes and see more fine-grained metrics like how much of your RAM is used for caching and your Swap usage. Read the [Metrics Guide](https://supabase.com/docs/guides/platform/metrics) to learn more.

## Common reasons for high disk IO usage [\#](https://supabase.com/docs/guides/troubleshooting/exhaust-disk-io\#common-reasons-for-high-disk-io-usage)

Most operations on your Supabase project require disk IO in some form. Hence, there can be many reasons for high disk IO usage. Here are some common ones:

- **High Memory Usage:** Every Supabase project has 1GB of disk allocated for swapping. When your memory usage is high, the operating system might frequently move parts of the memory back and forth of the swap space on the disk.
- **Low Cache Usage:** If your cache hit rate is low, many of your database requests might go straight to the disk. Go to the [Cache Hit Rate Guide](https://supabase.com/docs/guides/platform/performance#hit-rate) to learn more.
- **Query performance:**Queries that take a long time to complete (>1 second) could be using your disk inefficiently. Check our guide on[examining query performance](https://supabase.com/docs/guides/platform/performance#examining-query-performance).
- **High popularity:** Congrats! Your side project turned out to be a real success and is getting more requests than it can handle.

## How to fix [\#](https://supabase.com/docs/guides/troubleshooting/exhaust-disk-io\#how-to-fix)

1. **Upgrade your compute:**You can get a Compute Add-on for your project. Larger compute options (4XL and above) have more consistent disk performance. See your[upgrade options](https://supabase.com/dashboard/project/_/settings/compute-and-disk)by selecting your project. Do reference the [different baseline performances](https://supabase.com/docs/guides/platform/compute-add-ons#compute-size) that come with larger Compute Add-ons.
2. **Optimize performance:**Get more out of your instance's resources by optimizing your usage. Have a look at our[performance tuning guide](https://supabase.com/docs/guides/platform/performance#examining-query-performance)and our[production readiness guide](https://supabase.com/docs/guides/platform/going-into-prod#performance).

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_exhaust_ram.md">
# High RAM usage

Last edited: 2/3/2025

* * *

High memory usage doesn't necessarily mean that your instance is at risk. Memory that is used for caching and buffers improves data access speed. But if you notice less performance alongside high memory usage, your memory usage might be unhealthy.

## Base memory usage [\#](https://supabase.com/docs/guides/troubleshooting/exhaust-ram\#base-memory-usage)

You may observe elevated memory usage even when your database has little to no load. Supabase requires a wide range of services other than Postgres to operate, which can result in an elevated base memory usage. Especially on the smallest compute instance that comes with 1 GB of RAM, it is not unusual for your project to have a base memory usage of ~50%.

## Issues with high memory usage [\#](https://supabase.com/docs/guides/troubleshooting/exhaust-ram\#issues-with-high-memory-usage)

Every Supabase project runs in its own dedicated virtual machine. Your instance will have a different set of hardware provisioned depending on your [compute add-on](https://supabase.com/docs/guides/platform/compute-add-ons). Depending on your workload, your compute hardware may not be suitable and can result in high RAM usage.

A good proxy for unhealthy memory usage is swap usage. If you run out of RAM, your system will offload memory to your disk's much slower swap partition. If your swap is above 70%, chances are high that your compute hardware is not suitable for your workload. Head over to your project's [Database Health](https://supabase.com/dashboard/project/_/reports/database) to see your swap usage.

High RAM usage could come with a range of issues:

- degraded performance overall when your instance has to use swap memory
- the operating system may start killing processes as your system runs out of memory
- in rare cases, your instance may become unresponsive

## Monitor your RAM [\#](https://supabase.com/docs/guides/troubleshooting/exhaust-ram\#monitor-your-ram)

To check your RAM usage on the Supabase Platform, head over to [Database Health in the Reports section](https://supabase.com/dashboard/project/_/reports/database).

It is also possible to monitor your resources and set up alerts using Prometheus/Grafana. With Grafana you will be able to see how much of your RAM is used for caching and you can track other metrics such as your Swap usage. Read the [Metrics Guide](https://supabase.com/docs/guides/platform/metrics) to learn more.

## Common reasons for high RAM usage [\#](https://supabase.com/docs/guides/troubleshooting/exhaust-ram\#common-reasons-for-high-ram-usage)

Everything you do with your Supabase project requires memory in some form. Hence, there can be many reasons for high RAM usage. Here are some common ones:

- **Query performance:**Queries that take a long time to complete (>1 second) could be using your RAM inefficiently. Check our guide on[examining query performance](https://supabase.com/docs/guides/platform/performance#examining-query-performance).
- **Too many connections:**Every connection to your database consumes memory. You can check the number of active connections under [Database Roles](https://supabase.com/dashboard/project/_/database/roles) after you select your project. Read our guide on [too many open connections](https://supabase.com/docs/guides/platform/troubleshooting#too-many-open-connections).
- **Extensions:**Some extensions such as `timescaledb` or `pg_cron` can use a lot of memory. It can also add up when you have too many extensions running. You can manage your database extensions in the dashboard under [Extensions](https://supabase.com/dashboard/project/_/database/extensions).

## How to fix your memory issues [\#](https://supabase.com/docs/guides/troubleshooting/exhaust-ram\#how-to-fix-your-memory-issues)

1. **Upgrade your compute:**You can get a Compute Add-on for your project. See your [upgrade options](https://supabase.com/dashboard/project/_/settings/compute-and-disk) by selecting your project.
2. **Optimize performance:**Get more out of your instance's resources by optimizing your usage. Have a look at our[performance tuning guide](https://supabase.com/docs/guides/platform/performance#examining-query-performance)and our[production readiness guide](https://supabase.com/docs/guides/platform/going-into-prod#performance).

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_exhaust_swap.md">
# High swap usage

Last edited: 2/3/2025

* * *

Learn what high Swap usage means, what can cause it, and how to solve it.

## What is swap for? [\#](https://supabase.com/docs/guides/troubleshooting/exhaust-swap\#what-is-swap-for)

High Swap is usually not a problem unless other resources (such as RAM) are constrained.

Every Supabase project runs on its own dedicated virtual machine. The machine's underlying specs and hardware depend on your [compute add-on](https://supabase.com/docs/guides/platform/compute-add-ons). If your hardware isn't suitable for your workload, you might experience high Swap usage.

Swap is a portion of your instance's disk that is reserved for the operating system to use when the available RAM has been utilized. As it uses the disk, Swap is slower to access and is generally used as a last resort.

Swap can be used even if your instance has plenty of RAM. If this is the case, do not worry. Your instance might try to "preemptively swap" by swapping background processes to make space for your traffic in RAM.

### When is high swap concerning? [\#](https://supabase.com/docs/guides/troubleshooting/exhaust-swap\#when-is-high-swap-concerning)

High Swap is concerning if your instance is using all of the available RAM (i.e. consistently using more than 75%).

High Swap usage can affect your database performance. For example, you might see:

- **Slower query responses.**
- **Degraded performance due to swapping regularly between RAM and disk.**
- **Higher Disk I/O due to swapping regularly.**

## Monitor your swap [\#](https://supabase.com/docs/guides/troubleshooting/exhaust-swap\#monitor-your-swap)

You can check your Swap usage directly on the Supabase Platform. Navigate to the [**Database** page](https://supabase.com/dashboard/project/_/reports/database) of the **Reports** section.

You can also monitor your resources and set up alerts using Prometheus/Grafana. See the [metrics guide](https://supabase.com/docs/guides/platform/metrics) for more information.

An [example repository](https://github.com/supabase/supabase-grafana) to ingest metrics and visualize them with Grafana is provided in the linked guide, where we maintain a [list of the exported metrics](https://github.com/supabase/supabase-grafana/blob/main/docs/metrics.md).

Some useful metrics to monitor are (this is not an exhaustive list):

- `node_memory_SwapFree_bytes` \- The total amount of Swap available in bytes.
- `node_disk_io_time_seconds_total` and `node_disk_io_now` \- The amount of time spent on disk I/O. An increase might be an indirect sign of excessive swapping, but not always.
- `node_memory_MemTotal_bytes` and `node_memory_MemFree_bytes` \- The total RAM and available RAM.
- `node_vmstat_pswpin` and `node_vmstat_pswpout` \- The number of pages that have been swapped in or out (monitoring this for spikes means that your instance is swapping).

## Common reasons for high swap usage [\#](https://supabase.com/docs/guides/troubleshooting/exhaust-swap\#common-reasons-for-high-swap-usage)

Everything you do with your Supabase project requires compute. Hence, there can be many reasons for high Swap usage. Here are some common ones:

- **Query performance:** You might have high read traffic or queries that process a large amount of data on disk (this can happen even if you are returning a small amount of data).
- **Missing indexes:** Your database might have to scan through a large amount of data to find the information it needs. Creating indexes helps your database find data faster. See the [indexes guide](https://supabase.com/docs/guides/database/postgres/indexes) to learn more.
- **Unsuitable compute:** The compute size of your Supabase project might not be suitable for your application as you might have more traffic or run resource-intensive operations.
- **Workload style:** The usage pattern of your Supabase project might be more read heavy, or involve large amounts of data.
- **Extensions:** You might be using extensions that perform intensive operations on large datasets. This increases resource usage.

## Solving high swap usage [\#](https://supabase.com/docs/guides/troubleshooting/exhaust-swap\#solving-high-swap-usage)

If you find that your RAM and Swap usage are high, you have three options:

1. **Optimize performance:** Get more out of your instance's resources by optimizing your usage. See the [performance tuning guide](https://supabase.com/docs/guides/platform/performance#examining-query-performance) and our [production readiness guide](https://supabase.com/docs/guides/platform/going-into-prod#performance).
2. **Upgrade your compute:** You can get a Compute Add-on for your project. Follow [this link](https://supabase.com/dashboard/project/_/settings/compute-and-disk) and select your project to see your upgrade options.
3. **Read Replicas:** You can spread the load on your Supabase project by creating a Read Replica. See [the read replicas guide](https://supabase.com/docs/guides/platform/read-replicas) for more information.

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_failed_to_fetch_in_dashboard_and_other_areas____browser_extension_dyDTRU.md">
# Failed to Fetch in dashboard and other areas -- browser extension

Last edited: 1/18/2025

* * *

Although Failed to Fetch can occur for a variety of reasons a common one in the dashboard or when using update code is related to a browser extension.

![image](https://supabase.com/docs/img/troubleshooting/7fe991ac-40ea-4628-a5e3-181d706225ea.png)

[https://chrome.google.com/webstore/detail/allow-cors-access-control/lhobafahddgcelffkeicbaginigeejlf](https://chrome.google.com/webstore/detail/allow-cors-access-control/lhobafahddgcelffkeicbaginigeejlf)

This extension sets PATCH to be blocked by default for some reason...

![168501713-5f020510-4555-4cc3-84de-582efc1c62de](https://github.com/supabase/supabase/assets/54564956/c61b9292-2954-4c68-8129-995941f36210)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_failed_to_restore_from_backup_all_subscriptions_and_replication_slots_must_be_dropped_before_a_backup_can_be_restored_L_rCvt.md">
# Failed to restore from backup: All subscriptions and replication slots must be dropped before a backup can be restored.

Last edited: 1/18/2025

* * *

As the error suggests, you must first drop any current subscriptions or replication slots to restore backups.

You can check those with:

`
SELECT * FROM pg_replication_slots;
SELECT * FROM pg_subscription;
`

You can drop them with:

`
DROP SUBSCRIPTION <subscription>;
SELECT pg_drop_replication_slot(slot_name);
`

NOTE: These are destructive actions. This is fine since you will overwrite your database with a backup.

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_fetch_requests_to_api_endpoints_arent_showing_the_session_UbUwRs.md">
# Fetch requests to API endpoints aren't showing the session

Last edited: 1/18/2025

* * *

You must pass along the cookie header with the fetch request in order for your API endpoint to get access to the cookie from this request.

`
const res = await fetch('http://localhost:3000/contact', {
headers: {
    cookie: headers().get('cookie') as string,
},
})
`

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_fixing_520_errors_in_the_database_rest_api_Ur5_B2.md">
# Fixing 520 Errors in the Database REST API

Last edited: 1/17/2025

* * *

In the context of the database API, [Cloudflare 520 errors](https://developers.cloudflare.com/support/troubleshooting/cloudflare-errors/troubleshooting-cloudflare-5xx-errors/#error-520-web-server-returns-an-unknown-error) most often occur when 16+KB worth of data is present in the headers/URL of your requests.

The API will include filters within the URL, so a request like so:

`
let { data: countries, error } = await supabase.from('countries').select('name')
`

translates to a URL like:

`
https://<project ref>.supabase.co/rest/v1/countries?select=name
`

However, appending too much data to the URL can exceed the 16KB limitation, triggering a 520 failure. This typically occurs with lengthy `in` clauses, as demonstrated here:

`
const { data, error } = await supabase
.from('countries')
.select()
.not('id', 'in', '(5,6,7,8,9,...10,000)')
`

To circumvent this issue, you must use [RPCs](https://supabase.com/docs/reference/javascript/explain?queryGroups=example&example=call-a-postgres-function-with-arguments). They are database functions that you can call from the API. Instead of including a query's structure within the URL or header, they move it into the request's payload.

Here is a basic example of a [database function](https://supabase.com/docs/guides/database/functions)

`
create or replace function example(id uuid[])
returns uuid[]
language plpgsql
as $$
begin
raise log 'the function example was called with an array size of: %', (select array_length(id, 1));
return id;
end;
$$;
`

The [RPC](https://supabase.com/docs/reference/javascript/explain?queryGroups=example&example=call-a-postgres-function-with-arguments) can then call the function with an array that contains more than 16KB of data

`
const { data, error } = await supabase.rpc('example', { id: ['e2f34fb9-bbf9-4649-9b2f-09ec56e67a42', ...900 more UUIDs] })
`

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_forbidden_resource_error_from_the_cli_L6rm6l.md">
# Forbidden resource error from the CLI

Last edited: 2/21/2025

* * *

This error typically occurs as a protective measure to prevent unauthorized access to critical operations.

To address this issue, we recommend following these troubleshooting steps:

- Verify Project ID: Ensure the $PROJECT\*REF variable in your commands contains the correct Project ID. You can find your Reference ID under [Project -> Settings -> General](https://supabase.com/dashboard/project/*/settings/general) in your Supabase Dashboard. A Reference ID looks something like `xvljpkujuwroxcuvossw`.
- Authorization Check: Confirm that youve been properly authorized. You can also generate a new Access Token in your dashboard and use it for login. Generate a new token [here](https://supabase.com/dashboard/account/tokens) and use it to [log in](https://supabase.com/docs/reference/cli/supabase-login).
- Re-link Project: Try [re-linking](https://supabase.com/docs/reference/cli/supabase-link) your project with the newly generated token.
- Owner/Admin Permissions: Make sure you have [Owner/Admin](https://supabase.com/docs/guides/platform/access-control) permissions for the project.
- CLI Version: Ensure you are using the latest version of the Supabase CLI. If not, update to the most recent version available at [Supabase CLI GitHub](https://github.com/supabase/cli).

If the issue persists, add a --debug --create-ticket flags to your command and contact [support](https://supabase.com/support) with the ticket id and debug logs, which can help in diagnosing the problem further.

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_google_auth_fails_for_some_users_XcFXEu.md">
# Google Auth fails for some users

Last edited: 1/17/2025

* * *

## Google Auth fails for some users [\#](https://supabase.com/docs/guides/troubleshooting/google-auth-fails-for-some-users-XcFXEu\#google-auth-fails-for-some-users)

If you start facing either of these errors:

`
error=server_error&error_description=Error+getting+user+email+from+external+provider
Missing required authentication credential.
Expected OAuth 2 access token, login cookie or other valid authentication credential.
See https://developers.google.com/identity/sign-in/web/devconsole-project.\",\n \"status\": \"UNAUTHENTICATED\"
}
"level":"error","method":"GET","msg":"500: Error getting user email from external provider","path":"/callback","referer":"https://accounts.google.com/","remote_addr":"x.x.X.x","time":"2023-06-06T21:46:11Z","timestamp":"2023-06-06T21:46:11Z"}
`

It is happening because some Google Suite requires the explicit request of email Auth Scopes:
`https://www.googleapis.com/auth/userinfo.email`

`
const { data, error } = await supabase.auth.signInWithOAuth({
provider: 'google'
options: {
    scopes: 'https://www.googleapis.com/auth/userinfo.email'
}
})
`

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_grafana_not_displaying_data_sXJrMj.md">
# Grafana not displaying data

Last edited: 2/4/2025

* * *

This guide is for identifying configuration mistakes in [self-hosted Supabase Grafana installations](https://supabase.com/docs/guides/monitoring-troubleshooting/metrics#deploying-supabase-grafana)

## Step 1: Ping your Grafana endpoint [\#](https://supabase.com/docs/guides/troubleshooting/grafana-not-displaying-data-sXJrMj\#step-1-ping-your-grafana-endpoint)

Use the below cURL command to make sure your metrics endpoint returns data:

`
curl https://<YOUR_PROJECT_REF>.supabase.co/customer/v1/privileged/metrics --user 'service_role:<SERVICE_ROLE_KEY>'
`

## Step 2: Set your Grafana Dashboard to auto-refresh in the top right corner [\#](https://supabase.com/docs/guides/troubleshooting/grafana-not-displaying-data-sXJrMj\#step-2-set-your-grafana-dashboard-to-auto-refresh-in-the-top-right-corner)

![388343266-ed4b8f38-e0cd-474e-bc1c-1ac6ae68e1aa](https://supabase.com/docs/img/troubleshooting/47998bed-0b77-433a-bfed-63222beb2aee.png)

## Step 3: Make sure your docker container has the default configurations [\#](https://supabase.com/docs/guides/troubleshooting/grafana-not-displaying-data-sXJrMj\#step-3-make-sure-your-docker-container-has-the-default-configurations)

Run the following command in the terminal:

`
docker ps -f name=supabase-grafana
`

The output should look something like this:

![image](https://supabase.com/docs/img/troubleshooting/6c284180-0ffd-432d-b86b-e9fbcfe23868.png)

Here it is in an easier to read format

`
- CONTAINER ID: < container id >
- IMAGE: supabase-grafana-supabase-grafana
- COMMAND: /entrypoint.sh
- CREATED: < time >
- STATUS: Up < unit of time > ago
- PORTS: 3000/tcp, 0.0.0.0:8000  8080/tcp
- NAMES: supabase-grafana-supabase-grafana-1
`

## Step 4: Enter the container [\#](https://supabase.com/docs/guides/troubleshooting/grafana-not-displaying-data-sXJrMj\#step-4-enter-the-container)

Try running the following terminal command:

`
docker exec -it <container id> bash
`

## Step 5: Check the environment variables for errors [\#](https://supabase.com/docs/guides/troubleshooting/grafana-not-displaying-data-sXJrMj\#step-5-check-the-environment-variables-for-errors)

Run the following in the docker container:

`
printenv | egrep 'GRAFANA_PASSWORD|SUPABASE_PROJECT_REF|SUPABASE_SERVICE_ROLE_KEY'
`

Ensure the values are correct by comparing them with those in the Dashboard. Users have previously encountered issues by accidentally omitting the last character of their strings, so a thorough check is essential.

## Step 6: Go to the root folder and check permissions on the `entrypoint.sh` file [\#](https://supabase.com/docs/guides/troubleshooting/grafana-not-displaying-data-sXJrMj\#step-6-go-to-the-root-folder-and-check-permissions-on-the-entrypointsh-file)

Run the following terminal commands:

`
cd /
ls -l | grep entrypoint.sh
`

`entrypoint.sh` should have the following permissions:

`
-rwxr-xr-x
`

If off, update the values

`
chmod +x entrypoint.sh
`

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_high_cpu_usage.md">
# High CPU usage

Last edited: 2/3/2025

* * *

Learn what high CPU usage could mean for your Supabase instance and what could have caused it.

## The danger of high CPU usage [\#](https://supabase.com/docs/guides/troubleshooting/high-cpu-usage\#the-danger-of-high-cpu-usage)

Every Supabase project runs in its dedicated virtual machine. Your instance will have a different set of hardware provisioned depending on your [compute add-on](https://supabase.com/docs/guides/platform/compute-add-ons). Your hardware may not be suitable for the intended workload and may experience high CPU usage.

High CPU usage could come with a range of issues:

- slower queries
- disruption of daily backup routines
- in rare cases, your instance may become unresponsive

Moreover, your instance might not be able to handle future traffic spikes if it already has a high CPU usage.

## Monitor your CPU [\#](https://supabase.com/docs/guides/troubleshooting/high-cpu-usage\#monitor-your-cpu)

You can check your CPU usage directly on the Supabase Platform. For this go to database health in the reports section or [click here](https://supabase.com/dashboard/project/_/reports/database) and select your project.

![CPU usage reported on Supabase dashboard](https://supabase.com/docs/img/guides/platform/exhaust-cpu-report.png)

It is also possible to monitor your resources and set up alerts using Prometheus/Grafana. You can find a guide for this [here](https://supabase.com/docs/guides/platform/metrics).

## Common reasons for high CPU usage [\#](https://supabase.com/docs/guides/troubleshooting/high-cpu-usage\#common-reasons-for-high-cpu-usage)

Everything you do with your Supabase project requires compute. Hence, there can be many reasons for high CPU usage. Here are some common ones:

- **Query performance:** Queries that take a long time to complete (>1 second) as well as excessive amounts of querying can put a strain on the CPU. Check our guide on [examining query performance](https://supabase.com/docs/guides/platform/performance#examining-query-performance).
- **Missing indexes:** Your database might have to scan through a large amount of data to find the information it needs. Creating indexes helps your database find data faster. Learn more about indexes [here](https://supabase.com/docs/guides/database/postgres/indexes).
- **Unsuitable compute:** The compute size of your Supabase project might not be suitable for your application as you might have more traffic or run resource-intensive operations.

## Solving high CPU usage [\#](https://supabase.com/docs/guides/troubleshooting/high-cpu-usage\#solving-high-cpu-usage)

There are two ways to solve high CPU:

1. **Optimize performance:** Get more out of your instance's resources by optimizing your usage. Have a look at our [performance tuning guide](https://supabase.com/docs/guides/platform/performance#examining-query-performance) and our [production readiness guide](https://supabase.com/docs/guides/platform/going-into-prod#performance).
2. **Upgrade your compute:** You can get a Compute Add-on for your project. Follow [this link](https://supabase.com/dashboard/project/_/settings/compute-and-disk) and select your project to see your upgrade options.

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_high_latency_with_supabase_client_z0pZzR.md">
# High latency with supabase client

Last edited: 2/4/2025

* * *

## Describe the bug [\#](https://supabase.com/docs/guides/troubleshooting/high-latency-with-supabase-client-z0pZzR\#describe-the-bug)

Querying a table using the Supabase client is much slower than querying against the Postgres database directly.

## To reproduce [\#](https://supabase.com/docs/guides/troubleshooting/high-latency-with-supabase-client-z0pZzR\#to-reproduce)

1. Execute the below DDL statements.

`
-- Create table
CREATE TABLE your_table_name (
    id UUID PRIMARY KEY,
    column1 TEXT,
    column2 INT,
    column3 BOOLEAN
);
-- Insert statements
INSERT INTO your_table_name (id, column1, column2, column3) VALUES
    (uuid_generate_v4(), 'value1', 10, TRUE),
    (uuid_generate_v4(), 'value2', 20, FALSE),
    (uuid_generate_v4(), 'value3', 15, TRUE),
    (uuid_generate_v4(), 'value4', 8, FALSE),
    (uuid_generate_v4(), 'value5', 25, TRUE),
    (uuid_generate_v4(), 'value6', 12, FALSE),
    (uuid_generate_v4(), 'value7', 18, TRUE),
    (uuid_generate_v4(), 'value8', 30, FALSE),
    (uuid_generate_v4(), 'value9', 22, TRUE),
    (uuid_generate_v4(), 'value10', 5, FALSE),
    (uuid_generate_v4(), 'value11', 17, TRUE),
    (uuid_generate_v4(), 'value12', 9, FALSE),
    (uuid_generate_v4(), 'value13', 14, TRUE),
    (uuid_generate_v4(), 'value14', 28, FALSE),
    (uuid_generate_v4(), 'value15', 11, TRUE),
    (uuid_generate_v4(), 'value16', 7, FALSE),
    (uuid_generate_v4(), 'value17', 19, TRUE),
    (uuid_generate_v4(), 'value18', 26, FALSE),
    (uuid_generate_v4(), 'value19', 16, TRUE),
    (uuid_generate_v4(), 'value20', 21, FALSE);
`

2. Run the following script (you may need to `pip install psycopg[binary]` in addition to Supabase client.

`
import time
from supabase import Client, create_client
import psycopg
def psycop_call(): #user_ids: list[str]):
    user="YOUR_SUPABASE_USER"
    password="YOUR_SUPABASE_PASSWORD"
    host="SUPABASE_HOST"
    port=5432
    database="postgres"
    with psycopg.connect(f"host={host} port={port} dbname={database} user={user} password={password}") as conn:
        # Open a cursor to perform database operations
        results = []
        with conn.cursor() as cur:
            start = time.time()
            # Execute a command: this creates a new table
            cur.execute("SELECT * FROM public.your_table_name")
            cur.fetchall()
            for record in cur:
                results.append(record)
            stop = time.time()
            return (stop - start)
def supabase_call():
    supabase: Client = create_client("SUPABASE_URL", "SUPBASE_SERVICE_ROLE_KEY")
    start = time.time()
    result = supabase.table("your_table_name").select("*").execute()
    stop = time.time()
    return (stop - start)
if __name__ == "__main__":
    ref = psycop_call()
    sup = supabase_call()
    print(f"postgres: {ref}, supabase: {sup}, ratio: {sup/ref}")
`

3. You will see that the Supabase client takes longer to execute the same query, especially for smaller tables or queries returning just one row.

## Expected behavior [\#](https://supabase.com/docs/guides/troubleshooting/high-latency-with-supabase-client-z0pZzR\#expected-behavior)

The overhead from PostgREST shouldn't be higher than a few milliseconds at max. 60-70 ms is way too high. This is particular deceiving because one can run the query on the SQL Editor page and it reports the same time as the direct Postgres query, which is not what actually happens.

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_how_can_i_revoke_execution_of_a_postgresql_function_2GYb0A.md">
# How can I revoke execution of a PostgreSQL function?

Last edited: 1/17/2025

* * *

All functions access is PUBLIC by default, this means that any role can execute it. To revoke execution, there are 2 steps required:

- Revoke function execution ( `foo` in this case) from PUBLIC:

`
revoke execute on function foo from public;
`

- Revoke execution from a particular role ( `anon` in this case):

`
revoke execute on function foo from anon;
`

Now `anon` should get an error when trying to execute the function:

`
begin;
set local role anon;
select foo();
ERROR:  permission denied for function foo
`

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_how_do_i_check_gotrueapi_version_of_a_supabase_project_lQAnOR.md">
# How do I check GoTrue/API version of a Supabase project?

Last edited: 1/17/2025

* * *

Make a `GET` request to the health check endpoint to retrieve this information. Below is an example using `curl`:

`
curl -X GET 'https://project-ref.supabase.co/auth/v1/health' -H 'apikey: ANON_KEY'
{
    "version": "v2.60.7",
    "name": "GoTrue",
    "description": "GoTrue is a user registration and authentication API"
}
`

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_how_do_i_make_the_cookies_httponly_vwweFx.md">
# How do I make the cookies HttpOnly?

Last edited: 1/17/2025

* * *

This is not necessary. Both the access token and refresh token are designed to be passed around to different components in your application. The browser-based side of your application needs access to the refresh token to properly maintain a browser session anyway.

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_how_do_i_reset_my_supabase_database_password_oTs5sB.md">
# How do I reset my Supabase database password?

Last edited: 1/17/2025

* * *

You can reset your database password from the [database settings page](https://supabase.com/dashboard/project/_/settings/database) on the project dashboard.

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_how_do_i_update_connection_pool_settings_in_my_dashboard_wAxTJ_.md">
# How do I update connection pool settings in my dashboard?

Last edited: 2/21/2025

* * *

Common questions about updating settings for PgBouncer or Supavisor:

- How to tell which connection pooler you're using:
The PgBouncer connection string looks like: `postgres://postgres:[YOUR-PASSWORD]@db.xxxxxxxxxx.supabase.co:6543/postgres`

The Supavisor connection string looks like: `postgres://postgres.xxxxxxxxx:[YOUR-PASSWORD]@aws-0-us-west-1.pooler.supabase.com:6543/postgres`

The subdomain will vary depending on the region a project is deployed in. The project reference is to be included in the username following a `.`. If the username is `postgres` the username you use for Supavisor is `postgres.[PROJECT_REF]`.

- How to update the size of the connection pool to the database:
You can set the `Max Client Connections` field in your database settings here:

[https://supabase.com/dashboard/project/\_/settings/database](https://supabase.com/dashboard/project/_/settings/database)

- How to change the client connection limit:
You can set the `Default Pool Size` field in your database settings:

[https://supabase.com/dashboard/project/\_/settings/database](https://supabase.com/dashboard/project/_/settings/database)

- How to use `session` mode:
With Supavisor you can automatically use `session` mode by using the connection string with port `5432` in it.

You can also set the pooler port 6543 to use `session` mode in the database settings:

[https://supabase.com/dashboard/project/\_/settings/database](https://supabase.com/dashboard/project/_/settings/database)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_how_do_you_troubleshoot_nextjs___supabase_auth_issues_riMCZV.md">
# How do you troubleshoot Next.js - Supabase Auth issues?

Last edited: 2/21/2025

* * *

Authentication is hard. SSR is harder. At Supabase, we try to address these together by providing `@supabase/ssr` package to help implement authentication with Supabase conveniently. While Im targeting to address Next.js-related issues, you can probably apply these concepts to other SSR frameworks such as Nuxt, SvelteKit, and Remix. This is a living document, and we plan to update it regularly as Next.js and its APIs + `@supabase/ssr` evolve.

If you are experiencing issues with Supabase Auth and SSR, the following checklist will help you troubleshoot the issues.

 Youre on the latest version of `@supabase/ssr` package. Note that the `@supabase/auth-helpers` package is being deprecated, and all the bug fixes and feature releases will be focused on the `@supabase/ssr` package.
 Do you have all the client utility functions implemented? This way, you can import them into your components that need access to Supabase auth functions. Make sure to follow the [guide available here](https://supabase.com/docs/guides/auth/server-side/creating-a-client?queryGroups=framework&framework=nextjs&queryGroups=environment&environment=client-component#creating-a-client) carefully to avoid running into unexpected errors.
 Do you have the `middleware.ts` file correctly implemented? This lets you refresh expired sessions before loading server components that require a user session for authorization.

This documentation will help you validate that youre on the correct path.

- Setting up Server-Side Auth for Next.js - [https://supabase.com/docs/guides/auth/server-side/nextjs?queryGroups=router&router=app](https://supabase.com/docs/guides/auth/server-side/nextjs?queryGroups=router&router=app)
- SSR advanced guide - [https://supabase.com/docs/guides/auth/server-side/advanced-guide](https://supabase.com/docs/guides/auth/server-side/advanced-guide)
- Creating a Supabase client for SSR - [https://supabase.com/docs/guides/auth/server-side/creating-a-client?queryGroups=framework&framework=nextjs&queryGroups=environment&environment=middleware](https://supabase.com/docs/guides/auth/server-side/creating-a-client?queryGroups=framework&framework=nextjs&queryGroups=environment&environment=middleware)

Another way to identify any potential issues with your code is to compare it with the Supabase Next.js quickstart. Use the command `npx create-next-app -e with-supabase` to download a copy to your local machine of the quickstart application.

Our YouTube channel has great videos to help you implement Supabase Auth with Next.js.

- The Right Way to do Auth with the Next.js App Router - [https://youtu.be/v6UvgfSIjQ0?si=TBUN9dD4pmjRg78a](https://youtu.be/v6UvgfSIjQ0?si=TBUN9dD4pmjRg78a)

Also, take some time to get familiar with some concepts on authentication with Next.js, such as [https://nextjs.org/docs/app/building-your-application/authentication](https://nextjs.org/docs/app/building-your-application/authentication).

We know your requirements vary, and you might run into an edge case. In that scenario, use our amazing community channels ( [GitHub](https://github.com/orgs/supabase/discussions), [Discord](https://discord.gg/rxTfewPvys)) to get help troubleshooting the issue. You can post your issues to the `@supabase/ssr` [GitHub repo](https://github.com/supabase/ssr/issues). We always welcome your contributions!

If none of the above works, dont hesitate to reach out to [Supabase support](https://supabase.help/); consider adding more information, such as your use case, code snippets, a copy of your `package.json`, `middleware.ts` and a HAR file, to help the support team triage your issue.

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_how_long_does_it_take_to_restore_a_database_from_a_point_in_time_backup_pitr_qO8gOG.md">
# How long does it take to restore a database from a Point-in-Time backup (PITR)?

Last edited: 1/18/2025

* * *

The time required for a PIT restoration isn't fixed. It depends on several factors:

**Time Since Last Full Backup:**

Full backups occur weekly. The time elapsed since the last full backup can affect restoration time.

**Write-Ahead Logging (WAL) Activity:**

The volume of WAL activity since the last full backup is a critical factor. More activity can lead to longer restoration times.

**Database Size:**

While important, the size of the database isn't the sole determinant of restoration time.

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_how_postgres_chooses_which_index_to_use__JHrf4.md">
# How Postgres chooses which index to use

Last edited: 2/21/2025

* * *

> For the curious: [here is a list of all built-in indexes in Postgres](https://www.postgresql.org/docs/current/indexes-types.html)

### Postgres internals [\#](https://supabase.com/docs/guides/troubleshooting/how-postgres-chooses-which-index-to-use-_JHrf4\#postgres-internals)

#### How an index is chosen [\#](https://supabase.com/docs/guides/troubleshooting/how-postgres-chooses-which-index-to-use-_JHrf4\#how-an-index-is-chosen)

Postgres, internally, contains a few components that manage query execution:

| Module | Description |
| --- | --- |
| Parser | Converts SQL into an traversable query tree |
| Planner/Optimizer | Takes the query tree and uses rules and database statistics to find the optimal strategy for getting the data |
| Executor | Executes the plan created by the planner |

The planner will consider using an index when an indexed column is present in a filter statement, such as:

- `WHERE`
- `LIKE`
- `ILIKE`
- `DISTINCT`
- `SIMILAR TO`
- `JOIN`
- `ORDER BY`

Otherwise, it will likely perform a full table scan (sequential scan).

In the majority of cases, the indexed column must not only be present but also must be filtered by a comparison operator ( `=`, `>`, `<>`) that is compatible with the index.

As an example, one can create the following table:

| Column Name | Data Type |
| --- | --- |
| id | INT |
| data | JSONB |

On the data column, a GIN index can be applied, which is excellent for filtering JSONB datatypes:

`
CREATE INDEX some_arbitary_index_name ON some_table USING gin (data);
`

Here's a [link](https://www.postgresql.org/docs/current/gist-builtin-opclasses.html) to the list operators supported by the GIN index; notably, it does not support greater than `>`:

`
-- GIN index will never be used
select *
from some_table
where data -> val > 5;
`

GIN does support the `@>` operator:

`
--GIN will be considered
SELECT id FROM some_table
WHERE data @> '[ { "itemId": "p11" } ]';
`

In most cases, developers work with the default BTREE index. It is the most practical and performant in the majority of cases and is compatible with the following filter [operators](https://www.postgresql.org/docs/current/btree-behavior.html):

| Comparison Operator |
| --- |
| `<` |
| `<=` |
| `=` |
| `>=` |
| `>` |

An operator's functional equivalents, such as `IN`, `BETWEEN`, and `ANY`, are also valid.

However, just because the base requirements (relevant column, filter, and operators) are present, doesn't mean that an index will be used.

Indexes have a startup cost, so for small tables, Postgres might use a sequential scan if it believes that it will take less time. The database keeps statistics about each table that it uses to inform these choices.

In very rare cases, these statistics can become stale, and Postgres may opt to use a slower index or sequential scan when a better option is available.

You can see the query plan with the `EXPLAIN` keyword:

`
EXPLAIN <your query>
`

To understand how to interpret its output, you can check out this [explainer](https://github.com/orgs/supabase/discussions/22839).

To reset statistics within the database, you can use the following query:

`
-- use judiciously
select pg_stat_reset();
`

### Complex or composite indexes [\#](https://supabase.com/docs/guides/troubleshooting/how-postgres-chooses-which-index-to-use-_JHrf4\#complex-or-composite-indexes)

> For a more complete rundown, check the [Postgres Official Docs](https://www.postgresql.org/docs/current/indexes-multicolumn.html)

#### Multi-column indexes [\#](https://supabase.com/docs/guides/troubleshooting/how-postgres-chooses-which-index-to-use-_JHrf4\#multi-column-indexes)

If you make independent indexes on multiple columns, Postgres will likely use each of them independently to find the relevant rows and then combine the results together.

It is possible to make [multi-column indexes](https://www.postgresql.org/docs/current/indexes-multicolumn.html). If you are regularly filtering against multiple columns, there can be performance benefits using them instead of several independent indexes.

`
-- multi-column index
create index test2_mm_idx on test2 (major, minor);
-- multi-column comparison:
select name
from test2
where major = constant and minor = constant;
`

#### Ordered indexes [\#](https://supabase.com/docs/guides/troubleshooting/how-postgres-chooses-which-index-to-use-_JHrf4\#ordered-indexes)

If you're using an ORDER BY clause, [indexes can also be pre-sorted by DESC/ASC](https://www.postgresql.org/docs/current/indexes-ordering.html) for better performance.

`
-- organizes the index in a DESC order, places NULL values at the end
CREATE INDEX test3_desc_index ON test3 (id DESC NULLS LAST);
`

#### Functional indexes [\#](https://supabase.com/docs/guides/troubleshooting/how-postgres-chooses-which-index-to-use-_JHrf4\#functional-indexes)

Although not as common, indexes can also be leveraged against modified values, such as when using a LOWER function:

`
-- Index on modified column through function
create index test1_lower_col1_idx on test1 (lower(col1));
-- Index will be considered for the following query:
select * from test1 where lower(col1) = 'value';
`

#### Covering indexes [\#](https://supabase.com/docs/guides/troubleshooting/how-postgres-chooses-which-index-to-use-_JHrf4\#covering-indexes)

Indexes contain pointers to a specific row, but you could instruct an index to actually hold a copy of a column's value for even faster retrieval. These are known as `covering` indexes. Because maintaining a copy is storage intensive, you should avoid using it for values with large data footprints. [FULL VIDEO ON TOPIC](https://www.youtube.com/watch?v=bBu_V8CfWgM)

`
CREATE INDEX a_b_idx ON x (a,b) INCLUDE (c);
`

#### Indexes on JSONB [\#](https://supabase.com/docs/guides/troubleshooting/how-postgres-chooses-which-index-to-use-_JHrf4\#indexes-on-jsonb)

Although a GIN/GIST index can be used to index entire JSONB bodies, you can also target just specific Key-values with standard BTREE indexes:

`
-- Example table
create table person (
id serial primary key,
data jsonb
);
create index index_name on person ((data ->> 'name'));
`

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_how_to_change_max_database_connections__BQ8P5.md">
# How to change max database connections

Last edited: 2/21/2025

* * *

> WARNING: Manually configuring the connection count hard codes it. This means if you upgrade or downgrade your database, the connection count will not auto-resize. You will have to make sure to manually update it.

# Changing max database connections:

Each compute instance has a default direct connection and pooler connection settings. You can find the most recent settings in the [compute docs](https://supabase.com/docs/guides/platform/compute-add-ons#disk-io):

| Compute Size | Direct Connections | Pooler Connections |
| --- | --- | --- |
| Nano (free) | 60 | 200 |
| Micro | 60 | 200 |
| Small | 90 | 400 |
| Medium | 120 | 600 |
| Large | 160 | 800 |
| XL | 240 | 1,000 |
| 2XL | 380 | 1,500 |
| 4XL | 480 | 3,000 |
| 8XL | 490 | 6,000 |
| 12XL | 500 | 9,000 |
| 16XL | 500 | 12,000 |

## Configuring direct connections limits [\#](https://supabase.com/docs/guides/troubleshooting/how-to-change-max-database-connections-_BQ8P5\#configuring-direct-connections-limits)

> Note: the Supavisor connection limits are hard-coded and cannot be changed without upgrading the compute size:

You can configure the maximum amount of connections that Postgres will tolerate with the [Supabase CLI.](https://supabase.com/docs/guides/platform/custom-postgres-config)

You can run the following commands:

`
npx supabase login
npx supabase --experimental --project-ref <PROJECT REF> postgres-config update --config max_connections=<INTEGER VALUE>
`

Then you could run the following SQL in the SQL Editor to see if the changes went through:

`
SHOW max_connections;
`

# Dangers of increasing the direct connection limits

**Three** factors must be taken into consideration when adjusting the direct connection limit:

### Process schedulers and Postgres internals: [\#](https://supabase.com/docs/guides/troubleshooting/how-to-change-max-database-connections-_BQ8P5\#process-schedulers-and-postgres-internals)

Allowing too many direct connections in your database can overburden Postgres schedulers and other internal modules. This will result in a noticeable decrease in query throughput, despite having more connections available. EnterpriseDB wrote a wonderful [article](https://www.enterprisedb.com/postgres-tutorials/why-you-should-use-connection-pooling-when-setting-maxconnections-postgres) that outlines some of the considerations.

The default connection values are set based on a solid understanding of Postgres architecture, and straying too far from them is _likely_ to hinder performance. However, with some experimentation, you might discover a value better suited to your specific needs. Still, unless there's a compelling reason to adjust the setting, it's generally advisable to stick with the defaults or change the values judiciously.'

### Memory [\#](https://supabase.com/docs/guides/troubleshooting/how-to-change-max-database-connections-_BQ8P5\#memory)

> If you do not know how to monitor memory and CPU with Supabase Grafana, [check here](https://github.com/orgs/supabase/discussions/27141).

#### Each direct connection is a running process that will consume active memory [\#](https://supabase.com/docs/guides/troubleshooting/how-to-change-max-database-connections-_BQ8P5\#each-direct-connection-is-a-running-process-that-will-consume-active-memory)

This is a Grafana Chart of unhealthy memory usage:

![image](https://supabase.com/docs/img/troubleshooting/47685206-7914-440e-a010-da62f5c38186.png)

- Yellow: represents active memory
- Red: represents SWAP, which is disk storage that the system treats as if it were actually memory
- Green: it is unclaimed (the system will always leave some memory unclaimed)
- Blue: it is cached data and a buffer

The cache in Postgres is important because the database will store frequently accessed data in it for rapid retrieval. If too much active memory is needed, it runs the risk of excessively displacing cache. This will force queries to check disk, which is slow.

Most data in a database is idle. However, when there is little available memory or uncached data is rapidly accessed, [thrashing](https://en.wikipedia.org/wiki/Thrashing_(computer_science)) can occur.

To avoid displacing cache or straining system resources, it is advised to not increase your direct connections unless you have a clear excess of unclaimed memory (green).

Postgres will allow you to overcommit memory. You can run the below query to find out the hypothetical max value you could change it to without risking memory failure:

> NOTE: You can find your server memory in the [compute add-ons docs](https://supabase.com/docs/guides/platform/compute-add-ons)

`
select
'(SERVER MEMORY - ' || current_setting('shared_buffers') || ' - (' || current_setting(
    'autovacuum_max_workers'
) || ' * ' || current_setting('maintenance_work_mem') || ')) / ' || current_setting('work_mem');
`

### CPU [\#](https://supabase.com/docs/guides/troubleshooting/how-to-change-max-database-connections-_BQ8P5\#cpu)

The below chart is an example of what can occur to the CPU if 100s of connections are inappropriately opened/closed every second or many CPU intensive queries are run in parallel

![image](https://supabase.com/docs/img/troubleshooting/0e7f6842-78fd-44f9-b463-425507815fb6.png)

If you plan on increasing your direct connection numbers, your database should have relatively predictable or low CPU usage, such as what the example displays below:

![Screenshot 2024-06-11 at 3 09 03PM](https://github.com/supabase/supabase/assets/91111415/ee3e4f4c-87a1-4ef8-9ca5-af9094fc1b93)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_how_to_check_if_my_queries_are_being_blocked_by_other_queries_NSKtR1.md">
# How to check if my queries are being blocked by other queries?

Last edited: 1/17/2025

* * *

## You can set a lock monitor view to help investigate these. [\#](https://supabase.com/docs/guides/troubleshooting/how-to-check-if-my-queries-are-being-blocked-by-other-queries-NSKtR1\#you-can-set-a-lock-monitor-view-to-help-investigate-these)

Once you run the query that takes a long time to complete, you can go in the dashboard (or select from this view below) to check what are the blocks.

`
create view
public.lock_monitor as
select
coalesce(
    blockingl.relation::regclass::text,
    blockingl.locktype
) as locked_item,
now() - blockeda.query_start as waiting_duration,
blockeda.pid as blocked_pid,
blockeda.query as blocked_query,
blockedl.mode as blocked_mode,
blockinga.pid as blocking_pid,
blockinga.query as blocking_query,
blockingl.mode as blocking_mode
from
pg_locks blockedl
join pg_stat_activity blockeda on blockedl.pid = blockeda.pid
join pg_locks blockingl on (
    blockingl.transactionid = blockedl.transactionid
    or blockingl.relation = blockedl.relation
    and blockingl.locktype = blockedl.locktype
)
and blockedl.pid <> blockingl.pid
join pg_stat_activity blockinga on blockingl.pid = blockinga.pid
and blockinga.datid = blockeda.datid
where
not blockedl.granted
and blockinga.datname = current_database();
`

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_how_to_delete_a_role_in_postgres_8_AvxY.md">
# How to delete a role in Postgres

Last edited: 2/21/2025

* * *

[Quote from Postgres docs:](https://www.postgresql.org/docs/current/sql-droprole.html#:~:text=A%20role%20cannot%20be%20removed,been%20granted%20on%20other%20objects.)

> A role cannot be removed if it is still referenced in any database of the cluster; an error will be raised if so. Before dropping the role, you must drop all the objects it owns (or reassign their ownership) and revoke any privileges the role has been granted on other objects.

First make sure that Postgres has ownership over the role:

`
GRANT <role> TO "postgres";
`

Then you must reassign any objects owned by role:

`
REASSIGN OWNED BY <role> TO postgres;
`

Once ownership is transferred, you can run the following query:

`
DROP OWNED BY <role>;
`

[DROP OWNED BY](https://www.postgresql.org/docs/current/sql-drop-owned.html) does delete all objects owned by the role, which should be none. However, it also revokes the role's privileges. Once this is done, you should be able to run:

`
DROP role <role>;
`

If you encounter any issues, create a [support ticket](https://supabase.com/dashboard/support/new)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_how_to_interpret_and_explore_the_postgres_logs_OuCIOj.md">
# How to Interpret and Explore the Postgres Logs

Last edited: 2/21/2025

* * *

> A complimentary guide was made for the [API logs](https://github.com/orgs/supabase/discussions/22849)

# Debugging and monitoring Postgres with logs

Logs provide insights into Postgres operations. They help meet compliance requirements, detect suspicious activity, and troubleshoot problems.

## Table of contents [\#](https://supabase.com/docs/guides/troubleshooting/how-to-interpret-and-explore-the-postgres-logs-OuCIOj\#table-of-contents)

- Querying Logs
  - `postgres_logs` Table Structure
- Filtering Logs
  - Routine Events
  - By Timeframe
  - By Error Severity
  - By Query
  - By APIs/Roles
  - By Supabase Dashboard Queries
  - Full Example For Finding Errors
- Logging for Compliance and Security
- Reviewing Log Settings
- Changing Log Settings
  - Severity levels
  - Configuring queries logged
  - Logging within functions
- Frequently Asked Questions
- Other resources

## Querying logs [\#](https://supabase.com/docs/guides/troubleshooting/how-to-interpret-and-explore-the-postgres-logs-OuCIOj\#querying-logs)

The most practical way to explore and filter logs is through the [Logs Explorer](https://supabase.com/dashboard/project/_/logs/explorer).

It uses a subset of BigQuery SQL syntax and pre-parses queries for optimization. This imposes three primary limitations:

- No subqueries or `WITH` statements
- No `*` wildcards for column names
- No `ILIKE` statements

Although there are many strategies to filter logs, such as `like` and `in` statements, a helper function called [`regexp_contains`](https://github.com/orgs/supabase/discussions/22640) provides the most flexibility and control.

The `postgres_logs` table contains Postgres events.

### `postgres_logs` table structure [\#](https://supabase.com/docs/guides/troubleshooting/how-to-interpret-and-explore-the-postgres-logs-OuCIOj\#postgreslogs-table-structure)

The table contains 3 fundamental columns:

| column | description |
| --- | --- |
| event\_message | the log's message |
| timestamp | time event was recorded |
| parsed metadata | metadata about event |

The parsed metadata column is an array that contains relevant information about events. To access the information, it must be unnested. This is done with a `cross join`.

**Unnesting example**

`
select
event_message,
parsed.<column name>
from
postgres_logs
-- Unpack data stored in the 'metadata' field
cross join unnest(metadata) AS metadata
-- After unpacking the 'metadata' field, extract the 'parsed' field from it
cross join unnest(parsed) AS parsed;
`

### Parsed metadata fields [\#](https://supabase.com/docs/guides/troubleshooting/how-to-interpret-and-explore-the-postgres-logs-OuCIOj\#parsed-metadata-fields)

#### Query information [\#](https://supabase.com/docs/guides/troubleshooting/how-to-interpret-and-explore-the-postgres-logs-OuCIOj\#query-information)

| Field | Description | Example |
| --- | --- | --- |
| parsed.query | The SQL query executed | `SELECT * FROM table;` |
| parsed.command\_tag | Tag identifying the type of command (e.g., SELECT) | `SELECT`, `INSERT`, `UPDATE`... |
| parsed.internal\_query | An internal query that is used to facilitate a primary query. Often used by realtime for certain tasks | `select to_jsonb()` |

**Suggested use cases:**

- Identifying slow queries
- Identifying failing queries

#### Error/Warning information [\#](https://supabase.com/docs/guides/troubleshooting/how-to-interpret-and-explore-the-postgres-logs-OuCIOj\#errorwarning-information)

| Field | Description | Example |
| --- | --- | --- |
| parsed.error\_severity | [event severity](https://supabase.com/docs/guides/troubleshooting/how-to-interpret-and-explore-the-postgres-logs-OuCIOj#severity-levels) | `LOG`, `WARNING`, `ERROR`... |
| parsed.detail | Explanation of the event according to Postgres | "Key (fk\_table)=(553585367) already exists." |
| parsed.sql\_state\_code | An error code that maps to Postgres's error table | `42501` |
| parsed.hint | Hint on how to solve the error | "No function matches the given name and argument types. You might need to add explicit type casts." |
| parsed.context | Provides insight into where an error may have occurred | "PL/pgSQL function public.find\_text(public.vector,integer) line 3 at IF" |

**Suggested use cases:**

- Filter by error severity or SQL code
- Get hints, details, and context about error events

#### Connection/Identification information [\#](https://supabase.com/docs/guides/troubleshooting/how-to-interpret-and-explore-the-postgres-logs-OuCIOj\#connectionidentification-information)

| Field | Description | Example |
| --- | --- | --- |
| parsed.session\_id | The session ID | 12345 |
| parsed.session\_start\_time | The start time of the session | 2024-05-08 15:30:00 |
| parsed.connection\_from | The connection IP | 192.165.1.100 |
| parsed.user\_name | The name of the connecting database user | `postgres` |
| parsed.application\_name | The name of the application | Supavisor, PostgREST |
| parsed.database\_name | The name of the database | `postgres` |
| parsed.process\_id | The process ID, often used to identify extension workers | 1234 |
| parsed.backend\_type | Determine if the event originated internally (e.g., from background workers like pg\_net, timescale, or pg\_cron) or externally from a client ( `client backend`) | `client backend` |

**Suggested use cases:**

- Identify events by server/API
- Filter connections by IP
- Identify connections to specific databases
- Filter connections by sessions for debugging
- identify extension events

## Filtering logs [\#](https://supabase.com/docs/guides/troubleshooting/how-to-interpret-and-explore-the-postgres-logs-OuCIOj\#filtering-logs)

### Excluding routine events [\#](https://supabase.com/docs/guides/troubleshooting/how-to-interpret-and-explore-the-postgres-logs-OuCIOj\#excluding-routine-events)

Most Postgres logs during normal periods are routine events, such as connection authorizations and checkpoints. To see the default types of events that are logged, you can check this [guide](https://gist.github.com/TheOtherBrian1/991d32c2b00dbc75d29b80d4cdf41aa7).

When exploring the logs for atypical behavior, it's often strategic to filter out expected values. This can be done by adding the following filter to your queries:

`
...query
where
  -- Excluding routine events related to cron, PgBouncer, checkpoints, and successful connections
not regexp_contains(event_message, '^cron|PgBouncer|checkpoint|connection received|authenticated|authorized';
`

### By timeframe [\#](https://supabase.com/docs/guides/troubleshooting/how-to-interpret-and-explore-the-postgres-logs-OuCIOj\#by-timeframe)

To investigate issues around a specific period:

`
-- filtering by time period
...query
where
timestamp between '2024-05-06 04:44:00' and '2024-05-06 04:45:00'
`

### By error severity [\#](https://supabase.com/docs/guides/troubleshooting/how-to-interpret-and-explore-the-postgres-logs-OuCIOj\#by-error-severity)

This filter finds all errors, fatals, and panics:

| Severity | Usage |
| --- | --- |
| ERROR | Reports an error that caused the current command to abort. |
| FATAL | Reports an error that caused the current session to abort. |
| PANIC | Reports an error that caused all database sessions to abort. |

`
-- find error events
... query
where
parsed.error_severity in ('ERROR', 'FATAL', 'PANIC')
`

Failure events include an sql\_state\_code that can be referenced in the [Postgres Docs](https://www.postgresql.org/docs/current/errcodes-appendix.html)

### By query [\#](https://supabase.com/docs/guides/troubleshooting/how-to-interpret-and-explore-the-postgres-logs-OuCIOj\#by-query)

> NOTE: Unless pg\_audit is configured, only failed queries are logged

`
-- find queries executed by the Dashboard
...query
where
regexp_contains(parsed.query, '(?i)select . <some table>')
`

Queries can use complex syntax, so it is often helpful to isolate by referenced database objects, such as `functions`, `tables`, and `columns`. Because query structures can be complex, it is advised to use [regex](https://github.com/orgs/supabase/discussions/22640) to find matches. Some common regex patterns are:

- `(?i)`: ignore case sensitivity
- `.`: wildcard
- `^`: look for values at start of string
- `|`: or operator

## By APIs/roles [\#](https://supabase.com/docs/guides/troubleshooting/how-to-interpret-and-explore-the-postgres-logs-OuCIOj\#by-apisroles)

All failed queries, including those from PostgREST, Auth, and external libraries (e.g., Prisma) are logged with helpful error messages for debugging.

#### Server/Role mapping [\#](https://supabase.com/docs/guides/troubleshooting/how-to-interpret-and-explore-the-postgres-logs-OuCIOj\#serverrole-mapping)

API servers have assigned database roles for connecting to the database:

| Role | API/Tool |
| --- | --- |
| `supabase_admin` | Used by Supabase to configure projects and for monitoring |
| `authenticator` | PostgREST |
| `supabase_auth_admin` | Auth |
| `supabase_storage_admin` | Storage |
| `supabase_realtime_admin` | Realtime |
| `supabase_replication_admin` | Synchronizes Read Replicas |
| `postgres` | Supabase Dashboard and External Tools (e.g., Prisma, SQLAlchemy, PSQL...) |
| Custom roles | External Tools (e.g., Prisma, SQLAlchemy, PSQL...) |

Filter by the `parsed.user_name` role to only retrieve logs made by specific roles:

`
-- find events based on role/server
... query
where
  -- find events from the relevant role
parsed.user_name = '<ROLE>'
...
`

## By Dashboard queries [\#](https://supabase.com/docs/guides/troubleshooting/how-to-interpret-and-explore-the-postgres-logs-OuCIOj\#by-dashboard-queries)

Queries from the Supabase Dashboard are executed under the `postgres` role and include the comment `-- source: dashboard`. To isolate or exclude Dashboard requests during debugging, you can filter by this comment.

`
-- find queries executed by the Dashboard
...query
where
regexp_contains(parsed.query, '-- source: dashboard')
`

## Full example for finding errors [\#](https://supabase.com/docs/guides/troubleshooting/how-to-interpret-and-explore-the-postgres-logs-OuCIOj\#full-example-for-finding-errors)

`
select
cast(postgres_logs.timestamp as datetime) as timestamp,
event_message,
parsed.error_severity,
parsed.user_name,
parsed.query,
parsed.detail,
parsed.hint,
parsed.sql_state_code,
parsed.backend_type
from
postgres_logs
cross join unnest(metadata) as metadata
cross join unnest(metadata.parsed) as parsed
where
regexp_contains(parsed.error_severity, 'ERROR|FATAL|PANIC')
and parsed.user_name = 'postgres'
and regexp_contains(event_message, 'duration|operator')
and not regexp_contains(parsed.query, '<key words>')
and postgres_logs.timestamp between '2024-04-15 10:50:00' and '2024-04-15 10:50:27'
order by timestamp desc
limit 100;
`

# Logging for compliance and security

### Customized object and role activity logging [\#](https://supabase.com/docs/guides/troubleshooting/how-to-interpret-and-explore-the-postgres-logs-OuCIOj\#customized-object-and-role-activity-logging)

>  NOTE: This is specifically designated for those using the `postgres` role or [custom roles](https://supabase.com/docs/guides/database/postgres/roles) to interact with their database. Those utilizing the Database REST API should reference the [Database API Logging Guide](https://github.com/orgs/supabase/discussions/22849) instead.

When recording what is accessed and by whom, logging based on database roles and objects is the most reliable way to ensure a proper trail of activity.

You can use the [pg\_audit](https://supabase.com/docs/guides/database/extensions/pgaudit) extension to selectively log relevant queries (not just errors) by certain roles, against specific database objects.

You should take care when using the extension to not log all database events, but only what is absolutely necessary. Over-logging can strain the database and create log noise that makes it difficult to filter for relevant events.

**Filtering by pg\_audit**:

`
... query
where
 -- all pg_audit recorded events start with 'AUDIT'
regexp_contains(event_message, '^AUDIT')
and
 -- Finding queries executed from the relevant role (e.g., 'API_role')
parsed.user_name = 'API_role'
`

### Filtering by IP [\#](https://supabase.com/docs/guides/troubleshooting/how-to-interpret-and-explore-the-postgres-logs-OuCIOj\#filtering-by-ip)

> If you are connecting from a known, limited range of IP addresses, you should enable [network restrictions](https://supabase.com/docs/guides/platform/network-restrictions).

Monitoring IPs becomes tricky when dealing with dynamic addressing, such as those from serverless or edge environments. This challenge amplifies when relying on certain poolers, such as Prisma Accelerate, Supavisor, or Cloudflare's Hyperdrive, as they record the pooler's IP, not the true origin.

IP tracking is most effective when consistently relying on direct database connections from servers with static IP addresses:

`
-- filter by IP
select
event_message,
connection_from as ip,
count(connection_from) as ip_count
from
postgres_logs
cross join unnest(metadata) as metadata
cross join unnest(parsed) as parsed
where
regexp_contains(user_name, '<ROLE>')
and regexp_contains(backend_type, 'client backend') -- only search for connections from outside the database (excludes cron jobs)
and regexp_contains(event_message, '^connection authenticated') -- only view successful authentication events
group by connection_from, event_message
order by ip_count desc
limit 100;
`

# Reviewing log settings

The `pg_settings` table describes system and logging configurations.

`
-- view system variables
select * from pg_settings;
`

The settings that affect logs are categorized under:

| Category | Description |
| --- | --- |
| `Reporting and Logging / What to Log` | Specifies system events worth logging. |
| `Reporting and Logging / When to Log` | Specifies certain conditions or rules for logging |
| `Customized Options` | Configures extensions and loaded modules, including those enhancing logging like auto\_explain and pg\_audit. |

To view all log settings for your database, you can execute the following SQL:

`
-- view all log related settings
select *
from pg_settings
where
(
    category like 'Reporting and Logging / What to Log'
    or category like 'Reporting and Logging / When to Log'
    or category = 'Customized Options'
)
and name like '%log%';
`

## Changing log settings [\#](https://supabase.com/docs/guides/troubleshooting/how-to-interpret-and-explore-the-postgres-logs-OuCIOj\#changing-log-settings)

> WARNING: lenient settings can lead to over-logging, impacting database performance while creating noise in the logs.

#### Severity levels [\#](https://supabase.com/docs/guides/troubleshooting/how-to-interpret-and-explore-the-postgres-logs-OuCIOj\#severity-levels)

The `log_min_messages` variable determines what is severe enough to log. Here are the severity thresholds from the [Postgres docs](https://www.postgresql.org/docs/current/runtime-config-logging.html).

| Severity | Usage |
| --- | --- |
| DEBUG1 .. DEBUG5 | Provides successively-more-detailed information for use by developers. |
| INFO | Provides information implicitly requested by the user, e.g., output from VACUUM VERBOSE. |
| NOTICE | Provides information that might be helpful to users, e.g., notice of truncation of long identifiers. |
| WARNING | Provides warnings of likely problems, e.g., COMMIT outside a transaction block. |
| ERROR | Reports an error that caused the current command to abort. |
| LOG | Reports information of interest to administrators, e.g., checkpoint activity. |
| FATAL | Reports an error that caused the current session to abort. |
| PANIC | Reports an error that caused all database sessions to abort. |

In most cases, the default is adequate. However, if you must adjust the setting, you can do so with the following query:

`
alter role postgres set log_min_messages = '<NEW VALUE>';
-- view new setting
show log_min_messages; -- default WARNING
`

#### Configuring queries logged [\#](https://supabase.com/docs/guides/troubleshooting/how-to-interpret-and-explore-the-postgres-logs-OuCIOj\#configuring-queries-logged)

By default, only failed queries are logged. The [PGAudit extension](https://supabase.com/docs/guides/database/extensions/pgaudit) extends Postgres's built-in logging abilities. It can be used to selectively track all queries in your database by:

- role
- session
- database object
- entire database

#### Logging within database functions [\#](https://supabase.com/docs/guides/troubleshooting/how-to-interpret-and-explore-the-postgres-logs-OuCIOj\#logging-within-database-functions)

To track or debug functions, logging can be configured by following the [function debugging guide](https://supabase.com/docs/guides/database/functions#general-logging)

# Frequently Asked Questions

#### How to join different log tables [\#](https://supabase.com/docs/guides/troubleshooting/how-to-interpret-and-explore-the-postgres-logs-OuCIOj\#how-to-join-different-log-tables)

No, log tables are independent from each other and do not share any primary/foreign key relations for joining.

#### How to download logs [\#](https://supabase.com/docs/guides/troubleshooting/how-to-interpret-and-explore-the-postgres-logs-OuCIOj\#how-to-download-logs)

At the moment, the way to download logs is through the Log Dashboard as a CSV

#### What is logged? [\#](https://supabase.com/docs/guides/troubleshooting/how-to-interpret-and-explore-the-postgres-logs-OuCIOj\#what-is-logged)

To see the default types of events that are logged, you can check this [guide](https://gist.github.com/TheOtherBrian1/991d32c2b00dbc75d29b80d4cdf41aa7).

### Other resources: [\#](https://supabase.com/docs/guides/troubleshooting/how-to-interpret-and-explore-the-postgres-logs-OuCIOj\#other-resources)

- [Regex for filtering logs](https://github.com/orgs/supabase/discussions/22640)
- [Debugging with the DB API logs](https://github.com/orgs/supabase/discussions/22849)
- [Debugging Database Functions](https://supabase.com/docs/guides/database/functions#debugging-functions)
- [pg\_audit](https://supabase.com/docs/guides/database/extensions/pgaudit)
- [Supabase Logging](https://supabase.com/docs/guides/platform/logs)
- [Self-Hosting Logs](https://supabase.com/docs/reference/self-hosting-analytics/introduction)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_how_to_migrate_from_supabase_auth_helpers_to_ssr_package_5NRunM.md">
# How to Migrate from Supabase Auth Helpers to SSR package

Last edited: 2/21/2025

* * *

The `auth-helpers` packages are being deprecated and replaced with the `@supabase/ssr` package. We recommend migrating to the `@supabase/ssr` package as future bug fixes and feature releases are focused on the `@supabase/ssr` package.

Here are the steps for you to migrate your application from the `auth-helpers` package to `@supabase/ssr` package.

Depending on your implementation, you may ignore some parts of this documentation and use your own implementation (i.e. using API routes vs. Server Actions). Whats important is you replace the clients provided by `auth-helpers` with the utility functions created using clients provided by `@supabase/ssr`.

### 1\. Uninstall Supabase Auth helpers and install the Supabase SSR package [\#](https://supabase.com/docs/guides/troubleshooting/how-to-migrate-from-supabase-auth-helpers-to-ssr-package-5NRunM\#1-uninstall-supabase-auth-helpers-and-install-the-supabase-ssr-package)

Its important that you dont use both `auth-helpers-nextjs` and `@supabase/ssr` packages in the same application to avoid running into authentication issues.

`
npm uninstall @supabase/auth-helpers-nextjs @supabase/supabase-js
npm install @supabase/ssr @supabase/supabase-js
`

### 2\. Create the utility functions to create Supabase clients. [\#](https://supabase.com/docs/guides/troubleshooting/how-to-migrate-from-supabase-auth-helpers-to-ssr-package-5NRunM\#2-create-the-utility-functions-to-create-supabase-clients)

``
// utils/supabase/client.ts
import { createBrowserClient } from '@supabase/ssr';
export function createClient() {
return createBrowserClient(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!
);
}
// utils/supabase/server.ts
import { createServerClient, type CookieOptions } from '@supabase/ssr';
import { cookies } from 'next/headers';
export function createClient() {
const cookieStore = cookies();
return createServerClient(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!,
    {
      cookies: {
        getAll() {
          return cookieStore.getAll()
        },
        setAll(cookiesToSet) {
          try {
            cookiesToSet.forEach(({ name, value, options }) =>
              cookieStore.set(name, value, options)
            )
          } catch {
            // The `setAll` method was called from a Server Component.
            // This can be ignored if you have middleware refreshing
            // user sessions.
          }
        },
      },
    }
);
}
// utils/supabase/middleware.ts
import { createServerClient } from '@supabase/ssr';
import { NextResponse, type NextRequest } from 'next/server';
export async function updateSession(request: NextRequest) {
let supabaseResponse = NextResponse.next({
    request,
});
const supabase = createServerClient(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!,
    {
      cookies: {
        getAll() {
          return request.cookies.getAll()
        },
        setAll(cookiesToSet) {
          cookiesToSet.forEach(({ name, value, options }) => request.cookies.set(name, value))
          supabaseResponse = NextResponse.next({
            request,
          })
          cookiesToSet.forEach(({ name, value, options }) =>
            supabaseResponse.cookies.set(name, value, options)
          )
        },
      },
    }
);
// IMPORTANT: Avoid writing any logic between createServerClient and
// supabase.auth.getUser(). A simple mistake could make it very hard to debug
// issues with users being randomly logged out.
const {
    data: { user },
} = await supabase.auth.getUser();
if (
    !user &&
    !request.nextUrl.pathname.startsWith('/login') &&
    !request.nextUrl.pathname.startsWith('/auth')
) {
    // no user, potentially respond by redirecting the user to the login page
    const url = request.nextUrl.clone();
    url.pathname = '/login';
    return NextResponse.redirect(url);
}
// IMPORTANT: You *must* return the supabaseResponse object as it is. If you're
// creating a new response object with NextResponse.next() make sure to:
// 1. Pass the request in it, like so:
//    const myNewResponse = NextResponse.next({ request })
// 2. Copy over the cookies, like so:
//    myNewResponse.cookies.setAll(supabaseResponse.cookies.getAll())
// 3. Change the myNewResponse object to fit your needs, but avoid changing
//    the cookies!
// 4. Finally:
//    return myNewResponse
// If this is not done, you may be causing the browser and server to go out
// of sync and terminate the user's session prematurely!
return supabaseResponse;
}
``

### 3\. Replace your middleware.ts file [\#](https://supabase.com/docs/guides/troubleshooting/how-to-migrate-from-supabase-auth-helpers-to-ssr-package-5NRunM\#3-replace-your-middlewarets-file)

`
// middleware.ts
import { type NextRequest } from 'next/server';
import { updateSession } from '@/utils/supabase/middleware';
export async function middleware(request: NextRequest) {
return await updateSession(request);
}
export const config = {
matcher: [\
    /*\
     * Match all request paths except for the ones starting with:\
     * - _next/static (static files)\
     * - _next/image (image optimization files)\
     * - favicon.ico (favicon file)\
     * Feel free to modify this pattern to include more paths.\
     */\
    '/((?!_next/static|_next/image|favicon.ico|.*\\.(?:svg|png|jpg|jpeg|gif|webp)$).*)',\
],
};
`

### 4\. Create your server actions to handle login and sign up. [\#](https://supabase.com/docs/guides/troubleshooting/how-to-migrate-from-supabase-auth-helpers-to-ssr-package-5NRunM\#4-create-your-server-actions-to-handle-login-and-sign-up)

`
// app/login/actions.ts
'use server';
import { revalidatePath } from 'next/cache';
import { redirect } from 'next/navigation';
import { createClient } from '@/utils/supabase/server';
export async function login(formData: FormData) {
const supabase = createClient();
// type-casting here for convenience
// in practice, you should validate your inputs
const data = {
    email: formData.get('email') as string,
    password: formData.get('password') as string,
};
const { error } = await supabase.auth.signInWithPassword(data)
if (error) {
    redirect('/error');
}
revalidatePath('/', 'layout');
redirect('/');
}
export async function signup(formData: FormData) {
const supabase = createClient();
// type-casting here for convenience
// in practice, you should validate your inputs
const data = {
    email: formData.get('email') as string,
    password: formData.get('password') as string,
};
const { error } = await supabase.auth.signUp(data);
if (error) {
    redirect('/error');
}
revalidatePath('/', 'layout');
redirect('/');
}
`

### 5\. Utilize the server actions in your login page UI. [\#](https://supabase.com/docs/guides/troubleshooting/how-to-migrate-from-supabase-auth-helpers-to-ssr-package-5NRunM\#5-utilize-the-server-actions-in-your-login-page-ui)

`
// app/login/page.tsx
import { login, signup } from './actions';
export default function LoginPage() {
return (
    <form>
      <label htmlFor="email">Email:</label>
      <input id="email" name="email" type="email" required />
      <label htmlFor="password">Password:</label>
      <input id="password" name="password" type="password" required />
      <button formAction={login}>Log in</button>
      <button formAction={signup}>Sign up</button>
    </form>
);
}
`

### 6\. Client components [\#](https://supabase.com/docs/guides/troubleshooting/how-to-migrate-from-supabase-auth-helpers-to-ssr-package-5NRunM\#6-client-components)

`
'use client';
// replace this line
import { createClientComponentClient } from '@supabase/auth-helpers-nextjs';
// with
import { createClient } from '@/utils/supabase/client';
export default async function Page() {
	// replace this line
	const supabase = createClientComponentClient<Database>();
	// with
	const supabase = createClient();
	return...
}
`

### 7\. Server components [\#](https://supabase.com/docs/guides/troubleshooting/how-to-migrate-from-supabase-auth-helpers-to-ssr-package-5NRunM\#7-server-components)

`
// replace
import { cookies } from 'next/headers';
import { createServerComponentClient } from '@supabase/auth-helpers-nextjs';
// with
import { createClient } from '@/utils/supabase/server';
export default async function Page() {
	// replace
	const cookieStore = cookies();
	const supabase = createServerComponentClient<Database>({
		cookies: () => cookieStore
	});
	// with
	const supabase = createClient();
	return...
}
`

### 8\. Route handlers [\#](https://supabase.com/docs/guides/troubleshooting/how-to-migrate-from-supabase-auth-helpers-to-ssr-package-5NRunM\#8-route-handlers)

`
// replace
import { createRouteHandlerClient } from '@supabase/auth-helpers-nextjs';
import { cookies } from 'next/headers';
// with
import { createClient } from '@/utils/supabase/server';
export async function POST(request: Request) {
	// replace
	const supabase = createRouteHandlerClient<Database>({
    cookies: () => cookieStore,
});
// with
const supabase = createClient();
return...
}
`

Likewise, you can replace the clients created with `@supabase/auth-helpers-nextjs` with utility functions you created with `@supabase/ssr`.

`createMiddlewareClient`  `createServerClient` `createClientComponentClient`  `createBrowserClient` `createServerComponentClient`  `createServerClient` `createRouteHandlerClient`  `createServerClient`

You can find more clear and concise examples of creating clients in our documentation [here](https://supabase.com/docs/guides/auth/server-side/creating-a-client?queryGroups=framework&framework=nextjs&queryGroups=environment&environment=route-handler#creating-a-client).

If you have any feedback about this guide, provide them as a comment below. If you find any issues or have feedback for the `@supabase/ssr` client, post them as an issue in `@supabase/ssr` repo.

As always, our GitHub community and Discord channel are open for technical discussions and resolving your issues.

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting_how_to_view_database_metrics_uqf2z_.md">
# How to View Database Metrics

Last edited: 1/17/2025

* * *

To monitor real-time metrics of your database, like CPU, EBS, active database connections, and memory usage, you can deploy a Grafana Dashboard. Check our [GitHub repo](https://github.com/supabase/supabase-grafana) for setup instructions for local or free [Fly.io](http://fly.io/) deployments. Refer to our concise [documentation](https://supabase.com/docs/guides/platform/metrics) to learn more about the metrics endpoint.

While the [Dashboard's Reports Page](https://supabase.com/dashboard/project/_/reports) displays some metric data, it provides hourly averages, not real-time by the second data. However, it offers query metrics, which the Grafana Dashboard does not include.

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs_guides_troubleshooting.md">
# Troubleshooting

Search or browse our troubleshooting guides for solutions to common Supabase issues.

* * *

## Search and filter

Products

Error codes

Tags

Reset filters

## Matching troubleshooting entries

- [**42501 : permission denied for table http\_request\_queue**](https://supabase.com/docs/guides/troubleshooting/42501--permission-denied-for-table-httprequestqueue-KnozmQ) `42501`



Database



Feb 21

- [**All about Supabase Egress**](https://supabase.com/docs/guides/troubleshooting/all-about-supabase-egress-a_Sg_e)



PlatformDatabaseFunctionsStorageRealtimeAuthSupavisor



Feb 12

- [**An "invalid response was received from the upstream server" error when querying auth**](https://supabase.com/docs/guides/troubleshooting/an-invalid-response-was-received-from-the-upstream-server-error-when-querying-auth-RI4Vl-)



Auth



Feb 21

- [**Are all features available in self-hosted Supabase?**](https://supabase.com/docs/guides/troubleshooting/are-all-features-available-in-self-hosted-supabase-THPcqw)



Self-hosting



Jan 15

- [**Auth error: {401: invalid claim: missing sub}**](https://supabase.com/docs/guides/troubleshooting/auth-error-401-invalid-claim-missing-sub--AFwMR) `401`, `403`



Auth



Feb 4

- [**Avoiding timeouts in long running queries**](https://supabase.com/docs/guides/troubleshooting/avoiding-timeouts-in-long-running-queries-6nmbdN)



DatabasePlatform



Feb 21

- [**Canceling statement due to "statement timeout"**](https://supabase.com/docs/guides/troubleshooting/canceling-statement-due-to-statement-timeout-581wFv)



Database



Feb 4

- [**Certain operations are too complex to perform directly using the client libraries.**](https://supabase.com/docs/guides/troubleshooting/certain-operations-are-too-complex-to-perform-directly-using-the-client-libraries-8JaphH)



Database



Feb 21

- [**Change email associated with Supabase account**](https://supabase.com/docs/guides/troubleshooting/change-email-associated-with-supabase-account-T5eHNT)



PlatformAuth



Feb 4

- [**Change Project Region**](https://supabase.com/docs/guides/troubleshooting/change-project-region-eWJo5Z)



PlatformDatabaseAuth



Jan 17

- [**Check usage for monthly active users (MAU)**](https://supabase.com/docs/guides/troubleshooting/check-usage-for-monthly-active-users-mau-MwZaBs)



AuthPlatform



Jan 17

- [**Converted Github account to organization - Lost Supabase account access**](https://supabase.com/docs/guides/troubleshooting/converted-github-account-to-organisation---lost-supabase-account-access-5wsE_1)



Auth



Jan 17

- [**Customizing Emails by Language**](https://supabase.com/docs/guides/troubleshooting/customizing-emails-by-language-KZ_38Q)



Auth



Feb 4

- [**Dashboard errors when managing users**](https://supabase.com/docs/guides/troubleshooting/dashboard-errors-when-managing-users-N1ls4A) `500`,



AuthStudio



Feb 4

- [**Database Error: remaining connection slots are reserved for non-replication superuser connections**](https://supabase.com/docs/guides/troubleshooting/database-error-remaining-connection-slots-are-reserved-for-non-replication-superuser-connections-3V3nIb)



Database



Jan 18

- [**Database error saving new user**](https://supabase.com/docs/guides/troubleshooting/database-error-saving-new-user-RU_EwB)



AuthStudio



Jan 17

- [**Deprecated RLS features**](https://supabase.com/docs/guides/troubleshooting/deprecated-rls-features-Pm77Zs)



Database



Mar 7

- [**Disabling Prepared statements**](https://supabase.com/docs/guides/troubleshooting/disabling-prepared-statements-qL8lEL)



DatabaseSupavisor



Feb 4

- [**Discovering and Interpreting API Errors in the Logs**](https://supabase.com/docs/guides/troubleshooting/discovering-and-interpreting-api-errors-in-the-logs-7xREI9)



DatabasePlatform



Feb 21

- [**Do I need to expose "security definer" Functions in Row Level Security Policies?**](https://supabase.com/docs/guides/troubleshooting/do-i-need-to-expose-security-definer-functions-in-row-level-security-policies-iI0uOw)



Database



Mar 7

- [**How to download logical backups in Supabase with physical backups enabled?**](https://supabase.com/docs/guides/troubleshooting/download-logical-backups)



Database



Feb 21

- [**Edge Function 'wall clock time limit reached'**](https://supabase.com/docs/guides/troubleshooting/edge-function-wall-clock-time-limit-reached-Nk38bW) `546`



Functions



Jan 17

- [**Error: "Connection refused" when trying to connect to Supabase database**](https://supabase.com/docs/guides/troubleshooting/error-connection-refused-when-trying-to-connect-to-supabase-database-hwG0Dr)



DatabaseCli



Jan 18

- [**Error: index row size exceeds btree version 4 maximum for index**](https://supabase.com/docs/guides/troubleshooting/error-index-row-size-exceeds-btree-version-4-maximum-for-index-LMmoeU)



Database



Feb 4

- [**Error: "Invalid TOTP code entered"**](https://supabase.com/docs/guides/troubleshooting/error-invalid-totp-code-entered-CukLCj)



Auth



Feb 21

- [**error: no pg\_hba.conf entry for host "xx.xxx.xxx.xxx", user "postgres", database "postgres", SSL off**](https://supabase.com/docs/guides/troubleshooting/error-no-pghbaconf-entry-for-host-xxxxxxxxxxx-user-postgres-database-postgres-ssl-off-GOt5Ja)



DatabasePlatform



Jan 18

- [**Error: prepared statement "XXX" already exists**](https://supabase.com/docs/guides/troubleshooting/error-prepared-statement-xxx-already-exists-3laqeM)



Database



Jan 17

- [**High Disk I/O**](https://supabase.com/docs/guides/troubleshooting/exhaust-disk-io)



Platform



Feb 28

- [**High RAM usage**](https://supabase.com/docs/guides/troubleshooting/exhaust-ram)



Platform



Feb 3

- [**High swap usage**](https://supabase.com/docs/guides/troubleshooting/exhaust-swap)



DatabasePlatform



Feb 3

- [**Failed to Fetch in dashboard and other areas -- browser extension**](https://supabase.com/docs/guides/troubleshooting/failed-to-fetch-in-dashboard-and-other-areas----browser-extension-dyDTRU)



Studio



Jan 18

- [**Failed to restore from backup: All subscriptions and replication slots must be dropped before a backup can be restored.**](https://supabase.com/docs/guides/troubleshooting/failed-to-restore-from-backup-all-subscriptions-and-replication-slots-must-be-dropped-before-a-backup-can-be-restored-L-rCvt)



Database



Jan 18

- [**Fetch requests to API endpoints aren't showing the session**](https://supabase.com/docs/guides/troubleshooting/fetch-requests-to-api-endpoints-arent-showing-the-session-UbUwRs)



Auth



Jan 18

- [**Fixing 520 Errors in the Database REST API**](https://supabase.com/docs/guides/troubleshooting/fixing-520-errors-in-the-database-rest-api-Ur5-B2) `520`



Database



Jan 17

- [**Forbidden resource error from the CLI**](https://supabase.com/docs/guides/troubleshooting/forbidden-resource-error-from-the-cli-L6rm6l) `403`



CliPlatform



Feb 21

- [**Google Auth fails for some users**](https://supabase.com/docs/guides/troubleshooting/google-auth-fails-for-some-users-XcFXEu) `500 server_error`, `401 UNAUTHENTICATED`



Auth



Jan 17

- [**Grafana not displaying data**](https://supabase.com/docs/guides/troubleshooting/grafana-not-displaying-data-sXJrMj)



Database



Feb 4

- [**High CPU usage**](https://supabase.com/docs/guides/troubleshooting/high-cpu-usage)



Platform



Feb 3

- [**High latency with supabase client**](https://supabase.com/docs/guides/troubleshooting/high-latency-with-supabase-client-z0pZzR)



DatabasePlatform



Feb 4

- [**How can I revoke execution of a PostgreSQL function?**](https://supabase.com/docs/guides/troubleshooting/how-can-i-revoke-execution-of-a-postgresql-function-2GYb0A)



DatabaseFunctions



Jan 17

- [**How do I check GoTrue/API version of a Supabase project?**](https://supabase.com/docs/guides/troubleshooting/how-do-i-check-gotrueapi-version-of-a-supabase-project-lQAnOR)



AuthPlatform



Jan 17

- [**How do I make the cookies HttpOnly?**](https://supabase.com/docs/guides/troubleshooting/how-do-i-make-the-cookies-httponly-vwweFx)



Auth



Jan 17

- [**How do I reset my Supabase database password?**](https://supabase.com/docs/guides/troubleshooting/how-do-i-reset-my-supabase-database-password-oTs5sB)



Database



Jan 17

- [**How do I update connection pool settings in my dashboard?**](https://supabase.com/docs/guides/troubleshooting/how-do-i-update-connection-pool-settings-in-my-dashboard-wAxTJ_)



DatabaseSupavisor



Feb 21

- [**How do you troubleshoot Next.js - Supabase Auth issues?**](https://supabase.com/docs/guides/troubleshooting/how-do-you-troubleshoot-nextjs---supabase-auth-issues-riMCZV)



Auth



Feb 21

- [**How long does it take to restore a database from a Point-in-Time backup (PITR)?**](https://supabase.com/docs/guides/troubleshooting/how-long-does-it-take-to-restore-a-database-from-a-point-in-time-backup-pitr-qO8gOG)



Database



Jan 18

- [**How Postgres chooses which index to use**](https://supabase.com/docs/guides/troubleshooting/how-postgres-chooses-which-index-to-use-_JHrf4)



Database



Feb 21

- [**How to change max database connections**](https://supabase.com/docs/guides/troubleshooting/how-to-change-max-database-connections-_BQ8P5)



DatabaseSupavisorCli



Feb 21

- [**How to check if my queries are being blocked by other queries?**](https://supabase.com/docs/guides/troubleshooting/how-to-check-if-my-queries-are-being-blocked-by-other-queries-NSKtR1)



Database



Jan 17

- [**How to delete a role in Postgres**](https://supabase.com/docs/guides/troubleshooting/how-to-delete-a-role-in-postgres-8-AvxY)



Database



Feb 21

- [**How to Interpret and Explore the Postgres Logs**](https://supabase.com/docs/guides/troubleshooting/how-to-interpret-and-explore-the-postgres-logs-OuCIOj)



DatabasePlatform



Feb 21

- [**How to Migrate from Supabase Auth Helpers to SSR package**](https://supabase.com/docs/guides/troubleshooting/how-to-migrate-from-supabase-auth-helpers-to-ssr-package-5NRunM)



Auth



Feb 21

- [**How to View Database Metrics**](https://supabase.com/docs/guides/troubleshooting/how-to-view-database-metrics-uqf2z_)



DatabasePlatform



Jan 17

- [**Diagnose HTTP API issues**](https://supabase.com/docs/guides/troubleshooting/http-api-issues) `5xx`,



Platform



Feb 3

- [**HTTP status codes**](https://supabase.com/docs/guides/troubleshooting/http-status-codes) `402`, `540`, `544`, `546`



Platform



Feb 3

- [**I am not receiving password reset emails for Supabase dashboard**](https://supabase.com/docs/guides/troubleshooting/i-am-not-receiving-password-reset-emails-for-supabase-dashboard--cO5yf)



AuthPlatform



Feb 21

- [**Importing Stripe or other modules from esm.sh on Deno Edge Functions throws an error**](https://supabase.com/docs/guides/troubleshooting/importing-stripe-or-other-modules-from-esmsh-on-deno-edge-functions-throws-an-error-TmbB5p)



Functions



Jan 17

- [**Increase vector lookup speeds by applying an HSNW index**](https://supabase.com/docs/guides/troubleshooting/increase-vector-lookup-speeds-by-applying-an-hsnw-index-ohLHUM)



DatabaseAiPlatform



Feb 4

- [**Inserting into Sequence/Serial Table Causes "duplicate key violates unique constraint" Error**](https://supabase.com/docs/guides/troubleshooting/inserting-into-sequenceserial-table-causes-duplicate-key-violates-unique-constraint-error-pi6DnC)



Database



Jan 16

- [**Inspecting edge function environment variables**](https://supabase.com/docs/guides/troubleshooting/inspecting-edge-function-environment-variables-wg5qOQ)



FunctionsCli



Feb 4

- [**"insufficient privilege" when accessing pg\_stat\_statements**](https://supabase.com/docs/guides/troubleshooting/insufficient-privilege-when-accessing-pgstatstatements-e5M_EQ)



Database



Jan 16

- [**Interpreting Supabase Grafana CPU charts**](https://supabase.com/docs/guides/troubleshooting/interpreting-supabase-grafana-cpu-charts-9JSlkC)



PlatformDatabase



Jan 17

- [**Interpreting Supabase Grafana IO charts**](https://supabase.com/docs/guides/troubleshooting/interpreting-supabase-grafana-io-charts-MUynDR)



DatabasePlatform



Jan 17

- [**"JWT Expired" Error in Supabase Dashboard**](https://supabase.com/docs/guides/troubleshooting/jwt-expired-error-in-supabase-dashboard-F06k3x)



Studio



Jan 18

- [**Lost access/Forgot the MFA device**](https://supabase.com/docs/guides/troubleshooting/lost-accessforgot-the-mfa-device-nAPT-7)



AuthPlatform



Jan 17

- [**Memory and Swap usage explained**](https://supabase.com/docs/guides/troubleshooting/memory-and-swap-usage-explained-aPNgm0)



DatabasePlatform



Feb 4

- [**How to monitor Postgres and Supavisor connections**](https://supabase.com/docs/guides/troubleshooting/monitor-supavisor-postgres-connections)



DatabaseSupavisor



Feb 13

- [**NEW variable is null in a trigger function.**](https://supabase.com/docs/guides/troubleshooting/new-variable-is-null-in-a-trigger-function--l9AOZ)



DatabaseFunctions



Jan 16

- [**Next.js 13/14 stale data when changing RLS or table data.**](https://supabase.com/docs/guides/troubleshooting/nextjs-1314-stale-data-when-changing-rls-or-table-data-85b8oQ)



AuthPlatform



Feb 21

- [**No toast messages on the Dashboard**](https://supabase.com/docs/guides/troubleshooting/no-toast-messages-on-the-dashboard-BrvP8h)



Studio



Jan 18

- [**Not receiving Auth emails from the Supabase project**](https://supabase.com/docs/guides/troubleshooting/not-receiving-auth-emails-from-the-supabase-project-OFSNzw)



AuthPlatform



Feb 21

- [**OAuth sign in isn't redirecting on the server side**](https://supabase.com/docs/guides/troubleshooting/oauth-sign-in-isnt-redirecting-on-the-server-side-ShGMtr)



Auth



Feb 4

- [**Partitioning an existing table with same name**](https://supabase.com/docs/guides/troubleshooting/partitioning-an-existing-table-with-same-name-VEnbzK)



Database



Feb 4

- [**Pausing Pro-Projects**](https://supabase.com/docs/guides/troubleshooting/pausing-pro-projects-vNL-2a)



PlatformCliStorage



Feb 12

- [**Performing administration tasks on the server side with the service\_role secret**](https://supabase.com/docs/guides/troubleshooting/performing-administration-tasks-on-the-server-side-with-the-servicerole-secret-BYM4Fa)



AuthPlatform



Jan 15

- [**pg\_cron debugging guide**](https://supabase.com/docs/guides/troubleshooting/pgcron-debugging-guide-n1KTaz)



Database



Feb 21

- [**Prisma Error Management**](https://supabase.com/docs/guides/troubleshooting/prisma-error-management-Cm5P_o)



Database



Feb 21

- [**Realtime "Concurrent Peak Connections" quota**](https://supabase.com/docs/guides/troubleshooting/realtime-concurrent-peak-connections-quota-jdDqcp)



RealtimeSelf-hosting



Mar 7

- [**Resolving 42P01: relation does not exist error**](https://supabase.com/docs/guides/troubleshooting/resolving-42p01-relation-does-not-exist-error-W4_9-V) `42P01`, `42501`



Database



Jan 16

- [**Resolving 500 Status Authentication Errors**](https://supabase.com/docs/guides/troubleshooting/resolving-500-status-authentication-errors-7bU5U8) `500`



AuthDatabase



Feb 21

- [**Resolving database hostname and managing your IP address**](https://supabase.com/docs/guides/troubleshooting/resolving-database-hostname-and-managing-your-ip-address-pVlwE0)



Database



Feb 4

- [**RLS Performance and Best Practices**](https://supabase.com/docs/guides/troubleshooting/rls-performance-and-best-practices-Z5Jjwv)



AuthDatabase



Feb 21

- [**RLS Simplified**](https://supabase.com/docs/guides/troubleshooting/rls-simplified-BJTcS8)



DatabaseAuth



Feb 21

- [**Rotating Anon, Service, and JWT Secrets**](https://supabase.com/docs/guides/troubleshooting/rotating-anon-service-and-jwt-secrets-1Jq6yd)



AuthPlatform



Feb 21

- [**Security of Anonymous Sign-ins**](https://supabase.com/docs/guides/troubleshooting/security-of-anonymous-sign-ins-iOrGCL)



AuthPlatform



Feb 21

- [**Seeing "no pg\_hba.conf entry for host" errors in Postgres and they come from an IP address that I don't recognize**](https://supabase.com/docs/guides/troubleshooting/seeing-no-pghbaconf-entry-for-host-errors-in-postgres-and-they-come-from-an-ip-address-that-i-dont-recognize-4gds9f)



DatabasePlatform



Feb 4

- [**Should I set a shorter Max-Age parameter on the cookies?**](https://supabase.com/docs/guides/troubleshooting/should-i-set-a-shorter-max-age-parameter-on-the-cookies-8sbF4V)



Auth



Jan 17

- [**Slow Execution of ALTER TABLE on Large Table when changing column type**](https://supabase.com/docs/guides/troubleshooting/slow-execution-of-alter-table-on-large-table-when-changing-column-type-qmZRpZ)



Database



Jan 17

- [**Steps to improve query performance with indexes**](https://supabase.com/docs/guides/troubleshooting/steps-to-improve-query-performance-with-indexes-q8PoC9)



DatabasePlatformCli



Feb 21

- [**Supabase & Your Network: IPv4 and IPv6 compatibility**](https://supabase.com/docs/guides/troubleshooting/supabase--your-network-ipv4-and-ipv6-compatibility-cHe3BP)



DatabasePlatformSupavisor



Feb 4

- [**Supabase dashboard not loading/ Project not loading on dashboard**](https://supabase.com/docs/guides/troubleshooting/supabase-dashboard-not-loading-project-not-loading-on-dashboard-LfMq9F)



Studio



Feb 21

- [**Interpreting Supabase Grafana Memory Charts**](https://supabase.com/docs/guides/troubleshooting/supabase-grafana-memory-charts)



Database



Feb 21

- [**Supavisor and Connection Terminology Explained**](https://supabase.com/docs/guides/troubleshooting/supavisor-and-connection-terminology-explained-9pr_ZO)



SupavisorDatabase



Feb 4

- [**Supavisor FAQ**](https://supabase.com/docs/guides/troubleshooting/supavisor-faq-YyP5tI)



SupavisorDatabase



Feb 21

- [**Transferring from cloud to self-host in Supabase**](https://supabase.com/docs/guides/troubleshooting/transferring-from-cloud-to-self-host-in-supabase-2oWNvW)



DatabaseSelf-hosting



Jan 15

- [**Understanding PostgreSQL EXPLAIN Output**](https://supabase.com/docs/guides/troubleshooting/understanding-postgresql-explain-output-Un9dqX)



Database



Feb 21

- [**Understanding PostgreSQL Logging Levels and How They Impact Your Project**](https://supabase.com/docs/guides/troubleshooting/understanding-postgresql-logging-levels-and-how-they-impact-your-project-KXiJRm)



Database



Feb 21

- [**Understanding the Usage Summary on the Dashboard**](https://supabase.com/docs/guides/troubleshooting/understanding-the-usage-summary-on-the-dashboard-D7Gnle)



PlatformStudioDatabaseFunctions



Jan 18

- [**Upload file size restrictions**](https://supabase.com/docs/guides/troubleshooting/upload-file-size-restrictions-Y4wQLT)



Storage



Jan 15

- [**Using Google SMTP with Supabase Custom SMTP**](https://supabase.com/docs/guides/troubleshooting/using-google-smtp-with-supabase-custom-smtp-ZZzU4Y)



AuthPlatform



Feb 21

- [**Using SQLAlchemy with Supabase**](https://supabase.com/docs/guides/troubleshooting/using-sqlalchemy-with-supabase-FUqebT)



DatabaseSupavisorSelf-hostingFunctions



Feb 4

- [**Webhook debugging guide**](https://supabase.com/docs/guides/troubleshooting/webhook-debugging-guide-M8sk47)



Database



Feb 21

- [**Why am I being redirected to the wrong url when using auth redirectTo option?**](https://supabase.com/docs/guides/troubleshooting/why-am-i-being-redirected-to-the-wrong-url-when-using-auth-redirectto-option-_vqIeO)



Auth



Feb 21

- [**Why are there gaps in my Postgres id sequence?**](https://supabase.com/docs/guides/troubleshooting/why-are-there-gaps-in-my-postgres-id-sequence-Frifus)



Database



Feb 21

- [**Why can't I upload/list/etc my public bucket?**](https://supabase.com/docs/guides/troubleshooting/why-cant-i-uploadlistetc-my-public-bucket-Z6CmGt)



Storage



Jan 15

- [**Why do I see Auth & API requests in the dashboard? My app has no users**](https://supabase.com/docs/guides/troubleshooting/why-do-i-see-auth--api-requests-in-the-dashboard-my-app-has-no-users-CyadiO)



AuthPlatformDatabaseRealtimeFunctions



Feb 4

- [**Why is my camelCase name not working in Postgres functions or RLS policies?**](https://supabase.com/docs/guides/troubleshooting/why-is-my-camelcase-name-not-working-in-postgres-functions-or-rls-policies-EJMzVd)



Database



Jan 15

- [**Why is my select returning an empty data array and I have data in the table?**](https://supabase.com/docs/guides/troubleshooting/why-is-my-select-returning-an-empty-data-array-and-i-have-data-in-the-table-xvOPgx)



DatabaseAuth



Feb 21

- [**Why is my service role key client getting RLS errors or not returning data?**](https://supabase.com/docs/guides/troubleshooting/why-is-my-service-role-key-client-getting-rls-errors-or-not-returning-data-7_1K9z)



AuthDatabase



Feb 4

- [**Why is my supabase API call not returning?**](https://supabase.com/docs/guides/troubleshooting/why-is-my-supabase-api-call-not-returning-PGzXw0)



AuthPlatform



Feb 4

- [**Will backups be accessible from the dashboard immediately after upgrading to a paid plan?**](https://supabase.com/docs/guides/troubleshooting/will-backups-be-accessible-from-the-dashboard-immediately-after-upgrading-to-a-paid-plan-hXY4rs)



Platform



Feb 21


1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

<file path="supabase_com_docs.md">
# Supabase Documentation

Learn how to get up and running with Supabase through tutorials, APIs and platform resources.

## Getting Started

Set up and connect a database in just a few minutes.

[![ReactJS Icon](https://supabase.com/docs/img/icons/react-icon.svg)](https://supabase.com/docs/guides/getting-started/quickstarts/reactjs)[![Next.js Icon](https://supabase.com/docs/img/icons/nextjs-icon.svg)](https://supabase.com/docs/guides/getting-started/quickstarts/nextjs)[![RedwoodJS Icon](https://supabase.com/docs/img/icons/redwoodjs-icon.svg)](https://supabase.com/docs/guides/getting-started/quickstarts/redwoodjs)[![Flutter Icon](https://supabase.com/docs/img/icons/flutter-icon.svg)](https://supabase.com/docs/guides/getting-started/quickstarts/flutter)[![Android Kotlin Icon](https://supabase.com/docs/img/icons/kotlin-icon.svg)](https://supabase.com/docs/guides/getting-started/quickstarts/kotlin)[![SvelteKit Icon](https://supabase.com/docs/img/icons/svelte-icon.svg)](https://supabase.com/docs/guides/getting-started/quickstarts/sveltekit)[![SolidJS Icon](https://supabase.com/docs/img/icons/solidjs-icon.svg)](https://supabase.com/docs/guides/getting-started/quickstarts/solidjs)[![Vue Icon](https://supabase.com/docs/img/icons/vuejs-icon.svg)](https://supabase.com/docs/guides/getting-started/quickstarts/vue)[![Nuxt Icon](https://supabase.com/docs/img/icons/nuxt-icon.svg)](https://supabase.com/docs/guides/getting-started/quickstarts/nuxtjs)[![refine Icon](https://supabase.com/docs/img/icons/refine-icon.svg)](https://supabase.com/docs/guides/getting-started/quickstarts/refine)

[Start with Supabase AI prompts](https://supabase.com/docs/guides/getting-started/ai-prompts)

## Products

- [Database\\
\\
Supabase provides a full Postgres database for every project with Realtime functionality, database backups, extensions, and more.](https://supabase.com/docs/guides/database/overview)
- [Auth\\
\\
Add and manage email and password, passwordless, OAuth, and mobile logins to your project through a suite of identity providers and APIs.](https://supabase.com/docs/guides/auth)
- [Storage\\
\\
Store, organize, transform, and serve large filesfully integrated with your Postgres database with Row Level Security access policies.](https://supabase.com/docs/guides/storage)
- [Realtime\\
\\
Listen to database changes, store and sync user states across clients, broadcast data to clients subscribed to a channel, and more.](https://supabase.com/docs/guides/realtime)
- [Edge Functions\\
\\
Globally distributed, server-side functions to execute your code closest to your users for the lowest latency.](https://supabase.com/docs/guides/functions)

## Postgres Modules

[**AI & Vectors**](https://supabase.com/docs/guides/ai) [**Cron**](https://supabase.com/docs/guides/cron) [**Queues**](https://supabase.com/docs/guides/queues)

## Client Libraries

[**Javascript**](https://supabase.com/docs/reference/javascript/introduction) [**Flutter**](https://supabase.com/docs/reference/dart/introduction) [**Python**](https://supabase.com/docs/reference/python/introduction) [**C\#**](https://supabase.com/docs/reference/csharp/introduction) [**Swift**](https://supabase.com/docs/reference/swift/introduction) [**Kotlin**](https://supabase.com/docs/reference/kotlin/introduction)

## Migrate to Supabase

Bring your existing data, auth and storage to Supabase following our migration guides.

[Explore more resources about /guides/resourcesExplore more resources](https://supabase.com/docs/guides/resources)

- [![Amazon RDS Icon](https://supabase.com/docs/img/icons/aws-rds-icon.svg)\\
\\
**Amazon RDS**](https://supabase.com/docs/guides/platform/migrating-to-supabase/amazon-rds)
- [![Auth0 Icon](https://supabase.com/docs/img/icons/auth0-icon-light.svg)\\
\\
**Auth0**](https://supabase.com/docs/guides/platform/migrating-to-supabase/auth0)
- [![Firebase Auth Icon](https://supabase.com/docs/img/icons/firebase-icon.svg)\\
\\
**Firebase Auth**](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-auth)
- [![Firebase Storage Icon](https://supabase.com/docs/img/icons/firebase-icon.svg)\\
\\
**Firebase Storage**](https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-storage)
- [![Firestore Data Icon](https://supabase.com/docs/img/icons/firebase-icon.svg)\\
\\
**Firestore Data**](https://supabase.com/docs/guides/platform/migrating-to-supabase/firestore-data)
- [![Heroku Icon](https://supabase.com/docs/img/icons/heroku-icon.svg)\\
\\
**Heroku**](https://supabase.com/docs/guides/platform/migrating-to-supabase/heroku)
- [![MSSQL Icon](https://supabase.com/docs/img/icons/mssql-icon.svg)\\
\\
**MSSQL**](https://supabase.com/docs/guides/platform/migrating-to-supabase/mssql)
- [![MySQL Icon](https://supabase.com/docs/img/icons/mysql-icon.svg)\\
\\
**MySQL**](https://supabase.com/docs/guides/platform/migrating-to-supabase/mysql)
- [![Neon Icon](https://supabase.com/docs/img/icons/neon-icon-light.svg)\\
\\
**Neon**](https://supabase.com/docs/guides/platform/migrating-to-supabase/neon)
- [![Postgres Icon](https://supabase.com/docs/img/icons/postgres-icon.svg)\\
\\
**Postgres**](https://supabase.com/docs/guides/platform/migrating-to-supabase/postgres)
- [![Render Icon](https://supabase.com/docs/img/icons/render-icon.svg)\\
\\
**Render**](https://supabase.com/docs/guides/platform/migrating-to-supabase/render)
- [![Vercel Postgres Icon](https://supabase.com/docs/img/icons/vercel-icon-light.svg)\\
\\
**Vercel Postgres**](https://supabase.com/docs/guides/platform/migrating-to-supabase/vercel-postgres)

### Additional resources

- [Management API\\
\\
Manage your Supabase projects and organizations.](https://supabase.com/docs/reference/api/introduction)
- [Supabase CLI\\
\\
Use the CLI to develop, manage and deploy your projects.](https://supabase.com/docs/reference/cli/introduction)
- [Platform Guides\\
\\
Learn more about the tools and services powering Supabase.](https://supabase.com/docs/guides/platform)
- [Integrations\\
\\
Explore a variety of integrations from Supabase partners.](https://supabase.com/docs/guides/integrations)

### Self-Hosting

Get started with self-hosting Supabase.

[More on Self-Hosting about /guides/self-hostingMore on Self-Hosting](https://supabase.com/docs/guides/self-hosting)

- [**Auth**](https://supabase.com/docs/reference/self-hosting-auth/introduction)
- [**Realtime**](https://supabase.com/docs/reference/self-hosting-realtime/introduction)
- [**Storage**](https://supabase.com/docs/reference/self-hosting-storage/introduction)
- [**Analytics**](https://supabase.com/docs/reference/self-hosting-analytics/introduction)

1. We use first-party cookies to improve our services. [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)



   [Learn more](https://supabase.com/privacy#8-cookies-and-similar-technologies-used-on-our-european-services)Privacy settings





   AcceptOpt outPrivacy settings
</file>

</files>
